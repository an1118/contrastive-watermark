  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 15:17:29,187 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:05:48,  1.31it/s][INFO|trainer.py:4226] 2025-01-21 15:17:33,350 >>
{'loss': 3.2423, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.1654856204986572, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 3.5878, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.504441022872925, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 3.5702, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.5013413429260254, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.1385, 'grad_norm': 147.22314453125, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.0718538761138916, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 3.5862, 'grad_norm': 141.61846923828125, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.518846273422241, 'loss_2': 0.0673828125, 'loss_3': -13.699813842773438, 'loss_4': 9.447994232177734, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:33,350 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:33,350 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:07<1:05:48,  1.31it/s][INFO|trainer.py:3910] 2025-01-21 15:17:37,145 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 15:17:37,147 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-5/config.json                                                                               
{'eval_loss': 1.6378945112228394, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.925, 'eval_steps_per_second': 4.218, 'eval_loss_1': 1.5792511701583862, 'eval_loss_2': 0.058643341064453125, 'eval_loss_3': -17.838212966918945, 'eval_loss_4': 6.675486087799072, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:37,673 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:37,675 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:37,675 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:35:03,  1.11s/it][INFO|trainer.py:4226] 2025-01-21 15:17:42,151 >>
{'loss': 3.268, 'grad_norm': 136.22113037109375, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.2125320434570312, 'loss_2': 0.055419921875, 'loss_3': -13.888025283813477, 'loss_4': 7.273919105529785, 'epoch': 0.03}
{'loss': 2.9148, 'grad_norm': 141.96023559570312, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 2.8482308387756348, 'loss_2': 0.06658935546875, 'loss_3': -14.423583984375, 'loss_4': 7.285188674926758, 'epoch': 0.04}
{'loss': 2.5988, 'grad_norm': 141.28268432617188, 'learning_rate': 2.997093023255814e-05, 'loss_1': 2.533825397491455, 'loss_2': 0.06494140625, 'loss_3': -14.56241512298584, 'loss_4': 5.626652717590332, 'epoch': 0.05}
{'loss': 2.6858, 'grad_norm': 130.19760131835938, 'learning_rate': 2.996511627906977e-05, 'loss_1': 2.596203327178955, 'loss_2': 0.089599609375, 'loss_3': -14.678959846496582, 'loss_4': 7.619113922119141, 'epoch': 0.05}
{'loss': 2.4778, 'grad_norm': 126.07681274414062, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.379361152648926, 'loss_2': 0.09844970703125, 'loss_3': -14.804433822631836, 'loss_4': 8.133793830871582, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:42,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:42,151 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:35:03,  1.11s/it][INFO|trainer.py:3910] 2025-01-21 15:17:45,942 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 15:17:45,944 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-10/config.json                                                                              
{'eval_loss': 1.1603748798370361, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.184, 'eval_steps_per_second': 4.222, 'eval_loss_1': 1.0627566576004028, 'eval_loss_2': 0.09761810302734375, 'eval_loss_3': -17.9899959564209, 'eval_loss_4': 7.52955436706543, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:46,384 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:46,385 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:46,385 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:17:47,217 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:38:41,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:17:50,881 >>
{'loss': 2.2055, 'grad_norm': 112.51229095458984, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.107381582260132, 'loss_2': 0.09808349609375, 'loss_3': -15.071447372436523, 'loss_4': 8.290199279785156, 'epoch': 0.06}
{'loss': 2.3515, 'grad_norm': 146.66690063476562, 'learning_rate': 2.994767441860465e-05, 'loss_1': 2.243485689163208, 'loss_2': 0.10797119140625, 'loss_3': -14.856690406799316, 'loss_4': 7.429123878479004, 'epoch': 0.07}
{'loss': 2.1771, 'grad_norm': 119.96944427490234, 'learning_rate': 2.994186046511628e-05, 'loss_1': 2.0766801834106445, 'loss_2': 0.10040283203125, 'loss_3': -15.156965255737305, 'loss_4': 8.049510955810547, 'epoch': 0.08}
{'loss': 2.0272, 'grad_norm': 128.35716247558594, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 1.9199353456497192, 'loss_2': 0.10723876953125, 'loss_3': -15.035076141357422, 'loss_4': 7.18449592590332, 'epoch': 0.08}
{'loss': 1.869, 'grad_norm': 132.2090301513672, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.7740100622177124, 'loss_2': 0.094970703125, 'loss_3': -15.088424682617188, 'loss_4': 7.180980682373047, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:50,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:50,882 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:38:41,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:17:54,673 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 15:17:54,674 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-15/config.json                                                                              
{'eval_loss': 0.7382363080978394, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.21, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.6480301022529602, 'eval_loss_2': 0.09020614624023438, 'eval_loss_3': -18.001014709472656, 'eval_loss_4': 6.234018802642822, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:55,133 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:55,135 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:55,135 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:17:56,024 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:39:15,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:17:59,648 >>
{'loss': 1.708, 'grad_norm': 135.63021850585938, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.6067224740982056, 'loss_2': 0.10125732421875, 'loss_3': -15.018177032470703, 'loss_4': 6.321807861328125, 'epoch': 0.09}
{'loss': 1.902, 'grad_norm': 127.34847259521484, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.813233494758606, 'loss_2': 0.0887451171875, 'loss_3': -14.84759521484375, 'loss_4': 6.381026268005371, 'epoch': 0.1}
{'loss': 1.4085, 'grad_norm': inf, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.3175362348556519, 'loss_2': 0.09100341796875, 'loss_3': -15.11888313293457, 'loss_4': 6.193754196166992, 'epoch': 0.1}
{'loss': 1.3749, 'grad_norm': 106.89002227783203, 'learning_rate': 2.991279069767442e-05, 'loss_1': 1.2888143062591553, 'loss_2': 0.08612060546875, 'loss_3': -14.972957611083984, 'loss_4': 5.787834644317627, 'epoch': 0.11}
{'loss': 1.0953, 'grad_norm': 106.73526000976562, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 1.0128861665725708, 'loss_2': 0.08245849609375, 'loss_3': -15.298728942871094, 'loss_4': 4.526209831237793, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:59,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:59,648 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:39:15,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 15:18:03,441 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 15:18:03,442 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-20/config.json                                                                              
{'eval_loss': 0.48053961992263794, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.041, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.4079001843929291, 'eval_loss_2': 0.07263946533203125, 'eval_loss_3': -18.02615737915039, 'eval_loss_4': 5.502200126647949, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:03,967 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:03,969 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:03,969 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:04,971 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:39<1:40:55,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 15:18:08,633 >>
{'loss': 1.2492, 'grad_norm': 110.66874694824219, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 1.1667455434799194, 'loss_2': 0.08245849609375, 'loss_3': -14.987358093261719, 'loss_4': 5.0685882568359375, 'epoch': 0.12}
{'loss': 0.9945, 'grad_norm': 104.20793914794922, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 0.9047693610191345, 'loss_2': 0.0897216796875, 'loss_3': -14.967642784118652, 'loss_4': 5.70979118347168, 'epoch': 0.13}
{'loss': 0.9391, 'grad_norm': 90.25399780273438, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.8651143312454224, 'loss_2': 0.073974609375, 'loss_3': -14.956544876098633, 'loss_4': 4.995138645172119, 'epoch': 0.13}
{'loss': 0.9554, 'grad_norm': 91.91635131835938, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.8845826983451843, 'loss_2': 0.07086181640625, 'loss_3': -15.047109603881836, 'loss_4': 5.631950378417969, 'epoch': 0.14}
{'loss': 0.9412, 'grad_norm': 97.13443756103516, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.8937748670578003, 'loss_2': 0.047393798828125, 'loss_3': -15.139755249023438, 'loss_4': 5.440647602081299, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:08,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:08,633 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:43<1:40:55,  1.18s/it][INFO|trainer.py:3910] 2025-01-21 15:18:12,440 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 15:18:12,441 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-25/config.json                                                                              
{'eval_loss': 0.22205592691898346, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.16756489872932434, 'eval_loss_2': 0.05449104309082031, 'eval_loss_3': -18.275989532470703, 'eval_loss_4': 6.040822982788086, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:12,916 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:12,917 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:12,917 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:13,807 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:48<1:40:12,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:18:17,480 >>
{'loss': 0.7652, 'grad_norm': 86.7247543334961, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.7012569904327393, 'loss_2': 0.06396484375, 'loss_3': -15.289016723632812, 'loss_4': 6.4050703048706055, 'epoch': 0.15}
{'loss': 0.8906, 'grad_norm': 100.66063690185547, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.8286109566688538, 'loss_2': 0.061981201171875, 'loss_3': -15.312284469604492, 'loss_4': 7.1082658767700195, 'epoch': 0.16}
{'loss': 0.7203, 'grad_norm': 79.43562316894531, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.6638861298561096, 'loss_2': 0.05645751953125, 'loss_3': -15.280963897705078, 'loss_4': 6.642609596252441, 'epoch': 0.16}
{'loss': 0.698, 'grad_norm': 83.04134368896484, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.646381139755249, 'loss_2': 0.0516357421875, 'loss_3': -15.576639175415039, 'loss_4': 6.9060444831848145, 'epoch': 0.17}
{'loss': 0.5299, 'grad_norm': 74.68244934082031, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.48090222477912903, 'loss_2': 0.049041748046875, 'loss_3': -15.526223182678223, 'loss_4': 7.017927169799805, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:17,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:17,480 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:52<1:40:12,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 15:18:21,278 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 15:18:21,280 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-30/config.json                                                                              
{'eval_loss': 0.1770690232515335, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.703, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.13374359905719757, 'eval_loss_2': 0.04332542419433594, 'eval_loss_3': -18.18239402770996, 'eval_loss_4': 5.913290977478027, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:21,747 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:21,748 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:21,748 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:22,602 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:57<1:39:30,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:18:26,261 >>
{'loss': 0.859, 'grad_norm': 112.66020965576172, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.8140259981155396, 'loss_2': 0.04498291015625, 'loss_3': -15.074368476867676, 'loss_4': 7.434210777282715, 'epoch': 0.18}
{'loss': 0.4589, 'grad_norm': 60.09321212768555, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.41234272718429565, 'loss_2': 0.046600341796875, 'loss_3': -15.126376152038574, 'loss_4': 5.050830841064453, 'epoch': 0.19}
{'loss': 0.606, 'grad_norm': 77.22190856933594, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.5616824626922607, 'loss_2': 0.044342041015625, 'loss_3': -14.941058158874512, 'loss_4': 4.864689826965332, 'epoch': 0.19}
{'loss': 0.4547, 'grad_norm': 82.66694641113281, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.4180402457714081, 'loss_2': 0.03662109375, 'loss_3': -14.936834335327148, 'loss_4': 4.460946083068848, 'epoch': 0.2}
{'loss': 0.4702, 'grad_norm': 77.1938705444336, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.4389224052429199, 'loss_2': 0.03131103515625, 'loss_3': -14.759620666503906, 'loss_4': 4.589514255523682, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:26,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:26,261 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [01:00<1:39:30,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 15:18:30,060 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 15:18:30,061 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-35/config.json                                                                              
{'eval_loss': 0.17450666427612305, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.685, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.15174150466918945, 'eval_loss_2': 0.022765159606933594, 'eval_loss_3': -17.871482849121094, 'eval_loss_4': 4.569899559020996, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:30,552 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:30,553 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:30,554 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:31,400 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:05<1:39:27,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:18:35,060 >>
{'loss': 0.4157, 'grad_norm': 62.74057388305664, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.39765849709510803, 'loss_2': 0.01800537109375, 'loss_3': -14.907247543334961, 'loss_4': 4.794678688049316, 'epoch': 0.21}
{'loss': 0.4173, 'grad_norm': 63.62377166748047, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.3909097909927368, 'loss_2': 0.0263671875, 'loss_3': -14.763168334960938, 'loss_4': 4.681692123413086, 'epoch': 0.22}
{'loss': 0.524, 'grad_norm': 65.23575592041016, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.5037658214569092, 'loss_2': 0.0202789306640625, 'loss_3': -14.898720741271973, 'loss_4': 4.957785606384277, 'epoch': 0.22}
{'loss': 0.2642, 'grad_norm': 49.914886474609375, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.26264384388923645, 'loss_2': 0.0015840530395507812, 'loss_3': -14.837556838989258, 'loss_4': 3.951469898223877, 'epoch': 0.23}
{'loss': 0.3996, 'grad_norm': 84.59078979492188, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.39427879452705383, 'loss_2': 0.00534820556640625, 'loss_3': -14.703971862792969, 'loss_4': 4.686036109924316, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:35,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:35,060 >>   Batch size = 64
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:09<1:39:27,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 15:18:38,853 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-40
[INFO|configuration_utils.py:420] 2025-01-21 15:18:38,854 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-40/config.json                                                                              
{'eval_loss': 0.08780720829963684, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.069, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.08045069128274918, 'eval_loss_2': 0.007356524467468262, 'eval_loss_3': -17.861370086669922, 'eval_loss_4': 4.115340709686279, 'epoch': 0.23}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:39,378 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-40/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:39,379 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-40/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:39,379 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-40/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:40,259 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-35] due to args.save_total_limit
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:14<1:39:50,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:18:43,932 >>
{'loss': 0.2545, 'grad_norm': 44.0401496887207, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.24198482930660248, 'loss_2': 0.012481689453125, 'loss_3': -14.963910102844238, 'loss_4': 4.277373313903809, 'epoch': 0.24}
{'loss': 0.165, 'grad_norm': 39.26850509643555, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.15755558013916016, 'loss_2': 0.0074310302734375, 'loss_3': -14.859515190124512, 'loss_4': 3.6818645000457764, 'epoch': 0.24}
{'loss': 0.2288, 'grad_norm': 37.34702682495117, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.22111883759498596, 'loss_2': 0.00771331787109375, 'loss_3': -14.834929466247559, 'loss_4': 4.218276500701904, 'epoch': 0.25}
{'loss': 0.2891, 'grad_norm': 48.32746505737305, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.26546403765678406, 'loss_2': 0.023590087890625, 'loss_3': -14.72834587097168, 'loss_4': 4.739565849304199, 'epoch': 0.26}
{'loss': 0.2522, 'grad_norm': 51.412803649902344, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.24333392083644867, 'loss_2': 0.008819580078125, 'loss_3': -14.961731910705566, 'loss_4': 4.720120429992676, 'epoch': 0.26}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:43,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:43,932 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:18<1:39:50,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 15:18:47,779 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 15:18:47,781 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-45/config.json                                                                              
{'eval_loss': 0.06301559507846832, 'eval_runtime': 3.8455, 'eval_samples_per_second': 266.285, 'eval_steps_per_second': 4.161, 'eval_loss_1': 0.05064012110233307, 'eval_loss_2': 0.012375473976135254, 'eval_loss_3': -17.977643966674805, 'eval_loss_4': 3.876309633255005, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:48,250 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:48,251 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:48,252 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:49,137 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-40] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:23<1:39:47,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:18:52,802 >>
{'loss': 0.2682, 'grad_norm': 49.216548919677734, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.2601161003112793, 'loss_2': 0.0081329345703125, 'loss_3': -14.891458511352539, 'loss_4': 4.400896072387695, 'epoch': 0.27}
{'loss': 0.2125, 'grad_norm': 45.606624603271484, 'learning_rate': 2.975e-05, 'loss_1': 0.2075592279434204, 'loss_2': 0.004913330078125, 'loss_3': -14.685075759887695, 'loss_4': 3.4845497608184814, 'epoch': 0.27}
{'loss': 0.1591, 'grad_norm': 39.88025665283203, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.15680521726608276, 'loss_2': 0.002307891845703125, 'loss_3': -14.768047332763672, 'loss_4': 3.466057300567627, 'epoch': 0.28}
{'loss': 0.2699, 'grad_norm': 66.28799438476562, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.2682715058326721, 'loss_2': 0.0016689300537109375, 'loss_3': -14.611393928527832, 'loss_4': 3.944758176803589, 'epoch': 0.28}
{'loss': 0.1875, 'grad_norm': 38.10247802734375, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.18100781738758087, 'loss_2': 0.00653076171875, 'loss_3': -14.395451545715332, 'loss_4': 3.0554943084716797, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:52,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:52,802 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:31<1:30:32,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:19:00,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07963918149471283, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.021, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.07557480782270432, 'eval_loss_2': 0.004064381122589111, 'eval_loss_3': -17.875648498535156, 'eval_loss_4': 3.419468879699707, 'epoch': 0.29}
{'loss': 0.2771, 'grad_norm': 50.428504943847656, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.27703016996383667, 'loss_2': 3.981590270996094e-05, 'loss_3': -14.573030471801758, 'loss_4': 3.483032703399658, 'epoch': 0.3}
{'loss': 0.213, 'grad_norm': 46.92955017089844, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.20923572778701782, 'loss_2': 0.003749847412109375, 'loss_3': -14.724946975708008, 'loss_4': 3.743986129760742, 'epoch': 0.3}
{'loss': 0.1317, 'grad_norm': 28.47116470336914, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.12885119020938873, 'loss_2': 0.002834320068359375, 'loss_3': -14.704153060913086, 'loss_4': 3.2748031616210938, 'epoch': 0.31}
{'loss': 0.3525, 'grad_norm': 57.25481033325195, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.33477526903152466, 'loss_2': 0.0177154541015625, 'loss_3': -14.733901023864746, 'loss_4': 3.9181437492370605, 'epoch': 0.31}
{'loss': 0.2112, 'grad_norm': 45.364559173583984, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.20510119199752808, 'loss_2': 0.00609588623046875, 'loss_3': -14.863557815551758, 'loss_4': 3.3023905754089355, 'epoch': 0.32}
[INFO|trainer.py:4228] 2025-01-21 15:19:00,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:00,169 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:38<1:28:54,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:19:07,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08495275676250458, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.432, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.08027837425470352, 'eval_loss_2': 0.004674375057220459, 'eval_loss_3': -17.91074562072754, 'eval_loss_4': 3.3895375728607178, 'epoch': 0.32}
{'loss': 0.1528, 'grad_norm': 30.433273315429688, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.14079700410366058, 'loss_2': 0.01201629638671875, 'loss_3': -14.61478042602539, 'loss_4': 2.627145767211914, 'epoch': 0.33}
{'loss': 0.1897, 'grad_norm': 41.73222351074219, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.17906564474105835, 'loss_2': 0.0106048583984375, 'loss_3': -14.648272514343262, 'loss_4': 3.2578747272491455, 'epoch': 0.33}
{'loss': 0.1938, 'grad_norm': 40.34779739379883, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.1822071075439453, 'loss_2': 0.0115966796875, 'loss_3': -14.754659652709961, 'loss_4': 2.916555881500244, 'epoch': 0.34}
{'loss': 0.2103, 'grad_norm': 36.83732986450195, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.19826093316078186, 'loss_2': 0.012054443359375, 'loss_3': -14.931173324584961, 'loss_4': 3.579531669616699, 'epoch': 0.34}
{'loss': 0.1632, 'grad_norm': 34.72114944458008, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.15987534821033478, 'loss_2': 0.003326416015625, 'loss_3': -14.832378387451172, 'loss_4': 3.186903715133667, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 15:19:07,540 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:07,540 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:42<1:28:54,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 15:19:11,341 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-60
[INFO|configuration_utils.py:420] 2025-01-21 15:19:11,343 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-60/config.json                                                                              
{'eval_loss': 0.051885537803173065, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.461, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.04860656335949898, 'eval_loss_2': 0.003278970718383789, 'eval_loss_3': -18.060998916625977, 'eval_loss_4': 3.2879478931427, 'epoch': 0.35}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:11,843 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-60/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:11,844 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:11,845 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-60/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:12,744 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-45] due to args.save_total_limit
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:47<1:37:41,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:19:16,397 >>
{'loss': 0.2323, 'grad_norm': 42.9239387512207, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.2251560091972351, 'loss_2': 0.0070953369140625, 'loss_3': -14.803106307983398, 'loss_4': 3.384582281112671, 'epoch': 0.35}
{'loss': 0.1996, 'grad_norm': 51.40871810913086, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.19580967724323273, 'loss_2': 0.0038299560546875, 'loss_3': -14.819089889526367, 'loss_4': 3.6897599697113037, 'epoch': 0.36}
{'loss': 0.184, 'grad_norm': 38.153541564941406, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.18156418204307556, 'loss_2': 0.00244140625, 'loss_3': -14.838836669921875, 'loss_4': 3.4991209506988525, 'epoch': 0.37}
{'loss': 0.1378, 'grad_norm': 27.310487747192383, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.1303161233663559, 'loss_2': 0.00743865966796875, 'loss_3': -14.734823226928711, 'loss_4': 3.306504487991333, 'epoch': 0.37}
{'loss': 0.1537, 'grad_norm': 30.713359832763672, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.14897233247756958, 'loss_2': 0.00469207763671875, 'loss_3': -14.587316513061523, 'loss_4': 3.415070056915283, 'epoch': 0.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:16,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:16,397 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:54<1:30:00,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:19:23,767 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06031724065542221, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.499, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.05311058461666107, 'eval_loss_2': 0.007206659764051437, 'eval_loss_3': -17.990291595458984, 'eval_loss_4': 2.4916250705718994, 'epoch': 0.38}
{'loss': 0.1981, 'grad_norm': 41.08195114135742, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.18977582454681396, 'loss_2': 0.00836181640625, 'loss_3': -14.991833686828613, 'loss_4': 2.9054782390594482, 'epoch': 0.38}
{'loss': 0.1528, 'grad_norm': 36.89672088623047, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.14435194432735443, 'loss_2': 0.0084686279296875, 'loss_3': -15.109779357910156, 'loss_4': 2.6292624473571777, 'epoch': 0.39}
{'loss': 0.1925, 'grad_norm': 36.0651969909668, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.18833550810813904, 'loss_2': 0.004119873046875, 'loss_3': -14.900306701660156, 'loss_4': 2.4575462341308594, 'epoch': 0.4}
{'loss': 0.1385, 'grad_norm': 40.079254150390625, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.13238294422626495, 'loss_2': 0.00612640380859375, 'loss_3': -14.931739807128906, 'loss_4': 2.506049156188965, 'epoch': 0.4}
{'loss': 0.107, 'grad_norm': 25.04974937438965, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.10653115063905716, 'loss_2': 0.000476837158203125, 'loss_3': -15.094106674194336, 'loss_4': 1.9175848960876465, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 15:19:23,767 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:23,767 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:01<1:28:43,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:19:31,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07940405607223511, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.591, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.07521570473909378, 'eval_loss_2': 0.004188358783721924, 'eval_loss_3': -17.965957641601562, 'eval_loss_4': 2.145693063735962, 'epoch': 0.41}
{'loss': 0.1308, 'grad_norm': 32.082759857177734, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.12259792536497116, 'loss_2': 0.00818634033203125, 'loss_3': -14.849963188171387, 'loss_4': 2.2401363849639893, 'epoch': 0.41}
{'loss': 0.174, 'grad_norm': 41.00716781616211, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.1693929135799408, 'loss_2': 0.004608154296875, 'loss_3': -14.951513290405273, 'loss_4': 2.2263760566711426, 'epoch': 0.42}
{'loss': 0.2052, 'grad_norm': 68.28375244140625, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.1899603307247162, 'loss_2': 0.0152130126953125, 'loss_3': -14.788745880126953, 'loss_4': 2.876518726348877, 'epoch': 0.42}
{'loss': 0.1441, 'grad_norm': 22.295129776000977, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.11859142780303955, 'loss_2': 0.0255279541015625, 'loss_3': -14.767814636230469, 'loss_4': 2.102597713470459, 'epoch': 0.43}
{'loss': 0.1674, 'grad_norm': 33.75115203857422, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.1494116187095642, 'loss_2': 0.0179901123046875, 'loss_3': -15.019231796264648, 'loss_4': 2.3626365661621094, 'epoch': 0.44}
[INFO|trainer.py:4228] 2025-01-21 15:19:31,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:31,149 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:28:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:38,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09968599677085876, 'eval_runtime': 3.8245, 'eval_samples_per_second': 267.746, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.08595498651266098, 'eval_loss_2': 0.013731002807617188, 'eval_loss_3': -18.013259887695312, 'eval_loss_4': 2.433590888977051, 'epoch': 0.44}
{'loss': 0.1714, 'grad_norm': 41.57767105102539, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.15401515364646912, 'loss_2': 0.01739501953125, 'loss_3': -14.987687110900879, 'loss_4': 2.689465045928955, 'epoch': 0.44}
{'loss': 0.1202, 'grad_norm': 26.321016311645508, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.11216603219509125, 'loss_2': 0.00798797607421875, 'loss_3': -14.879990577697754, 'loss_4': 2.151865005493164, 'epoch': 0.45}
{'loss': 0.2526, 'grad_norm': 43.449398040771484, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.23502576351165771, 'loss_2': 0.0176239013671875, 'loss_3': -14.796856880187988, 'loss_4': 2.667006015777588, 'epoch': 0.45}
{'loss': 0.2089, 'grad_norm': 44.091590881347656, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.18701057136058807, 'loss_2': 0.021881103515625, 'loss_3': -14.887178421020508, 'loss_4': 3.036123514175415, 'epoch': 0.46}
{'loss': 0.2039, 'grad_norm': 42.38689422607422, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.1978890597820282, 'loss_2': 0.0059967041015625, 'loss_3': -14.884710311889648, 'loss_4': 2.661855936050415, 'epoch': 0.47}
[INFO|trainer.py:4228] 2025-01-21 15:19:38,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:38,536 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:16<1:28:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:45,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06785392761230469, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.852, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0636843666434288, 'eval_loss_2': 0.004169553518295288, 'eval_loss_3': -18.049293518066406, 'eval_loss_4': 2.5797603130340576, 'epoch': 0.47}
{'loss': 0.2386, 'grad_norm': 51.305049896240234, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.23190179467201233, 'loss_2': 0.00667572021484375, 'loss_3': -14.817203521728516, 'loss_4': 3.1490349769592285, 'epoch': 0.47}
{'loss': 0.2786, 'grad_norm': 42.41916275024414, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.27613699436187744, 'loss_2': 0.0024318695068359375, 'loss_3': -14.748236656188965, 'loss_4': 2.242391347885132, 'epoch': 0.48}
{'loss': 0.1716, 'grad_norm': 44.2695198059082, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.16891612112522125, 'loss_2': 0.0027313232421875, 'loss_3': -15.10413932800293, 'loss_4': 2.501021146774292, 'epoch': 0.48}
{'loss': 0.194, 'grad_norm': 37.827842712402344, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.18665258586406708, 'loss_2': 0.007305145263671875, 'loss_3': -15.026145935058594, 'loss_4': 2.4134469032287598, 'epoch': 0.49}
{'loss': 0.2597, 'grad_norm': 54.1522331237793, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.2414923906326294, 'loss_2': 0.0181732177734375, 'loss_3': -14.591980934143066, 'loss_4': 3.024200201034546, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 15:19:45,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:45,914 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:24<1:28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:53,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10267868638038635, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.996, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.07864990830421448, 'eval_loss_2': 0.024028778076171875, 'eval_loss_3': -17.964237213134766, 'eval_loss_4': 2.100928544998169, 'epoch': 0.49}
{'loss': 0.1977, 'grad_norm': 50.40513229370117, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.17730797827243805, 'loss_2': 0.0203857421875, 'loss_3': -14.986063957214355, 'loss_4': 2.8875107765197754, 'epoch': 0.5}
{'loss': 0.116, 'grad_norm': 22.551836013793945, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.09305901825428009, 'loss_2': 0.0229644775390625, 'loss_3': -15.018272399902344, 'loss_4': 2.41562557220459, 'epoch': 0.51}
{'loss': 0.1926, 'grad_norm': 41.38298797607422, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.16687335073947906, 'loss_2': 0.0257568359375, 'loss_3': -15.094775199890137, 'loss_4': 2.2417116165161133, 'epoch': 0.51}
{'loss': 0.2475, 'grad_norm': 58.81785202026367, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.20485417544841766, 'loss_2': 0.042694091796875, 'loss_3': -14.744478225708008, 'loss_4': 1.8206100463867188, 'epoch': 0.52}
{'loss': 0.1094, 'grad_norm': 20.57586097717285, 'learning_rate': 2.95e-05, 'loss_1': 0.07213369756937027, 'loss_2': 0.0372314453125, 'loss_3': -15.206194877624512, 'loss_4': 2.062864303588867, 'epoch': 0.52}
[INFO|trainer.py:4228] 2025-01-21 15:19:53,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:53,284 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:31<1:28:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:00,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0672481432557106, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.903, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03579023852944374, 'eval_loss_2': 0.03145790100097656, 'eval_loss_3': -18.17859649658203, 'eval_loss_4': 1.7404515743255615, 'epoch': 0.52}
{'loss': 0.2577, 'grad_norm': 53.449737548828125, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.22956986725330353, 'loss_2': 0.02813720703125, 'loss_3': -14.910572052001953, 'loss_4': 2.5868706703186035, 'epoch': 0.53}
{'loss': 0.1576, 'grad_norm': 32.43632507324219, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.14001153409481049, 'loss_2': 0.017608642578125, 'loss_3': -15.226334571838379, 'loss_4': 2.617297410964966, 'epoch': 0.53}
{'loss': 0.1719, 'grad_norm': 35.526676177978516, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.1536576747894287, 'loss_2': 0.01824951171875, 'loss_3': -15.218717575073242, 'loss_4': 2.7413992881774902, 'epoch': 0.54}
{'loss': 0.2449, 'grad_norm': 47.6776237487793, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.2226412147283554, 'loss_2': 0.022216796875, 'loss_3': -15.102947235107422, 'loss_4': 2.4191131591796875, 'epoch': 0.55}
{'loss': 0.2446, 'grad_norm': 53.50045394897461, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.22504617273807526, 'loss_2': 0.019561767578125, 'loss_3': -15.19995403289795, 'loss_4': 3.3969178199768066, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 15:20:00,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:00,668 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:38<1:27:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:08,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06051841005682945, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04369368776679039, 'eval_loss_2': 0.016824722290039062, 'eval_loss_3': -18.32571029663086, 'eval_loss_4': 2.4002838134765625, 'epoch': 0.55}
{'loss': 0.3201, 'grad_norm': 59.7991828918457, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.30082255601882935, 'loss_2': 0.0192718505859375, 'loss_3': -15.28860855102539, 'loss_4': 3.0273633003234863, 'epoch': 0.56}
{'loss': 0.3336, 'grad_norm': 51.21625900268555, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.3222048878669739, 'loss_2': 0.01137542724609375, 'loss_3': -15.174922943115234, 'loss_4': 3.099111318588257, 'epoch': 0.56}
{'loss': 0.2734, 'grad_norm': 45.73075866699219, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.263054221868515, 'loss_2': 0.0102996826171875, 'loss_3': -15.30747127532959, 'loss_4': 2.76006817817688, 'epoch': 0.57}
{'loss': 0.2161, 'grad_norm': 47.842159271240234, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.2137427031993866, 'loss_2': 0.0023746490478515625, 'loss_3': -15.430472373962402, 'loss_4': 3.2780373096466064, 'epoch': 0.58}
{'loss': 0.3862, 'grad_norm': 61.62527847290039, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.36993566155433655, 'loss_2': 0.016265869140625, 'loss_3': -15.279158592224121, 'loss_4': 2.7684922218322754, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 15:20:08,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:08,040 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:46<1:28:06,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:20:15,443 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.053233277052640915, 'eval_runtime': 3.8242, 'eval_samples_per_second': 267.768, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.043794285506010056, 'eval_loss_2': 0.00943899154663086, 'eval_loss_3': -18.326242446899414, 'eval_loss_4': 1.4426482915878296, 'epoch': 0.58}
{'loss': 0.1934, 'grad_norm': 37.8364143371582, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.17951102554798126, 'loss_2': 0.01390838623046875, 'loss_3': -15.36614990234375, 'loss_4': 1.8850306272506714, 'epoch': 0.59}
{'loss': 0.1958, 'grad_norm': 38.72771453857422, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.18683010339736938, 'loss_2': 0.00901031494140625, 'loss_3': -15.395825386047363, 'loss_4': 1.5626671314239502, 'epoch': 0.59}
{'loss': 0.282, 'grad_norm': 47.18223190307617, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.26789727807044983, 'loss_2': 0.014068603515625, 'loss_3': -15.356364250183105, 'loss_4': 2.2610654830932617, 'epoch': 0.6}
{'loss': 0.1806, 'grad_norm': 38.39079284667969, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.16653692722320557, 'loss_2': 0.01407623291015625, 'loss_3': -15.275793075561523, 'loss_4': 1.9749915599822998, 'epoch': 0.6}
{'loss': 0.2224, 'grad_norm': 34.556644439697266, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.22003573179244995, 'loss_2': 0.00238800048828125, 'loss_3': -15.241256713867188, 'loss_4': 1.9016423225402832, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 15:20:15,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:15,443 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:53<1:27:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:22,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07028864324092865, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.507, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.06518713384866714, 'eval_loss_2': 0.005101501941680908, 'eval_loss_3': -18.122215270996094, 'eval_loss_4': 1.2124786376953125, 'epoch': 0.61}
{'loss': 0.18, 'grad_norm': 45.00492858886719, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.16357609629631042, 'loss_2': 0.01641845703125, 'loss_3': -15.21537971496582, 'loss_4': 1.5443329811096191, 'epoch': 0.62}
{'loss': 0.3891, 'grad_norm': 63.136985778808594, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.38368257880210876, 'loss_2': 0.005374908447265625, 'loss_3': -15.08729362487793, 'loss_4': 1.9579187631607056, 'epoch': 0.62}
{'loss': 0.1843, 'grad_norm': 36.09438705444336, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.17627346515655518, 'loss_2': 0.0080413818359375, 'loss_3': -15.054104804992676, 'loss_4': 1.4808483123779297, 'epoch': 0.63}
{'loss': 0.1878, 'grad_norm': 34.39784240722656, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.1856115758419037, 'loss_2': 0.0021820068359375, 'loss_3': -15.006200790405273, 'loss_4': 1.9544250965118408, 'epoch': 0.63}
{'loss': 0.2041, 'grad_norm': 42.86744689941406, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.2024659961462021, 'loss_2': 0.0016412734985351562, 'loss_3': -15.130677223205566, 'loss_4': 2.710922956466675, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 15:20:22,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:22,824 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:01<1:27:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:30,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10266309976577759, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.832, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.09822358936071396, 'eval_loss_2': 0.004439502954483032, 'eval_loss_3': -17.96144676208496, 'eval_loss_4': 2.3745920658111572, 'epoch': 0.64}
{'loss': 0.3646, 'grad_norm': 51.255794525146484, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.3510209321975708, 'loss_2': 0.013580322265625, 'loss_3': -15.120290756225586, 'loss_4': 2.8291802406311035, 'epoch': 0.65}
{'loss': 0.259, 'grad_norm': 45.91226577758789, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.24442675709724426, 'loss_2': 0.0145721435546875, 'loss_3': -15.057892799377441, 'loss_4': 3.597628593444824, 'epoch': 0.65}
{'loss': 0.2237, 'grad_norm': 40.74736404418945, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.21267175674438477, 'loss_2': 0.01104736328125, 'loss_3': -15.075763702392578, 'loss_4': 3.3128037452697754, 'epoch': 0.66}
{'loss': 0.1558, 'grad_norm': 37.638671875, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.12970194220542908, 'loss_2': 0.0261077880859375, 'loss_3': -15.066412925720215, 'loss_4': 3.009103298187256, 'epoch': 0.66}
{'loss': 0.2429, 'grad_norm': 46.580814361572266, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.2338668555021286, 'loss_2': 0.009063720703125, 'loss_3': -15.025862693786621, 'loss_4': 2.997528553009033, 'epoch': 0.67}
[INFO|trainer.py:4228] 2025-01-21 15:20:30,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:30,207 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:08<1:27:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:37,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.11305242776870728, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.777, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.10290466994047165, 'eval_loss_2': 0.01014775037765503, 'eval_loss_3': -17.936737060546875, 'eval_loss_4': 3.1066970825195312, 'epoch': 0.67}
{'loss': 0.1966, 'grad_norm': 41.015586853027344, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.1749548465013504, 'loss_2': 0.0216064453125, 'loss_3': -14.821489334106445, 'loss_4': 3.367201328277588, 'epoch': 0.67}
{'loss': 0.1954, 'grad_norm': 39.03958511352539, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.18837912380695343, 'loss_2': 0.00701141357421875, 'loss_3': -15.040687561035156, 'loss_4': 2.6891918182373047, 'epoch': 0.68}
{'loss': 0.1257, 'grad_norm': 26.306291580200195, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.12078191339969635, 'loss_2': 0.00494384765625, 'loss_3': -15.19336986541748, 'loss_4': 2.6473960876464844, 'epoch': 0.69}
{'loss': 0.1449, 'grad_norm': 34.4107780456543, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.13876080513000488, 'loss_2': 0.006153106689453125, 'loss_3': -15.05264663696289, 'loss_4': 3.0635805130004883, 'epoch': 0.69}
{'loss': 0.1084, 'grad_norm': 27.786001205444336, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.10380987823009491, 'loss_2': 0.00457000732421875, 'loss_3': -15.197471618652344, 'loss_4': 2.535155773162842, 'epoch': 0.7}
[INFO|trainer.py:4228] 2025-01-21 15:20:37,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:37,585 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:12<1:27:37,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:20:41,395 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-120
[INFO|configuration_utils.py:420] 2025-01-21 15:20:41,396 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-120/config.json                                                                             
{'eval_loss': 0.03680574893951416, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03234893083572388, 'eval_loss_2': 0.004456818103790283, 'eval_loss_3': -18.13542938232422, 'eval_loss_4': 2.2424674034118652, 'epoch': 0.7}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:41,849 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-120/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:41,850 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-120/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:41,851 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-120/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:42,698 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-60] due to args.save_total_limit
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:17<1:35:52,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:20:46,346 >>
{'loss': 0.0646, 'grad_norm': 17.85825538635254, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.057315029203891754, 'loss_2': 0.0072479248046875, 'loss_3': -15.243085861206055, 'loss_4': 2.0529093742370605, 'epoch': 0.7}
{'loss': 0.0939, 'grad_norm': 26.016016006469727, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.08369041979312897, 'loss_2': 0.01019287109375, 'loss_3': -15.130607604980469, 'loss_4': 3.0247135162353516, 'epoch': 0.71}
{'loss': 0.1555, 'grad_norm': 40.028926849365234, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.15116018056869507, 'loss_2': 0.00435638427734375, 'loss_3': -15.255807876586914, 'loss_4': 2.6766841411590576, 'epoch': 0.72}
{'loss': 0.1168, 'grad_norm': 30.549936294555664, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.11442610621452332, 'loss_2': 0.0023632049560546875, 'loss_3': -15.454522132873535, 'loss_4': 2.2932024002075195, 'epoch': 0.72}
{'loss': 0.0752, 'grad_norm': 20.600610733032227, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.06513973325490952, 'loss_2': 0.0100860595703125, 'loss_3': -15.32000732421875, 'loss_4': 2.8383021354675293, 'epoch': 0.73}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:20:46,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:46,346 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:24<1:28:53,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:20:53,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03952794522047043, 'eval_runtime': 3.8192, 'eval_samples_per_second': 268.118, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.02738671749830246, 'eval_loss_2': 0.012141227722167969, 'eval_loss_3': -18.247581481933594, 'eval_loss_4': 2.3271353244781494, 'epoch': 0.73}
{'loss': 0.111, 'grad_norm': 31.76930809020996, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.09701283276081085, 'loss_2': 0.01403045654296875, 'loss_3': -15.311790466308594, 'loss_4': 2.795311450958252, 'epoch': 0.73}
{'loss': 0.1885, 'grad_norm': 35.961181640625, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.17449431121349335, 'loss_2': 0.01401519775390625, 'loss_3': -15.28342056274414, 'loss_4': 2.596648693084717, 'epoch': 0.74}
{'loss': 0.1966, 'grad_norm': 38.308895111083984, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.18545399606227875, 'loss_2': 0.0111846923828125, 'loss_3': -15.41368293762207, 'loss_4': 2.5845448970794678, 'epoch': 0.74}
{'loss': 0.2121, 'grad_norm': 35.789520263671875, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.19452451169490814, 'loss_2': 0.017578125, 'loss_3': -15.266756057739258, 'loss_4': 2.8628718852996826, 'epoch': 0.75}
{'loss': 0.1233, 'grad_norm': 24.429027557373047, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.11443687975406647, 'loss_2': 0.0089111328125, 'loss_3': -15.32442855834961, 'loss_4': 1.564875841140747, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 15:20:53,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:53,731 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:28<1:28:53,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:20:57,550 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-130
[INFO|configuration_utils.py:420] 2025-01-21 15:20:57,551 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-130/config.json                                                                             
{'eval_loss': 0.035499535501003265, 'eval_runtime': 3.8179, 'eval_samples_per_second': 268.212, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.029916727915406227, 'eval_loss_2': 0.0055828094482421875, 'eval_loss_3': -18.284873962402344, 'eval_loss_4': 1.5518972873687744, 'epoch': 0.76}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:58,039 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-130/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:58,040 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-130/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:58,040 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-130/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:58,901 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-120] due to args.save_total_limit
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:33<1:36:06,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:21:02,531 >>
{'loss': 0.1253, 'grad_norm': 39.62383270263672, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.12211613357067108, 'loss_2': 0.0031585693359375, 'loss_3': -15.220574378967285, 'loss_4': 2.006718635559082, 'epoch': 0.76}
{'loss': 0.0794, 'grad_norm': 23.218589782714844, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.07745779305696487, 'loss_2': 0.0019121170043945312, 'loss_3': -15.20404052734375, 'loss_4': 1.3927817344665527, 'epoch': 0.77}
{'loss': 0.2108, 'grad_norm': 54.97868728637695, 'learning_rate': 2.925e-05, 'loss_1': 0.19877590239048004, 'loss_2': 0.011993408203125, 'loss_3': -15.13718032836914, 'loss_4': 1.7078559398651123, 'epoch': 0.77}
{'loss': 0.1566, 'grad_norm': 38.78866195678711, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.14456871151924133, 'loss_2': 0.0120086669921875, 'loss_3': -15.113983154296875, 'loss_4': 1.6691277027130127, 'epoch': 0.78}
{'loss': 0.1629, 'grad_norm': 33.11699676513672, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.15708555281162262, 'loss_2': 0.00579833984375, 'loss_3': -15.305850982666016, 'loss_4': 1.725855827331543, 'epoch': 0.78}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:02,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:02,531 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:40<1:28:36,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:21:09,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04498250037431717, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.030183620750904083, 'eval_loss_2': 0.014798879623413086, 'eval_loss_3': -18.101778030395508, 'eval_loss_4': 1.4238747358322144, 'epoch': 0.78}
{'loss': 0.1009, 'grad_norm': 24.33942413330078, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.08078566938638687, 'loss_2': 0.0200653076171875, 'loss_3': -15.305627822875977, 'loss_4': 1.4355840682983398, 'epoch': 0.79}
{'loss': 0.1974, 'grad_norm': 30.8398380279541, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.172629714012146, 'loss_2': 0.0247802734375, 'loss_3': -15.17613697052002, 'loss_4': 1.5789566040039062, 'epoch': 0.8}
{'loss': 0.1276, 'grad_norm': 33.175662994384766, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.10812922567129135, 'loss_2': 0.019439697265625, 'loss_3': -15.040762901306152, 'loss_4': 1.9213175773620605, 'epoch': 0.8}
{'loss': 0.0399, 'grad_norm': 9.347562789916992, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.03666933998465538, 'loss_2': 0.00321197509765625, 'loss_3': -15.15967845916748, 'loss_4': 1.5684378147125244, 'epoch': 0.81}
{'loss': 0.0525, 'grad_norm': 14.562252044677734, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.042742714285850525, 'loss_2': 0.0097808837890625, 'loss_3': -15.16215705871582, 'loss_4': 1.9363713264465332, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 15:21:09,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:09,893 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:48<1:27:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:17,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04905752092599869, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.04423144459724426, 'eval_loss_2': 0.004826068878173828, 'eval_loss_3': -17.954301834106445, 'eval_loss_4': 1.8790290355682373, 'epoch': 0.81}
{'loss': 0.082, 'grad_norm': 21.588144302368164, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.07500552386045456, 'loss_2': 0.0069732666015625, 'loss_3': -14.929085731506348, 'loss_4': 1.7719391584396362, 'epoch': 0.82}
{'loss': 0.0883, 'grad_norm': 19.972570419311523, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.08091775327920914, 'loss_2': 0.0074005126953125, 'loss_3': -15.163475036621094, 'loss_4': 1.747908592224121, 'epoch': 0.83}
{'loss': 0.0943, 'grad_norm': 25.6142635345459, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.08946957439184189, 'loss_2': 0.00481414794921875, 'loss_3': -14.828311920166016, 'loss_4': 1.764014720916748, 'epoch': 0.83}
{'loss': 0.0756, 'grad_norm': 27.59317970275879, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.07509371638298035, 'loss_2': 0.0005540847778320312, 'loss_3': -15.185752868652344, 'loss_4': 1.1947561502456665, 'epoch': 0.84}
{'loss': 0.052, 'grad_norm': 14.721511840820312, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.04622410610318184, 'loss_2': 0.0057373046875, 'loss_3': -15.440776824951172, 'loss_4': 1.8403351306915283, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 15:21:17,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:17,261 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:55<1:27:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:24,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.036726027727127075, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.017, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.026819700375199318, 'eval_loss_2': 0.00990632176399231, 'eval_loss_3': -18.06227684020996, 'eval_loss_4': 1.3484162092208862, 'epoch': 0.84}
{'loss': 0.0921, 'grad_norm': 23.921186447143555, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.08035074174404144, 'loss_2': 0.01177215576171875, 'loss_3': -15.107755661010742, 'loss_4': 1.38787841796875, 'epoch': 0.85}
{'loss': 0.1193, 'grad_norm': 35.237674713134766, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.11374589055776596, 'loss_2': 0.00557708740234375, 'loss_3': -14.858580589294434, 'loss_4': 2.0433385372161865, 'epoch': 0.85}
{'loss': 0.0543, 'grad_norm': 14.05435562133789, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.04852703958749771, 'loss_2': 0.00580596923828125, 'loss_3': -15.178211212158203, 'loss_4': 1.4244484901428223, 'epoch': 0.86}
{'loss': 0.0426, 'grad_norm': 12.268037796020508, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.039596885442733765, 'loss_2': 0.002994537353515625, 'loss_3': -15.185253143310547, 'loss_4': 1.3528435230255127, 'epoch': 0.87}
{'loss': 0.0421, 'grad_norm': 11.346261978149414, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.03697294741868973, 'loss_2': 0.005146026611328125, 'loss_3': -14.93818187713623, 'loss_4': 1.2994039058685303, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 15:21:24,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:24,630 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:59<1:27:03,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:21:28,442 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-150
[INFO|configuration_utils.py:420] 2025-01-21 15:21:28,443 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-150/config.json                                                                             
{'eval_loss': 0.03408925235271454, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.709, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.025409821420907974, 'eval_loss_2': 0.008679427206516266, 'eval_loss_3': -18.037864685058594, 'eval_loss_4': 0.935992419719696, 'epoch': 0.87}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:28,937 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-150/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:28,938 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:28,939 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-150/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:29,863 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-130] due to args.save_total_limit
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:04<1:35:48,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:21:33,493 >>
{'loss': 0.0945, 'grad_norm': 23.42900276184082, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.08535517752170563, 'loss_2': 0.00917816162109375, 'loss_3': -15.090113639831543, 'loss_4': 1.1361898183822632, 'epoch': 0.88}
{'loss': 0.0964, 'grad_norm': 25.42032241821289, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.08858422189950943, 'loss_2': 0.007808685302734375, 'loss_3': -15.036370277404785, 'loss_4': 0.4874640703201294, 'epoch': 0.88}
{'loss': 0.1561, 'grad_norm': 38.50389099121094, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.14812378585338593, 'loss_2': 0.0079498291015625, 'loss_3': -15.08839225769043, 'loss_4': 0.7803771495819092, 'epoch': 0.89}
{'loss': 0.1273, 'grad_norm': 37.26518630981445, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.12504301965236664, 'loss_2': 0.002239227294921875, 'loss_3': -15.214982986450195, 'loss_4': 0.9949122071266174, 'epoch': 0.9}
{'loss': 0.0581, 'grad_norm': 18.813343048095703, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.05542460456490517, 'loss_2': 0.002712249755859375, 'loss_3': -15.193588256835938, 'loss_4': 0.978181004524231, 'epoch': 0.9}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:33,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:33,494 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:08<1:35:48,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:21:37,302 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-155
[INFO|configuration_utils.py:420] 2025-01-21 15:21:37,304 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-155/config.json                                                                             
{'eval_loss': 0.032222166657447815, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.929, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.027964847162365913, 'eval_loss_2': 0.004257321357727051, 'eval_loss_3': -18.03554344177246, 'eval_loss_4': 0.5748835802078247, 'epoch': 0.9}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:37,800 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-155/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:37,801 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-155/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:37,801 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-155/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:38,713 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-150] due to args.save_total_limit
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:13<1:37:14,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:21:42,364 >>
{'loss': 0.0539, 'grad_norm': 14.417186737060547, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.052593521773815155, 'loss_2': 0.00125885009765625, 'loss_3': -15.209930419921875, 'loss_4': -0.21616335213184357, 'epoch': 0.91}
{'loss': 0.0755, 'grad_norm': 16.73137664794922, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.05859927088022232, 'loss_2': 0.01690673828125, 'loss_3': -15.205068588256836, 'loss_4': 0.5607542991638184, 'epoch': 0.91}
{'loss': 0.1802, 'grad_norm': 33.394718170166016, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.1703098863363266, 'loss_2': 0.009857177734375, 'loss_3': -15.140180587768555, 'loss_4': 0.687969446182251, 'epoch': 0.92}
{'loss': 0.0608, 'grad_norm': 19.589069366455078, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.050317395478487015, 'loss_2': 0.0104522705078125, 'loss_3': -14.996634483337402, 'loss_4': 0.4810715913772583, 'epoch': 0.92}
{'loss': 0.0572, 'grad_norm': 14.021811485290527, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.04267539829015732, 'loss_2': 0.01453399658203125, 'loss_3': -15.004979133605957, 'loss_4': 0.3991251587867737, 'epoch': 0.93}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:42,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:42,364 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:20<1:28:23,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:21:49,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03916658088564873, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0333377867937088, 'eval_loss_2': 0.005828797817230225, 'eval_loss_3': -18.049379348754883, 'eval_loss_4': 0.47718051075935364, 'epoch': 0.93}
{'loss': 0.0957, 'grad_norm': 22.600526809692383, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.09016415476799011, 'loss_2': 0.005519866943359375, 'loss_3': -14.993844985961914, 'loss_4': -0.09555627405643463, 'epoch': 0.94}
{'loss': 0.038, 'grad_norm': 12.325008392333984, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.03565320372581482, 'loss_2': 0.002368927001953125, 'loss_3': -15.295687675476074, 'loss_4': 0.5360593795776367, 'epoch': 0.94}
{'loss': 0.0674, 'grad_norm': 22.25484848022461, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.06454071402549744, 'loss_2': 0.00290679931640625, 'loss_3': -15.301441192626953, 'loss_4': 0.7439743280410767, 'epoch': 0.95}
{'loss': 0.0454, 'grad_norm': 12.235042572021484, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.03974547237157822, 'loss_2': 0.00568389892578125, 'loss_3': -15.44616413116455, 'loss_4': 0.780898928642273, 'epoch': 0.95}
{'loss': 0.0609, 'grad_norm': 18.290359497070312, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.045373737812042236, 'loss_2': 0.0155487060546875, 'loss_3': -15.191435813903809, 'loss_4': 0.6447080373764038, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 15:21:49,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:49,727 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:27<1:26:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:57,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.047017838805913925, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.114, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.036263853311538696, 'eval_loss_2': 0.010753989219665527, 'eval_loss_3': -18.067062377929688, 'eval_loss_4': 1.0918631553649902, 'epoch': 0.96}
{'loss': 0.0666, 'grad_norm': 15.901269912719727, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.051712118089199066, 'loss_2': 0.014923095703125, 'loss_3': -15.559340476989746, 'loss_4': 0.8415133953094482, 'epoch': 0.97}
{'loss': 0.106, 'grad_norm': 22.427093505859375, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.08996910601854324, 'loss_2': 0.0160369873046875, 'loss_3': -15.370290756225586, 'loss_4': 0.6727871298789978, 'epoch': 0.97}
{'loss': 0.0686, 'grad_norm': 14.14721393585205, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.059399086982011795, 'loss_2': 0.00916290283203125, 'loss_3': -15.199172973632812, 'loss_4': 1.623305320739746, 'epoch': 0.98}
{'loss': 0.1133, 'grad_norm': 31.513702392578125, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.10692927241325378, 'loss_2': 0.00635528564453125, 'loss_3': -15.072168350219727, 'loss_4': 1.289362907409668, 'epoch': 0.98}
{'loss': 0.0845, 'grad_norm': 21.864486694335938, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.08347785472869873, 'loss_2': 0.001049041748046875, 'loss_3': -15.176587104797363, 'loss_4': 1.735220193862915, 'epoch': 0.99}
[INFO|trainer.py:4228] 2025-01-21 15:21:57,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:57,089 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:31<1:26:50,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:22:00,894 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-170
[INFO|configuration_utils.py:420] 2025-01-21 15:22:00,895 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-170/config.json                                                                             
{'eval_loss': 0.03119228407740593, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.191, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.025216232985258102, 'eval_loss_2': 0.005976051092147827, 'eval_loss_3': -18.16181182861328, 'eval_loss_4': 1.7560842037200928, 'epoch': 0.99}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:01,357 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-170/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:01,358 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-170/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:01,359 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-170/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:02,319 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-155] due to args.save_total_limit
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:36<1:33:07,  1.12s/it][INFO|trainer.py:4226] 2025-01-21 15:22:05,649 >>
{'loss': 0.0379, 'grad_norm': 13.808915138244629, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.03625758737325668, 'loss_2': 0.0016632080078125, 'loss_3': -15.294900894165039, 'loss_4': 1.5553016662597656, 'epoch': 0.99}
{'loss': 0.0404, 'grad_norm': 23.172849655151367, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.03928488865494728, 'loss_2': 0.0011005401611328125, 'loss_3': -15.629687309265137, 'loss_4': 2.59348201751709, 'epoch': 1.0}
{'loss': 0.0393, 'grad_norm': 12.307554244995117, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.03870011121034622, 'loss_2': 0.0006079673767089844, 'loss_3': -15.252290725708008, 'loss_4': 2.290029764175415, 'epoch': 1.01}
{'loss': 0.0564, 'grad_norm': 17.19227409362793, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.05392088741064072, 'loss_2': 0.002429962158203125, 'loss_3': -15.466997146606445, 'loss_4': 2.0533270835876465, 'epoch': 1.01}
{'loss': 0.0508, 'grad_norm': 16.521465301513672, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.05033501237630844, 'loss_2': 0.0004506111145019531, 'loss_3': -15.467541694641113, 'loss_4': 2.2014284133911133, 'epoch': 1.02}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:05,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:05,649 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:40<1:33:07,  1.12s/it][INFO|trainer.py:3910] 2025-01-21 15:22:09,465 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-175
[INFO|configuration_utils.py:420] 2025-01-21 15:22:09,466 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-175/config.json                                                                             
{'eval_loss': 0.023256098851561546, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.436, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.017060255631804466, 'eval_loss_2': 0.00619584321975708, 'eval_loss_3': -18.241273880004883, 'eval_loss_4': 2.206993341445923, 'epoch': 1.02}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:09,948 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-175/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:09,949 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-175/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:09,950 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-175/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:10,865 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-170] due to args.save_total_limit
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:45<1:36:34,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:22:14,523 >>
{'loss': 0.1381, 'grad_norm': 31.171707153320312, 'learning_rate': 2.9e-05, 'loss_1': 0.13571572303771973, 'loss_2': 0.002376556396484375, 'loss_3': -15.438715934753418, 'loss_4': 2.89066219329834, 'epoch': 1.02}
{'loss': 0.0419, 'grad_norm': 11.316649436950684, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.036039289087057114, 'loss_2': 0.005878448486328125, 'loss_3': -15.439860343933105, 'loss_4': 2.3981385231018066, 'epoch': 1.03}
{'loss': 0.0761, 'grad_norm': 25.393293380737305, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.07279361039400101, 'loss_2': 0.0033550262451171875, 'loss_3': -15.614511489868164, 'loss_4': 2.575068950653076, 'epoch': 1.03}
{'loss': 0.0691, 'grad_norm': 14.15719985961914, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.053568314760923386, 'loss_2': 0.0155792236328125, 'loss_3': -15.40433406829834, 'loss_4': 2.4230716228485107, 'epoch': 1.04}
{'loss': 0.0842, 'grad_norm': 26.585731506347656, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.08118128031492233, 'loss_2': 0.0030155181884765625, 'loss_3': -15.340727806091309, 'loss_4': 1.6237623691558838, 'epoch': 1.05}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:14,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:14,523 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:52<1:28:12,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:22:21,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025204356759786606, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.696, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.02025388926267624, 'eval_loss_2': 0.004950463771820068, 'eval_loss_3': -18.300033569335938, 'eval_loss_4': 2.1516940593719482, 'epoch': 1.05}
{'loss': 0.0597, 'grad_norm': 22.85822296142578, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.051348231732845306, 'loss_2': 0.00835418701171875, 'loss_3': -15.705061912536621, 'loss_4': 2.486387252807617, 'epoch': 1.05}
{'loss': 0.0528, 'grad_norm': 17.63446044921875, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.04235314577817917, 'loss_2': 0.01049041748046875, 'loss_3': -15.39527702331543, 'loss_4': 2.3936965465545654, 'epoch': 1.06}
{'loss': 0.0897, 'grad_norm': 20.604461669921875, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.07190663367509842, 'loss_2': 0.0178070068359375, 'loss_3': -15.673003196716309, 'loss_4': 2.458122730255127, 'epoch': 1.06}
{'loss': 0.0675, 'grad_norm': 16.125391006469727, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.06013281270861626, 'loss_2': 0.00740814208984375, 'loss_3': -15.31167984008789, 'loss_4': 2.302654266357422, 'epoch': 1.07}
{'loss': 0.0515, 'grad_norm': 11.412714004516602, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.048008114099502563, 'loss_2': 0.003490447998046875, 'loss_3': -15.418787002563477, 'loss_4': 2.4738283157348633, 'epoch': 1.08}
[INFO|trainer.py:4228] 2025-01-21 15:22:21,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:21,910 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:56<1:28:12,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:22:25,728 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-185
[INFO|configuration_utils.py:420] 2025-01-21 15:22:25,729 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-185/config.json                                                                             
{'eval_loss': 0.02285301499068737, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.317, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.019584981724619865, 'eval_loss_2': 0.003268033266067505, 'eval_loss_3': -18.313636779785156, 'eval_loss_4': 2.0054574012756348, 'epoch': 1.08}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:26,220 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-185/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:26,221 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-185/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:26,221 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-185/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:27,135 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-175] due to args.save_total_limit
  4%|████████                                                                                                                                                                                                                    | 190/5160 [05:01<1:35:40,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:22:30,798 >>
{'loss': 0.0813, 'grad_norm': 35.064571380615234, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.08074259757995605, 'loss_2': 0.0005326271057128906, 'loss_3': -15.404979705810547, 'loss_4': 2.243711233139038, 'epoch': 1.08}
{'loss': 0.0504, 'grad_norm': 12.19895076751709, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.04404063895344734, 'loss_2': 0.00634002685546875, 'loss_3': -15.201725006103516, 'loss_4': 1.7034014463424683, 'epoch': 1.09}
{'loss': 0.1245, 'grad_norm': 31.402233123779297, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.11837994307279587, 'loss_2': 0.006130218505859375, 'loss_3': -15.24008846282959, 'loss_4': 1.945517659187317, 'epoch': 1.09}
{'loss': 0.063, 'grad_norm': 17.964059829711914, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.054491132497787476, 'loss_2': 0.008514404296875, 'loss_3': -15.07339859008789, 'loss_4': 1.9374380111694336, 'epoch': 1.1}
{'loss': 0.0707, 'grad_norm': 19.074920654296875, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.06407662481069565, 'loss_2': 0.0066070556640625, 'loss_3': -15.383007049560547, 'loss_4': 2.2133431434631348, 'epoch': 1.1}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:30,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:30,798 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:09<1:27:40,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:22:38,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023665420711040497, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.020528748631477356, 'eval_loss_2': 0.003136672079563141, 'eval_loss_3': -18.27189826965332, 'eval_loss_4': 2.0595808029174805, 'epoch': 1.1}
{'loss': 0.0598, 'grad_norm': 13.17965316772461, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.05841623619198799, 'loss_2': 0.0013780593872070312, 'loss_3': -15.210164070129395, 'loss_4': 2.027538299560547, 'epoch': 1.11}
{'loss': 0.0721, 'grad_norm': 27.265209197998047, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.07025151699781418, 'loss_2': 0.001834869384765625, 'loss_3': -15.322620391845703, 'loss_4': 2.582005023956299, 'epoch': 1.12}
{'loss': 0.1169, 'grad_norm': 17.418317794799805, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.11266665905714035, 'loss_2': 0.0042572021484375, 'loss_3': -15.49193286895752, 'loss_4': 2.037410259246826, 'epoch': 1.12}
{'loss': 0.0597, 'grad_norm': 19.739212036132812, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.05141405388712883, 'loss_2': 0.008331298828125, 'loss_3': -15.376359939575195, 'loss_4': 1.6789841651916504, 'epoch': 1.13}
{'loss': 0.063, 'grad_norm': 22.61957550048828, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.05103350430727005, 'loss_2': 0.0119781494140625, 'loss_3': -15.050882339477539, 'loss_4': 1.538835048675537, 'epoch': 1.13}
[INFO|trainer.py:4228] 2025-01-21 15:22:38,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:38,160 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:16<1:26:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:45,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030184371396899223, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.025420647114515305, 'eval_loss_2': 0.0047637224197387695, 'eval_loss_3': -18.212352752685547, 'eval_loss_4': 1.895948886871338, 'epoch': 1.13}
{'loss': 0.0551, 'grad_norm': 24.764989852905273, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.05180780217051506, 'loss_2': 0.00325775146484375, 'loss_3': -15.219291687011719, 'loss_4': 1.780026912689209, 'epoch': 1.14}
{'loss': 0.0554, 'grad_norm': 11.638792991638184, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.043747060000896454, 'loss_2': 0.01168060302734375, 'loss_3': -15.382438659667969, 'loss_4': 1.423194408416748, 'epoch': 1.15}
{'loss': 0.1313, 'grad_norm': 17.869600296020508, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.12139396369457245, 'loss_2': 0.00994873046875, 'loss_3': -15.401926040649414, 'loss_4': 1.6074256896972656, 'epoch': 1.15}
{'loss': 0.0642, 'grad_norm': 17.409969329833984, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.054177477955818176, 'loss_2': 0.0100555419921875, 'loss_3': -15.205092430114746, 'loss_4': 1.6670557260513306, 'epoch': 1.16}
{'loss': 0.0519, 'grad_norm': 14.504511833190918, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.04607511684298515, 'loss_2': 0.005828857421875, 'loss_3': -15.300935745239258, 'loss_4': 2.02821946144104, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 15:22:45,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:45,511 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:23<1:25:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:52,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023895230144262314, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01872270554304123, 'eval_loss_2': 0.005172520875930786, 'eval_loss_3': -18.241981506347656, 'eval_loss_4': 1.7056471109390259, 'epoch': 1.16}
{'loss': 0.0336, 'grad_norm': 10.276703834533691, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.02756289765238762, 'loss_2': 0.006069183349609375, 'loss_3': -15.275951385498047, 'loss_4': 1.5840630531311035, 'epoch': 1.17}
{'loss': 0.1035, 'grad_norm': 23.976211547851562, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.10010772943496704, 'loss_2': 0.0034046173095703125, 'loss_3': -15.290299415588379, 'loss_4': 2.2361254692077637, 'epoch': 1.17}
{'loss': 0.0488, 'grad_norm': 23.212919235229492, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.04357892647385597, 'loss_2': 0.005199432373046875, 'loss_3': -15.214639663696289, 'loss_4': 1.9223119020462036, 'epoch': 1.18}
{'loss': 0.1091, 'grad_norm': 27.825477600097656, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.10682712495326996, 'loss_2': 0.002300262451171875, 'loss_3': -15.071599006652832, 'loss_4': 1.8086810111999512, 'epoch': 1.19}
{'loss': 0.1141, 'grad_norm': 33.80316162109375, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.10333780944347382, 'loss_2': 0.01071929931640625, 'loss_3': -15.134612083435059, 'loss_4': 1.131495475769043, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 15:22:52,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:52,873 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:31<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:00,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025754306465387344, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.391, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.021196160465478897, 'eval_loss_2': 0.004558145999908447, 'eval_loss_3': -18.204051971435547, 'eval_loss_4': 1.4988243579864502, 'epoch': 1.19}
{'loss': 0.0552, 'grad_norm': 14.12899398803711, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.04317416995763779, 'loss_2': 0.0119781494140625, 'loss_3': -15.207819938659668, 'loss_4': 1.3314831256866455, 'epoch': 1.2}
{'loss': 0.1169, 'grad_norm': 40.87297439575195, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.11079856008291245, 'loss_2': 0.0061187744140625, 'loss_3': -15.26506233215332, 'loss_4': 1.3792483806610107, 'epoch': 1.2}
{'loss': 0.0532, 'grad_norm': 18.505632400512695, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.05246882140636444, 'loss_2': 0.0007543563842773438, 'loss_3': -15.214624404907227, 'loss_4': 1.4969978332519531, 'epoch': 1.21}
{'loss': 0.0816, 'grad_norm': 25.148151397705078, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.07844142615795135, 'loss_2': 0.003192901611328125, 'loss_3': -15.171754837036133, 'loss_4': 1.1445062160491943, 'epoch': 1.22}
{'loss': 0.2084, 'grad_norm': 28.87824821472168, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.19079045951366425, 'loss_2': 0.017608642578125, 'loss_3': -15.006772994995117, 'loss_4': 1.2603785991668701, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 15:23:00,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:00,254 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:38<1:25:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:07,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07388313859701157, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.314, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.058491554111242294, 'eval_loss_2': 0.01539158821105957, 'eval_loss_3': -18.0385799407959, 'eval_loss_4': 1.5063397884368896, 'epoch': 1.22}
{'loss': 0.0895, 'grad_norm': 29.823734283447266, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.07913161814212799, 'loss_2': 0.0103759765625, 'loss_3': -15.078608512878418, 'loss_4': 0.7758411169052124, 'epoch': 1.23}
{'loss': 0.1795, 'grad_norm': 32.782222747802734, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.15588116645812988, 'loss_2': 0.0235748291015625, 'loss_3': -15.173442840576172, 'loss_4': 1.6289258003234863, 'epoch': 1.23}
{'loss': 0.0482, 'grad_norm': 10.343830108642578, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.03346182778477669, 'loss_2': 0.014739990234375, 'loss_3': -15.109245300292969, 'loss_4': 1.0402755737304688, 'epoch': 1.24}
{'loss': 0.0784, 'grad_norm': 17.01116943359375, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.051565930247306824, 'loss_2': 0.0268707275390625, 'loss_3': -15.344078063964844, 'loss_4': 0.9834234714508057, 'epoch': 1.24}
{'loss': 0.0589, 'grad_norm': 19.231170654296875, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.04229675978422165, 'loss_2': 0.0166168212890625, 'loss_3': -15.273350715637207, 'loss_4': 1.2380568981170654, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 15:23:07,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:07,620 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:45<1:25:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:14,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.052976690232753754, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.904, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04315647482872009, 'eval_loss_2': 0.009820222854614258, 'eval_loss_3': -18.109899520874023, 'eval_loss_4': 0.964165210723877, 'epoch': 1.25}
{'loss': 0.0387, 'grad_norm': 7.042316436767578, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.023996179923415184, 'loss_2': 0.01471710205078125, 'loss_3': -15.364853858947754, 'loss_4': 0.33152079582214355, 'epoch': 1.26}
{'loss': 0.0501, 'grad_norm': 14.513989448547363, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.04146593064069748, 'loss_2': 0.00860595703125, 'loss_3': -15.432053565979004, 'loss_4': 1.0624504089355469, 'epoch': 1.26}
{'loss': 0.056, 'grad_norm': 18.900053024291992, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.0483504943549633, 'loss_2': 0.007610321044921875, 'loss_3': -15.3427095413208, 'loss_4': 0.12239256501197815, 'epoch': 1.27}
{'loss': 0.0296, 'grad_norm': 7.051403999328613, 'learning_rate': 2.875e-05, 'loss_1': 0.021841390058398247, 'loss_2': 0.007709503173828125, 'loss_3': -15.444358825683594, 'loss_4': 1.071852445602417, 'epoch': 1.27}
{'loss': 0.0429, 'grad_norm': 8.584907531738281, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.017885010689496994, 'loss_2': 0.0250244140625, 'loss_3': -15.316198348999023, 'loss_4': 1.0967280864715576, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 15:23:14,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:14,994 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:53<1:25:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:22,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037330262362957, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.774, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.018554791808128357, 'eval_loss_2': 0.018775463104248047, 'eval_loss_3': -18.281814575195312, 'eval_loss_4': 0.7621345520019531, 'epoch': 1.28}
{'loss': 0.0472, 'grad_norm': 8.820107460021973, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.032349880784749985, 'loss_2': 0.01483154296875, 'loss_3': -15.520963668823242, 'loss_4': 0.2083633542060852, 'epoch': 1.28}
{'loss': 0.0571, 'grad_norm': 16.606840133666992, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.0486006960272789, 'loss_2': 0.0084686279296875, 'loss_3': -15.324363708496094, 'loss_4': 1.001131534576416, 'epoch': 1.29}
{'loss': 0.0872, 'grad_norm': 18.209259033203125, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.08089329302310944, 'loss_2': 0.0063323974609375, 'loss_3': -15.635459899902344, 'loss_4': 1.5895071029663086, 'epoch': 1.3}
{'loss': 0.033, 'grad_norm': 9.213382720947266, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.029343007132411003, 'loss_2': 0.00368499755859375, 'loss_3': -15.59788990020752, 'loss_4': 1.2330271005630493, 'epoch': 1.3}
{'loss': 0.0788, 'grad_norm': 18.19037437438965, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.07448022067546844, 'loss_2': 0.0043487548828125, 'loss_3': -15.39061164855957, 'loss_4': 1.6088216304779053, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 15:23:22,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:22,369 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [06:00<1:25:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:29,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02496221289038658, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.020436324179172516, 'eval_loss_2': 0.004525884985923767, 'eval_loss_3': -18.326581954956055, 'eval_loss_4': 0.9485778212547302, 'epoch': 1.31}
{'loss': 0.0297, 'grad_norm': 10.208109855651855, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.026260504499077797, 'loss_2': 0.003406524658203125, 'loss_3': -15.760114669799805, 'loss_4': 1.4374465942382812, 'epoch': 1.31}
{'loss': 0.1178, 'grad_norm': 33.52864074707031, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.10129578411579132, 'loss_2': 0.0164794921875, 'loss_3': -15.453048706054688, 'loss_4': 1.9270520210266113, 'epoch': 1.32}
{'loss': 0.0362, 'grad_norm': 9.848124504089355, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.03209308907389641, 'loss_2': 0.00408935546875, 'loss_3': -15.452661514282227, 'loss_4': 0.7540544867515564, 'epoch': 1.33}
{'loss': 0.0714, 'grad_norm': 15.884542465209961, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.07074251770973206, 'loss_2': 0.0006189346313476562, 'loss_3': -15.512012481689453, 'loss_4': 1.9864383935928345, 'epoch': 1.33}
{'loss': 0.0461, 'grad_norm': 17.973613739013672, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.044576313346624374, 'loss_2': 0.0015153884887695312, 'loss_3': -15.474462509155273, 'loss_4': 0.877058744430542, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 15:23:29,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:29,744 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [06:04<1:25:42,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:23:33,551 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-230
[INFO|configuration_utils.py:420] 2025-01-21 15:23:33,552 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-230/config.json                                                                             
{'eval_loss': 0.02182730659842491, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.018029529601335526, 'eval_loss_2': 0.003797776997089386, 'eval_loss_3': -18.31524658203125, 'eval_loss_4': 0.8614360094070435, 'epoch': 1.34}
[INFO|modeling_utils.py:2988] 2025-01-21 15:23:34,052 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-230/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:23:34,054 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-230/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:23:34,054 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-230/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:23:34,967 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-185] due to args.save_total_limit
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:09<1:34:23,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:23:38,616 >>
{'loss': 0.0595, 'grad_norm': 20.366315841674805, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.0590398907661438, 'loss_2': 0.0005054473876953125, 'loss_3': -15.406527519226074, 'loss_4': 1.4775841236114502, 'epoch': 1.34}
{'loss': 0.1613, 'grad_norm': 23.210163116455078, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.1595180183649063, 'loss_2': 0.0017747879028320312, 'loss_3': -15.2264986038208, 'loss_4': 0.6833286881446838, 'epoch': 1.35}
{'loss': 0.0816, 'grad_norm': 26.46331214904785, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.07851758599281311, 'loss_2': 0.003032684326171875, 'loss_3': -15.271903991699219, 'loss_4': 1.23982572555542, 'epoch': 1.35}
{'loss': 0.0396, 'grad_norm': 16.850305557250977, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.034234996885061264, 'loss_2': 0.005336761474609375, 'loss_3': -15.571492195129395, 'loss_4': 1.102756381034851, 'epoch': 1.36}
{'loss': 0.0643, 'grad_norm': 18.01215934753418, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.05397617816925049, 'loss_2': 0.01031494140625, 'loss_3': -15.51742935180664, 'loss_4': 1.1031322479248047, 'epoch': 1.37}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:23:38,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:38,616 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:13<1:34:23,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:23:42,430 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-235
[INFO|configuration_utils.py:420] 2025-01-21 15:23:42,431 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-235/config.json                                                                             
{'eval_loss': 0.020447706803679466, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.634, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.015240859240293503, 'eval_loss_2': 0.005206845700740814, 'eval_loss_3': -18.28729248046875, 'eval_loss_4': 0.20213724672794342, 'epoch': 1.37}
[INFO|modeling_utils.py:2988] 2025-01-21 15:23:42,922 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-235/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:23:42,923 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-235/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:23:42,924 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-235/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:23:43,835 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-230] due to args.save_total_limit
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:18<1:35:46,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:23:47,492 >>
{'loss': 0.0861, 'grad_norm': 24.41645622253418, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.08406122773885727, 'loss_2': 0.0020809173583984375, 'loss_3': -15.594606399536133, 'loss_4': 1.00624680519104, 'epoch': 1.37}
{'loss': 0.1112, 'grad_norm': 21.983179092407227, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.103279709815979, 'loss_2': 0.00788116455078125, 'loss_3': -15.3450345993042, 'loss_4': 0.6792421340942383, 'epoch': 1.38}
{'loss': 0.0311, 'grad_norm': 8.67513370513916, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.027307234704494476, 'loss_2': 0.003780364990234375, 'loss_3': -15.590315818786621, 'loss_4': 0.38537511229515076, 'epoch': 1.38}
{'loss': 0.0411, 'grad_norm': 9.93612289428711, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.03443872183561325, 'loss_2': 0.006649017333984375, 'loss_3': -15.380613327026367, 'loss_4': 0.16891975700855255, 'epoch': 1.39}
{'loss': 0.045, 'grad_norm': 10.858902931213379, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.03369632363319397, 'loss_2': 0.01129150390625, 'loss_3': -15.622303009033203, 'loss_4': -0.14484572410583496, 'epoch': 1.4}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:23:47,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:47,492 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:25<1:27:01,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:23:54,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023566074669361115, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.349, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.019524725154042244, 'eval_loss_2': 0.00404135137796402, 'eval_loss_3': -18.17875862121582, 'eval_loss_4': -0.08798939734697342, 'epoch': 1.4}
{'loss': 0.0534, 'grad_norm': 15.331521987915039, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.047055065631866455, 'loss_2': 0.00634002685546875, 'loss_3': -15.452621459960938, 'loss_4': 0.7790480256080627, 'epoch': 1.4}
{'loss': 0.0192, 'grad_norm': 7.064276695251465, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.016879132017493248, 'loss_2': 0.0023288726806640625, 'loss_3': -15.54780387878418, 'loss_4': -0.2928054928779602, 'epoch': 1.41}
{'loss': 0.0596, 'grad_norm': 15.233973503112793, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.051149819046258926, 'loss_2': 0.00849151611328125, 'loss_3': -15.401803016662598, 'loss_4': 0.4560732841491699, 'epoch': 1.41}
{'loss': 0.0337, 'grad_norm': 18.08721351623535, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.03045639395713806, 'loss_2': 0.00323486328125, 'loss_3': -15.421406745910645, 'loss_4': 0.3339046835899353, 'epoch': 1.42}
{'loss': 0.0582, 'grad_norm': 22.69927406311035, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.05327218770980835, 'loss_2': 0.00489044189453125, 'loss_3': -15.459359169006348, 'loss_4': -0.1777704656124115, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 15:23:54,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:54,853 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:33<1:25:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:02,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05611509084701538, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.457, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.04925030097365379, 'eval_loss_2': 0.006864786148071289, 'eval_loss_3': -18.02176284790039, 'eval_loss_4': 0.43835949897766113, 'epoch': 1.42}
{'loss': 0.0654, 'grad_norm': 16.967538833618164, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.055962514132261276, 'loss_2': 0.00946044921875, 'loss_3': -15.134357452392578, 'loss_4': 0.6589862704277039, 'epoch': 1.43}
{'loss': 0.1281, 'grad_norm': 20.212480545043945, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.11761260777711868, 'loss_2': 0.01052093505859375, 'loss_3': -15.386367797851562, 'loss_4': 0.8014111518859863, 'epoch': 1.44}
{'loss': 0.1757, 'grad_norm': 33.33266830444336, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.16891531646251678, 'loss_2': 0.006740570068359375, 'loss_3': -14.95218276977539, 'loss_4': 0.9080126285552979, 'epoch': 1.44}
{'loss': 0.1238, 'grad_norm': 34.810546875, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.11828191578388214, 'loss_2': 0.00547027587890625, 'loss_3': -15.08753776550293, 'loss_4': 0.731198787689209, 'epoch': 1.45}
{'loss': 0.0842, 'grad_norm': 17.70516586303711, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.0823170393705368, 'loss_2': 0.001865386962890625, 'loss_3': -15.350422859191895, 'loss_4': 1.4970535039901733, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 15:24:02,210 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:02,210 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:40<1:25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:09,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08220365643501282, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.228, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0782080739736557, 'eval_loss_2': 0.003995582461357117, 'eval_loss_3': -17.905654907226562, 'eval_loss_4': 1.3990719318389893, 'epoch': 1.45}
{'loss': 0.1428, 'grad_norm': 28.643476486206055, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.12937363982200623, 'loss_2': 0.013397216796875, 'loss_3': -15.03706169128418, 'loss_4': 1.7976574897766113, 'epoch': 1.46}
{'loss': 0.0443, 'grad_norm': 10.84195327758789, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.04426242411136627, 'loss_2': 6.198883056640625e-06, 'loss_3': -15.2622709274292, 'loss_4': 1.5220550298690796, 'epoch': 1.47}
{'loss': 0.0834, 'grad_norm': 16.9331111907959, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.07204227894544601, 'loss_2': 0.0113525390625, 'loss_3': -15.093317985534668, 'loss_4': 1.3991774320602417, 'epoch': 1.47}
{'loss': 0.1455, 'grad_norm': 53.259666442871094, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.1297907829284668, 'loss_2': 0.0157470703125, 'loss_3': -15.194379806518555, 'loss_4': 1.9941864013671875, 'epoch': 1.48}
{'loss': 0.0449, 'grad_norm': 7.993032932281494, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.024093523621559143, 'loss_2': 0.0208282470703125, 'loss_3': -15.612127304077148, 'loss_4': 0.9709936380386353, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 15:24:09,578 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:09,578 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:47<1:25:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:16,957 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03917434811592102, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.115, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.017841126769781113, 'eval_loss_2': 0.02133321762084961, 'eval_loss_3': -18.259098052978516, 'eval_loss_4': 1.6035103797912598, 'epoch': 1.48}
{'loss': 0.0629, 'grad_norm': 16.094104766845703, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.04701444134116173, 'loss_2': 0.0158538818359375, 'loss_3': -15.526877403259277, 'loss_4': 1.625319480895996, 'epoch': 1.49}
{'loss': 0.0751, 'grad_norm': 21.36952018737793, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.05813658609986305, 'loss_2': 0.0169830322265625, 'loss_3': -15.484962463378906, 'loss_4': 2.7756526470184326, 'epoch': 1.49}
{'loss': 0.0575, 'grad_norm': 16.122779846191406, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.042596928775310516, 'loss_2': 0.01490020751953125, 'loss_3': -15.516067504882812, 'loss_4': 2.5140364170074463, 'epoch': 1.5}
{'loss': 0.1849, 'grad_norm': 41.69528579711914, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.17878662049770355, 'loss_2': 0.00609588623046875, 'loss_3': -15.428415298461914, 'loss_4': 3.8497653007507324, 'epoch': 1.51}
{'loss': 0.1332, 'grad_norm': 44.49228286743164, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.12811747193336487, 'loss_2': 0.00507354736328125, 'loss_3': -15.569820404052734, 'loss_4': 4.225235939025879, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 15:24:16,957 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:16,957 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:55<1:25:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:24,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033429212868213654, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.115, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.024988599121570587, 'eval_loss_2': 0.008440613746643066, 'eval_loss_3': -18.364543914794922, 'eval_loss_4': 2.9651646614074707, 'epoch': 1.51}
{'loss': 0.099, 'grad_norm': 25.0638484954834, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.09003911912441254, 'loss_2': 0.0089569091796875, 'loss_3': -15.315309524536133, 'loss_4': 3.7246952056884766, 'epoch': 1.52}
{'loss': 0.1026, 'grad_norm': 19.41658592224121, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.0937323272228241, 'loss_2': 0.008819580078125, 'loss_3': -15.561927795410156, 'loss_4': 3.0220746994018555, 'epoch': 1.52}
{'loss': 0.132, 'grad_norm': 30.07636070251465, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.12783518433570862, 'loss_2': 0.00414276123046875, 'loss_3': -15.11715316772461, 'loss_4': 2.859544038772583, 'epoch': 1.53}
{'loss': 0.0662, 'grad_norm': 16.960214614868164, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.05982626602053642, 'loss_2': 0.006378173828125, 'loss_3': -15.129353523254395, 'loss_4': 2.521092414855957, 'epoch': 1.53}
{'loss': 0.0354, 'grad_norm': 7.4811110496521, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.026215730234980583, 'loss_2': 0.00921630859375, 'loss_3': -15.493207931518555, 'loss_4': 1.5388658046722412, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 15:24:24,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:24,328 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [07:02<1:24:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:31,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022935792803764343, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.33, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.018061809241771698, 'eval_loss_2': 0.004873983561992645, 'eval_loss_3': -18.24936294555664, 'eval_loss_4': 1.14309561252594, 'epoch': 1.54}
{'loss': 0.1064, 'grad_norm': 31.92569351196289, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.09834350645542145, 'loss_2': 0.00801849365234375, 'loss_3': -15.434839248657227, 'loss_4': 2.1951231956481934, 'epoch': 1.55}
{'loss': 0.079, 'grad_norm': 25.081212997436523, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.07459305226802826, 'loss_2': 0.00438690185546875, 'loss_3': -15.150733947753906, 'loss_4': 1.3934906721115112, 'epoch': 1.55}
{'loss': 0.0532, 'grad_norm': 14.690399169921875, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.05199763551354408, 'loss_2': 0.0012454986572265625, 'loss_3': -15.491169929504395, 'loss_4': 0.826994776725769, 'epoch': 1.56}
{'loss': 0.0578, 'grad_norm': 17.690582275390625, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.048295602202415466, 'loss_2': 0.0095367431640625, 'loss_3': -15.420846939086914, 'loss_4': 0.42819541692733765, 'epoch': 1.56}
{'loss': 0.111, 'grad_norm': 36.025699615478516, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.10402537882328033, 'loss_2': 0.00699615478515625, 'loss_3': -15.233177185058594, 'loss_4': 0.49967679381370544, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 15:24:31,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:31,689 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:09<1:24:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:39,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03309512883424759, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.02730054408311844, 'eval_loss_2': 0.00579458475112915, 'eval_loss_3': -18.101011276245117, 'eval_loss_4': 0.22496087849140167, 'epoch': 1.57}
{'loss': 0.0415, 'grad_norm': 12.79189682006836, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.04066180810332298, 'loss_2': 0.0008053779602050781, 'loss_3': -15.584843635559082, 'loss_4': 0.3893550634384155, 'epoch': 1.58}
{'loss': 0.0585, 'grad_norm': 13.11436939239502, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.055595993995666504, 'loss_2': 0.0029392242431640625, 'loss_3': -15.421032905578613, 'loss_4': 0.10523459315299988, 'epoch': 1.58}
{'loss': 0.0371, 'grad_norm': 10.95660400390625, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.03162509202957153, 'loss_2': 0.00545501708984375, 'loss_3': -15.628433227539062, 'loss_4': 0.18113991618156433, 'epoch': 1.59}
{'loss': 0.0575, 'grad_norm': 15.224150657653809, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.05639415606856346, 'loss_2': 0.0011091232299804688, 'loss_3': -15.391347885131836, 'loss_4': -0.3933107554912567, 'epoch': 1.59}
{'loss': 0.0575, 'grad_norm': 17.154443740844727, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.045214418321847916, 'loss_2': 0.0123291015625, 'loss_3': -15.34751033782959, 'loss_4': -0.20968852937221527, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 15:24:39,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:39,045 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:17<1:24:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:46,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0426589772105217, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.034266285598278046, 'eval_loss_2': 0.008392691612243652, 'eval_loss_3': -17.995819091796875, 'eval_loss_4': -0.0033942367881536484, 'epoch': 1.6}
{'loss': 0.0436, 'grad_norm': 9.029582977294922, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.04013578221201897, 'loss_2': 0.0034770965576171875, 'loss_3': -15.40998649597168, 'loss_4': -0.31976577639579773, 'epoch': 1.6}
{'loss': 0.0593, 'grad_norm': 18.154075622558594, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.05771413818001747, 'loss_2': 0.0015468597412109375, 'loss_3': -15.401371002197266, 'loss_4': -0.06299009919166565, 'epoch': 1.61}
{'loss': 0.0379, 'grad_norm': 9.029989242553711, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.033535413444042206, 'loss_2': 0.00433349609375, 'loss_3': -15.451164245605469, 'loss_4': 0.09837852418422699, 'epoch': 1.62}
{'loss': 0.0791, 'grad_norm': 30.92259407043457, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.07787568122148514, 'loss_2': 0.0012121200561523438, 'loss_3': -15.373199462890625, 'loss_4': 0.004837125539779663, 'epoch': 1.62}
{'loss': 0.0672, 'grad_norm': 15.998244285583496, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.05759831890463829, 'loss_2': 0.009613037109375, 'loss_3': -15.6422700881958, 'loss_4': -0.1511595994234085, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 15:24:46,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:46,411 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:24<1:24:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:53,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024551428854465485, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02020191214978695, 'eval_loss_2': 0.004349514842033386, 'eval_loss_3': -18.166278839111328, 'eval_loss_4': -0.31020838022232056, 'epoch': 1.63}
{'loss': 0.0441, 'grad_norm': 12.056427001953125, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.043744806200265884, 'loss_2': 0.0003364086151123047, 'loss_3': -15.619300842285156, 'loss_4': -0.6867515444755554, 'epoch': 1.63}
{'loss': 0.0734, 'grad_norm': 23.84445571899414, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.06906337291002274, 'loss_2': 0.004314422607421875, 'loss_3': -15.27083969116211, 'loss_4': -0.23867279291152954, 'epoch': 1.64}
{'loss': 0.0598, 'grad_norm': 26.264328002929688, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.058645687997341156, 'loss_2': 0.0011653900146484375, 'loss_3': -15.489436149597168, 'loss_4': -0.43827635049819946, 'epoch': 1.65}
{'loss': 0.1089, 'grad_norm': 35.250709533691406, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.0955260843038559, 'loss_2': 0.01332855224609375, 'loss_3': -15.357182502746582, 'loss_4': 0.4475542902946472, 'epoch': 1.65}
{'loss': 0.055, 'grad_norm': 16.38652229309082, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.053089264780282974, 'loss_2': 0.00193023681640625, 'loss_3': -15.339958190917969, 'loss_4': 0.09176874160766602, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 15:24:53,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:53,770 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:31<1:24:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:01,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020459406077861786, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.915, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.016446784138679504, 'eval_loss_2': 0.0040126219391822815, 'eval_loss_3': -18.250659942626953, 'eval_loss_4': -0.32612478733062744, 'epoch': 1.66}
{'loss': 0.0757, 'grad_norm': 19.921600341796875, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.07091149687767029, 'loss_2': 0.0048065185546875, 'loss_3': -15.545740127563477, 'loss_4': 0.15123891830444336, 'epoch': 1.66}
{'loss': 0.0736, 'grad_norm': 24.142433166503906, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.06970302760601044, 'loss_2': 0.00389862060546875, 'loss_3': -15.460058212280273, 'loss_4': -0.37242376804351807, 'epoch': 1.67}
{'loss': 0.072, 'grad_norm': 13.8530912399292, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.0653897151350975, 'loss_2': 0.00659942626953125, 'loss_3': -15.380922317504883, 'loss_4': 0.391397625207901, 'epoch': 1.67}
{'loss': 0.1281, 'grad_norm': 32.01279067993164, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.12649469077587128, 'loss_2': 0.0015659332275390625, 'loss_3': -15.666393280029297, 'loss_4': 0.08253999054431915, 'epoch': 1.68}
{'loss': 0.0321, 'grad_norm': 9.905633926391602, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.03147786483168602, 'loss_2': 0.0006589889526367188, 'loss_3': -15.573197364807129, 'loss_4': -0.08514142036437988, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 15:25:01,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:01,136 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:39<1:27:29,  1.08s/it][INFO|trainer.py:4226] 2025-01-21 15:25:08,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024497970938682556, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.546, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.019226297736167908, 'eval_loss_2': 0.0052716732025146484, 'eval_loss_3': -18.253297805786133, 'eval_loss_4': -0.1481989026069641, 'epoch': 1.69}
{'loss': 0.0661, 'grad_norm': 15.955305099487305, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.05830119922757149, 'loss_2': 0.007762908935546875, 'loss_3': -15.536176681518555, 'loss_4': 0.14376035332679749, 'epoch': 1.69}
{'loss': 0.0378, 'grad_norm': 10.870329856872559, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.032058995217084885, 'loss_2': 0.0056915283203125, 'loss_3': -15.39435863494873, 'loss_4': 0.4185565412044525, 'epoch': 1.7}
{'loss': 0.1433, 'grad_norm': 22.822372436523438, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.13443326950073242, 'loss_2': 0.0088653564453125, 'loss_3': -15.398160934448242, 'loss_4': 0.4076748192310333, 'epoch': 1.7}
{'loss': 0.0879, 'grad_norm': 31.606943130493164, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.07555858790874481, 'loss_2': 0.01238250732421875, 'loss_3': -15.350677490234375, 'loss_4': -0.045094773173332214, 'epoch': 1.71}
{'loss': 0.1425, 'grad_norm': 33.774192810058594, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.13494811952114105, 'loss_2': 0.00756072998046875, 'loss_3': -15.38028621673584, 'loss_4': 0.6570284962654114, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 15:25:08,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:08,688 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:46<1:24:55,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:25:16,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023956898599863052, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01626906357705593, 'eval_loss_2': 0.0076878368854522705, 'eval_loss_3': -18.200090408325195, 'eval_loss_4': 0.35351768136024475, 'epoch': 1.72}
{'loss': 0.0472, 'grad_norm': 12.506664276123047, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.03969239443540573, 'loss_2': 0.007472991943359375, 'loss_3': -15.262213706970215, 'loss_4': 0.2236633002758026, 'epoch': 1.72}
{'loss': 0.0743, 'grad_norm': 18.97466278076172, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.06616346538066864, 'loss_2': 0.00811767578125, 'loss_3': -15.33508586883545, 'loss_4': 0.11568334698677063, 'epoch': 1.73}
{'loss': 0.043, 'grad_norm': 8.847561836242676, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.02568340115249157, 'loss_2': 0.01727294921875, 'loss_3': -15.25538444519043, 'loss_4': 0.10746046900749207, 'epoch': 1.73}
{'loss': 0.0366, 'grad_norm': 24.479345321655273, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.0346459224820137, 'loss_2': 0.001983642578125, 'loss_3': -15.365720748901367, 'loss_4': 1.0947160720825195, 'epoch': 1.74}
{'loss': 0.0507, 'grad_norm': 15.847723960876465, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.04167924076318741, 'loss_2': 0.0090179443359375, 'loss_3': -15.347488403320312, 'loss_4': 0.4407431483268738, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 15:25:16,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:16,061 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:54<1:24:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:23,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02296106331050396, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.172, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018192393705248833, 'eval_loss_2': 0.004768669605255127, 'eval_loss_3': -18.112367630004883, 'eval_loss_4': 0.5855353474617004, 'epoch': 1.74}
{'loss': 0.107, 'grad_norm': 32.64292526245117, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.09654999524354935, 'loss_2': 0.0104217529296875, 'loss_3': -15.058481216430664, 'loss_4': 1.0349833965301514, 'epoch': 1.75}
{'loss': 0.0527, 'grad_norm': 14.37313461303711, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.046020179986953735, 'loss_2': 0.006687164306640625, 'loss_3': -15.499710083007812, 'loss_4': 0.6358736157417297, 'epoch': 1.76}
{'loss': 0.0208, 'grad_norm': 7.830212116241455, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.018744880333542824, 'loss_2': 0.002025604248046875, 'loss_3': -15.299349784851074, 'loss_4': 0.7717590928077698, 'epoch': 1.76}
{'loss': 0.0308, 'grad_norm': 9.62122917175293, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.026935210451483727, 'loss_2': 0.003879547119140625, 'loss_3': -15.207991600036621, 'loss_4': 0.6599328517913818, 'epoch': 1.77}
{'loss': 0.0888, 'grad_norm': 21.647863388061523, 'learning_rate': 2.825e-05, 'loss_1': 0.083999864757061, 'loss_2': 0.004810333251953125, 'loss_3': -15.345195770263672, 'loss_4': 0.881399929523468, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 15:25:23,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:23,418 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:01<1:24:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:30,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027464019134640694, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.012, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.023504111915826797, 'eval_loss_2': 0.003959909081459045, 'eval_loss_3': -18.0391902923584, 'eval_loss_4': 0.7910122871398926, 'epoch': 1.77}
{'loss': 0.0661, 'grad_norm': 19.8311767578125, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.06602977961301804, 'loss_2': 6.186962127685547e-05, 'loss_3': -15.193214416503906, 'loss_4': 0.7581635117530823, 'epoch': 1.78}
{'loss': 0.0424, 'grad_norm': 15.49375057220459, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.04078086465597153, 'loss_2': 0.001575469970703125, 'loss_3': -15.285249710083008, 'loss_4': 0.684855043888092, 'epoch': 1.78}
{'loss': 0.0461, 'grad_norm': 16.019365310668945, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.04282400757074356, 'loss_2': 0.0033130645751953125, 'loss_3': -15.277103424072266, 'loss_4': 1.2013835906982422, 'epoch': 1.79}
{'loss': 0.0329, 'grad_norm': 7.469927787780762, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.021246610209345818, 'loss_2': 0.01165008544921875, 'loss_3': -15.383481979370117, 'loss_4': 0.8792167901992798, 'epoch': 1.8}
{'loss': 0.0608, 'grad_norm': 23.462900161743164, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.057514872401952744, 'loss_2': 0.003269195556640625, 'loss_3': -15.258599281311035, 'loss_4': 0.4972240626811981, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 15:25:30,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:30,793 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:09<1:24:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:38,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023322422057390213, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.072, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.019564945250749588, 'eval_loss_2': 0.003757476806640625, 'eval_loss_3': -18.128887176513672, 'eval_loss_4': 0.8573157787322998, 'epoch': 1.8}
{'loss': 0.0335, 'grad_norm': 9.88615608215332, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.02927674725651741, 'loss_2': 0.004180908203125, 'loss_3': -15.314748764038086, 'loss_4': 0.682853102684021, 'epoch': 1.81}
{'loss': 0.0264, 'grad_norm': 9.69410228729248, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.02239871583878994, 'loss_2': 0.0040435791015625, 'loss_3': -15.350181579589844, 'loss_4': 1.0827544927597046, 'epoch': 1.81}
{'loss': 0.044, 'grad_norm': 16.728029251098633, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.039819058030843735, 'loss_2': 0.0041961669921875, 'loss_3': -15.171273231506348, 'loss_4': 1.1793525218963623, 'epoch': 1.82}
{'loss': 0.0458, 'grad_norm': 16.5246524810791, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.03437933325767517, 'loss_2': 0.0114288330078125, 'loss_3': -15.515193939208984, 'loss_4': 0.9599233865737915, 'epoch': 1.83}
{'loss': 0.1074, 'grad_norm': 18.76206398010254, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.09840834885835648, 'loss_2': 0.00897216796875, 'loss_3': -15.161006927490234, 'loss_4': 0.908125638961792, 'epoch': 1.83}
[INFO|trainer.py:4228] 2025-01-21 15:25:38,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:38,170 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:16<1:24:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:45,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020844031125307083, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.8, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017513038590550423, 'eval_loss_2': 0.0033309906721115112, 'eval_loss_3': -18.1757755279541, 'eval_loss_4': 1.0425939559936523, 'epoch': 1.83}
{'loss': 0.0367, 'grad_norm': 10.161900520324707, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.03119630739092827, 'loss_2': 0.0055084228515625, 'loss_3': -15.27788257598877, 'loss_4': 1.1653660535812378, 'epoch': 1.84}
{'loss': 0.0573, 'grad_norm': 18.199193954467773, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.04995027929544449, 'loss_2': 0.007350921630859375, 'loss_3': -15.484066009521484, 'loss_4': 1.1805062294006348, 'epoch': 1.84}
{'loss': 0.0348, 'grad_norm': 12.056968688964844, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.03397861868143082, 'loss_2': 0.0008597373962402344, 'loss_3': -15.217353820800781, 'loss_4': 1.0820603370666504, 'epoch': 1.85}
{'loss': 0.0472, 'grad_norm': 17.817174911499023, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.04135122522711754, 'loss_2': 0.00586700439453125, 'loss_3': -15.340725898742676, 'loss_4': 0.9184967875480652, 'epoch': 1.85}
{'loss': 0.1345, 'grad_norm': 31.19508171081543, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.13278985023498535, 'loss_2': 0.001720428466796875, 'loss_3': -15.086774826049805, 'loss_4': 0.7218998074531555, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 15:25:45,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:45,546 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:23<1:23:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:52,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023052876815199852, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.91, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.019196487963199615, 'eval_loss_2': 0.0038563907146453857, 'eval_loss_3': -18.153982162475586, 'eval_loss_4': 1.0048295259475708, 'epoch': 1.86}
{'loss': 0.0272, 'grad_norm': 8.571701049804688, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.026745598763227463, 'loss_2': 0.00046539306640625, 'loss_3': -15.261785507202148, 'loss_4': 0.7668642997741699, 'epoch': 1.87}
{'loss': 0.0325, 'grad_norm': 13.646714210510254, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.030711686238646507, 'loss_2': 0.00176239013671875, 'loss_3': -15.189170837402344, 'loss_4': 0.946214497089386, 'epoch': 1.87}
{'loss': 0.0319, 'grad_norm': 8.579801559448242, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.026798050850629807, 'loss_2': 0.005115509033203125, 'loss_3': -15.49886417388916, 'loss_4': 1.145691156387329, 'epoch': 1.88}
{'loss': 0.1622, 'grad_norm': 31.313095092773438, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.1562754213809967, 'loss_2': 0.00592803955078125, 'loss_3': -15.484841346740723, 'loss_4': 1.5405203104019165, 'epoch': 1.88}
{'loss': 0.0243, 'grad_norm': 6.601919651031494, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.01614416018128395, 'loss_2': 0.00820159912109375, 'loss_3': -15.364713668823242, 'loss_4': 0.9530947208404541, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 15:25:52,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:52,918 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:31<1:23:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:00,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02082163095474243, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.017896683886647224, 'eval_loss_2': 0.0029249489307403564, 'eval_loss_3': -18.187702178955078, 'eval_loss_4': 1.1687572002410889, 'epoch': 1.89}
{'loss': 0.0285, 'grad_norm': 8.092629432678223, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.02692716009914875, 'loss_2': 0.00152587890625, 'loss_3': -15.389158248901367, 'loss_4': 1.1220495700836182, 'epoch': 1.9}
{'loss': 0.0329, 'grad_norm': 8.178365707397461, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.026014763861894608, 'loss_2': 0.00685882568359375, 'loss_3': -15.53870964050293, 'loss_4': 0.964133620262146, 'epoch': 1.9}
{'loss': 0.0486, 'grad_norm': 12.252163887023926, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.045281827449798584, 'loss_2': 0.0032749176025390625, 'loss_3': -15.555992126464844, 'loss_4': 1.0852601528167725, 'epoch': 1.91}
{'loss': 0.0446, 'grad_norm': 9.48659896850586, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.033824373036623, 'loss_2': 0.0107421875, 'loss_3': -15.407716751098633, 'loss_4': 1.1193135976791382, 'epoch': 1.91}
{'loss': 0.0354, 'grad_norm': 8.559917449951172, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.02871820516884327, 'loss_2': 0.00666046142578125, 'loss_3': -15.262184143066406, 'loss_4': 1.446645736694336, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 15:26:00,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:00,292 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:34<1:23:54,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:26:04,092 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-330
[INFO|configuration_utils.py:420] 2025-01-21 15:26:04,094 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-330/config.json                                                                             
{'eval_loss': 0.018783381208777428, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.517, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015807202085852623, 'eval_loss_2': 0.0029761791229248047, 'eval_loss_3': -18.18621253967285, 'eval_loss_4': 1.5176929235458374, 'epoch': 1.92}
[INFO|modeling_utils.py:2988] 2025-01-21 15:26:04,583 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-330/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:26:04,585 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-330/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:26:04,585 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-330/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:26:05,482 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-235] due to args.save_total_limit
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:39<1:32:11,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:26:09,122 >>
{'loss': 0.0352, 'grad_norm': 13.714056968688965, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.0350024476647377, 'loss_2': 0.00019049644470214844, 'loss_3': -15.290061950683594, 'loss_4': 1.602221131324768, 'epoch': 1.92}
{'loss': 0.0486, 'grad_norm': 10.986438751220703, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.033506352454423904, 'loss_2': 0.01507568359375, 'loss_3': -15.21113395690918, 'loss_4': 1.4405238628387451, 'epoch': 1.93}
{'loss': 0.1218, 'grad_norm': 27.52423858642578, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.10730904340744019, 'loss_2': 0.0144500732421875, 'loss_3': -15.267900466918945, 'loss_4': 1.9025923013687134, 'epoch': 1.94}
{'loss': 0.0571, 'grad_norm': 14.510988235473633, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.036935415118932724, 'loss_2': 0.020172119140625, 'loss_3': -15.09878921508789, 'loss_4': 2.01086163520813, 'epoch': 1.94}
{'loss': 0.0454, 'grad_norm': 8.993620872497559, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.02715117111802101, 'loss_2': 0.0182342529296875, 'loss_3': -15.686899185180664, 'loss_4': 1.7323298454284668, 'epoch': 1.95}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:26:09,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:09,122 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:47<1:25:04,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:26:16,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02547670528292656, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.015071344561874866, 'eval_loss_2': 0.010405361652374268, 'eval_loss_3': -18.16500473022461, 'eval_loss_4': 1.8810484409332275, 'epoch': 1.95}
{'loss': 0.0775, 'grad_norm': 20.39217758178711, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.05833231285214424, 'loss_2': 0.019195556640625, 'loss_3': -15.454828262329102, 'loss_4': 1.4753482341766357, 'epoch': 1.95}
{'loss': 0.052, 'grad_norm': 19.19594955444336, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.04105796292424202, 'loss_2': 0.0109405517578125, 'loss_3': -15.408134460449219, 'loss_4': 1.2765069007873535, 'epoch': 1.96}
{'loss': 0.0749, 'grad_norm': 27.09333038330078, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.06851740181446075, 'loss_2': 0.006397247314453125, 'loss_3': -15.338909149169922, 'loss_4': 1.5205848217010498, 'epoch': 1.97}
{'loss': 0.0521, 'grad_norm': 16.692562103271484, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.0483693890273571, 'loss_2': 0.003742218017578125, 'loss_3': -15.093178749084473, 'loss_4': 2.165670394897461, 'epoch': 1.97}
{'loss': 0.0393, 'grad_norm': 10.689860343933105, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.031074687838554382, 'loss_2': 0.008270263671875, 'loss_3': -15.19287395477295, 'loss_4': 2.291937828063965, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 15:26:16,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:16,488 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:54<1:18:59,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 15:26:23,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020610833540558815, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014754099771380424, 'eval_loss_2': 0.0058567337691783905, 'eval_loss_3': -18.130725860595703, 'eval_loss_4': 2.132840633392334, 'epoch': 1.98}
{'loss': 0.0215, 'grad_norm': 6.016673564910889, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.016933120787143707, 'loss_2': 0.0045928955078125, 'loss_3': -15.467325210571289, 'loss_4': 2.4323689937591553, 'epoch': 1.98}
{'loss': 0.0321, 'grad_norm': 10.727212905883789, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.02307756058871746, 'loss_2': 0.0089874267578125, 'loss_3': -15.415643692016602, 'loss_4': 2.147765636444092, 'epoch': 1.99}
{'loss': 0.0643, 'grad_norm': 17.213882446289062, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.054552819579839706, 'loss_2': 0.00975799560546875, 'loss_3': -15.284027099609375, 'loss_4': 2.318227767944336, 'epoch': 1.99}
{'loss': 0.0416, 'grad_norm': 18.50429344177246, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.028695140033960342, 'loss_2': 0.0129241943359375, 'loss_3': -15.159759521484375, 'loss_4': 2.420381546020508, 'epoch': 2.0}
{'loss': 0.0276, 'grad_norm': 9.192411422729492, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.025562448427081108, 'loss_2': 0.002063751220703125, 'loss_3': -15.435504913330078, 'loss_4': 2.0095860958099365, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 15:26:23,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:23,549 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [09:01<1:22:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:26:30,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021259650588035583, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.697, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.018406614661216736, 'eval_loss_2': 0.0028530359268188477, 'eval_loss_3': -18.07870864868164, 'eval_loss_4': 2.0016183853149414, 'epoch': 2.01}
{'loss': 0.0369, 'grad_norm': 9.836097717285156, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.028684962540864944, 'loss_2': 0.008209228515625, 'loss_3': -15.447364807128906, 'loss_4': 1.704841136932373, 'epoch': 2.01}
{'loss': 0.0434, 'grad_norm': 20.078367233276367, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.042040660977363586, 'loss_2': 0.0013551712036132812, 'loss_3': -15.331157684326172, 'loss_4': 1.918532133102417, 'epoch': 2.02}
{'loss': 0.0364, 'grad_norm': 8.960573196411133, 'learning_rate': 2.8e-05, 'loss_1': 0.025791272521018982, 'loss_2': 0.01061248779296875, 'loss_3': -15.359118461608887, 'loss_4': 1.788377046585083, 'epoch': 2.02}
{'loss': 0.0126, 'grad_norm': 5.522782325744629, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.012304533272981644, 'loss_2': 0.00026416778564453125, 'loss_3': -15.596029281616211, 'loss_4': 1.108343482017517, 'epoch': 2.03}
{'loss': 0.0314, 'grad_norm': 10.62464714050293, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.029711924493312836, 'loss_2': 0.0016603469848632812, 'loss_3': -15.751138687133789, 'loss_4': 1.6791471242904663, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 15:26:30,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:30,918 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [09:05<1:22:44,  1.03s/it][INFO|trainer.py:3910] 2025-01-21 15:26:34,726 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-350
[INFO|configuration_utils.py:420] 2025-01-21 15:26:34,727 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-350/config.json                                                                             
{'eval_loss': 0.018213853240013123, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013300060294568539, 'eval_loss_2': 0.004913792014122009, 'eval_loss_3': -18.193838119506836, 'eval_loss_4': 1.9614930152893066, 'epoch': 2.03}
[INFO|modeling_utils.py:2988] 2025-01-21 15:26:35,209 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-350/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:26:35,210 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-350/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:26:35,211 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-350/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:26:36,098 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-330] due to args.save_total_limit
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:10<1:31:41,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:26:39,754 >>
{'loss': 0.0391, 'grad_norm': 12.312024116516113, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.038052670657634735, 'loss_2': 0.0010519027709960938, 'loss_3': -15.675037384033203, 'loss_4': 2.174572467803955, 'epoch': 2.04}
{'loss': 0.0454, 'grad_norm': 23.33717918395996, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.043998122215270996, 'loss_2': 0.001434326171875, 'loss_3': -15.617538452148438, 'loss_4': 3.0773439407348633, 'epoch': 2.05}
{'loss': 0.0432, 'grad_norm': 13.52200984954834, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.03258965536952019, 'loss_2': 0.0106048583984375, 'loss_3': -15.411333084106445, 'loss_4': 2.192309856414795, 'epoch': 2.05}
{'loss': 0.0525, 'grad_norm': 19.97227668762207, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.05113932862877846, 'loss_2': 0.0013294219970703125, 'loss_3': -15.542383193969727, 'loss_4': 2.7809572219848633, 'epoch': 2.06}
{'loss': 0.069, 'grad_norm': 16.26297378540039, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.06380807608366013, 'loss_2': 0.005199432373046875, 'loss_3': -15.70025634765625, 'loss_4': 2.832580804824829, 'epoch': 2.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:26:39,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:39,754 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:17<1:24:34,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:26:47,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02077491208910942, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.378, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01493481919169426, 'eval_loss_2': 0.005840092897415161, 'eval_loss_3': -18.272476196289062, 'eval_loss_4': 2.225236177444458, 'epoch': 2.06}
{'loss': 0.0407, 'grad_norm': 10.412862777709961, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.030818989500403404, 'loss_2': 0.0099029541015625, 'loss_3': -15.678502082824707, 'loss_4': 2.741903781890869, 'epoch': 2.07}
{'loss': 0.041, 'grad_norm': 11.888486862182617, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.03250189870595932, 'loss_2': 0.0084991455078125, 'loss_3': -15.856491088867188, 'loss_4': 1.867782711982727, 'epoch': 2.08}
{'loss': 0.0476, 'grad_norm': 14.555209159851074, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.0439828522503376, 'loss_2': 0.0035762786865234375, 'loss_3': -15.760503768920898, 'loss_4': 1.8009032011032104, 'epoch': 2.08}
{'loss': 0.0636, 'grad_norm': 12.21811294555664, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.05846711993217468, 'loss_2': 0.00516510009765625, 'loss_3': -15.481819152832031, 'loss_4': 2.454453706741333, 'epoch': 2.09}
{'loss': 0.0642, 'grad_norm': 20.24374008178711, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.05804865062236786, 'loss_2': 0.006183624267578125, 'loss_3': -15.707071304321289, 'loss_4': 2.0137577056884766, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 15:26:47,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:47,107 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:21<1:24:34,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:26:50,909 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-360
[INFO|configuration_utils.py:420] 2025-01-21 15:26:50,910 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-360/config.json                                                                             
{'eval_loss': 0.018200181424617767, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014863468706607819, 'eval_loss_2': 0.0033367127180099487, 'eval_loss_3': -18.230514526367188, 'eval_loss_4': 1.850020170211792, 'epoch': 2.09}
[INFO|modeling_utils.py:2988] 2025-01-21 15:26:51,418 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-360/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:26:51,420 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-360/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:26:51,420 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-360/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:26:52,331 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-350] due to args.save_total_limit
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:26<1:32:00,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:26:55,974 >>
{'loss': 0.0372, 'grad_norm': 11.139556884765625, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.03532497212290764, 'loss_2': 0.001922607421875, 'loss_3': -15.569129943847656, 'loss_4': 2.301537036895752, 'epoch': 2.1}
{'loss': 0.0878, 'grad_norm': 30.95053482055664, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.08706076443195343, 'loss_2': 0.0007886886596679688, 'loss_3': -15.87185287475586, 'loss_4': 1.9998059272766113, 'epoch': 2.1}
{'loss': 0.0446, 'grad_norm': 10.711614608764648, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.04247746244072914, 'loss_2': 0.002094268798828125, 'loss_3': -15.601295471191406, 'loss_4': 1.7669196128845215, 'epoch': 2.11}
{'loss': 0.0612, 'grad_norm': 23.60696029663086, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.05535610392689705, 'loss_2': 0.005889892578125, 'loss_3': -15.709455490112305, 'loss_4': 1.8301936388015747, 'epoch': 2.12}
{'loss': 0.0636, 'grad_norm': 13.987863540649414, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.04790068790316582, 'loss_2': 0.0157470703125, 'loss_3': -15.46430492401123, 'loss_4': 1.671248197555542, 'epoch': 2.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:26:55,974 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:55,974 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:34<1:24:28,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:27:03,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021652210503816605, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.185, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017297865822911263, 'eval_loss_2': 0.004354342818260193, 'eval_loss_3': -18.139957427978516, 'eval_loss_4': 2.081606388092041, 'epoch': 2.12}
{'loss': 0.0353, 'grad_norm': 9.487712860107422, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.03518819436430931, 'loss_2': 9.47117805480957e-05, 'loss_3': -15.729965209960938, 'loss_4': 1.71085786819458, 'epoch': 2.13}
{'loss': 0.0439, 'grad_norm': 11.497258186340332, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.0394841767847538, 'loss_2': 0.0044403076171875, 'loss_3': -15.790998458862305, 'loss_4': 2.261003017425537, 'epoch': 2.13}
{'loss': 0.0856, 'grad_norm': 23.50334930419922, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.068495973944664, 'loss_2': 0.01708984375, 'loss_3': -15.624821662902832, 'loss_4': 2.3429338932037354, 'epoch': 2.14}
{'loss': 0.067, 'grad_norm': 15.97414493560791, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.050321873277425766, 'loss_2': 0.016632080078125, 'loss_3': -15.440116882324219, 'loss_4': 2.3138246536254883, 'epoch': 2.15}
{'loss': 0.0668, 'grad_norm': 16.97260856628418, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.05088116228580475, 'loss_2': 0.0159454345703125, 'loss_3': -15.684928894042969, 'loss_4': 2.0497212409973145, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 15:27:03,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:03,331 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:41<1:23:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:10,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0379980243742466, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.727, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.019319837912917137, 'eval_loss_2': 0.01867818832397461, 'eval_loss_3': -18.132801055908203, 'eval_loss_4': 2.0167346000671387, 'epoch': 2.15}
{'loss': 0.049, 'grad_norm': 9.250523567199707, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.027045590803027153, 'loss_2': 0.0219879150390625, 'loss_3': -15.561393737792969, 'loss_4': 1.92374849319458, 'epoch': 2.16}
{'loss': 0.1733, 'grad_norm': 30.14381980895996, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.15946124494075775, 'loss_2': 0.013885498046875, 'loss_3': -15.317731857299805, 'loss_4': 1.6141772270202637, 'epoch': 2.16}
{'loss': 0.0676, 'grad_norm': 13.614889144897461, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.04628174006938934, 'loss_2': 0.021331787109375, 'loss_3': -15.60285758972168, 'loss_4': 1.5639841556549072, 'epoch': 2.17}
{'loss': 0.0502, 'grad_norm': 11.487038612365723, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.03802294656634331, 'loss_2': 0.0121307373046875, 'loss_3': -15.893813133239746, 'loss_4': 2.033769130706787, 'epoch': 2.17}
{'loss': 0.0378, 'grad_norm': 12.0209321975708, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.03769298270344734, 'loss_2': 6.449222564697266e-05, 'loss_3': -15.660126686096191, 'loss_4': 1.9555455446243286, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 15:27:10,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:10,691 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:45<1:23:09,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:27:14,494 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-375
[INFO|configuration_utils.py:420] 2025-01-21 15:27:14,495 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-375/config.json                                                                             
{'eval_loss': 0.01737765595316887, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014321590773761272, 'eval_loss_2': 0.003056064248085022, 'eval_loss_3': -18.167129516601562, 'eval_loss_4': 1.5667405128479004, 'epoch': 2.18}
[INFO|modeling_utils.py:2988] 2025-01-21 15:27:14,988 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-375/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:27:14,989 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-375/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:27:14,989 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-375/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:27:15,919 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-360] due to args.save_total_limit
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:50<1:31:28,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:27:19,555 >>
{'loss': 0.0769, 'grad_norm': 24.36029815673828, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.06960151344537735, 'loss_2': 0.007320404052734375, 'loss_3': -15.33613109588623, 'loss_4': 1.1878395080566406, 'epoch': 2.19}
{'loss': 0.0375, 'grad_norm': 11.668037414550781, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.036833103746175766, 'loss_2': 0.0006341934204101562, 'loss_3': -15.715206146240234, 'loss_4': 1.5167467594146729, 'epoch': 2.19}
{'loss': 0.1097, 'grad_norm': 22.994508743286133, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.09406072646379471, 'loss_2': 0.0156097412109375, 'loss_3': -15.777535438537598, 'loss_4': 1.8330415487289429, 'epoch': 2.2}
{'loss': 0.0662, 'grad_norm': 20.810667037963867, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.05757489800453186, 'loss_2': 0.00858306884765625, 'loss_3': -15.635355949401855, 'loss_4': 1.3581820726394653, 'epoch': 2.2}
{'loss': 0.0337, 'grad_norm': 6.268757343292236, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.018797434866428375, 'loss_2': 0.0149078369140625, 'loss_3': -15.713850021362305, 'loss_4': 1.4613397121429443, 'epoch': 2.21}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:27:19,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:19,556 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:57<1:24:08,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:27:26,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02945721708238125, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.844, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0183945931494236, 'eval_loss_2': 0.0110626220703125, 'eval_loss_3': -18.189071655273438, 'eval_loss_4': 1.4451394081115723, 'epoch': 2.21}
{'loss': 0.0913, 'grad_norm': 28.946138381958008, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.0744490996003151, 'loss_2': 0.0168609619140625, 'loss_3': -15.616756439208984, 'loss_4': 1.5568411350250244, 'epoch': 2.22}
{'loss': 0.0394, 'grad_norm': 9.985069274902344, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.03180958703160286, 'loss_2': 0.007598876953125, 'loss_3': -15.552223205566406, 'loss_4': 1.3149360418319702, 'epoch': 2.22}
{'loss': 0.0681, 'grad_norm': 21.137216567993164, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.059078894555568695, 'loss_2': 0.0090484619140625, 'loss_3': -15.446407318115234, 'loss_4': 1.3496952056884766, 'epoch': 2.23}
{'loss': 0.0215, 'grad_norm': 7.768674850463867, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.01823556236922741, 'loss_2': 0.003238677978515625, 'loss_3': -15.702081680297852, 'loss_4': 1.654025912284851, 'epoch': 2.23}
{'loss': 0.0287, 'grad_norm': 9.398909568786621, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.023579701781272888, 'loss_2': 0.005153656005859375, 'loss_3': -15.709434509277344, 'loss_4': 1.2701468467712402, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 15:27:26,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:26,904 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [10:05<1:22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:34,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01788451336324215, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.71, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014389850199222565, 'eval_loss_2': 0.003494665026664734, 'eval_loss_3': -18.18252182006836, 'eval_loss_4': 1.2171804904937744, 'epoch': 2.24}
{'loss': 0.05, 'grad_norm': 14.893024444580078, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.04783695191144943, 'loss_2': 0.002162933349609375, 'loss_3': -15.365703582763672, 'loss_4': 0.8678779602050781, 'epoch': 2.24}
{'loss': 0.0957, 'grad_norm': 24.081554412841797, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.09437449276447296, 'loss_2': 0.0012845993041992188, 'loss_3': -15.697121620178223, 'loss_4': 1.1854872703552246, 'epoch': 2.25}
{'loss': 0.0354, 'grad_norm': 15.905499458312988, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.030735183507204056, 'loss_2': 0.00469207763671875, 'loss_3': -15.548341751098633, 'loss_4': 0.9257025718688965, 'epoch': 2.26}
{'loss': 0.028, 'grad_norm': 9.745569229125977, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.0266790222376585, 'loss_2': 0.0012826919555664062, 'loss_3': -15.678033828735352, 'loss_4': 1.0360578298568726, 'epoch': 2.26}
{'loss': 0.0354, 'grad_norm': 9.208680152893066, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.024763401597738266, 'loss_2': 0.0106658935546875, 'loss_3': -15.626995086669922, 'loss_4': 0.9165990352630615, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 15:27:34,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:34,259 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [10:08<1:22:54,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:27:38,056 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-390
[INFO|configuration_utils.py:420] 2025-01-21 15:27:38,057 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-390/config.json                                                                             
{'eval_loss': 0.01603776216506958, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.761, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012569040060043335, 'eval_loss_2': 0.003468722105026245, 'eval_loss_3': -18.125595092773438, 'eval_loss_4': 1.0538182258605957, 'epoch': 2.27}
[INFO|modeling_utils.py:2988] 2025-01-21 15:27:38,548 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-390/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:27:38,549 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-390/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:27:38,549 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-390/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:27:39,496 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-375] due to args.save_total_limit
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:13<1:31:16,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:27:43,137 >>
{'loss': 0.0322, 'grad_norm': 11.874018669128418, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.03164846822619438, 'loss_2': 0.0005970001220703125, 'loss_3': -15.584127426147461, 'loss_4': 0.900644063949585, 'epoch': 2.27}
{'loss': 0.0213, 'grad_norm': 7.322666645050049, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.013819698244333267, 'loss_2': 0.00748443603515625, 'loss_3': -15.514242172241211, 'loss_4': 0.8593161106109619, 'epoch': 2.28}
{'loss': 0.0429, 'grad_norm': 15.127589225769043, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.03377299755811691, 'loss_2': 0.00914764404296875, 'loss_3': -15.54629135131836, 'loss_4': 0.39692583680152893, 'epoch': 2.28}
{'loss': 0.0442, 'grad_norm': 12.544867515563965, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.03145911917090416, 'loss_2': 0.0127105712890625, 'loss_3': -15.40442943572998, 'loss_4': 0.9288997650146484, 'epoch': 2.29}
{'loss': 0.0352, 'grad_norm': 7.980393886566162, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.01914888434112072, 'loss_2': 0.01605224609375, 'loss_3': -15.469171524047852, 'loss_4': 0.6586618423461914, 'epoch': 2.3}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:27:43,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:43,137 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:21<1:23:49,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:27:50,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026518525555729866, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015175970271229744, 'eval_loss_2': 0.011342555284500122, 'eval_loss_3': -18.122238159179688, 'eval_loss_4': 0.4971928596496582, 'epoch': 2.3}
{'loss': 0.0693, 'grad_norm': 23.53888511657715, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.06399238109588623, 'loss_2': 0.00533294677734375, 'loss_3': -15.420974731445312, 'loss_4': 0.567470908164978, 'epoch': 2.3}
{'loss': 0.0346, 'grad_norm': 12.485786437988281, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.02351215109229088, 'loss_2': 0.0110931396484375, 'loss_3': -15.682486534118652, 'loss_4': 0.13640934228897095, 'epoch': 2.31}
{'loss': 0.042, 'grad_norm': 17.768430709838867, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.037261489778757095, 'loss_2': 0.0047149658203125, 'loss_3': -15.511117935180664, 'loss_4': 0.23910309374332428, 'epoch': 2.31}
{'loss': 0.1051, 'grad_norm': 26.077014923095703, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.09482283890247345, 'loss_2': 0.01031494140625, 'loss_3': -15.356715202331543, 'loss_4': 0.03835248947143555, 'epoch': 2.32}
{'loss': 0.038, 'grad_norm': 14.856287002563477, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.03612760826945305, 'loss_2': 0.0018253326416015625, 'loss_3': -15.485719680786133, 'loss_4': -0.020770102739334106, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 15:27:50,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:50,485 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:28<1:22:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:57,830 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020403912290930748, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016960419714450836, 'eval_loss_2': 0.003443494439125061, 'eval_loss_3': -18.14211082458496, 'eval_loss_4': 0.14591088891029358, 'epoch': 2.33}
{'loss': 0.0325, 'grad_norm': 15.120891571044922, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.02864658087491989, 'loss_2': 0.0038433074951171875, 'loss_3': -15.671419143676758, 'loss_4': 0.03851223737001419, 'epoch': 2.33}
{'loss': 0.0263, 'grad_norm': 10.664031982421875, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.02288726344704628, 'loss_2': 0.0033740997314453125, 'loss_3': -15.7457275390625, 'loss_4': -0.15888062119483948, 'epoch': 2.34}
{'loss': 0.0333, 'grad_norm': 7.830103397369385, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.017645036801695824, 'loss_2': 0.01568603515625, 'loss_3': -15.689424514770508, 'loss_4': 0.43782150745391846, 'epoch': 2.34}
{'loss': 0.0288, 'grad_norm': 10.060020446777344, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.027647724375128746, 'loss_2': 0.0011425018310546875, 'loss_3': -15.556272506713867, 'loss_4': 0.4755260944366455, 'epoch': 2.35}
{'loss': 0.0546, 'grad_norm': 22.44900131225586, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.04784606397151947, 'loss_2': 0.006771087646484375, 'loss_3': -15.76806640625, 'loss_4': 0.7377585768699646, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 15:27:57,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:57,831 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:36<1:22:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:05,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01985337771475315, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.537, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.016998566687107086, 'eval_loss_2': 0.0028548091650009155, 'eval_loss_3': -18.22336196899414, 'eval_loss_4': 0.7870373725891113, 'epoch': 2.35}
{'loss': 0.0405, 'grad_norm': 11.366646766662598, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.033330123871564865, 'loss_2': 0.00717926025390625, 'loss_3': -15.664965629577637, 'loss_4': 1.4324897527694702, 'epoch': 2.36}
{'loss': 0.029, 'grad_norm': 9.696324348449707, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.024779608473181725, 'loss_2': 0.004222869873046875, 'loss_3': -15.59173583984375, 'loss_4': 0.6116206645965576, 'epoch': 2.37}
{'loss': 0.041, 'grad_norm': 14.919897079467773, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.036114465445280075, 'loss_2': 0.00492095947265625, 'loss_3': -15.510143280029297, 'loss_4': 0.6814755201339722, 'epoch': 2.37}
{'loss': 0.0282, 'grad_norm': 7.0032734870910645, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.015990296378731728, 'loss_2': 0.012237548828125, 'loss_3': -15.759138107299805, 'loss_4': 1.4712424278259277, 'epoch': 2.38}
{'loss': 0.0536, 'grad_norm': 24.330791473388672, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.04985626041889191, 'loss_2': 0.00376129150390625, 'loss_3': -15.598809242248535, 'loss_4': 1.6517003774642944, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 15:28:05,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:05,175 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:43<1:22:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:12,519 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016937946900725365, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012205934152007103, 'eval_loss_2': 0.004732012748718262, 'eval_loss_3': -18.18488883972168, 'eval_loss_4': 1.1313371658325195, 'epoch': 2.38}
{'loss': 0.0361, 'grad_norm': 10.538683891296387, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.028938230127096176, 'loss_2': 0.007171630859375, 'loss_3': -15.653654098510742, 'loss_4': 1.7364799976348877, 'epoch': 2.39}
{'loss': 0.072, 'grad_norm': 26.804750442504883, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.07186774164438248, 'loss_2': 0.00010961294174194336, 'loss_3': -15.493066787719727, 'loss_4': 1.2209084033966064, 'epoch': 2.4}
{'loss': 0.0254, 'grad_norm': 9.26929759979248, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.023019663989543915, 'loss_2': 0.0024127960205078125, 'loss_3': -15.618219375610352, 'loss_4': 1.0467112064361572, 'epoch': 2.4}
{'loss': 0.0381, 'grad_norm': 15.285640716552734, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.033926572650671005, 'loss_2': 0.004138946533203125, 'loss_3': -15.464073181152344, 'loss_4': 0.6938529014587402, 'epoch': 2.41}
{'loss': 0.03, 'grad_norm': 13.302484512329102, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.02971654385328293, 'loss_2': 0.0002665519714355469, 'loss_3': -15.575644493103027, 'loss_4': 0.9245137572288513, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 15:28:12,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:12,519 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:47<1:22:01,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:28:16,320 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-415
[INFO|configuration_utils.py:420] 2025-01-21 15:28:16,321 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-415/config.json                                                                             
{'eval_loss': 0.015797507017850876, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012453373521566391, 'eval_loss_2': 0.003344133496284485, 'eval_loss_3': -18.14418601989746, 'eval_loss_4': 0.8065717816352844, 'epoch': 2.41}
[INFO|modeling_utils.py:2988] 2025-01-21 15:28:16,833 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-415/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:28:16,834 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-415/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:28:16,835 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-415/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:28:17,762 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-390] due to args.save_total_limit
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:52<1:30:52,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:28:21,409 >>
{'loss': 0.0405, 'grad_norm': 20.904333114624023, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.030819613486528397, 'loss_2': 0.00968170166015625, 'loss_3': -15.424457550048828, 'loss_4': 1.0686719417572021, 'epoch': 2.42}
{'loss': 0.0257, 'grad_norm': 8.566984176635742, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.017079968005418777, 'loss_2': 0.008575439453125, 'loss_3': -15.45412826538086, 'loss_4': 0.8621022701263428, 'epoch': 2.42}
{'loss': 0.0182, 'grad_norm': 6.879759788513184, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.014904682524502277, 'loss_2': 0.003284454345703125, 'loss_3': -15.745832443237305, 'loss_4': 0.615545392036438, 'epoch': 2.43}
{'loss': 0.0181, 'grad_norm': 8.952937126159668, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.0160693172365427, 'loss_2': 0.0020294189453125, 'loss_3': -15.547335624694824, 'loss_4': 0.8551291227340698, 'epoch': 2.44}
{'loss': 0.0255, 'grad_norm': 9.07361125946045, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.02096129208803177, 'loss_2': 0.00452423095703125, 'loss_3': -15.547356605529785, 'loss_4': 0.32141661643981934, 'epoch': 2.44}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:28:21,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:21,410 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:59<1:23:27,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:28:28,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020320717245340347, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.907, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01541045866906643, 'eval_loss_2': 0.004910260438919067, 'eval_loss_3': -18.00820541381836, 'eval_loss_4': 0.7009578943252563, 'epoch': 2.44}
{'loss': 0.0221, 'grad_norm': 9.397327423095703, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.018675412982702255, 'loss_2': 0.003376007080078125, 'loss_3': -15.492929458618164, 'loss_4': 0.5665596723556519, 'epoch': 2.45}
{'loss': 0.0289, 'grad_norm': 10.98613166809082, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.020539458841085434, 'loss_2': 0.0083465576171875, 'loss_3': -15.42453670501709, 'loss_4': 0.21466167271137238, 'epoch': 2.45}
{'loss': 0.0142, 'grad_norm': 7.94142484664917, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.013627912849187851, 'loss_2': 0.000576019287109375, 'loss_3': -15.602045059204102, 'loss_4': 0.21753670275211334, 'epoch': 2.46}
{'loss': 0.0873, 'grad_norm': 22.730676651000977, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.08512725681066513, 'loss_2': 0.0022125244140625, 'loss_3': -15.168002128601074, 'loss_4': 0.4769558310508728, 'epoch': 2.47}
{'loss': 0.0228, 'grad_norm': 8.874643325805664, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.02002505399286747, 'loss_2': 0.0027256011962890625, 'loss_3': -15.343071937561035, 'loss_4': 0.6782432794570923, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 15:28:28,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:28,765 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [11:06<1:22:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:36,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033890459686517715, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.43, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.028590891510248184, 'eval_loss_2': 0.005299568176269531, 'eval_loss_3': -17.85692596435547, 'eval_loss_4': 1.0287187099456787, 'epoch': 2.47}
{'loss': 0.0241, 'grad_norm': 11.349706649780273, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.018243756145238876, 'loss_2': 0.00586700439453125, 'loss_3': -15.277727127075195, 'loss_4': 0.7532039880752563, 'epoch': 2.48}
{'loss': 0.0485, 'grad_norm': 24.891895294189453, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.03974837437272072, 'loss_2': 0.00875091552734375, 'loss_3': -15.370058059692383, 'loss_4': 1.2177307605743408, 'epoch': 2.48}
{'loss': 0.0497, 'grad_norm': 20.925064086914062, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.04346979781985283, 'loss_2': 0.00626373291015625, 'loss_3': -15.073485374450684, 'loss_4': 1.0808660984039307, 'epoch': 2.49}
{'loss': 0.0289, 'grad_norm': 9.207250595092773, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.026460550725460052, 'loss_2': 0.00240325927734375, 'loss_3': -15.17415714263916, 'loss_4': 1.1868393421173096, 'epoch': 2.49}
{'loss': 0.0627, 'grad_norm': 22.583553314208984, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.05453241243958473, 'loss_2': 0.00815582275390625, 'loss_3': -15.375859260559082, 'loss_4': 1.6918294429779053, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 15:28:36,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:36,112 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:14<1:21:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:43,464 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04677388817071915, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.439, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.043328989297151566, 'eval_loss_2': 0.0034448951482772827, 'eval_loss_3': -17.815128326416016, 'eval_loss_4': 1.7686941623687744, 'epoch': 2.5}
{'loss': 0.0645, 'grad_norm': 17.801015853881836, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.0638396367430687, 'loss_2': 0.0006260871887207031, 'loss_3': -15.477363586425781, 'loss_4': 1.625331163406372, 'epoch': 2.51}
{'loss': 0.1136, 'grad_norm': 37.68307113647461, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.1062188595533371, 'loss_2': 0.0074005126953125, 'loss_3': -15.252031326293945, 'loss_4': 1.8913402557373047, 'epoch': 2.51}
{'loss': 0.0595, 'grad_norm': 16.319766998291016, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.056061845272779465, 'loss_2': 0.003467559814453125, 'loss_3': -15.179999351501465, 'loss_4': 1.5475014448165894, 'epoch': 2.52}
{'loss': 0.1847, 'grad_norm': 41.88053512573242, 'learning_rate': 2.75e-05, 'loss_1': 0.18373873829841614, 'loss_2': 0.0010042190551757812, 'loss_3': -15.142976760864258, 'loss_4': 2.4177300930023193, 'epoch': 2.52}
{'loss': 0.0357, 'grad_norm': 7.815828323364258, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.02318623661994934, 'loss_2': 0.0125274658203125, 'loss_3': -15.31751823425293, 'loss_4': 1.3721150159835815, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 15:28:43,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:43,464 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:21<1:21:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:50,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03057102859020233, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.024730967357754707, 'eval_loss_2': 0.0058400630950927734, 'eval_loss_3': -17.94949722290039, 'eval_loss_4': 1.941397786140442, 'epoch': 2.53}
{'loss': 0.219, 'grad_norm': 49.73655319213867, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.21001039445400238, 'loss_2': 0.0090179443359375, 'loss_3': -15.33322525024414, 'loss_4': 2.0463154315948486, 'epoch': 2.53}
{'loss': 0.0384, 'grad_norm': 10.112011909484863, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.03134762868285179, 'loss_2': 0.0070648193359375, 'loss_3': -15.532023429870605, 'loss_4': 1.9821250438690186, 'epoch': 2.54}
{'loss': 0.0596, 'grad_norm': 16.076955795288086, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.05689707398414612, 'loss_2': 0.002735137939453125, 'loss_3': -15.489363670349121, 'loss_4': 2.0156006813049316, 'epoch': 2.55}
{'loss': 0.0198, 'grad_norm': 9.805215835571289, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.019701536744832993, 'loss_2': 0.0001323223114013672, 'loss_3': -15.553682327270508, 'loss_4': 1.9882497787475586, 'epoch': 2.55}
{'loss': 0.0508, 'grad_norm': 19.778526306152344, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.04761626571416855, 'loss_2': 0.003204345703125, 'loss_3': -15.261691093444824, 'loss_4': 2.124906539916992, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 15:28:50,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:50,826 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:29<1:21:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:58,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01706264726817608, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.311, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012702315114438534, 'eval_loss_2': 0.00436033308506012, 'eval_loss_3': -18.06248664855957, 'eval_loss_4': 2.004302740097046, 'epoch': 2.56}
{'loss': 0.0531, 'grad_norm': 17.776052474975586, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.05088513344526291, 'loss_2': 0.0021991729736328125, 'loss_3': -15.485843658447266, 'loss_4': 2.204695224761963, 'epoch': 2.56}
{'loss': 0.0545, 'grad_norm': 17.719303131103516, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.04160771518945694, 'loss_2': 0.01293182373046875, 'loss_3': -15.142749786376953, 'loss_4': 1.9314165115356445, 'epoch': 2.57}
{'loss': 0.0727, 'grad_norm': 27.050735473632812, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.06932004541158676, 'loss_2': 0.00339508056640625, 'loss_3': -15.560787200927734, 'loss_4': 2.0019354820251465, 'epoch': 2.58}
{'loss': 0.0377, 'grad_norm': 10.785567283630371, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.0303705595433712, 'loss_2': 0.00732421875, 'loss_3': -15.504878997802734, 'loss_4': 1.9696779251098633, 'epoch': 2.58}
{'loss': 0.103, 'grad_norm': 33.2953987121582, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.09260939061641693, 'loss_2': 0.0103607177734375, 'loss_3': -15.533265113830566, 'loss_4': 1.9852672815322876, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 15:28:58,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:58,189 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:36<1:21:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:05,563 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01784077286720276, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011623697355389595, 'eval_loss_2': 0.006217077374458313, 'eval_loss_3': -18.150249481201172, 'eval_loss_4': 2.1014087200164795, 'epoch': 2.59}
{'loss': 0.0425, 'grad_norm': 15.134797096252441, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.03599214926362038, 'loss_2': 0.006500244140625, 'loss_3': -15.593012809753418, 'loss_4': 2.316161870956421, 'epoch': 2.59}
{'loss': 0.0487, 'grad_norm': 21.351884841918945, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.0398312471807003, 'loss_2': 0.0088348388671875, 'loss_3': -15.555587768554688, 'loss_4': 2.1362760066986084, 'epoch': 2.6}
{'loss': 0.0417, 'grad_norm': 17.272581100463867, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.0412110798060894, 'loss_2': 0.000507354736328125, 'loss_3': -15.621006965637207, 'loss_4': 2.875916004180908, 'epoch': 2.6}
{'loss': 0.0573, 'grad_norm': 16.18001365661621, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.0504060834646225, 'loss_2': 0.006877899169921875, 'loss_3': -15.594534873962402, 'loss_4': 2.7432281970977783, 'epoch': 2.61}
{'loss': 0.0421, 'grad_norm': 14.79544448852539, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.03225540742278099, 'loss_2': 0.0098876953125, 'loss_3': -15.410358428955078, 'loss_4': 2.0515429973602295, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 15:29:05,563 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:05,564 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:43<1:21:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:12,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016509901732206345, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.147, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0099321398884058, 'eval_loss_2': 0.0065777599811553955, 'eval_loss_3': -18.17586326599121, 'eval_loss_4': 2.1572751998901367, 'epoch': 2.62}
{'loss': 0.0283, 'grad_norm': 9.262009620666504, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.02437470480799675, 'loss_2': 0.00391387939453125, 'loss_3': -15.57596206665039, 'loss_4': 2.2623233795166016, 'epoch': 2.62}
{'loss': 0.1046, 'grad_norm': 31.8806209564209, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.09872918576002121, 'loss_2': 0.0059051513671875, 'loss_3': -15.179641723632812, 'loss_4': 2.739624500274658, 'epoch': 2.63}
{'loss': 0.0223, 'grad_norm': 11.347576141357422, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.019900301471352577, 'loss_2': 0.00237274169921875, 'loss_3': -15.418264389038086, 'loss_4': 2.4590964317321777, 'epoch': 2.63}
{'loss': 0.1195, 'grad_norm': 31.420848846435547, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.11441392451524734, 'loss_2': 0.005126953125, 'loss_3': -15.236093521118164, 'loss_4': 2.6581692695617676, 'epoch': 2.64}
{'loss': 0.0336, 'grad_norm': 11.525019645690918, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.025805320590734482, 'loss_2': 0.00778961181640625, 'loss_3': -15.30444049835205, 'loss_4': 1.72475266456604, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 15:29:12,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:12,935 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:51<1:21:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:20,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019052710384130478, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009142222814261913, 'eval_loss_2': 0.00991048663854599, 'eval_loss_3': -18.13323974609375, 'eval_loss_4': 1.7590608596801758, 'epoch': 2.65}
{'loss': 0.0297, 'grad_norm': 10.285062789916992, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.01911631040275097, 'loss_2': 0.01062774658203125, 'loss_3': -15.225444793701172, 'loss_4': 1.7580567598342896, 'epoch': 2.65}
{'loss': 0.0292, 'grad_norm': 9.259252548217773, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.017226126044988632, 'loss_2': 0.01198577880859375, 'loss_3': -15.728363037109375, 'loss_4': 2.0974321365356445, 'epoch': 2.66}
{'loss': 0.0365, 'grad_norm': 13.424985885620117, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.02803042158484459, 'loss_2': 0.00849151611328125, 'loss_3': -15.344574928283691, 'loss_4': 1.6870415210723877, 'epoch': 2.66}
{'loss': 0.0299, 'grad_norm': 9.54348373413086, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.02242809534072876, 'loss_2': 0.0074615478515625, 'loss_3': -15.518115997314453, 'loss_4': 1.4372498989105225, 'epoch': 2.67}
{'loss': 0.0543, 'grad_norm': 15.865171432495117, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.045116961002349854, 'loss_2': 0.00922393798828125, 'loss_3': -15.446589469909668, 'loss_4': 1.1862390041351318, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 15:29:20,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:20,302 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:58<1:21:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:27,673 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030186325311660767, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.024780424311757088, 'eval_loss_2': 0.005405902862548828, 'eval_loss_3': -18.075319290161133, 'eval_loss_4': 1.2292908430099487, 'epoch': 2.67}
{'loss': 0.0246, 'grad_norm': 8.315177917480469, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.01611059531569481, 'loss_2': 0.00844573974609375, 'loss_3': -15.491853713989258, 'loss_4': 1.1134788990020752, 'epoch': 2.68}
{'loss': 0.0431, 'grad_norm': 14.620100021362305, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.03619435429573059, 'loss_2': 0.00691986083984375, 'loss_3': -15.371095657348633, 'loss_4': 1.0666859149932861, 'epoch': 2.69}
{'loss': 0.021, 'grad_norm': 8.116084098815918, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.017576321959495544, 'loss_2': 0.003437042236328125, 'loss_3': -15.536075592041016, 'loss_4': 0.8054000735282898, 'epoch': 2.69}
{'loss': 0.0671, 'grad_norm': 35.2379035949707, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.05350286886096001, 'loss_2': 0.01357269287109375, 'loss_3': -15.542888641357422, 'loss_4': 1.0333878993988037, 'epoch': 2.7}
{'loss': 0.0205, 'grad_norm': 7.827784061431885, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.013818643055856228, 'loss_2': 0.00665283203125, 'loss_3': -15.486990928649902, 'loss_4': 0.6401498317718506, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 15:29:27,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:27,673 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [12:05<1:21:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:35,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05141600966453552, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.807, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.04559943825006485, 'eval_loss_2': 0.005816571414470673, 'eval_loss_3': -18.015132904052734, 'eval_loss_4': 0.9584920406341553, 'epoch': 2.7}
{'loss': 0.0231, 'grad_norm': 6.978453159332275, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.02245176024734974, 'loss_2': 0.000682830810546875, 'loss_3': -15.463220596313477, 'loss_4': 0.6888154745101929, 'epoch': 2.71}
{'loss': 0.0252, 'grad_norm': 9.44477653503418, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.022711968049407005, 'loss_2': 0.002452850341796875, 'loss_3': -15.401391983032227, 'loss_4': 0.9888261556625366, 'epoch': 2.72}
{'loss': 0.0501, 'grad_norm': 11.3236722946167, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.03456835821270943, 'loss_2': 0.01554107666015625, 'loss_3': -15.618036270141602, 'loss_4': 0.9586081504821777, 'epoch': 2.72}
{'loss': 0.0604, 'grad_norm': 21.551265716552734, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.058477919548749924, 'loss_2': 0.0018863677978515625, 'loss_3': -15.429130554199219, 'loss_4': 0.7778871059417725, 'epoch': 2.73}
{'loss': 0.0305, 'grad_norm': 9.23430347442627, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.02850036323070526, 'loss_2': 0.00201416015625, 'loss_3': -15.555635452270508, 'loss_4': 0.8100307583808899, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 15:29:35,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:35,038 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:13<1:21:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:42,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.060956913977861404, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.05518069118261337, 'eval_loss_2': 0.00577622652053833, 'eval_loss_3': -18.061437606811523, 'eval_loss_4': 0.8909797072410583, 'epoch': 2.73}
{'loss': 0.1424, 'grad_norm': 36.27649688720703, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.1409100741147995, 'loss_2': 0.00151824951171875, 'loss_3': -15.466615676879883, 'loss_4': 1.1059386730194092, 'epoch': 2.74}
{'loss': 0.1301, 'grad_norm': 35.45819091796875, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.12560205161571503, 'loss_2': 0.00447845458984375, 'loss_3': -15.292752265930176, 'loss_4': 0.6171433925628662, 'epoch': 2.74}
{'loss': 0.0929, 'grad_norm': 23.577301025390625, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.09139180928468704, 'loss_2': 0.0015106201171875, 'loss_3': -15.735733985900879, 'loss_4': 0.9133384227752686, 'epoch': 2.75}
{'loss': 0.0676, 'grad_norm': 20.51801300048828, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.06389506161212921, 'loss_2': 0.00373077392578125, 'loss_3': -15.569385528564453, 'loss_4': 0.21764996647834778, 'epoch': 2.76}
{'loss': 0.084, 'grad_norm': 23.24873924255371, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.07338868081569672, 'loss_2': 0.0106048583984375, 'loss_3': -15.616640090942383, 'loss_4': 1.0055971145629883, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 15:29:42,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:42,399 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:20<1:21:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:49,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.056869473308324814, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.233, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.052199214696884155, 'eval_loss_2': 0.004670262336730957, 'eval_loss_3': -18.06699562072754, 'eval_loss_4': 0.3663293421268463, 'epoch': 2.76}
{'loss': 0.11, 'grad_norm': 31.78599739074707, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.10915994644165039, 'loss_2': 0.0007915496826171875, 'loss_3': -15.482611656188965, 'loss_4': 0.7286891937255859, 'epoch': 2.77}
{'loss': 0.1077, 'grad_norm': 24.65610122680664, 'learning_rate': 2.725e-05, 'loss_1': 0.1041596308350563, 'loss_2': 0.003570556640625, 'loss_3': -15.633464813232422, 'loss_4': 1.0150971412658691, 'epoch': 2.77}
{'loss': 0.0702, 'grad_norm': 20.370180130004883, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.06913118064403534, 'loss_2': 0.001064300537109375, 'loss_3': -15.818143844604492, 'loss_4': 0.6781868934631348, 'epoch': 2.78}
{'loss': 0.2031, 'grad_norm': 54.447288513183594, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.19336804747581482, 'loss_2': 0.0097198486328125, 'loss_3': -15.355015754699707, 'loss_4': 0.26931995153427124, 'epoch': 2.78}
{'loss': 0.0718, 'grad_norm': 18.633743286132812, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.05460713058710098, 'loss_2': 0.0172119140625, 'loss_3': -15.660502433776855, 'loss_4': 0.0995263159275055, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 15:29:49,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:49,784 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:27<1:21:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:57,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03341858088970184, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01926986500620842, 'eval_loss_2': 0.014148712158203125, 'eval_loss_3': -18.158666610717773, 'eval_loss_4': 0.42394012212753296, 'epoch': 2.79}
{'loss': 0.0447, 'grad_norm': 10.6057767868042, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.03474058583378792, 'loss_2': 0.00994873046875, 'loss_3': -15.71385669708252, 'loss_4': 0.2890309989452362, 'epoch': 2.8}
{'loss': 0.1126, 'grad_norm': 30.66275405883789, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.09435110539197922, 'loss_2': 0.01824951171875, 'loss_3': -15.663934707641602, 'loss_4': 2.0814335346221924, 'epoch': 2.8}
{'loss': 0.0546, 'grad_norm': 15.635842323303223, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.04402763396501541, 'loss_2': 0.010589599609375, 'loss_3': -15.490328788757324, 'loss_4': 1.016098141670227, 'epoch': 2.81}
{'loss': 0.1481, 'grad_norm': 34.09724044799805, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.14045943319797516, 'loss_2': 0.0076751708984375, 'loss_3': -15.632648468017578, 'loss_4': 1.924344539642334, 'epoch': 2.81}
{'loss': 0.0628, 'grad_norm': 17.54414939880371, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.05399472266435623, 'loss_2': 0.008758544921875, 'loss_3': -15.728927612304688, 'loss_4': 1.2263985872268677, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 15:29:57,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:57,144 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:35<1:21:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:04,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020200438797473907, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.039, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016233334317803383, 'eval_loss_2': 0.003967106342315674, 'eval_loss_3': -18.24681854248047, 'eval_loss_4': 1.197704792022705, 'epoch': 2.82}
{'loss': 0.0232, 'grad_norm': 7.13803243637085, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.020209690555930138, 'loss_2': 0.0029449462890625, 'loss_3': -15.792227745056152, 'loss_4': 1.4024618864059448, 'epoch': 2.83}
{'loss': 0.0627, 'grad_norm': 23.770679473876953, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.060786835849285126, 'loss_2': 0.0019207000732421875, 'loss_3': -15.631728172302246, 'loss_4': 1.2131365537643433, 'epoch': 2.83}
{'loss': 0.0626, 'grad_norm': 20.5860595703125, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.05456066131591797, 'loss_2': 0.00806427001953125, 'loss_3': -15.63912296295166, 'loss_4': 1.8709051609039307, 'epoch': 2.84}
{'loss': 0.056, 'grad_norm': 12.906462669372559, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.036287225782871246, 'loss_2': 0.01971435546875, 'loss_3': -15.64124584197998, 'loss_4': 1.2979507446289062, 'epoch': 2.84}
{'loss': 0.0379, 'grad_norm': 13.046443939208984, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.02498447336256504, 'loss_2': 0.01287078857421875, 'loss_3': -15.726287841796875, 'loss_4': 1.503166675567627, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 15:30:04,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:04,513 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:42<1:20:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:11,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025455577298998833, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.373, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012487992644309998, 'eval_loss_2': 0.012967586517333984, 'eval_loss_3': -18.18544578552246, 'eval_loss_4': 1.1854151487350464, 'epoch': 2.85}
{'loss': 0.0985, 'grad_norm': 25.19170570373535, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.07498457282781601, 'loss_2': 0.02349853515625, 'loss_3': -15.718228340148926, 'loss_4': 1.2294648885726929, 'epoch': 2.85}
{'loss': 0.0359, 'grad_norm': 8.246903419494629, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.019826022908091545, 'loss_2': 0.01605224609375, 'loss_3': -15.753018379211426, 'loss_4': 0.9755913019180298, 'epoch': 2.86}
{'loss': 0.0403, 'grad_norm': 15.767440795898438, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.02703111618757248, 'loss_2': 0.01323699951171875, 'loss_3': -15.748759269714355, 'loss_4': 1.352699875831604, 'epoch': 2.87}
{'loss': 0.082, 'grad_norm': 20.236799240112305, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.06623829901218414, 'loss_2': 0.0157928466796875, 'loss_3': -15.78719711303711, 'loss_4': 1.0538837909698486, 'epoch': 2.87}
{'loss': 0.043, 'grad_norm': 13.88768196105957, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.029833512380719185, 'loss_2': 0.013153076171875, 'loss_3': -15.661931991577148, 'loss_4': 1.0605175495147705, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 15:30:11,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:11,878 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:50<1:20:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:19,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025771621614694595, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.82, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.019399289041757584, 'eval_loss_2': 0.006372332572937012, 'eval_loss_3': -18.092926025390625, 'eval_loss_4': 1.3289809226989746, 'epoch': 2.88}
{'loss': 0.0536, 'grad_norm': 13.610724449157715, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.045125145465135574, 'loss_2': 0.00848388671875, 'loss_3': -15.703348159790039, 'loss_4': 1.8461403846740723, 'epoch': 2.88}
{'loss': 0.0439, 'grad_norm': 12.642889022827148, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.036596670746803284, 'loss_2': 0.0072784423828125, 'loss_3': -15.75851058959961, 'loss_4': 1.5085325241088867, 'epoch': 2.89}
{'loss': 0.0313, 'grad_norm': 9.717089653015137, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.025521447882056236, 'loss_2': 0.005802154541015625, 'loss_3': -15.532205581665039, 'loss_4': 1.052441120147705, 'epoch': 2.9}
{'loss': 0.052, 'grad_norm': 23.988189697265625, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.051649730652570724, 'loss_2': 0.0003533363342285156, 'loss_3': -15.800901412963867, 'loss_4': 1.52082359790802, 'epoch': 2.9}
{'loss': 0.0713, 'grad_norm': 25.397186279296875, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.06463146209716797, 'loss_2': 0.00664520263671875, 'loss_3': -15.726036071777344, 'loss_4': 1.5788846015930176, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 15:30:19,252 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:19,252 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:57<1:20:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:26,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05424845218658447, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.686, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.03771936520934105, 'eval_loss_2': 0.016529083251953125, 'eval_loss_3': -17.984859466552734, 'eval_loss_4': 1.8131661415100098, 'epoch': 2.91}
{'loss': 0.0502, 'grad_norm': 11.382363319396973, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.03832671791315079, 'loss_2': 0.011871337890625, 'loss_3': -15.668270111083984, 'loss_4': 2.1073732376098633, 'epoch': 2.91}
{'loss': 0.2383, 'grad_norm': 32.810577392578125, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.22554780542850494, 'loss_2': 0.012725830078125, 'loss_3': -15.58397388458252, 'loss_4': 1.7016077041625977, 'epoch': 2.92}
{'loss': 0.0674, 'grad_norm': 16.053508758544922, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.05120360851287842, 'loss_2': 0.01617431640625, 'loss_3': -15.6209716796875, 'loss_4': 1.6921710968017578, 'epoch': 2.92}
{'loss': 0.0475, 'grad_norm': 8.60478401184082, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.024144530296325684, 'loss_2': 0.023345947265625, 'loss_3': -15.74714183807373, 'loss_4': 1.2197952270507812, 'epoch': 2.93}
{'loss': 0.076, 'grad_norm': 24.01864242553711, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.062313660979270935, 'loss_2': 0.01367950439453125, 'loss_3': -15.666078567504883, 'loss_4': 1.5626219511032104, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 15:30:26,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:26,625 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [13:04<1:20:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:34,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04288869351148605, 'eval_runtime': 3.819, 'eval_samples_per_second': 268.132, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.023695994168519974, 'eval_loss_2': 0.01919269561767578, 'eval_loss_3': -18.080509185791016, 'eval_loss_4': 1.9446238279342651, 'epoch': 2.94}
{'loss': 0.0407, 'grad_norm': 9.900259017944336, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.025235706940293312, 'loss_2': 0.0154876708984375, 'loss_3': -15.756110191345215, 'loss_4': 2.0650086402893066, 'epoch': 2.94}
{'loss': 0.0599, 'grad_norm': 23.451997756958008, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.04411022737622261, 'loss_2': 0.015838623046875, 'loss_3': -15.857380867004395, 'loss_4': 1.6103265285491943, 'epoch': 2.95}
{'loss': 0.0502, 'grad_norm': 10.155323028564453, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.03357899561524391, 'loss_2': 0.0166015625, 'loss_3': -15.65035629272461, 'loss_4': 2.3192944526672363, 'epoch': 2.95}
{'loss': 0.036, 'grad_norm': 8.797674179077148, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.0318484827876091, 'loss_2': 0.00417327880859375, 'loss_3': -15.928278923034668, 'loss_4': 2.053607225418091, 'epoch': 2.96}
{'loss': 0.068, 'grad_norm': 14.898917198181152, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.060410257428884506, 'loss_2': 0.007598876953125, 'loss_3': -15.740328788757324, 'loss_4': 2.576937675476074, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 15:30:34,001 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:34,001 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:12<1:20:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:41,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02137655019760132, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.192, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017907502129673958, 'eval_loss_2': 0.0034690499305725098, 'eval_loss_3': -18.17446517944336, 'eval_loss_4': 2.4775190353393555, 'epoch': 2.97}
{'loss': 0.031, 'grad_norm': 9.646612167358398, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.026811137795448303, 'loss_2': 0.004215240478515625, 'loss_3': -16.07086944580078, 'loss_4': 2.4872097969055176, 'epoch': 2.97}
{'loss': 0.0461, 'grad_norm': 19.954477310180664, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.04276597499847412, 'loss_2': 0.00334930419921875, 'loss_3': -16.12314224243164, 'loss_4': 2.4748034477233887, 'epoch': 2.98}
{'loss': 0.1058, 'grad_norm': 21.380006790161133, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.10475421696901321, 'loss_2': 0.001094818115234375, 'loss_3': -15.985210418701172, 'loss_4': 3.140895128250122, 'epoch': 2.98}
{'loss': 0.0742, 'grad_norm': 21.731460571289062, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.05993720144033432, 'loss_2': 0.014251708984375, 'loss_3': -15.804237365722656, 'loss_4': 2.656341552734375, 'epoch': 2.99}
{'loss': 0.0747, 'grad_norm': 18.827754974365234, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.06173021346330643, 'loss_2': 0.012969970703125, 'loss_3': -15.949180603027344, 'loss_4': 3.018913745880127, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 15:30:41,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:41,348 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:19<1:18:56,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:30:48,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026415929198265076, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011545883491635323, 'eval_loss_2': 0.014870047569274902, 'eval_loss_3': -18.287403106689453, 'eval_loss_4': 3.0262274742126465, 'epoch': 2.99}
{'loss': 0.0367, 'grad_norm': 13.103317260742188, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.022580603137612343, 'loss_2': 0.0141448974609375, 'loss_3': -15.713608741760254, 'loss_4': 2.68392014503479, 'epoch': 3.0}
{'loss': 0.0384, 'grad_norm': 7.507721424102783, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.022337334230542183, 'loss_2': 0.0160980224609375, 'loss_3': -15.794106483459473, 'loss_4': 2.880260467529297, 'epoch': 3.01}
{'loss': 0.0431, 'grad_norm': 10.252479553222656, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.034261301159858704, 'loss_2': 0.0087890625, 'loss_3': -15.885396003723145, 'loss_4': 3.548732042312622, 'epoch': 3.01}
{'loss': 0.0716, 'grad_norm': 20.810213088989258, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.0690998062491417, 'loss_2': 0.002532958984375, 'loss_3': -15.910726547241211, 'loss_4': 3.58013916015625, 'epoch': 3.02}
{'loss': 0.051, 'grad_norm': 20.05417823791504, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.045846037566661835, 'loss_2': 0.0051116943359375, 'loss_3': -16.08545684814453, 'loss_4': 3.4951529502868652, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 15:30:48,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:48,420 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:26<1:20:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:55,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018032275140285492, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013765595853328705, 'eval_loss_2': 0.004266679286956787, 'eval_loss_3': -18.35045051574707, 'eval_loss_4': 3.1437339782714844, 'epoch': 3.02}
{'loss': 0.0513, 'grad_norm': 17.732315063476562, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.049180250614881516, 'loss_2': 0.00215911865234375, 'loss_3': -15.782583236694336, 'loss_4': 3.1960396766662598, 'epoch': 3.03}
{'loss': 0.0384, 'grad_norm': 14.5827054977417, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.03696582093834877, 'loss_2': 0.00141143798828125, 'loss_3': -15.838071823120117, 'loss_4': 3.474386692047119, 'epoch': 3.03}
{'loss': 0.0336, 'grad_norm': 10.787383079528809, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.026543721556663513, 'loss_2': 0.007045745849609375, 'loss_3': -15.840544700622559, 'loss_4': 3.332073450088501, 'epoch': 3.04}
{'loss': 0.0536, 'grad_norm': 16.01581573486328, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.052161261439323425, 'loss_2': 0.0013990402221679688, 'loss_3': -16.000261306762695, 'loss_4': 3.091702938079834, 'epoch': 3.05}
{'loss': 0.0433, 'grad_norm': 8.034936904907227, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.027706829831004143, 'loss_2': 0.015625, 'loss_3': -15.793243408203125, 'loss_4': 2.928556442260742, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 15:30:55,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:55,784 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:33<1:20:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:03,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022768743336200714, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0153852179646492, 'eval_loss_2': 0.007383525371551514, 'eval_loss_3': -18.324390411376953, 'eval_loss_4': 2.553389549255371, 'epoch': 3.05}
{'loss': 0.11, 'grad_norm': 28.405027389526367, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.10532116889953613, 'loss_2': 0.00470733642578125, 'loss_3': -15.723681449890137, 'loss_4': 3.010615825653076, 'epoch': 3.06}
{'loss': 0.0318, 'grad_norm': 5.855207920074463, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.018023207783699036, 'loss_2': 0.01375579833984375, 'loss_3': -15.73556137084961, 'loss_4': 2.8419008255004883, 'epoch': 3.06}
{'loss': 0.1223, 'grad_norm': 20.903196334838867, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.11553171277046204, 'loss_2': 0.006793975830078125, 'loss_3': -15.812483787536621, 'loss_4': 2.6501502990722656, 'epoch': 3.07}
{'loss': 0.026, 'grad_norm': 9.05312728881836, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.025584489107131958, 'loss_2': 0.00037407875061035156, 'loss_3': -16.000656127929688, 'loss_4': 2.2692742347717285, 'epoch': 3.08}
{'loss': 0.0399, 'grad_norm': 9.887423515319824, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.034699637442827225, 'loss_2': 0.005207061767578125, 'loss_3': -16.012264251708984, 'loss_4': 2.7328288555145264, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 15:31:03,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:03,157 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:41<1:20:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:10,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0205897968262434, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.709, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01215419266372919, 'eval_loss_2': 0.008435606956481934, 'eval_loss_3': -18.25322914123535, 'eval_loss_4': 2.0726327896118164, 'epoch': 3.08}
{'loss': 0.1042, 'grad_norm': 20.43124008178711, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.09275583177804947, 'loss_2': 0.0113983154296875, 'loss_3': -15.75455093383789, 'loss_4': 2.5069987773895264, 'epoch': 3.09}
{'loss': 0.0297, 'grad_norm': 7.468704700469971, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.019336504861712456, 'loss_2': 0.0103912353515625, 'loss_3': -15.843908309936523, 'loss_4': 2.0744380950927734, 'epoch': 3.09}
{'loss': 0.0359, 'grad_norm': 12.297599792480469, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.029674865305423737, 'loss_2': 0.006195068359375, 'loss_3': -15.792984008789062, 'loss_4': 2.380904197692871, 'epoch': 3.1}
{'loss': 0.0276, 'grad_norm': 7.7427520751953125, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.018744539469480515, 'loss_2': 0.008819580078125, 'loss_3': -15.748291015625, 'loss_4': 1.9836843013763428, 'epoch': 3.1}
{'loss': 0.0459, 'grad_norm': 21.507604598999023, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.041866183280944824, 'loss_2': 0.00406646728515625, 'loss_3': -15.687585830688477, 'loss_4': 2.102691650390625, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 15:31:10,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:10,527 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:48<1:20:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:17,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017740126699209213, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.003, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012182358652353287, 'eval_loss_2': 0.0055577680468559265, 'eval_loss_3': -18.18740463256836, 'eval_loss_4': 2.161377191543579, 'epoch': 3.11}
{'loss': 0.0833, 'grad_norm': 17.124330520629883, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.07160788774490356, 'loss_2': 0.01165008544921875, 'loss_3': -15.81356143951416, 'loss_4': 2.9728918075561523, 'epoch': 3.12}
{'loss': 0.0229, 'grad_norm': 6.884143352508545, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.017635008320212364, 'loss_2': 0.0052642822265625, 'loss_3': -15.771775245666504, 'loss_4': 2.0018343925476074, 'epoch': 3.12}
{'loss': 0.0343, 'grad_norm': 13.240494728088379, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.032547153532505035, 'loss_2': 0.0017547607421875, 'loss_3': -15.619543075561523, 'loss_4': 2.487010955810547, 'epoch': 3.13}
{'loss': 0.0328, 'grad_norm': 9.808773040771484, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.028370726853609085, 'loss_2': 0.00441741943359375, 'loss_3': -15.8626127243042, 'loss_4': 1.6857950687408447, 'epoch': 3.13}
{'loss': 0.0277, 'grad_norm': 7.6491618156433105, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.02370542287826538, 'loss_2': 0.00402069091796875, 'loss_3': -15.669576644897461, 'loss_4': 1.9449959993362427, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 15:31:17,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:17,905 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:56<1:20:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:25,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01698090136051178, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012411610223352909, 'eval_loss_2': 0.004569292068481445, 'eval_loss_3': -18.162534713745117, 'eval_loss_4': 1.8489100933074951, 'epoch': 3.14}
{'loss': 0.0357, 'grad_norm': 10.275060653686523, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.025283414870500565, 'loss_2': 0.0103759765625, 'loss_3': -15.822900772094727, 'loss_4': 1.546696424484253, 'epoch': 3.15}
{'loss': 0.0421, 'grad_norm': 19.649465560913086, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.03788081929087639, 'loss_2': 0.00418853759765625, 'loss_3': -15.725836753845215, 'loss_4': 1.6904194355010986, 'epoch': 3.15}
{'loss': 0.028, 'grad_norm': 8.925044059753418, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.024402035400271416, 'loss_2': 0.003643035888671875, 'loss_3': -15.691099166870117, 'loss_4': 1.3501259088516235, 'epoch': 3.16}
{'loss': 0.0274, 'grad_norm': 9.167610168457031, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.02199702337384224, 'loss_2': 0.0054473876953125, 'loss_3': -15.65174674987793, 'loss_4': 1.692676305770874, 'epoch': 3.16}
{'loss': 0.0268, 'grad_norm': 8.752166748046875, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.025245416909456253, 'loss_2': 0.0015869140625, 'loss_3': -15.7935209274292, 'loss_4': 1.6983606815338135, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 15:31:25,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:25,264 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [14:03<1:20:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:32,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016204070299863815, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.149, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012189572677016258, 'eval_loss_2': 0.004014499485492706, 'eval_loss_3': -18.146923065185547, 'eval_loss_4': 1.4140493869781494, 'epoch': 3.17}
{'loss': 0.0214, 'grad_norm': 6.6599531173706055, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.020866060629487038, 'loss_2': 0.0004963874816894531, 'loss_3': -15.725384712219238, 'loss_4': 1.4377129077911377, 'epoch': 3.17}
{'loss': 0.0219, 'grad_norm': 9.737688064575195, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.019268468022346497, 'loss_2': 0.00260162353515625, 'loss_3': -15.760635375976562, 'loss_4': 1.258256435394287, 'epoch': 3.18}
{'loss': 0.0358, 'grad_norm': 8.632756233215332, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.02401617169380188, 'loss_2': 0.01177215576171875, 'loss_3': -15.625703811645508, 'loss_4': 1.4978781938552856, 'epoch': 3.19}
{'loss': 0.0481, 'grad_norm': 18.12470054626465, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.03889893740415573, 'loss_2': 0.009246826171875, 'loss_3': -15.899417877197266, 'loss_4': 1.9582840204238892, 'epoch': 3.19}
{'loss': 0.0322, 'grad_norm': 7.07212495803833, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.01805296167731285, 'loss_2': 0.01412200927734375, 'loss_3': -15.908777236938477, 'loss_4': 1.4325511455535889, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 15:31:32,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:32,636 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:10<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:40,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018717609345912933, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013101851567626, 'eval_loss_2': 0.005615759640932083, 'eval_loss_3': -18.10769271850586, 'eval_loss_4': 1.6049189567565918, 'epoch': 3.2}
{'loss': 0.0165, 'grad_norm': 6.045194625854492, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.01240020152181387, 'loss_2': 0.00406646728515625, 'loss_3': -15.754884719848633, 'loss_4': 2.022801160812378, 'epoch': 3.2}
{'loss': 0.0131, 'grad_norm': 6.184150218963623, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.012057122774422169, 'loss_2': 0.001087188720703125, 'loss_3': -15.817682266235352, 'loss_4': 1.2295562028884888, 'epoch': 3.21}
{'loss': 0.0286, 'grad_norm': 9.21848201751709, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.022676903754472733, 'loss_2': 0.00592041015625, 'loss_3': -15.758143424987793, 'loss_4': 1.267682671546936, 'epoch': 3.22}
{'loss': 0.0753, 'grad_norm': 16.92340660095215, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.0690627470612526, 'loss_2': 0.00621795654296875, 'loss_3': -15.883491516113281, 'loss_4': 1.308413028717041, 'epoch': 3.22}
{'loss': 0.0232, 'grad_norm': 8.218634605407715, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.019726738333702087, 'loss_2': 0.0034465789794921875, 'loss_3': -15.827439308166504, 'loss_4': 1.6547402143478394, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 15:31:40,001 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:40,001 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:18<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:47,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02373577281832695, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.048, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01407385803759098, 'eval_loss_2': 0.00966191291809082, 'eval_loss_3': -18.08834457397461, 'eval_loss_4': 1.5435919761657715, 'epoch': 3.23}
{'loss': 0.0732, 'grad_norm': 18.37991714477539, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.05843081325292587, 'loss_2': 0.0147705078125, 'loss_3': -15.735583305358887, 'loss_4': 1.915677547454834, 'epoch': 3.23}
{'loss': 0.0296, 'grad_norm': 9.926361083984375, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.019612308591604233, 'loss_2': 0.009979248046875, 'loss_3': -15.676499366760254, 'loss_4': 1.6649580001831055, 'epoch': 3.24}
{'loss': 0.0408, 'grad_norm': 14.232352256774902, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.035527098923921585, 'loss_2': 0.0052642822265625, 'loss_3': -15.759598731994629, 'loss_4': 1.7540953159332275, 'epoch': 3.24}
{'loss': 0.031, 'grad_norm': 9.26378059387207, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.022663256153464317, 'loss_2': 0.00832366943359375, 'loss_3': -15.840963363647461, 'loss_4': 1.6225992441177368, 'epoch': 3.25}
{'loss': 0.019, 'grad_norm': 7.260005474090576, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.014635334722697735, 'loss_2': 0.00440216064453125, 'loss_3': -15.602916717529297, 'loss_4': 1.4592909812927246, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 15:31:47,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:47,375 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:25<1:19:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:54,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01755833812057972, 'eval_runtime': 3.819, 'eval_samples_per_second': 268.131, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.013165474869310856, 'eval_loss_2': 0.004392862319946289, 'eval_loss_3': -18.118444442749023, 'eval_loss_4': 1.263763427734375, 'epoch': 3.26}
{'loss': 0.0282, 'grad_norm': 7.204528331756592, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.01764592155814171, 'loss_2': 0.010528564453125, 'loss_3': -15.850727081298828, 'loss_4': 1.2220128774642944, 'epoch': 3.26}
{'loss': 0.0477, 'grad_norm': 15.648027420043945, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.04186636954545975, 'loss_2': 0.00579071044921875, 'loss_3': -15.718191146850586, 'loss_4': 1.2000420093536377, 'epoch': 3.27}
{'loss': 0.0279, 'grad_norm': 6.847123146057129, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.015041971579194069, 'loss_2': 0.0128326416015625, 'loss_3': -15.959528923034668, 'loss_4': 1.5840785503387451, 'epoch': 3.27}
{'loss': 0.0382, 'grad_norm': 8.606224060058594, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.024494389072060585, 'loss_2': 0.01366424560546875, 'loss_3': -15.832742691040039, 'loss_4': 0.9795161485671997, 'epoch': 3.28}
{'loss': 0.0262, 'grad_norm': 10.079858779907227, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.024519730359315872, 'loss_2': 0.0016565322875976562, 'loss_3': -15.58041763305664, 'loss_4': 1.6432403326034546, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 15:31:54,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:54,755 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:32<1:19:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:02,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021649133414030075, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.309, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013963949866592884, 'eval_loss_2': 0.007685184478759766, 'eval_loss_3': -18.17125129699707, 'eval_loss_4': 1.2558505535125732, 'epoch': 3.28}
{'loss': 0.0334, 'grad_norm': 15.252555847167969, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.03162554278969765, 'loss_2': 0.001758575439453125, 'loss_3': -15.586113929748535, 'loss_4': 1.5180583000183105, 'epoch': 3.29}
{'loss': 0.1358, 'grad_norm': 36.759456634521484, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.12876541912555695, 'loss_2': 0.00704193115234375, 'loss_3': -15.866939544677734, 'loss_4': 1.7347283363342285, 'epoch': 3.3}
{'loss': 0.0273, 'grad_norm': 7.705878257751465, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.01802108809351921, 'loss_2': 0.0093231201171875, 'loss_3': -15.821456909179688, 'loss_4': 1.8175649642944336, 'epoch': 3.3}
{'loss': 0.0471, 'grad_norm': 10.911126136779785, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.04492955654859543, 'loss_2': 0.00218963623046875, 'loss_3': -15.79141902923584, 'loss_4': 1.5407288074493408, 'epoch': 3.31}
{'loss': 0.0327, 'grad_norm': 13.026985168457031, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.03271743655204773, 'loss_2': 3.337860107421875e-06, 'loss_3': -15.983570098876953, 'loss_4': 1.8457527160644531, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 15:32:02,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:02,115 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:40<1:19:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:09,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019565122202038765, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012889225967228413, 'eval_loss_2': 0.006675899028778076, 'eval_loss_3': -18.199481964111328, 'eval_loss_4': 1.5629547834396362, 'epoch': 3.31}
{'loss': 0.0638, 'grad_norm': 21.78536033630371, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.062341172248125076, 'loss_2': 0.0014867782592773438, 'loss_3': -15.762125015258789, 'loss_4': 1.9707927703857422, 'epoch': 3.32}
{'loss': 0.0349, 'grad_norm': 11.606244087219238, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.023642294108867645, 'loss_2': 0.01126861572265625, 'loss_3': -15.845258712768555, 'loss_4': 1.7971434593200684, 'epoch': 3.33}
{'loss': 0.0327, 'grad_norm': 8.883553504943848, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.024738630279898643, 'loss_2': 0.00791168212890625, 'loss_3': -16.02495002746582, 'loss_4': 1.8218398094177246, 'epoch': 3.33}
{'loss': 0.1495, 'grad_norm': 30.989288330078125, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.1458931416273117, 'loss_2': 0.0036468505859375, 'loss_3': -15.702423095703125, 'loss_4': 1.544403076171875, 'epoch': 3.34}
{'loss': 0.1213, 'grad_norm': 13.541240692138672, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.11056498438119888, 'loss_2': 0.01068878173828125, 'loss_3': -15.79336929321289, 'loss_4': 1.8730666637420654, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 15:32:09,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:09,487 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:47<1:19:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:16,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020602229982614517, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.122, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01488998718559742, 'eval_loss_2': 0.005712240934371948, 'eval_loss_3': -18.205183029174805, 'eval_loss_4': 1.4390734434127808, 'epoch': 3.34}
{'loss': 0.0478, 'grad_norm': 20.212074279785156, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.04351647570729256, 'loss_2': 0.00431060791015625, 'loss_3': -15.867549896240234, 'loss_4': 1.7578070163726807, 'epoch': 3.35}
{'loss': 0.0497, 'grad_norm': 14.739461898803711, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.0496586412191391, 'loss_2': 8.83340835571289e-05, 'loss_3': -15.582642555236816, 'loss_4': 1.5923974514007568, 'epoch': 3.35}
{'loss': 0.0204, 'grad_norm': 7.423001289367676, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.020064232870936394, 'loss_2': 0.00034999847412109375, 'loss_3': -15.864184379577637, 'loss_4': 1.5558242797851562, 'epoch': 3.36}
{'loss': 0.0659, 'grad_norm': 19.34362030029297, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.055242475122213364, 'loss_2': 0.010650634765625, 'loss_3': -15.764776229858398, 'loss_4': 1.3104140758514404, 'epoch': 3.37}
{'loss': 0.0736, 'grad_norm': 24.016830444335938, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.06795558333396912, 'loss_2': 0.00560760498046875, 'loss_3': -15.51225757598877, 'loss_4': 1.6785223484039307, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 15:32:16,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:16,855 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:55<1:19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:24,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023446492850780487, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.365, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012653285637497902, 'eval_loss_2': 0.010793209075927734, 'eval_loss_3': -18.20173454284668, 'eval_loss_4': 1.0459556579589844, 'epoch': 3.37}
{'loss': 0.0456, 'grad_norm': 14.018678665161133, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.03377249836921692, 'loss_2': 0.01186370849609375, 'loss_3': -15.964463233947754, 'loss_4': 1.1894810199737549, 'epoch': 3.38}
{'loss': 0.0845, 'grad_norm': 19.325504302978516, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.07351081073284149, 'loss_2': 0.011016845703125, 'loss_3': -15.811832427978516, 'loss_4': 1.401219129562378, 'epoch': 3.38}
{'loss': 0.0556, 'grad_norm': 16.57040023803711, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.03706832975149155, 'loss_2': 0.0185546875, 'loss_3': -15.66972541809082, 'loss_4': 0.7192584872245789, 'epoch': 3.39}
{'loss': 0.0346, 'grad_norm': 9.631685256958008, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.02815372869372368, 'loss_2': 0.006439208984375, 'loss_3': -15.907740592956543, 'loss_4': 0.8122108578681946, 'epoch': 3.4}
{'loss': 0.0366, 'grad_norm': 9.006765365600586, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.01988350972533226, 'loss_2': 0.0166778564453125, 'loss_3': -15.807940483093262, 'loss_4': 0.757379949092865, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 15:32:24,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:24,211 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [15:02<1:19:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:31,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020791618153452873, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.569, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012209025211632252, 'eval_loss_2': 0.008582592010498047, 'eval_loss_3': -18.16889762878418, 'eval_loss_4': 0.47920945286750793, 'epoch': 3.4}
{'loss': 0.0284, 'grad_norm': 10.395772933959961, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.021891310811042786, 'loss_2': 0.00652313232421875, 'loss_3': -15.784320831298828, 'loss_4': 0.3178093731403351, 'epoch': 3.41}
{'loss': 0.0417, 'grad_norm': 12.565390586853027, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.04015367478132248, 'loss_2': 0.00153350830078125, 'loss_3': -15.701549530029297, 'loss_4': 1.125927209854126, 'epoch': 3.41}
{'loss': 0.0332, 'grad_norm': 9.235260963439941, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.026164107024669647, 'loss_2': 0.00701141357421875, 'loss_3': -15.870084762573242, 'loss_4': 0.03278513252735138, 'epoch': 3.42}
{'loss': 0.0732, 'grad_norm': 23.255205154418945, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.07306303828954697, 'loss_2': 0.00010073184967041016, 'loss_3': -15.744710922241211, 'loss_4': 0.8647754788398743, 'epoch': 3.42}
{'loss': 0.0356, 'grad_norm': 9.008787155151367, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.032719001173973083, 'loss_2': 0.00289154052734375, 'loss_3': -15.892132759094238, 'loss_4': 0.11434755474328995, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 15:32:31,582 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:31,582 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:09<1:19:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:38,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018829721957445145, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.658, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010831492953002453, 'eval_loss_2': 0.007998228073120117, 'eval_loss_3': -18.13628387451172, 'eval_loss_4': 0.09865188598632812, 'epoch': 3.43}
{'loss': 0.0702, 'grad_norm': 22.94144058227539, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.06602414697408676, 'loss_2': 0.004180908203125, 'loss_3': -15.948843955993652, 'loss_4': 0.11112943291664124, 'epoch': 3.44}
{'loss': 0.0326, 'grad_norm': 10.982443809509277, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.032389722764492035, 'loss_2': 0.00019919872283935547, 'loss_3': -15.779439926147461, 'loss_4': -0.3830627202987671, 'epoch': 3.44}
{'loss': 0.031, 'grad_norm': 8.522054672241211, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.016385721042752266, 'loss_2': 0.01457977294921875, 'loss_3': -15.819470405578613, 'loss_4': 0.14062339067459106, 'epoch': 3.45}
{'loss': 0.0123, 'grad_norm': 5.425512790679932, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.011255253106355667, 'loss_2': 0.0010051727294921875, 'loss_3': -15.672979354858398, 'loss_4': -0.2586574852466583, 'epoch': 3.45}
{'loss': 0.0175, 'grad_norm': 7.860479831695557, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.015560414642095566, 'loss_2': 0.00189208984375, 'loss_3': -15.70640754699707, 'loss_4': 0.20506253838539124, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 15:32:38,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:38,933 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:13<1:19:05,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:32:42,735 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-595
[INFO|configuration_utils.py:420] 2025-01-21 15:32:42,737 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-595/config.json                                                                             
{'eval_loss': 0.013334541581571102, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.385, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010560808703303337, 'eval_loss_2': 0.0027737319469451904, 'eval_loss_3': -18.16046905517578, 'eval_loss_4': -0.004531970247626305, 'epoch': 3.46}
[INFO|modeling_utils.py:2988] 2025-01-21 15:32:43,227 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-595/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:32:43,229 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-595/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:32:43,229 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-595/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:32:44,136 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-415] due to args.save_total_limit
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:18<1:27:07,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:32:47,775 >>
{'loss': 0.0363, 'grad_norm': 16.21180534362793, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.03423337638378143, 'loss_2': 0.002109527587890625, 'loss_3': -15.905169486999512, 'loss_4': -0.40548187494277954, 'epoch': 3.47}
{'loss': 0.0187, 'grad_norm': 7.066089630126953, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.017038345336914062, 'loss_2': 0.0016231536865234375, 'loss_3': -15.832403182983398, 'loss_4': 0.43218672275543213, 'epoch': 3.47}
{'loss': 0.0315, 'grad_norm': 8.561044692993164, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.025932203978300095, 'loss_2': 0.005603790283203125, 'loss_3': -15.821174621582031, 'loss_4': 0.4025377631187439, 'epoch': 3.48}
{'loss': 0.0216, 'grad_norm': 7.0735955238342285, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.01316403690725565, 'loss_2': 0.008392333984375, 'loss_3': -16.025115966796875, 'loss_4': -0.19906383752822876, 'epoch': 3.48}
{'loss': 0.013, 'grad_norm': 5.8751044273376465, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.012255764566361904, 'loss_2': 0.0007486343383789062, 'loss_3': -15.935714721679688, 'loss_4': -0.28809425234794617, 'epoch': 3.49}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:32:47,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:47,775 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:25<1:20:21,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:32:55,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014013849198818207, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010319703258574009, 'eval_loss_2': 0.0036941468715667725, 'eval_loss_3': -18.19263458251953, 'eval_loss_4': -0.07273349165916443, 'epoch': 3.49}
{'loss': 0.0196, 'grad_norm': 8.205931663513184, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.017927909269928932, 'loss_2': 0.001682281494140625, 'loss_3': -15.902634620666504, 'loss_4': -0.06682606041431427, 'epoch': 3.49}
{'loss': 0.0267, 'grad_norm': 6.106747150421143, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.012664723210036755, 'loss_2': 0.0140380859375, 'loss_3': -15.878438949584961, 'loss_4': 0.3425597846508026, 'epoch': 3.5}
{'loss': 0.037, 'grad_norm': 11.970608711242676, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.03024953417479992, 'loss_2': 0.006771087646484375, 'loss_3': -16.014781951904297, 'loss_4': 0.10596363246440887, 'epoch': 3.51}
{'loss': 0.0198, 'grad_norm': 7.236846923828125, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.014186198823153973, 'loss_2': 0.0056304931640625, 'loss_3': -15.753131866455078, 'loss_4': 0.00685572624206543, 'epoch': 3.51}
{'loss': 0.0258, 'grad_norm': 6.227881908416748, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.01696750707924366, 'loss_2': 0.00885009765625, 'loss_3': -15.90021800994873, 'loss_4': 0.3498409390449524, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 15:32:55,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:55,132 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:33<1:19:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:02,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016114648431539536, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011597911827266216, 'eval_loss_2': 0.004516735672950745, 'eval_loss_3': -18.18366050720215, 'eval_loss_4': -0.0105418860912323, 'epoch': 3.52}
{'loss': 0.0299, 'grad_norm': 10.037691116333008, 'learning_rate': 2.65e-05, 'loss_1': 0.024748966097831726, 'loss_2': 0.00510406494140625, 'loss_3': -16.01129722595215, 'loss_4': -0.04547932744026184, 'epoch': 3.52}
{'loss': 0.0332, 'grad_norm': 9.666394233703613, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.029265956953167915, 'loss_2': 0.00397491455078125, 'loss_3': -15.80260181427002, 'loss_4': 0.09808075428009033, 'epoch': 3.53}
{'loss': 0.0164, 'grad_norm': 7.457293510437012, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.016263119876384735, 'loss_2': 0.00015687942504882812, 'loss_3': -15.924622535705566, 'loss_4': -0.31800609827041626, 'epoch': 3.53}
{'loss': 0.0204, 'grad_norm': 6.931007385253906, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.019807955250144005, 'loss_2': 0.0006208419799804688, 'loss_3': -15.918233871459961, 'loss_4': 0.09457188844680786, 'epoch': 3.54}
{'loss': 0.0869, 'grad_norm': 21.50324249267578, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.0848100557923317, 'loss_2': 0.0020503997802734375, 'loss_3': -15.708629608154297, 'loss_4': -0.36232712864875793, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 15:33:02,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:02,486 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:40<1:18:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:09,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01719348505139351, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013041157275438309, 'eval_loss_2': 0.0041523277759552, 'eval_loss_3': -18.169910430908203, 'eval_loss_4': -0.24954774975776672, 'epoch': 3.55}
{'loss': 0.0273, 'grad_norm': 10.665848731994629, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.023651225492358208, 'loss_2': 0.0036869049072265625, 'loss_3': -15.943215370178223, 'loss_4': 0.07863357663154602, 'epoch': 3.55}
{'loss': 0.0701, 'grad_norm': 23.650548934936523, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.05968151241540909, 'loss_2': 0.01044464111328125, 'loss_3': -15.786916732788086, 'loss_4': 0.014369383454322815, 'epoch': 3.56}
{'loss': 0.0271, 'grad_norm': 6.537461757659912, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.014828241430222988, 'loss_2': 0.01226806640625, 'loss_3': -15.927746772766113, 'loss_4': -0.24183519184589386, 'epoch': 3.56}
{'loss': 0.0241, 'grad_norm': 9.413347244262695, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.020527642220258713, 'loss_2': 0.0035858154296875, 'loss_3': -15.790021896362305, 'loss_4': -0.3513985276222229, 'epoch': 3.57}
{'loss': 0.02, 'grad_norm': 8.37440299987793, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.018243061378598213, 'loss_2': 0.0017766952514648438, 'loss_3': -15.833061218261719, 'loss_4': -0.23569491505622864, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 15:33:09,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:09,846 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:48<1:18:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:17,208 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017213542014360428, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013383759185671806, 'eval_loss_2': 0.0038297846913337708, 'eval_loss_3': -18.127187728881836, 'eval_loss_4': -0.46715664863586426, 'epoch': 3.58}
{'loss': 0.0323, 'grad_norm': 10.459127426147461, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.027029307559132576, 'loss_2': 0.0052490234375, 'loss_3': -15.974190711975098, 'loss_4': -0.6901065707206726, 'epoch': 3.58}
{'loss': 0.0172, 'grad_norm': 5.649970531463623, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.014006500132381916, 'loss_2': 0.00322723388671875, 'loss_3': -15.988621711730957, 'loss_4': -0.6510027050971985, 'epoch': 3.59}
{'loss': 0.035, 'grad_norm': 13.08532428741455, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.026021871715784073, 'loss_2': 0.00899505615234375, 'loss_3': -15.839319229125977, 'loss_4': -0.3745298981666565, 'epoch': 3.59}
{'loss': 0.1047, 'grad_norm': 20.058176040649414, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.09695769846439362, 'loss_2': 0.00771331787109375, 'loss_3': -15.891136169433594, 'loss_4': -0.6382280588150024, 'epoch': 3.6}
{'loss': 0.0193, 'grad_norm': 6.276993274688721, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.013505940325558186, 'loss_2': 0.0057830810546875, 'loss_3': -15.976604461669922, 'loss_4': -0.736703634262085, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 15:33:17,208 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:17,208 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:55<1:19:37,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:33:24,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016259193420410156, 'eval_runtime': 3.9858, 'eval_samples_per_second': 256.915, 'eval_steps_per_second': 4.014, 'eval_loss_1': 0.011072514578700066, 'eval_loss_2': 0.005186676979064941, 'eval_loss_3': -18.1532039642334, 'eval_loss_4': -0.4774237275123596, 'epoch': 3.6}
{'loss': 0.0203, 'grad_norm': 6.532464027404785, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.01479890663176775, 'loss_2': 0.005527496337890625, 'loss_3': -15.826141357421875, 'loss_4': -0.44152677059173584, 'epoch': 3.61}
{'loss': 0.0762, 'grad_norm': 16.38350486755371, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.07618612051010132, 'loss_2': 4.5180320739746094e-05, 'loss_3': -15.929403305053711, 'loss_4': -0.22930766642093658, 'epoch': 3.62}
{'loss': 0.0171, 'grad_norm': 6.190454483032227, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.013838349841535091, 'loss_2': 0.0032367706298828125, 'loss_3': -15.617006301879883, 'loss_4': -0.4725262224674225, 'epoch': 3.62}
{'loss': 0.0585, 'grad_norm': 21.926786422729492, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.05207236111164093, 'loss_2': 0.00646209716796875, 'loss_3': -15.816949844360352, 'loss_4': -0.36635076999664307, 'epoch': 3.63}
{'loss': 0.0311, 'grad_norm': 11.188179016113281, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.02405559830367565, 'loss_2': 0.00707244873046875, 'loss_3': -15.833220481872559, 'loss_4': -3.3080577850341797e-06, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 15:33:24,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:24,748 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [16:02<1:18:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:32,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03005082905292511, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.019828278571367264, 'eval_loss_2': 0.010222554206848145, 'eval_loss_3': -18.076269149780273, 'eval_loss_4': -0.022002289071679115, 'epoch': 3.63}
{'loss': 0.0372, 'grad_norm': 7.626513957977295, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.020492441952228546, 'loss_2': 0.0167083740234375, 'loss_3': -15.689210891723633, 'loss_4': -0.1402386575937271, 'epoch': 3.64}
{'loss': 0.066, 'grad_norm': 27.674747467041016, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.053289465606212616, 'loss_2': 0.0126953125, 'loss_3': -15.613533020019531, 'loss_4': -0.033285535871982574, 'epoch': 3.65}
{'loss': 0.0546, 'grad_norm': 18.64698028564453, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.046535320580005646, 'loss_2': 0.00801849365234375, 'loss_3': -15.932541847229004, 'loss_4': 0.2105686217546463, 'epoch': 3.65}
{'loss': 0.0458, 'grad_norm': 15.252914428710938, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.027561737224459648, 'loss_2': 0.0181884765625, 'loss_3': -15.688557624816895, 'loss_4': 0.08749567717313766, 'epoch': 3.66}
{'loss': 0.0545, 'grad_norm': 26.299440383911133, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.049400877207517624, 'loss_2': 0.00505828857421875, 'loss_3': -15.67776870727539, 'loss_4': 0.6857866048812866, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 15:33:32,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:32,106 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [16:10<1:18:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:39,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022244295105338097, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.431, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0141459871083498, 'eval_loss_2': 0.008098307996988297, 'eval_loss_3': -18.139625549316406, 'eval_loss_4': 0.2108072191476822, 'epoch': 3.66}
{'loss': 0.0234, 'grad_norm': 6.329549312591553, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.011763637885451317, 'loss_2': 0.0116424560546875, 'loss_3': -15.666078567504883, 'loss_4': 0.6245718002319336, 'epoch': 3.67}
{'loss': 0.0269, 'grad_norm': 8.083415985107422, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.02285783924162388, 'loss_2': 0.0040435791015625, 'loss_3': -15.788856506347656, 'loss_4': 0.36148953437805176, 'epoch': 3.67}
{'loss': 0.0355, 'grad_norm': 14.764052391052246, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.03041667863726616, 'loss_2': 0.00507354736328125, 'loss_3': -15.646080017089844, 'loss_4': 0.6051421761512756, 'epoch': 3.68}
{'loss': 0.0287, 'grad_norm': 10.588494300842285, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.02596031129360199, 'loss_2': 0.00270843505859375, 'loss_3': -15.752737045288086, 'loss_4': -0.19699588418006897, 'epoch': 3.69}
{'loss': 0.019, 'grad_norm': 6.445247173309326, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.01701086014509201, 'loss_2': 0.001972198486328125, 'loss_3': -15.870107650756836, 'loss_4': 0.5699810981750488, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 15:33:39,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:39,467 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:17<1:18:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:46,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014600580558180809, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009048408828675747, 'eval_loss_2': 0.005552172660827637, 'eval_loss_3': -18.263057708740234, 'eval_loss_4': 0.27393433451652527, 'epoch': 3.69}
{'loss': 0.0166, 'grad_norm': 9.55595588684082, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.016543317586183548, 'loss_2': 6.282329559326172e-05, 'loss_3': -15.873512268066406, 'loss_4': 1.07187819480896, 'epoch': 3.7}
{'loss': 0.052, 'grad_norm': 18.340511322021484, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.03820817172527313, 'loss_2': 0.0138092041015625, 'loss_3': -15.967529296875, 'loss_4': 1.2477678060531616, 'epoch': 3.7}
{'loss': 0.1406, 'grad_norm': 21.518508911132812, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.1330222487449646, 'loss_2': 0.0076141357421875, 'loss_3': -15.63795280456543, 'loss_4': 0.43212825059890747, 'epoch': 3.71}
{'loss': 0.0499, 'grad_norm': 20.006473541259766, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.04925806447863579, 'loss_2': 0.0006222724914550781, 'loss_3': -15.926986694335938, 'loss_4': 0.4784473776817322, 'epoch': 3.72}
{'loss': 0.0347, 'grad_norm': 11.115434646606445, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.031649135053157806, 'loss_2': 0.00305938720703125, 'loss_3': -15.873823165893555, 'loss_4': 1.0123587846755981, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 15:33:46,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:46,826 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:25<1:18:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:54,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0182143934071064, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.55, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009717869572341442, 'eval_loss_2': 0.008496522903442383, 'eval_loss_3': -18.348512649536133, 'eval_loss_4': 0.09418947249650955, 'epoch': 3.72}
{'loss': 0.0282, 'grad_norm': 11.912936210632324, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.026193920522928238, 'loss_2': 0.001995086669921875, 'loss_3': -16.06435775756836, 'loss_4': 0.15571315586566925, 'epoch': 3.73}
{'loss': 0.0184, 'grad_norm': 5.554882049560547, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.010689878836274147, 'loss_2': 0.0077056884765625, 'loss_3': -16.028980255126953, 'loss_4': 0.619094967842102, 'epoch': 3.73}
{'loss': 0.0747, 'grad_norm': 24.603252410888672, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.07098928838968277, 'loss_2': 0.003753662109375, 'loss_3': -15.837960243225098, 'loss_4': 0.22102852165699005, 'epoch': 3.74}
{'loss': 0.028, 'grad_norm': 22.485271453857422, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.025979196652770042, 'loss_2': 0.002063751220703125, 'loss_3': -16.127241134643555, 'loss_4': -0.042924001812934875, 'epoch': 3.74}
{'loss': 0.0235, 'grad_norm': 8.114191055297852, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.015292137861251831, 'loss_2': 0.00820159912109375, 'loss_3': -15.943143844604492, 'loss_4': 0.057372480630874634, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 15:33:54,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:54,203 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:32<1:18:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:01,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013513946905732155, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.323, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008640104904770851, 'eval_loss_2': 0.004873842000961304, 'eval_loss_3': -18.327192306518555, 'eval_loss_4': -0.058790676295757294, 'epoch': 3.75}
{'loss': 0.019, 'grad_norm': 6.42586612701416, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.017483018338680267, 'loss_2': 0.0015382766723632812, 'loss_3': -15.933895111083984, 'loss_4': 0.0795648992061615, 'epoch': 3.76}
{'loss': 0.0316, 'grad_norm': 10.376157760620117, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.02689513750374317, 'loss_2': 0.00469207763671875, 'loss_3': -16.18272590637207, 'loss_4': 0.13038012385368347, 'epoch': 3.76}
{'loss': 0.0501, 'grad_norm': 22.123842239379883, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.045473676174879074, 'loss_2': 0.00464630126953125, 'loss_3': -16.093597412109375, 'loss_4': 0.10584167391061783, 'epoch': 3.77}
{'loss': 0.0306, 'grad_norm': 18.276811599731445, 'learning_rate': 2.625e-05, 'loss_1': 0.029179247096180916, 'loss_2': 0.001468658447265625, 'loss_3': -15.943421363830566, 'loss_4': 0.2970143258571625, 'epoch': 3.77}
{'loss': 0.0417, 'grad_norm': 15.257340431213379, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.03547585755586624, 'loss_2': 0.006256103515625, 'loss_3': -16.069580078125, 'loss_4': 0.21417391300201416, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 15:34:01,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:01,560 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:36<1:18:10,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:34:05,364 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-650
[INFO|configuration_utils.py:420] 2025-01-21 15:34:05,365 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-650/config.json                                                                             
{'eval_loss': 0.012165624648332596, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008819865994155407, 'eval_loss_2': 0.0033457577228546143, 'eval_loss_3': -18.27115249633789, 'eval_loss_4': -0.053904540836811066, 'epoch': 3.78}
[INFO|modeling_utils.py:2988] 2025-01-21 15:34:05,848 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-650/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:34:05,849 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-650/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:34:05,850 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-650/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:34:06,768 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-595] due to args.save_total_limit
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:41<1:25:56,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:34:10,393 >>
{'loss': 0.0463, 'grad_norm': 16.072235107421875, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.04604538530111313, 'loss_2': 0.00023126602172851562, 'loss_3': -15.982255935668945, 'loss_4': -0.2281647026538849, 'epoch': 3.78}
{'loss': 0.0281, 'grad_norm': 11.738225936889648, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.027235079556703568, 'loss_2': 0.000885009765625, 'loss_3': -16.083663940429688, 'loss_4': -0.2016044408082962, 'epoch': 3.79}
{'loss': 0.0197, 'grad_norm': 7.999814987182617, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.018204431980848312, 'loss_2': 0.0014791488647460938, 'loss_3': -16.212007522583008, 'loss_4': 0.05337432399392128, 'epoch': 3.8}
{'loss': 0.0262, 'grad_norm': 11.667027473449707, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.02175750583410263, 'loss_2': 0.004486083984375, 'loss_3': -16.134078979492188, 'loss_4': 0.27868419885635376, 'epoch': 3.8}
{'loss': 0.0315, 'grad_norm': 12.084916114807129, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.02861393801867962, 'loss_2': 0.0029277801513671875, 'loss_3': -15.882628440856934, 'loss_4': -0.3536659777164459, 'epoch': 3.81}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:34:10,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:10,393 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:48<1:19:07,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:34:17,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01265666726976633, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008695759810507298, 'eval_loss_2': 0.003960907459259033, 'eval_loss_3': -18.24469566345215, 'eval_loss_4': -0.2132471203804016, 'epoch': 3.81}
{'loss': 0.0173, 'grad_norm': 6.229387283325195, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.016673430800437927, 'loss_2': 0.0005970001220703125, 'loss_3': -16.085622787475586, 'loss_4': -0.1620820164680481, 'epoch': 3.81}
{'loss': 0.0239, 'grad_norm': 8.214309692382812, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.020947033539414406, 'loss_2': 0.00299072265625, 'loss_3': -16.12427520751953, 'loss_4': -0.24178291857242584, 'epoch': 3.82}
{'loss': 0.0339, 'grad_norm': 12.053193092346191, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.03163614496588707, 'loss_2': 0.0023097991943359375, 'loss_3': -15.921147346496582, 'loss_4': -0.20454558730125427, 'epoch': 3.83}
{'loss': 0.0398, 'grad_norm': 10.011399269104004, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.03041975013911724, 'loss_2': 0.00940704345703125, 'loss_3': -16.203227996826172, 'loss_4': -0.33285409212112427, 'epoch': 3.83}
{'loss': 0.0275, 'grad_norm': 15.331680297851562, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.026486776769161224, 'loss_2': 0.0010089874267578125, 'loss_3': -16.08806610107422, 'loss_4': -0.30202460289001465, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 15:34:17,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:17,732 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:55<1:17:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:25,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012819623574614525, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.814, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007720716297626495, 'eval_loss_2': 0.005098909139633179, 'eval_loss_3': -18.26055145263672, 'eval_loss_4': -0.39813748002052307, 'epoch': 3.84}
{'loss': 0.0243, 'grad_norm': 10.021744728088379, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.021488353610038757, 'loss_2': 0.002796173095703125, 'loss_3': -16.051071166992188, 'loss_4': -0.520319402217865, 'epoch': 3.84}
{'loss': 0.0229, 'grad_norm': 7.968802452087402, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.018127596005797386, 'loss_2': 0.00482177734375, 'loss_3': -16.20009994506836, 'loss_4': -0.25179100036621094, 'epoch': 3.85}
{'loss': 0.0156, 'grad_norm': 5.7293219566345215, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.012092921882867813, 'loss_2': 0.0035400390625, 'loss_3': -16.24163246154785, 'loss_4': -0.5298331379890442, 'epoch': 3.85}
{'loss': 0.027, 'grad_norm': 6.57597541809082, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.02152576856315136, 'loss_2': 0.0054473876953125, 'loss_3': -16.084697723388672, 'loss_4': -0.44106772541999817, 'epoch': 3.86}
{'loss': 0.0303, 'grad_norm': 8.784509658813477, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.023990163579583168, 'loss_2': 0.0063323974609375, 'loss_3': -15.999844551086426, 'loss_4': 0.13830013573169708, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 15:34:25,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:25,076 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [17:03<1:17:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:32,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018077772110700607, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009776751510798931, 'eval_loss_2': 0.008301019668579102, 'eval_loss_3': -18.21380615234375, 'eval_loss_4': -0.5244334936141968, 'epoch': 3.87}
{'loss': 0.0298, 'grad_norm': 11.305249214172363, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.020464802160859108, 'loss_2': 0.009307861328125, 'loss_3': -16.045818328857422, 'loss_4': -0.16553178429603577, 'epoch': 3.87}
{'loss': 0.031, 'grad_norm': 11.116518020629883, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.02620992437005043, 'loss_2': 0.004795074462890625, 'loss_3': -15.974430084228516, 'loss_4': -0.4955698549747467, 'epoch': 3.88}
{'loss': 0.0461, 'grad_norm': 22.701467514038086, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.03663221001625061, 'loss_2': 0.0095062255859375, 'loss_3': -16.260366439819336, 'loss_4': -0.4537278115749359, 'epoch': 3.88}
{'loss': 0.0448, 'grad_norm': 12.638020515441895, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.030990371480584145, 'loss_2': 0.0138397216796875, 'loss_3': -16.23465919494629, 'loss_4': -0.24977955222129822, 'epoch': 3.89}
{'loss': 0.0227, 'grad_norm': 7.6529436111450195, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.02241613157093525, 'loss_2': 0.0002474784851074219, 'loss_3': -16.100032806396484, 'loss_4': -0.6368993520736694, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 15:34:32,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:32,432 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:10<1:17:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:39,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03368040919303894, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.025531142950057983, 'eval_loss_2': 0.008149266242980957, 'eval_loss_3': -18.069873809814453, 'eval_loss_4': -0.7023689150810242, 'epoch': 3.9}
{'loss': 0.027, 'grad_norm': 6.987780570983887, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.019061820581555367, 'loss_2': 0.00797271728515625, 'loss_3': -15.884563446044922, 'loss_4': -0.5525205731391907, 'epoch': 3.9}
{'loss': 0.0235, 'grad_norm': 7.613619804382324, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.019188106060028076, 'loss_2': 0.004314422607421875, 'loss_3': -15.966249465942383, 'loss_4': -0.4464297294616699, 'epoch': 3.91}
{'loss': 0.0414, 'grad_norm': 13.009284019470215, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.02931552194058895, 'loss_2': 0.01206207275390625, 'loss_3': -16.05848503112793, 'loss_4': -0.4438836872577667, 'epoch': 3.91}
{'loss': 0.0194, 'grad_norm': 10.8609619140625, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.018736811354756355, 'loss_2': 0.0006384849548339844, 'loss_3': -16.05767822265625, 'loss_4': -0.8343033790588379, 'epoch': 3.92}
{'loss': 0.0226, 'grad_norm': 7.780760288238525, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.019816989079117775, 'loss_2': 0.00273895263671875, 'loss_3': -16.05091094970703, 'loss_4': -0.9438894987106323, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 15:34:39,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:39,785 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:17<1:17:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:47,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012309025973081589, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.963, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009505432099103928, 'eval_loss_2': 0.002803593873977661, 'eval_loss_3': -18.19639778137207, 'eval_loss_4': -0.9056261777877808, 'epoch': 3.92}
{'loss': 0.0275, 'grad_norm': 9.675387382507324, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.026558980345726013, 'loss_2': 0.0009479522705078125, 'loss_3': -16.150543212890625, 'loss_4': -0.3983317017555237, 'epoch': 3.93}
{'loss': 0.0423, 'grad_norm': 11.457566261291504, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.04004838317632675, 'loss_2': 0.0022182464599609375, 'loss_3': -15.966560363769531, 'loss_4': -0.6833081245422363, 'epoch': 3.94}
{'loss': 0.0205, 'grad_norm': 9.25697135925293, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.01883525587618351, 'loss_2': 0.0016279220581054688, 'loss_3': -16.208528518676758, 'loss_4': -0.7869097590446472, 'epoch': 3.94}
{'loss': 0.0223, 'grad_norm': 7.144839286804199, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.02222544327378273, 'loss_2': 0.00011563301086425781, 'loss_3': -16.13949203491211, 'loss_4': -0.35867631435394287, 'epoch': 3.95}
{'loss': 0.0919, 'grad_norm': 32.02994155883789, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.08688818663358688, 'loss_2': 0.00496673583984375, 'loss_3': -16.119455337524414, 'loss_4': 0.5118263363838196, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 15:34:47,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:47,144 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:25<1:17:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:54,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013501884415745735, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010375918820500374, 'eval_loss_2': 0.0031259655952453613, 'eval_loss_3': -18.312519073486328, 'eval_loss_4': -0.6128581762313843, 'epoch': 3.95}
{'loss': 0.0451, 'grad_norm': 13.874665260314941, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.04409677907824516, 'loss_2': 0.0010356903076171875, 'loss_3': -16.079273223876953, 'loss_4': -0.07713204622268677, 'epoch': 3.96}
{'loss': 0.0352, 'grad_norm': 13.357444763183594, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.032010480761528015, 'loss_2': 0.003238677978515625, 'loss_3': -16.228382110595703, 'loss_4': -0.12258470058441162, 'epoch': 3.97}
{'loss': 0.0168, 'grad_norm': 6.357710361480713, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.014937285333871841, 'loss_2': 0.001888275146484375, 'loss_3': -16.13149642944336, 'loss_4': 0.1541597843170166, 'epoch': 3.97}
{'loss': 0.04, 'grad_norm': 13.50786304473877, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.034565676003694534, 'loss_2': 0.005401611328125, 'loss_3': -16.069124221801758, 'loss_4': 0.16665123403072357, 'epoch': 3.98}
{'loss': 0.0182, 'grad_norm': 5.855551719665527, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.016567714512348175, 'loss_2': 0.00160980224609375, 'loss_3': -15.993258476257324, 'loss_4': 0.6501923203468323, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 15:34:54,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:54,509 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:32<1:14:15,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 15:35:01,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015545422211289406, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.47, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010427827946841717, 'eval_loss_2': 0.005117595195770264, 'eval_loss_3': -18.318185806274414, 'eval_loss_4': -0.46990805864334106, 'epoch': 3.98}
{'loss': 0.0556, 'grad_norm': 19.750947952270508, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.04727717116475105, 'loss_2': 0.00827789306640625, 'loss_3': -16.23040008544922, 'loss_4': 0.11984838545322418, 'epoch': 3.99}
{'loss': 0.0217, 'grad_norm': 9.025064468383789, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.02025550790131092, 'loss_2': 0.0014209747314453125, 'loss_3': -16.231487274169922, 'loss_4': 0.7216910123825073, 'epoch': 3.99}
{'loss': 0.131, 'grad_norm': 54.244937896728516, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.1298009306192398, 'loss_2': 0.0012311935424804688, 'loss_3': -15.939925193786621, 'loss_4': 0.8465786576271057, 'epoch': 4.0}
{'loss': 0.0199, 'grad_norm': 8.056057929992676, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.01724826544523239, 'loss_2': 0.0026683807373046875, 'loss_3': -16.267032623291016, 'loss_4': -0.08042280375957489, 'epoch': 4.01}
{'loss': 0.2464, 'grad_norm': 25.874740600585938, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.24600434303283691, 'loss_2': 0.0003521442413330078, 'loss_3': -15.92934799194336, 'loss_4': -0.5296117663383484, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 15:35:01,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:01,546 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:39<1:16:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:35:08,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0145341195166111, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.369, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010275328531861305, 'eval_loss_2': 0.004258789122104645, 'eval_loss_3': -18.298397064208984, 'eval_loss_4': -0.44250550866127014, 'epoch': 4.01}
{'loss': 0.0296, 'grad_norm': 9.605101585388184, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.027289532124996185, 'loss_2': 0.002338409423828125, 'loss_3': -16.164461135864258, 'loss_4': 0.13159799575805664, 'epoch': 4.02}
{'loss': 0.0168, 'grad_norm': 7.40349817276001, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.015011555515229702, 'loss_2': 0.001800537109375, 'loss_3': -16.335010528564453, 'loss_4': 0.13040436804294586, 'epoch': 4.02}
{'loss': 0.0271, 'grad_norm': 9.51350212097168, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.0233288761228323, 'loss_2': 0.0037670135498046875, 'loss_3': -15.974651336669922, 'loss_4': -0.5059212446212769, 'epoch': 4.03}
{'loss': 0.085, 'grad_norm': 21.93503761291504, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.08056735247373581, 'loss_2': 0.004451751708984375, 'loss_3': -16.186870574951172, 'loss_4': 0.008184492588043213, 'epoch': 4.03}
{'loss': 0.0212, 'grad_norm': 8.99783706665039, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.019955988973379135, 'loss_2': 0.001262664794921875, 'loss_3': -16.21287727355957, 'loss_4': -0.20071417093276978, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 15:35:08,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:08,907 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:47<1:17:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:16,274 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021464861929416656, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.402, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.016637520864605904, 'eval_loss_2': 0.004827339202165604, 'eval_loss_3': -18.21862030029297, 'eval_loss_4': -0.2781188488006592, 'epoch': 4.04}
{'loss': 0.0256, 'grad_norm': 8.834296226501465, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.02357838861644268, 'loss_2': 0.002002716064453125, 'loss_3': -16.198999404907227, 'loss_4': 0.02318212389945984, 'epoch': 4.05}
{'loss': 0.0467, 'grad_norm': 15.706306457519531, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.04146571084856987, 'loss_2': 0.005207061767578125, 'loss_3': -16.020252227783203, 'loss_4': 0.06647121906280518, 'epoch': 4.05}
{'loss': 0.0253, 'grad_norm': 6.707200527191162, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.017361097037792206, 'loss_2': 0.0079498291015625, 'loss_3': -16.098676681518555, 'loss_4': -0.2821190357208252, 'epoch': 4.06}
{'loss': 0.0376, 'grad_norm': 9.605918884277344, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.028449349105358124, 'loss_2': 0.0091552734375, 'loss_3': -16.180654525756836, 'loss_4': 0.13872355222702026, 'epoch': 4.06}
{'loss': 0.0607, 'grad_norm': 17.902122497558594, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.05050075426697731, 'loss_2': 0.01024627685546875, 'loss_3': -16.10649299621582, 'loss_4': -0.3962799310684204, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 15:35:16,274 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:16,274 >>   Batch size = 64
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:54<1:17:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:23,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03285626322031021, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.02475784160196781, 'eval_loss_2': 0.008098423480987549, 'eval_loss_3': -18.240203857421875, 'eval_loss_4': -0.159600168466568, 'epoch': 4.07}
{'loss': 0.0287, 'grad_norm': 9.589079856872559, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.02410919778048992, 'loss_2': 0.004589080810546875, 'loss_3': -16.156906127929688, 'loss_4': -0.20209455490112305, 'epoch': 4.08}
{'loss': 0.0283, 'grad_norm': 9.268473625183105, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.025170253589749336, 'loss_2': 0.003177642822265625, 'loss_3': -16.38254165649414, 'loss_4': -0.07398451119661331, 'epoch': 4.08}
{'loss': 0.0647, 'grad_norm': 21.457387924194336, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.05326646566390991, 'loss_2': 0.01145172119140625, 'loss_3': -16.16446304321289, 'loss_4': -0.22463640570640564, 'epoch': 4.09}
{'loss': 0.0476, 'grad_norm': 25.670093536376953, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.03612242266535759, 'loss_2': 0.01145172119140625, 'loss_3': -16.055938720703125, 'loss_4': 0.0016018114984035492, 'epoch': 4.09}
{'loss': 0.0513, 'grad_norm': 11.84688949584961, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.05115582421422005, 'loss_2': 0.00013637542724609375, 'loss_3': -16.20998764038086, 'loss_4': -0.25769609212875366, 'epoch': 4.1}
[INFO|trainer.py:4228] 2025-01-21 15:35:23,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:23,637 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [18:01<1:17:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:30,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.040584318339824677, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.644, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.034439411014318466, 'eval_loss_2': 0.006144911050796509, 'eval_loss_3': -18.21294593811035, 'eval_loss_4': 0.2112591415643692, 'epoch': 4.1}
{'loss': 0.0445, 'grad_norm': 17.429859161376953, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.04007092863321304, 'loss_2': 0.00445556640625, 'loss_3': -16.079833984375, 'loss_4': -0.11490654200315475, 'epoch': 4.1}
{'loss': 0.0382, 'grad_norm': 9.966320991516113, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.028828725218772888, 'loss_2': 0.00939178466796875, 'loss_3': -16.108089447021484, 'loss_4': -0.030619442462921143, 'epoch': 4.11}
{'loss': 0.0532, 'grad_norm': 10.93332576751709, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.03536291420459747, 'loss_2': 0.01788330078125, 'loss_3': -16.14940643310547, 'loss_4': 0.604836106300354, 'epoch': 4.12}
{'loss': 0.0841, 'grad_norm': 20.707021713256836, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.07524009793996811, 'loss_2': 0.00888824462890625, 'loss_3': -16.117366790771484, 'loss_4': -0.22089038789272308, 'epoch': 4.12}
{'loss': 0.0514, 'grad_norm': 14.122032165527344, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.03943534567952156, 'loss_2': 0.01200103759765625, 'loss_3': -16.127843856811523, 'loss_4': 0.7400821447372437, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 15:35:31,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:31,000 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [18:09<1:17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:38,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05918409675359726, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.556, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.05441909283399582, 'eval_loss_2': 0.00476500391960144, 'eval_loss_3': -18.08234405517578, 'eval_loss_4': 0.7187137007713318, 'epoch': 4.13}
{'loss': 0.0313, 'grad_norm': 19.619844436645508, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.030474979430437088, 'loss_2': 0.0008196830749511719, 'loss_3': -16.288860321044922, 'loss_4': 0.11546020954847336, 'epoch': 4.13}
{'loss': 0.0982, 'grad_norm': 19.809879302978516, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.09271630644798279, 'loss_2': 0.005504608154296875, 'loss_3': -16.38074493408203, 'loss_4': 0.92616868019104, 'epoch': 4.14}
{'loss': 0.0585, 'grad_norm': 20.01834487915039, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.055200524628162384, 'loss_2': 0.0032806396484375, 'loss_3': -16.292123794555664, 'loss_4': 0.04650308936834335, 'epoch': 4.15}
{'loss': 0.0468, 'grad_norm': 19.565204620361328, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.04495876282453537, 'loss_2': 0.0018739700317382812, 'loss_3': -15.961779594421387, 'loss_4': 0.4301023483276367, 'epoch': 4.15}
{'loss': 0.0249, 'grad_norm': 19.99090003967285, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.02328845113515854, 'loss_2': 0.001575469970703125, 'loss_3': -16.1699161529541, 'loss_4': 0.23672789335250854, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 15:35:38,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:38,353 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:16<1:16:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:45,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03270101174712181, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.837, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.026310954242944717, 'eval_loss_2': 0.0063900575041770935, 'eval_loss_3': -18.19746971130371, 'eval_loss_4': 0.5424801707267761, 'epoch': 4.16}
{'loss': 0.0289, 'grad_norm': 10.289706230163574, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.026727993041276932, 'loss_2': 0.0022125244140625, 'loss_3': -16.261167526245117, 'loss_4': 0.3547753095626831, 'epoch': 4.16}
{'loss': 0.023, 'grad_norm': 5.932216644287109, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.012516163289546967, 'loss_2': 0.01047515869140625, 'loss_3': -16.261856079101562, 'loss_4': 0.7171694040298462, 'epoch': 4.17}
{'loss': 0.0294, 'grad_norm': 8.879104614257812, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.024733059108257294, 'loss_2': 0.00463104248046875, 'loss_3': -16.15533447265625, 'loss_4': 0.4002563953399658, 'epoch': 4.17}
{'loss': 0.04, 'grad_norm': 18.229053497314453, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.03153569996356964, 'loss_2': 0.008453369140625, 'loss_3': -16.042797088623047, 'loss_4': 0.5106089115142822, 'epoch': 4.18}
{'loss': 0.02, 'grad_norm': 6.185395240783691, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.011856522411108017, 'loss_2': 0.0081787109375, 'loss_3': -16.02303123474121, 'loss_4': 0.5869301557540894, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 15:35:45,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:45,715 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:23<1:17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:53,090 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01682581752538681, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.503, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011334127746522427, 'eval_loss_2': 0.005491688847541809, 'eval_loss_3': -18.280099868774414, 'eval_loss_4': 0.6682156324386597, 'epoch': 4.19}
{'loss': 0.0231, 'grad_norm': 9.356121063232422, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.022205408662557602, 'loss_2': 0.0008687973022460938, 'loss_3': -16.092788696289062, 'loss_4': 0.8013414740562439, 'epoch': 4.19}
{'loss': 0.0149, 'grad_norm': 5.964561462402344, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.01463527511805296, 'loss_2': 0.0003066062927246094, 'loss_3': -15.95622444152832, 'loss_4': 0.8333790898323059, 'epoch': 4.2}
{'loss': 0.0226, 'grad_norm': 8.736335754394531, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.017788201570510864, 'loss_2': 0.0048370361328125, 'loss_3': -16.026187896728516, 'loss_4': 0.7857299447059631, 'epoch': 4.2}
{'loss': 0.0513, 'grad_norm': 15.096668243408203, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.04944301024079323, 'loss_2': 0.0018987655639648438, 'loss_3': -16.18558120727539, 'loss_4': 1.6477580070495605, 'epoch': 4.21}
{'loss': 0.0549, 'grad_norm': 18.16655731201172, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.0415162518620491, 'loss_2': 0.01335906982421875, 'loss_3': -16.305814743041992, 'loss_4': 1.2721331119537354, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 15:35:53,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:53,090 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:31<1:16:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:00,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022599000483751297, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.479, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010165231302380562, 'eval_loss_2': 0.012433767318725586, 'eval_loss_3': -18.28536033630371, 'eval_loss_4': 0.6809206008911133, 'epoch': 4.22}
{'loss': 0.0351, 'grad_norm': 15.914355278015137, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.024478688836097717, 'loss_2': 0.0106201171875, 'loss_3': -16.310293197631836, 'loss_4': 0.9165663719177246, 'epoch': 4.22}
{'loss': 0.0339, 'grad_norm': 7.7123942375183105, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.017267893999814987, 'loss_2': 0.0166015625, 'loss_3': -15.825489044189453, 'loss_4': 1.3597662448883057, 'epoch': 4.23}
{'loss': 0.0295, 'grad_norm': 6.099978923797607, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.013795418664813042, 'loss_2': 0.015716552734375, 'loss_3': -16.14264488220215, 'loss_4': 0.5227883458137512, 'epoch': 4.23}
{'loss': 0.0377, 'grad_norm': 23.081668853759766, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.026601606979966164, 'loss_2': 0.0111236572265625, 'loss_3': -16.089908599853516, 'loss_4': 0.4594888687133789, 'epoch': 4.24}
{'loss': 0.0416, 'grad_norm': 7.417657852172852, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.018836190924048424, 'loss_2': 0.022735595703125, 'loss_3': -16.040037155151367, 'loss_4': 0.26406577229499817, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 15:36:00,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:00,461 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:38<1:16:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:07,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02200227975845337, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013331354595720768, 'eval_loss_2': 0.008670926094055176, 'eval_loss_3': -18.255090713500977, 'eval_loss_4': 0.3311966359615326, 'epoch': 4.24}
{'loss': 0.0735, 'grad_norm': 19.21026039123535, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.06455418467521667, 'loss_2': 0.00897979736328125, 'loss_3': -16.135753631591797, 'loss_4': 0.6784117221832275, 'epoch': 4.25}
{'loss': 0.0246, 'grad_norm': 8.581475257873535, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.016229020431637764, 'loss_2': 0.0083465576171875, 'loss_3': -16.24539566040039, 'loss_4': 0.5997351408004761, 'epoch': 4.26}
{'loss': 0.0529, 'grad_norm': 23.888593673706055, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.049523837864398956, 'loss_2': 0.00337982177734375, 'loss_3': -16.033884048461914, 'loss_4': 0.7732934355735779, 'epoch': 4.26}
{'loss': 0.0462, 'grad_norm': 24.209217071533203, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.04516925290226936, 'loss_2': 0.0010700225830078125, 'loss_3': -16.059961318969727, 'loss_4': 0.4935837686061859, 'epoch': 4.27}
{'loss': 0.0296, 'grad_norm': 9.855642318725586, 'learning_rate': 2.575e-05, 'loss_1': 0.02283407188951969, 'loss_2': 0.006740570068359375, 'loss_3': -15.774197578430176, 'loss_4': 0.3785433769226074, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 15:36:07,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:07,819 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:46<1:16:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:15,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02239406481385231, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.189, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016843516379594803, 'eval_loss_2': 0.005550548434257507, 'eval_loss_3': -18.232982635498047, 'eval_loss_4': 0.45756784081459045, 'epoch': 4.27}
{'loss': 0.0325, 'grad_norm': 9.47594165802002, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.02913738414645195, 'loss_2': 0.003398895263671875, 'loss_3': -16.328163146972656, 'loss_4': 0.7690509557723999, 'epoch': 4.28}
{'loss': 0.0573, 'grad_norm': 20.11219024658203, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.04862307012081146, 'loss_2': 0.0086517333984375, 'loss_3': -16.219886779785156, 'loss_4': 1.4669463634490967, 'epoch': 4.28}
{'loss': 0.0325, 'grad_norm': 12.046341896057129, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.030039623379707336, 'loss_2': 0.00244903564453125, 'loss_3': -15.884459495544434, 'loss_4': 1.440281629562378, 'epoch': 4.29}
{'loss': 0.0359, 'grad_norm': 11.44703197479248, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.03468692675232887, 'loss_2': 0.0012187957763671875, 'loss_3': -16.04018783569336, 'loss_4': 1.0730923414230347, 'epoch': 4.3}
{'loss': 0.0177, 'grad_norm': 6.783447265625, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.014390203170478344, 'loss_2': 0.0033168792724609375, 'loss_3': -16.212215423583984, 'loss_4': 1.000331163406372, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 15:36:15,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:15,183 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:53<1:16:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:22,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021106265485286713, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012788078747689724, 'eval_loss_2': 0.008318185806274414, 'eval_loss_3': -18.279136657714844, 'eval_loss_4': 0.30328744649887085, 'epoch': 4.3}
{'loss': 0.0278, 'grad_norm': 8.11026668548584, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.019866621121764183, 'loss_2': 0.00795745849609375, 'loss_3': -16.20520782470703, 'loss_4': 0.750027596950531, 'epoch': 4.31}
{'loss': 0.0184, 'grad_norm': 10.465962409973145, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.018302377313375473, 'loss_2': 0.0001125335693359375, 'loss_3': -16.194515228271484, 'loss_4': 0.5628851652145386, 'epoch': 4.31}
{'loss': 0.0659, 'grad_norm': 35.937320709228516, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.059126123785972595, 'loss_2': 0.00677490234375, 'loss_3': -15.854461669921875, 'loss_4': 0.4334163963794708, 'epoch': 4.32}
{'loss': 0.04, 'grad_norm': 12.975666046142578, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.031915705651044846, 'loss_2': 0.00804901123046875, 'loss_3': -16.299291610717773, 'loss_4': 1.091737151145935, 'epoch': 4.33}
{'loss': 0.0384, 'grad_norm': 8.452923774719238, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.02554130181670189, 'loss_2': 0.01282501220703125, 'loss_3': -15.965261459350586, 'loss_4': 0.650276243686676, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 15:36:22,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:22,535 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [19:00<1:16:54,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:36:29,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02155100181698799, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011961806565523148, 'eval_loss_2': 0.009589195251464844, 'eval_loss_3': -18.331539154052734, 'eval_loss_4': 0.071796715259552, 'epoch': 4.33}
{'loss': 0.0332, 'grad_norm': 8.352540016174316, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.02452312409877777, 'loss_2': 0.0086517333984375, 'loss_3': -16.124343872070312, 'loss_4': 0.9719415903091431, 'epoch': 4.34}
{'loss': 0.0227, 'grad_norm': 9.861544609069824, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.017757290974259377, 'loss_2': 0.00492095947265625, 'loss_3': -16.077219009399414, 'loss_4': 0.3287496864795685, 'epoch': 4.34}
{'loss': 0.0286, 'grad_norm': 14.234681129455566, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.027023715898394585, 'loss_2': 0.0015401840209960938, 'loss_3': -16.121946334838867, 'loss_4': 1.388201117515564, 'epoch': 4.35}
{'loss': 0.0364, 'grad_norm': 9.626479148864746, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.03407161310315132, 'loss_2': 0.00234222412109375, 'loss_3': -16.1724853515625, 'loss_4': 0.7761850953102112, 'epoch': 4.35}
{'loss': 0.0236, 'grad_norm': 9.030266761779785, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.02177383564412594, 'loss_2': 0.0017795562744140625, 'loss_3': -16.053157806396484, 'loss_4': -0.13622911274433136, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 15:36:29,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:29,927 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:08<1:16:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:37,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021531790494918823, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.497, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.017935220152139664, 'eval_loss_2': 0.0035965703427791595, 'eval_loss_3': -18.39649772644043, 'eval_loss_4': -0.655853807926178, 'epoch': 4.36}
{'loss': 0.022, 'grad_norm': 7.202811241149902, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.01883614808320999, 'loss_2': 0.0031795501708984375, 'loss_3': -16.32986831665039, 'loss_4': 0.3320196568965912, 'epoch': 4.37}
{'loss': 0.071, 'grad_norm': 18.94670295715332, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.0670325830578804, 'loss_2': 0.003986358642578125, 'loss_3': -16.256893157958984, 'loss_4': -0.14790187776088715, 'epoch': 4.37}
{'loss': 0.0579, 'grad_norm': 12.483290672302246, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.045757394284009933, 'loss_2': 0.012115478515625, 'loss_3': -16.086997985839844, 'loss_4': -0.41426169872283936, 'epoch': 4.38}
{'loss': 0.1015, 'grad_norm': 23.545482635498047, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.09748248010873795, 'loss_2': 0.003997802734375, 'loss_3': -16.399030685424805, 'loss_4': -0.7564786672592163, 'epoch': 4.38}
{'loss': 0.035, 'grad_norm': 11.90169906616211, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.033458411693573, 'loss_2': 0.0015277862548828125, 'loss_3': -16.327476501464844, 'loss_4': -1.1041127443313599, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 15:36:37,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:37,300 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:15<1:16:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:44,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019846061244606972, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.773, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.016835952177643776, 'eval_loss_2': 0.003010109066963196, 'eval_loss_3': -18.414405822753906, 'eval_loss_4': -1.5417239665985107, 'epoch': 4.39}
{'loss': 0.0336, 'grad_norm': 9.319485664367676, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.027736833319067955, 'loss_2': 0.005878448486328125, 'loss_3': -16.296260833740234, 'loss_4': -1.591196060180664, 'epoch': 4.4}
{'loss': 0.0371, 'grad_norm': 13.442811012268066, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.031674761325120926, 'loss_2': 0.00543975830078125, 'loss_3': -16.187908172607422, 'loss_4': -1.4855382442474365, 'epoch': 4.4}
{'loss': 0.0253, 'grad_norm': 12.964937210083008, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.020240487530827522, 'loss_2': 0.005016326904296875, 'loss_3': -16.436206817626953, 'loss_4': -1.6277461051940918, 'epoch': 4.41}
{'loss': 0.0258, 'grad_norm': 7.434414386749268, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.017412036657333374, 'loss_2': 0.00843048095703125, 'loss_3': -16.11856460571289, 'loss_4': -1.565157413482666, 'epoch': 4.41}
{'loss': 0.0419, 'grad_norm': 8.97978401184082, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.029801929369568825, 'loss_2': 0.0121307373046875, 'loss_3': -16.3391056060791, 'loss_4': -1.2189401388168335, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 15:36:44,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:44,668 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:22<1:16:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:52,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02609318122267723, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014749343506991863, 'eval_loss_2': 0.011343836784362793, 'eval_loss_3': -18.33983039855957, 'eval_loss_4': -1.7274435758590698, 'epoch': 4.42}
{'loss': 0.0243, 'grad_norm': 6.92995548248291, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.011966289952397346, 'loss_2': 0.0123748779296875, 'loss_3': -16.219585418701172, 'loss_4': -1.7893602848052979, 'epoch': 4.42}
{'loss': 0.0597, 'grad_norm': 18.71574592590332, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.05496872216463089, 'loss_2': 0.0047454833984375, 'loss_3': -15.941572189331055, 'loss_4': -0.61484694480896, 'epoch': 4.43}
{'loss': 0.0689, 'grad_norm': 25.415027618408203, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.061980366706848145, 'loss_2': 0.0069580078125, 'loss_3': -16.292659759521484, 'loss_4': -1.2428746223449707, 'epoch': 4.44}
{'loss': 0.032, 'grad_norm': 11.178885459899902, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.030856113880872726, 'loss_2': 0.0011911392211914062, 'loss_3': -15.981878280639648, 'loss_4': -0.8343529105186462, 'epoch': 4.44}
{'loss': 0.0137, 'grad_norm': 7.026392936706543, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.009339092299342155, 'loss_2': 0.00438690185546875, 'loss_3': -15.964790344238281, 'loss_4': -0.7387515902519226, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 15:36:52,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:52,032 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:30<1:16:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:59,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01866687834262848, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.459, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.015292121097445488, 'eval_loss_2': 0.003374755382537842, 'eval_loss_3': -18.238210678100586, 'eval_loss_4': -1.1248921155929565, 'epoch': 4.45}
{'loss': 0.0206, 'grad_norm': 7.583117485046387, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.019574854522943497, 'loss_2': 0.0010328292846679688, 'loss_3': -16.104267120361328, 'loss_4': -0.9633991718292236, 'epoch': 4.45}
{'loss': 0.0499, 'grad_norm': 15.844805717468262, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.045779455453157425, 'loss_2': 0.004077911376953125, 'loss_3': -16.082273483276367, 'loss_4': -1.3077954053878784, 'epoch': 4.46}
{'loss': 0.0223, 'grad_norm': 6.003347873687744, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.014521690085530281, 'loss_2': 0.00782012939453125, 'loss_3': -15.996938705444336, 'loss_4': -1.2618378400802612, 'epoch': 4.47}
{'loss': 0.0234, 'grad_norm': 6.362369537353516, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.016873285174369812, 'loss_2': 0.00653076171875, 'loss_3': -16.022096633911133, 'loss_4': -0.8203151226043701, 'epoch': 4.47}
{'loss': 0.024, 'grad_norm': 8.040661811828613, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.014382343739271164, 'loss_2': 0.0096435546875, 'loss_3': -15.998638153076172, 'loss_4': -0.2766016721725464, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 15:36:59,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:59,402 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:37<1:16:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:06,767 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03865043446421623, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.696, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.032364435493946075, 'eval_loss_2': 0.006285998970270157, 'eval_loss_3': -18.164525985717773, 'eval_loss_4': -0.4959268867969513, 'epoch': 4.48}
{'loss': 0.0106, 'grad_norm': 5.351663112640381, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.010385370813310146, 'loss_2': 0.00016987323760986328, 'loss_3': -15.898560523986816, 'loss_4': -0.22183175384998322, 'epoch': 4.48}
{'loss': 0.0236, 'grad_norm': 7.503312587738037, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.01832236722111702, 'loss_2': 0.00531768798828125, 'loss_3': -16.074142456054688, 'loss_4': -0.05960679054260254, 'epoch': 4.49}
{'loss': 0.0202, 'grad_norm': 7.177412509918213, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.015525098890066147, 'loss_2': 0.004627227783203125, 'loss_3': -15.937801361083984, 'loss_4': -0.595728874206543, 'epoch': 4.49}
{'loss': 0.0184, 'grad_norm': 5.355631351470947, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.011063870042562485, 'loss_2': 0.00734710693359375, 'loss_3': -15.935293197631836, 'loss_4': -0.42590832710266113, 'epoch': 4.5}
{'loss': 0.0203, 'grad_norm': 8.24119758605957, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.018324146047234535, 'loss_2': 0.00201416015625, 'loss_3': -16.114032745361328, 'loss_4': 0.14813025295734406, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 15:37:06,767 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:06,767 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:44<1:16:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:14,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.045681845396757126, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.472, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.042147789150476456, 'eval_loss_2': 0.00353405624628067, 'eval_loss_3': -18.13111686706543, 'eval_loss_4': -0.02655637636780739, 'epoch': 4.51}
{'loss': 0.0463, 'grad_norm': 15.771716117858887, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.04372529312968254, 'loss_2': 0.002559661865234375, 'loss_3': -15.818921089172363, 'loss_4': 0.15370061993598938, 'epoch': 4.51}
{'loss': 0.0256, 'grad_norm': 14.83030891418457, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.02008085511624813, 'loss_2': 0.005504608154296875, 'loss_3': -16.07718276977539, 'loss_4': 0.19149388372898102, 'epoch': 4.52}
{'loss': 0.0146, 'grad_norm': 5.0768938064575195, 'learning_rate': 2.55e-05, 'loss_1': 0.006051205564290285, 'loss_2': 0.008575439453125, 'loss_3': -16.052566528320312, 'loss_4': 0.056555312126874924, 'epoch': 4.52}
{'loss': 0.1066, 'grad_norm': 27.09930419921875, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.09163257479667664, 'loss_2': 0.01499176025390625, 'loss_3': -15.694883346557617, 'loss_4': 0.1809014081954956, 'epoch': 4.53}
{'loss': 0.0362, 'grad_norm': 32.20533752441406, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.030412349849939346, 'loss_2': 0.005741119384765625, 'loss_3': -16.07973861694336, 'loss_4': 0.00275614857673645, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 15:37:14,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:14,141 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:52<1:15:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:21,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03749731928110123, 'eval_runtime': 3.8194, 'eval_samples_per_second': 268.105, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.030784286558628082, 'eval_loss_2': 0.0067130327224731445, 'eval_loss_3': -18.206832885742188, 'eval_loss_4': 0.05899028107523918, 'epoch': 4.53}
{'loss': 0.044, 'grad_norm': 10.495725631713867, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.029367974027991295, 'loss_2': 0.01465606689453125, 'loss_3': -16.030841827392578, 'loss_4': 0.2906644940376282, 'epoch': 4.54}
{'loss': 0.0229, 'grad_norm': 10.144308090209961, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.015821943059563637, 'loss_2': 0.00710296630859375, 'loss_3': -15.96177864074707, 'loss_4': 0.42467543482780457, 'epoch': 4.55}
{'loss': 0.0174, 'grad_norm': 10.287314414978027, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.016758227720856667, 'loss_2': 0.0006742477416992188, 'loss_3': -15.844711303710938, 'loss_4': -0.03589168190956116, 'epoch': 4.55}
{'loss': 0.0216, 'grad_norm': 8.349444389343262, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.020212333649396896, 'loss_2': 0.0014181137084960938, 'loss_3': -15.942869186401367, 'loss_4': 0.322087824344635, 'epoch': 4.56}
{'loss': 0.0145, 'grad_norm': 6.853688716888428, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.014302995055913925, 'loss_2': 0.00022840499877929688, 'loss_3': -16.008712768554688, 'loss_4': 0.49648767709732056, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 15:37:21,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:21,522 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:59<1:15:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:28,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023953843861818314, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.717, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.020785009488463402, 'eval_loss_2': 0.003168836236000061, 'eval_loss_3': -18.2553768157959, 'eval_loss_4': 0.2448197305202484, 'epoch': 4.56}
{'loss': 0.0186, 'grad_norm': 8.400681495666504, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.01439379807561636, 'loss_2': 0.00421142578125, 'loss_3': -16.04159927368164, 'loss_4': 0.6292673945426941, 'epoch': 4.57}
{'loss': 0.0193, 'grad_norm': 8.546472549438477, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.015753185376524925, 'loss_2': 0.0035266876220703125, 'loss_3': -16.016082763671875, 'loss_4': 0.557593584060669, 'epoch': 4.58}
{'loss': 0.0195, 'grad_norm': 7.255170822143555, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.015749402344226837, 'loss_2': 0.0037670135498046875, 'loss_3': -16.122901916503906, 'loss_4': 0.49583709239959717, 'epoch': 4.58}
{'loss': 0.0278, 'grad_norm': 8.354625701904297, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.020918145775794983, 'loss_2': 0.00685882568359375, 'loss_3': -16.10897445678711, 'loss_4': 0.7732126712799072, 'epoch': 4.59}
{'loss': 0.0193, 'grad_norm': 7.805594444274902, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.019001396372914314, 'loss_2': 0.00028061866760253906, 'loss_3': -16.095468521118164, 'loss_4': 0.7952592372894287, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 15:37:28,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:28,889 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [20:07<1:15:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:36,257 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025292910635471344, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.713, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.022090474143624306, 'eval_loss_2': 0.0032024383544921875, 'eval_loss_3': -18.274612426757812, 'eval_loss_4': 0.2594447433948517, 'epoch': 4.59}
{'loss': 0.0373, 'grad_norm': 21.860979080200195, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.03639189153909683, 'loss_2': 0.0008840560913085938, 'loss_3': -16.04617691040039, 'loss_4': 0.7903531789779663, 'epoch': 4.6}
{'loss': 0.0631, 'grad_norm': 37.00197982788086, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.05927819013595581, 'loss_2': 0.003849029541015625, 'loss_3': -15.968096733093262, 'loss_4': 0.23224443197250366, 'epoch': 4.6}
{'loss': 0.0371, 'grad_norm': 12.311748504638672, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.031449366360902786, 'loss_2': 0.005603790283203125, 'loss_3': -16.269683837890625, 'loss_4': 0.7916619777679443, 'epoch': 4.61}
{'loss': 0.0233, 'grad_norm': 7.851645469665527, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.017315659672021866, 'loss_2': 0.0059967041015625, 'loss_3': -16.36930274963379, 'loss_4': 0.4487467408180237, 'epoch': 4.62}
{'loss': 0.0186, 'grad_norm': 7.002156734466553, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.013749169185757637, 'loss_2': 0.00485992431640625, 'loss_3': -16.13156509399414, 'loss_4': 0.33652880787849426, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 15:37:36,257 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:36,258 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:14<1:15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:43,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0439838171005249, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.515, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.040816038846969604, 'eval_loss_2': 0.003167778253555298, 'eval_loss_3': -18.218568801879883, 'eval_loss_4': 0.08517922461032867, 'epoch': 4.62}
{'loss': 0.0711, 'grad_norm': 24.022274017333984, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.06823033094406128, 'loss_2': 0.00286102294921875, 'loss_3': -16.023170471191406, 'loss_4': 0.5504063963890076, 'epoch': 4.63}
{'loss': 0.035, 'grad_norm': 12.408449172973633, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.03226993978023529, 'loss_2': 0.002704620361328125, 'loss_3': -16.09438133239746, 'loss_4': 0.03160620480775833, 'epoch': 4.63}
{'loss': 0.0365, 'grad_norm': 7.667141437530518, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.024829257279634476, 'loss_2': 0.0116424560546875, 'loss_3': -16.24820327758789, 'loss_4': -0.04506624490022659, 'epoch': 4.64}
{'loss': 0.0606, 'grad_norm': 19.554641723632812, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.056903667747974396, 'loss_2': 0.003696441650390625, 'loss_3': -16.01929473876953, 'loss_4': 0.037396520376205444, 'epoch': 4.65}
{'loss': 0.0274, 'grad_norm': 10.402438163757324, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.02257268689572811, 'loss_2': 0.0048370361328125, 'loss_3': -16.13422393798828, 'loss_4': 0.014329440891742706, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 15:37:43,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:43,630 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:21<1:15:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:51,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03272492438554764, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.655, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.03009132668375969, 'eval_loss_2': 0.002633601427078247, 'eval_loss_3': -18.279245376586914, 'eval_loss_4': -0.16414599120616913, 'epoch': 4.65}
{'loss': 0.0397, 'grad_norm': 12.671408653259277, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.038363441824913025, 'loss_2': 0.0013170242309570312, 'loss_3': -16.057209014892578, 'loss_4': -0.03192095458507538, 'epoch': 4.66}
{'loss': 0.0257, 'grad_norm': 7.8849568367004395, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.018970273435115814, 'loss_2': 0.00677490234375, 'loss_3': -16.279117584228516, 'loss_4': -0.11570985615253448, 'epoch': 4.66}
{'loss': 0.0519, 'grad_norm': 15.840109825134277, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.04911324754357338, 'loss_2': 0.002773284912109375, 'loss_3': -16.17803955078125, 'loss_4': 0.03851853311061859, 'epoch': 4.67}
{'loss': 0.0267, 'grad_norm': 9.838061332702637, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.02279098890721798, 'loss_2': 0.003871917724609375, 'loss_3': -16.440540313720703, 'loss_4': 0.3345264792442322, 'epoch': 4.67}
{'loss': 0.0818, 'grad_norm': 37.32707977294922, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.07481570541858673, 'loss_2': 0.006999969482421875, 'loss_3': -16.07572364807129, 'loss_4': 0.0016179829835891724, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 15:37:51,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:51,002 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:29<1:15:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:58,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024768218398094177, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.403, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.020734652876853943, 'eval_loss_2': 0.004033565521240234, 'eval_loss_3': -18.329153060913086, 'eval_loss_4': -0.13219961524009705, 'epoch': 4.68}
{'loss': 0.0609, 'grad_norm': 18.44729995727539, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.05400311201810837, 'loss_2': 0.00689697265625, 'loss_3': -16.010967254638672, 'loss_4': 0.31990575790405273, 'epoch': 4.69}
{'loss': 0.0367, 'grad_norm': 10.695233345031738, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.026787543669342995, 'loss_2': 0.0099029541015625, 'loss_3': -16.08978271484375, 'loss_4': -0.07074630260467529, 'epoch': 4.69}
{'loss': 0.0872, 'grad_norm': 28.116987228393555, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.0810883492231369, 'loss_2': 0.006069183349609375, 'loss_3': -16.16372299194336, 'loss_4': 0.249696284532547, 'epoch': 4.7}
{'loss': 0.0258, 'grad_norm': 6.478788375854492, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.018577640876173973, 'loss_2': 0.00722503662109375, 'loss_3': -16.20826530456543, 'loss_4': 0.6627851724624634, 'epoch': 4.7}
{'loss': 0.0631, 'grad_norm': 21.825443267822266, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.06032223626971245, 'loss_2': 0.0027313232421875, 'loss_3': -16.32485580444336, 'loss_4': -0.41642290353775024, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 15:37:58,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:58,377 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:36<1:15:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:05,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02060282975435257, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.017358900979161263, 'eval_loss_2': 0.003243926912546158, 'eval_loss_3': -18.303964614868164, 'eval_loss_4': -0.23265962302684784, 'epoch': 4.71}
{'loss': 0.0188, 'grad_norm': 7.307728290557861, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.017555532976984978, 'loss_2': 0.001285552978515625, 'loss_3': -16.228065490722656, 'loss_4': -0.38469749689102173, 'epoch': 4.72}
{'loss': 0.03, 'grad_norm': 8.935392379760742, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.021297868341207504, 'loss_2': 0.0087432861328125, 'loss_3': -16.281536102294922, 'loss_4': 0.1988610327243805, 'epoch': 4.72}
{'loss': 0.0185, 'grad_norm': 6.684200763702393, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.01151459850370884, 'loss_2': 0.007015228271484375, 'loss_3': -16.310117721557617, 'loss_4': 0.2939271926879883, 'epoch': 4.73}
{'loss': 0.0281, 'grad_norm': 8.236515998840332, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.024822810664772987, 'loss_2': 0.0032787322998046875, 'loss_3': -16.13788604736328, 'loss_4': 0.40248724818229675, 'epoch': 4.73}
{'loss': 0.0232, 'grad_norm': 7.52231502532959, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.017773238942027092, 'loss_2': 0.00539398193359375, 'loss_3': -16.15167236328125, 'loss_4': -0.5250124335289001, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 15:38:05,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:05,738 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:43<1:15:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:13,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012637419626116753, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008613063022494316, 'eval_loss_2': 0.0040243566036224365, 'eval_loss_3': -18.331201553344727, 'eval_loss_4': -0.03914148360490799, 'epoch': 4.74}
{'loss': 0.0285, 'grad_norm': 8.248808860778809, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.02359112910926342, 'loss_2': 0.00494384765625, 'loss_3': -16.102123260498047, 'loss_4': 0.5959962606430054, 'epoch': 4.74}
{'loss': 0.0351, 'grad_norm': 19.42091178894043, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.03343008831143379, 'loss_2': 0.0016384124755859375, 'loss_3': -16.037700653076172, 'loss_4': 0.09738868474960327, 'epoch': 4.75}
{'loss': 0.0262, 'grad_norm': 8.365208625793457, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.017374427989125252, 'loss_2': 0.0088043212890625, 'loss_3': -16.032461166381836, 'loss_4': 0.3034815192222595, 'epoch': 4.76}
{'loss': 0.0214, 'grad_norm': 6.8468780517578125, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.018790842965245247, 'loss_2': 0.002567291259765625, 'loss_3': -16.012739181518555, 'loss_4': 0.5721439719200134, 'epoch': 4.76}
{'loss': 0.0229, 'grad_norm': 6.474672794342041, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.019132673740386963, 'loss_2': 0.003814697265625, 'loss_3': -16.130666732788086, 'loss_4': 0.627779483795166, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 15:38:13,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:13,105 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:51<1:15:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:20,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012981763109564781, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.576, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009041867218911648, 'eval_loss_2': 0.003939896821975708, 'eval_loss_3': -18.319854736328125, 'eval_loss_4': -0.0476275235414505, 'epoch': 4.77}
{'loss': 0.0275, 'grad_norm': 10.65604305267334, 'learning_rate': 2.525e-05, 'loss_1': 0.026977911591529846, 'loss_2': 0.00051116943359375, 'loss_3': -16.136674880981445, 'loss_4': 0.4965049922466278, 'epoch': 4.77}
{'loss': 0.0208, 'grad_norm': 10.82526969909668, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.015501297079026699, 'loss_2': 0.00533294677734375, 'loss_3': -16.134925842285156, 'loss_4': 0.20106413960456848, 'epoch': 4.78}
{'loss': 0.0567, 'grad_norm': 14.450654029846191, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.052526794373989105, 'loss_2': 0.004207611083984375, 'loss_3': -16.20470428466797, 'loss_4': 0.565296471118927, 'epoch': 4.78}
{'loss': 0.0105, 'grad_norm': 5.339068412780762, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.009303632192313671, 'loss_2': 0.0011472702026367188, 'loss_3': -16.271482467651367, 'loss_4': 0.23197530210018158, 'epoch': 4.79}
{'loss': 0.1049, 'grad_norm': 27.349679946899414, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.08455171436071396, 'loss_2': 0.0203399658203125, 'loss_3': -15.849428176879883, 'loss_4': -0.10578171908855438, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 15:38:20,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:20,478 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:58<1:15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:27,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019195012748241425, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.048, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010447435081005096, 'eval_loss_2': 0.008747577667236328, 'eval_loss_3': -18.284093856811523, 'eval_loss_4': -0.14558029174804688, 'epoch': 4.8}
{'loss': 0.0349, 'grad_norm': 7.586369037628174, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.020160630345344543, 'loss_2': 0.0147857666015625, 'loss_3': -16.162704467773438, 'loss_4': -0.260407418012619, 'epoch': 4.8}
{'loss': 0.0231, 'grad_norm': 8.746933937072754, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.020790068432688713, 'loss_2': 0.002315521240234375, 'loss_3': -16.22850799560547, 'loss_4': 0.28927290439605713, 'epoch': 4.81}
{'loss': 0.04, 'grad_norm': 7.79475212097168, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.02169189229607582, 'loss_2': 0.018280029296875, 'loss_3': -16.20037078857422, 'loss_4': 0.1827249526977539, 'epoch': 4.81}
{'loss': 0.0441, 'grad_norm': 14.120536804199219, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.03989919647574425, 'loss_2': 0.004230499267578125, 'loss_3': -16.21441078186035, 'loss_4': 0.5446386337280273, 'epoch': 4.82}
{'loss': 0.0342, 'grad_norm': 21.749536514282227, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.026284895837306976, 'loss_2': 0.00789642333984375, 'loss_3': -15.909072875976562, 'loss_4': 0.49213021993637085, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 15:38:27,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:27,834 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [21:06<1:15:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:35,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017389975488185883, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.695, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011303268373012543, 'eval_loss_2': 0.00608670711517334, 'eval_loss_3': -18.301231384277344, 'eval_loss_4': -0.06849242746829987, 'epoch': 4.83}
{'loss': 0.0151, 'grad_norm': 6.149142265319824, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.01128214318305254, 'loss_2': 0.00382232666015625, 'loss_3': -16.18698501586914, 'loss_4': -0.013675481081008911, 'epoch': 4.83}
{'loss': 0.0272, 'grad_norm': 12.319666862487793, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.024791887030005455, 'loss_2': 0.00244903564453125, 'loss_3': -16.175695419311523, 'loss_4': 0.6075076460838318, 'epoch': 4.84}
{'loss': 0.0242, 'grad_norm': 9.034496307373047, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.02137722074985504, 'loss_2': 0.0028514862060546875, 'loss_3': -16.194236755371094, 'loss_4': -0.2948560416698456, 'epoch': 4.84}
{'loss': 0.0267, 'grad_norm': 9.92352294921875, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.021263623610138893, 'loss_2': 0.005474090576171875, 'loss_3': -16.12371826171875, 'loss_4': 0.10595771670341492, 'epoch': 4.85}
{'loss': 0.0648, 'grad_norm': 22.972986221313477, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.06352534145116806, 'loss_2': 0.0012826919555664062, 'loss_3': -15.985260009765625, 'loss_4': 0.5353621244430542, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 15:38:35,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:35,203 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:13<1:15:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:42,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014621222391724586, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.48, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009864771738648415, 'eval_loss_2': 0.004756450653076172, 'eval_loss_3': -18.311124801635742, 'eval_loss_4': -0.19608300924301147, 'epoch': 4.85}
{'loss': 0.0295, 'grad_norm': 12.034530639648438, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.026703691110014915, 'loss_2': 0.002811431884765625, 'loss_3': -16.12175750732422, 'loss_4': 0.33423349261283875, 'epoch': 4.86}
{'loss': 0.0281, 'grad_norm': 10.822047233581543, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.024149756878614426, 'loss_2': 0.003948211669921875, 'loss_3': -16.192886352539062, 'loss_4': -0.007724285125732422, 'epoch': 4.87}
{'loss': 0.0641, 'grad_norm': 16.382352828979492, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.06028077006340027, 'loss_2': 0.0037841796875, 'loss_3': -16.058483123779297, 'loss_4': 0.06715669482946396, 'epoch': 4.87}
{'loss': 0.0129, 'grad_norm': 6.599575042724609, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.012244094163179398, 'loss_2': 0.0006499290466308594, 'loss_3': -16.196426391601562, 'loss_4': 0.08456312119960785, 'epoch': 4.88}
{'loss': 0.0592, 'grad_norm': 17.982778549194336, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.05343145504593849, 'loss_2': 0.00572967529296875, 'loss_3': -15.972148895263672, 'loss_4': 0.0016840547323226929, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 15:38:42,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:42,585 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:20<1:14:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:49,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016724344342947006, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.894, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010649558156728745, 'eval_loss_2': 0.006074786186218262, 'eval_loss_3': -18.311756134033203, 'eval_loss_4': -0.49723681807518005, 'epoch': 4.88}
{'loss': 0.031, 'grad_norm': 12.970812797546387, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.021312925964593887, 'loss_2': 0.0096588134765625, 'loss_3': -16.238697052001953, 'loss_4': 0.15423691272735596, 'epoch': 4.89}
{'loss': 0.043, 'grad_norm': 11.694620132446289, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.03585420921444893, 'loss_2': 0.00714874267578125, 'loss_3': -16.173301696777344, 'loss_4': -0.5333520770072937, 'epoch': 4.9}
{'loss': 0.0333, 'grad_norm': 11.791280746459961, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.022861836478114128, 'loss_2': 0.01039886474609375, 'loss_3': -16.130882263183594, 'loss_4': -0.15407417714595795, 'epoch': 4.9}
{'loss': 0.0244, 'grad_norm': 10.726310729980469, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.024171004071831703, 'loss_2': 0.00018036365509033203, 'loss_3': -16.307167053222656, 'loss_4': -0.39352571964263916, 'epoch': 4.91}
{'loss': 0.0329, 'grad_norm': 10.1616849899292, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.030063925310969353, 'loss_2': 0.002796173095703125, 'loss_3': -16.02833366394043, 'loss_4': -0.2202683687210083, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 15:38:49,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:49,956 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:28<1:14:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:57,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016055837273597717, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.151, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012646474875509739, 'eval_loss_2': 0.003409363329410553, 'eval_loss_3': -18.32052230834961, 'eval_loss_4': -0.8141607046127319, 'epoch': 4.91}
{'loss': 0.0206, 'grad_norm': 6.034211158752441, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.015515066683292389, 'loss_2': 0.005096435546875, 'loss_3': -16.225448608398438, 'loss_4': -0.8223665356636047, 'epoch': 4.92}
{'loss': 0.0883, 'grad_norm': 20.376733779907227, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.08758824318647385, 'loss_2': 0.000690460205078125, 'loss_3': -16.341604232788086, 'loss_4': -0.19507421553134918, 'epoch': 4.92}
{'loss': 0.0271, 'grad_norm': 9.924543380737305, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.02700055204331875, 'loss_2': 0.0001068115234375, 'loss_3': -16.152976989746094, 'loss_4': -0.8511158227920532, 'epoch': 4.93}
{'loss': 0.0469, 'grad_norm': 10.76428508758545, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.036927301436662674, 'loss_2': 0.009979248046875, 'loss_3': -16.390010833740234, 'loss_4': -0.6128743886947632, 'epoch': 4.94}
{'loss': 0.0721, 'grad_norm': 17.306129455566406, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.06425801664590836, 'loss_2': 0.0078887939453125, 'loss_3': -15.963141441345215, 'loss_4': -0.9145280122756958, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 15:38:57,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:57,325 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:35<1:14:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:04,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026322323828935623, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.988, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013851599767804146, 'eval_loss_2': 0.012470722198486328, 'eval_loss_3': -18.300487518310547, 'eval_loss_4': -0.961652934551239, 'epoch': 4.94}
{'loss': 0.0493, 'grad_norm': 17.348405838012695, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.03606395795941353, 'loss_2': 0.01319122314453125, 'loss_3': -16.08216094970703, 'loss_4': -0.660138726234436, 'epoch': 4.95}
{'loss': 0.0448, 'grad_norm': 9.853070259094238, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.026229990646243095, 'loss_2': 0.018585205078125, 'loss_3': -16.16887664794922, 'loss_4': -0.7482492327690125, 'epoch': 4.95}
{'loss': 0.0188, 'grad_norm': 5.96965217590332, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.012298373505473137, 'loss_2': 0.006473541259765625, 'loss_3': -16.332788467407227, 'loss_4': -0.8894035220146179, 'epoch': 4.96}
{'loss': 0.0392, 'grad_norm': 12.09214973449707, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.02177736721932888, 'loss_2': 0.017425537109375, 'loss_3': -15.978023529052734, 'loss_4': -0.6526844501495361, 'epoch': 4.97}
{'loss': 0.0391, 'grad_norm': 14.8878173828125, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.032724566757678986, 'loss_2': 0.00634765625, 'loss_3': -16.29204750061035, 'loss_4': -0.7805602550506592, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 15:39:04,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:04,687 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:42<1:07:10,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 15:39:11,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02749232016503811, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.141, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018019622191786766, 'eval_loss_2': 0.009472697973251343, 'eval_loss_3': -18.26617431640625, 'eval_loss_4': -0.915351927280426, 'epoch': 4.97}
{'loss': 0.0286, 'grad_norm': 9.151302337646484, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.019130680710077286, 'loss_2': 0.0095062255859375, 'loss_3': -16.36156463623047, 'loss_4': -0.8921585083007812, 'epoch': 4.98}
{'loss': 0.0911, 'grad_norm': 18.568601608276367, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.08153261244297028, 'loss_2': 0.00958251953125, 'loss_3': -16.161895751953125, 'loss_4': -0.7759711742401123, 'epoch': 4.98}
{'loss': 0.0203, 'grad_norm': 7.681667804718018, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.019552530720829964, 'loss_2': 0.0007877349853515625, 'loss_3': -16.001325607299805, 'loss_4': -0.985005259513855, 'epoch': 4.99}
{'loss': 0.0231, 'grad_norm': 9.24639892578125, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.01678878627717495, 'loss_2': 0.006298065185546875, 'loss_3': -16.1822452545166, 'loss_4': -0.5090153217315674, 'epoch': 4.99}
{'loss': 0.0074, 'grad_norm': 6.445654392242432, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.0042348820716142654, 'loss_2': 0.0031890869140625, 'loss_3': -16.102947235107422, 'loss_4': -1.0280609130859375, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 15:39:11,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:11,702 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:49<1:13:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:39:19,127 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030397534370422363, 'eval_runtime': 3.8257, 'eval_samples_per_second': 267.663, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.02572103962302208, 'eval_loss_2': 0.004676491022109985, 'eval_loss_3': -18.246023178100586, 'eval_loss_4': -0.7542057633399963, 'epoch': 5.0}
{'loss': 0.0392, 'grad_norm': 23.55316734313965, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.03620801120996475, 'loss_2': 0.00301361083984375, 'loss_3': -16.092830657958984, 'loss_4': -0.20940342545509338, 'epoch': 5.01}
{'loss': 0.0313, 'grad_norm': 8.876858711242676, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.028288263827562332, 'loss_2': 0.003047943115234375, 'loss_3': -16.10972023010254, 'loss_4': -0.3568452298641205, 'epoch': 5.01}
{'loss': 0.0313, 'grad_norm': 6.796746730804443, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.01842842623591423, 'loss_2': 0.012847900390625, 'loss_3': -16.096277236938477, 'loss_4': -0.6103140115737915, 'epoch': 5.02}
{'loss': 0.0239, 'grad_norm': 8.38308334350586, 'learning_rate': 2.5e-05, 'loss_1': 0.016827791929244995, 'loss_2': 0.0070953369140625, 'loss_3': -16.143932342529297, 'loss_4': -0.5679787993431091, 'epoch': 5.02}
{'loss': 0.0597, 'grad_norm': 21.122947692871094, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.03774360194802284, 'loss_2': 0.0219268798828125, 'loss_3': -15.935522079467773, 'loss_4': -0.8782587051391602, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 15:39:19,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:19,127 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:57<1:14:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:26,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04104910418391228, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.114, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.032178860157728195, 'eval_loss_2': 0.008870244026184082, 'eval_loss_3': -18.223590850830078, 'eval_loss_4': -0.6475237011909485, 'epoch': 5.03}
{'loss': 0.0247, 'grad_norm': 7.2401299476623535, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.016395842656493187, 'loss_2': 0.008331298828125, 'loss_3': -16.173030853271484, 'loss_4': -0.36424535512924194, 'epoch': 5.03}
{'loss': 0.0395, 'grad_norm': 13.082456588745117, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.02906828559935093, 'loss_2': 0.01043701171875, 'loss_3': -16.109514236450195, 'loss_4': -0.6585248708724976, 'epoch': 5.04}
{'loss': 0.0188, 'grad_norm': 7.055447578430176, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.015111291781067848, 'loss_2': 0.003673553466796875, 'loss_3': -16.043195724487305, 'loss_4': -0.27517473697662354, 'epoch': 5.05}
{'loss': 0.0356, 'grad_norm': 15.905571937561035, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.03413534536957741, 'loss_2': 0.0014905929565429688, 'loss_3': -16.125978469848633, 'loss_4': -0.13600194454193115, 'epoch': 5.05}
{'loss': 0.0255, 'grad_norm': 7.720121383666992, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.020773878321051598, 'loss_2': 0.00473785400390625, 'loss_3': -16.034181594848633, 'loss_4': -0.6053929924964905, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 15:39:26,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:26,485 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [22:04<1:14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:33,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04069133102893829, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.297, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.033056747168302536, 'eval_loss_2': 0.007634580135345459, 'eval_loss_3': -18.201623916625977, 'eval_loss_4': -0.736056923866272, 'epoch': 5.06}
{'loss': 0.0272, 'grad_norm': 8.062812805175781, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.017621438950300217, 'loss_2': 0.009613037109375, 'loss_3': -15.841686248779297, 'loss_4': -0.3504422903060913, 'epoch': 5.06}
{'loss': 0.0594, 'grad_norm': 21.259706497192383, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.05844051390886307, 'loss_2': 0.0009708404541015625, 'loss_3': -16.277725219726562, 'loss_4': -0.6165530681610107, 'epoch': 5.07}
{'loss': 0.0486, 'grad_norm': 11.600266456604004, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.03302484005689621, 'loss_2': 0.01552581787109375, 'loss_3': -15.97995376586914, 'loss_4': -0.7122143507003784, 'epoch': 5.08}
{'loss': 0.0403, 'grad_norm': 6.645030498504639, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.016878295689821243, 'loss_2': 0.023468017578125, 'loss_3': -16.182167053222656, 'loss_4': -0.8857073783874512, 'epoch': 5.08}
{'loss': 0.0355, 'grad_norm': 7.466368198394775, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.019402043893933296, 'loss_2': 0.01611328125, 'loss_3': -16.01129722595215, 'loss_4': -0.8457764387130737, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 15:39:33,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:33,841 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [22:12<1:14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:41,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0522131510078907, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.218, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.03765293210744858, 'eval_loss_2': 0.014560222625732422, 'eval_loss_3': -18.16338539123535, 'eval_loss_4': -0.5998286604881287, 'epoch': 5.09}
{'loss': 0.0353, 'grad_norm': 13.482442855834961, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.022372117266058922, 'loss_2': 0.012969970703125, 'loss_3': -16.206106185913086, 'loss_4': -0.32535722851753235, 'epoch': 5.09}
{'loss': 0.0149, 'grad_norm': 7.006457328796387, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.013640670105814934, 'loss_2': 0.0012826919555664062, 'loss_3': -16.122968673706055, 'loss_4': -0.8170098066329956, 'epoch': 5.1}
{'loss': 0.0455, 'grad_norm': 13.588656425476074, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.04087882488965988, 'loss_2': 0.00460052490234375, 'loss_3': -16.111892700195312, 'loss_4': -0.012540042400360107, 'epoch': 5.1}
{'loss': 0.0297, 'grad_norm': 14.738308906555176, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.020464012399315834, 'loss_2': 0.009246826171875, 'loss_3': -16.08851432800293, 'loss_4': -0.1583111733198166, 'epoch': 5.11}
{'loss': 0.0354, 'grad_norm': 16.799442291259766, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.03178664669394493, 'loss_2': 0.003658294677734375, 'loss_3': -16.178985595703125, 'loss_4': -0.2865651845932007, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 15:39:41,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:41,198 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:19<1:14:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:48,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0538705438375473, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.282, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.04976606369018555, 'eval_loss_2': 0.004104480147361755, 'eval_loss_3': -18.115018844604492, 'eval_loss_4': -0.11334870755672455, 'epoch': 5.12}
{'loss': 0.0514, 'grad_norm': 16.613262176513672, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.04858610779047012, 'loss_2': 0.00281524658203125, 'loss_3': -15.996400833129883, 'loss_4': 0.6514909267425537, 'epoch': 5.12}
{'loss': 0.0481, 'grad_norm': 16.730575561523438, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.039514750242233276, 'loss_2': 0.008575439453125, 'loss_3': -16.064353942871094, 'loss_4': -0.071192666888237, 'epoch': 5.13}
{'loss': 0.0306, 'grad_norm': 11.542632102966309, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.027270950376987457, 'loss_2': 0.0033016204833984375, 'loss_3': -15.993633270263672, 'loss_4': 0.4527920186519623, 'epoch': 5.13}
{'loss': 0.1129, 'grad_norm': 24.639942169189453, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.0984484851360321, 'loss_2': 0.0144195556640625, 'loss_3': -15.992929458618164, 'loss_4': 0.5189777612686157, 'epoch': 5.14}
{'loss': 0.0245, 'grad_norm': 6.574460029602051, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.01719609647989273, 'loss_2': 0.007293701171875, 'loss_3': -16.04016876220703, 'loss_4': 0.08876796066761017, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 15:39:48,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:48,555 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:26<1:14:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:55,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.041801802814006805, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.464, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.03323578089475632, 'eval_loss_2': 0.008566021919250488, 'eval_loss_3': -18.198104858398438, 'eval_loss_4': 0.05612163990736008, 'epoch': 5.15}
{'loss': 0.0293, 'grad_norm': 6.403217315673828, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.021919861435890198, 'loss_2': 0.007396697998046875, 'loss_3': -16.31685447692871, 'loss_4': -0.12141233682632446, 'epoch': 5.15}
{'loss': 0.0347, 'grad_norm': 9.861200332641602, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.027306945994496346, 'loss_2': 0.00739288330078125, 'loss_3': -16.200923919677734, 'loss_4': 0.22743985056877136, 'epoch': 5.16}
{'loss': 0.045, 'grad_norm': 16.431428909301758, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.03197989985346794, 'loss_2': 0.01306915283203125, 'loss_3': -16.13628578186035, 'loss_4': 0.28863370418548584, 'epoch': 5.16}
{'loss': 0.0232, 'grad_norm': 7.303474426269531, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.019221985712647438, 'loss_2': 0.003986358642578125, 'loss_3': -16.20843505859375, 'loss_4': 0.5104043483734131, 'epoch': 5.17}
{'loss': 0.0249, 'grad_norm': 6.596826553344727, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.01860921084880829, 'loss_2': 0.0063018798828125, 'loss_3': -16.02355194091797, 'loss_4': -0.00046250224113464355, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 15:39:55,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:55,936 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:34<1:13:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:03,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026088029146194458, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.442, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.023230914026498795, 'eval_loss_2': 0.002857118844985962, 'eval_loss_3': -18.25435447692871, 'eval_loss_4': 0.04977044090628624, 'epoch': 5.17}
{'loss': 0.0388, 'grad_norm': 16.974590301513672, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.032805927097797394, 'loss_2': 0.00598907470703125, 'loss_3': -15.993188858032227, 'loss_4': 0.21144619584083557, 'epoch': 5.18}
{'loss': 0.0439, 'grad_norm': 12.826077461242676, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.03425134718418121, 'loss_2': 0.00963592529296875, 'loss_3': -16.21918487548828, 'loss_4': 0.0043054670095443726, 'epoch': 5.19}
{'loss': 0.0251, 'grad_norm': 6.193223476409912, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.015090336091816425, 'loss_2': 0.01003265380859375, 'loss_3': -16.138288497924805, 'loss_4': 0.003332369029521942, 'epoch': 5.19}
{'loss': 0.0216, 'grad_norm': 7.701918125152588, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.01614576019346714, 'loss_2': 0.00543975830078125, 'loss_3': -16.159839630126953, 'loss_4': 0.050101906061172485, 'epoch': 5.2}
{'loss': 0.0176, 'grad_norm': 6.2248854637146, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.014183935709297657, 'loss_2': 0.00342559814453125, 'loss_3': -16.330469131469727, 'loss_4': -0.08058490604162216, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 15:40:03,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:03,301 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:41<1:13:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:10,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022375524044036865, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.019608942791819572, 'eval_loss_2': 0.0027665793895721436, 'eval_loss_3': -18.313705444335938, 'eval_loss_4': -0.006182163022458553, 'epoch': 5.2}
{'loss': 0.0492, 'grad_norm': 13.667841911315918, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.04489569738507271, 'loss_2': 0.00434112548828125, 'loss_3': -16.00882911682129, 'loss_4': 0.32528138160705566, 'epoch': 5.21}
{'loss': 0.1508, 'grad_norm': 23.65762710571289, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.14359606802463531, 'loss_2': 0.00722503662109375, 'loss_3': -16.237762451171875, 'loss_4': 1.0293004512786865, 'epoch': 5.22}
{'loss': 0.0182, 'grad_norm': 6.073385715484619, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.016793953254818916, 'loss_2': 0.0014171600341796875, 'loss_3': -16.173166275024414, 'loss_4': 0.06597830355167389, 'epoch': 5.22}
{'loss': 0.0349, 'grad_norm': 11.618029594421387, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.03072509542107582, 'loss_2': 0.00417327880859375, 'loss_3': -15.97953987121582, 'loss_4': 0.31397348642349243, 'epoch': 5.23}
{'loss': 0.0344, 'grad_norm': 12.250638961791992, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.033754024654626846, 'loss_2': 0.0006513595581054688, 'loss_3': -16.158042907714844, 'loss_4': 0.2554771304130554, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 15:40:10,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:10,661 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:48<1:13:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:18,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018210627138614655, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016731394454836845, 'eval_loss_2': 0.00147923082113266, 'eval_loss_3': -18.30426597595215, 'eval_loss_4': -0.14234988391399384, 'epoch': 5.23}
{'loss': 0.0277, 'grad_norm': 7.825982093811035, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.024623144418001175, 'loss_2': 0.003032684326171875, 'loss_3': -16.09678840637207, 'loss_4': 0.36551791429519653, 'epoch': 5.24}
{'loss': 0.0243, 'grad_norm': 6.003839492797852, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.014836051501333714, 'loss_2': 0.0094146728515625, 'loss_3': -16.05739974975586, 'loss_4': -0.07873491942882538, 'epoch': 5.24}
{'loss': 0.0205, 'grad_norm': 6.950318813323975, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.01565791852772236, 'loss_2': 0.00489044189453125, 'loss_3': -16.109909057617188, 'loss_4': -0.229188472032547, 'epoch': 5.25}
{'loss': 0.0984, 'grad_norm': 31.104507446289062, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.09061452746391296, 'loss_2': 0.007781982421875, 'loss_3': -16.165693283081055, 'loss_4': 0.23622500896453857, 'epoch': 5.26}
{'loss': 0.0353, 'grad_norm': 13.751291275024414, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.032143183052539825, 'loss_2': 0.00312042236328125, 'loss_3': -16.144012451171875, 'loss_4': -0.02567252516746521, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 15:40:18,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:18,016 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:56<1:13:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:25,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021607697010040283, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.235, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018615784123539925, 'eval_loss_2': 0.002991914749145508, 'eval_loss_3': -18.27545166015625, 'eval_loss_4': -0.37157419323921204, 'epoch': 5.26}
{'loss': 0.0289, 'grad_norm': 9.659323692321777, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.024739796295762062, 'loss_2': 0.004184722900390625, 'loss_3': -15.971996307373047, 'loss_4': -0.5425914525985718, 'epoch': 5.27}
{'loss': 0.038, 'grad_norm': 17.81483268737793, 'learning_rate': 2.475e-05, 'loss_1': 0.028559120371937752, 'loss_2': 0.00946044921875, 'loss_3': -15.910978317260742, 'loss_4': -0.1175645962357521, 'epoch': 5.27}
{'loss': 0.0184, 'grad_norm': 6.982902526855469, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.01515870075672865, 'loss_2': 0.003269195556640625, 'loss_3': -16.07797622680664, 'loss_4': -0.1828950047492981, 'epoch': 5.28}
{'loss': 0.0347, 'grad_norm': 17.071374893188477, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.03105863742530346, 'loss_2': 0.0036754608154296875, 'loss_3': -16.16865348815918, 'loss_4': -0.3668448328971863, 'epoch': 5.28}
{'loss': 0.0246, 'grad_norm': 9.89484977722168, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.020303942263126373, 'loss_2': 0.00432586669921875, 'loss_3': -16.113727569580078, 'loss_4': -0.24830307066440582, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 15:40:25,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:25,374 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [23:03<1:13:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:32,733 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020551137626171112, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01683191768825054, 'eval_loss_2': 0.003719218075275421, 'eval_loss_3': -18.267391204833984, 'eval_loss_4': -0.3554609715938568, 'epoch': 5.29}
{'loss': 0.0202, 'grad_norm': 6.44189977645874, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.01617281511425972, 'loss_2': 0.00399017333984375, 'loss_3': -16.137531280517578, 'loss_4': -0.059682976454496384, 'epoch': 5.3}
{'loss': 0.0884, 'grad_norm': 22.238224029541016, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.08378785103559494, 'loss_2': 0.004627227783203125, 'loss_3': -16.00495147705078, 'loss_4': -0.13150721788406372, 'epoch': 5.3}
{'loss': 0.0212, 'grad_norm': 6.468437671661377, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.019090062007308006, 'loss_2': 0.0020656585693359375, 'loss_3': -16.039335250854492, 'loss_4': 0.031320810317993164, 'epoch': 5.31}
{'loss': 0.0174, 'grad_norm': 6.285604476928711, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.010447020642459393, 'loss_2': 0.0069122314453125, 'loss_3': -16.09778594970703, 'loss_4': -0.1477593332529068, 'epoch': 5.31}
{'loss': 0.0313, 'grad_norm': 12.352319717407227, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.018147964030504227, 'loss_2': 0.01316070556640625, 'loss_3': -16.28204917907715, 'loss_4': 0.04453801363706589, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 15:40:32,733 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:32,733 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:10<1:13:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:40,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02763165906071663, 'eval_runtime': 3.8187, 'eval_samples_per_second': 268.151, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.019127266481518745, 'eval_loss_2': 0.008504390716552734, 'eval_loss_3': -18.276371002197266, 'eval_loss_4': -0.2950993478298187, 'epoch': 5.32}
{'loss': 0.025, 'grad_norm': 6.484352111816406, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.014206793159246445, 'loss_2': 0.01084136962890625, 'loss_3': -16.2479248046875, 'loss_4': -0.29835161566734314, 'epoch': 5.33}
{'loss': 0.0376, 'grad_norm': 10.541985511779785, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.022546084597706795, 'loss_2': 0.01503753662109375, 'loss_3': -16.145320892333984, 'loss_4': -0.07989417016506195, 'epoch': 5.33}
{'loss': 0.0251, 'grad_norm': 6.817843437194824, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.019308093935251236, 'loss_2': 0.005802154541015625, 'loss_3': -16.16139793395996, 'loss_4': -0.2849315106868744, 'epoch': 5.34}
{'loss': 0.0309, 'grad_norm': 9.813148498535156, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.025426624342799187, 'loss_2': 0.00550079345703125, 'loss_3': -16.258737564086914, 'loss_4': -0.5332148671150208, 'epoch': 5.34}
{'loss': 0.0164, 'grad_norm': 4.925415515899658, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.012319003231823444, 'loss_2': 0.004058837890625, 'loss_3': -16.014699935913086, 'loss_4': -0.09578636288642883, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 15:40:40,104 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:40,104 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:18<1:13:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:47,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02228941209614277, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.818, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017783300951123238, 'eval_loss_2': 0.004506111145019531, 'eval_loss_3': -18.300683975219727, 'eval_loss_4': -0.3430638611316681, 'epoch': 5.35}
{'loss': 0.0219, 'grad_norm': 8.33161449432373, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.019939934834837914, 'loss_2': 0.001918792724609375, 'loss_3': -16.16158676147461, 'loss_4': 0.21771091222763062, 'epoch': 5.35}
{'loss': 0.0299, 'grad_norm': 10.55941104888916, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.022336319088935852, 'loss_2': 0.00753021240234375, 'loss_3': -16.1486873626709, 'loss_4': -0.32248273491859436, 'epoch': 5.36}
{'loss': 0.0212, 'grad_norm': 9.944549560546875, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.019749801605939865, 'loss_2': 0.00144195556640625, 'loss_3': -16.091899871826172, 'loss_4': 0.27309173345565796, 'epoch': 5.37}
{'loss': 0.0185, 'grad_norm': 7.553266525268555, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.016121895983815193, 'loss_2': 0.002349853515625, 'loss_3': -16.110910415649414, 'loss_4': -0.48094165325164795, 'epoch': 5.37}
{'loss': 0.0847, 'grad_norm': 16.429397583007812, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.08178424090147018, 'loss_2': 0.0029201507568359375, 'loss_3': -16.15292739868164, 'loss_4': -0.6400359869003296, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 15:40:47,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:47,463 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:25<1:13:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:54,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026711344718933105, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.019329192116856575, 'eval_loss_2': 0.00738215446472168, 'eval_loss_3': -18.299346923828125, 'eval_loss_4': -0.5040033459663391, 'epoch': 5.38}
{'loss': 0.0284, 'grad_norm': 9.420502662658691, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.021424081176519394, 'loss_2': 0.0069732666015625, 'loss_3': -16.149158477783203, 'loss_4': -0.5980681777000427, 'epoch': 5.38}
{'loss': 0.0206, 'grad_norm': 9.08544921875, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.01567043922841549, 'loss_2': 0.00489044189453125, 'loss_3': -16.194143295288086, 'loss_4': -0.5410982370376587, 'epoch': 5.39}
{'loss': 0.0189, 'grad_norm': 11.229804992675781, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.017370808869600296, 'loss_2': 0.0015306472778320312, 'loss_3': -16.398090362548828, 'loss_4': -0.6781941652297974, 'epoch': 5.4}
{'loss': 0.0184, 'grad_norm': 11.18952751159668, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.018317995592951775, 'loss_2': 3.4332275390625e-05, 'loss_3': -16.084766387939453, 'loss_4': -0.9203481674194336, 'epoch': 5.4}
{'loss': 0.0332, 'grad_norm': 8.634069442749023, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.025320811197161674, 'loss_2': 0.0078887939453125, 'loss_3': -16.21195411682129, 'loss_4': -0.016497544944286346, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 15:40:54,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:54,819 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:33<1:13:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:02,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026551133021712303, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.819, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0219582412391901, 'eval_loss_2': 0.0045928955078125, 'eval_loss_3': -18.317123413085938, 'eval_loss_4': -0.5022349953651428, 'epoch': 5.41}
{'loss': 0.0366, 'grad_norm': 7.73280143737793, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.021642012521624565, 'loss_2': 0.0149688720703125, 'loss_3': -15.994016647338867, 'loss_4': -0.5697848796844482, 'epoch': 5.41}
{'loss': 0.0262, 'grad_norm': 7.345608234405518, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.01574268937110901, 'loss_2': 0.01050567626953125, 'loss_3': -16.214214324951172, 'loss_4': -0.5348660945892334, 'epoch': 5.42}
{'loss': 0.0277, 'grad_norm': 9.479022979736328, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.021738599985837936, 'loss_2': 0.0059356689453125, 'loss_3': -16.068286895751953, 'loss_4': -0.3926452100276947, 'epoch': 5.42}
{'loss': 0.0235, 'grad_norm': 7.007049560546875, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.013808785937726498, 'loss_2': 0.009674072265625, 'loss_3': -16.212646484375, 'loss_4': -0.22942094504833221, 'epoch': 5.43}
{'loss': 0.0314, 'grad_norm': 11.8809814453125, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.025839202105998993, 'loss_2': 0.005596160888671875, 'loss_3': -16.25924301147461, 'loss_4': -0.42689627408981323, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 15:41:02,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:02,178 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:40<1:13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:09,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028092214837670326, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.156, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.024444350972771645, 'eval_loss_2': 0.0036478638648986816, 'eval_loss_3': -18.3231201171875, 'eval_loss_4': -0.5771954655647278, 'epoch': 5.44}
{'loss': 0.0391, 'grad_norm': 15.862588882446289, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.03716612979769707, 'loss_2': 0.0019197463989257812, 'loss_3': -16.00860595703125, 'loss_4': -0.43849682807922363, 'epoch': 5.44}
{'loss': 0.0131, 'grad_norm': 7.32957649230957, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.012646285817027092, 'loss_2': 0.0004763603210449219, 'loss_3': -16.186431884765625, 'loss_4': -0.4331854581832886, 'epoch': 5.45}
{'loss': 0.0314, 'grad_norm': 11.878568649291992, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.02308138646185398, 'loss_2': 0.0083160400390625, 'loss_3': -16.287174224853516, 'loss_4': -0.7283484935760498, 'epoch': 5.45}
{'loss': 0.0269, 'grad_norm': 8.807040214538574, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.022608604282140732, 'loss_2': 0.004329681396484375, 'loss_3': -16.17331886291504, 'loss_4': -0.4531818926334381, 'epoch': 5.46}
{'loss': 0.0355, 'grad_norm': 7.164648056030273, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.018949026241898537, 'loss_2': 0.016571044921875, 'loss_3': -16.436748504638672, 'loss_4': -0.7576082944869995, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 15:41:09,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:09,535 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:47<1:13:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:16,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04975612834095955, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.906, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04594019427895546, 'eval_loss_2': 0.0038159415125846863, 'eval_loss_3': -18.2163028717041, 'eval_loss_4': -0.5090585350990295, 'epoch': 5.47}
{'loss': 0.0141, 'grad_norm': 5.90378475189209, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.013737075962126255, 'loss_2': 0.0004036426544189453, 'loss_3': -16.212873458862305, 'loss_4': -0.525153636932373, 'epoch': 5.47}
{'loss': 0.0197, 'grad_norm': 7.1748046875, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.0128640690818429, 'loss_2': 0.0068511962890625, 'loss_3': -16.0281982421875, 'loss_4': -0.49815627932548523, 'epoch': 5.48}
{'loss': 0.0485, 'grad_norm': 22.64698028564453, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.042645711451768875, 'loss_2': 0.005828857421875, 'loss_3': -16.251996994018555, 'loss_4': -0.0989140123128891, 'epoch': 5.48}
{'loss': 0.0146, 'grad_norm': 5.383538246154785, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.012179834768176079, 'loss_2': 0.00246429443359375, 'loss_3': -16.40471649169922, 'loss_4': -0.14114610850811005, 'epoch': 5.49}
{'loss': 0.0234, 'grad_norm': 10.564278602600098, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.020721998065710068, 'loss_2': 0.002689361572265625, 'loss_3': -16.457378387451172, 'loss_4': -0.5087844133377075, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 15:41:16,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:16,908 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:55<1:13:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:24,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05936026945710182, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.815, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.056018002331256866, 'eval_loss_2': 0.0033422671258449554, 'eval_loss_3': -18.18349838256836, 'eval_loss_4': -0.22985729575157166, 'epoch': 5.49}
{'loss': 0.0175, 'grad_norm': 7.126352787017822, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.01689852960407734, 'loss_2': 0.0006361007690429688, 'loss_3': -16.36691665649414, 'loss_4': -0.011013872921466827, 'epoch': 5.5}
{'loss': 0.0368, 'grad_norm': 15.832304954528809, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.036241814494132996, 'loss_2': 0.000537872314453125, 'loss_3': -16.210723876953125, 'loss_4': -0.2539973258972168, 'epoch': 5.51}
{'loss': 0.0146, 'grad_norm': 7.122984886169434, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.014279483817517757, 'loss_2': 0.0003056526184082031, 'loss_3': -16.31548500061035, 'loss_4': -0.3711751103401184, 'epoch': 5.51}
{'loss': 0.0832, 'grad_norm': 20.0161190032959, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.0797712653875351, 'loss_2': 0.003452301025390625, 'loss_3': -15.979333877563477, 'loss_4': -0.4435172975063324, 'epoch': 5.52}
{'loss': 0.078, 'grad_norm': 14.437965393066406, 'learning_rate': 2.45e-05, 'loss_1': 0.07143466174602509, 'loss_2': 0.00659942626953125, 'loss_3': -16.359329223632812, 'loss_4': -0.12424840778112411, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 15:41:24,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:24,272 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [24:02<1:12:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:31,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033581338822841644, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.602, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.025671420618891716, 'eval_loss_2': 0.007909923791885376, 'eval_loss_3': -18.302410125732422, 'eval_loss_4': -0.44208839535713196, 'epoch': 5.52}
{'loss': 0.0682, 'grad_norm': 26.870471954345703, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.058458250015974045, 'loss_2': 0.0097503662109375, 'loss_3': -16.354736328125, 'loss_4': 0.1437877118587494, 'epoch': 5.53}
{'loss': 0.0413, 'grad_norm': 14.037364959716797, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.03830535709857941, 'loss_2': 0.00299835205078125, 'loss_3': -16.14459991455078, 'loss_4': -0.2652820944786072, 'epoch': 5.53}
{'loss': 0.0166, 'grad_norm': 5.870169162750244, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.013272764161229134, 'loss_2': 0.003314971923828125, 'loss_3': -16.103071212768555, 'loss_4': -0.33487606048583984, 'epoch': 5.54}
{'loss': 0.0417, 'grad_norm': 9.873784065246582, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.025872139260172844, 'loss_2': 0.01580810546875, 'loss_3': -16.176349639892578, 'loss_4': -0.36423414945602417, 'epoch': 5.55}
{'loss': 0.0171, 'grad_norm': 6.8140869140625, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.014487466774880886, 'loss_2': 0.0025634765625, 'loss_3': -16.57857322692871, 'loss_4': -0.008649997413158417, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 15:41:31,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:31,617 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:09<1:12:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:38,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025610007345676422, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.268, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018012680113315582, 'eval_loss_2': 0.00759732723236084, 'eval_loss_3': -18.370468139648438, 'eval_loss_4': -0.3984132409095764, 'epoch': 5.55}
{'loss': 0.0151, 'grad_norm': 5.1617431640625, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.009528342634439468, 'loss_2': 0.00559234619140625, 'loss_3': -16.098718643188477, 'loss_4': -0.37568971514701843, 'epoch': 5.56}
{'loss': 0.0194, 'grad_norm': 5.7207560539245605, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.013261920772492886, 'loss_2': 0.006145477294921875, 'loss_3': -16.435626983642578, 'loss_4': -0.051581308245658875, 'epoch': 5.56}
{'loss': 0.0263, 'grad_norm': 9.64136028289795, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.024589059874415398, 'loss_2': 0.0016918182373046875, 'loss_3': -16.328264236450195, 'loss_4': 0.19403667747974396, 'epoch': 5.57}
{'loss': 0.0179, 'grad_norm': 6.50636625289917, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.014087202027440071, 'loss_2': 0.0038623809814453125, 'loss_3': -16.11320686340332, 'loss_4': 0.07450661808252335, 'epoch': 5.58}
{'loss': 0.0367, 'grad_norm': 18.76291847229004, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.030972419306635857, 'loss_2': 0.005767822265625, 'loss_3': -16.22089385986328, 'loss_4': 0.03595873713493347, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 15:41:38,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:38,975 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:17<1:13:35,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:41:46,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02541874721646309, 'eval_runtime': 3.9871, 'eval_samples_per_second': 256.828, 'eval_steps_per_second': 4.013, 'eval_loss_1': 0.013684023171663284, 'eval_loss_2': 0.011734724044799805, 'eval_loss_3': -18.442089080810547, 'eval_loss_4': -0.061606720089912415, 'epoch': 5.58}
{'loss': 0.0379, 'grad_norm': 7.55450439453125, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.023189358413219452, 'loss_2': 0.01470184326171875, 'loss_3': -16.36410140991211, 'loss_4': 0.9814066886901855, 'epoch': 5.59}
{'loss': 0.0378, 'grad_norm': 11.060983657836914, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.025707129389047623, 'loss_2': 0.01206207275390625, 'loss_3': -16.166576385498047, 'loss_4': 0.7967206239700317, 'epoch': 5.59}
{'loss': 0.043, 'grad_norm': 9.690263748168945, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.030290111899375916, 'loss_2': 0.012664794921875, 'loss_3': -16.221363067626953, 'loss_4': 0.25938260555267334, 'epoch': 5.6}
{'loss': 0.0575, 'grad_norm': 15.450552940368652, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.03960500657558441, 'loss_2': 0.0179443359375, 'loss_3': -16.192310333251953, 'loss_4': 0.4508291184902191, 'epoch': 5.6}
{'loss': 0.0642, 'grad_norm': 14.40873908996582, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.04621703550219536, 'loss_2': 0.0180206298828125, 'loss_3': -16.209625244140625, 'loss_4': 0.2465612292289734, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 15:41:46,514 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:46,514 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:24<1:12:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:53,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02573716640472412, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.531, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.014060853980481625, 'eval_loss_2': 0.011676311492919922, 'eval_loss_3': -18.435405731201172, 'eval_loss_4': -0.05730833858251572, 'epoch': 5.61}
{'loss': 0.0257, 'grad_norm': 6.407619476318359, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.019650785252451897, 'loss_2': 0.00604248046875, 'loss_3': -16.22028923034668, 'loss_4': 0.26363012194633484, 'epoch': 5.62}
{'loss': 0.034, 'grad_norm': 7.810025691986084, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.022920401766896248, 'loss_2': 0.01104736328125, 'loss_3': -16.280757904052734, 'loss_4': 0.24287399649620056, 'epoch': 5.62}
{'loss': 0.0312, 'grad_norm': 10.454168319702148, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.024067005142569542, 'loss_2': 0.007106781005859375, 'loss_3': -16.18682861328125, 'loss_4': 0.5647116303443909, 'epoch': 5.63}
{'loss': 0.0251, 'grad_norm': 8.816489219665527, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.01760184019804001, 'loss_2': 0.00751495361328125, 'loss_3': -16.206987380981445, 'loss_4': 0.05299048125743866, 'epoch': 5.63}
{'loss': 0.0248, 'grad_norm': 8.520829200744629, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.022940441966056824, 'loss_2': 0.0018768310546875, 'loss_3': -16.20030403137207, 'loss_4': 0.2242097109556198, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 15:41:53,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:53,881 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:32<1:12:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:01,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02014877274632454, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.989, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014242966659367085, 'eval_loss_2': 0.005905807018280029, 'eval_loss_3': -18.441877365112305, 'eval_loss_4': 0.01477353647351265, 'epoch': 5.64}
{'loss': 0.0781, 'grad_norm': 23.453798294067383, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.06975648552179337, 'loss_2': 0.00836944580078125, 'loss_3': -16.25130844116211, 'loss_4': 0.5113074779510498, 'epoch': 5.65}
{'loss': 0.0773, 'grad_norm': 18.359180450439453, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.05950535833835602, 'loss_2': 0.0177459716796875, 'loss_3': -16.286968231201172, 'loss_4': 0.7892216444015503, 'epoch': 5.65}
{'loss': 0.0581, 'grad_norm': 14.852400779724121, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.0406758151948452, 'loss_2': 0.01739501953125, 'loss_3': -16.486446380615234, 'loss_4': 0.7160676717758179, 'epoch': 5.66}
{'loss': 0.04, 'grad_norm': 13.388619422912598, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.027646753937005997, 'loss_2': 0.01232147216796875, 'loss_3': -16.21729850769043, 'loss_4': 0.19403895735740662, 'epoch': 5.66}
{'loss': 0.0496, 'grad_norm': 11.30611515045166, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.03779733553528786, 'loss_2': 0.01175689697265625, 'loss_3': -16.243253707885742, 'loss_4': 0.35891789197921753, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 15:42:01,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:01,242 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:39<1:12:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:08,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03289179503917694, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014766257256269455, 'eval_loss_2': 0.018125534057617188, 'eval_loss_3': -18.423791885375977, 'eval_loss_4': 0.003667861223220825, 'epoch': 5.67}
{'loss': 0.0961, 'grad_norm': 23.36529541015625, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.07626712322235107, 'loss_2': 0.0197906494140625, 'loss_3': -16.30714225769043, 'loss_4': 0.43014535307884216, 'epoch': 5.67}
{'loss': 0.0416, 'grad_norm': 8.4755277633667, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.021870732307434082, 'loss_2': 0.0196990966796875, 'loss_3': -16.33147430419922, 'loss_4': -0.16849300265312195, 'epoch': 5.68}
{'loss': 0.0596, 'grad_norm': 16.788206100463867, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.04730553925037384, 'loss_2': 0.0122833251953125, 'loss_3': -16.035831451416016, 'loss_4': -0.536567211151123, 'epoch': 5.69}
{'loss': 0.0602, 'grad_norm': 16.789318084716797, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.039883192628622055, 'loss_2': 0.020355224609375, 'loss_3': -16.359176635742188, 'loss_4': 0.15240858495235443, 'epoch': 5.69}
{'loss': 0.0501, 'grad_norm': 14.439035415649414, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.032897498458623886, 'loss_2': 0.017242431640625, 'loss_3': -16.26905059814453, 'loss_4': 0.21062876284122467, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 15:42:08,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:08,602 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:46<1:12:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:15,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02468501590192318, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.973, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014290740713477135, 'eval_loss_2': 0.010394275188446045, 'eval_loss_3': -18.380464553833008, 'eval_loss_4': -0.17984530329704285, 'epoch': 5.7}
{'loss': 0.0334, 'grad_norm': 8.916600227355957, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.02570607326924801, 'loss_2': 0.00771331787109375, 'loss_3': -16.170690536499023, 'loss_4': 0.11435994505882263, 'epoch': 5.7}
{'loss': 0.0245, 'grad_norm': 7.8899335861206055, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.019771847873926163, 'loss_2': 0.0047454833984375, 'loss_3': -16.177438735961914, 'loss_4': 0.22711549699306488, 'epoch': 5.71}
{'loss': 0.0403, 'grad_norm': 12.828186988830566, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.028566986322402954, 'loss_2': 0.0117340087890625, 'loss_3': -16.144882202148438, 'loss_4': -0.4418565630912781, 'epoch': 5.72}
{'loss': 0.039, 'grad_norm': 18.971220016479492, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.03352118656039238, 'loss_2': 0.005466461181640625, 'loss_3': -16.33350372314453, 'loss_4': -0.1723146140575409, 'epoch': 5.72}
{'loss': 0.0428, 'grad_norm': 13.132123947143555, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.030461011454463005, 'loss_2': 0.01229095458984375, 'loss_3': -16.096588134765625, 'loss_4': 0.01185603067278862, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 15:42:15,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:15,968 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:54<1:12:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:23,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020140554755926132, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01296266634017229, 'eval_loss_2': 0.007177889347076416, 'eval_loss_3': -18.34577751159668, 'eval_loss_4': -0.341581791639328, 'epoch': 5.73}
{'loss': 0.0137, 'grad_norm': 6.073371410369873, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.011785761453211308, 'loss_2': 0.0018672943115234375, 'loss_3': -16.226247787475586, 'loss_4': 0.2315257042646408, 'epoch': 5.73}
{'loss': 0.0288, 'grad_norm': 14.07129192352295, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.02101760543882847, 'loss_2': 0.0077667236328125, 'loss_3': -16.248062133789062, 'loss_4': -0.024919748306274414, 'epoch': 5.74}
{'loss': 0.0195, 'grad_norm': 8.010332107543945, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.014185016974806786, 'loss_2': 0.005321502685546875, 'loss_3': -16.195110321044922, 'loss_4': -0.5094770193099976, 'epoch': 5.74}
{'loss': 0.0176, 'grad_norm': 5.1132941246032715, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.008509866893291473, 'loss_2': 0.00905609130859375, 'loss_3': -16.201725006103516, 'loss_4': 0.16972965002059937, 'epoch': 5.75}
{'loss': 0.0342, 'grad_norm': 19.11474609375, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.02926301397383213, 'loss_2': 0.00496673583984375, 'loss_3': -16.20311164855957, 'loss_4': 0.031704388558864594, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 15:42:23,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:23,326 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [25:01<1:12:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:30,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01992928236722946, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.095, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01541900634765625, 'eval_loss_2': 0.004510276019573212, 'eval_loss_3': -18.314538955688477, 'eval_loss_4': -0.3045782744884491, 'epoch': 5.76}
{'loss': 0.0491, 'grad_norm': 11.460497856140137, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.039727263152599335, 'loss_2': 0.0093841552734375, 'loss_3': -16.269807815551758, 'loss_4': -0.5269985198974609, 'epoch': 5.76}
{'loss': 0.011, 'grad_norm': 6.045471668243408, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.010602930560708046, 'loss_2': 0.00041675567626953125, 'loss_3': -16.160865783691406, 'loss_4': -0.39777904748916626, 'epoch': 5.77}
{'loss': 0.0281, 'grad_norm': 11.63906192779541, 'learning_rate': 2.425e-05, 'loss_1': 0.02686421573162079, 'loss_2': 0.001255035400390625, 'loss_3': -16.294170379638672, 'loss_4': -0.10783930122852325, 'epoch': 5.77}
{'loss': 0.0149, 'grad_norm': 7.338123321533203, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.013734761625528336, 'loss_2': 0.0011577606201171875, 'loss_3': -16.152446746826172, 'loss_4': -0.38440605998039246, 'epoch': 5.78}
{'loss': 0.0204, 'grad_norm': 6.660778045654297, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.01533213909715414, 'loss_2': 0.00502777099609375, 'loss_3': -16.043790817260742, 'loss_4': -0.27167025208473206, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 15:42:30,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:30,688 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [25:08<1:12:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:38,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019369397312402725, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.818, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.016206536442041397, 'eval_loss_2': 0.003162860870361328, 'eval_loss_3': -18.28044891357422, 'eval_loss_4': -0.25081029534339905, 'epoch': 5.78}
{'loss': 0.04, 'grad_norm': 11.681300163269043, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.029884636402130127, 'loss_2': 0.010101318359375, 'loss_3': -16.101499557495117, 'loss_4': -0.15032100677490234, 'epoch': 5.79}
{'loss': 0.0155, 'grad_norm': 5.747544765472412, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.011349868960678577, 'loss_2': 0.004138946533203125, 'loss_3': -15.885751724243164, 'loss_4': -0.2652420997619629, 'epoch': 5.8}
{'loss': 0.0257, 'grad_norm': 23.413490295410156, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.025477571412920952, 'loss_2': 0.0002073049545288086, 'loss_3': -16.10248374938965, 'loss_4': -0.32845550775527954, 'epoch': 5.8}
{'loss': 0.0298, 'grad_norm': 14.212889671325684, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.022465156391263008, 'loss_2': 0.00733184814453125, 'loss_3': -16.126781463623047, 'loss_4': -0.03421073779463768, 'epoch': 5.81}
{'loss': 0.0191, 'grad_norm': 6.4201741218566895, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.013844749890267849, 'loss_2': 0.005268096923828125, 'loss_3': -16.17906379699707, 'loss_4': -0.37815308570861816, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 15:42:38,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:38,050 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:16<1:11:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:45,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018262580037117004, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.377, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013478982262313366, 'eval_loss_2': 0.004783600568771362, 'eval_loss_3': -18.308958053588867, 'eval_loss_4': -0.10637775808572769, 'epoch': 5.81}
{'loss': 0.0225, 'grad_norm': 7.543111801147461, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.018378011882305145, 'loss_2': 0.004146575927734375, 'loss_3': -16.280532836914062, 'loss_4': -0.48356425762176514, 'epoch': 5.82}
{'loss': 0.0487, 'grad_norm': 17.10478401184082, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.046043314039707184, 'loss_2': 0.0026607513427734375, 'loss_3': -16.15365982055664, 'loss_4': -0.23978197574615479, 'epoch': 5.83}
{'loss': 0.022, 'grad_norm': 6.693849086761475, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.019465727731585503, 'loss_2': 0.0025691986083984375, 'loss_3': -16.234607696533203, 'loss_4': -0.2445533573627472, 'epoch': 5.83}
{'loss': 0.0207, 'grad_norm': 6.075204849243164, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.010009318590164185, 'loss_2': 0.010711669921875, 'loss_3': -16.272701263427734, 'loss_4': 0.313845157623291, 'epoch': 5.84}
{'loss': 0.0253, 'grad_norm': 7.166288375854492, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.016429146751761436, 'loss_2': 0.008880615234375, 'loss_3': -16.281551361083984, 'loss_4': 0.047714851796627045, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 15:42:45,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:45,401 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:23<1:11:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:52,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019214626401662827, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.43, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012989876791834831, 'eval_loss_2': 0.0062247514724731445, 'eval_loss_3': -18.376113891601562, 'eval_loss_4': -0.09653570502996445, 'epoch': 5.84}
{'loss': 0.0374, 'grad_norm': 10.6760892868042, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.02860918827354908, 'loss_2': 0.00879669189453125, 'loss_3': -16.08275032043457, 'loss_4': 0.3645389676094055, 'epoch': 5.85}
{'loss': 0.0243, 'grad_norm': 7.105666637420654, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.01990109123289585, 'loss_2': 0.00439453125, 'loss_3': -16.197938919067383, 'loss_4': 0.21301206946372986, 'epoch': 5.85}
{'loss': 0.0365, 'grad_norm': 9.522587776184082, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.029773812741041183, 'loss_2': 0.0067291259765625, 'loss_3': -16.317977905273438, 'loss_4': -0.2757503092288971, 'epoch': 5.86}
{'loss': 0.0152, 'grad_norm': 6.003848552703857, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.012277350760996342, 'loss_2': 0.0029506683349609375, 'loss_3': -16.31361961364746, 'loss_4': 0.200129896402359, 'epoch': 5.87}
{'loss': 0.0489, 'grad_norm': 10.923789978027344, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.04614909738302231, 'loss_2': 0.0027065277099609375, 'loss_3': -16.328304290771484, 'loss_4': 0.2516617774963379, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 15:42:52,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:52,748 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:30<1:11:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:00,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01646542176604271, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.032, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01294909231364727, 'eval_loss_2': 0.00351632758975029, 'eval_loss_3': -18.401748657226562, 'eval_loss_4': -0.17125432193279266, 'epoch': 5.87}
{'loss': 0.016, 'grad_norm': 6.535203456878662, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.015791546553373337, 'loss_2': 0.00018334388732910156, 'loss_3': -16.191757202148438, 'loss_4': 0.45435693860054016, 'epoch': 5.88}
{'loss': 0.0327, 'grad_norm': 6.977965354919434, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.020041611045598984, 'loss_2': 0.0126800537109375, 'loss_3': -16.075138092041016, 'loss_4': -0.2240068018436432, 'epoch': 5.88}
{'loss': 0.018, 'grad_norm': 8.027233123779297, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.016380835324525833, 'loss_2': 0.0015993118286132812, 'loss_3': -16.256290435791016, 'loss_4': -0.25964152812957764, 'epoch': 5.89}
{'loss': 0.0304, 'grad_norm': 13.961505889892578, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.02960798516869545, 'loss_2': 0.0007791519165039062, 'loss_3': -16.333621978759766, 'loss_4': 0.8065429925918579, 'epoch': 5.9}
{'loss': 0.0199, 'grad_norm': 9.203575134277344, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.01948467269539833, 'loss_2': 0.0004601478576660156, 'loss_3': -16.240337371826172, 'loss_4': 0.2637045979499817, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 15:43:00,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:00,112 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:38<1:11:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:07,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016158506274223328, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01272590458393097, 'eval_loss_2': 0.0034326016902923584, 'eval_loss_3': -18.411365509033203, 'eval_loss_4': -0.29027166962623596, 'epoch': 5.9}
{'loss': 0.047, 'grad_norm': 13.8485689163208, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.03696222975850105, 'loss_2': 0.010040283203125, 'loss_3': -16.04145050048828, 'loss_4': -0.33438053727149963, 'epoch': 5.91}
{'loss': 0.0634, 'grad_norm': 20.708965301513672, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.05531704053282738, 'loss_2': 0.0081024169921875, 'loss_3': -16.605205535888672, 'loss_4': 0.5909087657928467, 'epoch': 5.91}
{'loss': 0.0256, 'grad_norm': 7.381515979766846, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.018933912739157677, 'loss_2': 0.0067138671875, 'loss_3': -16.27532958984375, 'loss_4': -0.2643471956253052, 'epoch': 5.92}
{'loss': 0.0448, 'grad_norm': 15.02015209197998, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.04404154047369957, 'loss_2': 0.0007500648498535156, 'loss_3': -16.608430862426758, 'loss_4': -0.01739761233329773, 'epoch': 5.92}
{'loss': 0.0317, 'grad_norm': 9.072977066040039, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.030655531212687492, 'loss_2': 0.0010824203491210938, 'loss_3': -16.275211334228516, 'loss_4': 0.2603718340396881, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 15:43:07,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:07,468 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:45<1:11:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:14,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01661078818142414, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.7, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014152506366372108, 'eval_loss_2': 0.0024582818150520325, 'eval_loss_3': -18.40142250061035, 'eval_loss_4': -0.5648444890975952, 'epoch': 5.93}
{'loss': 0.0211, 'grad_norm': 9.85274887084961, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.02107786014676094, 'loss_2': 6.389617919921875e-05, 'loss_3': -16.59084701538086, 'loss_4': 0.07551512122154236, 'epoch': 5.94}
{'loss': 0.0139, 'grad_norm': 6.335382461547852, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.012428137473762035, 'loss_2': 0.001453399658203125, 'loss_3': -16.454776763916016, 'loss_4': -0.1729230284690857, 'epoch': 5.94}
{'loss': 0.0465, 'grad_norm': 11.021997451782227, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.0382269024848938, 'loss_2': 0.0082550048828125, 'loss_3': -16.488842010498047, 'loss_4': -0.5452126264572144, 'epoch': 5.95}
{'loss': 0.0431, 'grad_norm': 10.02393913269043, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.04175613820552826, 'loss_2': 0.001377105712890625, 'loss_3': -16.17483901977539, 'loss_4': -0.5505841970443726, 'epoch': 5.95}
{'loss': 0.028, 'grad_norm': 10.662144660949707, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.024961009621620178, 'loss_2': 0.0030269622802734375, 'loss_3': -16.382064819335938, 'loss_4': -0.6231918334960938, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 15:43:14,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:14,838 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:53<1:11:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:22,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02108551189303398, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015517186373472214, 'eval_loss_2': 0.005568325519561768, 'eval_loss_3': -18.35794448852539, 'eval_loss_4': -0.6480441689491272, 'epoch': 5.96}
{'loss': 0.0244, 'grad_norm': 7.449772834777832, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.021627385169267654, 'loss_2': 0.002750396728515625, 'loss_3': -16.299327850341797, 'loss_4': -0.2600691616535187, 'epoch': 5.97}
{'loss': 0.0348, 'grad_norm': 11.079622268676758, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.03428857773542404, 'loss_2': 0.0005426406860351562, 'loss_3': -16.432096481323242, 'loss_4': 0.1275286078453064, 'epoch': 5.97}
{'loss': 0.0491, 'grad_norm': 14.462448120117188, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.04213675484061241, 'loss_2': 0.0069732666015625, 'loss_3': -16.317676544189453, 'loss_4': -0.056337326765060425, 'epoch': 5.98}
{'loss': 0.0474, 'grad_norm': 14.326925277709961, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.04033760353922844, 'loss_2': 0.007106781005859375, 'loss_3': -16.36741828918457, 'loss_4': -0.40140312910079956, 'epoch': 5.98}
{'loss': 0.0161, 'grad_norm': 6.280846118927002, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.015219837427139282, 'loss_2': 0.0009236335754394531, 'loss_3': -16.226852416992188, 'loss_4': -0.7652159333229065, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 15:43:22,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:22,198 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [26:00<1:09:22,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 15:43:29,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018049724400043488, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.618, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013858207501471043, 'eval_loss_2': 0.0041915178298950195, 'eval_loss_3': -18.33405876159668, 'eval_loss_4': -0.5124411582946777, 'epoch': 5.99}
{'loss': 0.0316, 'grad_norm': 9.309248924255371, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.029722165316343307, 'loss_2': 0.0018520355224609375, 'loss_3': -16.16895294189453, 'loss_4': -0.19334664940834045, 'epoch': 5.99}
{'loss': 0.0268, 'grad_norm': 9.015162467956543, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.01551483292132616, 'loss_2': 0.011322021484375, 'loss_3': -15.993890762329102, 'loss_4': -1.077677845954895, 'epoch': 6.0}
{'loss': 0.0368, 'grad_norm': 10.852324485778809, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.031832072883844376, 'loss_2': 0.00492095947265625, 'loss_3': -16.31467628479004, 'loss_4': -0.4693804979324341, 'epoch': 6.01}
{'loss': 0.0574, 'grad_norm': 25.344104766845703, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.050944361835718155, 'loss_2': 0.00646209716796875, 'loss_3': -16.278305053710938, 'loss_4': -0.13240113854408264, 'epoch': 6.01}
{'loss': 0.0298, 'grad_norm': 8.401737213134766, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.028585676103830338, 'loss_2': 0.0012416839599609375, 'loss_3': -16.480051040649414, 'loss_4': 0.14584419131278992, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 15:43:29,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:29,235 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:07<1:10:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:43:36,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021149883046746254, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.56, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015680843964219093, 'eval_loss_2': 0.005469039082527161, 'eval_loss_3': -18.279905319213867, 'eval_loss_4': -0.3610219657421112, 'epoch': 6.02}
{'loss': 0.0229, 'grad_norm': 14.857487678527832, 'learning_rate': 2.4e-05, 'loss_1': 0.013880198821425438, 'loss_2': 0.0090179443359375, 'loss_3': -16.3416805267334, 'loss_4': -0.26238518953323364, 'epoch': 6.02}
{'loss': 0.027, 'grad_norm': 7.38304328918457, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.017946379259228706, 'loss_2': 0.00908660888671875, 'loss_3': -16.5040283203125, 'loss_4': -0.019435223191976547, 'epoch': 6.03}
{'loss': 0.0297, 'grad_norm': 11.610583305358887, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.027951166033744812, 'loss_2': 0.0017852783203125, 'loss_3': -16.34017562866211, 'loss_4': 0.21872180700302124, 'epoch': 6.03}
{'loss': 0.0186, 'grad_norm': 6.078420162200928, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.014466335996985435, 'loss_2': 0.0041351318359375, 'loss_3': -16.114620208740234, 'loss_4': -0.12358115613460541, 'epoch': 6.04}
{'loss': 0.0149, 'grad_norm': 7.21457576751709, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.01393426675349474, 'loss_2': 0.0009222030639648438, 'loss_3': -16.164196014404297, 'loss_4': 0.02381516993045807, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 15:43:36,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:36,581 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:14<1:11:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:43,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016335833817720413, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013103920966386795, 'eval_loss_2': 0.003231912851333618, 'eval_loss_3': -18.25621223449707, 'eval_loss_4': -0.335267573595047, 'epoch': 6.05}
{'loss': 0.0187, 'grad_norm': 7.357738971710205, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.016675550490617752, 'loss_2': 0.0020503997802734375, 'loss_3': -16.247169494628906, 'loss_4': -0.307878702878952, 'epoch': 6.05}
{'loss': 0.015, 'grad_norm': 5.98775577545166, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.013011666014790535, 'loss_2': 0.00196075439453125, 'loss_3': -16.207658767700195, 'loss_4': 0.0363955944776535, 'epoch': 6.06}
{'loss': 0.0298, 'grad_norm': 8.428858757019043, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.020797669887542725, 'loss_2': 0.00904083251953125, 'loss_3': -16.002275466918945, 'loss_4': -0.7437241077423096, 'epoch': 6.06}
{'loss': 0.0307, 'grad_norm': 8.715344429016113, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.018616674467921257, 'loss_2': 0.0120391845703125, 'loss_3': -16.284143447875977, 'loss_4': 0.009628742933273315, 'epoch': 6.07}
{'loss': 0.0506, 'grad_norm': 8.560139656066895, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.0298801027238369, 'loss_2': 0.0207366943359375, 'loss_3': -16.249656677246094, 'loss_4': -0.14336220920085907, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 15:43:43,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:43,931 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:22<1:11:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:51,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0326869860291481, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.105, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.02108142524957657, 'eval_loss_2': 0.011605560779571533, 'eval_loss_3': -18.202186584472656, 'eval_loss_4': -0.3247929811477661, 'epoch': 6.08}
{'loss': 0.0267, 'grad_norm': 7.525898456573486, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.019669555127620697, 'loss_2': 0.00705718994140625, 'loss_3': -16.16476058959961, 'loss_4': -0.37503576278686523, 'epoch': 6.08}
{'loss': 0.0256, 'grad_norm': 6.946597099304199, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.013789479620754719, 'loss_2': 0.01177978515625, 'loss_3': -16.027246475219727, 'loss_4': -0.5323719382286072, 'epoch': 6.09}
{'loss': 0.0334, 'grad_norm': 16.74864387512207, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.022100215777754784, 'loss_2': 0.0112762451171875, 'loss_3': -16.03240203857422, 'loss_4': -0.6225842237472534, 'epoch': 6.09}
{'loss': 0.0235, 'grad_norm': 14.431662559509277, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.02220955491065979, 'loss_2': 0.0013103485107421875, 'loss_3': -16.27457046508789, 'loss_4': 0.3113936483860016, 'epoch': 6.1}
{'loss': 0.0335, 'grad_norm': 9.694747924804688, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.018997404724359512, 'loss_2': 0.0145263671875, 'loss_3': -16.119874954223633, 'loss_4': -0.032212913036346436, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 15:43:51,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:51,286 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:29<1:11:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:58,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030963260680437088, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.585, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.026490798220038414, 'eval_loss_2': 0.004472464323043823, 'eval_loss_3': -18.144704818725586, 'eval_loss_4': -0.12290047109127045, 'epoch': 6.1}
{'loss': 0.0126, 'grad_norm': 5.526818752288818, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.00854516588151455, 'loss_2': 0.004055023193359375, 'loss_3': -16.13992691040039, 'loss_4': -0.08328418433666229, 'epoch': 6.11}
{'loss': 0.0239, 'grad_norm': 12.574305534362793, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.02339458279311657, 'loss_2': 0.0004711151123046875, 'loss_3': -16.158451080322266, 'loss_4': -0.23963414132595062, 'epoch': 6.12}
{'loss': 0.0217, 'grad_norm': 7.673208713531494, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.014636704698204994, 'loss_2': 0.0070343017578125, 'loss_3': -16.045289993286133, 'loss_4': 0.022885825484991074, 'epoch': 6.12}
{'loss': 0.0554, 'grad_norm': 17.7333984375, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.045610107481479645, 'loss_2': 0.00982666015625, 'loss_3': -16.23943519592285, 'loss_4': -0.39184796810150146, 'epoch': 6.13}
{'loss': 0.0288, 'grad_norm': 6.574166297912598, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.01521031279116869, 'loss_2': 0.01355743408203125, 'loss_3': -16.24624252319336, 'loss_4': -0.5140239000320435, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 15:43:58,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:58,651 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:36<1:11:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:06,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03382791206240654, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.019249213859438896, 'eval_loss_2': 0.014578700065612793, 'eval_loss_3': -18.18136215209961, 'eval_loss_4': -0.1737096905708313, 'epoch': 6.13}
{'loss': 0.02, 'grad_norm': 5.271691799163818, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.0053201960399746895, 'loss_2': 0.0146636962890625, 'loss_3': -16.199508666992188, 'loss_4': -0.1338042914867401, 'epoch': 6.14}
{'loss': 0.0301, 'grad_norm': 6.028415679931641, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.011713946238160133, 'loss_2': 0.0183563232421875, 'loss_3': -16.40564727783203, 'loss_4': -0.4312124252319336, 'epoch': 6.15}
{'loss': 0.0127, 'grad_norm': 5.469241142272949, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.008631683886051178, 'loss_2': 0.00402069091796875, 'loss_3': -16.23597526550293, 'loss_4': -0.35342639684677124, 'epoch': 6.15}
{'loss': 0.0229, 'grad_norm': 5.670464992523193, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.013098168186843395, 'loss_2': 0.0097808837890625, 'loss_3': -16.36753273010254, 'loss_4': 0.03551812469959259, 'epoch': 6.16}
{'loss': 0.0186, 'grad_norm': 7.418586730957031, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.017423328012228012, 'loss_2': 0.0011816024780273438, 'loss_3': -16.09286880493164, 'loss_4': -0.8125187158584595, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 15:44:06,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:06,011 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:44<1:10:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:13,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019588228315114975, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01539679802954197, 'eval_loss_2': 0.0041914284229278564, 'eval_loss_3': -18.235675811767578, 'eval_loss_4': -0.15019026398658752, 'epoch': 6.16}
{'loss': 0.0184, 'grad_norm': 6.8064727783203125, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.015709547325968742, 'loss_2': 0.002719879150390625, 'loss_3': -16.206789016723633, 'loss_4': -0.22100742161273956, 'epoch': 6.17}
{'loss': 0.042, 'grad_norm': 16.432863235473633, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.03760121762752533, 'loss_2': 0.00441741943359375, 'loss_3': -16.320627212524414, 'loss_4': -0.3898438513278961, 'epoch': 6.17}
{'loss': 0.0416, 'grad_norm': 11.81717586517334, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.033886540681123734, 'loss_2': 0.007701873779296875, 'loss_3': -16.187211990356445, 'loss_4': -0.1635488122701645, 'epoch': 6.18}
{'loss': 0.0603, 'grad_norm': 33.44806671142578, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.047219227999448776, 'loss_2': 0.01312255859375, 'loss_3': -16.252471923828125, 'loss_4': 0.27695465087890625, 'epoch': 6.19}
{'loss': 0.0247, 'grad_norm': 5.399458885192871, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.009130497463047504, 'loss_2': 0.01555633544921875, 'loss_3': -16.332561492919922, 'loss_4': -0.1348831057548523, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 15:44:13,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:13,362 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:51<1:10:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:20,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027985308319330215, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012703157030045986, 'eval_loss_2': 0.015282154083251953, 'eval_loss_3': -18.289749145507812, 'eval_loss_4': -0.06539560854434967, 'epoch': 6.19}
{'loss': 0.0582, 'grad_norm': 17.23932647705078, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.04525693133473396, 'loss_2': 0.01293182373046875, 'loss_3': -15.895797729492188, 'loss_4': -0.29621821641921997, 'epoch': 6.2}
{'loss': 0.0359, 'grad_norm': 6.005751132965088, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.01163722388446331, 'loss_2': 0.024261474609375, 'loss_3': -16.17908477783203, 'loss_4': 0.15009573101997375, 'epoch': 6.2}
{'loss': 0.0251, 'grad_norm': 5.7949018478393555, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.012233908288180828, 'loss_2': 0.01290130615234375, 'loss_3': -16.21371078491211, 'loss_4': -0.005324915051460266, 'epoch': 6.21}
{'loss': 0.0323, 'grad_norm': 7.605020999908447, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.014256216585636139, 'loss_2': 0.0180816650390625, 'loss_3': -16.234481811523438, 'loss_4': 0.5352297425270081, 'epoch': 6.22}
{'loss': 0.028, 'grad_norm': 5.431220054626465, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.008595279417932034, 'loss_2': 0.0193939208984375, 'loss_3': -16.188547134399414, 'loss_4': -0.2594577372074127, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 15:44:20,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:20,728 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:58<1:10:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:28,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019910428673028946, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011883621104061604, 'eval_loss_2': 0.008026808500289917, 'eval_loss_3': -18.28091812133789, 'eval_loss_4': 0.09031371772289276, 'epoch': 6.22}
{'loss': 0.0127, 'grad_norm': 4.998631477355957, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.008701585233211517, 'loss_2': 0.003955841064453125, 'loss_3': -16.240829467773438, 'loss_4': -0.07977530360221863, 'epoch': 6.23}
{'loss': 0.0327, 'grad_norm': 16.189125061035156, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.02848968468606472, 'loss_2': 0.004241943359375, 'loss_3': -16.16080093383789, 'loss_4': 0.8264939785003662, 'epoch': 6.23}
{'loss': 0.0107, 'grad_norm': 6.82059907913208, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.009746707044541836, 'loss_2': 0.00098419189453125, 'loss_3': -16.142391204833984, 'loss_4': 0.15653544664382935, 'epoch': 6.24}
{'loss': 0.0196, 'grad_norm': 5.750424385070801, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.013389409519731998, 'loss_2': 0.00616455078125, 'loss_3': -16.12015151977539, 'loss_4': -0.001141190528869629, 'epoch': 6.24}
{'loss': 0.0157, 'grad_norm': 5.542087554931641, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.010626288130879402, 'loss_2': 0.00507354736328125, 'loss_3': -16.252084732055664, 'loss_4': -0.1032492071390152, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 15:44:28,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:28,086 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [27:06<1:10:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:35,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025701627135276794, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.739, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.012612208724021912, 'eval_loss_2': 0.013089418411254883, 'eval_loss_3': -18.260902404785156, 'eval_loss_4': 0.07916644215583801, 'epoch': 6.25}
{'loss': 0.0227, 'grad_norm': 7.350915908813477, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.018408458679914474, 'loss_2': 0.00434112548828125, 'loss_3': -16.194072723388672, 'loss_4': 0.2923342287540436, 'epoch': 6.26}
{'loss': 0.0215, 'grad_norm': 8.11240005493164, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.013273789547383785, 'loss_2': 0.0082244873046875, 'loss_3': -15.952372550964355, 'loss_4': -0.3302317261695862, 'epoch': 6.26}
{'loss': 0.0231, 'grad_norm': 6.147256851196289, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.012613230384886265, 'loss_2': 0.0105133056640625, 'loss_3': -16.30708885192871, 'loss_4': 0.3976750373840332, 'epoch': 6.27}
{'loss': 0.0235, 'grad_norm': 5.610388278961182, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.008882693015038967, 'loss_2': 0.0146484375, 'loss_3': -16.3173828125, 'loss_4': 0.27937981486320496, 'epoch': 6.27}
{'loss': 0.0314, 'grad_norm': 8.542497634887695, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.020519601181149483, 'loss_2': 0.0109100341796875, 'loss_3': -16.1066837310791, 'loss_4': 0.44774603843688965, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 15:44:35,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:35,463 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:13<1:10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:42,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021775074303150177, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01398450881242752, 'eval_loss_2': 0.007790565490722656, 'eval_loss_3': -18.227994918823242, 'eval_loss_4': 0.256404846906662, 'epoch': 6.28}
{'loss': 0.0317, 'grad_norm': 14.239079475402832, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.026702387258410454, 'loss_2': 0.00501251220703125, 'loss_3': -16.18039321899414, 'loss_4': 0.5218291878700256, 'epoch': 6.28}
{'loss': 0.0136, 'grad_norm': 5.556812286376953, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.008899099193513393, 'loss_2': 0.004726409912109375, 'loss_3': -16.322429656982422, 'loss_4': 0.08413457125425339, 'epoch': 6.29}
{'loss': 0.0249, 'grad_norm': 8.368142127990723, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.02292710915207863, 'loss_2': 0.001956939697265625, 'loss_3': -16.29993438720703, 'loss_4': 0.40348881483078003, 'epoch': 6.3}
{'loss': 0.023, 'grad_norm': 12.470681190490723, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.02030339278280735, 'loss_2': 0.0027008056640625, 'loss_3': -16.075851440429688, 'loss_4': -0.07278703898191452, 'epoch': 6.3}
{'loss': 0.0372, 'grad_norm': 14.64922046661377, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.02918776124715805, 'loss_2': 0.00798797607421875, 'loss_3': -16.044113159179688, 'loss_4': 0.5656560063362122, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 15:44:42,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:42,819 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:21<1:10:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:50,176 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017057135701179504, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.939, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01450134627521038, 'eval_loss_2': 0.0025557875633239746, 'eval_loss_3': -18.217287063598633, 'eval_loss_4': 0.27870091795921326, 'epoch': 6.31}
{'loss': 0.0824, 'grad_norm': 28.15180206298828, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.07795672863721848, 'loss_2': 0.00439453125, 'loss_3': -16.325410842895508, 'loss_4': 0.9885499477386475, 'epoch': 6.31}
{'loss': 0.0172, 'grad_norm': 10.750940322875977, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.016418714076280594, 'loss_2': 0.0008182525634765625, 'loss_3': -16.244155883789062, 'loss_4': 0.17918774485588074, 'epoch': 6.32}
{'loss': 0.0244, 'grad_norm': 7.640331745147705, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.017045758664608, 'loss_2': 0.00738525390625, 'loss_3': -16.215763092041016, 'loss_4': 0.2837978005409241, 'epoch': 6.33}
{'loss': 0.0623, 'grad_norm': 19.957040786743164, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.05761067196726799, 'loss_2': 0.004680633544921875, 'loss_3': -16.424894332885742, 'loss_4': 0.40255188941955566, 'epoch': 6.33}
{'loss': 0.0225, 'grad_norm': 6.596240043640137, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.01807418465614319, 'loss_2': 0.004421234130859375, 'loss_3': -15.899199485778809, 'loss_4': 0.4302777945995331, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 15:44:50,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:50,176 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:28<1:10:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:57,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0186660997569561, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016693320125341415, 'eval_loss_2': 0.001972779631614685, 'eval_loss_3': -18.21877670288086, 'eval_loss_4': 0.19175602495670319, 'epoch': 6.34}
{'loss': 0.0129, 'grad_norm': 6.254500389099121, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.012247679755091667, 'loss_2': 0.0006847381591796875, 'loss_3': -16.252920150756836, 'loss_4': 0.08432836830615997, 'epoch': 6.34}
{'loss': 0.0105, 'grad_norm': 4.934272289276123, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.007247458677738905, 'loss_2': 0.003269195556640625, 'loss_3': -16.26870346069336, 'loss_4': 0.10999948531389236, 'epoch': 6.35}
{'loss': 0.0103, 'grad_norm': 4.9579572677612305, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.008712510578334332, 'loss_2': 0.0015392303466796875, 'loss_3': -16.002399444580078, 'loss_4': -0.3924556374549866, 'epoch': 6.35}
{'loss': 0.0247, 'grad_norm': 7.626017093658447, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.016493817791342735, 'loss_2': 0.00818634033203125, 'loss_3': -16.04975700378418, 'loss_4': 0.12352347373962402, 'epoch': 6.36}
{'loss': 0.0196, 'grad_norm': 12.524991989135742, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.016781235113739967, 'loss_2': 0.0028285980224609375, 'loss_3': -15.88637638092041, 'loss_4': -0.18038836121559143, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 15:44:57,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:57,532 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:35<1:10:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:04,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03253142908215523, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.147, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.026252202689647675, 'eval_loss_2': 0.0062792301177978516, 'eval_loss_3': -18.17245864868164, 'eval_loss_4': -0.0024003013968467712, 'epoch': 6.37}
{'loss': 0.0724, 'grad_norm': 26.89385414123535, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.07025964558124542, 'loss_2': 0.002105712890625, 'loss_3': -16.07730484008789, 'loss_4': 0.0300673246383667, 'epoch': 6.37}
{'loss': 0.037, 'grad_norm': 16.119203567504883, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.030603380873799324, 'loss_2': 0.0063629150390625, 'loss_3': -16.3124942779541, 'loss_4': 0.061084993183612823, 'epoch': 6.38}
{'loss': 0.0237, 'grad_norm': 9.025727272033691, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.01820489764213562, 'loss_2': 0.0055389404296875, 'loss_3': -16.378406524658203, 'loss_4': -0.04523548483848572, 'epoch': 6.38}
{'loss': 0.0227, 'grad_norm': 6.981828689575195, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.012752613052725792, 'loss_2': 0.009918212890625, 'loss_3': -16.091957092285156, 'loss_4': -0.45685485005378723, 'epoch': 6.39}
{'loss': 0.0289, 'grad_norm': 12.975383758544922, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.024140402674674988, 'loss_2': 0.00472259521484375, 'loss_3': -16.194316864013672, 'loss_4': -0.268349826335907, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 15:45:04,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:04,893 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:43<1:10:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:12,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029792742803692818, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.018, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.026101110503077507, 'eval_loss_2': 0.003691628575325012, 'eval_loss_3': -18.179149627685547, 'eval_loss_4': -0.1955925077199936, 'epoch': 6.4}
{'loss': 0.0157, 'grad_norm': 7.109734058380127, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.010772147215902805, 'loss_2': 0.0048828125, 'loss_3': -16.20815658569336, 'loss_4': -0.26079297065734863, 'epoch': 6.4}
{'loss': 0.0288, 'grad_norm': 19.192697525024414, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.025385253131389618, 'loss_2': 0.003414154052734375, 'loss_3': -16.23895835876465, 'loss_4': -0.07617418467998505, 'epoch': 6.41}
{'loss': 0.0786, 'grad_norm': 25.75701332092285, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.07803574949502945, 'loss_2': 0.0005893707275390625, 'loss_3': -16.004150390625, 'loss_4': -0.16513027250766754, 'epoch': 6.41}
{'loss': 0.0199, 'grad_norm': 5.317600727081299, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.010096176527440548, 'loss_2': 0.0097808837890625, 'loss_3': -16.425376892089844, 'loss_4': 0.03538171201944351, 'epoch': 6.42}
{'loss': 0.0465, 'grad_norm': 12.606850624084473, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.035364989191293716, 'loss_2': 0.01116943359375, 'loss_3': -16.2081241607666, 'loss_4': -0.1024695485830307, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 15:45:12,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:12,260 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:50<1:10:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:19,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029575403779745102, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.653, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.02136867679655552, 'eval_loss_2': 0.008206725120544434, 'eval_loss_3': -18.189537048339844, 'eval_loss_4': -0.0575614795088768, 'epoch': 6.42}
{'loss': 0.0125, 'grad_norm': 5.252488613128662, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.010722187347710133, 'loss_2': 0.0017948150634765625, 'loss_3': -16.336490631103516, 'loss_4': 0.4085792601108551, 'epoch': 6.43}
{'loss': 0.0167, 'grad_norm': 5.679673194885254, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.010518252849578857, 'loss_2': 0.006145477294921875, 'loss_3': -16.182483673095703, 'loss_4': -0.30227771401405334, 'epoch': 6.44}
{'loss': 0.0157, 'grad_norm': 5.801375865936279, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.012888302095234394, 'loss_2': 0.0028247833251953125, 'loss_3': -15.972274780273438, 'loss_4': 0.012862712144851685, 'epoch': 6.44}
{'loss': 0.0227, 'grad_norm': 6.9075140953063965, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.015490350313484669, 'loss_2': 0.0072479248046875, 'loss_3': -16.334476470947266, 'loss_4': -0.12907078862190247, 'epoch': 6.45}
{'loss': 0.0169, 'grad_norm': 8.951187133789062, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.016641583293676376, 'loss_2': 0.00023984909057617188, 'loss_3': -16.458850860595703, 'loss_4': -0.1675921380519867, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 15:45:19,627 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:19,627 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:57<1:10:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:26,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02454383298754692, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.148, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018410364165902138, 'eval_loss_2': 0.006133466958999634, 'eval_loss_3': -18.218360900878906, 'eval_loss_4': -0.15732645988464355, 'epoch': 6.45}
{'loss': 0.0308, 'grad_norm': 14.11188793182373, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.02583872154355049, 'loss_2': 0.004978179931640625, 'loss_3': -16.440332412719727, 'loss_4': -0.07679075002670288, 'epoch': 6.46}
{'loss': 0.023, 'grad_norm': 9.745893478393555, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.015938516706228256, 'loss_2': 0.007080078125, 'loss_3': -16.373977661132812, 'loss_4': 0.17490532994270325, 'epoch': 6.47}
{'loss': 0.0223, 'grad_norm': 6.981175899505615, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.013119326904416084, 'loss_2': 0.00914764404296875, 'loss_3': -16.261926651000977, 'loss_4': 0.06523758172988892, 'epoch': 6.47}
{'loss': 0.0178, 'grad_norm': 5.492166519165039, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.00999005138874054, 'loss_2': 0.00777435302734375, 'loss_3': -16.36467170715332, 'loss_4': -0.3017004430294037, 'epoch': 6.48}
{'loss': 0.0309, 'grad_norm': 10.92666244506836, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.023783881217241287, 'loss_2': 0.00708770751953125, 'loss_3': -16.331558227539062, 'loss_4': 0.17681436240673065, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 15:45:26,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:26,984 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [28:05<1:10:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:34,345 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027743259444832802, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01732734777033329, 'eval_loss_2': 0.010415911674499512, 'eval_loss_3': -18.226465225219727, 'eval_loss_4': -0.04322720319032669, 'epoch': 6.48}
{'loss': 0.0152, 'grad_norm': 5.904806137084961, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.008905136026442051, 'loss_2': 0.00632476806640625, 'loss_3': -16.25823211669922, 'loss_4': -0.08495385944843292, 'epoch': 6.49}
{'loss': 0.0169, 'grad_norm': 6.35746431350708, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.012414718046784401, 'loss_2': 0.00444793701171875, 'loss_3': -16.071868896484375, 'loss_4': 0.09170873463153839, 'epoch': 6.49}
{'loss': 0.0372, 'grad_norm': 19.882476806640625, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.0276145301759243, 'loss_2': 0.009613037109375, 'loss_3': -16.200958251953125, 'loss_4': -0.22311702370643616, 'epoch': 6.5}
{'loss': 0.0122, 'grad_norm': 6.151834964752197, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.010279732756316662, 'loss_2': 0.0019130706787109375, 'loss_3': -16.207958221435547, 'loss_4': 0.38595226407051086, 'epoch': 6.51}
{'loss': 0.0247, 'grad_norm': 13.129798889160156, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.02120177075266838, 'loss_2': 0.003448486328125, 'loss_3': -16.398881912231445, 'loss_4': -0.061649903655052185, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 15:45:34,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:34,345 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:12<1:10:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:41,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02079189196228981, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.166, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018080417066812515, 'eval_loss_2': 0.002711474895477295, 'eval_loss_3': -18.21763801574707, 'eval_loss_4': 0.1866777390241623, 'epoch': 6.51}
{'loss': 0.0132, 'grad_norm': 6.483666896820068, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.012428098358213902, 'loss_2': 0.0007801055908203125, 'loss_3': -16.154266357421875, 'loss_4': 0.5799639225006104, 'epoch': 6.52}
{'loss': 0.0112, 'grad_norm': 7.364613056182861, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.009632297791540623, 'loss_2': 0.0016107559204101562, 'loss_3': -16.168392181396484, 'loss_4': -0.006384134292602539, 'epoch': 6.52}
{'loss': 0.011, 'grad_norm': 7.335150718688965, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.010950989089906216, 'loss_2': 8.189678192138672e-05, 'loss_3': -16.28331756591797, 'loss_4': 0.320320725440979, 'epoch': 6.53}
{'loss': 0.0249, 'grad_norm': 12.05811595916748, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.02429516613483429, 'loss_2': 0.0005979537963867188, 'loss_3': -16.187925338745117, 'loss_4': 0.5791270732879639, 'epoch': 6.53}
{'loss': 0.0128, 'grad_norm': 5.615670680999756, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.011600556783378124, 'loss_2': 0.0012025833129882812, 'loss_3': -16.000757217407227, 'loss_4': 0.40376347303390503, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 15:45:41,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:41,708 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:19<1:09:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:49,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023014556616544724, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.15, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020215574651956558, 'eval_loss_2': 0.0027989856898784637, 'eval_loss_3': -18.225069046020508, 'eval_loss_4': 0.37846022844314575, 'epoch': 6.54}
{'loss': 0.0167, 'grad_norm': 5.876162528991699, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.01296019647270441, 'loss_2': 0.0037364959716796875, 'loss_3': -16.217071533203125, 'loss_4': 0.4632376432418823, 'epoch': 6.55}
{'loss': 0.0296, 'grad_norm': 9.602150917053223, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.024220796301960945, 'loss_2': 0.00537109375, 'loss_3': -16.12272834777832, 'loss_4': 0.4024314284324646, 'epoch': 6.55}
{'loss': 0.0193, 'grad_norm': 5.975733757019043, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.013764804229140282, 'loss_2': 0.00556182861328125, 'loss_3': -16.14068603515625, 'loss_4': 0.39065951108932495, 'epoch': 6.56}
{'loss': 0.0188, 'grad_norm': 7.1711344718933105, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.015378802083432674, 'loss_2': 0.003437042236328125, 'loss_3': -16.055143356323242, 'loss_4': 0.4618333876132965, 'epoch': 6.56}
{'loss': 0.0235, 'grad_norm': 10.51776123046875, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.020043551921844482, 'loss_2': 0.00341796875, 'loss_3': -15.997587203979492, 'loss_4': 0.8875024318695068, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 15:45:49,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:49,067 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:27<1:09:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:56,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024261418730020523, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.336, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.021498728543519974, 'eval_loss_2': 0.0027626901865005493, 'eval_loss_3': -18.179807662963867, 'eval_loss_4': 0.4667704999446869, 'epoch': 6.57}
{'loss': 0.025, 'grad_norm': 10.937740325927734, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.024799255654215813, 'loss_2': 0.0002503395080566406, 'loss_3': -16.256938934326172, 'loss_4': 0.5050581097602844, 'epoch': 6.58}
{'loss': 0.0364, 'grad_norm': 16.44228172302246, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.035441502928733826, 'loss_2': 0.0009317398071289062, 'loss_3': -16.116073608398438, 'loss_4': 0.1632053405046463, 'epoch': 6.58}
{'loss': 0.0184, 'grad_norm': 5.225118637084961, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.009202071465551853, 'loss_2': 0.009185791015625, 'loss_3': -16.345054626464844, 'loss_4': 0.4739741086959839, 'epoch': 6.59}
{'loss': 0.0301, 'grad_norm': 13.549318313598633, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.023952666670084, 'loss_2': 0.006134033203125, 'loss_3': -16.08538055419922, 'loss_4': 0.573714017868042, 'epoch': 6.59}
{'loss': 0.0593, 'grad_norm': 18.05231475830078, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.05846286565065384, 'loss_2': 0.0008392333984375, 'loss_3': -16.300886154174805, 'loss_4': 0.4139448404312134, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 15:45:56,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:56,445 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:34<1:09:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:03,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04168201610445976, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.041, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03849663957953453, 'eval_loss_2': 0.003185376524925232, 'eval_loss_3': -18.096620559692383, 'eval_loss_4': 0.6497607231140137, 'epoch': 6.6}
{'loss': 0.08, 'grad_norm': 17.09246826171875, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.07541203498840332, 'loss_2': 0.00453948974609375, 'loss_3': -16.194347381591797, 'loss_4': 0.5170788168907166, 'epoch': 6.6}
{'loss': 0.0378, 'grad_norm': 8.589723587036133, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.030505763366818428, 'loss_2': 0.0072784423828125, 'loss_3': -16.24874496459961, 'loss_4': 0.9807872772216797, 'epoch': 6.61}
{'loss': 0.0289, 'grad_norm': 10.213861465454102, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.028206653892993927, 'loss_2': 0.0006937980651855469, 'loss_3': -15.862200736999512, 'loss_4': 0.7687896490097046, 'epoch': 6.62}
{'loss': 0.0452, 'grad_norm': 14.849373817443848, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.04478110000491142, 'loss_2': 0.0003910064697265625, 'loss_3': -16.116931915283203, 'loss_4': 1.1916797161102295, 'epoch': 6.62}
{'loss': 0.0579, 'grad_norm': 18.358928680419922, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.048530180007219315, 'loss_2': 0.009368896484375, 'loss_3': -15.715575218200684, 'loss_4': 0.22841227054595947, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 15:46:03,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:03,804 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:41<1:09:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:11,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.045495495200157166, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.399, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.03245018422603607, 'eval_loss_2': 0.013045310974121094, 'eval_loss_3': -18.13787841796875, 'eval_loss_4': 0.6762441992759705, 'epoch': 6.63}
{'loss': 0.0618, 'grad_norm': 19.83896255493164, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.05228520929813385, 'loss_2': 0.0094757080078125, 'loss_3': -16.04168701171875, 'loss_4': 0.6953052282333374, 'epoch': 6.63}
{'loss': 0.0335, 'grad_norm': 6.216117858886719, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.010795698501169682, 'loss_2': 0.0227203369140625, 'loss_3': -16.165302276611328, 'loss_4': 0.4420020580291748, 'epoch': 6.64}
{'loss': 0.0372, 'grad_norm': 8.606620788574219, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.015764644369482994, 'loss_2': 0.0214080810546875, 'loss_3': -16.298595428466797, 'loss_4': 0.5324278473854065, 'epoch': 6.65}
{'loss': 0.1149, 'grad_norm': 22.95455551147461, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.10434847325086594, 'loss_2': 0.0105743408203125, 'loss_3': -16.065053939819336, 'loss_4': 0.23978321254253387, 'epoch': 6.65}
{'loss': 0.0383, 'grad_norm': 11.93704891204834, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.03246303275227547, 'loss_2': 0.005825042724609375, 'loss_3': -16.06593132019043, 'loss_4': 0.27630558609962463, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 15:46:11,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:11,160 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:49<1:09:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:18,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027969300746917725, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016021907329559326, 'eval_loss_2': 0.011947393417358398, 'eval_loss_3': -18.242313385009766, 'eval_loss_4': 0.27468618750572205, 'epoch': 6.66}
{'loss': 0.0383, 'grad_norm': 14.723450660705566, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.024323657155036926, 'loss_2': 0.01397705078125, 'loss_3': -16.388376235961914, 'loss_4': 0.5501235723495483, 'epoch': 6.66}
{'loss': 0.0351, 'grad_norm': 10.669322967529297, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.02354149892926216, 'loss_2': 0.0115814208984375, 'loss_3': -15.9932222366333, 'loss_4': -0.005459193140268326, 'epoch': 6.67}
{'loss': 0.0204, 'grad_norm': 8.639404296875, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.01620139554142952, 'loss_2': 0.00421142578125, 'loss_3': -16.36266326904297, 'loss_4': 0.3049719035625458, 'epoch': 6.67}
{'loss': 0.0174, 'grad_norm': 7.626281261444092, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.016894645988941193, 'loss_2': 0.0005197525024414062, 'loss_3': -16.340158462524414, 'loss_4': 0.43862614035606384, 'epoch': 6.68}
{'loss': 0.0636, 'grad_norm': 24.49517059326172, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.056811537593603134, 'loss_2': 0.00679779052734375, 'loss_3': -16.60340690612793, 'loss_4': 0.775994062423706, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 15:46:18,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:18,506 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:56<1:09:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:25,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015516702085733414, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.243, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011949452571570873, 'eval_loss_2': 0.003567248582839966, 'eval_loss_3': -18.304227828979492, 'eval_loss_4': 0.15193945169448853, 'epoch': 6.69}
{'loss': 0.0352, 'grad_norm': 14.795888900756836, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.02995097078382969, 'loss_2': 0.0052490234375, 'loss_3': -16.25178337097168, 'loss_4': 0.6250056028366089, 'epoch': 6.69}
{'loss': 0.0376, 'grad_norm': 13.789088249206543, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.03252696245908737, 'loss_2': 0.00511932373046875, 'loss_3': -16.233795166015625, 'loss_4': 0.12684151530265808, 'epoch': 6.7}
{'loss': 0.0324, 'grad_norm': 19.12995147705078, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.02763555571436882, 'loss_2': 0.004787445068359375, 'loss_3': -16.242807388305664, 'loss_4': 0.15693449974060059, 'epoch': 6.7}
{'loss': 0.0283, 'grad_norm': 8.904452323913574, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.02775708958506584, 'loss_2': 0.00054168701171875, 'loss_3': -16.36830711364746, 'loss_4': 0.6469002366065979, 'epoch': 6.71}
{'loss': 0.0289, 'grad_norm': 13.152908325195312, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.02805222012102604, 'loss_2': 0.0008845329284667969, 'loss_3': -16.23503875732422, 'loss_4': 0.2665563225746155, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 15:46:25,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:25,866 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [29:04<1:09:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:33,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02073691599071026, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.575, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.015221763402223587, 'eval_loss_2': 0.005515150725841522, 'eval_loss_3': -18.268878936767578, 'eval_loss_4': 0.07114102691411972, 'epoch': 6.72}
{'loss': 0.0157, 'grad_norm': 8.895756721496582, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.015580372884869576, 'loss_2': 8.922815322875977e-05, 'loss_3': -16.20684242248535, 'loss_4': 0.20137958228588104, 'epoch': 6.72}
{'loss': 0.0216, 'grad_norm': 5.6184234619140625, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.008493153378367424, 'loss_2': 0.01309967041015625, 'loss_3': -16.287029266357422, 'loss_4': 0.1110503152012825, 'epoch': 6.73}
{'loss': 0.0727, 'grad_norm': 26.55014419555664, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.05858366936445236, 'loss_2': 0.01416015625, 'loss_3': -16.343584060668945, 'loss_4': -0.025803178548812866, 'epoch': 6.73}
{'loss': 0.1351, 'grad_norm': 28.416900634765625, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.12689951062202454, 'loss_2': 0.0081634521484375, 'loss_3': -16.35236930847168, 'loss_4': 0.5747867822647095, 'epoch': 6.74}
{'loss': 0.0256, 'grad_norm': 7.545742034912109, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.014092991128563881, 'loss_2': 0.0115203857421875, 'loss_3': -16.242870330810547, 'loss_4': 0.37305280566215515, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 15:46:33,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:33,229 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [29:11<1:09:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:40,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0277276448905468, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01842455193400383, 'eval_loss_2': 0.009303092956542969, 'eval_loss_3': -18.258831024169922, 'eval_loss_4': -0.2527143955230713, 'epoch': 6.74}
{'loss': 0.034, 'grad_norm': 11.849560737609863, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.023959606885910034, 'loss_2': 0.0100555419921875, 'loss_3': -16.482433319091797, 'loss_4': -0.001848079264163971, 'epoch': 6.75}
{'loss': 0.0242, 'grad_norm': 6.027663230895996, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.012268283404409885, 'loss_2': 0.0119476318359375, 'loss_3': -16.349557876586914, 'loss_4': -0.4081810414791107, 'epoch': 6.76}
{'loss': 0.0205, 'grad_norm': 7.9343180656433105, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.013790611177682877, 'loss_2': 0.0067138671875, 'loss_3': -16.26604461669922, 'loss_4': -0.4446319341659546, 'epoch': 6.76}
{'loss': 0.0194, 'grad_norm': 4.8815507888793945, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.010890870355069637, 'loss_2': 0.00850677490234375, 'loss_3': -16.333200454711914, 'loss_4': -0.35387060046195984, 'epoch': 6.77}
{'loss': 0.0115, 'grad_norm': 5.75042724609375, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.01063317060470581, 'loss_2': 0.0009050369262695312, 'loss_3': -16.437808990478516, 'loss_4': -0.8030457496643066, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 15:46:40,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:40,580 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:18<1:09:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:47,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02385014295578003, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.020227624103426933, 'eval_loss_2': 0.0036225169897079468, 'eval_loss_3': -18.288145065307617, 'eval_loss_4': -0.50791335105896, 'epoch': 6.77}
{'loss': 0.0253, 'grad_norm': 15.126161575317383, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.023273609578609467, 'loss_2': 0.0020160675048828125, 'loss_3': -16.078269958496094, 'loss_4': -0.6287714242935181, 'epoch': 6.78}
{'loss': 0.0245, 'grad_norm': 9.390157699584961, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.01081557385623455, 'loss_2': 0.0136871337890625, 'loss_3': -16.384912490844727, 'loss_4': -0.2345632016658783, 'epoch': 6.78}
{'loss': 0.056, 'grad_norm': 20.012577056884766, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.045247938483953476, 'loss_2': 0.01070404052734375, 'loss_3': -16.223297119140625, 'loss_4': -0.20443899929523468, 'epoch': 6.79}
{'loss': 0.0297, 'grad_norm': 13.612504959106445, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.024984152987599373, 'loss_2': 0.004730224609375, 'loss_3': -16.330610275268555, 'loss_4': -0.7612454891204834, 'epoch': 6.8}
{'loss': 0.0249, 'grad_norm': 7.765171051025391, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.0191376730799675, 'loss_2': 0.00580596923828125, 'loss_3': -16.324939727783203, 'loss_4': -0.23068282008171082, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 15:46:47,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:47,931 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:26<1:09:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:55,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02262786030769348, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.189, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018886851146817207, 'eval_loss_2': 0.0037410110235214233, 'eval_loss_3': -18.329158782958984, 'eval_loss_4': -0.4874423146247864, 'epoch': 6.8}
{'loss': 0.024, 'grad_norm': 5.942918300628662, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.014842763543128967, 'loss_2': 0.00919342041015625, 'loss_3': -16.344703674316406, 'loss_4': 0.07906907051801682, 'epoch': 6.81}
{'loss': 0.0391, 'grad_norm': 11.884586334228516, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.03504202142357826, 'loss_2': 0.004058837890625, 'loss_3': -16.22563934326172, 'loss_4': -0.33384639024734497, 'epoch': 6.81}
{'loss': 0.0207, 'grad_norm': 6.730539798736572, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.017208918929100037, 'loss_2': 0.003482818603515625, 'loss_3': -16.215866088867188, 'loss_4': -0.2299148589372635, 'epoch': 6.82}
{'loss': 0.0285, 'grad_norm': 20.31195068359375, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.028319770470261574, 'loss_2': 0.00020194053649902344, 'loss_3': -16.228759765625, 'loss_4': -0.3950520157814026, 'epoch': 6.83}
{'loss': 0.0261, 'grad_norm': 7.357666492462158, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.019857967272400856, 'loss_2': 0.00626373291015625, 'loss_3': -16.279996871948242, 'loss_4': -0.6308491230010986, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 15:46:55,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:55,286 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:33<1:08:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:02,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022006690502166748, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.395, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.017866160720586777, 'eval_loss_2': 0.004140526056289673, 'eval_loss_3': -18.331418991088867, 'eval_loss_4': -0.5021448135375977, 'epoch': 6.83}
{'loss': 0.0198, 'grad_norm': 5.399845123291016, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.013023162260651588, 'loss_2': 0.00681304931640625, 'loss_3': -16.45662498474121, 'loss_4': -0.39568376541137695, 'epoch': 6.84}
{'loss': 0.0138, 'grad_norm': 5.802664279937744, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.008767087012529373, 'loss_2': 0.0050506591796875, 'loss_3': -16.23950958251953, 'loss_4': -0.5290685892105103, 'epoch': 6.84}
{'loss': 0.0162, 'grad_norm': 6.463210105895996, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.014538838528096676, 'loss_2': 0.0016508102416992188, 'loss_3': -16.2810001373291, 'loss_4': -0.10896008461713791, 'epoch': 6.85}
{'loss': 0.0235, 'grad_norm': 8.439543724060059, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.022219300270080566, 'loss_2': 0.00128173828125, 'loss_3': -16.16757583618164, 'loss_4': -0.4074126183986664, 'epoch': 6.85}
{'loss': 0.0228, 'grad_norm': 10.68643569946289, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.017334893345832825, 'loss_2': 0.0055084228515625, 'loss_3': -16.325414657592773, 'loss_4': -0.4769802987575531, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 15:47:02,638 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:02,638 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:40<1:08:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:10,000 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01968369260430336, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.264, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01582740619778633, 'eval_loss_2': 0.003856286406517029, 'eval_loss_3': -18.342357635498047, 'eval_loss_4': -0.3635672628879547, 'epoch': 6.86}
{'loss': 0.0437, 'grad_norm': 18.226116180419922, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.036959126591682434, 'loss_2': 0.0066986083984375, 'loss_3': -16.336986541748047, 'loss_4': 0.15912073850631714, 'epoch': 6.87}
{'loss': 0.0171, 'grad_norm': 9.01561164855957, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.014166591688990593, 'loss_2': 0.0029735565185546875, 'loss_3': -16.31280517578125, 'loss_4': -0.008104592561721802, 'epoch': 6.87}
{'loss': 0.0132, 'grad_norm': 5.938291072845459, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.01081007532775402, 'loss_2': 0.00240325927734375, 'loss_3': -16.09745216369629, 'loss_4': -0.3522859215736389, 'epoch': 6.88}
{'loss': 0.0383, 'grad_norm': 9.975313186645508, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.02758360281586647, 'loss_2': 0.0107574462890625, 'loss_3': -16.045917510986328, 'loss_4': -0.27446407079696655, 'epoch': 6.88}
{'loss': 0.0212, 'grad_norm': 8.014368057250977, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.015383457764983177, 'loss_2': 0.00585174560546875, 'loss_3': -16.25164031982422, 'loss_4': -0.2342570722103119, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 15:47:10,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:10,000 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:48<1:08:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:17,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01874009147286415, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.412, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.014471087604761124, 'eval_loss_2': 0.004269003868103027, 'eval_loss_3': -18.33786392211914, 'eval_loss_4': -0.2474144697189331, 'epoch': 6.89}
{'loss': 0.0256, 'grad_norm': 10.29666519165039, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.021997272968292236, 'loss_2': 0.003627777099609375, 'loss_3': -16.384796142578125, 'loss_4': -0.1368447095155716, 'epoch': 6.9}
{'loss': 0.0146, 'grad_norm': 6.729491233825684, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.014052739366889, 'loss_2': 0.0005431175231933594, 'loss_3': -16.262325286865234, 'loss_4': -0.5019158124923706, 'epoch': 6.9}
{'loss': 0.033, 'grad_norm': 9.518661499023438, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.02561788260936737, 'loss_2': 0.007415771484375, 'loss_3': -16.201580047607422, 'loss_4': -0.5036600232124329, 'epoch': 6.91}
{'loss': 0.0122, 'grad_norm': 5.616888046264648, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.011406072415411472, 'loss_2': 0.0007624626159667969, 'loss_3': -16.146709442138672, 'loss_4': -0.07649755477905273, 'epoch': 6.91}
{'loss': 0.0141, 'grad_norm': 6.438741683959961, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.013699118979275227, 'loss_2': 0.00038814544677734375, 'loss_3': -16.234596252441406, 'loss_4': -0.13268575072288513, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 15:47:17,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:17,370 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:55<1:08:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:24,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01711389049887657, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013309965841472149, 'eval_loss_2': 0.003803923726081848, 'eval_loss_3': -18.32546043395996, 'eval_loss_4': -0.21528422832489014, 'epoch': 6.92}
{'loss': 0.0148, 'grad_norm': 7.556665420532227, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.01325258705765009, 'loss_2': 0.00150299072265625, 'loss_3': -16.298677444458008, 'loss_4': -0.18001630902290344, 'epoch': 6.92}
{'loss': 0.055, 'grad_norm': 21.310123443603516, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.05118309706449509, 'loss_2': 0.003833770751953125, 'loss_3': -16.123594284057617, 'loss_4': 0.13109715282917023, 'epoch': 6.93}
{'loss': 0.0103, 'grad_norm': 5.5941362380981445, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.009177304804325104, 'loss_2': 0.00115203857421875, 'loss_3': -16.18619155883789, 'loss_4': -0.3800312280654907, 'epoch': 6.94}
{'loss': 0.0176, 'grad_norm': 6.538283824920654, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.017273131757974625, 'loss_2': 0.0003116130828857422, 'loss_3': -16.099609375, 'loss_4': -0.38973742723464966, 'epoch': 6.94}
{'loss': 0.0212, 'grad_norm': 7.9139204025268555, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.014880510047078133, 'loss_2': 0.00634765625, 'loss_3': -16.33303451538086, 'loss_4': 0.17678110301494598, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 15:47:24,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:24,726 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [30:02<1:08:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:32,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019357025623321533, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016359031200408936, 'eval_loss_2': 0.0029979944229125977, 'eval_loss_3': -18.328750610351562, 'eval_loss_4': -0.2622150778770447, 'epoch': 6.95}
{'loss': 0.0161, 'grad_norm': 6.180793285369873, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.013344570063054562, 'loss_2': 0.002796173095703125, 'loss_3': -16.352458953857422, 'loss_4': 0.2895418405532837, 'epoch': 6.95}
{'loss': 0.0206, 'grad_norm': 7.204922676086426, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.015258276835083961, 'loss_2': 0.0053863525390625, 'loss_3': -16.4166202545166, 'loss_4': -0.10642945766448975, 'epoch': 6.96}
{'loss': 0.011, 'grad_norm': 5.816239833831787, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.008144636638462543, 'loss_2': 0.0028247833251953125, 'loss_3': -16.126914978027344, 'loss_4': 0.034206897020339966, 'epoch': 6.97}
{'loss': 0.0199, 'grad_norm': 7.727625846862793, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.015872959047555923, 'loss_2': 0.0040130615234375, 'loss_3': -16.10964584350586, 'loss_4': -0.046673864126205444, 'epoch': 6.97}
{'loss': 0.0231, 'grad_norm': 12.070038795471191, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.017848992720246315, 'loss_2': 0.0052337646484375, 'loss_3': -16.116090774536133, 'loss_4': 0.09599293023347855, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 15:47:32,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:32,076 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [30:09<1:04:26,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 15:47:39,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02357766032218933, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.571, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.021022627130150795, 'eval_loss_2': 0.0025550276041030884, 'eval_loss_3': -18.264293670654297, 'eval_loss_4': -0.13785898685455322, 'epoch': 6.98}
{'loss': 0.0256, 'grad_norm': 12.112347602844238, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.024162622168660164, 'loss_2': 0.0014066696166992188, 'loss_3': -16.263927459716797, 'loss_4': -0.00854925811290741, 'epoch': 6.98}
{'loss': 0.0451, 'grad_norm': 12.344972610473633, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.04480312764644623, 'loss_2': 0.0002753734588623047, 'loss_3': -16.112133026123047, 'loss_4': 0.4745265543460846, 'epoch': 6.99}
{'loss': 0.0143, 'grad_norm': 6.589951515197754, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.013338894583284855, 'loss_2': 0.0009279251098632812, 'loss_3': -16.12706184387207, 'loss_4': 0.21502867341041565, 'epoch': 6.99}
{'loss': 0.0078, 'grad_norm': 6.0218095779418945, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.0021851176861673594, 'loss_2': 0.005634307861328125, 'loss_3': -16.18891143798828, 'loss_4': -0.2238921821117401, 'epoch': 7.0}
{'loss': 0.0323, 'grad_norm': 13.226547241210938, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.029528766870498657, 'loss_2': 0.00278472900390625, 'loss_3': -16.088205337524414, 'loss_4': -0.3094881474971771, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 15:47:39,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:39,107 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:17<1:07:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:47:46,456 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030864613130688667, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.027851451188325882, 'eval_loss_2': 0.0030131638050079346, 'eval_loss_3': -18.220422744750977, 'eval_loss_4': 0.022622212767601013, 'epoch': 7.01}
{'loss': 0.0149, 'grad_norm': 6.400269985198975, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.011312206275761127, 'loss_2': 0.0035762786865234375, 'loss_3': -16.190086364746094, 'loss_4': 0.003306739032268524, 'epoch': 7.01}
{'loss': 0.0463, 'grad_norm': 13.965141296386719, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.04203888773918152, 'loss_2': 0.00428009033203125, 'loss_3': -16.095739364624023, 'loss_4': 0.12607839703559875, 'epoch': 7.02}
{'loss': 0.0154, 'grad_norm': 5.8906474113464355, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.013998513109982014, 'loss_2': 0.0014095306396484375, 'loss_3': -16.26400375366211, 'loss_4': 0.39283305406570435, 'epoch': 7.02}
{'loss': 0.0141, 'grad_norm': 6.20750093460083, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.00999447237700224, 'loss_2': 0.00414276123046875, 'loss_3': -16.20806121826172, 'loss_4': -0.19493478536605835, 'epoch': 7.03}
{'loss': 0.016, 'grad_norm': 6.011992454528809, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.013059327378869057, 'loss_2': 0.002948760986328125, 'loss_3': -16.27907943725586, 'loss_4': -0.1292978972196579, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 15:47:46,456 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:46,457 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:24<1:08:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:53,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029084403067827225, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.892, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02163740061223507, 'eval_loss_2': 0.007447004318237305, 'eval_loss_3': -18.240848541259766, 'eval_loss_4': 0.058475881814956665, 'epoch': 7.03}
{'loss': 0.0255, 'grad_norm': 8.58895206451416, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.018101153895258904, 'loss_2': 0.007415771484375, 'loss_3': -16.457138061523438, 'loss_4': 0.03802699223160744, 'epoch': 7.04}
{'loss': 0.0146, 'grad_norm': 6.579318523406982, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.013632290065288544, 'loss_2': 0.000946044921875, 'loss_3': -16.354398727416992, 'loss_4': -0.008044958114624023, 'epoch': 7.05}
{'loss': 0.0224, 'grad_norm': 6.280800819396973, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.011998021975159645, 'loss_2': 0.01042938232421875, 'loss_3': -16.39923858642578, 'loss_4': -0.22885528206825256, 'epoch': 7.05}
{'loss': 0.0302, 'grad_norm': 6.2426981925964355, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.015038280747830868, 'loss_2': 0.01513671875, 'loss_3': -16.276872634887695, 'loss_4': -0.08642127364873886, 'epoch': 7.06}
{'loss': 0.0252, 'grad_norm': 5.1282830238342285, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.009879926219582558, 'loss_2': 0.015289306640625, 'loss_3': -16.427196502685547, 'loss_4': 0.041665032505989075, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 15:47:53,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:53,820 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:32<1:08:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:01,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029431646689772606, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.844, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019681280478835106, 'eval_loss_2': 0.0097503662109375, 'eval_loss_3': -18.258201599121094, 'eval_loss_4': 0.20718926191329956, 'epoch': 7.06}
{'loss': 0.0166, 'grad_norm': 5.935055732727051, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.012734021060168743, 'loss_2': 0.00391387939453125, 'loss_3': -16.419021606445312, 'loss_4': 0.38936376571655273, 'epoch': 7.07}
{'loss': 0.0195, 'grad_norm': 6.085947036743164, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.011351285502314568, 'loss_2': 0.00811767578125, 'loss_3': -16.17816734313965, 'loss_4': 0.5989508032798767, 'epoch': 7.08}
{'loss': 0.0132, 'grad_norm': 4.891214370727539, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.007438960485160351, 'loss_2': 0.005794525146484375, 'loss_3': -16.355655670166016, 'loss_4': 0.23003160953521729, 'epoch': 7.08}
{'loss': 0.0175, 'grad_norm': 6.119208812713623, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.009993640705943108, 'loss_2': 0.0075225830078125, 'loss_3': -16.11486053466797, 'loss_4': 0.3865792751312256, 'epoch': 7.09}
{'loss': 0.0241, 'grad_norm': 7.667304515838623, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.015685541555285454, 'loss_2': 0.0084228515625, 'loss_3': -16.415653228759766, 'loss_4': 0.43278172612190247, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 15:48:01,162 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:01,162 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:39<1:08:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:08,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021321728825569153, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.642, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01878417283296585, 'eval_loss_2': 0.002537555992603302, 'eval_loss_3': -18.27455711364746, 'eval_loss_4': 0.2990604639053345, 'epoch': 7.09}
{'loss': 0.0072, 'grad_norm': 5.415251731872559, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.0070815435610711575, 'loss_2': 7.081031799316406e-05, 'loss_3': -16.520004272460938, 'loss_4': 0.14220358431339264, 'epoch': 7.1}
{'loss': 0.0274, 'grad_norm': 8.931504249572754, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.016032319515943527, 'loss_2': 0.01141357421875, 'loss_3': -16.315221786499023, 'loss_4': 0.8899132609367371, 'epoch': 7.1}
{'loss': 0.0457, 'grad_norm': 23.588485717773438, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.045195870101451874, 'loss_2': 0.000476837158203125, 'loss_3': -16.478242874145508, 'loss_4': 0.6286866068840027, 'epoch': 7.11}
{'loss': 0.0234, 'grad_norm': 10.908127784729004, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.021095160394906998, 'loss_2': 0.002307891845703125, 'loss_3': -16.532020568847656, 'loss_4': 0.5766592025756836, 'epoch': 7.12}
{'loss': 0.023, 'grad_norm': 7.290623664855957, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.02098725736141205, 'loss_2': 0.002017974853515625, 'loss_3': -16.415727615356445, 'loss_4': 0.31018805503845215, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 15:48:08,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:08,508 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:46<1:07:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:15,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022106245160102844, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.715, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.019797323271632195, 'eval_loss_2': 0.0023089200258255005, 'eval_loss_3': -18.280012130737305, 'eval_loss_4': 0.2268548160791397, 'epoch': 7.12}
{'loss': 0.0283, 'grad_norm': 11.418363571166992, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.026316242292523384, 'loss_2': 0.0019683837890625, 'loss_3': -16.26528549194336, 'loss_4': 0.3425731956958771, 'epoch': 7.13}
{'loss': 0.0385, 'grad_norm': 13.915396690368652, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.03111216239631176, 'loss_2': 0.0073699951171875, 'loss_3': -16.344270706176758, 'loss_4': 0.4895642399787903, 'epoch': 7.13}
{'loss': 0.0422, 'grad_norm': 13.427746772766113, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.030943628400564194, 'loss_2': 0.01123046875, 'loss_3': -16.426633834838867, 'loss_4': -0.08757679164409637, 'epoch': 7.14}
{'loss': 0.0211, 'grad_norm': 9.561971664428711, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.01804320327937603, 'loss_2': 0.003101348876953125, 'loss_3': -16.60024642944336, 'loss_4': 0.1052224189043045, 'epoch': 7.15}
{'loss': 0.0285, 'grad_norm': 10.777395248413086, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.02439039759337902, 'loss_2': 0.00412750244140625, 'loss_3': -16.4617977142334, 'loss_4': 0.11545111238956451, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 15:48:15,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:15,852 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:54<1:07:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:23,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0256721843034029, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.747, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.023386919870972633, 'eval_loss_2': 0.0022852644324302673, 'eval_loss_3': -18.307680130004883, 'eval_loss_4': 0.054187726229429245, 'epoch': 7.15}
{'loss': 0.0361, 'grad_norm': 8.420271873474121, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.03013809584081173, 'loss_2': 0.00594329833984375, 'loss_3': -16.471725463867188, 'loss_4': 0.564734935760498, 'epoch': 7.16}
{'loss': 0.0381, 'grad_norm': 11.213496208190918, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.032740842550992966, 'loss_2': 0.00539398193359375, 'loss_3': -16.304147720336914, 'loss_4': 0.3745064437389374, 'epoch': 7.16}
{'loss': 0.0499, 'grad_norm': 11.595917701721191, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.03964236006140709, 'loss_2': 0.0102081298828125, 'loss_3': -16.609514236450195, 'loss_4': 0.34774842858314514, 'epoch': 7.17}
{'loss': 0.0239, 'grad_norm': 8.844489097595215, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.020280424505472183, 'loss_2': 0.00363922119140625, 'loss_3': -16.395309448242188, 'loss_4': 0.28332385420799255, 'epoch': 7.17}
{'loss': 0.0216, 'grad_norm': 5.524878025054932, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.01491688471287489, 'loss_2': 0.0066986083984375, 'loss_3': -16.375717163085938, 'loss_4': 0.5437114238739014, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 15:48:23,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:23,194 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [31:01<1:07:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:30,551 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029358137398958206, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.261, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.02705288492143154, 'eval_loss_2': 0.002305254340171814, 'eval_loss_3': -18.296836853027344, 'eval_loss_4': 0.19095441699028015, 'epoch': 7.18}
{'loss': 0.0181, 'grad_norm': 8.251606941223145, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.01652619056403637, 'loss_2': 0.001598358154296875, 'loss_3': -16.37375259399414, 'loss_4': 0.31350427865982056, 'epoch': 7.19}
{'loss': 0.0919, 'grad_norm': 19.303768157958984, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.08968930691480637, 'loss_2': 0.0022373199462890625, 'loss_3': -16.3165340423584, 'loss_4': 0.26957088708877563, 'epoch': 7.19}
{'loss': 0.0139, 'grad_norm': 5.339629650115967, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.013913619332015514, 'loss_2': 1.0251998901367188e-05, 'loss_3': -16.530019760131836, 'loss_4': 0.008051261305809021, 'epoch': 7.2}
{'loss': 0.028, 'grad_norm': 9.642439842224121, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.02747401036322117, 'loss_2': 0.0005583763122558594, 'loss_3': -16.65372085571289, 'loss_4': 0.36230209469795227, 'epoch': 7.2}
{'loss': 0.0198, 'grad_norm': 7.614124774932861, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.017330510541796684, 'loss_2': 0.00246429443359375, 'loss_3': -16.427030563354492, 'loss_4': 0.6652107834815979, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 15:48:30,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:30,551 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [31:08<1:07:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:37,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032155949622392654, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.517, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.028062809258699417, 'eval_loss_2': 0.004093140363693237, 'eval_loss_3': -18.3243465423584, 'eval_loss_4': 0.39331158995628357, 'epoch': 7.21}
{'loss': 0.042, 'grad_norm': 10.801786422729492, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.031812675297260284, 'loss_2': 0.0102081298828125, 'loss_3': -16.364667892456055, 'loss_4': 0.5645935535430908, 'epoch': 7.22}
{'loss': 0.024, 'grad_norm': 8.609238624572754, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.023404041305184364, 'loss_2': 0.0005865097045898438, 'loss_3': -16.57691192626953, 'loss_4': 0.7955873012542725, 'epoch': 7.22}
{'loss': 0.0163, 'grad_norm': 7.336661338806152, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.014505499973893166, 'loss_2': 0.0018224716186523438, 'loss_3': -16.326873779296875, 'loss_4': 0.6443416476249695, 'epoch': 7.23}
{'loss': 0.0268, 'grad_norm': 7.787896633148193, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.026110364124178886, 'loss_2': 0.0006608963012695312, 'loss_3': -16.594396591186523, 'loss_4': 0.4657112956047058, 'epoch': 7.23}
{'loss': 0.021, 'grad_norm': 6.642894268035889, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.01922784373164177, 'loss_2': 0.0017490386962890625, 'loss_3': -16.372968673706055, 'loss_4': 0.425325870513916, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 15:48:37,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:37,914 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:16<1:07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:45,262 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030093228444457054, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.633, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.027098847553133965, 'eval_loss_2': 0.0029943808913230896, 'eval_loss_3': -18.315507888793945, 'eval_loss_4': 0.5437045097351074, 'epoch': 7.24}
{'loss': 0.0135, 'grad_norm': 6.541779041290283, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.01281492318958044, 'loss_2': 0.00067138671875, 'loss_3': -16.45050811767578, 'loss_4': 0.908037543296814, 'epoch': 7.24}
{'loss': 0.024, 'grad_norm': 12.440427780151367, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.02341001108288765, 'loss_2': 0.0006151199340820312, 'loss_3': -16.510162353515625, 'loss_4': 0.8685739040374756, 'epoch': 7.25}
{'loss': 0.0253, 'grad_norm': 10.657590866088867, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.019030960276722908, 'loss_2': 0.006305694580078125, 'loss_3': -16.604633331298828, 'loss_4': 0.7076223492622375, 'epoch': 7.26}
{'loss': 0.0187, 'grad_norm': 12.290400505065918, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.014605305157601833, 'loss_2': 0.004058837890625, 'loss_3': -16.439926147460938, 'loss_4': 0.7460564374923706, 'epoch': 7.26}
{'loss': 0.0213, 'grad_norm': 9.392391204833984, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.018881922587752342, 'loss_2': 0.002407073974609375, 'loss_3': -16.316720962524414, 'loss_4': 0.8119362592697144, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 15:48:45,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:45,262 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:23<1:07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:52,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025922000408172607, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.651, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.023511219769716263, 'eval_loss_2': 0.002410784363746643, 'eval_loss_3': -18.307159423828125, 'eval_loss_4': 0.5753189325332642, 'epoch': 7.27}
{'loss': 0.0692, 'grad_norm': 23.510387420654297, 'learning_rate': 2.275e-05, 'loss_1': 0.06868358701467514, 'loss_2': 0.0004734992980957031, 'loss_3': -16.473316192626953, 'loss_4': 1.3065781593322754, 'epoch': 7.27}
{'loss': 0.0158, 'grad_norm': 5.309836387634277, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.01215712632983923, 'loss_2': 0.00360107421875, 'loss_3': -16.269275665283203, 'loss_4': 1.2066590785980225, 'epoch': 7.28}
{'loss': 0.0067, 'grad_norm': 5.047852039337158, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.006378258112818003, 'loss_2': 0.0003669261932373047, 'loss_3': -16.521774291992188, 'loss_4': 0.7631168365478516, 'epoch': 7.28}
{'loss': 0.0256, 'grad_norm': 6.770723819732666, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.014406883157789707, 'loss_2': 0.01116943359375, 'loss_3': -16.343902587890625, 'loss_4': 0.888310432434082, 'epoch': 7.29}
{'loss': 0.0362, 'grad_norm': 12.383235931396484, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.03164942190051079, 'loss_2': 0.00455474853515625, 'loss_3': -16.58627700805664, 'loss_4': 0.9893330335617065, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 15:48:52,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:52,609 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:30<1:07:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:59,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01762954331934452, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014615665189921856, 'eval_loss_2': 0.0030138790607452393, 'eval_loss_3': -18.309249877929688, 'eval_loss_4': 0.44233083724975586, 'epoch': 7.3}
{'loss': 0.018, 'grad_norm': 6.227717399597168, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.011832498013973236, 'loss_2': 0.006175994873046875, 'loss_3': -16.350322723388672, 'loss_4': 0.6706340312957764, 'epoch': 7.3}
{'loss': 0.0325, 'grad_norm': 11.631889343261719, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.02792607992887497, 'loss_2': 0.00457763671875, 'loss_3': -16.34911346435547, 'loss_4': 0.7156001329421997, 'epoch': 7.31}
{'loss': 0.0826, 'grad_norm': 14.290457725524902, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.08000832051038742, 'loss_2': 0.00255584716796875, 'loss_3': -16.388275146484375, 'loss_4': 0.40158820152282715, 'epoch': 7.31}
{'loss': 0.013, 'grad_norm': 5.524871349334717, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.010965720750391483, 'loss_2': 0.0020599365234375, 'loss_3': -16.20531463623047, 'loss_4': 0.6261293888092041, 'epoch': 7.32}
{'loss': 0.0151, 'grad_norm': 4.989992618560791, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.007348504848778248, 'loss_2': 0.0077056884765625, 'loss_3': -16.40362548828125, 'loss_4': -0.1092241108417511, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 15:48:59,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:59,958 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:38<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:07,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018829787150025368, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.592, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01270077470690012, 'eval_loss_2': 0.006129011511802673, 'eval_loss_3': -18.27384376525879, 'eval_loss_4': 0.08329353481531143, 'epoch': 7.33}
{'loss': 0.0958, 'grad_norm': 16.410869598388672, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.0946020781993866, 'loss_2': 0.001178741455078125, 'loss_3': -16.309585571289062, 'loss_4': 0.4976642429828644, 'epoch': 7.33}
{'loss': 0.064, 'grad_norm': 23.350595474243164, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.06346214562654495, 'loss_2': 0.00055694580078125, 'loss_3': -16.29914093017578, 'loss_4': 0.20185774564743042, 'epoch': 7.34}
{'loss': 0.0133, 'grad_norm': 5.137585639953613, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.0064092897810041904, 'loss_2': 0.006866455078125, 'loss_3': -16.236103057861328, 'loss_4': 0.11306845396757126, 'epoch': 7.34}
{'loss': 0.0141, 'grad_norm': 6.762111663818359, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.01199614442884922, 'loss_2': 0.002117156982421875, 'loss_3': -16.37512969970703, 'loss_4': 0.026366084814071655, 'epoch': 7.35}
{'loss': 0.0376, 'grad_norm': 10.907365798950195, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.03516440838575363, 'loss_2': 0.002452850341796875, 'loss_3': -16.25258445739746, 'loss_4': 0.3713269531726837, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 15:49:07,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:07,310 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:45<1:07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:14,673 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01921563595533371, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.581, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.013101869262754917, 'eval_loss_2': 0.006113767623901367, 'eval_loss_3': -18.254671096801758, 'eval_loss_4': -0.03404153883457184, 'epoch': 7.35}
{'loss': 0.0769, 'grad_norm': 19.783151626586914, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.06416627764701843, 'loss_2': 0.01270294189453125, 'loss_3': -16.25888442993164, 'loss_4': 0.5934478044509888, 'epoch': 7.36}
{'loss': 0.0166, 'grad_norm': 5.501156806945801, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.00690197478979826, 'loss_2': 0.009674072265625, 'loss_3': -16.408893585205078, 'loss_4': 0.29441025853157043, 'epoch': 7.37}
{'loss': 0.0159, 'grad_norm': 7.359612941741943, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.012099787592887878, 'loss_2': 0.0037841796875, 'loss_3': -16.3339786529541, 'loss_4': -0.1551772505044937, 'epoch': 7.37}
{'loss': 0.012, 'grad_norm': 5.327713966369629, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.009349126368761063, 'loss_2': 0.0026702880859375, 'loss_3': -16.16510772705078, 'loss_4': -0.1362912654876709, 'epoch': 7.38}
{'loss': 0.0301, 'grad_norm': 17.384885787963867, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.021799396723508835, 'loss_2': 0.00826263427734375, 'loss_3': -16.17270278930664, 'loss_4': 0.14030444622039795, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 15:49:14,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:14,673 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:52<1:07:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:22,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0158509723842144, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01278824731707573, 'eval_loss_2': 0.003062725067138672, 'eval_loss_3': -18.249467849731445, 'eval_loss_4': -0.0748881846666336, 'epoch': 7.38}
{'loss': 0.0116, 'grad_norm': 6.476499080657959, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.011280933395028114, 'loss_2': 0.00033664703369140625, 'loss_3': -16.224346160888672, 'loss_4': -0.11489186435937881, 'epoch': 7.39}
{'loss': 0.0153, 'grad_norm': 6.339722633361816, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.012091920711100101, 'loss_2': 0.003170013427734375, 'loss_3': -16.365873336791992, 'loss_4': -0.12248821556568146, 'epoch': 7.4}
{'loss': 0.0107, 'grad_norm': 4.5857462882995605, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.005467652343213558, 'loss_2': 0.00525665283203125, 'loss_3': -16.276126861572266, 'loss_4': 0.08769635856151581, 'epoch': 7.4}
{'loss': 0.0099, 'grad_norm': 5.412266731262207, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.007720734924077988, 'loss_2': 0.00222015380859375, 'loss_3': -16.15275764465332, 'loss_4': 0.7873628735542297, 'epoch': 7.41}
{'loss': 0.022, 'grad_norm': 16.282814025878906, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.021695302799344063, 'loss_2': 0.0003120899200439453, 'loss_3': -16.141036987304688, 'loss_4': -0.11893709003925323, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 15:49:22,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:22,021 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [32:00<1:07:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:29,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01969705894589424, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.156, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013603362254798412, 'eval_loss_2': 0.006093695759773254, 'eval_loss_3': -18.24789047241211, 'eval_loss_4': 0.30613064765930176, 'epoch': 7.41}
{'loss': 0.0273, 'grad_norm': 8.915934562683105, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.020468508824706078, 'loss_2': 0.0068511962890625, 'loss_3': -16.38810920715332, 'loss_4': 0.0866028368473053, 'epoch': 7.42}
{'loss': 0.0245, 'grad_norm': 6.582098007202148, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.01867547072470188, 'loss_2': 0.0058441162109375, 'loss_3': -16.042621612548828, 'loss_4': 0.7456375956535339, 'epoch': 7.42}
{'loss': 0.0237, 'grad_norm': 8.249056816101074, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.01874365657567978, 'loss_2': 0.00495147705078125, 'loss_3': -16.231910705566406, 'loss_4': 0.5820639729499817, 'epoch': 7.43}
{'loss': 0.0169, 'grad_norm': 7.593074321746826, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.013807445764541626, 'loss_2': 0.0030689239501953125, 'loss_3': -16.267704010009766, 'loss_4': 0.47173458337783813, 'epoch': 7.44}
{'loss': 0.0463, 'grad_norm': 17.539608001708984, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.04190453141927719, 'loss_2': 0.004360198974609375, 'loss_3': -16.158470153808594, 'loss_4': 0.5507873892784119, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 15:49:29,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:29,369 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:07<1:07:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:36,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017793109640479088, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.625, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014283827506005764, 'eval_loss_2': 0.0035092830657958984, 'eval_loss_3': -18.234508514404297, 'eval_loss_4': 0.569807231426239, 'epoch': 7.44}
{'loss': 0.0194, 'grad_norm': 7.566224098205566, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.01504773274064064, 'loss_2': 0.004329681396484375, 'loss_3': -16.08071517944336, 'loss_4': 0.6723582148551941, 'epoch': 7.45}
{'loss': 0.0124, 'grad_norm': 5.445215702056885, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.009804349392652512, 'loss_2': 0.0026340484619140625, 'loss_3': -16.21786880493164, 'loss_4': 0.7573143243789673, 'epoch': 7.45}
{'loss': 0.0148, 'grad_norm': 6.456422805786133, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.013091743923723698, 'loss_2': 0.001739501953125, 'loss_3': -16.295804977416992, 'loss_4': 1.0404102802276611, 'epoch': 7.46}
{'loss': 0.0143, 'grad_norm': 6.589877128601074, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.014114579185843468, 'loss_2': 0.00015425682067871094, 'loss_3': -16.26010513305664, 'loss_4': 0.8712763786315918, 'epoch': 7.47}
{'loss': 0.0386, 'grad_norm': 11.389946937561035, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.02728632465004921, 'loss_2': 0.011322021484375, 'loss_3': -16.307933807373047, 'loss_4': 0.644443154335022, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 15:49:36,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:36,717 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:14<1:07:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:44,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018632829189300537, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.506, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0156131312251091, 'eval_loss_2': 0.0030196979641914368, 'eval_loss_3': -18.237823486328125, 'eval_loss_4': 0.7475403547286987, 'epoch': 7.47}
{'loss': 0.0346, 'grad_norm': 13.131965637207031, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.033497996628284454, 'loss_2': 0.001102447509765625, 'loss_3': -16.200183868408203, 'loss_4': 0.9056532979011536, 'epoch': 7.48}
{'loss': 0.02, 'grad_norm': 8.269527435302734, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.018977582454681396, 'loss_2': 0.00099945068359375, 'loss_3': -16.301822662353516, 'loss_4': 1.162860631942749, 'epoch': 7.48}
{'loss': 0.0078, 'grad_norm': 6.1571173667907715, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.007683136500418186, 'loss_2': 9.393692016601562e-05, 'loss_3': -16.565753936767578, 'loss_4': 0.9320781230926514, 'epoch': 7.49}
{'loss': 0.0157, 'grad_norm': 6.433515548706055, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.015472357161343098, 'loss_2': 0.00020241737365722656, 'loss_3': -16.29302215576172, 'loss_4': 0.8752714395523071, 'epoch': 7.49}
{'loss': 0.0246, 'grad_norm': 6.8029465675354, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.014209400862455368, 'loss_2': 0.01036834716796875, 'loss_3': -16.18649673461914, 'loss_4': 0.5662842988967896, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 15:49:44,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:44,069 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:22<1:06:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:51,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02107904851436615, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.018068762496113777, 'eval_loss_2': 0.003010287880897522, 'eval_loss_3': -18.23736572265625, 'eval_loss_4': 0.9083108901977539, 'epoch': 7.5}
{'loss': 0.0182, 'grad_norm': 6.436777114868164, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.014300941489636898, 'loss_2': 0.003887176513671875, 'loss_3': -16.426891326904297, 'loss_4': 0.7905716896057129, 'epoch': 7.51}
{'loss': 0.0154, 'grad_norm': 10.634613990783691, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.015154819004237652, 'loss_2': 0.00021564960479736328, 'loss_3': -16.495100021362305, 'loss_4': 1.017016887664795, 'epoch': 7.51}
{'loss': 0.0281, 'grad_norm': 11.153868675231934, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.024021554738283157, 'loss_2': 0.00412750244140625, 'loss_3': -16.265865325927734, 'loss_4': 0.9741751551628113, 'epoch': 7.52}
{'loss': 0.0242, 'grad_norm': 9.547706604003906, 'learning_rate': 2.25e-05, 'loss_1': 0.021343881264328957, 'loss_2': 0.0028705596923828125, 'loss_3': -16.213212966918945, 'loss_4': 1.2609188556671143, 'epoch': 7.52}
{'loss': 0.0134, 'grad_norm': 7.095835208892822, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.012028113938868046, 'loss_2': 0.0013265609741210938, 'loss_3': -16.422462463378906, 'loss_4': 1.153401494026184, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 15:49:51,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:51,427 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:29<1:06:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:58,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02440473437309265, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.928, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.020611727610230446, 'eval_loss_2': 0.0037930049002170563, 'eval_loss_3': -18.202348709106445, 'eval_loss_4': 0.9096932411193848, 'epoch': 7.53}
{'loss': 0.0232, 'grad_norm': 7.3947625160217285, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.02177043817937374, 'loss_2': 0.00138092041015625, 'loss_3': -16.186386108398438, 'loss_4': 0.8585574626922607, 'epoch': 7.53}
{'loss': 0.0324, 'grad_norm': 12.333806991577148, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.03120145946741104, 'loss_2': 0.00115203857421875, 'loss_3': -16.192304611206055, 'loss_4': 0.9145384430885315, 'epoch': 7.54}
{'loss': 0.0583, 'grad_norm': 29.787656784057617, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.05527648329734802, 'loss_2': 0.003047943115234375, 'loss_3': -16.350255966186523, 'loss_4': 1.484699010848999, 'epoch': 7.55}
{'loss': 0.0521, 'grad_norm': 20.529972076416016, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.051480483263731, 'loss_2': 0.0005750656127929688, 'loss_3': -16.16844940185547, 'loss_4': 1.9536131620407104, 'epoch': 7.55}
{'loss': 0.0256, 'grad_norm': 15.351905822753906, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.019936557859182358, 'loss_2': 0.005619049072265625, 'loss_3': -16.311275482177734, 'loss_4': 1.503377914428711, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 15:49:58,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:58,789 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:36<1:06:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:06,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029127273708581924, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.652, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02539246156811714, 'eval_loss_2': 0.0037348121404647827, 'eval_loss_3': -18.17013931274414, 'eval_loss_4': 0.955005407333374, 'epoch': 7.56}
{'loss': 0.0203, 'grad_norm': 7.304069519042969, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.017804831266403198, 'loss_2': 0.0025081634521484375, 'loss_3': -16.081836700439453, 'loss_4': 1.1398183107376099, 'epoch': 7.56}
{'loss': 0.0503, 'grad_norm': 17.36897850036621, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.04938952624797821, 'loss_2': 0.0009222030639648438, 'loss_3': -16.305402755737305, 'loss_4': 1.2729099988937378, 'epoch': 7.57}
{'loss': 0.0143, 'grad_norm': 5.159869194030762, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.01209013257175684, 'loss_2': 0.0022125244140625, 'loss_3': -16.301212310791016, 'loss_4': 0.7456825375556946, 'epoch': 7.58}
{'loss': 0.0304, 'grad_norm': 11.310125350952148, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.024883447214961052, 'loss_2': 0.00547027587890625, 'loss_3': -16.305522918701172, 'loss_4': 1.064731240272522, 'epoch': 7.58}
{'loss': 0.0211, 'grad_norm': 9.050467491149902, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.02033199928700924, 'loss_2': 0.0007677078247070312, 'loss_3': -16.508678436279297, 'loss_4': 0.22498995065689087, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 15:50:06,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:06,134 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:44<1:06:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:13,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028124146163463593, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.284, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.022297877818346024, 'eval_loss_2': 0.0058262646198272705, 'eval_loss_3': -18.154218673706055, 'eval_loss_4': 0.8620314002037048, 'epoch': 7.59}
{'loss': 0.043, 'grad_norm': 11.114554405212402, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.037602588534355164, 'loss_2': 0.00537109375, 'loss_3': -16.432289123535156, 'loss_4': 0.6261373162269592, 'epoch': 7.59}
{'loss': 0.0371, 'grad_norm': 23.676422119140625, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.033104151487350464, 'loss_2': 0.004024505615234375, 'loss_3': -16.41802215576172, 'loss_4': 1.146507978439331, 'epoch': 7.6}
{'loss': 0.0381, 'grad_norm': 14.687235832214355, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.03750352934002876, 'loss_2': 0.0005712509155273438, 'loss_3': -16.241910934448242, 'loss_4': 0.8299265503883362, 'epoch': 7.6}
{'loss': 0.0288, 'grad_norm': 11.699951171875, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.024965407326817513, 'loss_2': 0.00382232666015625, 'loss_3': -16.45098114013672, 'loss_4': 1.2125048637390137, 'epoch': 7.61}
{'loss': 0.0533, 'grad_norm': 16.243165969848633, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.051315680146217346, 'loss_2': 0.002017974853515625, 'loss_3': -16.250598907470703, 'loss_4': 1.144290566444397, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 15:50:13,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:13,486 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:51<1:07:26,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:50:21,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03309324383735657, 'eval_runtime': 3.9896, 'eval_samples_per_second': 256.666, 'eval_steps_per_second': 4.01, 'eval_loss_1': 0.02530589886009693, 'eval_loss_2': 0.007787346839904785, 'eval_loss_3': -18.113855361938477, 'eval_loss_4': 0.9971530437469482, 'epoch': 7.62}
{'loss': 0.0277, 'grad_norm': 9.306413650512695, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.018024032935500145, 'loss_2': 0.00971221923828125, 'loss_3': -16.320253372192383, 'loss_4': 0.9930011630058289, 'epoch': 7.62}
{'loss': 0.041, 'grad_norm': 11.751701354980469, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.03853033483028412, 'loss_2': 0.00247955322265625, 'loss_3': -16.309457778930664, 'loss_4': 0.8432168960571289, 'epoch': 7.63}
{'loss': 0.0088, 'grad_norm': 4.987034797668457, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.006032183300703764, 'loss_2': 0.0027313232421875, 'loss_3': -16.158058166503906, 'loss_4': 1.035927653312683, 'epoch': 7.63}
{'loss': 0.0168, 'grad_norm': 10.081433296203613, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.01601359434425831, 'loss_2': 0.0007777214050292969, 'loss_3': -16.242412567138672, 'loss_4': 1.14059317111969, 'epoch': 7.64}
{'loss': 0.0477, 'grad_norm': 22.22760009765625, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.045932989567518234, 'loss_2': 0.0017805099487304688, 'loss_3': -16.06050682067871, 'loss_4': 1.0941669940948486, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 15:50:21,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:21,027 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [32:59<1:06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:28,390 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03337586671113968, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.029312260448932648, 'eval_loss_2': 0.004063606262207031, 'eval_loss_3': -18.084468841552734, 'eval_loss_4': 0.969399094581604, 'epoch': 7.65}
{'loss': 0.0155, 'grad_norm': 6.688022613525391, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.011996880173683167, 'loss_2': 0.0035228729248046875, 'loss_3': -16.165477752685547, 'loss_4': 0.4271657466888428, 'epoch': 7.65}
{'loss': 0.0352, 'grad_norm': 12.332529067993164, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.030970869585871696, 'loss_2': 0.00421142578125, 'loss_3': -16.460525512695312, 'loss_4': 1.3885324001312256, 'epoch': 7.66}
{'loss': 0.0415, 'grad_norm': 16.080991744995117, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.03434005007147789, 'loss_2': 0.0072021484375, 'loss_3': -16.208253860473633, 'loss_4': 0.8394378423690796, 'epoch': 7.66}
{'loss': 0.0386, 'grad_norm': 13.972158432006836, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.03354684263467789, 'loss_2': 0.005035400390625, 'loss_3': -16.386653900146484, 'loss_4': 1.0333291292190552, 'epoch': 7.67}
{'loss': 0.0382, 'grad_norm': 24.893321990966797, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.0380266048014164, 'loss_2': 0.0001652240753173828, 'loss_3': -16.07129669189453, 'loss_4': 0.7785251140594482, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 15:50:28,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:28,390 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [33:06<1:06:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:35,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02911600098013878, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.384, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.025995071977376938, 'eval_loss_2': 0.003120929002761841, 'eval_loss_3': -18.082012176513672, 'eval_loss_4': 0.8502664566040039, 'epoch': 7.67}
{'loss': 0.026, 'grad_norm': 11.815314292907715, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.0209792647510767, 'loss_2': 0.004974365234375, 'loss_3': -16.459251403808594, 'loss_4': 0.9961174726486206, 'epoch': 7.68}
{'loss': 0.017, 'grad_norm': 5.632599353790283, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.012437541969120502, 'loss_2': 0.004520416259765625, 'loss_3': -16.47617530822754, 'loss_4': 1.186903476715088, 'epoch': 7.69}
{'loss': 0.0181, 'grad_norm': 7.714219570159912, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.013867096975445747, 'loss_2': 0.00423431396484375, 'loss_3': -16.2159423828125, 'loss_4': 1.151841402053833, 'epoch': 7.69}
{'loss': 0.0434, 'grad_norm': 13.444550514221191, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.034479498863220215, 'loss_2': 0.008880615234375, 'loss_3': -16.386938095092773, 'loss_4': 0.5575514435768127, 'epoch': 7.7}
{'loss': 0.0129, 'grad_norm': 6.035128116607666, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.012597734108567238, 'loss_2': 0.0003466606140136719, 'loss_3': -16.19715118408203, 'loss_4': 0.7816604375839233, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 15:50:35,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:35,757 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:13<1:06:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:43,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02459261193871498, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02088303491473198, 'eval_loss_2': 0.0037095770239830017, 'eval_loss_3': -18.16989517211914, 'eval_loss_4': 0.839471161365509, 'epoch': 7.7}
{'loss': 0.0298, 'grad_norm': 9.108153343200684, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.026507189497351646, 'loss_2': 0.003265380859375, 'loss_3': -16.22589111328125, 'loss_4': 0.8129498362541199, 'epoch': 7.71}
{'loss': 0.0184, 'grad_norm': 6.617165565490723, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.014580179005861282, 'loss_2': 0.003864288330078125, 'loss_3': -16.2161808013916, 'loss_4': 1.109175205230713, 'epoch': 7.72}
{'loss': 0.0143, 'grad_norm': 6.328454494476318, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.012507460080087185, 'loss_2': 0.0018291473388671875, 'loss_3': -16.286653518676758, 'loss_4': 0.4367460310459137, 'epoch': 7.72}
{'loss': 0.0329, 'grad_norm': 16.628360748291016, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.02834443561732769, 'loss_2': 0.00457000732421875, 'loss_3': -16.338266372680664, 'loss_4': 0.6097408533096313, 'epoch': 7.73}
{'loss': 0.0149, 'grad_norm': 5.320338249206543, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.008015817031264305, 'loss_2': 0.00690460205078125, 'loss_3': -16.46637725830078, 'loss_4': 0.5385549664497375, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 15:50:43,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:43,121 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:21<1:06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:50,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022244945168495178, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018552284687757492, 'eval_loss_2': 0.003692660480737686, 'eval_loss_3': -18.20641326904297, 'eval_loss_4': 0.8092702031135559, 'epoch': 7.73}
{'loss': 0.0774, 'grad_norm': 21.137510299682617, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.07065185904502869, 'loss_2': 0.00670623779296875, 'loss_3': -16.234256744384766, 'loss_4': 0.5611819624900818, 'epoch': 7.74}
{'loss': 0.0127, 'grad_norm': 5.675448417663574, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.010934255085885525, 'loss_2': 0.0018062591552734375, 'loss_3': -16.320955276489258, 'loss_4': 0.734849750995636, 'epoch': 7.74}
{'loss': 0.0257, 'grad_norm': 6.875006198883057, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.01844414323568344, 'loss_2': 0.00730133056640625, 'loss_3': -16.422039031982422, 'loss_4': 0.15051260590553284, 'epoch': 7.75}
{'loss': 0.0413, 'grad_norm': 12.656347274780273, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.035082004964351654, 'loss_2': 0.00621795654296875, 'loss_3': -16.22783088684082, 'loss_4': 0.42515406012535095, 'epoch': 7.76}
{'loss': 0.0241, 'grad_norm': 15.180489540100098, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.023940661922097206, 'loss_2': 0.0001748800277709961, 'loss_3': -16.246850967407227, 'loss_4': 0.6469026803970337, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 15:50:50,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:50,477 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:28<1:06:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:57,823 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02133471705019474, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.563, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01607937179505825, 'eval_loss_2': 0.005255341529846191, 'eval_loss_3': -18.283422470092773, 'eval_loss_4': 0.8813189268112183, 'epoch': 7.76}
{'loss': 0.0445, 'grad_norm': 19.019638061523438, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.044139496982097626, 'loss_2': 0.000316619873046875, 'loss_3': -16.32039451599121, 'loss_4': 0.9203289747238159, 'epoch': 7.77}
{'loss': 0.0185, 'grad_norm': 6.053525447845459, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.016947772353887558, 'loss_2': 0.0015344619750976562, 'loss_3': -16.38760757446289, 'loss_4': 0.11364410817623138, 'epoch': 7.77}
{'loss': 0.0218, 'grad_norm': 7.240293979644775, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.020728768780827522, 'loss_2': 0.0010833740234375, 'loss_3': -16.503726959228516, 'loss_4': 0.6351399421691895, 'epoch': 7.78}
{'loss': 0.0523, 'grad_norm': 15.597081184387207, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.04990098252892494, 'loss_2': 0.002361297607421875, 'loss_3': -16.277158737182617, 'loss_4': 1.194917917251587, 'epoch': 7.78}
{'loss': 0.0321, 'grad_norm': 12.183850288391113, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.03158722072839737, 'loss_2': 0.0005512237548828125, 'loss_3': -16.370540618896484, 'loss_4': 0.8467490673065186, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 15:50:57,823 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:57,823 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:36<1:06:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:05,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01968506909906864, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.61, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.015483837574720383, 'eval_loss_2': 0.004201233386993408, 'eval_loss_3': -18.314117431640625, 'eval_loss_4': 0.8147560358047485, 'epoch': 7.79}
{'loss': 0.0393, 'grad_norm': 17.699769973754883, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.036247964948415756, 'loss_2': 0.003070831298828125, 'loss_3': -16.137348175048828, 'loss_4': 0.7249090671539307, 'epoch': 7.8}
{'loss': 0.0254, 'grad_norm': 10.907499313354492, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.022732142359018326, 'loss_2': 0.002658843994140625, 'loss_3': -16.36130142211914, 'loss_4': 1.067697525024414, 'epoch': 7.8}
{'loss': 0.0245, 'grad_norm': 10.506749153137207, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.023185674101114273, 'loss_2': 0.0013256072998046875, 'loss_3': -16.231029510498047, 'loss_4': 0.3844658434391022, 'epoch': 7.81}
{'loss': 0.0174, 'grad_norm': 7.711288928985596, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.011634774506092072, 'loss_2': 0.0057525634765625, 'loss_3': -16.433361053466797, 'loss_4': 0.7709915637969971, 'epoch': 7.81}
{'loss': 0.0119, 'grad_norm': 5.5162482261657715, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.010263263247907162, 'loss_2': 0.001590728759765625, 'loss_3': -16.433944702148438, 'loss_4': 0.8160890340805054, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 15:51:05,181 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:05,182 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:43<1:06:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:12,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02276071533560753, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016315337270498276, 'eval_loss_2': 0.006445378065109253, 'eval_loss_3': -18.269947052001953, 'eval_loss_4': 0.8755956888198853, 'epoch': 7.82}
{'loss': 0.0529, 'grad_norm': 14.741994857788086, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.04437870904803276, 'loss_2': 0.00847625732421875, 'loss_3': -16.371904373168945, 'loss_4': 0.6562880277633667, 'epoch': 7.83}
{'loss': 0.0117, 'grad_norm': 6.110701084136963, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.010898895561695099, 'loss_2': 0.0007696151733398438, 'loss_3': -16.303234100341797, 'loss_4': 0.4457787275314331, 'epoch': 7.83}
{'loss': 0.0203, 'grad_norm': 6.406334400177002, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.013679064810276031, 'loss_2': 0.0066680908203125, 'loss_3': -16.066692352294922, 'loss_4': 0.7110852003097534, 'epoch': 7.84}
{'loss': 0.0169, 'grad_norm': 6.207014560699463, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.012587079778313637, 'loss_2': 0.0043182373046875, 'loss_3': -16.22209358215332, 'loss_4': 0.6667544841766357, 'epoch': 7.84}
{'loss': 0.0332, 'grad_norm': 8.036044120788574, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.027221689000725746, 'loss_2': 0.0060272216796875, 'loss_3': -16.044391632080078, 'loss_4': 1.0228612422943115, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 15:51:12,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:12,547 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:50<1:05:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:19,899 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0266878642141819, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.021590951830148697, 'eval_loss_2': 0.005096912384033203, 'eval_loss_3': -18.2115478515625, 'eval_loss_4': 1.0387707948684692, 'epoch': 7.85}
{'loss': 0.0181, 'grad_norm': 7.371455192565918, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.012070415541529655, 'loss_2': 0.00603485107421875, 'loss_3': -16.138751983642578, 'loss_4': 0.7337446212768555, 'epoch': 7.85}
{'loss': 0.0188, 'grad_norm': 8.357782363891602, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.01799003966152668, 'loss_2': 0.0008387565612792969, 'loss_3': -16.095888137817383, 'loss_4': 0.7399197816848755, 'epoch': 7.86}
{'loss': 0.0099, 'grad_norm': 5.59203577041626, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.0071840002201497555, 'loss_2': 0.00267791748046875, 'loss_3': -16.519275665283203, 'loss_4': 0.9174754023551941, 'epoch': 7.87}
{'loss': 0.0087, 'grad_norm': 5.667070388793945, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.00864758063107729, 'loss_2': 9.691715240478516e-05, 'loss_3': -16.134048461914062, 'loss_4': 1.234281301498413, 'epoch': 7.87}
{'loss': 0.0266, 'grad_norm': 9.111712455749512, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.018427308648824692, 'loss_2': 0.0081329345703125, 'loss_3': -16.182449340820312, 'loss_4': 1.6090993881225586, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 15:51:19,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:19,899 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [33:58<1:05:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:27,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02747652865946293, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.022898180410265923, 'eval_loss_2': 0.004578351974487305, 'eval_loss_3': -18.204917907714844, 'eval_loss_4': 1.2541297674179077, 'epoch': 7.88}
{'loss': 0.0162, 'grad_norm': 5.337994575500488, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.009495084173977375, 'loss_2': 0.00672149658203125, 'loss_3': -16.32123565673828, 'loss_4': 1.0947259664535522, 'epoch': 7.88}
{'loss': 0.0199, 'grad_norm': 8.004234313964844, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.015399494208395481, 'loss_2': 0.00446319580078125, 'loss_3': -16.304475784301758, 'loss_4': 1.5373334884643555, 'epoch': 7.89}
{'loss': 0.0149, 'grad_norm': 5.56982946395874, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.012125362642109394, 'loss_2': 0.00278472900390625, 'loss_3': -16.234657287597656, 'loss_4': 1.2408490180969238, 'epoch': 7.9}
{'loss': 0.013, 'grad_norm': 5.483022212982178, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.012813768349587917, 'loss_2': 0.00014901161193847656, 'loss_3': -16.36817169189453, 'loss_4': 1.3188334703445435, 'epoch': 7.9}
{'loss': 0.0197, 'grad_norm': 5.437521457672119, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.011289597488939762, 'loss_2': 0.00836944580078125, 'loss_3': -16.210161209106445, 'loss_4': 1.9538984298706055, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 15:51:27,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:27,258 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [34:05<1:05:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:34,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028727561235427856, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.022746292874217033, 'eval_loss_2': 0.005981266498565674, 'eval_loss_3': -18.237165451049805, 'eval_loss_4': 1.759106159210205, 'epoch': 7.91}
{'loss': 0.0502, 'grad_norm': 21.86234474182129, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.04433838278055191, 'loss_2': 0.00586700439453125, 'loss_3': -16.18274688720703, 'loss_4': 1.408430814743042, 'epoch': 7.91}
{'loss': 0.0655, 'grad_norm': 20.49398422241211, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.05813315883278847, 'loss_2': 0.00739288330078125, 'loss_3': -16.21213150024414, 'loss_4': 2.050194263458252, 'epoch': 7.92}
{'loss': 0.0216, 'grad_norm': 8.899806022644043, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.018202148377895355, 'loss_2': 0.0033626556396484375, 'loss_3': -16.282073974609375, 'loss_4': 2.131624937057495, 'epoch': 7.92}
{'loss': 0.0146, 'grad_norm': 5.990823745727539, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.00844933558255434, 'loss_2': 0.006114959716796875, 'loss_3': -16.447216033935547, 'loss_4': 2.187596559524536, 'epoch': 7.93}
{'loss': 0.026, 'grad_norm': 13.389046669006348, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.025714047253131866, 'loss_2': 0.0002899169921875, 'loss_3': -16.275407791137695, 'loss_4': 2.2243237495422363, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 15:51:34,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:34,614 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:12<1:05:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:41,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02627946436405182, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.43, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019938422366976738, 'eval_loss_2': 0.006341040134429932, 'eval_loss_3': -18.293432235717773, 'eval_loss_4': 2.352938175201416, 'epoch': 7.94}
{'loss': 0.0241, 'grad_norm': 6.354093074798584, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.014424421824514866, 'loss_2': 0.0097198486328125, 'loss_3': -16.445222854614258, 'loss_4': 2.2321419715881348, 'epoch': 7.94}
{'loss': 0.017, 'grad_norm': 5.860397815704346, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.01043879333883524, 'loss_2': 0.006595611572265625, 'loss_3': -16.389019012451172, 'loss_4': 2.5279321670532227, 'epoch': 7.95}
{'loss': 0.0211, 'grad_norm': 6.910355091094971, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.01601237803697586, 'loss_2': 0.005046844482421875, 'loss_3': -16.35761260986328, 'loss_4': 2.76168155670166, 'epoch': 7.95}
{'loss': 0.0225, 'grad_norm': 10.752936363220215, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.022423479706048965, 'loss_2': 9.179115295410156e-05, 'loss_3': -16.298126220703125, 'loss_4': 3.0011749267578125, 'epoch': 7.96}
{'loss': 0.0244, 'grad_norm': 8.56989860534668, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.018331876024603844, 'loss_2': 0.006099700927734375, 'loss_3': -16.352846145629883, 'loss_4': 2.6225593090057373, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 15:51:41,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:41,973 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:20<1:05:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:49,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021542174741625786, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.588, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01782580465078354, 'eval_loss_2': 0.0037163682281970978, 'eval_loss_3': -18.293941497802734, 'eval_loss_4': 2.7131927013397217, 'epoch': 7.97}
{'loss': 0.025, 'grad_norm': 6.537812232971191, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.018257321789860725, 'loss_2': 0.0067596435546875, 'loss_3': -16.544540405273438, 'loss_4': 2.7928147315979004, 'epoch': 7.97}
{'loss': 0.0226, 'grad_norm': 5.949989318847656, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.014524363912642002, 'loss_2': 0.008026123046875, 'loss_3': -16.384307861328125, 'loss_4': 3.1130685806274414, 'epoch': 7.98}
{'loss': 0.0262, 'grad_norm': 7.774880409240723, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.020769312977790833, 'loss_2': 0.0054779052734375, 'loss_3': -16.47945785522461, 'loss_4': 3.3766326904296875, 'epoch': 7.98}
{'loss': 0.0314, 'grad_norm': 19.831436157226562, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.02747788466513157, 'loss_2': 0.0039520263671875, 'loss_3': -16.119972229003906, 'loss_4': 2.698420286178589, 'epoch': 7.99}
{'loss': 0.0192, 'grad_norm': 5.668720245361328, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.010463748127222061, 'loss_2': 0.0087738037109375, 'loss_3': -16.291791915893555, 'loss_4': 2.789836883544922, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 15:51:49,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:49,330 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:27<1:04:17,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:51:56,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017752259969711304, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.953, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01255118940025568, 'eval_loss_2': 0.005201071500778198, 'eval_loss_3': -18.325454711914062, 'eval_loss_4': 2.7818689346313477, 'epoch': 7.99}
{'loss': 0.0143, 'grad_norm': 5.732054233551025, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.008299686014652252, 'loss_2': 0.0059814453125, 'loss_3': -15.957072257995605, 'loss_4': 2.413689374923706, 'epoch': 8.0}
{'loss': 0.0217, 'grad_norm': 8.123299598693848, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.01581849716603756, 'loss_2': 0.0058746337890625, 'loss_3': -16.589374542236328, 'loss_4': 3.071237087249756, 'epoch': 8.01}
{'loss': 0.02, 'grad_norm': 6.874435901641846, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.017075153067708015, 'loss_2': 0.0029582977294921875, 'loss_3': -16.452598571777344, 'loss_4': 2.806365966796875, 'epoch': 8.01}
{'loss': 0.0202, 'grad_norm': 7.089249610900879, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.015651144087314606, 'loss_2': 0.0045623779296875, 'loss_3': -16.23686408996582, 'loss_4': 3.2080278396606445, 'epoch': 8.02}
{'loss': 0.0268, 'grad_norm': 8.915517807006836, 'learning_rate': 2.2e-05, 'loss_1': 0.024968579411506653, 'loss_2': 0.0018062591552734375, 'loss_3': -16.204362869262695, 'loss_4': 2.817923069000244, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 15:51:56,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:56,405 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:34<1:05:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:03,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018696239218115807, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013171812519431114, 'eval_loss_2': 0.005524426698684692, 'eval_loss_3': -18.333454132080078, 'eval_loss_4': 2.904231309890747, 'epoch': 8.02}
{'loss': 0.0252, 'grad_norm': 7.047178268432617, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.020813943818211555, 'loss_2': 0.00435638427734375, 'loss_3': -16.33902359008789, 'loss_4': 3.216426134109497, 'epoch': 8.03}
{'loss': 0.0319, 'grad_norm': 9.117141723632812, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.021244550123810768, 'loss_2': 0.0106353759765625, 'loss_3': -16.217126846313477, 'loss_4': 3.032641649246216, 'epoch': 8.03}
{'loss': 0.0373, 'grad_norm': 12.173267364501953, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.025229735299944878, 'loss_2': 0.012054443359375, 'loss_3': -16.362606048583984, 'loss_4': 2.918036460876465, 'epoch': 8.04}
{'loss': 0.0269, 'grad_norm': 8.150593757629395, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.01718055084347725, 'loss_2': 0.00968170166015625, 'loss_3': -16.340152740478516, 'loss_4': 2.8025424480438232, 'epoch': 8.05}
{'loss': 0.0218, 'grad_norm': 6.646271228790283, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.015184450894594193, 'loss_2': 0.006595611572265625, 'loss_3': -16.3604736328125, 'loss_4': 2.7863152027130127, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 15:52:03,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:03,770 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:41<1:05:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:11,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024408377707004547, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.497, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012939255684614182, 'eval_loss_2': 0.011469125747680664, 'eval_loss_3': -18.332321166992188, 'eval_loss_4': 2.625972032546997, 'epoch': 8.05}
{'loss': 0.038, 'grad_norm': 11.954476356506348, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.03194407373666763, 'loss_2': 0.006103515625, 'loss_3': -16.392635345458984, 'loss_4': 2.746079921722412, 'epoch': 8.06}
{'loss': 0.0356, 'grad_norm': 8.102965354919434, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.023682694882154465, 'loss_2': 0.011932373046875, 'loss_3': -16.404436111450195, 'loss_4': 2.5730538368225098, 'epoch': 8.06}
{'loss': 0.0404, 'grad_norm': 12.793937683105469, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.02605452388525009, 'loss_2': 0.014312744140625, 'loss_3': -16.471277236938477, 'loss_4': 2.7922990322113037, 'epoch': 8.07}
{'loss': 0.0176, 'grad_norm': 7.3298563957214355, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.014018114656209946, 'loss_2': 0.0035495758056640625, 'loss_3': -16.261783599853516, 'loss_4': 2.3267006874084473, 'epoch': 8.08}
{'loss': 0.0183, 'grad_norm': 6.7183637619018555, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.012588712386786938, 'loss_2': 0.00569915771484375, 'loss_3': -16.617881774902344, 'loss_4': 2.5594053268432617, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 15:52:11,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:11,124 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:49<1:05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:18,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0156867615878582, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.154, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012464519590139389, 'eval_loss_2': 0.003222241997718811, 'eval_loss_3': -18.315168380737305, 'eval_loss_4': 2.0029489994049072, 'epoch': 8.08}
{'loss': 0.0298, 'grad_norm': 9.431354522705078, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.02834227681159973, 'loss_2': 0.001445770263671875, 'loss_3': -16.419357299804688, 'loss_4': 2.4491469860076904, 'epoch': 8.09}
{'loss': 0.0151, 'grad_norm': 5.295745849609375, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.012339571490883827, 'loss_2': 0.002750396728515625, 'loss_3': -16.365633010864258, 'loss_4': 1.9475903511047363, 'epoch': 8.09}
{'loss': 0.0402, 'grad_norm': 11.092089653015137, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.029496585950255394, 'loss_2': 0.0106658935546875, 'loss_3': -16.498552322387695, 'loss_4': 1.8935439586639404, 'epoch': 8.1}
{'loss': 0.0176, 'grad_norm': 6.802272796630859, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.012904119677841663, 'loss_2': 0.00469207763671875, 'loss_3': -16.415353775024414, 'loss_4': 2.0279393196105957, 'epoch': 8.1}
{'loss': 0.0181, 'grad_norm': 6.917726993560791, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.014688422903418541, 'loss_2': 0.003376007080078125, 'loss_3': -16.364078521728516, 'loss_4': 2.34950590133667, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 15:52:18,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:18,487 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:56<1:05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:25,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022085729986429214, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.455, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015056224539875984, 'eval_loss_2': 0.007029503583908081, 'eval_loss_3': -18.26350212097168, 'eval_loss_4': 1.6560410261154175, 'epoch': 8.11}
{'loss': 0.0229, 'grad_norm': 5.947365760803223, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.010983902961015701, 'loss_2': 0.01190948486328125, 'loss_3': -16.116931915283203, 'loss_4': 1.5489208698272705, 'epoch': 8.12}
{'loss': 0.0281, 'grad_norm': 9.341451644897461, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.01720285415649414, 'loss_2': 0.0108642578125, 'loss_3': -16.396198272705078, 'loss_4': 1.3909215927124023, 'epoch': 8.12}
{'loss': 0.0208, 'grad_norm': 5.890717029571533, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.009894512593746185, 'loss_2': 0.0108795166015625, 'loss_3': -16.334070205688477, 'loss_4': 1.6435468196868896, 'epoch': 8.13}
{'loss': 0.0139, 'grad_norm': 6.35923957824707, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.011399166658520699, 'loss_2': 0.002460479736328125, 'loss_3': -16.244365692138672, 'loss_4': 1.8809409141540527, 'epoch': 8.13}
{'loss': 0.0245, 'grad_norm': 8.168879508972168, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.02161288633942604, 'loss_2': 0.0029239654541015625, 'loss_3': -16.246925354003906, 'loss_4': 1.5607333183288574, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 15:52:25,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:25,846 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [35:04<1:05:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:33,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02463708445429802, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.447, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.021045349538326263, 'eval_loss_2': 0.0035917386412620544, 'eval_loss_3': -18.18758201599121, 'eval_loss_4': 1.4682351350784302, 'epoch': 8.14}
{'loss': 0.0215, 'grad_norm': 11.651236534118652, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.02097776159644127, 'loss_2': 0.0005016326904296875, 'loss_3': -16.045827865600586, 'loss_4': 1.3229904174804688, 'epoch': 8.15}
{'loss': 0.0185, 'grad_norm': 6.937255859375, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.016559872776269913, 'loss_2': 0.001987457275390625, 'loss_3': -16.31909942626953, 'loss_4': 1.5188710689544678, 'epoch': 8.15}
{'loss': 0.0392, 'grad_norm': 11.390108108520508, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.028730472549796104, 'loss_2': 0.0104217529296875, 'loss_3': -16.299697875976562, 'loss_4': 1.359961748123169, 'epoch': 8.16}
{'loss': 0.0242, 'grad_norm': 6.678409099578857, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.015090914443135262, 'loss_2': 0.00907135009765625, 'loss_3': -16.416675567626953, 'loss_4': 1.570127010345459, 'epoch': 8.16}
{'loss': 0.0162, 'grad_norm': 5.86737585067749, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.008320673368871212, 'loss_2': 0.00792694091796875, 'loss_3': -16.25775909423828, 'loss_4': 0.9222275018692017, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 15:52:33,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:33,216 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [35:11<1:05:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:40,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020595429465174675, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.206, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016802754253149033, 'eval_loss_2': 0.003792673349380493, 'eval_loss_3': -18.189678192138672, 'eval_loss_4': 1.1299303770065308, 'epoch': 8.17}
{'loss': 0.0103, 'grad_norm': 4.878472328186035, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.008724994957447052, 'loss_2': 0.0015583038330078125, 'loss_3': -16.33502197265625, 'loss_4': 1.3925998210906982, 'epoch': 8.17}
{'loss': 0.0563, 'grad_norm': 38.6934700012207, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.04628657549619675, 'loss_2': 0.0099639892578125, 'loss_3': -16.060497283935547, 'loss_4': 1.4497101306915283, 'epoch': 8.18}
{'loss': 0.0382, 'grad_norm': 11.872003555297852, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.03284488245844841, 'loss_2': 0.005401611328125, 'loss_3': -16.289173126220703, 'loss_4': 0.9231201410293579, 'epoch': 8.19}
{'loss': 0.0139, 'grad_norm': 7.29019021987915, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.01081872545182705, 'loss_2': 0.00312042236328125, 'loss_3': -16.511507034301758, 'loss_4': 1.614682674407959, 'epoch': 8.19}
{'loss': 0.025, 'grad_norm': 14.89572525024414, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.021472636610269547, 'loss_2': 0.0035076141357421875, 'loss_3': -16.225202560424805, 'loss_4': 1.2781474590301514, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 15:52:40,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:40,572 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:18<1:04:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:47,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01527949795126915, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009958337992429733, 'eval_loss_2': 0.0053211599588394165, 'eval_loss_3': -18.178499221801758, 'eval_loss_4': 0.8011199831962585, 'epoch': 8.2}
{'loss': 0.016, 'grad_norm': 7.341552734375, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.009352750144898891, 'loss_2': 0.006664276123046875, 'loss_3': -16.200241088867188, 'loss_4': 0.7499957084655762, 'epoch': 8.2}
{'loss': 0.0212, 'grad_norm': 5.223323822021484, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.0065191988833248615, 'loss_2': 0.0146331787109375, 'loss_3': -16.04522705078125, 'loss_4': 1.1967995166778564, 'epoch': 8.21}
{'loss': 0.0205, 'grad_norm': 5.794425964355469, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.007407396100461483, 'loss_2': 0.013092041015625, 'loss_3': -16.265575408935547, 'loss_4': 0.6939789056777954, 'epoch': 8.22}
{'loss': 0.0213, 'grad_norm': 6.203390598297119, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.007532636635005474, 'loss_2': 0.0137176513671875, 'loss_3': -16.323989868164062, 'loss_4': 0.5970947742462158, 'epoch': 8.22}
{'loss': 0.0374, 'grad_norm': 12.950778007507324, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.03479986637830734, 'loss_2': 0.0025577545166015625, 'loss_3': -16.404579162597656, 'loss_4': 0.7913457155227661, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 15:52:47,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:47,930 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:22<1:04:56,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:52:51,739 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1415
[INFO|configuration_utils.py:420] 2025-01-21 15:52:51,740 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1415/config.json                                                                            
{'eval_loss': 0.010547790676355362, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.899, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008672516793012619, 'eval_loss_2': 0.001875273883342743, 'eval_loss_3': -18.14315414428711, 'eval_loss_4': 0.5887767672538757, 'epoch': 8.23}
[INFO|modeling_utils.py:2988] 2025-01-21 15:52:52,236 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1415/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:52:52,238 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1415/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:52:52,238 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1415/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:52:53,193 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-650] due to args.save_total_limit
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:27<1:11:40,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:52:56,830 >>
{'loss': 0.0365, 'grad_norm': 21.74728012084961, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.03633643686771393, 'loss_2': 0.00013685226440429688, 'loss_3': -16.134765625, 'loss_4': 0.9743386507034302, 'epoch': 8.23}
{'loss': 0.0235, 'grad_norm': 10.956514358520508, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.01990208774805069, 'loss_2': 0.003627777099609375, 'loss_3': -16.265178680419922, 'loss_4': 1.0358808040618896, 'epoch': 8.24}
{'loss': 0.0178, 'grad_norm': 7.444620132446289, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.013647312298417091, 'loss_2': 0.00411224365234375, 'loss_3': -16.385343551635742, 'loss_4': 1.0360406637191772, 'epoch': 8.24}
{'loss': 0.0165, 'grad_norm': 8.489584922790527, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.01554361917078495, 'loss_2': 0.0009579658508300781, 'loss_3': -16.333141326904297, 'loss_4': 0.33299708366394043, 'epoch': 8.25}
{'loss': 0.0206, 'grad_norm': 8.795254707336426, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.01579606719315052, 'loss_2': 0.0048065185546875, 'loss_3': -16.184396743774414, 'loss_4': 1.105924367904663, 'epoch': 8.26}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:52:56,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:56,830 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:35<1:05:53,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:53:04,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012734385207295418, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008331377059221268, 'eval_loss_2': 0.004403010010719299, 'eval_loss_3': -18.112024307250977, 'eval_loss_4': 0.5178218483924866, 'epoch': 8.26}
{'loss': 0.0295, 'grad_norm': 13.032614707946777, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.028061604127287865, 'loss_2': 0.0014476776123046875, 'loss_3': -16.29727554321289, 'loss_4': 0.6790162324905396, 'epoch': 8.26}
{'loss': 0.0634, 'grad_norm': 22.38087272644043, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.05558498948812485, 'loss_2': 0.007778167724609375, 'loss_3': -15.974597930908203, 'loss_4': 0.9873731136322021, 'epoch': 8.27}
{'loss': 0.0213, 'grad_norm': 10.328184127807617, 'learning_rate': 2.175e-05, 'loss_1': 0.020185545086860657, 'loss_2': 0.0011234283447265625, 'loss_3': -16.132972717285156, 'loss_4': 0.8672338724136353, 'epoch': 8.27}
{'loss': 0.0137, 'grad_norm': 5.770979404449463, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.008389010094106197, 'loss_2': 0.005321502685546875, 'loss_3': -16.427936553955078, 'loss_4': 1.0197422504425049, 'epoch': 8.28}
{'loss': 0.0093, 'grad_norm': 4.564897537231445, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.0034425987396389246, 'loss_2': 0.00588226318359375, 'loss_3': -16.43107795715332, 'loss_4': 0.4294869303703308, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 15:53:04,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:04,183 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:42<1:04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:11,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015054455026984215, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.792, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006623259745538235, 'eval_loss_2': 0.008431196212768555, 'eval_loss_3': -18.13966941833496, 'eval_loss_4': 0.44104015827178955, 'epoch': 8.28}
{'loss': 0.0407, 'grad_norm': 26.456846237182617, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.030655402690172195, 'loss_2': 0.01003265380859375, 'loss_3': -16.395265579223633, 'loss_4': 0.5300642251968384, 'epoch': 8.29}
{'loss': 0.0105, 'grad_norm': 5.224809646606445, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.005816532298922539, 'loss_2': 0.00467681884765625, 'loss_3': -16.278968811035156, 'loss_4': 0.25576668977737427, 'epoch': 8.3}
{'loss': 0.0151, 'grad_norm': 4.904179096221924, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.00710460776463151, 'loss_2': 0.008026123046875, 'loss_3': -16.354736328125, 'loss_4': 0.4441632628440857, 'epoch': 8.3}
{'loss': 0.02, 'grad_norm': 6.8301849365234375, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.016366463154554367, 'loss_2': 0.0036258697509765625, 'loss_3': -15.92263412475586, 'loss_4': 0.5445517301559448, 'epoch': 8.31}
{'loss': 0.0101, 'grad_norm': 5.33257532119751, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.009776930324733257, 'loss_2': 0.00031566619873046875, 'loss_3': -16.127153396606445, 'loss_4': 0.39965301752090454, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 15:53:11,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:11,547 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:46<1:04:50,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:53:15,368 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1430
[INFO|configuration_utils.py:420] 2025-01-21 15:53:15,369 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1430/config.json                                                                            
{'eval_loss': 0.009808770380914211, 'eval_runtime': 3.8198, 'eval_samples_per_second': 268.076, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.00630365964025259, 'eval_loss_2': 0.003505110740661621, 'eval_loss_3': -18.17169952392578, 'eval_loss_4': 0.44095897674560547, 'epoch': 8.31}
[INFO|modeling_utils.py:2988] 2025-01-21 15:53:15,849 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1430/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:53:15,850 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1430/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:53:15,851 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1430/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:53:16,817 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1415] due to args.save_total_limit
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:51<1:11:30,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:53:20,463 >>
{'loss': 0.0208, 'grad_norm': 9.025469779968262, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.01632600650191307, 'loss_2': 0.0044708251953125, 'loss_3': -16.297073364257812, 'loss_4': 0.6508036255836487, 'epoch': 8.32}
{'loss': 0.0117, 'grad_norm': 6.181573867797852, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.009964736178517342, 'loss_2': 0.00176239013671875, 'loss_3': -16.256675720214844, 'loss_4': 0.6573281288146973, 'epoch': 8.33}
{'loss': 0.0076, 'grad_norm': 5.16607141494751, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.006261996924877167, 'loss_2': 0.0013065338134765625, 'loss_3': -16.361637115478516, 'loss_4': 0.9742282629013062, 'epoch': 8.33}
{'loss': 0.0196, 'grad_norm': 5.689490795135498, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.009210304357111454, 'loss_2': 0.010345458984375, 'loss_3': -16.080852508544922, 'loss_4': 0.5406232476234436, 'epoch': 8.34}
{'loss': 0.0176, 'grad_norm': 10.206124305725098, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.012626847252249718, 'loss_2': 0.00494384765625, 'loss_3': -16.459081649780273, 'loss_4': 0.6595488786697388, 'epoch': 8.34}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:53:20,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:20,463 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:58<1:05:28,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:53:27,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011527173221111298, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.557, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0053731463849544525, 'eval_loss_2': 0.006154026836156845, 'eval_loss_3': -18.185894012451172, 'eval_loss_4': 0.4674680233001709, 'epoch': 8.34}
{'loss': 0.0156, 'grad_norm': 6.013867378234863, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.008081632666289806, 'loss_2': 0.0075225830078125, 'loss_3': -16.250812530517578, 'loss_4': 0.4449055790901184, 'epoch': 8.35}
{'loss': 0.0127, 'grad_norm': 6.427618026733398, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.009418275207281113, 'loss_2': 0.00328826904296875, 'loss_3': -16.299718856811523, 'loss_4': 0.5492719411849976, 'epoch': 8.35}
{'loss': 0.0312, 'grad_norm': 17.38242530822754, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.026357309892773628, 'loss_2': 0.004878997802734375, 'loss_3': -16.188098907470703, 'loss_4': 0.6164605021476746, 'epoch': 8.36}
{'loss': 0.0255, 'grad_norm': 12.52346134185791, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.018539419397711754, 'loss_2': 0.006938934326171875, 'loss_3': -16.2799129486084, 'loss_4': 0.8816275596618652, 'epoch': 8.37}
{'loss': 0.0253, 'grad_norm': 11.931940078735352, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.019389722496271133, 'loss_2': 0.005931854248046875, 'loss_3': -16.17512321472168, 'loss_4': 0.3709470331668854, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 15:53:27,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:27,803 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [36:05<1:04:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:35,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010493519715964794, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0061548370867967606, 'eval_loss_2': 0.004338681697845459, 'eval_loss_3': -18.15194320678711, 'eval_loss_4': 0.5011633038520813, 'epoch': 8.37}
{'loss': 0.0136, 'grad_norm': 6.826502323150635, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.007991763763129711, 'loss_2': 0.005573272705078125, 'loss_3': -16.28411293029785, 'loss_4': 0.571402907371521, 'epoch': 8.38}
{'loss': 0.0134, 'grad_norm': 5.213411808013916, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.006974570453166962, 'loss_2': 0.006443023681640625, 'loss_3': -16.329078674316406, 'loss_4': 0.5817266702651978, 'epoch': 8.38}
{'loss': 0.0187, 'grad_norm': 7.241066932678223, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.011104293167591095, 'loss_2': 0.007598876953125, 'loss_3': -16.14335060119629, 'loss_4': 1.0118749141693115, 'epoch': 8.39}
{'loss': 0.0293, 'grad_norm': 7.223932266235352, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.025579094886779785, 'loss_2': 0.00372314453125, 'loss_3': -16.185163497924805, 'loss_4': 0.7703429460525513, 'epoch': 8.4}
{'loss': 0.0147, 'grad_norm': 5.522012233734131, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.0076411510817706585, 'loss_2': 0.00705718994140625, 'loss_3': -16.301921844482422, 'loss_4': 0.9995870590209961, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 15:53:35,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:35,149 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:13<1:04:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:42,497 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017083996906876564, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.583, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010388906113803387, 'eval_loss_2': 0.006695091724395752, 'eval_loss_3': -18.114078521728516, 'eval_loss_4': 0.7592453360557556, 'epoch': 8.4}
{'loss': 0.0164, 'grad_norm': 8.195393562316895, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.01167529821395874, 'loss_2': 0.00469207763671875, 'loss_3': -16.255760192871094, 'loss_4': 0.8728766441345215, 'epoch': 8.41}
{'loss': 0.0161, 'grad_norm': 5.930135726928711, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.010512946173548698, 'loss_2': 0.005558013916015625, 'loss_3': -16.176111221313477, 'loss_4': 0.7382495403289795, 'epoch': 8.41}
{'loss': 0.0107, 'grad_norm': 6.249239444732666, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.0093624172732234, 'loss_2': 0.0013856887817382812, 'loss_3': -16.2362003326416, 'loss_4': 0.8817294836044312, 'epoch': 8.42}
{'loss': 0.0231, 'grad_norm': 7.845754623413086, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.017074398696422577, 'loss_2': 0.006023406982421875, 'loss_3': -16.166025161743164, 'loss_4': 0.7568530440330505, 'epoch': 8.42}
{'loss': 0.0138, 'grad_norm': 6.335580348968506, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.009588400833308697, 'loss_2': 0.004261016845703125, 'loss_3': -16.167190551757812, 'loss_4': 0.7927155494689941, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 15:53:42,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:42,497 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:20<1:04:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:49,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017035681754350662, 'eval_runtime': 3.8231, 'eval_samples_per_second': 267.843, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.012926573865115643, 'eval_loss_2': 0.004109106957912445, 'eval_loss_3': -18.12485694885254, 'eval_loss_4': 0.7204455137252808, 'epoch': 8.43}
{'loss': 0.0068, 'grad_norm': 4.593613624572754, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.004850109573453665, 'loss_2': 0.001995086669921875, 'loss_3': -16.420989990234375, 'loss_4': 0.6354426145553589, 'epoch': 8.44}
{'loss': 0.0285, 'grad_norm': 12.241401672363281, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.020007401704788208, 'loss_2': 0.00848388671875, 'loss_3': -16.228910446166992, 'loss_4': 1.0041146278381348, 'epoch': 8.44}
{'loss': 0.0193, 'grad_norm': 6.876791954040527, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.014302633702754974, 'loss_2': 0.0049591064453125, 'loss_3': -15.977045059204102, 'loss_4': 0.9363514184951782, 'epoch': 8.45}
{'loss': 0.0297, 'grad_norm': 6.972842216491699, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.017973480746150017, 'loss_2': 0.01171112060546875, 'loss_3': -16.245906829833984, 'loss_4': 0.9857528805732727, 'epoch': 8.45}
{'loss': 0.0188, 'grad_norm': 12.100528717041016, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.01784123107790947, 'loss_2': 0.0009746551513671875, 'loss_3': -16.19220542907715, 'loss_4': 0.44685691595077515, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 15:53:49,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:49,879 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:28<1:04:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:57,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0178353413939476, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013275625184178352, 'eval_loss_2': 0.004559718072414398, 'eval_loss_3': -18.127357482910156, 'eval_loss_4': 0.6448091864585876, 'epoch': 8.46}
{'loss': 0.0308, 'grad_norm': 10.373748779296875, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.028265783563256264, 'loss_2': 0.0025653839111328125, 'loss_3': -16.04639434814453, 'loss_4': 0.6458507180213928, 'epoch': 8.47}
{'loss': 0.0189, 'grad_norm': 5.961066722869873, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.014590682461857796, 'loss_2': 0.00429534912109375, 'loss_3': -16.105684280395508, 'loss_4': 0.5827375054359436, 'epoch': 8.47}
{'loss': 0.014, 'grad_norm': 5.723710536956787, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.011142141185700893, 'loss_2': 0.002857208251953125, 'loss_3': -16.30377960205078, 'loss_4': 0.04909536615014076, 'epoch': 8.48}
{'loss': 0.0174, 'grad_norm': 5.522322177886963, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.010042806155979633, 'loss_2': 0.007354736328125, 'loss_3': -16.40504264831543, 'loss_4': 0.8526753187179565, 'epoch': 8.48}
{'loss': 0.0204, 'grad_norm': 13.544187545776367, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.01943250559270382, 'loss_2': 0.0009851455688476562, 'loss_3': -15.951775550842285, 'loss_4': 0.5147385597229004, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 15:53:57,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:57,241 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:35<1:04:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:04,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01883469894528389, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.118, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014717577025294304, 'eval_loss_2': 0.004117123782634735, 'eval_loss_3': -18.139507293701172, 'eval_loss_4': 0.6480349898338318, 'epoch': 8.49}
{'loss': 0.0119, 'grad_norm': 5.569928169250488, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.008039766922593117, 'loss_2': 0.0038909912109375, 'loss_3': -16.17715072631836, 'loss_4': 1.0331835746765137, 'epoch': 8.49}
{'loss': 0.0305, 'grad_norm': 20.50602149963379, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.02430262230336666, 'loss_2': 0.00618743896484375, 'loss_3': -16.043258666992188, 'loss_4': 0.518979549407959, 'epoch': 8.5}
{'loss': 0.0149, 'grad_norm': 6.015999794006348, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.013045337051153183, 'loss_2': 0.0018215179443359375, 'loss_3': -16.264381408691406, 'loss_4': 0.5023741722106934, 'epoch': 8.51}
{'loss': 0.0123, 'grad_norm': 4.9899396896362305, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.008909407071769238, 'loss_2': 0.003414154052734375, 'loss_3': -16.156352996826172, 'loss_4': 0.6088938117027283, 'epoch': 8.51}
{'loss': 0.0238, 'grad_norm': 8.201925277709961, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.0221633929759264, 'loss_2': 0.0016183853149414062, 'loss_3': -16.143207550048828, 'loss_4': 0.6830465793609619, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 15:54:04,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:04,603 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:42<1:03:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:11,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01903916522860527, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01578044705092907, 'eval_loss_2': 0.0032587163150310516, 'eval_loss_3': -18.14714813232422, 'eval_loss_4': 0.6069909334182739, 'epoch': 8.52}
{'loss': 0.0129, 'grad_norm': 4.4710845947265625, 'learning_rate': 2.15e-05, 'loss_1': 0.005206241738051176, 'loss_2': 0.007717132568359375, 'loss_3': -16.17176055908203, 'loss_4': 0.7052716612815857, 'epoch': 8.52}
{'loss': 0.015, 'grad_norm': 7.439579010009766, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.01016798336058855, 'loss_2': 0.004802703857421875, 'loss_3': -16.420448303222656, 'loss_4': 0.6400659084320068, 'epoch': 8.53}
{'loss': 0.0095, 'grad_norm': 5.122800350189209, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.007114925887435675, 'loss_2': 0.002429962158203125, 'loss_3': -16.396804809570312, 'loss_4': 0.5576218366622925, 'epoch': 8.53}
{'loss': 0.0266, 'grad_norm': 8.811934471130371, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.016671234741806984, 'loss_2': 0.009918212890625, 'loss_3': -16.33006477355957, 'loss_4': 0.9231055974960327, 'epoch': 8.54}
{'loss': 0.0148, 'grad_norm': 6.424797058105469, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.011365723796188831, 'loss_2': 0.003429412841796875, 'loss_3': -16.39969253540039, 'loss_4': 0.4865275025367737, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 15:54:11,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:11,960 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:50<1:03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:19,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017720084637403488, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014784271828830242, 'eval_loss_2': 0.0029358118772506714, 'eval_loss_3': -18.142736434936523, 'eval_loss_4': 0.4603275656700134, 'epoch': 8.55}
{'loss': 0.0156, 'grad_norm': 8.707277297973633, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.014942726120352745, 'loss_2': 0.0006761550903320312, 'loss_3': -16.255271911621094, 'loss_4': 0.20860415697097778, 'epoch': 8.55}
{'loss': 0.0444, 'grad_norm': 16.634395599365234, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.04427231848239899, 'loss_2': 0.00014853477478027344, 'loss_3': -16.188671112060547, 'loss_4': 0.6942368149757385, 'epoch': 8.56}
{'loss': 0.0177, 'grad_norm': 7.362612724304199, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.012704766355454922, 'loss_2': 0.0050048828125, 'loss_3': -16.1771240234375, 'loss_4': 0.47469958662986755, 'epoch': 8.56}
{'loss': 0.0266, 'grad_norm': 6.97111701965332, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.01738855428993702, 'loss_2': 0.0091705322265625, 'loss_3': -16.549114227294922, 'loss_4': -0.07393241673707962, 'epoch': 8.57}
{'loss': 0.0759, 'grad_norm': 19.58070182800293, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.06702811270952225, 'loss_2': 0.0088958740234375, 'loss_3': -15.96193790435791, 'loss_4': 0.9624237418174744, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 15:54:19,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:19,315 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:57<1:03:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:26,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015275035053491592, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009023105725646019, 'eval_loss_2': 0.006251931190490723, 'eval_loss_3': -18.20878028869629, 'eval_loss_4': 0.4714547097682953, 'epoch': 8.58}
{'loss': 0.0239, 'grad_norm': 6.350706100463867, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.009786941111087799, 'loss_2': 0.0140838623046875, 'loss_3': -16.08190155029297, 'loss_4': 0.3836601674556732, 'epoch': 8.58}
{'loss': 0.0392, 'grad_norm': 13.328875541687012, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.027695609256625175, 'loss_2': 0.0114593505859375, 'loss_3': -16.16257095336914, 'loss_4': 0.35472795367240906, 'epoch': 8.59}
{'loss': 0.0388, 'grad_norm': 12.740090370178223, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.028570689260959625, 'loss_2': 0.01019287109375, 'loss_3': -16.2327938079834, 'loss_4': 0.46111929416656494, 'epoch': 8.59}
{'loss': 0.029, 'grad_norm': 13.062173843383789, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.02765357308089733, 'loss_2': 0.00133514404296875, 'loss_3': -16.47954559326172, 'loss_4': 0.8745224475860596, 'epoch': 8.6}
{'loss': 0.019, 'grad_norm': 5.9668474197387695, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.013408991508185863, 'loss_2': 0.005611419677734375, 'loss_3': -16.340335845947266, 'loss_4': 0.9307199716567993, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 15:54:26,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:26,680 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [37:04<1:03:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:34,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01071782223880291, 'eval_runtime': 3.8217, 'eval_samples_per_second': 267.943, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.007764703128486872, 'eval_loss_2': 0.0029531195759773254, 'eval_loss_3': -18.239030838012695, 'eval_loss_4': 0.71204674243927, 'epoch': 8.6}
{'loss': 0.0109, 'grad_norm': 5.277521133422852, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.010143489576876163, 'loss_2': 0.0007753372192382812, 'loss_3': -16.220272064208984, 'loss_4': 0.4750233292579651, 'epoch': 8.61}
{'loss': 0.0133, 'grad_norm': 6.259280681610107, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.009862490929663181, 'loss_2': 0.003452301025390625, 'loss_3': -16.19207191467285, 'loss_4': 0.5569310188293457, 'epoch': 8.62}
{'loss': 0.0126, 'grad_norm': 6.4469475746154785, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.012301215901970863, 'loss_2': 0.0003371238708496094, 'loss_3': -16.22985076904297, 'loss_4': 1.0725791454315186, 'epoch': 8.62}
{'loss': 0.0308, 'grad_norm': 13.279312133789062, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.021556852385401726, 'loss_2': 0.0092926025390625, 'loss_3': -16.243711471557617, 'loss_4': 1.0591681003570557, 'epoch': 8.63}
{'loss': 0.0274, 'grad_norm': 8.061358451843262, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.015798965469002724, 'loss_2': 0.011566162109375, 'loss_3': -16.248577117919922, 'loss_4': 1.1294631958007812, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 15:54:34,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:34,061 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:12<1:03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:41,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017935888841748238, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008733650669455528, 'eval_loss_2': 0.00920223817229271, 'eval_loss_3': -18.257774353027344, 'eval_loss_4': 1.0636931657791138, 'epoch': 8.63}
{'loss': 0.0245, 'grad_norm': 11.338520050048828, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.02050940692424774, 'loss_2': 0.00399017333984375, 'loss_3': -16.11023712158203, 'loss_4': 1.3426845073699951, 'epoch': 8.64}
{'loss': 0.0292, 'grad_norm': 14.390532493591309, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.018106656149029732, 'loss_2': 0.01104736328125, 'loss_3': -16.259702682495117, 'loss_4': 1.4634373188018799, 'epoch': 8.65}
{'loss': 0.0536, 'grad_norm': 11.62398910522461, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.043776363134384155, 'loss_2': 0.00984954833984375, 'loss_3': -16.246932983398438, 'loss_4': 1.3714277744293213, 'epoch': 8.65}
{'loss': 0.0757, 'grad_norm': 20.942432403564453, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.05994648486375809, 'loss_2': 0.0157928466796875, 'loss_3': -16.173555374145508, 'loss_4': 1.619288444519043, 'epoch': 8.66}
{'loss': 0.0965, 'grad_norm': 16.646787643432617, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.08914462476968765, 'loss_2': 0.00736236572265625, 'loss_3': -16.21619415283203, 'loss_4': 1.5066697597503662, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 15:54:41,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:41,431 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:19<1:03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:48,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018243458122015, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008747276850044727, 'eval_loss_2': 0.009496182203292847, 'eval_loss_3': -18.2353458404541, 'eval_loss_4': 1.1108758449554443, 'epoch': 8.66}
{'loss': 0.0182, 'grad_norm': 5.885010242462158, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.010033618658781052, 'loss_2': 0.00812530517578125, 'loss_3': -16.29319953918457, 'loss_4': 1.2581040859222412, 'epoch': 8.67}
{'loss': 0.0249, 'grad_norm': 8.318477630615234, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.018893646076321602, 'loss_2': 0.0059967041015625, 'loss_3': -16.308395385742188, 'loss_4': 1.1094462871551514, 'epoch': 8.67}
{'loss': 0.0157, 'grad_norm': 5.643503189086914, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.013166047632694244, 'loss_2': 0.0025196075439453125, 'loss_3': -16.414657592773438, 'loss_4': 1.466483473777771, 'epoch': 8.68}
{'loss': 0.0312, 'grad_norm': 12.69324779510498, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.030550586059689522, 'loss_2': 0.0006766319274902344, 'loss_3': -16.490694046020508, 'loss_4': 1.0170353651046753, 'epoch': 8.69}
{'loss': 0.0169, 'grad_norm': 6.965709209442139, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.014425924979150295, 'loss_2': 0.002429962158203125, 'loss_3': -16.231220245361328, 'loss_4': 1.0595709085464478, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 15:54:48,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:48,800 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:27<1:03:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:56,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01384061574935913, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00989182386547327, 'eval_loss_2': 0.003948792815208435, 'eval_loss_3': -18.236188888549805, 'eval_loss_4': 1.0451133251190186, 'epoch': 8.69}
{'loss': 0.0275, 'grad_norm': 13.391494750976562, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.026110148057341576, 'loss_2': 0.0014190673828125, 'loss_3': -16.43235969543457, 'loss_4': 0.7874664068222046, 'epoch': 8.7}
{'loss': 0.078, 'grad_norm': 26.00655174255371, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.07569962739944458, 'loss_2': 0.0023441314697265625, 'loss_3': -16.231910705566406, 'loss_4': 0.5910645723342896, 'epoch': 8.7}
{'loss': 0.0177, 'grad_norm': 7.865657806396484, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.014861363917589188, 'loss_2': 0.0028247833251953125, 'loss_3': -16.35429573059082, 'loss_4': 1.4428224563598633, 'epoch': 8.71}
{'loss': 0.0192, 'grad_norm': 6.574190139770508, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.011865698732435703, 'loss_2': 0.00733184814453125, 'loss_3': -16.491146087646484, 'loss_4': 0.8049201369285583, 'epoch': 8.72}
{'loss': 0.0401, 'grad_norm': 11.711244583129883, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.033812593668699265, 'loss_2': 0.0063018798828125, 'loss_3': -16.34899139404297, 'loss_4': 0.5556033253669739, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 15:54:56,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:56,165 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:34<1:03:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:03,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014017077162861824, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008632572367787361, 'eval_loss_2': 0.005384504795074463, 'eval_loss_3': -18.227434158325195, 'eval_loss_4': 0.8535947203636169, 'epoch': 8.72}
{'loss': 0.0279, 'grad_norm': 10.43571662902832, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.02063850872218609, 'loss_2': 0.0072479248046875, 'loss_3': -16.56854248046875, 'loss_4': 0.9030504822731018, 'epoch': 8.73}
{'loss': 0.0112, 'grad_norm': 5.557132720947266, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.007885591126978397, 'loss_2': 0.003314971923828125, 'loss_3': -16.299983978271484, 'loss_4': 0.6375576257705688, 'epoch': 8.73}
{'loss': 0.0275, 'grad_norm': 8.59687328338623, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.025542041286826134, 'loss_2': 0.0019407272338867188, 'loss_3': -16.343334197998047, 'loss_4': 0.6637094020843506, 'epoch': 8.74}
{'loss': 0.0333, 'grad_norm': 11.238104820251465, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.027701810002326965, 'loss_2': 0.005584716796875, 'loss_3': -16.36378288269043, 'loss_4': 0.6578536033630371, 'epoch': 8.74}
{'loss': 0.0218, 'grad_norm': 7.664046764373779, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.01297700498253107, 'loss_2': 0.0087890625, 'loss_3': -16.116193771362305, 'loss_4': 0.5579444169998169, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 15:55:03,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:03,522 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:41<1:03:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:10,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019896196201443672, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.285, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.016344016417860985, 'eval_loss_2': 0.0035521797835826874, 'eval_loss_3': -18.128313064575195, 'eval_loss_4': 0.5495507121086121, 'epoch': 8.75}
{'loss': 0.0098, 'grad_norm': 5.336236000061035, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.006991576869040728, 'loss_2': 0.0027904510498046875, 'loss_3': -16.103622436523438, 'loss_4': 0.2680233120918274, 'epoch': 8.76}
{'loss': 0.0153, 'grad_norm': 6.194202423095703, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.012181872501969337, 'loss_2': 0.003086090087890625, 'loss_3': -16.240787506103516, 'loss_4': 0.6031855940818787, 'epoch': 8.76}
{'loss': 0.0065, 'grad_norm': 4.5966901779174805, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.005990499630570412, 'loss_2': 0.0005178451538085938, 'loss_3': -16.279762268066406, 'loss_4': 0.4421229362487793, 'epoch': 8.77}
{'loss': 0.0277, 'grad_norm': 11.805512428283691, 'learning_rate': 2.125e-05, 'loss_1': 0.024883119389414787, 'loss_2': 0.00279998779296875, 'loss_3': -15.892666816711426, 'loss_4': -0.14999771118164062, 'epoch': 8.77}
{'loss': 0.0184, 'grad_norm': 7.246314525604248, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.011641742661595345, 'loss_2': 0.006740570068359375, 'loss_3': -16.388227462768555, 'loss_4': 0.14931097626686096, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 15:55:10,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:10,895 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:49<1:03:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:18,252 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027323197573423386, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02162715420126915, 'eval_loss_2': 0.005696043372154236, 'eval_loss_3': -18.098546981811523, 'eval_loss_4': 0.2208370864391327, 'epoch': 8.78}
{'loss': 0.0121, 'grad_norm': 5.147704601287842, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.01023650262504816, 'loss_2': 0.0019073486328125, 'loss_3': -16.233043670654297, 'loss_4': 0.18472065031528473, 'epoch': 8.78}
{'loss': 0.0246, 'grad_norm': 7.607508659362793, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.013808652758598328, 'loss_2': 0.01081085205078125, 'loss_3': -16.151365280151367, 'loss_4': 0.145058274269104, 'epoch': 8.79}
{'loss': 0.0139, 'grad_norm': 5.318685054779053, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.006931007839739323, 'loss_2': 0.006923675537109375, 'loss_3': -16.19961166381836, 'loss_4': 0.0745275616645813, 'epoch': 8.8}
{'loss': 0.0254, 'grad_norm': 10.312050819396973, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.02108212187886238, 'loss_2': 0.004306793212890625, 'loss_3': -15.96237850189209, 'loss_4': 0.2745714783668518, 'epoch': 8.8}
{'loss': 0.0308, 'grad_norm': 9.557781219482422, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.02410120889544487, 'loss_2': 0.006664276123046875, 'loss_3': -16.196319580078125, 'loss_4': -0.09658990055322647, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 15:55:18,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:18,253 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:56<1:03:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:25,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03733859956264496, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.033295027911663055, 'eval_loss_2': 0.0040435791015625, 'eval_loss_3': -18.06974220275879, 'eval_loss_4': 0.13047339022159576, 'epoch': 8.81}
{'loss': 0.0982, 'grad_norm': 18.04191780090332, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.09273629635572433, 'loss_2': 0.00547027587890625, 'loss_3': -16.154741287231445, 'loss_4': -0.2705311179161072, 'epoch': 8.81}
{'loss': 0.0127, 'grad_norm': 5.9764204025268555, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.011759229935705662, 'loss_2': 0.0009174346923828125, 'loss_3': -16.0832576751709, 'loss_4': -0.18105822801589966, 'epoch': 8.82}
{'loss': 0.0475, 'grad_norm': 25.17719841003418, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.04746926203370094, 'loss_2': 7.063150405883789e-05, 'loss_3': -15.909369468688965, 'loss_4': -0.005715280771255493, 'epoch': 8.83}
{'loss': 0.0181, 'grad_norm': 4.898353099822998, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.007630839478224516, 'loss_2': 0.0105133056640625, 'loss_3': -16.274822235107422, 'loss_4': -0.009969070553779602, 'epoch': 8.83}
{'loss': 0.019, 'grad_norm': 6.905756950378418, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.014263003133237362, 'loss_2': 0.0047454833984375, 'loss_3': -16.11808967590332, 'loss_4': 0.02068488672375679, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 15:55:25,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:25,612 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [38:03<1:02:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:32,969 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04396817460656166, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0368865467607975, 'eval_loss_2': 0.00708162784576416, 'eval_loss_3': -18.060287475585938, 'eval_loss_4': 0.03933456540107727, 'epoch': 8.84}
{'loss': 0.0688, 'grad_norm': 35.09347152709961, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.06511695683002472, 'loss_2': 0.0037174224853515625, 'loss_3': -16.321365356445312, 'loss_4': -0.29809361696243286, 'epoch': 8.84}
{'loss': 0.0168, 'grad_norm': 5.4074883460998535, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.007995367050170898, 'loss_2': 0.0088043212890625, 'loss_3': -16.267807006835938, 'loss_4': -0.3047911524772644, 'epoch': 8.85}
{'loss': 0.0883, 'grad_norm': 15.313189506530762, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.08721057325601578, 'loss_2': 0.00110626220703125, 'loss_3': -16.200927734375, 'loss_4': 0.03708666190505028, 'epoch': 8.85}
{'loss': 0.0238, 'grad_norm': 8.197837829589844, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.023506538942456245, 'loss_2': 0.0002627372741699219, 'loss_3': -16.330888748168945, 'loss_4': -0.04821673780679703, 'epoch': 8.86}
{'loss': 0.0157, 'grad_norm': 7.665311336517334, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.015043823979794979, 'loss_2': 0.000667572021484375, 'loss_3': -16.26371192932129, 'loss_4': -0.11635319888591766, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 15:55:32,969 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:32,970 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [38:11<1:02:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:40,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05176936089992523, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.813, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.04701133072376251, 'eval_loss_2': 0.00475803017616272, 'eval_loss_3': -18.09126091003418, 'eval_loss_4': 0.05470610037446022, 'epoch': 8.87}
{'loss': 0.015, 'grad_norm': 6.836677551269531, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.010938912630081177, 'loss_2': 0.0040283203125, 'loss_3': -16.23076057434082, 'loss_4': -0.12128064036369324, 'epoch': 8.87}
{'loss': 0.0215, 'grad_norm': 10.517706871032715, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.019703755155205727, 'loss_2': 0.0017843246459960938, 'loss_3': -16.288223266601562, 'loss_4': -0.11383648961782455, 'epoch': 8.88}
{'loss': 0.0762, 'grad_norm': 10.346400260925293, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.07303532212972641, 'loss_2': 0.0031280517578125, 'loss_3': -16.343379974365234, 'loss_4': 0.15979862213134766, 'epoch': 8.88}
{'loss': 0.0473, 'grad_norm': 14.481531143188477, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.04579073563218117, 'loss_2': 0.00147247314453125, 'loss_3': -16.44766616821289, 'loss_4': -0.12216874957084656, 'epoch': 8.89}
{'loss': 0.0233, 'grad_norm': 7.9734649658203125, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.02077123522758484, 'loss_2': 0.00255584716796875, 'loss_3': -16.318973541259766, 'loss_4': -0.5808850526809692, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 15:55:40,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:40,337 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:18<1:02:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:47,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04537815973162651, 'eval_runtime': 3.8175, 'eval_samples_per_second': 268.241, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.041221655905246735, 'eval_loss_2': 0.0041565001010894775, 'eval_loss_3': -18.118755340576172, 'eval_loss_4': -0.012613554485142231, 'epoch': 8.9}
{'loss': 0.0183, 'grad_norm': 6.914212226867676, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.017887843772768974, 'loss_2': 0.0004229545593261719, 'loss_3': -16.485700607299805, 'loss_4': -0.04948721081018448, 'epoch': 8.9}
{'loss': 0.0234, 'grad_norm': 7.184478759765625, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.016135672107338905, 'loss_2': 0.0072174072265625, 'loss_3': -16.29051971435547, 'loss_4': 0.040209658443927765, 'epoch': 8.91}
{'loss': 0.032, 'grad_norm': 8.523109436035156, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.027830054983496666, 'loss_2': 0.00420379638671875, 'loss_3': -16.411752700805664, 'loss_4': -0.9670760631561279, 'epoch': 8.91}
{'loss': 0.0298, 'grad_norm': 11.455122947692871, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.026285698637366295, 'loss_2': 0.003490447998046875, 'loss_3': -16.4656982421875, 'loss_4': -0.31037014722824097, 'epoch': 8.92}
{'loss': 0.0461, 'grad_norm': 23.717409133911133, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.03966614603996277, 'loss_2': 0.006465911865234375, 'loss_3': -16.257644653320312, 'loss_4': 0.09238353371620178, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 15:55:47,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:47,709 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:25<1:02:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:55,074 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03742973133921623, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.606, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.03438527509570122, 'eval_loss_2': 0.003044459968805313, 'eval_loss_3': -18.171125411987305, 'eval_loss_4': 0.16713659465312958, 'epoch': 8.92}
{'loss': 0.0502, 'grad_norm': 18.535005569458008, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.04694216698408127, 'loss_2': 0.0032100677490234375, 'loss_3': -16.43159294128418, 'loss_4': 0.007702875882387161, 'epoch': 8.93}
{'loss': 0.0245, 'grad_norm': 9.636418342590332, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.019872717559337616, 'loss_2': 0.004608154296875, 'loss_3': -16.23577308654785, 'loss_4': 0.012094125151634216, 'epoch': 8.94}
{'loss': 0.0467, 'grad_norm': 14.73486614227295, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.04365028068423271, 'loss_2': 0.0030517578125, 'loss_3': -16.578506469726562, 'loss_4': 0.1925850510597229, 'epoch': 8.94}
{'loss': 0.0422, 'grad_norm': 11.553692817687988, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.03426945209503174, 'loss_2': 0.00788116455078125, 'loss_3': -16.267566680908203, 'loss_4': 0.3439445495605469, 'epoch': 8.95}
{'loss': 0.0566, 'grad_norm': 19.613515853881836, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.05193399637937546, 'loss_2': 0.00470733642578125, 'loss_3': -16.39870834350586, 'loss_4': 0.6484777927398682, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 15:55:55,074 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:55,074 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:33<1:02:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:02,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03362887725234032, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.03, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03023422881960869, 'eval_loss_2': 0.0033946484327316284, 'eval_loss_3': -18.180007934570312, 'eval_loss_4': 0.4685575067996979, 'epoch': 8.95}
{'loss': 0.0173, 'grad_norm': 5.9735541343688965, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.016163144260644913, 'loss_2': 0.001155853271484375, 'loss_3': -16.498672485351562, 'loss_4': 0.08211500942707062, 'epoch': 8.96}
{'loss': 0.0425, 'grad_norm': 83.87445831298828, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.04192178323864937, 'loss_2': 0.0006222724914550781, 'loss_3': -16.307289123535156, 'loss_4': 0.14592784643173218, 'epoch': 8.97}
{'loss': 0.0204, 'grad_norm': 7.778824806213379, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.01872931234538555, 'loss_2': 0.001682281494140625, 'loss_3': -16.24625587463379, 'loss_4': 0.7302700281143188, 'epoch': 8.97}
{'loss': 0.0142, 'grad_norm': 4.816620826721191, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.009085837751626968, 'loss_2': 0.00506591796875, 'loss_3': -16.375457763671875, 'loss_4': 0.2910439968109131, 'epoch': 8.98}
{'loss': 0.0266, 'grad_norm': 8.486244201660156, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.02235453389585018, 'loss_2': 0.00426483154296875, 'loss_3': -16.157039642333984, 'loss_4': 0.2956467270851135, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 15:56:02,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:02,434 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:40<59:58,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 15:56:09,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028087487444281578, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.021285487338900566, 'eval_loss_2': 0.006802000105381012, 'eval_loss_3': -18.24295425415039, 'eval_loss_4': 0.670916736125946, 'epoch': 8.98}
{'loss': 0.0565, 'grad_norm': 21.929431915283203, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.054415781050920486, 'loss_2': 0.0020542144775390625, 'loss_3': -16.59728240966797, 'loss_4': 0.38382643461227417, 'epoch': 8.99}
{'loss': 0.025, 'grad_norm': 7.916272163391113, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.02121603488922119, 'loss_2': 0.0037841796875, 'loss_3': -16.20864486694336, 'loss_4': 0.6161149740219116, 'epoch': 8.99}
{'loss': 0.0133, 'grad_norm': 5.4304327964782715, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.005900448188185692, 'loss_2': 0.00738525390625, 'loss_3': -16.713016510009766, 'loss_4': 0.17417244613170624, 'epoch': 9.0}
{'loss': 0.0236, 'grad_norm': 7.240753173828125, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.017247702926397324, 'loss_2': 0.00634002685546875, 'loss_3': -16.408281326293945, 'loss_4': 0.5549867153167725, 'epoch': 9.01}
{'loss': 0.0201, 'grad_norm': 6.240164279937744, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.017036814242601395, 'loss_2': 0.003093719482421875, 'loss_3': -16.436504364013672, 'loss_4': 0.6088215112686157, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 15:56:09,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:09,478 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:47<1:02:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:56:16,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02141234651207924, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.247, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018104109913110733, 'eval_loss_2': 0.003308236598968506, 'eval_loss_3': -18.293222427368164, 'eval_loss_4': 0.8578613996505737, 'epoch': 9.01}
{'loss': 0.0334, 'grad_norm': 9.909436225891113, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.03224775567650795, 'loss_2': 0.0011844635009765625, 'loss_3': -16.477941513061523, 'loss_4': 0.6761597990989685, 'epoch': 9.02}
{'loss': 0.0378, 'grad_norm': 8.933459281921387, 'learning_rate': 2.1e-05, 'loss_1': 0.034416235983371735, 'loss_2': 0.00334930419921875, 'loss_3': -16.56256675720215, 'loss_4': 0.367514431476593, 'epoch': 9.02}
{'loss': 0.012, 'grad_norm': 5.361760139465332, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.010226340033113956, 'loss_2': 0.001739501953125, 'loss_3': -16.460453033447266, 'loss_4': 0.7725549936294556, 'epoch': 9.03}
{'loss': 0.0456, 'grad_norm': 22.748098373413086, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.043350379914045334, 'loss_2': 0.002208709716796875, 'loss_3': -16.358192443847656, 'loss_4': 0.9444514513015747, 'epoch': 9.03}
{'loss': 0.1088, 'grad_norm': 17.397235870361328, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.1018066480755806, 'loss_2': 0.0069580078125, 'loss_3': -16.42229461669922, 'loss_4': 1.0548522472381592, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 15:56:16,842 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:16,842 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:55<1:02:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:24,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02153029479086399, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.955, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.018763341009616852, 'eval_loss_2': 0.0027669519186019897, 'eval_loss_3': -18.276409149169922, 'eval_loss_4': 0.9152112007141113, 'epoch': 9.04}
{'loss': 0.0322, 'grad_norm': 12.13889217376709, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.028012989088892937, 'loss_2': 0.004150390625, 'loss_3': -16.453655242919922, 'loss_4': 0.802958607673645, 'epoch': 9.05}
{'loss': 0.0308, 'grad_norm': 10.615753173828125, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.03065241500735283, 'loss_2': 0.0001678466796875, 'loss_3': -16.529809951782227, 'loss_4': 0.57808917760849, 'epoch': 9.05}
{'loss': 0.032, 'grad_norm': 8.343703269958496, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.017527561634778976, 'loss_2': 0.0144500732421875, 'loss_3': -16.339492797851562, 'loss_4': 0.8616936206817627, 'epoch': 9.06}
{'loss': 0.0371, 'grad_norm': 11.955991744995117, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.036849670112133026, 'loss_2': 0.0002834796905517578, 'loss_3': -16.170772552490234, 'loss_4': 0.9547560214996338, 'epoch': 9.06}
{'loss': 0.0199, 'grad_norm': 8.140496253967285, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.019484413787722588, 'loss_2': 0.0004124641418457031, 'loss_3': -16.459915161132812, 'loss_4': 0.5115742683410645, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 15:56:24,212 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:24,212 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [39:02<1:02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:31,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023639094084501266, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.506, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.02144641987979412, 'eval_loss_2': 0.002192676067352295, 'eval_loss_3': -18.255144119262695, 'eval_loss_4': 1.0714092254638672, 'epoch': 9.07}
{'loss': 0.0287, 'grad_norm': 7.7010321617126465, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.020522167906165123, 'loss_2': 0.0081787109375, 'loss_3': -16.299367904663086, 'loss_4': 0.8410729169845581, 'epoch': 9.08}
{'loss': 0.0186, 'grad_norm': 5.7533159255981445, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.015069807879626751, 'loss_2': 0.0035400390625, 'loss_3': -16.458703994750977, 'loss_4': 0.8364352583885193, 'epoch': 9.08}
{'loss': 0.0227, 'grad_norm': 5.537848949432373, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.012283137999475002, 'loss_2': 0.0103759765625, 'loss_3': -16.48164176940918, 'loss_4': 1.1058353185653687, 'epoch': 9.09}
{'loss': 0.0263, 'grad_norm': 8.075308799743652, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.018662506714463234, 'loss_2': 0.007602691650390625, 'loss_3': -16.23158073425293, 'loss_4': 1.274205207824707, 'epoch': 9.09}
{'loss': 0.0167, 'grad_norm': 7.8053083419799805, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.01486594881862402, 'loss_2': 0.0017900466918945312, 'loss_3': -16.237350463867188, 'loss_4': 1.5331757068634033, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 15:56:31,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:31,588 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [39:09<1:02:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:38,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029316673055291176, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.833, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.026260921731591225, 'eval_loss_2': 0.003055751323699951, 'eval_loss_3': -18.198162078857422, 'eval_loss_4': 1.308501124382019, 'epoch': 9.1}
{'loss': 0.0261, 'grad_norm': 11.554900169372559, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.02387230470776558, 'loss_2': 0.00225067138671875, 'loss_3': -16.330259323120117, 'loss_4': 1.2031893730163574, 'epoch': 9.1}
{'loss': 0.0219, 'grad_norm': 7.5512166023254395, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.018850630149245262, 'loss_2': 0.003093719482421875, 'loss_3': -16.341642379760742, 'loss_4': 1.0734946727752686, 'epoch': 9.11}
{'loss': 0.0292, 'grad_norm': 10.006237983703613, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.023578424006700516, 'loss_2': 0.005634307861328125, 'loss_3': -16.361738204956055, 'loss_4': 1.368825912475586, 'epoch': 9.12}
{'loss': 0.0159, 'grad_norm': 6.264129638671875, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.014933282509446144, 'loss_2': 0.000988006591796875, 'loss_3': -16.203201293945312, 'loss_4': 1.5837600231170654, 'epoch': 9.12}
{'loss': 0.0233, 'grad_norm': 6.739021301269531, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.013407723978161812, 'loss_2': 0.0099334716796875, 'loss_3': -16.213951110839844, 'loss_4': 1.2300082445144653, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 15:56:38,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:38,956 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:17<1:02:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:46,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03375200927257538, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.074, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03150559589266777, 'eval_loss_2': 0.0022464096546173096, 'eval_loss_3': -18.16886329650879, 'eval_loss_4': 1.5482362508773804, 'epoch': 9.13}
{'loss': 0.0195, 'grad_norm': 10.989912033081055, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.019252847880125046, 'loss_2': 0.00023424625396728516, 'loss_3': -16.35144805908203, 'loss_4': 0.9723684787750244, 'epoch': 9.13}
{'loss': 0.0446, 'grad_norm': 16.18674087524414, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.039068978279829025, 'loss_2': 0.0055084228515625, 'loss_3': -16.180152893066406, 'loss_4': 1.0471904277801514, 'epoch': 9.14}
{'loss': 0.0345, 'grad_norm': 8.659229278564453, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.030754826962947845, 'loss_2': 0.0037384033203125, 'loss_3': -16.23464584350586, 'loss_4': 1.5580840110778809, 'epoch': 9.15}
{'loss': 0.0352, 'grad_norm': 12.314715385437012, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.03518093004822731, 'loss_2': 6.67572021484375e-05, 'loss_3': -16.20684051513672, 'loss_4': 0.8373485803604126, 'epoch': 9.15}
{'loss': 0.0421, 'grad_norm': 10.164433479309082, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.030747216194868088, 'loss_2': 0.0113372802734375, 'loss_3': -16.234405517578125, 'loss_4': 1.5440797805786133, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 15:56:46,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:46,315 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:24<1:02:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:53,676 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035209085792303085, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.164, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.025231504812836647, 'eval_loss_2': 0.009977579116821289, 'eval_loss_3': -18.20303726196289, 'eval_loss_4': 1.4842300415039062, 'epoch': 9.16}
{'loss': 0.0368, 'grad_norm': 9.98348617553711, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.019645318388938904, 'loss_2': 0.0171051025390625, 'loss_3': -16.427583694458008, 'loss_4': 1.4319878816604614, 'epoch': 9.16}
{'loss': 0.0617, 'grad_norm': 21.118192672729492, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.05007519572973251, 'loss_2': 0.01158905029296875, 'loss_3': -16.23833656311035, 'loss_4': 1.3602381944656372, 'epoch': 9.17}
{'loss': 0.0336, 'grad_norm': 8.803587913513184, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.020200544968247414, 'loss_2': 0.0133514404296875, 'loss_3': -16.276445388793945, 'loss_4': 1.6034691333770752, 'epoch': 9.17}
{'loss': 0.0347, 'grad_norm': 11.36959171295166, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.021520623937249184, 'loss_2': 0.013214111328125, 'loss_3': -16.249353408813477, 'loss_4': 1.2567704916000366, 'epoch': 9.18}
{'loss': 0.1025, 'grad_norm': 16.460718154907227, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.09291380643844604, 'loss_2': 0.00957489013671875, 'loss_3': -16.372201919555664, 'loss_4': 1.272176742553711, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 15:56:53,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:53,676 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:31<1:01:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:01,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029532313346862793, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.407, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.02012336254119873, 'eval_loss_2': 0.009408950805664062, 'eval_loss_3': -18.263107299804688, 'eval_loss_4': 1.2735936641693115, 'epoch': 9.19}
{'loss': 0.0219, 'grad_norm': 6.904819488525391, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.01711377128958702, 'loss_2': 0.004795074462890625, 'loss_3': -16.28726577758789, 'loss_4': 0.8493080735206604, 'epoch': 9.19}
{'loss': 0.0258, 'grad_norm': 6.1950273513793945, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.01678643748164177, 'loss_2': 0.009033203125, 'loss_3': -16.432353973388672, 'loss_4': 1.0290000438690186, 'epoch': 9.2}
{'loss': 0.01, 'grad_norm': 4.906164646148682, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.008993629366159439, 'loss_2': 0.0010051727294921875, 'loss_3': -16.280977249145508, 'loss_4': 1.4703900814056396, 'epoch': 9.2}
{'loss': 0.0298, 'grad_norm': 10.15661907196045, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.02524181641638279, 'loss_2': 0.00458526611328125, 'loss_3': -16.454219818115234, 'loss_4': 0.6541540622711182, 'epoch': 9.21}
{'loss': 0.0268, 'grad_norm': 13.080516815185547, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.023186255246400833, 'loss_2': 0.003620147705078125, 'loss_3': -16.37453842163086, 'loss_4': 1.375412940979004, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 15:57:01,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:01,026 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:39<1:01:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:08,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022159798070788383, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.969, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.019219595938920975, 'eval_loss_2': 0.0029402002692222595, 'eval_loss_3': -18.26884651184082, 'eval_loss_4': 1.3465955257415771, 'epoch': 9.22}
{'loss': 0.0177, 'grad_norm': 7.676041126251221, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.01158412080258131, 'loss_2': 0.00615692138671875, 'loss_3': -16.373510360717773, 'loss_4': 1.3414607048034668, 'epoch': 9.22}
{'loss': 0.0155, 'grad_norm': 5.0822434425354, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.009829956106841564, 'loss_2': 0.005680084228515625, 'loss_3': -16.306156158447266, 'loss_4': 1.2889184951782227, 'epoch': 9.23}
{'loss': 0.0128, 'grad_norm': 4.915421962738037, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.008468713611364365, 'loss_2': 0.004364013671875, 'loss_3': -16.255901336669922, 'loss_4': 1.341031789779663, 'epoch': 9.23}
{'loss': 0.015, 'grad_norm': 5.571782112121582, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.010728315450251102, 'loss_2': 0.004245758056640625, 'loss_3': -16.166797637939453, 'loss_4': 1.561667799949646, 'epoch': 9.24}
{'loss': 0.0141, 'grad_norm': 5.187783241271973, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.012445252388715744, 'loss_2': 0.0016088485717773438, 'loss_3': -16.221609115600586, 'loss_4': 1.6698333024978638, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 15:57:08,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:08,392 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:46<1:01:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:15,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02699316293001175, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.024671383202075958, 'eval_loss_2': 0.002321779727935791, 'eval_loss_3': -18.187217712402344, 'eval_loss_4': 1.5735218524932861, 'epoch': 9.24}
{'loss': 0.0278, 'grad_norm': 8.45634937286377, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.02247963659465313, 'loss_2': 0.00528717041015625, 'loss_3': -16.101417541503906, 'loss_4': 1.8124412298202515, 'epoch': 9.25}
{'loss': 0.0109, 'grad_norm': 5.364031791687012, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.010094479657709599, 'loss_2': 0.0008020401000976562, 'loss_3': -16.382366180419922, 'loss_4': 0.9084858894348145, 'epoch': 9.26}
{'loss': 0.0164, 'grad_norm': 6.309875965118408, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.015395634807646275, 'loss_2': 0.0010290145874023438, 'loss_3': -16.344696044921875, 'loss_4': 1.548971176147461, 'epoch': 9.26}
{'loss': 0.0192, 'grad_norm': 6.1269211769104, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.016991542652249336, 'loss_2': 0.0021610260009765625, 'loss_3': -16.237735748291016, 'loss_4': 1.4628351926803589, 'epoch': 9.27}
{'loss': 0.0167, 'grad_norm': 6.696381092071533, 'learning_rate': 2.075e-05, 'loss_1': 0.016070079058408737, 'loss_2': 0.0006561279296875, 'loss_3': -16.47635841369629, 'loss_4': 1.248710036277771, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 15:57:15,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:15,753 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:53<1:01:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:23,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033598288893699646, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.78, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02896583452820778, 'eval_loss_2': 0.0046324580907821655, 'eval_loss_3': -18.149614334106445, 'eval_loss_4': 1.3809318542480469, 'epoch': 9.27}
{'loss': 0.0323, 'grad_norm': 17.39925193786621, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.02974545955657959, 'loss_2': 0.0025768280029296875, 'loss_3': -16.385623931884766, 'loss_4': 1.154746651649475, 'epoch': 9.28}
{'loss': 0.0393, 'grad_norm': 16.70954704284668, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.03315054625272751, 'loss_2': 0.0061798095703125, 'loss_3': -16.347434997558594, 'loss_4': 1.3519840240478516, 'epoch': 9.28}
{'loss': 0.017, 'grad_norm': 6.156944751739502, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.011098187416791916, 'loss_2': 0.00591278076171875, 'loss_3': -16.223979949951172, 'loss_4': 1.1271237134933472, 'epoch': 9.29}
{'loss': 0.0095, 'grad_norm': 4.845607280731201, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.008118816651403904, 'loss_2': 0.00133514404296875, 'loss_3': -16.37185287475586, 'loss_4': 1.0311031341552734, 'epoch': 9.3}
{'loss': 0.0158, 'grad_norm': 5.419496059417725, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.007636952213943005, 'loss_2': 0.0081939697265625, 'loss_3': -16.426820755004883, 'loss_4': 1.1490635871887207, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 15:57:23,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:23,117 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [40:01<1:01:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:30,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02326253242790699, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.27, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.019901026040315628, 'eval_loss_2': 0.0033615082502365112, 'eval_loss_3': -18.231258392333984, 'eval_loss_4': 1.2027437686920166, 'epoch': 9.3}
{'loss': 0.025, 'grad_norm': 6.896480560302734, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.016540126875042915, 'loss_2': 0.0084381103515625, 'loss_3': -16.28293228149414, 'loss_4': 1.2747249603271484, 'epoch': 9.31}
{'loss': 0.0173, 'grad_norm': 5.380051136016846, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.014798087999224663, 'loss_2': 0.0024547576904296875, 'loss_3': -16.54645538330078, 'loss_4': 1.3034470081329346, 'epoch': 9.31}
{'loss': 0.0209, 'grad_norm': 6.822378158569336, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.011957993730902672, 'loss_2': 0.0089569091796875, 'loss_3': -16.281002044677734, 'loss_4': 0.8462865352630615, 'epoch': 9.32}
{'loss': 0.0177, 'grad_norm': 6.158651828765869, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.016110194846987724, 'loss_2': 0.0016222000122070312, 'loss_3': -16.534164428710938, 'loss_4': 0.909514307975769, 'epoch': 9.33}
{'loss': 0.0138, 'grad_norm': 5.7389140129089355, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.011785841546952724, 'loss_2': 0.00201416015625, 'loss_3': -16.244464874267578, 'loss_4': 1.2787322998046875, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 15:57:30,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:30,479 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [40:08<1:01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:37,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022740300744771957, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.501, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016292927786707878, 'eval_loss_2': 0.0064473748207092285, 'eval_loss_3': -18.291240692138672, 'eval_loss_4': 1.2209163904190063, 'epoch': 9.33}
{'loss': 0.0303, 'grad_norm': 10.287210464477539, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.023550482466816902, 'loss_2': 0.0067138671875, 'loss_3': -16.30577278137207, 'loss_4': 1.554401159286499, 'epoch': 9.34}
{'loss': 0.0396, 'grad_norm': 16.96175193786621, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.025805097073316574, 'loss_2': 0.01380157470703125, 'loss_3': -16.351680755615234, 'loss_4': 1.6335419416427612, 'epoch': 9.34}
{'loss': 0.0394, 'grad_norm': 13.022529602050781, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.02645426243543625, 'loss_2': 0.0129547119140625, 'loss_3': -16.517112731933594, 'loss_4': 0.86213219165802, 'epoch': 9.35}
{'loss': 0.0216, 'grad_norm': 6.08098840713501, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.016812171787023544, 'loss_2': 0.00482177734375, 'loss_3': -16.22515106201172, 'loss_4': 1.3072911500930786, 'epoch': 9.35}
{'loss': 0.0198, 'grad_norm': 5.849623680114746, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.010493992827832699, 'loss_2': 0.0092620849609375, 'loss_3': -16.617565155029297, 'loss_4': 1.5063612461090088, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 15:57:37,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:37,834 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:16<1:01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:45,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01944032683968544, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.231, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015046718530356884, 'eval_loss_2': 0.0043936073780059814, 'eval_loss_3': -18.324464797973633, 'eval_loss_4': 1.2798829078674316, 'epoch': 9.36}
{'loss': 0.0224, 'grad_norm': 6.970396995544434, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.017092157155275345, 'loss_2': 0.00533294677734375, 'loss_3': -16.505638122558594, 'loss_4': 0.9929547309875488, 'epoch': 9.37}
{'loss': 0.0199, 'grad_norm': 10.719518661499023, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.01753031648695469, 'loss_2': 0.0023899078369140625, 'loss_3': -16.426002502441406, 'loss_4': 1.2366728782653809, 'epoch': 9.37}
{'loss': 0.0301, 'grad_norm': 8.890256881713867, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.023840663954615593, 'loss_2': 0.006237030029296875, 'loss_3': -16.602066040039062, 'loss_4': 1.0763492584228516, 'epoch': 9.38}
{'loss': 0.0246, 'grad_norm': 8.68984317779541, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.019330017268657684, 'loss_2': 0.00527191162109375, 'loss_3': -16.15179443359375, 'loss_4': 1.2075300216674805, 'epoch': 9.38}
{'loss': 0.0181, 'grad_norm': 5.1808881759643555, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.009303287602961063, 'loss_2': 0.0087738037109375, 'loss_3': -16.44549560546875, 'loss_4': 1.265777826309204, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 15:57:45,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:45,197 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:23<1:01:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:52,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02120298333466053, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.193, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014456422999501228, 'eval_loss_2': 0.006746560335159302, 'eval_loss_3': -18.343393325805664, 'eval_loss_4': 1.290747880935669, 'epoch': 9.39}
{'loss': 0.0112, 'grad_norm': 6.491069316864014, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.010514765046536922, 'loss_2': 0.000675201416015625, 'loss_3': -16.59024429321289, 'loss_4': 1.3506407737731934, 'epoch': 9.4}
{'loss': 0.0143, 'grad_norm': 4.8718180656433105, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.011915738694369793, 'loss_2': 0.002414703369140625, 'loss_3': -16.257644653320312, 'loss_4': 1.227515697479248, 'epoch': 9.4}
{'loss': 0.0319, 'grad_norm': 8.237199783325195, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.02017097733914852, 'loss_2': 0.0117645263671875, 'loss_3': -16.332496643066406, 'loss_4': 1.4940097332000732, 'epoch': 9.41}
{'loss': 0.0186, 'grad_norm': 5.497920513153076, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.010190200991928577, 'loss_2': 0.00841522216796875, 'loss_3': -16.454387664794922, 'loss_4': 1.3255960941314697, 'epoch': 9.41}
{'loss': 0.0184, 'grad_norm': 6.672187805175781, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.01797645166516304, 'loss_2': 0.0004496574401855469, 'loss_3': -16.538772583007812, 'loss_4': 1.14360511302948, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 15:57:52,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:52,558 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:30<1:01:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:59,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016488347202539444, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01390008069574833, 'eval_loss_2': 0.002588268369436264, 'eval_loss_3': -18.34709358215332, 'eval_loss_4': 1.3672845363616943, 'epoch': 9.42}
{'loss': 0.0194, 'grad_norm': 9.687904357910156, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.017566263675689697, 'loss_2': 0.0018596649169921875, 'loss_3': -16.42725944519043, 'loss_4': 1.410698413848877, 'epoch': 9.42}
{'loss': 0.0098, 'grad_norm': 5.0374884605407715, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.007356423418968916, 'loss_2': 0.0024566650390625, 'loss_3': -16.512826919555664, 'loss_4': 1.4888384342193604, 'epoch': 9.43}
{'loss': 0.0292, 'grad_norm': 7.722162246704102, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.023980116471648216, 'loss_2': 0.005245208740234375, 'loss_3': -16.737579345703125, 'loss_4': 1.7004200220108032, 'epoch': 9.44}
{'loss': 0.0217, 'grad_norm': 5.667883396148682, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.01136573776602745, 'loss_2': 0.0103607177734375, 'loss_3': -16.50492286682129, 'loss_4': 1.285799264907837, 'epoch': 9.44}
{'loss': 0.016, 'grad_norm': 8.180413246154785, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.015404196456074715, 'loss_2': 0.0006427764892578125, 'loss_3': -16.352458953857422, 'loss_4': 0.9954500794410706, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 15:57:59,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:59,916 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:38<1:01:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:07,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017606761306524277, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014196311123669147, 'eval_loss_2': 0.003410451114177704, 'eval_loss_3': -18.30371856689453, 'eval_loss_4': 1.4326627254486084, 'epoch': 9.45}
{'loss': 0.0205, 'grad_norm': 6.210671424865723, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.012263452634215355, 'loss_2': 0.00824737548828125, 'loss_3': -16.435279846191406, 'loss_4': 1.431518793106079, 'epoch': 9.45}
{'loss': 0.0186, 'grad_norm': 6.603759765625, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.012889597564935684, 'loss_2': 0.00572967529296875, 'loss_3': -16.156879425048828, 'loss_4': 1.1629278659820557, 'epoch': 9.46}
{'loss': 0.0255, 'grad_norm': 8.268152236938477, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.023841317743062973, 'loss_2': 0.00168609619140625, 'loss_3': -16.48850440979004, 'loss_4': 1.010694980621338, 'epoch': 9.47}
{'loss': 0.0145, 'grad_norm': 8.682945251464844, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.012277375906705856, 'loss_2': 0.002201080322265625, 'loss_3': -16.443523406982422, 'loss_4': 1.5067644119262695, 'epoch': 9.47}
{'loss': 0.0327, 'grad_norm': 21.441795349121094, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.03096623905003071, 'loss_2': 0.001781463623046875, 'loss_3': -16.530893325805664, 'loss_4': 1.3614743947982788, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 15:58:07,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:07,270 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:45<1:01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:14,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02083088457584381, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.019, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015399264171719551, 'eval_loss_2': 0.005431622266769409, 'eval_loss_3': -18.267406463623047, 'eval_loss_4': 1.4254423379898071, 'epoch': 9.48}
{'loss': 0.0145, 'grad_norm': 7.287092208862305, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.013195954263210297, 'loss_2': 0.0012826919555664062, 'loss_3': -16.483905792236328, 'loss_4': 1.0956085920333862, 'epoch': 9.48}
{'loss': 0.0214, 'grad_norm': 7.599187850952148, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.013693784363567829, 'loss_2': 0.00771331787109375, 'loss_3': -16.286733627319336, 'loss_4': 1.5080335140228271, 'epoch': 9.49}
{'loss': 0.0118, 'grad_norm': 5.781994342803955, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.008175507187843323, 'loss_2': 0.0036029815673828125, 'loss_3': -16.40576934814453, 'loss_4': 1.073313593864441, 'epoch': 9.49}
{'loss': 0.0097, 'grad_norm': 5.144313335418701, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.009359355084598064, 'loss_2': 0.00037217140197753906, 'loss_3': -16.346294403076172, 'loss_4': 0.8993817567825317, 'epoch': 9.5}
{'loss': 0.0128, 'grad_norm': 4.425258636474609, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.004377045668661594, 'loss_2': 0.0083770751953125, 'loss_3': -16.447269439697266, 'loss_4': 1.3283497095108032, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 15:58:14,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:14,633 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:52<1:00:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:21,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01994134858250618, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015408054925501347, 'eval_loss_2': 0.004533290863037109, 'eval_loss_3': -18.235164642333984, 'eval_loss_4': 1.3164459466934204, 'epoch': 9.51}
{'loss': 0.0158, 'grad_norm': 6.308403491973877, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.01341873500496149, 'loss_2': 0.00238800048828125, 'loss_3': -16.282005310058594, 'loss_4': 1.2650753259658813, 'epoch': 9.51}
{'loss': 0.0109, 'grad_norm': 5.47041654586792, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.0099992286413908, 'loss_2': 0.0009098052978515625, 'loss_3': -16.28851318359375, 'loss_4': 1.3014254570007324, 'epoch': 9.52}
{'loss': 0.0204, 'grad_norm': 7.264512062072754, 'learning_rate': 2.05e-05, 'loss_1': 0.013263534754514694, 'loss_2': 0.00716400146484375, 'loss_3': -16.25336456298828, 'loss_4': 1.521697998046875, 'epoch': 9.52}
{'loss': 0.0112, 'grad_norm': 4.573531150817871, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.006947977002710104, 'loss_2': 0.00420379638671875, 'loss_3': -16.258211135864258, 'loss_4': 1.2761151790618896, 'epoch': 9.53}
{'loss': 0.0196, 'grad_norm': 5.410831928253174, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.010379862040281296, 'loss_2': 0.00923919677734375, 'loss_3': -16.301130294799805, 'loss_4': 0.8494166731834412, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 15:58:21,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:21,985 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [41:00<1:01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:29,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023764753714203835, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.54, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01835688017308712, 'eval_loss_2': 0.005407869815826416, 'eval_loss_3': -18.195892333984375, 'eval_loss_4': 1.1303707361221313, 'epoch': 9.53}
{'loss': 0.0204, 'grad_norm': 9.16637897491455, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.013877365738153458, 'loss_2': 0.00647735595703125, 'loss_3': -16.265586853027344, 'loss_4': 1.0078692436218262, 'epoch': 9.54}
{'loss': 0.1007, 'grad_norm': 14.89254379272461, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.09171402454376221, 'loss_2': 0.00901031494140625, 'loss_3': -16.134313583374023, 'loss_4': 1.4317944049835205, 'epoch': 9.55}
{'loss': 0.0234, 'grad_norm': 13.040233612060547, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.021768521517515182, 'loss_2': 0.001659393310546875, 'loss_3': -16.046598434448242, 'loss_4': 1.4338734149932861, 'epoch': 9.55}
{'loss': 0.0095, 'grad_norm': 6.461465835571289, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.009236586280167103, 'loss_2': 0.00028252601623535156, 'loss_3': -16.286996841430664, 'loss_4': 0.9888278841972351, 'epoch': 9.56}
{'loss': 0.0145, 'grad_norm': 6.592226982116699, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.013221385888755322, 'loss_2': 0.0012760162353515625, 'loss_3': -16.19106101989746, 'loss_4': 1.6430851221084595, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 15:58:29,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:29,358 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [41:07<1:00:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:36,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037547096610069275, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.030262211337685585, 'eval_loss_2': 0.007284879684448242, 'eval_loss_3': -18.136320114135742, 'eval_loss_4': 0.9292324781417847, 'epoch': 9.56}
{'loss': 0.0124, 'grad_norm': 5.222600936889648, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.008056131191551685, 'loss_2': 0.00434112548828125, 'loss_3': -16.34008026123047, 'loss_4': 0.8339815735816956, 'epoch': 9.57}
{'loss': 0.0177, 'grad_norm': 5.654833793640137, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.00896706897765398, 'loss_2': 0.008758544921875, 'loss_3': -16.127696990966797, 'loss_4': 0.556710958480835, 'epoch': 9.58}
{'loss': 0.0203, 'grad_norm': 7.771353721618652, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.01883206143975258, 'loss_2': 0.0014743804931640625, 'loss_3': -16.181068420410156, 'loss_4': 1.2668795585632324, 'epoch': 9.58}
{'loss': 0.0267, 'grad_norm': 6.963714599609375, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.013065777719020844, 'loss_2': 0.0136260986328125, 'loss_3': -16.295921325683594, 'loss_4': 1.2088966369628906, 'epoch': 9.59}
{'loss': 0.0262, 'grad_norm': 10.947005271911621, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.02026296593248844, 'loss_2': 0.005977630615234375, 'loss_3': -16.546640396118164, 'loss_4': 0.7629221677780151, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 15:58:36,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:36,716 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:14<1:00:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:44,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032822564244270325, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.029903126880526543, 'eval_loss_2': 0.002919435501098633, 'eval_loss_3': -18.165302276611328, 'eval_loss_4': 0.6927427053451538, 'epoch': 9.59}
{'loss': 0.0494, 'grad_norm': 18.506620407104492, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.041548535227775574, 'loss_2': 0.00787353515625, 'loss_3': -16.129154205322266, 'loss_4': 0.623167872428894, 'epoch': 9.6}
{'loss': 0.0122, 'grad_norm': 5.9671149253845215, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.01136979553848505, 'loss_2': 0.0008306503295898438, 'loss_3': -16.44906997680664, 'loss_4': 0.5960568189620972, 'epoch': 9.6}
{'loss': 0.038, 'grad_norm': 19.394493103027344, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.037885259836912155, 'loss_2': 0.0001277923583984375, 'loss_3': -16.248092651367188, 'loss_4': 0.7725067138671875, 'epoch': 9.61}
{'loss': 0.0257, 'grad_norm': 8.16619873046875, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.017357677221298218, 'loss_2': 0.008331298828125, 'loss_3': -16.308643341064453, 'loss_4': 0.5863488912582397, 'epoch': 9.62}
{'loss': 0.0181, 'grad_norm': 7.4484429359436035, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.0155201880261302, 'loss_2': 0.002552032470703125, 'loss_3': -16.293720245361328, 'loss_4': 0.7116372585296631, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 15:58:44,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:44,068 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:22<1:00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:51,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028522271662950516, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.335, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.025200294330716133, 'eval_loss_2': 0.0033219754695892334, 'eval_loss_3': -18.211462020874023, 'eval_loss_4': 0.5686910152435303, 'epoch': 9.62}
{'loss': 0.0216, 'grad_norm': 8.875810623168945, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.020972954109311104, 'loss_2': 0.0006542205810546875, 'loss_3': -16.42969512939453, 'loss_4': 0.3826889395713806, 'epoch': 9.63}
{'loss': 0.0172, 'grad_norm': 6.493363857269287, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.01210331916809082, 'loss_2': 0.0051422119140625, 'loss_3': -16.39010238647461, 'loss_4': 0.16230472922325134, 'epoch': 9.63}
{'loss': 0.0176, 'grad_norm': 6.872101306915283, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.01408836618065834, 'loss_2': 0.003536224365234375, 'loss_3': -16.238325119018555, 'loss_4': 0.2590402364730835, 'epoch': 9.64}
{'loss': 0.023, 'grad_norm': 10.789013862609863, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.02082103304564953, 'loss_2': 0.002147674560546875, 'loss_3': -16.39228057861328, 'loss_4': 0.6955887079238892, 'epoch': 9.65}
{'loss': 0.0156, 'grad_norm': 5.680429458618164, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.009016666561365128, 'loss_2': 0.006572723388671875, 'loss_3': -16.473365783691406, 'loss_4': 0.6018388867378235, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 15:58:51,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:51,418 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:29<1:01:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:58:58,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01988125964999199, 'eval_runtime': 3.9911, 'eval_samples_per_second': 256.573, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.017203999683260918, 'eval_loss_2': 0.0026772618293762207, 'eval_loss_3': -18.247774124145508, 'eval_loss_4': 0.3012647032737732, 'epoch': 9.65}
{'loss': 0.0095, 'grad_norm': 5.027942657470703, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.008679686114192009, 'loss_2': 0.00077056884765625, 'loss_3': -16.524280548095703, 'loss_4': 0.20952272415161133, 'epoch': 9.66}
{'loss': 0.0211, 'grad_norm': 6.597908973693848, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.012672116048634052, 'loss_2': 0.008453369140625, 'loss_3': -16.343196868896484, 'loss_4': -0.29873552918434143, 'epoch': 9.66}
{'loss': 0.0144, 'grad_norm': 6.7882819175720215, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.012768820859491825, 'loss_2': 0.001651763916015625, 'loss_3': -16.325077056884766, 'loss_4': -0.08825075626373291, 'epoch': 9.67}
{'loss': 0.0122, 'grad_norm': 4.94343900680542, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.012129079550504684, 'loss_2': 3.159046173095703e-05, 'loss_3': -16.400279998779297, 'loss_4': -0.24569840729236603, 'epoch': 9.67}
{'loss': 0.0392, 'grad_norm': 11.429853439331055, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.03394745662808418, 'loss_2': 0.0052947998046875, 'loss_3': -16.562339782714844, 'loss_4': 0.1506684273481369, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 15:58:58,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:58,960 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:37<1:00:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:06,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02117004431784153, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.792, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017947275191545486, 'eval_loss_2': 0.0032227709889411926, 'eval_loss_3': -18.26233673095703, 'eval_loss_4': -0.02748265489935875, 'epoch': 9.68}
{'loss': 0.0227, 'grad_norm': 10.050115585327148, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.021795762702822685, 'loss_2': 0.0008745193481445312, 'loss_3': -16.460494995117188, 'loss_4': -0.18756993114948273, 'epoch': 9.69}
{'loss': 0.0091, 'grad_norm': 4.7022929191589355, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.007981420494616032, 'loss_2': 0.0011425018310546875, 'loss_3': -16.44305419921875, 'loss_4': 0.008374512195587158, 'epoch': 9.69}
{'loss': 0.0089, 'grad_norm': 5.484956741333008, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.00888747163116932, 'loss_2': 1.8715858459472656e-05, 'loss_3': -16.349895477294922, 'loss_4': 0.38084107637405396, 'epoch': 9.7}
{'loss': 0.0352, 'grad_norm': 15.361623764038086, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.03150533139705658, 'loss_2': 0.00368499755859375, 'loss_3': -16.42410659790039, 'loss_4': -0.6934794187545776, 'epoch': 9.7}
{'loss': 0.0226, 'grad_norm': 7.180700778961182, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.016611767932772636, 'loss_2': 0.00597381591796875, 'loss_3': -16.328006744384766, 'loss_4': -0.4664522111415863, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 15:59:06,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:06,322 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:44<1:00:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:13,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027292564511299133, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.714, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.024846957996487617, 'eval_loss_2': 0.002445608377456665, 'eval_loss_3': -18.20905303955078, 'eval_loss_4': -0.3203945755958557, 'epoch': 9.71}
{'loss': 0.0171, 'grad_norm': 5.311605930328369, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.010897875763475895, 'loss_2': 0.006183624267578125, 'loss_3': -16.37672996520996, 'loss_4': -0.6856176853179932, 'epoch': 9.72}
{'loss': 0.0194, 'grad_norm': 8.486821174621582, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.017413094639778137, 'loss_2': 0.00196075439453125, 'loss_3': -16.421436309814453, 'loss_4': -0.5270467400550842, 'epoch': 9.72}
{'loss': 0.0221, 'grad_norm': 7.848598480224609, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.01907077059149742, 'loss_2': 0.0030231475830078125, 'loss_3': -16.36893081665039, 'loss_4': -0.760188102722168, 'epoch': 9.73}
{'loss': 0.0158, 'grad_norm': 7.325514793395996, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.012856091372668743, 'loss_2': 0.002971649169921875, 'loss_3': -16.34044647216797, 'loss_4': -0.11757033318281174, 'epoch': 9.73}
{'loss': 0.0113, 'grad_norm': 8.58349609375, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.010063319467008114, 'loss_2': 0.0012798309326171875, 'loss_3': -16.509475708007812, 'loss_4': -0.48079508543014526, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 15:59:13,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:13,675 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:51<1:00:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:21,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04450821876525879, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.04183363541960716, 'eval_loss_2': 0.002674587070941925, 'eval_loss_3': -18.14007568359375, 'eval_loss_4': -0.34282225370407104, 'epoch': 9.74}
{'loss': 0.016, 'grad_norm': 5.702438831329346, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.01235269196331501, 'loss_2': 0.003620147705078125, 'loss_3': -16.21819496154785, 'loss_4': -0.21237875521183014, 'epoch': 9.74}
{'loss': 0.0157, 'grad_norm': 6.042513370513916, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.012570968829095364, 'loss_2': 0.00315093994140625, 'loss_3': -16.04505157470703, 'loss_4': -0.727878749370575, 'epoch': 9.75}
{'loss': 0.017, 'grad_norm': 7.191411018371582, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.013503198511898518, 'loss_2': 0.003536224365234375, 'loss_3': -16.316720962524414, 'loss_4': -0.3024939298629761, 'epoch': 9.76}
{'loss': 0.0798, 'grad_norm': 24.849712371826172, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.07868190109729767, 'loss_2': 0.00107574462890625, 'loss_3': -16.21834945678711, 'loss_4': -0.29010164737701416, 'epoch': 9.76}
{'loss': 0.0201, 'grad_norm': 6.57277250289917, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.013876199722290039, 'loss_2': 0.0062103271484375, 'loss_3': -16.086257934570312, 'loss_4': -0.6437690258026123, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 15:59:21,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:21,026 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [41:59<1:00:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:28,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031546447426080704, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.028268998488783836, 'eval_loss_2': 0.0032774507999420166, 'eval_loss_3': -18.162376403808594, 'eval_loss_4': -0.2265506088733673, 'epoch': 9.77}
{'loss': 0.0128, 'grad_norm': 5.5157790184021, 'learning_rate': 2.025e-05, 'loss_1': 0.010686620138585567, 'loss_2': 0.00209808349609375, 'loss_3': -16.343677520751953, 'loss_4': -0.4004906117916107, 'epoch': 9.77}
{'loss': 0.014, 'grad_norm': 5.002837181091309, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.007930653169751167, 'loss_2': 0.006023406982421875, 'loss_3': -16.27461051940918, 'loss_4': 0.03555724024772644, 'epoch': 9.78}
{'loss': 0.0393, 'grad_norm': 15.765937805175781, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.03858461603522301, 'loss_2': 0.0006842613220214844, 'loss_3': -16.131412506103516, 'loss_4': -0.36504513025283813, 'epoch': 9.78}
{'loss': 0.019, 'grad_norm': 7.782422065734863, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.013508039526641369, 'loss_2': 0.00545501708984375, 'loss_3': -16.1163387298584, 'loss_4': -0.21984875202178955, 'epoch': 9.79}
{'loss': 0.0109, 'grad_norm': 5.1522369384765625, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.006329631432890892, 'loss_2': 0.0045623779296875, 'loss_3': -16.424448013305664, 'loss_4': -0.03462093695998192, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 15:59:28,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:28,381 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1690/5160 [42:06<1:00:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:35,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018205031752586365, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014359371736645699, 'eval_loss_2': 0.0038456618785858154, 'eval_loss_3': -18.196884155273438, 'eval_loss_4': 0.010606853291392326, 'epoch': 9.8}
{'loss': 0.0132, 'grad_norm': 5.186498165130615, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.0099774906411767, 'loss_2': 0.0032501220703125, 'loss_3': -16.45294952392578, 'loss_4': -0.45366865396499634, 'epoch': 9.8}
{'loss': 0.0209, 'grad_norm': 10.815011024475098, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.015893986448645592, 'loss_2': 0.005008697509765625, 'loss_3': -16.176734924316406, 'loss_4': 0.1503518968820572, 'epoch': 9.81}
{'loss': 0.0132, 'grad_norm': 5.6669440269470215, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.009202614426612854, 'loss_2': 0.00400543212890625, 'loss_3': -16.352184295654297, 'loss_4': 0.1510152816772461, 'epoch': 9.81}
{'loss': 0.0318, 'grad_norm': 19.92637062072754, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.030038228258490562, 'loss_2': 0.0017147064208984375, 'loss_3': -16.35662078857422, 'loss_4': 0.44602811336517334, 'epoch': 9.82}
{'loss': 0.025, 'grad_norm': 15.429484367370605, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.02352495864033699, 'loss_2': 0.0014410018920898438, 'loss_3': -16.310768127441406, 'loss_4': 0.45765888690948486, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 15:59:35,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:35,737 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [42:13<59:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:43,085 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015703849494457245, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.202, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01208712812513113, 'eval_loss_2': 0.00361672043800354, 'eval_loss_3': -18.210939407348633, 'eval_loss_4': 0.14286932349205017, 'epoch': 9.83}
{'loss': 0.0135, 'grad_norm': 6.951156139373779, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.012637641280889511, 'loss_2': 0.0008478164672851562, 'loss_3': -16.209043502807617, 'loss_4': 0.2424517273902893, 'epoch': 9.83}
{'loss': 0.0082, 'grad_norm': 5.662786483764648, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.007857677526772022, 'loss_2': 0.0003745555877685547, 'loss_3': -16.253929138183594, 'loss_4': 0.5655183792114258, 'epoch': 9.84}
{'loss': 0.0258, 'grad_norm': 9.762070655822754, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.022393733263015747, 'loss_2': 0.0034160614013671875, 'loss_3': -16.336742401123047, 'loss_4': 0.08890507370233536, 'epoch': 9.84}
{'loss': 0.0121, 'grad_norm': 5.141682147979736, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.007536128628998995, 'loss_2': 0.004608154296875, 'loss_3': -16.022567749023438, 'loss_4': -0.20860573649406433, 'epoch': 9.85}
{'loss': 0.0186, 'grad_norm': 10.89376163482666, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.018339181318879128, 'loss_2': 0.00026679039001464844, 'loss_3': -16.409893035888672, 'loss_4': 0.5166776180267334, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 15:59:43,085 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:43,085 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▏                                                                                                                                                  | 1700/5160 [42:21<1:00:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:50,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016693172976374626, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.32, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.013102754019200802, 'eval_loss_2': 0.003590419888496399, 'eval_loss_3': -18.204927444458008, 'eval_loss_4': 0.05824443697929382, 'epoch': 9.85}
{'loss': 0.0088, 'grad_norm': 5.855312824249268, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.008383769541978836, 'loss_2': 0.0003910064697265625, 'loss_3': -16.529685974121094, 'loss_4': 0.13416600227355957, 'epoch': 9.86}
{'loss': 0.0187, 'grad_norm': 14.474329948425293, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.017579184845089912, 'loss_2': 0.00107574462890625, 'loss_3': -16.396726608276367, 'loss_4': 0.10436320304870605, 'epoch': 9.87}
{'loss': 0.0142, 'grad_norm': 5.154504776000977, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.0088678989559412, 'loss_2': 0.00537109375, 'loss_3': -16.279518127441406, 'loss_4': 0.6785843372344971, 'epoch': 9.87}
{'loss': 0.0167, 'grad_norm': 5.290855407714844, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.009987087920308113, 'loss_2': 0.006710052490234375, 'loss_3': -16.250961303710938, 'loss_4': 0.158003568649292, 'epoch': 9.88}
{'loss': 0.024, 'grad_norm': 8.892985343933105, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.014459053054451942, 'loss_2': 0.009521484375, 'loss_3': -16.226810455322266, 'loss_4': 0.15240496397018433, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 15:59:50,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:50,458 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:28<59:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:57,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015113667584955692, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.996, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011369490996003151, 'eval_loss_2': 0.003744177520275116, 'eval_loss_3': -18.254417419433594, 'eval_loss_4': 0.22698147594928741, 'epoch': 9.88}
{'loss': 0.0306, 'grad_norm': 10.043885231018066, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.02368381805717945, 'loss_2': 0.006866455078125, 'loss_3': -16.3287353515625, 'loss_4': 0.6561765670776367, 'epoch': 9.89}
{'loss': 0.0156, 'grad_norm': 7.169695854187012, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.013299127109348774, 'loss_2': 0.0023441314697265625, 'loss_3': -16.302831649780273, 'loss_4': 0.6886795163154602, 'epoch': 9.9}
{'loss': 0.0185, 'grad_norm': 12.227642059326172, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.01794525422155857, 'loss_2': 0.0005102157592773438, 'loss_3': -16.22654914855957, 'loss_4': 0.6677194833755493, 'epoch': 9.9}
{'loss': 0.0144, 'grad_norm': 7.500472545623779, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.013543262146413326, 'loss_2': 0.0008363723754882812, 'loss_3': -16.17812156677246, 'loss_4': 1.4796247482299805, 'epoch': 9.91}
{'loss': 0.0218, 'grad_norm': 8.735591888427734, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.020786570385098457, 'loss_2': 0.0009646415710449219, 'loss_3': -16.46060562133789, 'loss_4': 0.9959044456481934, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 15:59:57,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:57,810 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:36<59:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:05,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015256671234965324, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.06, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010720668360590935, 'eval_loss_2': 0.00453600287437439, 'eval_loss_3': -18.297523498535156, 'eval_loss_4': 0.594682514667511, 'epoch': 9.91}
{'loss': 0.0143, 'grad_norm': 6.408856391906738, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.011922163888812065, 'loss_2': 0.00238037109375, 'loss_3': -16.281599044799805, 'loss_4': 1.1837875843048096, 'epoch': 9.92}
{'loss': 0.0137, 'grad_norm': 5.548304080963135, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.012440244667232037, 'loss_2': 0.0012464523315429688, 'loss_3': -16.275104522705078, 'loss_4': 0.6764401793479919, 'epoch': 9.92}
{'loss': 0.015, 'grad_norm': 6.185452938079834, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.014006557874381542, 'loss_2': 0.0009546279907226562, 'loss_3': -16.36756706237793, 'loss_4': 0.5999014377593994, 'epoch': 9.93}
{'loss': 0.072, 'grad_norm': 22.307390213012695, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.071883924305439, 'loss_2': 0.0001494884490966797, 'loss_3': -16.383216857910156, 'loss_4': 1.593915343284607, 'epoch': 9.94}
{'loss': 0.0342, 'grad_norm': 13.147786140441895, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.031063474714756012, 'loss_2': 0.0031528472900390625, 'loss_3': -16.481895446777344, 'loss_4': 0.6708576679229736, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 16:00:05,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:05,168 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:43<59:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:12,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013953815214335918, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.265, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009623507969081402, 'eval_loss_2': 0.004330307245254517, 'eval_loss_3': -18.29530906677246, 'eval_loss_4': 0.7005057334899902, 'epoch': 9.94}
{'loss': 0.0178, 'grad_norm': 5.84099006652832, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.010802777484059334, 'loss_2': 0.0070343017578125, 'loss_3': -16.595489501953125, 'loss_4': 1.2910902500152588, 'epoch': 9.95}
{'loss': 0.0092, 'grad_norm': 5.589916229248047, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.007713131606578827, 'loss_2': 0.001522064208984375, 'loss_3': -16.41391372680664, 'loss_4': 1.0600557327270508, 'epoch': 9.95}
{'loss': 0.0163, 'grad_norm': 7.444495677947998, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.011747550219297409, 'loss_2': 0.00460052490234375, 'loss_3': -16.38494873046875, 'loss_4': 0.419106125831604, 'epoch': 9.96}
{'loss': 0.0723, 'grad_norm': 21.384838104248047, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.06772758811712265, 'loss_2': 0.00455474853515625, 'loss_3': -16.23780059814453, 'loss_4': 1.0346729755401611, 'epoch': 9.97}
{'loss': 0.0104, 'grad_norm': 5.029041767120361, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.006838507018983364, 'loss_2': 0.003597259521484375, 'loss_3': -16.434337615966797, 'loss_4': 0.9425419569015503, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 16:00:12,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:12,526 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:50<53:35,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:00:19,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014726419933140278, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009897788055241108, 'eval_loss_2': 0.00482863187789917, 'eval_loss_3': -18.306299209594727, 'eval_loss_4': 0.674647331237793, 'epoch': 9.97}
{'loss': 0.0379, 'grad_norm': 28.845491409301758, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.035896897315979004, 'loss_2': 0.002017974853515625, 'loss_3': -16.652433395385742, 'loss_4': 0.7756975889205933, 'epoch': 9.98}
{'loss': 0.0153, 'grad_norm': 10.128695487976074, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.015103960409760475, 'loss_2': 0.00019812583923339844, 'loss_3': -16.36165428161621, 'loss_4': 0.9202865362167358, 'epoch': 9.98}
{'loss': 0.0121, 'grad_norm': 4.877467155456543, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.007190999109297991, 'loss_2': 0.00490570068359375, 'loss_3': -16.501441955566406, 'loss_4': 0.6753450632095337, 'epoch': 9.99}
{'loss': 0.0259, 'grad_norm': 7.764697074890137, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.01788223534822464, 'loss_2': 0.008026123046875, 'loss_3': -16.471538543701172, 'loss_4': 0.6312910318374634, 'epoch': 9.99}
{'loss': 0.0144, 'grad_norm': 6.2918524742126465, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.003626972669735551, 'loss_2': 0.01078033447265625, 'loss_3': -16.35780906677246, 'loss_4': 0.8432351350784302, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 16:00:19,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:19,526 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [42:57<58:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:00:26,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013197117485105991, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.046, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009342829696834087, 'eval_loss_2': 0.0038542896509170532, 'eval_loss_3': -18.234716415405273, 'eval_loss_4': 0.25719234347343445, 'epoch': 10.0}
{'loss': 0.0195, 'grad_norm': 7.431228160858154, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.01387469656765461, 'loss_2': 0.00560760498046875, 'loss_3': -16.27908706665039, 'loss_4': 0.4938329756259918, 'epoch': 10.01}
{'loss': 0.0141, 'grad_norm': 4.715911388397217, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.007442397531121969, 'loss_2': 0.00665283203125, 'loss_3': -16.339832305908203, 'loss_4': 0.14288613200187683, 'epoch': 10.01}
{'loss': 0.0095, 'grad_norm': 4.832542896270752, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.0068170251324772835, 'loss_2': 0.002712249755859375, 'loss_3': -16.370573043823242, 'loss_4': 0.8191307783126831, 'epoch': 10.02}
{'loss': 0.0111, 'grad_norm': 4.649802207946777, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.004977826029062271, 'loss_2': 0.00609588623046875, 'loss_3': -16.51702117919922, 'loss_4': 0.44543829560279846, 'epoch': 10.02}
{'loss': 0.0067, 'grad_norm': 4.9708170890808105, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.005457994993776083, 'loss_2': 0.0012760162353515625, 'loss_3': -16.53795051574707, 'loss_4': 0.2882467210292816, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 16:00:26,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:26,931 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [43:05<59:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:34,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014065587893128395, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.316, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.011132465675473213, 'eval_loss_2': 0.002933122217655182, 'eval_loss_3': -18.19260025024414, 'eval_loss_4': 0.1089993566274643, 'epoch': 10.03}
{'loss': 0.0351, 'grad_norm': 14.118478775024414, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.02329154685139656, 'loss_2': 0.0118408203125, 'loss_3': -16.561206817626953, 'loss_4': -0.08813434839248657, 'epoch': 10.03}
{'loss': 0.022, 'grad_norm': 7.750897407531738, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.01408669725060463, 'loss_2': 0.007904052734375, 'loss_3': -16.391494750976562, 'loss_4': 0.13118621706962585, 'epoch': 10.04}
{'loss': 0.0268, 'grad_norm': 10.107630729675293, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.017556702718138695, 'loss_2': 0.00927734375, 'loss_3': -16.227760314941406, 'loss_4': 0.3054037392139435, 'epoch': 10.05}
{'loss': 0.0157, 'grad_norm': 7.2922749519348145, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.009450975805521011, 'loss_2': 0.0062255859375, 'loss_3': -16.481220245361328, 'loss_4': 0.4455839991569519, 'epoch': 10.05}
{'loss': 0.0193, 'grad_norm': 6.767016887664795, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.015848135575652122, 'loss_2': 0.003498077392578125, 'loss_3': -16.297597885131836, 'loss_4': 0.44597527384757996, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 16:00:34,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:34,300 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [43:12<59:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:41,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01772933267056942, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.203, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013439706526696682, 'eval_loss_2': 0.0042896270751953125, 'eval_loss_3': -18.160831451416016, 'eval_loss_4': 0.051352500915527344, 'epoch': 10.06}
{'loss': 0.013, 'grad_norm': 5.3530073165893555, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.00628224853426218, 'loss_2': 0.0067291259765625, 'loss_3': -16.345809936523438, 'loss_4': 0.2917670011520386, 'epoch': 10.06}
{'loss': 0.0183, 'grad_norm': 9.37905216217041, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.012082801200449467, 'loss_2': 0.00617218017578125, 'loss_3': -16.336875915527344, 'loss_4': 0.1300767958164215, 'epoch': 10.07}
{'loss': 0.0151, 'grad_norm': 5.681038856506348, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.009994464926421642, 'loss_2': 0.005096435546875, 'loss_3': -16.264698028564453, 'loss_4': 0.48428595066070557, 'epoch': 10.08}
{'loss': 0.0164, 'grad_norm': 7.0984039306640625, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.014795508235692978, 'loss_2': 0.001617431640625, 'loss_3': -16.314250946044922, 'loss_4': 0.6099546551704407, 'epoch': 10.08}
{'loss': 0.0201, 'grad_norm': 4.731960296630859, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.007813752628862858, 'loss_2': 0.012298583984375, 'loss_3': -16.284557342529297, 'loss_4': 0.0455332025885582, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 16:00:41,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:41,658 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:19<59:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:49,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02800380252301693, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018747203052043915, 'eval_loss_2': 0.009256601333618164, 'eval_loss_3': -18.144140243530273, 'eval_loss_4': 0.04158937558531761, 'epoch': 10.09}
{'loss': 0.0157, 'grad_norm': 5.553011417388916, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.00941742118448019, 'loss_2': 0.006290435791015625, 'loss_3': -16.263900756835938, 'loss_4': 0.12272655218839645, 'epoch': 10.09}
{'loss': 0.025, 'grad_norm': 11.052715301513672, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.017674732953310013, 'loss_2': 0.0073699951171875, 'loss_3': -16.343202590942383, 'loss_4': 0.36735832691192627, 'epoch': 10.1}
{'loss': 0.0191, 'grad_norm': 6.108318328857422, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.009748910553753376, 'loss_2': 0.009368896484375, 'loss_3': -16.339927673339844, 'loss_4': 0.5157111287117004, 'epoch': 10.1}
{'loss': 0.0225, 'grad_norm': 7.629731178283691, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.018584735691547394, 'loss_2': 0.00394439697265625, 'loss_3': -16.294044494628906, 'loss_4': 0.3100684881210327, 'epoch': 10.11}
{'loss': 0.0163, 'grad_norm': 6.921419143676758, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.015149333514273167, 'loss_2': 0.0011835098266601562, 'loss_3': -16.390642166137695, 'loss_4': 0.40742558240890503, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 16:00:49,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:49,015 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:27<59:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:56,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017846740782260895, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015364311635494232, 'eval_loss_2': 0.0024824291467666626, 'eval_loss_3': -18.138580322265625, 'eval_loss_4': 0.07422288507223129, 'epoch': 10.12}
{'loss': 0.0145, 'grad_norm': 5.503627300262451, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.007577439770102501, 'loss_2': 0.00689697265625, 'loss_3': -16.415573120117188, 'loss_4': 0.3894340395927429, 'epoch': 10.12}
{'loss': 0.0364, 'grad_norm': 10.131572723388672, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.02724461629986763, 'loss_2': 0.0091552734375, 'loss_3': -16.315067291259766, 'loss_4': 0.398905485868454, 'epoch': 10.13}
{'loss': 0.0213, 'grad_norm': 6.389002799987793, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.013018620200455189, 'loss_2': 0.008270263671875, 'loss_3': -16.429523468017578, 'loss_4': 0.17882689833641052, 'epoch': 10.13}
{'loss': 0.0197, 'grad_norm': 5.2328715324401855, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.007421518210321665, 'loss_2': 0.01226806640625, 'loss_3': -16.620662689208984, 'loss_4': -0.2487282156944275, 'epoch': 10.14}
{'loss': 0.0191, 'grad_norm': 7.852118015289307, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.012246420606970787, 'loss_2': 0.0068817138671875, 'loss_3': -16.242515563964844, 'loss_4': 0.17914822697639465, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 16:00:56,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:56,364 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:34<59:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:03,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01827268674969673, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.281, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0151131646707654, 'eval_loss_2': 0.0031595230102539062, 'eval_loss_3': -18.15042495727539, 'eval_loss_4': 0.11809896677732468, 'epoch': 10.15}
{'loss': 0.0143, 'grad_norm': 6.463943958282471, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.009226854890584946, 'loss_2': 0.00510406494140625, 'loss_3': -16.113353729248047, 'loss_4': 0.5164867639541626, 'epoch': 10.15}
{'loss': 0.009, 'grad_norm': 4.892748832702637, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.006547420751303434, 'loss_2': 0.00246429443359375, 'loss_3': -16.332427978515625, 'loss_4': 0.0755099505186081, 'epoch': 10.16}
{'loss': 0.0165, 'grad_norm': 7.087314128875732, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.012677956372499466, 'loss_2': 0.003871917724609375, 'loss_3': -16.378883361816406, 'loss_4': 0.4877700209617615, 'epoch': 10.16}
{'loss': 0.0267, 'grad_norm': 9.730706214904785, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.020419185981154442, 'loss_2': 0.00627899169921875, 'loss_3': -16.2978515625, 'loss_4': 0.5184770226478577, 'epoch': 10.17}
{'loss': 0.0775, 'grad_norm': 19.84451675415039, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.07581270486116409, 'loss_2': 0.0016775131225585938, 'loss_3': -16.41888427734375, 'loss_4': 0.776940107345581, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 16:01:03,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:03,724 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:41<59:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:11,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029496725648641586, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.729, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.018531378358602524, 'eval_loss_2': 0.010965347290039062, 'eval_loss_3': -18.145856857299805, 'eval_loss_4': 0.23878350853919983, 'epoch': 10.17}
{'loss': 0.0352, 'grad_norm': 7.438981533050537, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.019639506936073303, 'loss_2': 0.0155792236328125, 'loss_3': -16.53095817565918, 'loss_4': 0.4932785630226135, 'epoch': 10.18}
{'loss': 0.0195, 'grad_norm': 8.072748184204102, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.014054305851459503, 'loss_2': 0.005458831787109375, 'loss_3': -16.456146240234375, 'loss_4': -0.09501950442790985, 'epoch': 10.19}
{'loss': 0.0458, 'grad_norm': 9.991060256958008, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.0293415654450655, 'loss_2': 0.016448974609375, 'loss_3': -16.159818649291992, 'loss_4': 0.5119278430938721, 'epoch': 10.19}
{'loss': 0.0183, 'grad_norm': 5.57634973526001, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.008382263593375683, 'loss_2': 0.00989532470703125, 'loss_3': -16.501829147338867, 'loss_4': 0.20714884996414185, 'epoch': 10.2}
{'loss': 0.043, 'grad_norm': 13.282377243041992, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.02716688998043537, 'loss_2': 0.01580810546875, 'loss_3': -16.185880661010742, 'loss_4': 0.44615304470062256, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 16:01:11,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:11,086 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:49<58:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:18,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03691628947854042, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.025925667956471443, 'eval_loss_2': 0.010990619659423828, 'eval_loss_3': -18.134281158447266, 'eval_loss_4': 0.4523003399372101, 'epoch': 10.2}
{'loss': 0.0341, 'grad_norm': 8.792397499084473, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.030104801058769226, 'loss_2': 0.004001617431640625, 'loss_3': -16.247669219970703, 'loss_4': 0.2711297571659088, 'epoch': 10.21}
{'loss': 0.0323, 'grad_norm': 14.57753849029541, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.027448199689388275, 'loss_2': 0.004802703857421875, 'loss_3': -16.225807189941406, 'loss_4': 0.322782963514328, 'epoch': 10.22}
{'loss': 0.0272, 'grad_norm': 8.350448608398438, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.01775646023452282, 'loss_2': 0.0094146728515625, 'loss_3': -16.21207046508789, 'loss_4': 0.5724582076072693, 'epoch': 10.22}
{'loss': 0.0186, 'grad_norm': 6.346507549285889, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.01816996932029724, 'loss_2': 0.0004291534423828125, 'loss_3': -16.347686767578125, 'loss_4': 0.4533318281173706, 'epoch': 10.23}
{'loss': 0.0237, 'grad_norm': 6.355664253234863, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.01704617589712143, 'loss_2': 0.00666046142578125, 'loss_3': -16.441085815429688, 'loss_4': 0.46814918518066406, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 16:01:18,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:18,432 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:56<58:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:25,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02280276268720627, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0197837483137846, 'eval_loss_2': 0.0030190125107765198, 'eval_loss_3': -18.190195083618164, 'eval_loss_4': 0.49331581592559814, 'epoch': 10.23}
{'loss': 0.0243, 'grad_norm': 7.456865310668945, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.0205986350774765, 'loss_2': 0.0036525726318359375, 'loss_3': -16.641250610351562, 'loss_4': 0.437771737575531, 'epoch': 10.24}
{'loss': 0.0115, 'grad_norm': 5.279906749725342, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.011210321448743343, 'loss_2': 0.00029468536376953125, 'loss_3': -16.5662899017334, 'loss_4': 0.5066846609115601, 'epoch': 10.24}
{'loss': 0.0218, 'grad_norm': 5.535052299499512, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.013576445169746876, 'loss_2': 0.00821685791015625, 'loss_3': -16.400774002075195, 'loss_4': 0.15098361670970917, 'epoch': 10.25}
{'loss': 0.0297, 'grad_norm': 6.82064962387085, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.02186913602054119, 'loss_2': 0.0078125, 'loss_3': -16.422927856445312, 'loss_4': 0.9277114272117615, 'epoch': 10.26}
{'loss': 0.0204, 'grad_norm': 6.7945661544799805, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.01450017374008894, 'loss_2': 0.00585174560546875, 'loss_3': -16.457984924316406, 'loss_4': 0.9165641069412231, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 16:01:25,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:25,783 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [44:03<58:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:33,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021896280348300934, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017186500132083893, 'eval_loss_2': 0.004709780216217041, 'eval_loss_3': -18.212860107421875, 'eval_loss_4': 0.4916348159313202, 'epoch': 10.26}
{'loss': 0.0131, 'grad_norm': 5.699595928192139, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.011151737533509731, 'loss_2': 0.001964569091796875, 'loss_3': -16.37303924560547, 'loss_4': 0.873615026473999, 'epoch': 10.27}
{'loss': 0.0214, 'grad_norm': 6.330456256866455, 'learning_rate': 1.975e-05, 'loss_1': 0.012697529047727585, 'loss_2': 0.008697509765625, 'loss_3': -16.279285430908203, 'loss_4': 0.5699886083602905, 'epoch': 10.27}
{'loss': 0.0136, 'grad_norm': 5.184452533721924, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.010263314470648766, 'loss_2': 0.0033626556396484375, 'loss_3': -16.618715286254883, 'loss_4': 0.7131405472755432, 'epoch': 10.28}
{'loss': 0.0232, 'grad_norm': 6.738100051879883, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.019697967916727066, 'loss_2': 0.003536224365234375, 'loss_3': -16.38384437561035, 'loss_4': 0.6897110342979431, 'epoch': 10.28}
{'loss': 0.0222, 'grad_norm': 9.786524772644043, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.014882177114486694, 'loss_2': 0.007289886474609375, 'loss_3': -16.476757049560547, 'loss_4': 0.25856682658195496, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 16:01:33,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:33,134 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [44:11<58:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:40,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021885305643081665, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.019083604216575623, 'eval_loss_2': 0.0028017014265060425, 'eval_loss_3': -18.179872512817383, 'eval_loss_4': 0.55162113904953, 'epoch': 10.29}
{'loss': 0.0246, 'grad_norm': 8.64844036102295, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.01706896908581257, 'loss_2': 0.0074920654296875, 'loss_3': -16.243404388427734, 'loss_4': 0.5104258060455322, 'epoch': 10.3}
{'loss': 0.0214, 'grad_norm': 7.165322780609131, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.01479752454906702, 'loss_2': 0.0066070556640625, 'loss_3': -16.541208267211914, 'loss_4': 0.8814107775688171, 'epoch': 10.3}
{'loss': 0.0171, 'grad_norm': 7.350155353546143, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.01340607088059187, 'loss_2': 0.003719329833984375, 'loss_3': -16.526094436645508, 'loss_4': 0.6650286316871643, 'epoch': 10.31}
{'loss': 0.0174, 'grad_norm': 5.736276149749756, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.011407204903662205, 'loss_2': 0.006011962890625, 'loss_3': -16.443756103515625, 'loss_4': 0.6421804428100586, 'epoch': 10.31}
{'loss': 0.0218, 'grad_norm': 6.850925445556641, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.01893157884478569, 'loss_2': 0.0028858184814453125, 'loss_3': -16.281227111816406, 'loss_4': 0.013216286897659302, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 16:01:40,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:40,487 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:18<58:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:47,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026062369346618652, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.023441625759005547, 'eval_loss_2': 0.0026207417249679565, 'eval_loss_3': -18.138795852661133, 'eval_loss_4': 0.5454484224319458, 'epoch': 10.32}
{'loss': 0.0093, 'grad_norm': 5.149622440338135, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.00719873420894146, 'loss_2': 0.002132415771484375, 'loss_3': -16.45180892944336, 'loss_4': 0.5287226438522339, 'epoch': 10.33}
{'loss': 0.0304, 'grad_norm': 13.136256217956543, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.021552804857492447, 'loss_2': 0.00887298583984375, 'loss_3': -16.280559539794922, 'loss_4': 0.3203282952308655, 'epoch': 10.33}
{'loss': 0.0073, 'grad_norm': 4.716546058654785, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.004984837956726551, 'loss_2': 0.0023593902587890625, 'loss_3': -16.394012451171875, 'loss_4': 0.7371249198913574, 'epoch': 10.34}
{'loss': 0.0241, 'grad_norm': 8.304883003234863, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.01838063634932041, 'loss_2': 0.0057525634765625, 'loss_3': -16.405241012573242, 'loss_4': 0.594445526599884, 'epoch': 10.34}
{'loss': 0.0141, 'grad_norm': 7.1086745262146, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.011504714377224445, 'loss_2': 0.002590179443359375, 'loss_3': -16.213058471679688, 'loss_4': 0.6481384038925171, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 16:01:47,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:47,849 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:26<58:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:55,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03287167474627495, 'eval_runtime': 3.813, 'eval_samples_per_second': 268.556, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.028642598539590836, 'eval_loss_2': 0.0042290762066841125, 'eval_loss_3': -18.11551284790039, 'eval_loss_4': 0.5583567023277283, 'epoch': 10.35}
{'loss': 0.041, 'grad_norm': 25.00243377685547, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.0362762026488781, 'loss_2': 0.00472259521484375, 'loss_3': -16.28157615661621, 'loss_4': 0.5786898136138916, 'epoch': 10.35}
{'loss': 0.0162, 'grad_norm': 6.733460903167725, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.01591053046286106, 'loss_2': 0.00025463104248046875, 'loss_3': -16.325817108154297, 'loss_4': 0.5691919326782227, 'epoch': 10.36}
{'loss': 0.0167, 'grad_norm': 4.839334487915039, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.006388280540704727, 'loss_2': 0.0102691650390625, 'loss_3': -16.34005355834961, 'loss_4': 0.3795261085033417, 'epoch': 10.37}
{'loss': 0.0238, 'grad_norm': 6.720763683319092, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.015921898186206818, 'loss_2': 0.00791168212890625, 'loss_3': -16.535602569580078, 'loss_4': 0.7344598770141602, 'epoch': 10.37}
{'loss': 0.0118, 'grad_norm': 6.599238395690918, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.010467514395713806, 'loss_2': 0.0013065338134765625, 'loss_3': -16.578022003173828, 'loss_4': 0.9970804452896118, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 16:01:55,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:55,213 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:33<58:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:02,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01744050532579422, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.388, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014347072690725327, 'eval_loss_2': 0.0030934326350688934, 'eval_loss_3': -18.185993194580078, 'eval_loss_4': 0.368676096200943, 'epoch': 10.38}
{'loss': 0.0168, 'grad_norm': 9.088398933410645, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.014516488648951054, 'loss_2': 0.00225830078125, 'loss_3': -16.569904327392578, 'loss_4': 0.416431725025177, 'epoch': 10.38}
{'loss': 0.0098, 'grad_norm': 4.748492240905762, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.008188423700630665, 'loss_2': 0.0015821456909179688, 'loss_3': -16.54901123046875, 'loss_4': 0.5861314535140991, 'epoch': 10.39}
{'loss': 0.0074, 'grad_norm': 5.067981719970703, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.006583689711987972, 'loss_2': 0.0008401870727539062, 'loss_3': -16.39175033569336, 'loss_4': 0.4944090247154236, 'epoch': 10.4}
{'loss': 0.0208, 'grad_norm': 7.634714603424072, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.014603751711547375, 'loss_2': 0.00621795654296875, 'loss_3': -16.36941909790039, 'loss_4': 0.141189306974411, 'epoch': 10.4}
{'loss': 0.0157, 'grad_norm': 5.205086708068848, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.009885960258543491, 'loss_2': 0.0057830810546875, 'loss_3': -16.541866302490234, 'loss_4': 0.4689120054244995, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 16:02:02,575 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:02,575 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:40<58:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:09,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014158029109239578, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011330914683640003, 'eval_loss_2': 0.0028271153569221497, 'eval_loss_3': -18.250335693359375, 'eval_loss_4': 0.17494353652000427, 'epoch': 10.41}
{'loss': 0.0203, 'grad_norm': 5.27192497253418, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.009885409846901894, 'loss_2': 0.0104217529296875, 'loss_3': -16.472326278686523, 'loss_4': 0.27928611636161804, 'epoch': 10.41}
{'loss': 0.0161, 'grad_norm': 6.221078872680664, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.015647996217012405, 'loss_2': 0.0004849433898925781, 'loss_3': -16.4385986328125, 'loss_4': -0.042464062571525574, 'epoch': 10.42}
{'loss': 0.0347, 'grad_norm': 7.951767444610596, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.03160069137811661, 'loss_2': 0.0030517578125, 'loss_3': -16.428424835205078, 'loss_4': 0.15962131321430206, 'epoch': 10.42}
{'loss': 0.0129, 'grad_norm': 5.24578857421875, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.010937253944575787, 'loss_2': 0.00196075439453125, 'loss_3': -16.313447952270508, 'loss_4': 0.1397896707057953, 'epoch': 10.43}
{'loss': 0.0198, 'grad_norm': 6.362119197845459, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.016453901305794716, 'loss_2': 0.00336456298828125, 'loss_3': -16.50827407836914, 'loss_4': -0.13329964876174927, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 16:02:09,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:09,929 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:48<58:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:17,278 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013128256425261497, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.432, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010613755322992802, 'eval_loss_2': 0.002514500170946121, 'eval_loss_3': -18.27827262878418, 'eval_loss_4': 0.0368671752512455, 'epoch': 10.44}
{'loss': 0.0289, 'grad_norm': 8.827936172485352, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.01634121499955654, 'loss_2': 0.0125274658203125, 'loss_3': -16.410140991210938, 'loss_4': 0.35748550295829773, 'epoch': 10.44}
{'loss': 0.0191, 'grad_norm': 6.338013172149658, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.01563059538602829, 'loss_2': 0.00344085693359375, 'loss_3': -16.4361572265625, 'loss_4': -0.013631947338581085, 'epoch': 10.45}
{'loss': 0.0326, 'grad_norm': 11.310867309570312, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.023227984085679054, 'loss_2': 0.0093841552734375, 'loss_3': -16.506916046142578, 'loss_4': -0.35076966881752014, 'epoch': 10.45}
{'loss': 0.0245, 'grad_norm': 8.3775634765625, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.021543383598327637, 'loss_2': 0.002979278564453125, 'loss_3': -16.509363174438477, 'loss_4': 0.42480897903442383, 'epoch': 10.46}
{'loss': 0.0147, 'grad_norm': 5.6138916015625, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.014417128637433052, 'loss_2': 0.0002651214599609375, 'loss_3': -16.430465698242188, 'loss_4': 0.43391406536102295, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 16:02:17,278 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:17,278 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:55<58:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:24,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01802236959338188, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010705780237913132, 'eval_loss_2': 0.00731658935546875, 'eval_loss_3': -18.310285568237305, 'eval_loss_4': 0.06095680966973305, 'epoch': 10.47}
{'loss': 0.0232, 'grad_norm': 6.794094085693359, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.01686227321624756, 'loss_2': 0.006366729736328125, 'loss_3': -16.499374389648438, 'loss_4': 0.019343674182891846, 'epoch': 10.47}
{'loss': 0.0167, 'grad_norm': 5.033812999725342, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.009080523625016212, 'loss_2': 0.00762176513671875, 'loss_3': -16.569156646728516, 'loss_4': 0.08964891731739044, 'epoch': 10.48}
{'loss': 0.0313, 'grad_norm': 17.168628692626953, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.02420610375702381, 'loss_2': 0.007106781005859375, 'loss_3': -16.540283203125, 'loss_4': 0.031231261789798737, 'epoch': 10.48}
{'loss': 0.0249, 'grad_norm': 13.690625190734863, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.023011863231658936, 'loss_2': 0.0018644332885742188, 'loss_3': -16.485530853271484, 'loss_4': 0.3885379433631897, 'epoch': 10.49}
{'loss': 0.0157, 'grad_norm': 6.46441650390625, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.0127247404307127, 'loss_2': 0.002933502197265625, 'loss_3': -16.513351440429688, 'loss_4': 0.5224552750587463, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 16:02:24,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:24,629 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [45:02<58:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:31,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013976097106933594, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.052, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010602801106870174, 'eval_loss_2': 0.0033732950687408447, 'eval_loss_3': -18.326454162597656, 'eval_loss_4': 0.16162598133087158, 'epoch': 10.49}
{'loss': 0.0189, 'grad_norm': 10.686929702758789, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.017516694962978363, 'loss_2': 0.0013408660888671875, 'loss_3': -16.612205505371094, 'loss_4': 0.06951837986707687, 'epoch': 10.5}
{'loss': 0.0141, 'grad_norm': 5.669991970062256, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.012719311751425266, 'loss_2': 0.001399993896484375, 'loss_3': -16.41140365600586, 'loss_4': 0.22731444239616394, 'epoch': 10.51}
{'loss': 0.0205, 'grad_norm': 6.626420974731445, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.013209948316216469, 'loss_2': 0.0073394775390625, 'loss_3': -16.663612365722656, 'loss_4': 0.4286210536956787, 'epoch': 10.51}
{'loss': 0.0177, 'grad_norm': 7.761299133300781, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.01008959487080574, 'loss_2': 0.007598876953125, 'loss_3': -16.62946891784668, 'loss_4': 0.6006141901016235, 'epoch': 10.52}
{'loss': 0.0167, 'grad_norm': 6.317119121551514, 'learning_rate': 1.95e-05, 'loss_1': 0.010057416744530201, 'loss_2': 0.006683349609375, 'loss_3': -16.482521057128906, 'loss_4': 0.5010699033737183, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 16:02:31,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:31,990 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [45:10<57:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:39,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015465455129742622, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009928153827786446, 'eval_loss_2': 0.005537301301956177, 'eval_loss_3': -18.342058181762695, 'eval_loss_4': 0.06476455181837082, 'epoch': 10.52}
{'loss': 0.0202, 'grad_norm': 10.895540237426758, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.01990341953933239, 'loss_2': 0.00026798248291015625, 'loss_3': -16.573284149169922, 'loss_4': 0.037270937114953995, 'epoch': 10.53}
{'loss': 0.027, 'grad_norm': 4.706324100494385, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.01007989700883627, 'loss_2': 0.01690673828125, 'loss_3': -16.508127212524414, 'loss_4': 0.0625053346157074, 'epoch': 10.53}
{'loss': 0.0244, 'grad_norm': 10.684309005737305, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.022682810202240944, 'loss_2': 0.0016956329345703125, 'loss_3': -16.492774963378906, 'loss_4': 0.24842770397663116, 'epoch': 10.54}
{'loss': 0.0269, 'grad_norm': 5.794010639190674, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.015803931280970573, 'loss_2': 0.01113128662109375, 'loss_3': -16.587831497192383, 'loss_4': 0.19183139503002167, 'epoch': 10.55}
{'loss': 0.0136, 'grad_norm': 6.232173442840576, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.012892011553049088, 'loss_2': 0.0007262229919433594, 'loss_3': -16.454021453857422, 'loss_4': 0.019526049494743347, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 16:02:39,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:39,341 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:17<57:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:46,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0139116570353508, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.386, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009401671588420868, 'eval_loss_2': 0.004509985446929932, 'eval_loss_3': -18.33136558532715, 'eval_loss_4': 0.02015811949968338, 'epoch': 10.55}
{'loss': 0.0405, 'grad_norm': 14.256452560424805, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.032328393310308456, 'loss_2': 0.0081787109375, 'loss_3': -16.290376663208008, 'loss_4': 0.6602029800415039, 'epoch': 10.56}
{'loss': 0.0187, 'grad_norm': 6.520195484161377, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.01296934299170971, 'loss_2': 0.005695343017578125, 'loss_3': -16.58493423461914, 'loss_4': 0.3392038941383362, 'epoch': 10.56}
{'loss': 0.0172, 'grad_norm': 6.8056440353393555, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.009517368860542774, 'loss_2': 0.0077056884765625, 'loss_3': -16.60417366027832, 'loss_4': 0.36036109924316406, 'epoch': 10.57}
{'loss': 0.0197, 'grad_norm': 5.564859390258789, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.011743028648197651, 'loss_2': 0.00798797607421875, 'loss_3': -16.591115951538086, 'loss_4': 0.11890116333961487, 'epoch': 10.58}
{'loss': 0.021, 'grad_norm': 5.37809419631958, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.008792191743850708, 'loss_2': 0.01216888427734375, 'loss_3': -16.485475540161133, 'loss_4': -0.15207508206367493, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 16:02:46,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:46,691 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:24<57:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:54,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016202421858906746, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.408, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010383102111518383, 'eval_loss_2': 0.0058193206787109375, 'eval_loss_3': -18.30093002319336, 'eval_loss_4': -0.07086241245269775, 'epoch': 10.58}
{'loss': 0.0267, 'grad_norm': 8.367460250854492, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.01359882764518261, 'loss_2': 0.01306915283203125, 'loss_3': -16.402891159057617, 'loss_4': 0.003958888351917267, 'epoch': 10.59}
{'loss': 0.0237, 'grad_norm': 6.472105979919434, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.015811210498213768, 'loss_2': 0.007843017578125, 'loss_3': -16.67615509033203, 'loss_4': 0.08698511868715286, 'epoch': 10.59}
{'loss': 0.0215, 'grad_norm': 6.165313720703125, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.012043728493154049, 'loss_2': 0.00946807861328125, 'loss_3': -16.67517852783203, 'loss_4': 0.004057377576828003, 'epoch': 10.6}
{'loss': 0.018, 'grad_norm': 6.579108715057373, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.01756197214126587, 'loss_2': 0.0004763603210449219, 'loss_3': -16.52967071533203, 'loss_4': -0.21783794462680817, 'epoch': 10.6}
{'loss': 0.023, 'grad_norm': 7.534509181976318, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.01912505552172661, 'loss_2': 0.003894805908203125, 'loss_3': -16.387908935546875, 'loss_4': 0.4072125554084778, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 16:02:54,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:54,043 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:32<57:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:01,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017705757170915604, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010038753971457481, 'eval_loss_2': 0.0076670050621032715, 'eval_loss_3': -18.298831939697266, 'eval_loss_4': 0.20874539017677307, 'epoch': 10.61}
{'loss': 0.0264, 'grad_norm': 8.468632698059082, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.014955076389014721, 'loss_2': 0.011474609375, 'loss_3': -16.356325149536133, 'loss_4': 0.23943065106868744, 'epoch': 10.62}
{'loss': 0.0331, 'grad_norm': 8.245925903320312, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.023107286542654037, 'loss_2': 0.0100250244140625, 'loss_3': -16.394615173339844, 'loss_4': 0.007442288100719452, 'epoch': 10.62}
{'loss': 0.0301, 'grad_norm': 7.310024738311768, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.020037591457366943, 'loss_2': 0.01004791259765625, 'loss_3': -16.441070556640625, 'loss_4': 0.577920138835907, 'epoch': 10.63}
{'loss': 0.0159, 'grad_norm': 4.773011207580566, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.008290469646453857, 'loss_2': 0.00760650634765625, 'loss_3': -16.434432983398438, 'loss_4': 0.23466245830059052, 'epoch': 10.63}
{'loss': 0.0303, 'grad_norm': 12.84544563293457, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.023408452048897743, 'loss_2': 0.0069122314453125, 'loss_3': -16.485336303710938, 'loss_4': 0.6066941022872925, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 16:03:01,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:01,392 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:39<57:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:08,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021655021235346794, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.849, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009808477945625782, 'eval_loss_2': 0.011846542358398438, 'eval_loss_3': -18.309955596923828, 'eval_loss_4': 0.444809228181839, 'epoch': 10.64}
{'loss': 0.0435, 'grad_norm': 13.579854011535645, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.03187967464327812, 'loss_2': 0.01160430908203125, 'loss_3': -16.603862762451172, 'loss_4': 0.47103995084762573, 'epoch': 10.65}
{'loss': 0.0277, 'grad_norm': 5.1368021965026855, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.008921761065721512, 'loss_2': 0.01873779296875, 'loss_3': -16.373287200927734, 'loss_4': 0.9539326429367065, 'epoch': 10.65}
{'loss': 0.0915, 'grad_norm': 14.697668075561523, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.0717809870839119, 'loss_2': 0.019683837890625, 'loss_3': -16.193077087402344, 'loss_4': 0.940152645111084, 'epoch': 10.66}
{'loss': 0.0103, 'grad_norm': 5.139440536499023, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.005924217402935028, 'loss_2': 0.004352569580078125, 'loss_3': -16.230878829956055, 'loss_4': 0.44795331358909607, 'epoch': 10.66}
{'loss': 0.0177, 'grad_norm': 5.5601325035095215, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.007727101445198059, 'loss_2': 0.00997161865234375, 'loss_3': -16.598003387451172, 'loss_4': 1.029711127281189, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 16:03:08,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:08,753 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:46<57:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:16,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012822799384593964, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.218, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008177096024155617, 'eval_loss_2': 0.004645705223083496, 'eval_loss_3': -18.292491912841797, 'eval_loss_4': 0.442045658826828, 'epoch': 10.67}
{'loss': 0.011, 'grad_norm': 6.503835678100586, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.007329393178224564, 'loss_2': 0.0036792755126953125, 'loss_3': -16.363218307495117, 'loss_4': 0.6764759421348572, 'epoch': 10.67}
{'loss': 0.0311, 'grad_norm': 12.278158187866211, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.026466473937034607, 'loss_2': 0.00458526611328125, 'loss_3': -16.161481857299805, 'loss_4': 0.821172297000885, 'epoch': 10.68}
{'loss': 0.023, 'grad_norm': 10.576005935668945, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.01888902671635151, 'loss_2': 0.004150390625, 'loss_3': -16.380647659301758, 'loss_4': 0.7930598855018616, 'epoch': 10.69}
{'loss': 0.0062, 'grad_norm': 4.707866668701172, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.005724459886550903, 'loss_2': 0.00049591064453125, 'loss_3': -16.39040184020996, 'loss_4': 0.3646821975708008, 'epoch': 10.69}
{'loss': 0.0131, 'grad_norm': 5.410330295562744, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.0075070359744131565, 'loss_2': 0.0056304931640625, 'loss_3': -16.506519317626953, 'loss_4': 0.5512933731079102, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 16:03:16,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:16,100 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:54<57:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:23,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013095342554152012, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007723884657025337, 'eval_loss_2': 0.005371458828449249, 'eval_loss_3': -18.259931564331055, 'eval_loss_4': 0.27499598264694214, 'epoch': 10.7}
{'loss': 0.0217, 'grad_norm': 12.495428085327148, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.017430895939469337, 'loss_2': 0.00423431396484375, 'loss_3': -16.474912643432617, 'loss_4': 0.09807780385017395, 'epoch': 10.7}
{'loss': 0.0147, 'grad_norm': 5.102285385131836, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.007578881457448006, 'loss_2': 0.00713348388671875, 'loss_3': -16.482736587524414, 'loss_4': 0.04456913471221924, 'epoch': 10.71}
{'loss': 0.0132, 'grad_norm': 4.57819938659668, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.006054208148270845, 'loss_2': 0.007110595703125, 'loss_3': -16.327678680419922, 'loss_4': 0.22532300651073456, 'epoch': 10.72}
{'loss': 0.0115, 'grad_norm': 6.039554119110107, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.010588973760604858, 'loss_2': 0.0009126663208007812, 'loss_3': -16.299320220947266, 'loss_4': 0.29515862464904785, 'epoch': 10.72}
{'loss': 0.0171, 'grad_norm': 7.6073408126831055, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.014116166159510612, 'loss_2': 0.003017425537109375, 'loss_3': -16.45255470275879, 'loss_4': -0.5122827887535095, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 16:03:23,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:23,450 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [46:01<57:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:30,796 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010273084975779057, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007631675340235233, 'eval_loss_2': 0.0026414096355438232, 'eval_loss_3': -18.245895385742188, 'eval_loss_4': -0.043605804443359375, 'epoch': 10.73}
{'loss': 0.0141, 'grad_norm': 5.580056667327881, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.012836964800953865, 'loss_2': 0.0013113021850585938, 'loss_3': -16.418869018554688, 'loss_4': 0.26500803232192993, 'epoch': 10.73}
{'loss': 0.0147, 'grad_norm': 7.089395523071289, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.012863670475780964, 'loss_2': 0.0018758773803710938, 'loss_3': -16.462160110473633, 'loss_4': 0.3212193250656128, 'epoch': 10.74}
{'loss': 0.0165, 'grad_norm': 7.253873348236084, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.012951352633535862, 'loss_2': 0.00354766845703125, 'loss_3': -16.615266799926758, 'loss_4': -0.12151262164115906, 'epoch': 10.74}
{'loss': 0.021, 'grad_norm': 10.502359390258789, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.017539577558636665, 'loss_2': 0.00342559814453125, 'loss_3': -16.382293701171875, 'loss_4': 0.0755249559879303, 'epoch': 10.75}
{'loss': 0.044, 'grad_norm': 15.671359062194824, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.041797563433647156, 'loss_2': 0.0021686553955078125, 'loss_3': -16.58233642578125, 'loss_4': 0.07311822474002838, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 16:03:30,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:30,797 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [46:08<57:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:38,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011871695518493652, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.425, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0095834881067276, 'eval_loss_2': 0.0022882074117660522, 'eval_loss_3': -18.21663475036621, 'eval_loss_4': -0.23509562015533447, 'epoch': 10.76}
{'loss': 0.0084, 'grad_norm': 4.780827522277832, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.007798080798238516, 'loss_2': 0.0005788803100585938, 'loss_3': -16.377458572387695, 'loss_4': -0.30073320865631104, 'epoch': 10.76}
{'loss': 0.0101, 'grad_norm': 6.004120826721191, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.007223049178719521, 'loss_2': 0.002887725830078125, 'loss_3': -16.514495849609375, 'loss_4': -0.520782470703125, 'epoch': 10.77}
{'loss': 0.0159, 'grad_norm': 6.343236923217773, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.012061890214681625, 'loss_2': 0.003803253173828125, 'loss_3': -16.403316497802734, 'loss_4': -0.3473331034183502, 'epoch': 10.77}
{'loss': 0.0262, 'grad_norm': 8.009878158569336, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.0181888397783041, 'loss_2': 0.00804901123046875, 'loss_3': -16.194747924804688, 'loss_4': -0.5557914972305298, 'epoch': 10.78}
{'loss': 0.0152, 'grad_norm': 8.551921844482422, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.01424417458474636, 'loss_2': 0.0009107589721679688, 'loss_3': -16.454742431640625, 'loss_4': -0.3642520308494568, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 16:03:38,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:38,141 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:16<57:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:45,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031199611723423004, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.869, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.028331317007541656, 'eval_loss_2': 0.0028682947158813477, 'eval_loss_3': -18.06829261779785, 'eval_loss_4': -0.3527471423149109, 'epoch': 10.78}
{'loss': 0.0125, 'grad_norm': 5.173445224761963, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.005991759710013866, 'loss_2': 0.006504058837890625, 'loss_3': -16.32904052734375, 'loss_4': -0.3426963686943054, 'epoch': 10.79}
{'loss': 0.0105, 'grad_norm': 5.370013236999512, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.00804983451962471, 'loss_2': 0.00249481201171875, 'loss_3': -16.262958526611328, 'loss_4': -0.41253507137298584, 'epoch': 10.8}
{'loss': 0.0152, 'grad_norm': 8.095545768737793, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.012058548629283905, 'loss_2': 0.003185272216796875, 'loss_3': -16.504905700683594, 'loss_4': -0.6814247369766235, 'epoch': 10.8}
{'loss': 0.0324, 'grad_norm': 18.84307861328125, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.03223657235503197, 'loss_2': 0.0001780986785888672, 'loss_3': -16.192401885986328, 'loss_4': -0.48618653416633606, 'epoch': 10.81}
{'loss': 0.0271, 'grad_norm': 7.407400131225586, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.016084901988506317, 'loss_2': 0.01100921630859375, 'loss_3': -16.187110900878906, 'loss_4': -0.7538430094718933, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 16:03:45,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:45,498 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:23<57:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:52,857 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.049877721816301346, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.04685099795460701, 'eval_loss_2': 0.003026723861694336, 'eval_loss_3': -18.043304443359375, 'eval_loss_4': -0.37139612436294556, 'epoch': 10.81}
{'loss': 0.0262, 'grad_norm': 7.993797779083252, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.016423793509602547, 'loss_2': 0.0097503662109375, 'loss_3': -16.06529426574707, 'loss_4': -0.33107489347457886, 'epoch': 10.82}
{'loss': 0.012, 'grad_norm': 6.454561710357666, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.011228710412979126, 'loss_2': 0.0008068084716796875, 'loss_3': -16.569561004638672, 'loss_4': -0.3877171277999878, 'epoch': 10.83}
{'loss': 0.0133, 'grad_norm': 7.93904972076416, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.012902671471238136, 'loss_2': 0.0003666877746582031, 'loss_3': -16.268144607543945, 'loss_4': -0.6175792813301086, 'epoch': 10.83}
{'loss': 0.0118, 'grad_norm': 5.020938873291016, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.008067072369158268, 'loss_2': 0.003765106201171875, 'loss_3': -16.480022430419922, 'loss_4': -0.754770040512085, 'epoch': 10.84}
{'loss': 0.0127, 'grad_norm': 6.152894973754883, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.00891285389661789, 'loss_2': 0.0037822723388671875, 'loss_3': -16.375221252441406, 'loss_4': -0.7413227558135986, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 16:03:52,857 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:52,857 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:31<56:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:00,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04485161602497101, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.04171718657016754, 'eval_loss_2': 0.003134429454803467, 'eval_loss_3': -18.098670959472656, 'eval_loss_4': -0.260797381401062, 'epoch': 10.84}
{'loss': 0.0162, 'grad_norm': 5.9397711753845215, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.009115583263337612, 'loss_2': 0.00711822509765625, 'loss_3': -16.420242309570312, 'loss_4': -0.27733904123306274, 'epoch': 10.85}
{'loss': 0.0142, 'grad_norm': 6.164139747619629, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.01283979881554842, 'loss_2': 0.0013132095336914062, 'loss_3': -16.376253128051758, 'loss_4': -0.1961463838815689, 'epoch': 10.85}
{'loss': 0.0171, 'grad_norm': 5.9272637367248535, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.011711155995726585, 'loss_2': 0.00543212890625, 'loss_3': -16.43901252746582, 'loss_4': -0.6608681082725525, 'epoch': 10.86}
{'loss': 0.0175, 'grad_norm': 6.036992073059082, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.011196907609701157, 'loss_2': 0.00630950927734375, 'loss_3': -16.465557098388672, 'loss_4': -0.3479148745536804, 'epoch': 10.87}
{'loss': 0.0172, 'grad_norm': 6.678461074829102, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.012352310121059418, 'loss_2': 0.00479888916015625, 'loss_3': -16.511905670166016, 'loss_4': -0.3312729597091675, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 16:04:00,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:00,203 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:38<56:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:07,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021079324185848236, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017040245234966278, 'eval_loss_2': 0.004039078950881958, 'eval_loss_3': -18.198904037475586, 'eval_loss_4': -0.22817492485046387, 'epoch': 10.87}
{'loss': 0.0183, 'grad_norm': 5.906711578369141, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.010869652964174747, 'loss_2': 0.00743865966796875, 'loss_3': -16.467548370361328, 'loss_4': -0.0116012804210186, 'epoch': 10.88}
{'loss': 0.0178, 'grad_norm': 5.215741157531738, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.008924871683120728, 'loss_2': 0.00885772705078125, 'loss_3': -16.42230224609375, 'loss_4': 0.17772240936756134, 'epoch': 10.88}
{'loss': 0.0417, 'grad_norm': 24.183629989624023, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.030844898894429207, 'loss_2': 0.01087188720703125, 'loss_3': -16.45430564880371, 'loss_4': -0.023997411131858826, 'epoch': 10.89}
{'loss': 0.0195, 'grad_norm': 10.278139114379883, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.015546697191894054, 'loss_2': 0.00396728515625, 'loss_3': -16.473817825317383, 'loss_4': -0.42483144998550415, 'epoch': 10.9}
{'loss': 0.0192, 'grad_norm': 7.285782337188721, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.01729457825422287, 'loss_2': 0.0019435882568359375, 'loss_3': -16.531936645507812, 'loss_4': 0.06278502941131592, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 16:04:07,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:07,551 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:45<56:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:14,900 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013848735019564629, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.388, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0103081576526165, 'eval_loss_2': 0.0035405755043029785, 'eval_loss_3': -18.24580955505371, 'eval_loss_4': -0.30907243490219116, 'epoch': 10.9}
{'loss': 0.0203, 'grad_norm': 8.232726097106934, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.012614419683814049, 'loss_2': 0.00768280029296875, 'loss_3': -16.43982696533203, 'loss_4': -0.12785537540912628, 'epoch': 10.91}
{'loss': 0.0135, 'grad_norm': 6.045699596405029, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.01144606526941061, 'loss_2': 0.00205230712890625, 'loss_3': -16.417490005493164, 'loss_4': -0.32955068349838257, 'epoch': 10.91}
{'loss': 0.0132, 'grad_norm': 6.188691139221191, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.009468276053667068, 'loss_2': 0.0037212371826171875, 'loss_3': -16.510915756225586, 'loss_4': -0.41464757919311523, 'epoch': 10.92}
{'loss': 0.0305, 'grad_norm': 11.457275390625, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.02560271881520748, 'loss_2': 0.00487518310546875, 'loss_3': -16.308135986328125, 'loss_4': -0.11710809916257858, 'epoch': 10.92}
{'loss': 0.0149, 'grad_norm': 8.421672821044922, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.012854397296905518, 'loss_2': 0.002002716064453125, 'loss_3': -16.42874526977539, 'loss_4': -0.4017106890678406, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 16:04:14,900 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:14,900 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:53<56:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:22,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013408124446868896, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.715, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00970463640987873, 'eval_loss_2': 0.003703489899635315, 'eval_loss_3': -18.244457244873047, 'eval_loss_4': -0.32588398456573486, 'epoch': 10.93}
{'loss': 0.017, 'grad_norm': 7.764623165130615, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.015348754823207855, 'loss_2': 0.0016984939575195312, 'loss_3': -16.205730438232422, 'loss_4': -0.2674799859523773, 'epoch': 10.94}
{'loss': 0.075, 'grad_norm': 15.025323867797852, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.07294511049985886, 'loss_2': 0.0020751953125, 'loss_3': -16.456802368164062, 'loss_4': -0.17440390586853027, 'epoch': 10.94}
{'loss': 0.0122, 'grad_norm': 5.040633201599121, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.01066946517676115, 'loss_2': 0.00156402587890625, 'loss_3': -16.59081268310547, 'loss_4': -0.20927490293979645, 'epoch': 10.95}
{'loss': 0.0075, 'grad_norm': 5.0199737548828125, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.007330375723540783, 'loss_2': 0.00012028217315673828, 'loss_3': -16.334449768066406, 'loss_4': -0.31387895345687866, 'epoch': 10.95}
{'loss': 0.015, 'grad_norm': 5.684140682220459, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.007381433621048927, 'loss_2': 0.007656097412109375, 'loss_3': -16.430660247802734, 'loss_4': 0.30300724506378174, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 16:04:22,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:22,246 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [47:00<56:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:29,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012837102636694908, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.679, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009119397960603237, 'eval_loss_2': 0.0037177056074142456, 'eval_loss_3': -18.246389389038086, 'eval_loss_4': -0.15853792428970337, 'epoch': 10.96}
{'loss': 0.0144, 'grad_norm': 8.458186149597168, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.013110368512570858, 'loss_2': 0.0012664794921875, 'loss_3': -16.139339447021484, 'loss_4': 0.1881396472454071, 'epoch': 10.97}
{'loss': 0.0125, 'grad_norm': 5.644793510437012, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.009439635090529919, 'loss_2': 0.00302886962890625, 'loss_3': -16.326858520507812, 'loss_4': -0.25216424465179443, 'epoch': 10.97}
{'loss': 0.0735, 'grad_norm': 9.980574607849121, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.07260783016681671, 'loss_2': 0.0008726119995117188, 'loss_3': -16.418928146362305, 'loss_4': 0.6757769584655762, 'epoch': 10.98}
{'loss': 0.0214, 'grad_norm': 5.9187750816345215, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.016334276646375656, 'loss_2': 0.00505828857421875, 'loss_3': -16.37717628479004, 'loss_4': -0.4937368631362915, 'epoch': 10.98}
{'loss': 0.0312, 'grad_norm': 11.059889793395996, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.021638624370098114, 'loss_2': 0.009521484375, 'loss_3': -16.155691146850586, 'loss_4': 0.2816738486289978, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 16:04:29,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:29,610 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [47:07<54:49,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:04:36,639 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014238791540265083, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010409310460090637, 'eval_loss_2': 0.003829479217529297, 'eval_loss_3': -18.2121639251709, 'eval_loss_4': 0.0262112095952034, 'epoch': 10.99}
{'loss': 0.0139, 'grad_norm': 8.231687545776367, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.010783454403281212, 'loss_2': 0.003101348876953125, 'loss_3': -16.267940521240234, 'loss_4': 0.545821487903595, 'epoch': 10.99}
{'loss': 0.0059, 'grad_norm': 6.476641654968262, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.002735741436481476, 'loss_2': 0.0032138824462890625, 'loss_3': -16.384294509887695, 'loss_4': 0.045657865703105927, 'epoch': 11.0}
{'loss': 0.0126, 'grad_norm': 5.65103006362915, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.011375028640031815, 'loss_2': 0.001224517822265625, 'loss_3': -16.4495792388916, 'loss_4': -0.02002352476119995, 'epoch': 11.01}
{'loss': 0.0197, 'grad_norm': 6.416274070739746, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.012222034856677055, 'loss_2': 0.00750732421875, 'loss_3': -16.60171127319336, 'loss_4': 0.10512225329875946, 'epoch': 11.01}
{'loss': 0.0159, 'grad_norm': 5.583052635192871, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.010988730937242508, 'loss_2': 0.00487518310546875, 'loss_3': -16.39788818359375, 'loss_4': -0.16227243840694427, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 16:04:36,639 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:36,639 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:14<56:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:04:43,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01859872415661812, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01451848540455103, 'eval_loss_2': 0.004080235958099365, 'eval_loss_3': -18.18680763244629, 'eval_loss_4': 0.053922347724437714, 'epoch': 11.02}
{'loss': 0.0129, 'grad_norm': 5.481137752532959, 'learning_rate': 1.9e-05, 'loss_1': 0.0102519690990448, 'loss_2': 0.002613067626953125, 'loss_3': -16.29828643798828, 'loss_4': 0.21328969299793243, 'epoch': 11.02}
{'loss': 0.0327, 'grad_norm': 12.045774459838867, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.029079394415020943, 'loss_2': 0.00359344482421875, 'loss_3': -16.396331787109375, 'loss_4': 0.19220316410064697, 'epoch': 11.03}
{'loss': 0.0197, 'grad_norm': 12.467695236206055, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.014510801993310452, 'loss_2': 0.00516510009765625, 'loss_3': -16.384395599365234, 'loss_4': -0.03374965488910675, 'epoch': 11.03}
{'loss': 0.0099, 'grad_norm': 5.282911777496338, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.007428979966789484, 'loss_2': 0.00244140625, 'loss_3': -16.237958908081055, 'loss_4': 0.3179881274700165, 'epoch': 11.04}
{'loss': 0.0349, 'grad_norm': 16.300697326660156, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.0309736505150795, 'loss_2': 0.00390625, 'loss_3': -16.500932693481445, 'loss_4': 0.34957680106163025, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 16:04:43,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:43,984 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:22<56:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:51,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022970352321863174, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.391, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018892411142587662, 'eval_loss_2': 0.004077941179275513, 'eval_loss_3': -18.174448013305664, 'eval_loss_4': 0.04933924227952957, 'epoch': 11.05}
{'loss': 0.0299, 'grad_norm': 17.169719696044922, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.02520087920129299, 'loss_2': 0.004665374755859375, 'loss_3': -16.434202194213867, 'loss_4': 0.28596827387809753, 'epoch': 11.05}
{'loss': 0.014, 'grad_norm': 9.771830558776855, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.012618674896657467, 'loss_2': 0.0013637542724609375, 'loss_3': -16.29710578918457, 'loss_4': 0.25610867142677307, 'epoch': 11.06}
{'loss': 0.0396, 'grad_norm': 11.563329696655273, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.036310240626335144, 'loss_2': 0.00327301025390625, 'loss_3': -16.49081802368164, 'loss_4': 0.2526279091835022, 'epoch': 11.06}
{'loss': 0.0328, 'grad_norm': 8.706480979919434, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.022478865459561348, 'loss_2': 0.010284423828125, 'loss_3': -16.32569122314453, 'loss_4': 0.2564469873905182, 'epoch': 11.07}
{'loss': 0.0411, 'grad_norm': 10.179097175598145, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.030356399714946747, 'loss_2': 0.0106964111328125, 'loss_3': -16.60354995727539, 'loss_4': 0.2014579474925995, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 16:04:51,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:51,331 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:29<56:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:58,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028885971754789352, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.787, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.023234736174345016, 'eval_loss_2': 0.005651235580444336, 'eval_loss_3': -18.140748977661133, 'eval_loss_4': 0.0757521539926529, 'epoch': 11.08}
{'loss': 0.0285, 'grad_norm': 9.92125415802002, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.018865013495087624, 'loss_2': 0.0096588134765625, 'loss_3': -16.536663055419922, 'loss_4': 0.33726197481155396, 'epoch': 11.08}
{'loss': 0.0395, 'grad_norm': 14.423227310180664, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.038532987236976624, 'loss_2': 0.00095367431640625, 'loss_3': -16.22963523864746, 'loss_4': -0.001949012279510498, 'epoch': 11.09}
{'loss': 0.0135, 'grad_norm': 6.123757362365723, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.013419367372989655, 'loss_2': 9.584426879882812e-05, 'loss_3': -16.446550369262695, 'loss_4': -0.08133292198181152, 'epoch': 11.09}
{'loss': 0.0397, 'grad_norm': 13.84554386138916, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.038638800382614136, 'loss_2': 0.00110626220703125, 'loss_3': -16.633159637451172, 'loss_4': 0.06509779393672943, 'epoch': 11.1}
{'loss': 0.0907, 'grad_norm': 19.981048583984375, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.09045567363500595, 'loss_2': 0.0002865791320800781, 'loss_3': -16.394466400146484, 'loss_4': 0.1648937463760376, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 16:04:58,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:58,675 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:36<56:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:06,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024132832884788513, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01802973449230194, 'eval_loss_2': 0.006103098392486572, 'eval_loss_3': -18.151744842529297, 'eval_loss_4': 0.28727734088897705, 'epoch': 11.1}
{'loss': 0.0355, 'grad_norm': 12.764388084411621, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.030229683965444565, 'loss_2': 0.00525665283203125, 'loss_3': -16.23213005065918, 'loss_4': 0.10780169069766998, 'epoch': 11.11}
{'loss': 0.0194, 'grad_norm': 4.916031360626221, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.007353267632424831, 'loss_2': 0.0120086669921875, 'loss_3': -16.591777801513672, 'loss_4': 0.5329809188842773, 'epoch': 11.12}
{'loss': 0.0147, 'grad_norm': 5.861586570739746, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.010206406004726887, 'loss_2': 0.00449371337890625, 'loss_3': -16.350765228271484, 'loss_4': 0.6657463312149048, 'epoch': 11.12}
{'loss': 0.0227, 'grad_norm': 7.339474678039551, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.018287930637598038, 'loss_2': 0.00443267822265625, 'loss_3': -16.494670867919922, 'loss_4': 0.46630987524986267, 'epoch': 11.13}
{'loss': 0.0228, 'grad_norm': 5.903449058532715, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.013113540597259998, 'loss_2': 0.00970458984375, 'loss_3': -16.418760299682617, 'loss_4': 0.7305001020431519, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 16:05:06,030 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:06,031 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:44<56:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:13,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02549980953335762, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.021318335086107254, 'eval_loss_2': 0.004181474447250366, 'eval_loss_3': -18.17133140563965, 'eval_loss_4': 0.5022389888763428, 'epoch': 11.13}
{'loss': 0.021, 'grad_norm': 6.545505046844482, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.011636975221335888, 'loss_2': 0.00931549072265625, 'loss_3': -16.378925323486328, 'loss_4': 0.635305643081665, 'epoch': 11.14}
{'loss': 0.0421, 'grad_norm': 19.269289016723633, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.04161066561937332, 'loss_2': 0.00047135353088378906, 'loss_3': -16.371967315673828, 'loss_4': 0.7576680779457092, 'epoch': 11.15}
{'loss': 0.0134, 'grad_norm': 6.079302787780762, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.010121768340468407, 'loss_2': 0.0032749176025390625, 'loss_3': -16.561050415039062, 'loss_4': 0.7219661474227905, 'epoch': 11.15}
{'loss': 0.0147, 'grad_norm': 6.424039363861084, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.013286766596138477, 'loss_2': 0.0013713836669921875, 'loss_3': -16.4688663482666, 'loss_4': 0.7112898230552673, 'epoch': 11.16}
{'loss': 0.0124, 'grad_norm': 6.482173919677734, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.010275146923959255, 'loss_2': 0.0021686553955078125, 'loss_3': -16.338838577270508, 'loss_4': 0.8841555118560791, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 16:05:13,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:13,382 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:51<56:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:20,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02050701156258583, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01619577594101429, 'eval_loss_2': 0.004311233758926392, 'eval_loss_3': -18.222400665283203, 'eval_loss_4': 0.6885236501693726, 'epoch': 11.16}
{'loss': 0.0168, 'grad_norm': 6.458070278167725, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.011954818852245808, 'loss_2': 0.00481414794921875, 'loss_3': -16.563182830810547, 'loss_4': 0.8932508826255798, 'epoch': 11.17}
{'loss': 0.0142, 'grad_norm': 6.883563041687012, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.01413135789334774, 'loss_2': 5.1975250244140625e-05, 'loss_3': -16.629714965820312, 'loss_4': 1.190413475036621, 'epoch': 11.17}
{'loss': 0.0122, 'grad_norm': 6.306969165802002, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.010847021825611591, 'loss_2': 0.0013675689697265625, 'loss_3': -16.502883911132812, 'loss_4': 0.8982329964637756, 'epoch': 11.18}
{'loss': 0.0243, 'grad_norm': 11.48369312286377, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.019118783995509148, 'loss_2': 0.00518035888671875, 'loss_3': -16.42813491821289, 'loss_4': 0.8553252220153809, 'epoch': 11.19}
{'loss': 0.0112, 'grad_norm': 5.58337926864624, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.009795879013836384, 'loss_2': 0.0013942718505859375, 'loss_3': -16.56365966796875, 'loss_4': 1.3147629499435425, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 16:05:20,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:20,739 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [47:58<55:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:28,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015664882957935333, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.407, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011535384692251682, 'eval_loss_2': 0.004129499197006226, 'eval_loss_3': -18.238265991210938, 'eval_loss_4': 0.7567980289459229, 'epoch': 11.19}
{'loss': 0.0201, 'grad_norm': 5.89834451675415, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.014151736162602901, 'loss_2': 0.00591278076171875, 'loss_3': -16.422183990478516, 'loss_4': 1.037292718887329, 'epoch': 11.2}
{'loss': 0.0131, 'grad_norm': 6.0298237800598145, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.006651014089584351, 'loss_2': 0.00644683837890625, 'loss_3': -16.559202194213867, 'loss_4': 0.7741450667381287, 'epoch': 11.2}
{'loss': 0.0158, 'grad_norm': 6.169492244720459, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.008922189474105835, 'loss_2': 0.0069122314453125, 'loss_3': -16.41082763671875, 'loss_4': 1.1003046035766602, 'epoch': 11.21}
{'loss': 0.0075, 'grad_norm': 4.991665363311768, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.007254194468259811, 'loss_2': 0.00020432472229003906, 'loss_3': -16.684829711914062, 'loss_4': 0.8271178007125854, 'epoch': 11.22}
{'loss': 0.0118, 'grad_norm': 7.125655651092529, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.008220654912292957, 'loss_2': 0.0035572052001953125, 'loss_3': -16.549720764160156, 'loss_4': 0.8927152156829834, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 16:05:28,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:28,088 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [48:06<55:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:35,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013696359470486641, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.207, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010214845649898052, 'eval_loss_2': 0.0034815147519111633, 'eval_loss_3': -18.257173538208008, 'eval_loss_4': 0.8874523639678955, 'epoch': 11.22}
{'loss': 0.0156, 'grad_norm': 4.691903114318848, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.006850434932857752, 'loss_2': 0.0087890625, 'loss_3': -16.576194763183594, 'loss_4': 1.2261521816253662, 'epoch': 11.23}
{'loss': 0.0185, 'grad_norm': 5.673295497894287, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.013366381637752056, 'loss_2': 0.00514984130859375, 'loss_3': -16.585494995117188, 'loss_4': 0.9908740520477295, 'epoch': 11.23}
{'loss': 0.0207, 'grad_norm': 5.973670959472656, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.01434365939348936, 'loss_2': 0.00635528564453125, 'loss_3': -16.615266799926758, 'loss_4': 1.0914406776428223, 'epoch': 11.24}
{'loss': 0.0098, 'grad_norm': 4.827596187591553, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.0072507732547819614, 'loss_2': 0.002529144287109375, 'loss_3': -16.500017166137695, 'loss_4': 1.1632905006408691, 'epoch': 11.24}
{'loss': 0.0167, 'grad_norm': 6.392759799957275, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.012925566174089909, 'loss_2': 0.003814697265625, 'loss_3': -16.560434341430664, 'loss_4': 1.0486559867858887, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 16:05:35,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:35,444 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [48:13<55:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:42,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014499288983643055, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011467663571238518, 'eval_loss_2': 0.003031626343727112, 'eval_loss_3': -18.271818161010742, 'eval_loss_4': 1.0225437879562378, 'epoch': 11.25}
{'loss': 0.0234, 'grad_norm': 7.217070579528809, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.015518288128077984, 'loss_2': 0.007904052734375, 'loss_3': -16.612186431884766, 'loss_4': 1.6423041820526123, 'epoch': 11.26}
{'loss': 0.0198, 'grad_norm': 5.630610942840576, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.010212340392172337, 'loss_2': 0.00957489013671875, 'loss_3': -16.49976348876953, 'loss_4': 1.4618886709213257, 'epoch': 11.26}
{'loss': 0.0113, 'grad_norm': 5.840483665466309, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.011032044887542725, 'loss_2': 0.00022208690643310547, 'loss_3': -16.550189971923828, 'loss_4': 1.1342204809188843, 'epoch': 11.27}
{'loss': 0.0157, 'grad_norm': 5.879656791687012, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.012452382594347, 'loss_2': 0.00324249267578125, 'loss_3': -16.382850646972656, 'loss_4': 1.2436962127685547, 'epoch': 11.27}
{'loss': 0.0175, 'grad_norm': 5.704418659210205, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.013997155241668224, 'loss_2': 0.00345611572265625, 'loss_3': -16.578327178955078, 'loss_4': 1.471766471862793, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 16:05:42,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:42,801 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:21<55:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:50,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013568216934800148, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01002046000212431, 'eval_loss_2': 0.003547757863998413, 'eval_loss_3': -18.271074295043945, 'eval_loss_4': 0.9676605463027954, 'epoch': 11.28}
{'loss': 0.0191, 'grad_norm': 6.709773063659668, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.014812661334872246, 'loss_2': 0.0042877197265625, 'loss_3': -16.637252807617188, 'loss_4': 1.1127293109893799, 'epoch': 11.28}
{'loss': 0.0265, 'grad_norm': 11.952716827392578, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.021036546677350998, 'loss_2': 0.00542449951171875, 'loss_3': -16.796772003173828, 'loss_4': 1.157560110092163, 'epoch': 11.29}
{'loss': 0.0581, 'grad_norm': 15.025385856628418, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.04399839788675308, 'loss_2': 0.0141143798828125, 'loss_3': -16.433429718017578, 'loss_4': 1.4270257949829102, 'epoch': 11.3}
{'loss': 0.0577, 'grad_norm': 18.76498031616211, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.0518370196223259, 'loss_2': 0.005859375, 'loss_3': -16.524629592895508, 'loss_4': 0.7453566193580627, 'epoch': 11.3}
{'loss': 0.0202, 'grad_norm': 6.871010780334473, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.013352898880839348, 'loss_2': 0.0068359375, 'loss_3': -16.657777786254883, 'loss_4': 1.6524500846862793, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 16:05:50,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:50,160 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:28<55:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:57,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016552075743675232, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.501, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01014392077922821, 'eval_loss_2': 0.0064081549644470215, 'eval_loss_3': -18.278532028198242, 'eval_loss_4': 1.102473258972168, 'epoch': 11.31}
{'loss': 0.083, 'grad_norm': 12.573777198791504, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.07781774550676346, 'loss_2': 0.005146026611328125, 'loss_3': -16.665023803710938, 'loss_4': 1.6828128099441528, 'epoch': 11.31}
{'loss': 0.0138, 'grad_norm': 5.39792537689209, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.012867881916463375, 'loss_2': 0.0008912086486816406, 'loss_3': -16.671417236328125, 'loss_4': 1.219160556793213, 'epoch': 11.32}
{'loss': 0.0193, 'grad_norm': 7.083024501800537, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.01639259234070778, 'loss_2': 0.00295257568359375, 'loss_3': -16.530977249145508, 'loss_4': 1.4634979963302612, 'epoch': 11.33}
{'loss': 0.0241, 'grad_norm': 7.848745346069336, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.0196050014346838, 'loss_2': 0.004520416259765625, 'loss_3': -16.713138580322266, 'loss_4': 1.0397212505340576, 'epoch': 11.33}
{'loss': 0.0229, 'grad_norm': 10.022665023803711, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.020905304700136185, 'loss_2': 0.001979827880859375, 'loss_3': -16.710865020751953, 'loss_4': 1.3693674802780151, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 16:05:57,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:57,511 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:35<55:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:04,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011616921052336693, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008350704796612263, 'eval_loss_2': 0.0032662153244018555, 'eval_loss_3': -18.297388076782227, 'eval_loss_4': 1.1537541151046753, 'epoch': 11.34}
{'loss': 0.0641, 'grad_norm': 15.149538040161133, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.06186912581324577, 'loss_2': 0.002197265625, 'loss_3': -16.578561782836914, 'loss_4': 1.6798591613769531, 'epoch': 11.34}
{'loss': 0.0198, 'grad_norm': 7.695249080657959, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.016425922513008118, 'loss_2': 0.0034008026123046875, 'loss_3': -16.43906593322754, 'loss_4': 1.486506700515747, 'epoch': 11.35}
{'loss': 0.0087, 'grad_norm': 4.547228813171387, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.006958093028515577, 'loss_2': 0.001735687255859375, 'loss_3': -16.3432674407959, 'loss_4': 1.2780609130859375, 'epoch': 11.35}
{'loss': 0.006, 'grad_norm': 4.636028289794922, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.0055352384224534035, 'loss_2': 0.0004487037658691406, 'loss_3': -16.72136116027832, 'loss_4': 1.504558801651001, 'epoch': 11.36}
{'loss': 0.0167, 'grad_norm': 9.259994506835938, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.01588042825460434, 'loss_2': 0.0008020401000976562, 'loss_3': -16.603187561035156, 'loss_4': 1.712989330291748, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 16:06:04,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:04,861 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:43<55:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:12,210 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011958533897995949, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.444, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007639491464942694, 'eval_loss_2': 0.004319041967391968, 'eval_loss_3': -18.295352935791016, 'eval_loss_4': 1.1046171188354492, 'epoch': 11.37}
{'loss': 0.0156, 'grad_norm': 5.097874164581299, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.009689237922430038, 'loss_2': 0.0059356689453125, 'loss_3': -16.529502868652344, 'loss_4': 1.2083423137664795, 'epoch': 11.37}
{'loss': 0.0159, 'grad_norm': 5.5091681480407715, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.009808357805013657, 'loss_2': 0.0060882568359375, 'loss_3': -16.809343338012695, 'loss_4': 1.4940115213394165, 'epoch': 11.38}
{'loss': 0.0265, 'grad_norm': 8.779434204101562, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.02058800496160984, 'loss_2': 0.00595855712890625, 'loss_3': -16.532825469970703, 'loss_4': 1.5439627170562744, 'epoch': 11.38}
{'loss': 0.0119, 'grad_norm': 5.7459259033203125, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.009908860549330711, 'loss_2': 0.0019435882568359375, 'loss_3': -16.430438995361328, 'loss_4': 1.03896164894104, 'epoch': 11.39}
{'loss': 0.0165, 'grad_norm': 4.9976654052734375, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.004920750390738249, 'loss_2': 0.0115966796875, 'loss_3': -16.47203826904297, 'loss_4': 1.5938515663146973, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 16:06:12,210 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:12,210 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:50<55:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:19,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011069885455071926, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.513, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007977521978318691, 'eval_loss_2': 0.003092363476753235, 'eval_loss_3': -18.253585815429688, 'eval_loss_4': 0.9556830525398254, 'epoch': 11.4}
{'loss': 0.0131, 'grad_norm': 5.09963846206665, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.008299092762172222, 'loss_2': 0.004764556884765625, 'loss_3': -16.6239070892334, 'loss_4': 1.304548740386963, 'epoch': 11.4}
{'loss': 0.0139, 'grad_norm': 5.291901111602783, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.009315691888332367, 'loss_2': 0.00453948974609375, 'loss_3': -16.584918975830078, 'loss_4': 1.675543189048767, 'epoch': 11.41}
{'loss': 0.0214, 'grad_norm': 10.631827354431152, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.02078760787844658, 'loss_2': 0.0006508827209472656, 'loss_3': -16.53006935119629, 'loss_4': 1.40879487991333, 'epoch': 11.41}
{'loss': 0.0313, 'grad_norm': 9.07764720916748, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.02284407429397106, 'loss_2': 0.0084381103515625, 'loss_3': -16.658119201660156, 'loss_4': 1.2695637941360474, 'epoch': 11.42}
{'loss': 0.0216, 'grad_norm': 8.095331192016602, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.018306056037545204, 'loss_2': 0.003284454345703125, 'loss_3': -16.58818244934082, 'loss_4': 1.162564754486084, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 16:06:19,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:19,570 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:57<55:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:26,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012052185833454132, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.653, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0088809160515666, 'eval_loss_2': 0.0031712688505649567, 'eval_loss_3': -18.23670196533203, 'eval_loss_4': 0.759303629398346, 'epoch': 11.42}
{'loss': 0.011, 'grad_norm': 5.0384721755981445, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.00900518149137497, 'loss_2': 0.00197601318359375, 'loss_3': -16.51494026184082, 'loss_4': 0.8232830762863159, 'epoch': 11.43}
{'loss': 0.0119, 'grad_norm': 7.266323566436768, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.010866018943488598, 'loss_2': 0.0010128021240234375, 'loss_3': -16.705181121826172, 'loss_4': 1.0775632858276367, 'epoch': 11.44}
{'loss': 0.0122, 'grad_norm': 6.238754749298096, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.011037344112992287, 'loss_2': 0.0011138916015625, 'loss_3': -16.4392147064209, 'loss_4': 0.6941294074058533, 'epoch': 11.44}
{'loss': 0.0104, 'grad_norm': 5.856608867645264, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.008818448521196842, 'loss_2': 0.001628875732421875, 'loss_3': -16.330839157104492, 'loss_4': 0.7603420615196228, 'epoch': 11.45}
{'loss': 0.0331, 'grad_norm': 11.563782691955566, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.029567843303084373, 'loss_2': 0.003536224365234375, 'loss_3': -16.460105895996094, 'loss_4': 0.5568171739578247, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 16:06:26,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:26,945 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [49:05<55:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:34,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011875355616211891, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008557284250855446, 'eval_loss_2': 0.0033180713653564453, 'eval_loss_3': -18.217384338378906, 'eval_loss_4': 0.5855645537376404, 'epoch': 11.45}
{'loss': 0.0169, 'grad_norm': 6.896265506744385, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.01555659994482994, 'loss_2': 0.001361846923828125, 'loss_3': -16.539152145385742, 'loss_4': 1.2819148302078247, 'epoch': 11.46}
{'loss': 0.0175, 'grad_norm': 4.881707668304443, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.00578951695933938, 'loss_2': 0.01168060302734375, 'loss_3': -16.59271240234375, 'loss_4': 0.8123096227645874, 'epoch': 11.47}
{'loss': 0.0268, 'grad_norm': 7.353545665740967, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.014390859752893448, 'loss_2': 0.0124359130859375, 'loss_3': -16.29018211364746, 'loss_4': 0.17939302325248718, 'epoch': 11.47}
{'loss': 0.0243, 'grad_norm': 11.518712043762207, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.018897710368037224, 'loss_2': 0.0054168701171875, 'loss_3': -16.433578491210938, 'loss_4': 0.6900933980941772, 'epoch': 11.48}
{'loss': 0.0172, 'grad_norm': 5.2965521812438965, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.006984787527471781, 'loss_2': 0.0102386474609375, 'loss_3': -16.44679069519043, 'loss_4': 0.7567079663276672, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 16:06:34,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:34,299 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [49:12<55:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:41,649 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016813375055789948, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.641, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009559253230690956, 'eval_loss_2': 0.007254123687744141, 'eval_loss_3': -18.178823471069336, 'eval_loss_4': 0.5263150930404663, 'epoch': 11.48}
{'loss': 0.0208, 'grad_norm': 10.943461418151855, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.01460628118366003, 'loss_2': 0.00618743896484375, 'loss_3': -16.432308197021484, 'loss_4': 0.9184306263923645, 'epoch': 11.49}
{'loss': 0.0148, 'grad_norm': 7.535327434539795, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.010170409455895424, 'loss_2': 0.00463104248046875, 'loss_3': -16.481048583984375, 'loss_4': 1.0703420639038086, 'epoch': 11.49}
{'loss': 0.0224, 'grad_norm': 9.843497276306152, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.01915586367249489, 'loss_2': 0.0032863616943359375, 'loss_3': -16.32392120361328, 'loss_4': 0.7119040489196777, 'epoch': 11.5}
{'loss': 0.0255, 'grad_norm': 7.432403564453125, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.015713756904006004, 'loss_2': 0.0097808837890625, 'loss_3': -16.45087242126465, 'loss_4': 0.926572859287262, 'epoch': 11.51}
{'loss': 0.0098, 'grad_norm': 4.573562145233154, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.006465248763561249, 'loss_2': 0.003292083740234375, 'loss_3': -16.525291442871094, 'loss_4': 1.1885987520217896, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 16:06:41,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:41,649 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:19<54:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:48,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012401802465319633, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00929850060492754, 'eval_loss_2': 0.003103300929069519, 'eval_loss_3': -18.164474487304688, 'eval_loss_4': 0.6660411953926086, 'epoch': 11.51}
{'loss': 0.0154, 'grad_norm': 5.83956241607666, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.011804618872702122, 'loss_2': 0.00356292724609375, 'loss_3': -16.525653839111328, 'loss_4': 1.226592779159546, 'epoch': 11.52}
{'loss': 0.02, 'grad_norm': 12.468443870544434, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.017826151102781296, 'loss_2': 0.0021991729736328125, 'loss_3': -16.36944007873535, 'loss_4': 0.6717807650566101, 'epoch': 11.52}
{'loss': 0.0208, 'grad_norm': 6.022704124450684, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.012225345708429813, 'loss_2': 0.008575439453125, 'loss_3': -16.512847900390625, 'loss_4': 0.9928995966911316, 'epoch': 11.53}
{'loss': 0.0126, 'grad_norm': 4.65217399597168, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.008684448897838593, 'loss_2': 0.003940582275390625, 'loss_3': -16.38018035888672, 'loss_4': 0.8846845626831055, 'epoch': 11.53}
{'loss': 0.0173, 'grad_norm': 7.979877471923828, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.012306624092161655, 'loss_2': 0.004970550537109375, 'loss_3': -16.309724807739258, 'loss_4': 0.48032844066619873, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 16:06:48,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:48,994 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:27<54:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:56,345 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021353567019104958, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.507, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013989977538585663, 'eval_loss_2': 0.0073635876178741455, 'eval_loss_3': -18.133180618286133, 'eval_loss_4': 0.7574640512466431, 'epoch': 11.54}
{'loss': 0.0133, 'grad_norm': 5.8813252449035645, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.0125393345952034, 'loss_2': 0.0007801055908203125, 'loss_3': -16.43308448791504, 'loss_4': 0.863573431968689, 'epoch': 11.55}
{'loss': 0.0257, 'grad_norm': 8.099337577819824, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.01609751395881176, 'loss_2': 0.0096282958984375, 'loss_3': -16.387035369873047, 'loss_4': 1.019080400466919, 'epoch': 11.55}
{'loss': 0.0141, 'grad_norm': 4.944050312042236, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.008094682358205318, 'loss_2': 0.00605010986328125, 'loss_3': -16.495637893676758, 'loss_4': 0.9008650779724121, 'epoch': 11.56}
{'loss': 0.0082, 'grad_norm': 4.90563440322876, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.005953012965619564, 'loss_2': 0.00228118896484375, 'loss_3': -16.599660873413086, 'loss_4': 0.9149764776229858, 'epoch': 11.56}
{'loss': 0.02, 'grad_norm': 5.430993556976318, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.011756336316466331, 'loss_2': 0.0082244873046875, 'loss_3': -16.383922576904297, 'loss_4': 0.6324748396873474, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 16:06:56,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:56,345 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:34<54:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:03,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02333081141114235, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.019222186878323555, 'eval_loss_2': 0.004108622670173645, 'eval_loss_3': -18.14481544494629, 'eval_loss_4': 0.5634825825691223, 'epoch': 11.57}
{'loss': 0.0137, 'grad_norm': 7.664414405822754, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.010496504604816437, 'loss_2': 0.003154754638671875, 'loss_3': -16.43891716003418, 'loss_4': 0.8706509470939636, 'epoch': 11.58}
{'loss': 0.0154, 'grad_norm': 4.83502721786499, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.009384026750922203, 'loss_2': 0.0059661865234375, 'loss_3': -16.325037002563477, 'loss_4': 1.1162086725234985, 'epoch': 11.58}
{'loss': 0.0195, 'grad_norm': 6.9309773445129395, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.016092389822006226, 'loss_2': 0.003452301025390625, 'loss_3': -16.562904357910156, 'loss_4': 0.5872611403465271, 'epoch': 11.59}
{'loss': 0.0308, 'grad_norm': 10.116333961486816, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.022885749116539955, 'loss_2': 0.00789642333984375, 'loss_3': -16.455684661865234, 'loss_4': 0.535921037197113, 'epoch': 11.59}
{'loss': 0.0245, 'grad_norm': 6.544071674346924, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.012013235129415989, 'loss_2': 0.0124969482421875, 'loss_3': -16.274471282958984, 'loss_4': 0.4410111606121063, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 16:07:03,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:03,707 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:41<54:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:11,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0250021293759346, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.123, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.017928848043084145, 'eval_loss_2': 0.0070732831954956055, 'eval_loss_3': -18.154197692871094, 'eval_loss_4': 0.17161555588245392, 'epoch': 11.6}
{'loss': 0.0139, 'grad_norm': 6.79916524887085, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.013786151073873043, 'loss_2': 0.0001475811004638672, 'loss_3': -16.448190689086914, 'loss_4': 0.4731099009513855, 'epoch': 11.6}
{'loss': 0.0233, 'grad_norm': 7.346707344055176, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.013014204800128937, 'loss_2': 0.01025390625, 'loss_3': -16.673139572143555, 'loss_4': 0.1395542323589325, 'epoch': 11.61}
{'loss': 0.0609, 'grad_norm': 26.985279083251953, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.04649972543120384, 'loss_2': 0.01444244384765625, 'loss_3': -16.543167114257812, 'loss_4': 0.029831387102603912, 'epoch': 11.62}
{'loss': 0.0203, 'grad_norm': 6.017592906951904, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.009523320943117142, 'loss_2': 0.01079559326171875, 'loss_3': -16.39065170288086, 'loss_4': 0.3506739139556885, 'epoch': 11.62}
{'loss': 0.0251, 'grad_norm': 6.941567420959473, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.014450179412961006, 'loss_2': 0.0106353759765625, 'loss_3': -16.528949737548828, 'loss_4': 0.4351949393749237, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 16:07:11,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:11,064 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:49<54:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:18,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02267838455736637, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013345250859856606, 'eval_loss_2': 0.009333133697509766, 'eval_loss_3': -18.174945831298828, 'eval_loss_4': -0.08985109627246857, 'epoch': 11.63}
{'loss': 0.0259, 'grad_norm': 7.360321044921875, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.01623798906803131, 'loss_2': 0.0096282958984375, 'loss_3': -16.375375747680664, 'loss_4': 0.05520227551460266, 'epoch': 11.63}
{'loss': 0.0244, 'grad_norm': 15.290492057800293, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.024267366155982018, 'loss_2': 0.00015425682067871094, 'loss_3': -16.46823501586914, 'loss_4': 0.4663003087043762, 'epoch': 11.64}
{'loss': 0.0132, 'grad_norm': 5.607387542724609, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.010641170665621758, 'loss_2': 0.002605438232421875, 'loss_3': -16.692520141601562, 'loss_4': 0.4127470850944519, 'epoch': 11.65}
{'loss': 0.0201, 'grad_norm': 7.854002952575684, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.01930093951523304, 'loss_2': 0.000797271728515625, 'loss_3': -16.450836181640625, 'loss_4': -0.1402854174375534, 'epoch': 11.65}
{'loss': 0.0113, 'grad_norm': 6.055781841278076, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.010997727513313293, 'loss_2': 0.00026035308837890625, 'loss_3': -16.59380531311035, 'loss_4': 0.04217018187046051, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 16:07:18,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:18,417 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:56<54:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:25,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013243215158581734, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.41, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009951906278729439, 'eval_loss_2': 0.003291308879852295, 'eval_loss_3': -18.244625091552734, 'eval_loss_4': -0.33130428194999695, 'epoch': 11.66}
{'loss': 0.0135, 'grad_norm': 6.9697184562683105, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.01209509838372469, 'loss_2': 0.0013818740844726562, 'loss_3': -16.738759994506836, 'loss_4': -0.10632649809122086, 'epoch': 11.66}
{'loss': 0.0182, 'grad_norm': 5.547726631164551, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.01198579091578722, 'loss_2': 0.00616455078125, 'loss_3': -16.667041778564453, 'loss_4': 0.13034749031066895, 'epoch': 11.67}
{'loss': 0.0154, 'grad_norm': 6.41942024230957, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.01332783605903387, 'loss_2': 0.0020751953125, 'loss_3': -16.552213668823242, 'loss_4': 0.19489502906799316, 'epoch': 11.67}
{'loss': 0.0179, 'grad_norm': 7.960681438446045, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.017491159960627556, 'loss_2': 0.0003733634948730469, 'loss_3': -16.658294677734375, 'loss_4': -0.17853152751922607, 'epoch': 11.68}
{'loss': 0.024, 'grad_norm': 7.699210166931152, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.018182775005698204, 'loss_2': 0.005859375, 'loss_3': -16.636817932128906, 'loss_4': -0.25931432843208313, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 16:07:25,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:25,768 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [50:04<55:06,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:07:33,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015062965452671051, 'eval_runtime': 3.9815, 'eval_samples_per_second': 257.188, 'eval_steps_per_second': 4.019, 'eval_loss_1': 0.009656853042542934, 'eval_loss_2': 0.005406111478805542, 'eval_loss_3': -18.271665573120117, 'eval_loss_4': -0.5327610373497009, 'epoch': 11.69}
{'loss': 0.0458, 'grad_norm': 23.8942928314209, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.040270525962114334, 'loss_2': 0.00557708740234375, 'loss_3': -16.41221046447754, 'loss_4': -0.03871127963066101, 'epoch': 11.69}
{'loss': 0.0713, 'grad_norm': 20.479984283447266, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.06216639652848244, 'loss_2': 0.00909423828125, 'loss_3': -16.413021087646484, 'loss_4': -0.1275862455368042, 'epoch': 11.7}
{'loss': 0.0281, 'grad_norm': 7.187914848327637, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.019584836438298225, 'loss_2': 0.0084991455078125, 'loss_3': -16.272354125976562, 'loss_4': -0.2312747836112976, 'epoch': 11.7}
{'loss': 0.0242, 'grad_norm': 6.565718173980713, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.018111318349838257, 'loss_2': 0.00604248046875, 'loss_3': -16.73796844482422, 'loss_4': -0.08983436971902847, 'epoch': 11.71}
{'loss': 0.0165, 'grad_norm': 5.017922878265381, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.014439509250223637, 'loss_2': 0.002105712890625, 'loss_3': -16.447338104248047, 'loss_4': -0.1309291422367096, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 16:07:33,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:33,297 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [50:11<54:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:40,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012849151156842709, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009859173558652401, 'eval_loss_2': 0.0029899775981903076, 'eval_loss_3': -18.309253692626953, 'eval_loss_4': -0.4627910256385803, 'epoch': 11.72}
{'loss': 0.0246, 'grad_norm': 8.720853805541992, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.018043704330921173, 'loss_2': 0.006565093994140625, 'loss_3': -16.45924949645996, 'loss_4': -0.34152811765670776, 'epoch': 11.72}
{'loss': 0.0242, 'grad_norm': 8.931035041809082, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.020075561478734016, 'loss_2': 0.00417327880859375, 'loss_3': -16.526350021362305, 'loss_4': 0.10751603543758392, 'epoch': 11.73}
{'loss': 0.0406, 'grad_norm': 14.776971817016602, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.035994865000247955, 'loss_2': 0.004642486572265625, 'loss_3': -16.502235412597656, 'loss_4': 0.26899540424346924, 'epoch': 11.73}
{'loss': 0.0309, 'grad_norm': 13.040648460388184, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.027914881706237793, 'loss_2': 0.003025054931640625, 'loss_3': -16.540637969970703, 'loss_4': 0.216401606798172, 'epoch': 11.74}
{'loss': 0.0221, 'grad_norm': 10.825645446777344, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.019273925572633743, 'loss_2': 0.00283050537109375, 'loss_3': -16.396167755126953, 'loss_4': 0.12073244154453278, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 16:07:40,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:40,648 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:18<54:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:48,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013338560238480568, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00929094199091196, 'eval_loss_2': 0.004047617316246033, 'eval_loss_3': -18.27395248413086, 'eval_loss_4': -0.4947107136249542, 'epoch': 11.74}
{'loss': 0.0178, 'grad_norm': 7.053716659545898, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.01558646745979786, 'loss_2': 0.00220489501953125, 'loss_3': -16.82978630065918, 'loss_4': 0.3353685140609741, 'epoch': 11.75}
{'loss': 0.0294, 'grad_norm': 17.95049476623535, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.025472300127148628, 'loss_2': 0.0038928985595703125, 'loss_3': -16.681682586669922, 'loss_4': -0.1049172431230545, 'epoch': 11.76}
{'loss': 0.0132, 'grad_norm': 5.668692111968994, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.012198327109217644, 'loss_2': 0.001010894775390625, 'loss_3': -16.566465377807617, 'loss_4': -0.4264785051345825, 'epoch': 11.76}
{'loss': 0.0326, 'grad_norm': 12.430099487304688, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.02567002922296524, 'loss_2': 0.006954193115234375, 'loss_3': -16.642797470092773, 'loss_4': -0.19638755917549133, 'epoch': 11.77}
{'loss': 0.0173, 'grad_norm': 6.838992118835449, 'learning_rate': 1.825e-05, 'loss_1': 0.012967630289494991, 'loss_2': 0.004329681396484375, 'loss_3': -16.412193298339844, 'loss_4': -0.04360521212220192, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 16:07:48,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:48,010 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:26<54:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:55,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014422189444303513, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.353, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009897659532725811, 'eval_loss_2': 0.004524528980255127, 'eval_loss_3': -18.19808578491211, 'eval_loss_4': -0.4057960510253906, 'epoch': 11.77}
{'loss': 0.0371, 'grad_norm': 13.352265357971191, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.030864249914884567, 'loss_2': 0.006256103515625, 'loss_3': -16.40921401977539, 'loss_4': 0.06035156548023224, 'epoch': 11.78}
{'loss': 0.0452, 'grad_norm': 14.510754585266113, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.03725983202457428, 'loss_2': 0.0079803466796875, 'loss_3': -16.40213394165039, 'loss_4': -0.10426858067512512, 'epoch': 11.78}
{'loss': 0.0137, 'grad_norm': 6.046359539031982, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.008600084111094475, 'loss_2': 0.005126953125, 'loss_3': -16.44167709350586, 'loss_4': 0.31229400634765625, 'epoch': 11.79}
{'loss': 0.0371, 'grad_norm': 15.411287307739258, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.030405007302761078, 'loss_2': 0.0066680908203125, 'loss_3': -16.34157943725586, 'loss_4': -0.002832788974046707, 'epoch': 11.8}
{'loss': 0.0158, 'grad_norm': 5.972390651702881, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.013515664264559746, 'loss_2': 0.00226593017578125, 'loss_3': -16.343379974365234, 'loss_4': 0.17407865822315216, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 16:07:55,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:55,374 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:33<54:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:02,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01888350024819374, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015535008162260056, 'eval_loss_2': 0.0033484920859336853, 'eval_loss_3': -18.10906219482422, 'eval_loss_4': -0.12844301760196686, 'epoch': 11.8}
{'loss': 0.0152, 'grad_norm': 4.8189849853515625, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.010633425787091255, 'loss_2': 0.00455474853515625, 'loss_3': -16.54726791381836, 'loss_4': -0.018903933465480804, 'epoch': 11.81}
{'loss': 0.0228, 'grad_norm': 8.030562400817871, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.01901865005493164, 'loss_2': 0.0037994384765625, 'loss_3': -16.366554260253906, 'loss_4': 0.2834537625312805, 'epoch': 11.81}
{'loss': 0.0712, 'grad_norm': 27.621265411376953, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.066706083714962, 'loss_2': 0.00446319580078125, 'loss_3': -16.203121185302734, 'loss_4': 0.5500912666320801, 'epoch': 11.82}
{'loss': 0.0158, 'grad_norm': 6.621287822723389, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.014150870963931084, 'loss_2': 0.001605987548828125, 'loss_3': -16.287948608398438, 'loss_4': 0.13904859125614166, 'epoch': 11.83}
{'loss': 0.0124, 'grad_norm': 5.37558126449585, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.007826818153262138, 'loss_2': 0.00452423095703125, 'loss_3': -16.47644805908203, 'loss_4': 0.026141971349716187, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 16:08:02,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:02,729 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:40<54:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:10,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03308027237653732, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.029509015381336212, 'eval_loss_2': 0.003571256995201111, 'eval_loss_3': -18.04599380493164, 'eval_loss_4': 0.19394555687904358, 'epoch': 11.83}
{'loss': 0.0276, 'grad_norm': 6.71120023727417, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.01999577321112156, 'loss_2': 0.00765228271484375, 'loss_3': -16.283348083496094, 'loss_4': 0.2602936625480652, 'epoch': 11.84}
{'loss': 0.0486, 'grad_norm': 34.51408767700195, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.04018130153417587, 'loss_2': 0.00839996337890625, 'loss_3': -16.20519256591797, 'loss_4': 0.2532011866569519, 'epoch': 11.84}
{'loss': 0.0142, 'grad_norm': 5.164882183074951, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.010284020565450191, 'loss_2': 0.00391387939453125, 'loss_3': -16.300539016723633, 'loss_4': 0.6534878015518188, 'epoch': 11.85}
{'loss': 0.0256, 'grad_norm': 17.936914443969727, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.02452489361166954, 'loss_2': 0.0010318756103515625, 'loss_3': -16.328758239746094, 'loss_4': 0.2681681513786316, 'epoch': 11.85}
{'loss': 0.0194, 'grad_norm': 8.723504066467285, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.017709720879793167, 'loss_2': 0.001651763916015625, 'loss_3': -16.565807342529297, 'loss_4': 0.2529740333557129, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 16:08:10,080 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:10,080 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:48<53:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:17,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015225455164909363, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.284, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011480927467346191, 'eval_loss_2': 0.0037445276975631714, 'eval_loss_3': -18.08888053894043, 'eval_loss_4': 0.26693612337112427, 'epoch': 11.86}
{'loss': 0.0093, 'grad_norm': 4.749760627746582, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.006501912605017424, 'loss_2': 0.00284576416015625, 'loss_3': -16.37713050842285, 'loss_4': 0.36005035042762756, 'epoch': 11.87}
{'loss': 0.009, 'grad_norm': 5.3822102546691895, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.0066187758930027485, 'loss_2': 0.0023555755615234375, 'loss_3': -16.50983428955078, 'loss_4': 0.571745753288269, 'epoch': 11.87}
{'loss': 0.0098, 'grad_norm': 5.102433204650879, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.006525672972202301, 'loss_2': 0.00325775146484375, 'loss_3': -16.265869140625, 'loss_4': 0.23973128199577332, 'epoch': 11.88}
{'loss': 0.0259, 'grad_norm': 4.6254682540893555, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.009505019523203373, 'loss_2': 0.016387939453125, 'loss_3': -16.24191665649414, 'loss_4': 0.6170153021812439, 'epoch': 11.88}
{'loss': 0.0172, 'grad_norm': 7.378263473510742, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.007765856105834246, 'loss_2': 0.009429931640625, 'loss_3': -16.358299255371094, 'loss_4': 0.6168702840805054, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 16:08:17,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:17,434 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:55<53:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:24,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01232907921075821, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0072880759835243225, 'eval_loss_2': 0.005041003227233887, 'eval_loss_3': -18.1566162109375, 'eval_loss_4': 0.30336758494377136, 'epoch': 11.89}
{'loss': 0.0264, 'grad_norm': 8.783585548400879, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.01926918886601925, 'loss_2': 0.007106781005859375, 'loss_3': -16.337779998779297, 'loss_4': 0.10582610964775085, 'epoch': 11.9}
{'loss': 0.0102, 'grad_norm': 5.130438804626465, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.0058271861635148525, 'loss_2': 0.00439453125, 'loss_3': -16.428197860717773, 'loss_4': 0.7829509973526001, 'epoch': 11.9}
{'loss': 0.0122, 'grad_norm': 6.742763519287109, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.009855157695710659, 'loss_2': 0.00229644775390625, 'loss_3': -16.51276397705078, 'loss_4': 0.7533063888549805, 'epoch': 11.91}
{'loss': 0.0106, 'grad_norm': 5.202199459075928, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.010556256398558617, 'loss_2': 4.7206878662109375e-05, 'loss_3': -16.225173950195312, 'loss_4': 0.7990375757217407, 'epoch': 11.91}
{'loss': 0.0311, 'grad_norm': 11.007518768310547, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.018327727913856506, 'loss_2': 0.0128021240234375, 'loss_3': -16.526260375976562, 'loss_4': 0.5765376091003418, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 16:08:24,796 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:24,796 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [51:03<53:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:32,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014071065001189709, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009232732467353344, 'eval_loss_2': 0.004838332533836365, 'eval_loss_3': -18.177278518676758, 'eval_loss_4': 0.5238015055656433, 'epoch': 11.92}
{'loss': 0.0351, 'grad_norm': 15.868244171142578, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.027177980169653893, 'loss_2': 0.00794219970703125, 'loss_3': -16.477209091186523, 'loss_4': 1.087160587310791, 'epoch': 11.92}
{'loss': 0.0456, 'grad_norm': 19.74503517150879, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.039444003254175186, 'loss_2': 0.006160736083984375, 'loss_3': -16.44625473022461, 'loss_4': 0.9707285165786743, 'epoch': 11.93}
{'loss': 0.0199, 'grad_norm': 5.067101955413818, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.00846164021641016, 'loss_2': 0.01142120361328125, 'loss_3': -16.272174835205078, 'loss_4': 0.5427190065383911, 'epoch': 11.94}
{'loss': 0.0169, 'grad_norm': 9.843242645263672, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.014373373240232468, 'loss_2': 0.002506256103515625, 'loss_3': -16.374446868896484, 'loss_4': 1.1345583200454712, 'epoch': 11.94}
{'loss': 0.0203, 'grad_norm': 10.763713836669922, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.01648511365056038, 'loss_2': 0.003833770751953125, 'loss_3': -16.33687973022461, 'loss_4': 0.7919217944145203, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 16:08:32,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:32,161 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [51:10<53:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:39,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015613459050655365, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009875589050352573, 'eval_loss_2': 0.005737870931625366, 'eval_loss_3': -18.157520294189453, 'eval_loss_4': 0.37335914373397827, 'epoch': 11.95}
{'loss': 0.0161, 'grad_norm': 6.113216876983643, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.011515442281961441, 'loss_2': 0.00457000732421875, 'loss_3': -16.394315719604492, 'loss_4': 0.6007413864135742, 'epoch': 11.95}
{'loss': 0.0166, 'grad_norm': 7.356021881103516, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.014124944806098938, 'loss_2': 0.002429962158203125, 'loss_3': -16.347156524658203, 'loss_4': 0.2958071827888489, 'epoch': 11.96}
{'loss': 0.0155, 'grad_norm': 5.088753700256348, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.007900719530880451, 'loss_2': 0.0075836181640625, 'loss_3': -16.356922149658203, 'loss_4': 0.9072613716125488, 'epoch': 11.97}
{'loss': 0.0112, 'grad_norm': 6.976413726806641, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.010993885807693005, 'loss_2': 0.00022971630096435547, 'loss_3': -16.16103744506836, 'loss_4': -0.17730587720870972, 'epoch': 11.97}
{'loss': 0.0113, 'grad_norm': 6.846307277679443, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.01103221531957388, 'loss_2': 0.0002467632293701172, 'loss_3': -16.32347869873047, 'loss_4': 0.08602321892976761, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 16:08:39,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:39,518 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:17<50:29,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:08:46,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012268844991922379, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009458755142986774, 'eval_loss_2': 0.0028100907802581787, 'eval_loss_3': -18.149831771850586, 'eval_loss_4': 0.1952105313539505, 'epoch': 11.98}
{'loss': 0.082, 'grad_norm': 30.086467742919922, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.0735500156879425, 'loss_2': 0.00841522216796875, 'loss_3': -16.28457260131836, 'loss_4': 0.6645088195800781, 'epoch': 11.98}
{'loss': 0.0129, 'grad_norm': 4.848084926605225, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.010791649110615253, 'loss_2': 0.0020751953125, 'loss_3': -16.255664825439453, 'loss_4': 0.2876640558242798, 'epoch': 11.99}
{'loss': 0.0359, 'grad_norm': 13.336455345153809, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.03159795701503754, 'loss_2': 0.00434112548828125, 'loss_3': -16.320907592773438, 'loss_4': 0.2207029163837433, 'epoch': 11.99}
{'loss': 0.0177, 'grad_norm': 10.065709114074707, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.012380624189972878, 'loss_2': 0.00531005859375, 'loss_3': -16.094541549682617, 'loss_4': 0.3464090824127197, 'epoch': 12.0}
{'loss': 0.1003, 'grad_norm': 28.351634979248047, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.09366937726736069, 'loss_2': 0.00666046142578125, 'loss_3': -16.57623291015625, 'loss_4': 0.3960030674934387, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 16:08:46,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:46,559 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:24<52:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:08:53,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013540640473365784, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009630070067942142, 'eval_loss_2': 0.003910571336746216, 'eval_loss_3': -18.17595100402832, 'eval_loss_4': 0.1622636914253235, 'epoch': 12.01}
{'loss': 0.0231, 'grad_norm': 9.074013710021973, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.01640458032488823, 'loss_2': 0.00665283203125, 'loss_3': -16.31158447265625, 'loss_4': 0.3531343936920166, 'epoch': 12.01}
{'loss': 0.0165, 'grad_norm': 9.699742317199707, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.014193987473845482, 'loss_2': 0.002277374267578125, 'loss_3': -16.18832778930664, 'loss_4': 0.33275720477104187, 'epoch': 12.02}
{'loss': 0.0102, 'grad_norm': 5.325955867767334, 'learning_rate': 1.8e-05, 'loss_1': 0.00842603761702776, 'loss_2': 0.001758575439453125, 'loss_3': -16.130725860595703, 'loss_4': 0.0928284153342247, 'epoch': 12.02}
{'loss': 0.04, 'grad_norm': 19.73283576965332, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.036436572670936584, 'loss_2': 0.003559112548828125, 'loss_3': -16.183622360229492, 'loss_4': -0.0355742871761322, 'epoch': 12.03}
{'loss': 0.0164, 'grad_norm': 6.56571102142334, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.015567509457468987, 'loss_2': 0.000850677490234375, 'loss_3': -16.260629653930664, 'loss_4': 0.19178877770900726, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 16:08:53,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:53,908 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:32<53:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:01,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012039320543408394, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008418607525527477, 'eval_loss_2': 0.003620713949203491, 'eval_loss_3': -18.18472671508789, 'eval_loss_4': 0.10168515890836716, 'epoch': 12.03}
{'loss': 0.0096, 'grad_norm': 6.024860858917236, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.00827497337013483, 'loss_2': 0.0013685226440429688, 'loss_3': -16.479755401611328, 'loss_4': 0.27331608533859253, 'epoch': 12.04}
{'loss': 0.0132, 'grad_norm': 5.766798496246338, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.006574657279998064, 'loss_2': 0.006580352783203125, 'loss_3': -16.416851043701172, 'loss_4': -0.17918351292610168, 'epoch': 12.05}
{'loss': 0.0262, 'grad_norm': 14.155466079711914, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.019073698669672012, 'loss_2': 0.0071563720703125, 'loss_3': -16.170974731445312, 'loss_4': 0.24896925687789917, 'epoch': 12.05}
{'loss': 0.031, 'grad_norm': 10.149972915649414, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.021622663363814354, 'loss_2': 0.0094146728515625, 'loss_3': -16.578123092651367, 'loss_4': -0.09521480649709702, 'epoch': 12.06}
{'loss': 0.0093, 'grad_norm': 5.695985317230225, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.008700046688318253, 'loss_2': 0.00064849853515625, 'loss_3': -16.592151641845703, 'loss_4': 0.0697130411863327, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 16:09:01,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:01,265 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:39<53:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:08,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017982520163059235, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.767, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00915149413049221, 'eval_loss_2': 0.008831024169921875, 'eval_loss_3': -18.176067352294922, 'eval_loss_4': -0.10740543901920319, 'epoch': 12.06}
{'loss': 0.0143, 'grad_norm': 5.2530670166015625, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.007714285049587488, 'loss_2': 0.006561279296875, 'loss_3': -16.298158645629883, 'loss_4': -0.0629468634724617, 'epoch': 12.07}
{'loss': 0.022, 'grad_norm': 6.081957817077637, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.013902008533477783, 'loss_2': 0.00807952880859375, 'loss_3': -16.493839263916016, 'loss_4': -0.3623332381248474, 'epoch': 12.08}
{'loss': 0.0227, 'grad_norm': 17.38511848449707, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.022654395550489426, 'loss_2': 7.647275924682617e-05, 'loss_3': -16.4080867767334, 'loss_4': -0.04870270937681198, 'epoch': 12.08}
{'loss': 0.0235, 'grad_norm': 7.3380866050720215, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.01783234067261219, 'loss_2': 0.005649566650390625, 'loss_3': -16.059968948364258, 'loss_4': 0.15157486498355865, 'epoch': 12.09}
{'loss': 0.03, 'grad_norm': 7.199117183685303, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.018816683441400528, 'loss_2': 0.0112152099609375, 'loss_3': -16.60189437866211, 'loss_4': -0.3095555305480957, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 16:09:08,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:08,629 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:46<53:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:15,977 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01295168325304985, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.537, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00972812157124281, 'eval_loss_2': 0.0032235607504844666, 'eval_loss_3': -18.170307159423828, 'eval_loss_4': -0.11489105224609375, 'epoch': 12.09}
{'loss': 0.0194, 'grad_norm': 6.143345355987549, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.014677152037620544, 'loss_2': 0.00469207763671875, 'loss_3': -16.168720245361328, 'loss_4': -0.11614865064620972, 'epoch': 12.1}
{'loss': 0.015, 'grad_norm': 5.860649585723877, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.01229509525001049, 'loss_2': 0.0027294158935546875, 'loss_3': -16.503999710083008, 'loss_4': 0.09510751068592072, 'epoch': 12.1}
{'loss': 0.0204, 'grad_norm': 5.244288444519043, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.01628461293876171, 'loss_2': 0.00411224365234375, 'loss_3': -16.34832191467285, 'loss_4': -0.41040515899658203, 'epoch': 12.11}
{'loss': 0.0118, 'grad_norm': 5.009228706359863, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.008262386545538902, 'loss_2': 0.003505706787109375, 'loss_3': -16.5239200592041, 'loss_4': -0.13378772139549255, 'epoch': 12.12}
{'loss': 0.025, 'grad_norm': 12.29427433013916, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.024343207478523254, 'loss_2': 0.00069427490234375, 'loss_3': -16.227787017822266, 'loss_4': -0.112388476729393, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 16:09:15,977 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:15,977 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:54<53:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:23,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019318565726280212, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011267111636698246, 'eval_loss_2': 0.008051455020904541, 'eval_loss_3': -18.145172119140625, 'eval_loss_4': 0.003155522746965289, 'epoch': 12.12}
{'loss': 0.0269, 'grad_norm': 9.392754554748535, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.021260766312479973, 'loss_2': 0.00559234619140625, 'loss_3': -16.502910614013672, 'loss_4': -0.44561776518821716, 'epoch': 12.13}
{'loss': 0.024, 'grad_norm': 6.494368076324463, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.014300416223704815, 'loss_2': 0.00968170166015625, 'loss_3': -16.34972381591797, 'loss_4': -0.6309270858764648, 'epoch': 12.13}
{'loss': 0.0176, 'grad_norm': 5.826139450073242, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.008442861959338188, 'loss_2': 0.009185791015625, 'loss_3': -16.477527618408203, 'loss_4': -0.01264619454741478, 'epoch': 12.14}
{'loss': 0.0228, 'grad_norm': 5.494699001312256, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.008489159867167473, 'loss_2': 0.01433563232421875, 'loss_3': -16.29963493347168, 'loss_4': 0.19062361121177673, 'epoch': 12.15}
{'loss': 0.0183, 'grad_norm': 12.230180740356445, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.01005967240780592, 'loss_2': 0.00824737548828125, 'loss_3': -16.028879165649414, 'loss_4': 0.06493893265724182, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 16:09:23,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:23,322 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [52:01<53:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:30,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02095700055360794, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.501, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011105901561677456, 'eval_loss_2': 0.00985109806060791, 'eval_loss_3': -18.1291446685791, 'eval_loss_4': 0.23994241654872894, 'epoch': 12.15}
{'loss': 0.0328, 'grad_norm': 9.779728889465332, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.027629848569631577, 'loss_2': 0.0052032470703125, 'loss_3': -16.46526336669922, 'loss_4': 0.11934389173984528, 'epoch': 12.16}
{'loss': 0.0222, 'grad_norm': 7.312464237213135, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.013551875948905945, 'loss_2': 0.0086212158203125, 'loss_3': -16.504880905151367, 'loss_4': 0.27534955739974976, 'epoch': 12.16}
{'loss': 0.0224, 'grad_norm': 8.729190826416016, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.01524454914033413, 'loss_2': 0.0071258544921875, 'loss_3': -16.218463897705078, 'loss_4': -0.007440797984600067, 'epoch': 12.17}
{'loss': 0.0285, 'grad_norm': 11.951632499694824, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.02055252343416214, 'loss_2': 0.007904052734375, 'loss_3': -16.503345489501953, 'loss_4': 0.42987021803855896, 'epoch': 12.17}
{'loss': 0.0112, 'grad_norm': 6.34453821182251, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.010751018300652504, 'loss_2': 0.00045299530029296875, 'loss_3': -16.4907283782959, 'loss_4': 0.1913173943758011, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 16:09:30,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:30,675 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [52:08<52:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:38,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013966393657028675, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010891702957451344, 'eval_loss_2': 0.0030746906995773315, 'eval_loss_3': -18.127601623535156, 'eval_loss_4': 0.3368149995803833, 'epoch': 12.18}
{'loss': 0.0128, 'grad_norm': 4.597046375274658, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.005541007965803146, 'loss_2': 0.007282257080078125, 'loss_3': -16.361665725708008, 'loss_4': 0.05877333879470825, 'epoch': 12.19}
{'loss': 0.0131, 'grad_norm': 4.997903347015381, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.009118067100644112, 'loss_2': 0.00394439697265625, 'loss_3': -16.292945861816406, 'loss_4': 0.10524050891399384, 'epoch': 12.19}
{'loss': 0.0223, 'grad_norm': 4.895483016967773, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.009465375915169716, 'loss_2': 0.012847900390625, 'loss_3': -16.139928817749023, 'loss_4': 0.377667635679245, 'epoch': 12.2}
{'loss': 0.0078, 'grad_norm': 5.338348865509033, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.007561170030385256, 'loss_2': 0.00020265579223632812, 'loss_3': -16.320222854614258, 'loss_4': 0.1430567055940628, 'epoch': 12.2}
{'loss': 0.0115, 'grad_norm': 4.673701763153076, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.0075333151035010815, 'loss_2': 0.003948211669921875, 'loss_3': -16.403072357177734, 'loss_4': -0.06036660447716713, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 16:09:38,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:38,027 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:16<52:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:45,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011738093569874763, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00839781854301691, 'eval_loss_2': 0.0033402740955352783, 'eval_loss_3': -18.146041870117188, 'eval_loss_4': 0.16532617807388306, 'epoch': 12.21}
{'loss': 0.0105, 'grad_norm': 4.771762371063232, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.008433384820818901, 'loss_2': 0.00205230712890625, 'loss_3': -16.477603912353516, 'loss_4': 0.042804986238479614, 'epoch': 12.22}
{'loss': 0.0096, 'grad_norm': 5.986238479614258, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.006133561953902245, 'loss_2': 0.003448486328125, 'loss_3': -16.39349937438965, 'loss_4': -0.027372106909751892, 'epoch': 12.22}
{'loss': 0.0073, 'grad_norm': 5.031744480133057, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.0061729671433568, 'loss_2': 0.0011425018310546875, 'loss_3': -16.375720977783203, 'loss_4': -0.3884381055831909, 'epoch': 12.23}
{'loss': 0.0176, 'grad_norm': 7.953757286071777, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.017552973702549934, 'loss_2': 4.100799560546875e-05, 'loss_3': -16.308176040649414, 'loss_4': -0.03909352421760559, 'epoch': 12.23}
{'loss': 0.0182, 'grad_norm': 7.030755043029785, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.015522357076406479, 'loss_2': 0.0026397705078125, 'loss_3': -16.23282814025879, 'loss_4': -0.21174612641334534, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 16:09:45,380 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:45,380 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:23<52:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:52,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01204502023756504, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009137388318777084, 'eval_loss_2': 0.0029076337814331055, 'eval_loss_3': -18.162174224853516, 'eval_loss_4': -0.0007707446347922087, 'epoch': 12.24}
{'loss': 0.0145, 'grad_norm': 8.103531837463379, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.011128507554531097, 'loss_2': 0.00334930419921875, 'loss_3': -16.385875701904297, 'loss_4': -0.430847704410553, 'epoch': 12.24}
{'loss': 0.0166, 'grad_norm': 5.357022285461426, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.008488070219755173, 'loss_2': 0.00811004638671875, 'loss_3': -16.194656372070312, 'loss_4': 0.08700313419103622, 'epoch': 12.25}
{'loss': 0.0325, 'grad_norm': 9.211833000183105, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.021051708608865738, 'loss_2': 0.01140594482421875, 'loss_3': -16.331748962402344, 'loss_4': -0.11370027810335159, 'epoch': 12.26}
{'loss': 0.0228, 'grad_norm': 8.677943229675293, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.019800793379545212, 'loss_2': 0.003021240234375, 'loss_3': -16.411781311035156, 'loss_4': 0.07269928604364395, 'epoch': 12.26}
{'loss': 0.0123, 'grad_norm': 4.86734676361084, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.008639195002615452, 'loss_2': 0.0036678314208984375, 'loss_3': -16.27237319946289, 'loss_4': -0.15521331131458282, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 16:09:52,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:52,744 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:30<52:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:00,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014318733476102352, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.454, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01115029864013195, 'eval_loss_2': 0.003168433904647827, 'eval_loss_3': -18.14435386657715, 'eval_loss_4': 0.04480740427970886, 'epoch': 12.27}
{'loss': 0.0183, 'grad_norm': 4.90239143371582, 'learning_rate': 1.775e-05, 'loss_1': 0.009569776244461536, 'loss_2': 0.0086822509765625, 'loss_3': -16.209096908569336, 'loss_4': 0.04628894105553627, 'epoch': 12.27}
{'loss': 0.0251, 'grad_norm': 8.72005844116211, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.019566170871257782, 'loss_2': 0.005519866943359375, 'loss_3': -16.512678146362305, 'loss_4': -0.31426045298576355, 'epoch': 12.28}
{'loss': 0.0179, 'grad_norm': 5.7168731689453125, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.013087603263556957, 'loss_2': 0.00482177734375, 'loss_3': -16.37969207763672, 'loss_4': 0.06849441677331924, 'epoch': 12.28}
{'loss': 0.0154, 'grad_norm': 6.302920818328857, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.011052029207348824, 'loss_2': 0.00435638427734375, 'loss_3': -16.230188369750977, 'loss_4': -0.2806850075721741, 'epoch': 12.29}
{'loss': 0.0126, 'grad_norm': 5.478469371795654, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.007678764872252941, 'loss_2': 0.00492095947265625, 'loss_3': -16.340595245361328, 'loss_4': -0.27919989824295044, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 16:10:00,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:00,095 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:38<52:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:07,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015527086332440376, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.552, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010553703643381596, 'eval_loss_2': 0.004973381757736206, 'eval_loss_3': -18.154203414916992, 'eval_loss_4': 0.1082301139831543, 'epoch': 12.3}
{'loss': 0.0092, 'grad_norm': 5.783482551574707, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.0072729079984128475, 'loss_2': 0.00193023681640625, 'loss_3': -16.26325225830078, 'loss_4': 0.165052130818367, 'epoch': 12.3}
{'loss': 0.0157, 'grad_norm': 9.504984855651855, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.014544099569320679, 'loss_2': 0.001190185546875, 'loss_3': -16.393863677978516, 'loss_4': -0.34729641675949097, 'epoch': 12.31}
{'loss': 0.0144, 'grad_norm': 6.168837070465088, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.01408329326659441, 'loss_2': 0.00033664703369140625, 'loss_3': -16.40157127380371, 'loss_4': -0.04290975630283356, 'epoch': 12.31}
{'loss': 0.0265, 'grad_norm': 10.552103042602539, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.02247520349919796, 'loss_2': 0.004024505615234375, 'loss_3': -16.406085968017578, 'loss_4': -0.06395420432090759, 'epoch': 12.32}
{'loss': 0.0228, 'grad_norm': 11.381162643432617, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.022286558523774147, 'loss_2': 0.0005283355712890625, 'loss_3': -16.20020294189453, 'loss_4': 0.0006540566682815552, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 16:10:07,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:07,448 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:45<52:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:14,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013939136639237404, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.499, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010812008753418922, 'eval_loss_2': 0.0031271278858184814, 'eval_loss_3': -18.169517517089844, 'eval_loss_4': 0.10439465939998627, 'epoch': 12.33}
{'loss': 0.0243, 'grad_norm': 10.71517276763916, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.0197343360632658, 'loss_2': 0.0045928955078125, 'loss_3': -16.603736877441406, 'loss_4': 0.10929276049137115, 'epoch': 12.33}
{'loss': 0.0227, 'grad_norm': 6.849631309509277, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.0194028802216053, 'loss_2': 0.00328826904296875, 'loss_3': -16.248477935791016, 'loss_4': -0.37036949396133423, 'epoch': 12.34}
{'loss': 0.022, 'grad_norm': 8.016480445861816, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.014021546579897404, 'loss_2': 0.0079803466796875, 'loss_3': -16.437820434570312, 'loss_4': -0.27585944533348083, 'epoch': 12.34}
{'loss': 0.016, 'grad_norm': 8.858651161193848, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.012587749399244785, 'loss_2': 0.0034027099609375, 'loss_3': -16.5137882232666, 'loss_4': 0.12995122373104095, 'epoch': 12.35}
{'loss': 0.0142, 'grad_norm': 5.619247913360596, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.009526125155389309, 'loss_2': 0.004638671875, 'loss_3': -16.280197143554688, 'loss_4': -0.2757829427719116, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 16:10:14,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:14,803 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:53<52:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:22,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014421590603888035, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.557, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010508308187127113, 'eval_loss_2': 0.003913283348083496, 'eval_loss_3': -18.224578857421875, 'eval_loss_4': 0.0365290530025959, 'epoch': 12.35}
{'loss': 0.0154, 'grad_norm': 8.365630149841309, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.012918242253363132, 'loss_2': 0.00249481201171875, 'loss_3': -16.411231994628906, 'loss_4': 0.1232566088438034, 'epoch': 12.36}
{'loss': 0.0098, 'grad_norm': 5.236430644989014, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.00868939608335495, 'loss_2': 0.001155853271484375, 'loss_3': -16.485252380371094, 'loss_4': -0.25601494312286377, 'epoch': 12.37}
{'loss': 0.0167, 'grad_norm': 8.464014053344727, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.0145407160744071, 'loss_2': 0.00217437744140625, 'loss_3': -16.542293548583984, 'loss_4': 0.18157032132148743, 'epoch': 12.37}
{'loss': 0.0091, 'grad_norm': 6.320677280426025, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.0071069346740841866, 'loss_2': 0.002025604248046875, 'loss_3': -16.324844360351562, 'loss_4': -0.048698000609874725, 'epoch': 12.38}
{'loss': 0.0196, 'grad_norm': 7.259207725524902, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.017638979479670525, 'loss_2': 0.0019683837890625, 'loss_3': -16.594934463500977, 'loss_4': -0.2675531506538391, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 16:10:22,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:22,163 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [53:00<52:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:29,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012982198968529701, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009323815815150738, 'eval_loss_2': 0.003658384084701538, 'eval_loss_3': -18.271472930908203, 'eval_loss_4': 0.11093616485595703, 'epoch': 12.38}
{'loss': 0.0106, 'grad_norm': 5.634696006774902, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.010329053737223148, 'loss_2': 0.0002918243408203125, 'loss_3': -16.456207275390625, 'loss_4': 0.11641409993171692, 'epoch': 12.39}
{'loss': 0.0115, 'grad_norm': 6.6533522605896, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.011345889419317245, 'loss_2': 0.00019478797912597656, 'loss_3': -16.26519775390625, 'loss_4': -0.1551389992237091, 'epoch': 12.4}
{'loss': 0.0172, 'grad_norm': 6.383728981018066, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.011407317593693733, 'loss_2': 0.00576019287109375, 'loss_3': -16.39456558227539, 'loss_4': 0.834797203540802, 'epoch': 12.4}
{'loss': 0.028, 'grad_norm': 12.391098022460938, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.027575260028243065, 'loss_2': 0.0004649162292480469, 'loss_3': -16.217082977294922, 'loss_4': 0.03116188943386078, 'epoch': 12.41}
{'loss': 0.0142, 'grad_norm': 6.229238510131836, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.011448386125266552, 'loss_2': 0.002712249755859375, 'loss_3': -16.411121368408203, 'loss_4': 0.17992909252643585, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 16:10:29,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:29,519 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [53:07<52:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:36,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012952730059623718, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00839223526418209, 'eval_loss_2': 0.004560496658086777, 'eval_loss_3': -18.25455093383789, 'eval_loss_4': 0.2789508104324341, 'epoch': 12.41}
{'loss': 0.0113, 'grad_norm': 4.9592671394348145, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.007577401120215654, 'loss_2': 0.00376129150390625, 'loss_3': -16.43657684326172, 'loss_4': 0.2369261384010315, 'epoch': 12.42}
{'loss': 0.021, 'grad_norm': 7.434355735778809, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.02038157731294632, 'loss_2': 0.0006084442138671875, 'loss_3': -16.559707641601562, 'loss_4': 0.24258461594581604, 'epoch': 12.42}
{'loss': 0.0809, 'grad_norm': 11.879868507385254, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.07429152727127075, 'loss_2': 0.00656890869140625, 'loss_3': -16.734880447387695, 'loss_4': 0.7387738823890686, 'epoch': 12.43}
{'loss': 0.0171, 'grad_norm': 9.405003547668457, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.012333939783275127, 'loss_2': 0.00476837158203125, 'loss_3': -16.283000946044922, 'loss_4': 0.16723334789276123, 'epoch': 12.44}
{'loss': 0.0143, 'grad_norm': 5.123249053955078, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.007120081223547459, 'loss_2': 0.00722503662109375, 'loss_3': -16.623109817504883, 'loss_4': 0.29635655879974365, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 16:10:36,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:36,868 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:15<52:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:44,219 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012318691238760948, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.54, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007463683374226093, 'eval_loss_2': 0.00485500693321228, 'eval_loss_3': -18.241188049316406, 'eval_loss_4': 0.5395857691764832, 'epoch': 12.44}
{'loss': 0.0258, 'grad_norm': 14.903779029846191, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.02231276035308838, 'loss_2': 0.0034961700439453125, 'loss_3': -16.48011589050293, 'loss_4': 0.4250515103340149, 'epoch': 12.45}
{'loss': 0.0108, 'grad_norm': 4.721177577972412, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.006446981802582741, 'loss_2': 0.00431060791015625, 'loss_3': -16.605743408203125, 'loss_4': 0.6020599603652954, 'epoch': 12.45}
{'loss': 0.0254, 'grad_norm': 8.486602783203125, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.01965807005763054, 'loss_2': 0.0057830810546875, 'loss_3': -16.3402042388916, 'loss_4': 0.41657328605651855, 'epoch': 12.46}
{'loss': 0.0342, 'grad_norm': 15.940987586975098, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.03213374316692352, 'loss_2': 0.0020751953125, 'loss_3': -16.387378692626953, 'loss_4': 0.4773081839084625, 'epoch': 12.47}
{'loss': 0.0064, 'grad_norm': 4.4127960205078125, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.005152259487658739, 'loss_2': 0.0012874603271484375, 'loss_3': -16.63707733154297, 'loss_4': 0.3362226188182831, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 16:10:44,219 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:44,219 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:22<52:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:51,570 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0105667719617486, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006941885221749544, 'eval_loss_2': 0.0036248862743377686, 'eval_loss_3': -18.270462036132812, 'eval_loss_4': 0.7383448481559753, 'epoch': 12.47}
{'loss': 0.0251, 'grad_norm': 11.083986282348633, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.018708089366555214, 'loss_2': 0.0063629150390625, 'loss_3': -16.602737426757812, 'loss_4': 0.5623501539230347, 'epoch': 12.48}
{'loss': 0.01, 'grad_norm': 4.591803550720215, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.007021061144769192, 'loss_2': 0.0030231475830078125, 'loss_3': -16.48196029663086, 'loss_4': 1.0086910724639893, 'epoch': 12.48}
{'loss': 0.0134, 'grad_norm': 5.891227722167969, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.011428958736360073, 'loss_2': 0.00201416015625, 'loss_3': -16.322185516357422, 'loss_4': 0.7354772686958313, 'epoch': 12.49}
{'loss': 0.0136, 'grad_norm': 4.917664527893066, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.005546820815652609, 'loss_2': 0.00803375244140625, 'loss_3': -16.396690368652344, 'loss_4': 0.44997647404670715, 'epoch': 12.49}
{'loss': 0.0097, 'grad_norm': 6.398359298706055, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.008057699538767338, 'loss_2': 0.0016279220581054688, 'loss_3': -16.29623031616211, 'loss_4': 0.9500932097434998, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 16:10:51,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:51,570 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:29<52:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:58,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010458697564899921, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.483, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0070491028018295765, 'eval_loss_2': 0.0034095942974090576, 'eval_loss_3': -18.261247634887695, 'eval_loss_4': 0.8503696322441101, 'epoch': 12.5}
{'loss': 0.0156, 'grad_norm': 11.207064628601074, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.014498027041554451, 'loss_2': 0.0011444091796875, 'loss_3': -16.551786422729492, 'loss_4': 0.8274806141853333, 'epoch': 12.51}
{'loss': 0.0118, 'grad_norm': 7.109312534332275, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.011727512814104557, 'loss_2': 9.316205978393555e-05, 'loss_3': -16.414995193481445, 'loss_4': 0.3664930462837219, 'epoch': 12.51}
{'loss': 0.0146, 'grad_norm': 5.593142032623291, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.007856759242713451, 'loss_2': 0.00670623779296875, 'loss_3': -16.57354736328125, 'loss_4': 1.1352965831756592, 'epoch': 12.52}
{'loss': 0.0196, 'grad_norm': 8.194814682006836, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.015294907614588737, 'loss_2': 0.004291534423828125, 'loss_3': -16.35076141357422, 'loss_4': 0.1413339078426361, 'epoch': 12.52}
{'loss': 0.015, 'grad_norm': 5.247334003448486, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.00941190030425787, 'loss_2': 0.0055694580078125, 'loss_3': -16.316322326660156, 'loss_4': 0.6703652143478394, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 16:10:58,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:58,926 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:33<52:04,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 16:11:02,724 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-2155
[INFO|configuration_utils.py:420] 2025-01-21 16:11:02,725 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-2155/config.json                                                                            
{'eval_loss': 0.008876129053533077, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006277373991906643, 'eval_loss_2': 0.0025987550616264343, 'eval_loss_3': -18.27871322631836, 'eval_loss_4': 0.8750014901161194, 'epoch': 12.53}
[INFO|modeling_utils.py:2988] 2025-01-21 16:11:03,204 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-2155/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:11:03,206 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-2155/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:11:03,206 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-2155/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:11:04,156 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-1430] due to args.save_total_limit
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:38<57:22,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:11:07,793 >>
{'loss': 0.0198, 'grad_norm': 15.357318878173828, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.01621275767683983, 'loss_2': 0.003597259521484375, 'loss_3': -16.193262100219727, 'loss_4': 1.1613752841949463, 'epoch': 12.53}
{'loss': 0.0252, 'grad_norm': 12.301613807678223, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.02406318485736847, 'loss_2': 0.0011196136474609375, 'loss_3': -16.32647705078125, 'loss_4': 0.740108072757721, 'epoch': 12.54}
{'loss': 0.0071, 'grad_norm': 4.628012180328369, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.004547449294477701, 'loss_2': 0.0025177001953125, 'loss_3': -16.627052307128906, 'loss_4': 1.0146377086639404, 'epoch': 12.55}
{'loss': 0.0079, 'grad_norm': 4.685105800628662, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.005025281570851803, 'loss_2': 0.0028705596923828125, 'loss_3': -16.374473571777344, 'loss_4': 0.8261542916297913, 'epoch': 12.55}
{'loss': 0.0078, 'grad_norm': 4.836314678192139, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.00721520883962512, 'loss_2': 0.0006151199340820312, 'loss_3': -16.479520797729492, 'loss_4': 1.1663012504577637, 'epoch': 12.56}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:11:07,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:07,793 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:45<52:44,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:11:15,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0158592127263546, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.764, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008622018620371819, 'eval_loss_2': 0.00723719596862793, 'eval_loss_3': -18.207788467407227, 'eval_loss_4': 0.9396570920944214, 'epoch': 12.56}
{'loss': 0.0206, 'grad_norm': 6.650875568389893, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.011323855258524418, 'loss_2': 0.00925445556640625, 'loss_3': -16.493206024169922, 'loss_4': 0.6381618976593018, 'epoch': 12.56}
{'loss': 0.021, 'grad_norm': 5.703534126281738, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.010246786288917065, 'loss_2': 0.01076507568359375, 'loss_3': -16.419525146484375, 'loss_4': 1.185624122619629, 'epoch': 12.57}
{'loss': 0.0228, 'grad_norm': 7.95584774017334, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.013577374629676342, 'loss_2': 0.009185791015625, 'loss_3': -16.44924545288086, 'loss_4': 0.7390556335449219, 'epoch': 12.58}
{'loss': 0.0284, 'grad_norm': 7.381258010864258, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.01513273362070322, 'loss_2': 0.0132293701171875, 'loss_3': -16.512001037597656, 'loss_4': 0.8959482908248901, 'epoch': 12.58}
{'loss': 0.0319, 'grad_norm': 8.091885566711426, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.015114430338144302, 'loss_2': 0.016815185546875, 'loss_3': -16.253875732421875, 'loss_4': 0.7943419814109802, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 16:11:15,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:15,138 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:53<51:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:22,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030916834250092506, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.992, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.020887520164251328, 'eval_loss_2': 0.010029315948486328, 'eval_loss_3': -18.184816360473633, 'eval_loss_4': 1.0338701009750366, 'epoch': 12.59}
{'loss': 0.0324, 'grad_norm': 15.31098747253418, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.020693359896540642, 'loss_2': 0.011688232421875, 'loss_3': -16.30966567993164, 'loss_4': 0.6861241459846497, 'epoch': 12.59}
{'loss': 0.0309, 'grad_norm': 6.63421106338501, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.018511783331632614, 'loss_2': 0.01239013671875, 'loss_3': -16.53380584716797, 'loss_4': 1.1885648965835571, 'epoch': 12.6}
{'loss': 0.0195, 'grad_norm': 6.956195831298828, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.01251237653195858, 'loss_2': 0.00698089599609375, 'loss_3': -16.670307159423828, 'loss_4': 0.9048243761062622, 'epoch': 12.6}
{'loss': 0.0139, 'grad_norm': 8.699213027954102, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.010841967537999153, 'loss_2': 0.00307464599609375, 'loss_3': -16.24862289428711, 'loss_4': 0.7899608612060547, 'epoch': 12.61}
{'loss': 0.0258, 'grad_norm': 6.762998104095459, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.0131390281021595, 'loss_2': 0.01263427734375, 'loss_3': -16.54805564880371, 'loss_4': 1.072523593902588, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 16:11:22,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:22,471 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [54:00<51:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:29,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03524526208639145, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.141, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.03065456449985504, 'eval_loss_2': 0.004590701311826706, 'eval_loss_3': -18.146045684814453, 'eval_loss_4': 1.0896673202514648, 'epoch': 12.62}
{'loss': 0.0124, 'grad_norm': 7.931395053863525, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.011114206165075302, 'loss_2': 0.0012569427490234375, 'loss_3': -16.357955932617188, 'loss_4': 0.7093291282653809, 'epoch': 12.62}
{'loss': 0.0177, 'grad_norm': 8.331873893737793, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.0122899878770113, 'loss_2': 0.0054168701171875, 'loss_3': -16.3665714263916, 'loss_4': 0.9090243577957153, 'epoch': 12.63}
{'loss': 0.0152, 'grad_norm': 5.92963171005249, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.012305477634072304, 'loss_2': 0.002872467041015625, 'loss_3': -16.535812377929688, 'loss_4': 0.7591550350189209, 'epoch': 12.63}
{'loss': 0.0183, 'grad_norm': 13.47162914276123, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.016527382656931877, 'loss_2': 0.0017604827880859375, 'loss_3': -16.269668579101562, 'loss_4': 1.4456586837768555, 'epoch': 12.64}
{'loss': 0.0131, 'grad_norm': 6.006735324859619, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.011228001676499844, 'loss_2': 0.00182342529296875, 'loss_3': -16.48412322998047, 'loss_4': 0.893187940120697, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 16:11:29,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:29,804 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [54:07<51:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:37,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.039598047733306885, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.911, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.036003950983285904, 'eval_loss_2': 0.0035941004753112793, 'eval_loss_3': -18.140378952026367, 'eval_loss_4': 1.1998848915100098, 'epoch': 12.65}
{'loss': 0.0157, 'grad_norm': 5.021195888519287, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.006125476211309433, 'loss_2': 0.00960540771484375, 'loss_3': -16.33208656311035, 'loss_4': 1.5275259017944336, 'epoch': 12.65}
{'loss': 0.077, 'grad_norm': 22.729785919189453, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.07307901233434677, 'loss_2': 0.003936767578125, 'loss_3': -16.332923889160156, 'loss_4': 1.0653612613677979, 'epoch': 12.66}
{'loss': 0.0246, 'grad_norm': 11.465107917785645, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.021641459316015244, 'loss_2': 0.00296783447265625, 'loss_3': -16.28535270690918, 'loss_4': 0.8477317094802856, 'epoch': 12.66}
{'loss': 0.0333, 'grad_norm': 17.89654541015625, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.03179766610264778, 'loss_2': 0.0014886856079101562, 'loss_3': -16.32085418701172, 'loss_4': 0.3471219539642334, 'epoch': 12.67}
{'loss': 0.0131, 'grad_norm': 5.73838472366333, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.012469789944589138, 'loss_2': 0.0005903244018554688, 'loss_3': -16.393714904785156, 'loss_4': 1.0242977142333984, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 16:11:37,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:37,137 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [54:15<51:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:44,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08680229634046555, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.939, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.08240056782960892, 'eval_loss_2': 0.00440172478556633, 'eval_loss_3': -18.022010803222656, 'eval_loss_4': 1.3750909566879272, 'epoch': 12.67}
{'loss': 0.0247, 'grad_norm': 13.392542839050293, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.022229451686143875, 'loss_2': 0.0024261474609375, 'loss_3': -16.390411376953125, 'loss_4': 1.394791841506958, 'epoch': 12.68}
{'loss': 0.0107, 'grad_norm': 5.51392126083374, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.006046523805707693, 'loss_2': 0.00469970703125, 'loss_3': -16.34247398376465, 'loss_4': 0.6281943321228027, 'epoch': 12.69}
{'loss': 0.0249, 'grad_norm': 6.126944541931152, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.014381814748048782, 'loss_2': 0.010498046875, 'loss_3': -16.199485778808594, 'loss_4': 0.914766788482666, 'epoch': 12.69}
{'loss': 0.1408, 'grad_norm': 29.89461326599121, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.13985782861709595, 'loss_2': 0.0009889602661132812, 'loss_3': -16.387290954589844, 'loss_4': 1.5909264087677002, 'epoch': 12.7}
{'loss': 0.1472, 'grad_norm': 29.032657623291016, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.14302663505077362, 'loss_2': 0.004177093505859375, 'loss_3': -15.985796928405762, 'loss_4': 1.325277328491211, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 16:11:44,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:44,470 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:22<51:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:51,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10352116078138351, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.098628468811512, 'eval_loss_2': 0.004892684519290924, 'eval_loss_3': -17.93539047241211, 'eval_loss_4': 1.5068542957305908, 'epoch': 12.7}
{'loss': 0.0099, 'grad_norm': 8.066024780273438, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.00827668234705925, 'loss_2': 0.0016384124755859375, 'loss_3': -16.446969985961914, 'loss_4': 0.7662811279296875, 'epoch': 12.71}
{'loss': 0.0598, 'grad_norm': 11.425146102905273, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.05235318839550018, 'loss_2': 0.0074005126953125, 'loss_3': -16.079002380371094, 'loss_4': 1.1686618328094482, 'epoch': 12.72}
{'loss': 0.0226, 'grad_norm': 8.793929100036621, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.016327397897839546, 'loss_2': 0.0062408447265625, 'loss_3': -16.356929779052734, 'loss_4': 1.6696215867996216, 'epoch': 12.72}
{'loss': 0.0917, 'grad_norm': 25.487560272216797, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.09035860002040863, 'loss_2': 0.0013179779052734375, 'loss_3': -16.01832389831543, 'loss_4': 1.6928644180297852, 'epoch': 12.73}
{'loss': 0.1718, 'grad_norm': 51.7889404296875, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.17148849368095398, 'loss_2': 0.000335693359375, 'loss_3': -16.150617599487305, 'loss_4': 1.653728723526001, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 16:11:51,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:51,810 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:29<51:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:59,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05467697232961655, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.853, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.05152690038084984, 'eval_loss_2': 0.003150075674057007, 'eval_loss_3': -18.09218978881836, 'eval_loss_4': 1.6033014059066772, 'epoch': 12.73}
{'loss': 0.0804, 'grad_norm': 46.433319091796875, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.07938196510076523, 'loss_2': 0.0010547637939453125, 'loss_3': -16.185813903808594, 'loss_4': 1.6588335037231445, 'epoch': 12.74}
{'loss': 0.0249, 'grad_norm': 12.683100700378418, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.023199409246444702, 'loss_2': 0.0017290115356445312, 'loss_3': -16.25564956665039, 'loss_4': 1.6004141569137573, 'epoch': 12.74}
{'loss': 0.0087, 'grad_norm': 4.667314052581787, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.005201913416385651, 'loss_2': 0.0035247802734375, 'loss_3': -16.420116424560547, 'loss_4': 1.6456623077392578, 'epoch': 12.75}
{'loss': 0.0066, 'grad_norm': 4.937765598297119, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.004856144078075886, 'loss_2': 0.0017833709716796875, 'loss_3': -16.412220001220703, 'loss_4': 1.413492202758789, 'epoch': 12.76}
{'loss': 0.0109, 'grad_norm': 4.7043890953063965, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.00810288917273283, 'loss_2': 0.0028018951416015625, 'loss_3': -16.303049087524414, 'loss_4': 1.3708385229110718, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 16:11:59,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:59,142 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:37<51:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:06,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0102900555357337, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.829, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007549701724201441, 'eval_loss_2': 0.0027403533458709717, 'eval_loss_3': -18.291873931884766, 'eval_loss_4': 1.7023382186889648, 'epoch': 12.76}
{'loss': 0.0093, 'grad_norm': 5.109708786010742, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.0073816427029669285, 'loss_2': 0.00194549560546875, 'loss_3': -16.42856216430664, 'loss_4': 1.6833999156951904, 'epoch': 12.77}
{'loss': 0.0144, 'grad_norm': 7.5054612159729, 'learning_rate': 1.725e-05, 'loss_1': 0.011079014278948307, 'loss_2': 0.003345489501953125, 'loss_3': -16.40996742248535, 'loss_4': 1.7388520240783691, 'epoch': 12.77}
{'loss': 0.0196, 'grad_norm': 10.618291854858398, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.015242451801896095, 'loss_2': 0.004383087158203125, 'loss_3': -16.5732364654541, 'loss_4': 2.0382676124572754, 'epoch': 12.78}
{'loss': 0.0881, 'grad_norm': 26.734804153442383, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.08051266521215439, 'loss_2': 0.007595062255859375, 'loss_3': -16.42403793334961, 'loss_4': 2.3130340576171875, 'epoch': 12.78}
{'loss': 0.0127, 'grad_norm': 5.836014747619629, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.011432791128754616, 'loss_2': 0.0012645721435546875, 'loss_3': -16.552932739257812, 'loss_4': 2.480332374572754, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 16:12:06,489 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:06,489 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:44<51:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:13,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014789135195314884, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009722413495182991, 'eval_loss_2': 0.005066722631454468, 'eval_loss_3': -18.325416564941406, 'eval_loss_4': 2.150498628616333, 'epoch': 12.79}
{'loss': 0.0122, 'grad_norm': 6.105401992797852, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.010686478577554226, 'loss_2': 0.0014734268188476562, 'loss_3': -16.41417694091797, 'loss_4': 2.590268135070801, 'epoch': 12.8}
{'loss': 0.0427, 'grad_norm': 19.794275283813477, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.039533983916044235, 'loss_2': 0.0031280517578125, 'loss_3': -16.33950424194336, 'loss_4': 3.039201021194458, 'epoch': 12.8}
{'loss': 0.017, 'grad_norm': 7.044277191162109, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.014979919418692589, 'loss_2': 0.002025604248046875, 'loss_3': -16.539432525634766, 'loss_4': 2.3385510444641113, 'epoch': 12.81}
{'loss': 0.0272, 'grad_norm': 18.148014068603516, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.026040101423859596, 'loss_2': 0.0011882781982421875, 'loss_3': -16.25786590576172, 'loss_4': 2.901664972305298, 'epoch': 12.81}
{'loss': 0.0258, 'grad_norm': 14.270825386047363, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.024559056386351585, 'loss_2': 0.001201629638671875, 'loss_3': -16.567577362060547, 'loss_4': 2.8094863891601562, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 16:12:13,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:13,841 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:52<51:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:21,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015006300061941147, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.855, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009238806553184986, 'eval_loss_2': 0.005767494440078735, 'eval_loss_3': -18.297502517700195, 'eval_loss_4': 1.9188389778137207, 'epoch': 12.82}
{'loss': 0.0181, 'grad_norm': 6.893888473510742, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.008883633650839329, 'loss_2': 0.00921630859375, 'loss_3': -16.256057739257812, 'loss_4': 2.4003922939300537, 'epoch': 12.83}
{'loss': 0.0213, 'grad_norm': 9.849481582641602, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.01667526550590992, 'loss_2': 0.00460052490234375, 'loss_3': -16.529802322387695, 'loss_4': 1.8099561929702759, 'epoch': 12.83}
{'loss': 0.0275, 'grad_norm': 16.88651466369629, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.02609657682478428, 'loss_2': 0.001392364501953125, 'loss_3': -16.397750854492188, 'loss_4': 2.205136299133301, 'epoch': 12.84}
{'loss': 0.0151, 'grad_norm': 5.351870536804199, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.007240258622914553, 'loss_2': 0.00787353515625, 'loss_3': -16.22719955444336, 'loss_4': 1.4624748229980469, 'epoch': 12.84}
{'loss': 0.0137, 'grad_norm': 5.6605000495910645, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.010656431317329407, 'loss_2': 0.003047943115234375, 'loss_3': -16.755903244018555, 'loss_4': 1.3866653442382812, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 16:12:21,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:21,185 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:59<50:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:28,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009711398743093014, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006073659751564264, 'eval_loss_2': 0.003637738525867462, 'eval_loss_3': -18.271799087524414, 'eval_loss_4': 1.3134886026382446, 'epoch': 12.85}
{'loss': 0.0281, 'grad_norm': 11.362732887268066, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.018426021561026573, 'loss_2': 0.00971221923828125, 'loss_3': -16.506744384765625, 'loss_4': 1.5493671894073486, 'epoch': 12.85}
{'loss': 0.0093, 'grad_norm': 4.593527793884277, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.003096308559179306, 'loss_2': 0.006198883056640625, 'loss_3': -16.419721603393555, 'loss_4': 1.4347501993179321, 'epoch': 12.86}
{'loss': 0.0114, 'grad_norm': 4.917462348937988, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.006141493562608957, 'loss_2': 0.00521087646484375, 'loss_3': -16.617691040039062, 'loss_4': 1.0477871894836426, 'epoch': 12.87}
{'loss': 0.0173, 'grad_norm': 9.526598930358887, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.0169756468385458, 'loss_2': 0.00030303001403808594, 'loss_3': -16.51725196838379, 'loss_4': 1.064980149269104, 'epoch': 12.87}
{'loss': 0.015, 'grad_norm': 4.772722244262695, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.003620231756940484, 'loss_2': 0.01134490966796875, 'loss_3': -16.351341247558594, 'loss_4': 1.0045208930969238, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 16:12:28,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:28,539 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [55:06<50:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:35,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010716401971876621, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.245, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007975215092301369, 'eval_loss_2': 0.002741187810897827, 'eval_loss_3': -18.19356346130371, 'eval_loss_4': 1.019252896308899, 'epoch': 12.88}
{'loss': 0.0183, 'grad_norm': 8.483736991882324, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.012394108809530735, 'loss_2': 0.00586700439453125, 'loss_3': -16.385387420654297, 'loss_4': 0.8982058763504028, 'epoch': 12.88}
{'loss': 0.0145, 'grad_norm': 5.523615837097168, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.00817929022014141, 'loss_2': 0.00634765625, 'loss_3': -16.458559036254883, 'loss_4': 0.8274742364883423, 'epoch': 12.89}
{'loss': 0.0167, 'grad_norm': 8.02956485748291, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.01117878220975399, 'loss_2': 0.0055084228515625, 'loss_3': -16.46149444580078, 'loss_4': 0.519202709197998, 'epoch': 12.9}
{'loss': 0.0102, 'grad_norm': 7.030777931213379, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.00990197341889143, 'loss_2': 0.00027179718017578125, 'loss_3': -16.28754425048828, 'loss_4': 1.1136775016784668, 'epoch': 12.9}
{'loss': 0.011, 'grad_norm': 4.3900322914123535, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.008351502940058708, 'loss_2': 0.0025997161865234375, 'loss_3': -16.346960067749023, 'loss_4': 0.691331148147583, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 16:12:35,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:35,892 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [55:14<50:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:43,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017544586211442947, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.809, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014014264568686485, 'eval_loss_2': 0.0035303235054016113, 'eval_loss_3': -18.114063262939453, 'eval_loss_4': 0.8429158329963684, 'epoch': 12.91}
{'loss': 0.0167, 'grad_norm': 11.072470664978027, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.014425036497414112, 'loss_2': 0.002277374267578125, 'loss_3': -16.386680603027344, 'loss_4': 0.7571653127670288, 'epoch': 12.91}
{'loss': 0.0154, 'grad_norm': 6.855786323547363, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.011914473958313465, 'loss_2': 0.0035247802734375, 'loss_3': -16.304227828979492, 'loss_4': 0.6024710536003113, 'epoch': 12.92}
{'loss': 0.0063, 'grad_norm': 4.651749134063721, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.004457099828869104, 'loss_2': 0.00188446044921875, 'loss_3': -16.498483657836914, 'loss_4': 0.6670677065849304, 'epoch': 12.92}
{'loss': 0.0184, 'grad_norm': 7.5472517013549805, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.008578444831073284, 'loss_2': 0.00980377197265625, 'loss_3': -16.479267120361328, 'loss_4': 0.5214357376098633, 'epoch': 12.93}
{'loss': 0.0115, 'grad_norm': 5.101053714752197, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.0040475171990692616, 'loss_2': 0.00740814208984375, 'loss_3': -16.362268447875977, 'loss_4': 0.20554371178150177, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 16:12:43,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:43,232 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:21<50:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:50,571 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021377060562372208, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.694, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01551565807312727, 'eval_loss_2': 0.005861401557922363, 'eval_loss_3': -18.085512161254883, 'eval_loss_4': 0.7567585110664368, 'epoch': 12.94}
{'loss': 0.0272, 'grad_norm': 7.446021556854248, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.020722627639770508, 'loss_2': 0.006435394287109375, 'loss_3': -16.385908126831055, 'loss_4': 0.48275044560432434, 'epoch': 12.94}
{'loss': 0.0151, 'grad_norm': 5.998878479003906, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.00961649976670742, 'loss_2': 0.00545501708984375, 'loss_3': -16.32596778869629, 'loss_4': 0.3948560953140259, 'epoch': 12.95}
{'loss': 0.0293, 'grad_norm': 23.79840660095215, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.02857993170619011, 'loss_2': 0.0006837844848632812, 'loss_3': -16.292917251586914, 'loss_4': 0.46417999267578125, 'epoch': 12.95}
{'loss': 0.0105, 'grad_norm': 5.603202819824219, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.00824544858187437, 'loss_2': 0.0022716522216796875, 'loss_3': -16.374523162841797, 'loss_4': 0.837064802646637, 'epoch': 12.96}
{'loss': 0.0097, 'grad_norm': 5.465834140777588, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.007279273122549057, 'loss_2': 0.00238037109375, 'loss_3': -16.479116439819336, 'loss_4': 0.5962754487991333, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 16:12:50,571 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:50,571 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:28<50:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:12:57,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017700152471661568, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.877, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013950662687420845, 'eval_loss_2': 0.0037494897842407227, 'eval_loss_3': -18.075149536132812, 'eval_loss_4': 0.693440854549408, 'epoch': 12.97}
{'loss': 0.0344, 'grad_norm': 15.886438369750977, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.030273620039224625, 'loss_2': 0.00408172607421875, 'loss_3': -16.165931701660156, 'loss_4': 0.9364556074142456, 'epoch': 12.97}
{'loss': 0.0255, 'grad_norm': 11.928579330444336, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.025445714592933655, 'loss_2': 2.467632293701172e-05, 'loss_3': -16.257017135620117, 'loss_4': 0.7356835007667542, 'epoch': 12.98}
{'loss': 0.0066, 'grad_norm': 4.900561332702637, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.00535792438313365, 'loss_2': 0.001220703125, 'loss_3': -16.423599243164062, 'loss_4': 0.4507516026496887, 'epoch': 12.98}
{'loss': 0.0195, 'grad_norm': 12.160431861877441, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.015982048586010933, 'loss_2': 0.0035400390625, 'loss_3': -16.104751586914062, 'loss_4': 0.7680202126502991, 'epoch': 12.99}
{'loss': 0.0161, 'grad_norm': 6.278216361999512, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.008351008407771587, 'loss_2': 0.007781982421875, 'loss_3': -16.26772689819336, 'loss_4': 0.8711737990379333, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 16:12:57,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:57,885 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:35<49:27,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:13:04,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0174037404358387, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014752550981938839, 'eval_loss_2': 0.0026511885225772858, 'eval_loss_3': -18.078277587890625, 'eval_loss_4': 0.7375535368919373, 'epoch': 12.99}
{'loss': 0.0035, 'grad_norm': 6.194492340087891, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.0014154522214084864, 'loss_2': 0.002109527587890625, 'loss_3': -16.403125762939453, 'loss_4': 1.0682867765426636, 'epoch': 13.0}
{'loss': 0.0281, 'grad_norm': 8.053313255310059, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.014675603248178959, 'loss_2': 0.013397216796875, 'loss_3': -16.231534957885742, 'loss_4': 0.7999411821365356, 'epoch': 13.01}
{'loss': 0.0115, 'grad_norm': 6.56088924407959, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.0075282147154212, 'loss_2': 0.00396728515625, 'loss_3': -16.48483657836914, 'loss_4': 0.5977172255516052, 'epoch': 13.01}
{'loss': 0.0249, 'grad_norm': 7.931774616241455, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.01575285941362381, 'loss_2': 0.00917816162109375, 'loss_3': -16.260986328125, 'loss_4': 0.681719183921814, 'epoch': 13.02}
{'loss': 0.0088, 'grad_norm': 4.9681854248046875, 'learning_rate': 1.7e-05, 'loss_1': 0.008628361858427525, 'loss_2': 0.00015079975128173828, 'loss_3': -16.399932861328125, 'loss_4': 0.8239462375640869, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 16:13:04,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:04,933 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:43<50:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:12,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010601570829749107, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007776258047670126, 'eval_loss_2': 0.002825312316417694, 'eval_loss_3': -18.1485538482666, 'eval_loss_4': 0.842000424861908, 'epoch': 13.02}
{'loss': 0.0314, 'grad_norm': 10.892082214355469, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.029391556978225708, 'loss_2': 0.002044677734375, 'loss_3': -16.569059371948242, 'loss_4': 1.0028636455535889, 'epoch': 13.03}
{'loss': 0.018, 'grad_norm': 6.557589054107666, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.011711626313626766, 'loss_2': 0.006290435791015625, 'loss_3': -16.249662399291992, 'loss_4': 0.6280434131622314, 'epoch': 13.03}
{'loss': 0.0096, 'grad_norm': 5.3978166580200195, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.008199884556233883, 'loss_2': 0.001445770263671875, 'loss_3': -16.269073486328125, 'loss_4': 0.6163234710693359, 'epoch': 13.04}
{'loss': 0.0217, 'grad_norm': 11.370976448059082, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.02073977142572403, 'loss_2': 0.0009202957153320312, 'loss_3': -16.490522384643555, 'loss_4': 0.481044203042984, 'epoch': 13.05}
{'loss': 0.0238, 'grad_norm': 5.67262601852417, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.011421877890825272, 'loss_2': 0.0123443603515625, 'loss_3': -16.620758056640625, 'loss_4': 0.9560824036598206, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 16:13:12,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:12,285 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:50<50:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:19,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01288016326725483, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.712, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.005943493917584419, 'eval_loss_2': 0.00693666934967041, 'eval_loss_3': -18.193683624267578, 'eval_loss_4': 0.8981543779373169, 'epoch': 13.05}
{'loss': 0.0136, 'grad_norm': 5.693368434906006, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.007520448882132769, 'loss_2': 0.00605010986328125, 'loss_3': -16.25172996520996, 'loss_4': 0.7575998306274414, 'epoch': 13.06}
{'loss': 0.0191, 'grad_norm': 4.947843551635742, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.0054510049521923065, 'loss_2': 0.013641357421875, 'loss_3': -16.24675750732422, 'loss_4': 0.5730559825897217, 'epoch': 13.06}
{'loss': 0.0146, 'grad_norm': 5.671600818634033, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.005445399787276983, 'loss_2': 0.00911712646484375, 'loss_3': -16.23939323425293, 'loss_4': 0.7894423007965088, 'epoch': 13.07}
{'loss': 0.0522, 'grad_norm': 14.546720504760742, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.04727381095290184, 'loss_2': 0.004913330078125, 'loss_3': -16.395465850830078, 'loss_4': 1.0573904514312744, 'epoch': 13.08}
{'loss': 0.008, 'grad_norm': 4.971733093261719, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.0077631487511098385, 'loss_2': 0.00018787384033203125, 'loss_3': -16.220064163208008, 'loss_4': 0.599952757358551, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 16:13:19,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:19,621 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:57<50:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:26,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010899702087044716, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.666, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006011168006807566, 'eval_loss_2': 0.0048885345458984375, 'eval_loss_3': -18.168031692504883, 'eval_loss_4': 0.8884098529815674, 'epoch': 13.08}
{'loss': 0.0197, 'grad_norm': 13.334328651428223, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.019535258412361145, 'loss_2': 0.00015473365783691406, 'loss_3': -16.268627166748047, 'loss_4': 0.5210965871810913, 'epoch': 13.09}
{'loss': 0.01, 'grad_norm': 4.891191482543945, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.004921358078718185, 'loss_2': 0.00508880615234375, 'loss_3': -16.526031494140625, 'loss_4': 1.2958366870880127, 'epoch': 13.09}
{'loss': 0.0141, 'grad_norm': 5.665938377380371, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.007711677346378565, 'loss_2': 0.0063934326171875, 'loss_3': -16.393884658813477, 'loss_4': 0.4344182312488556, 'epoch': 13.1}
{'loss': 0.0163, 'grad_norm': 7.938812255859375, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.013023841194808483, 'loss_2': 0.0033111572265625, 'loss_3': -16.512907028198242, 'loss_4': 0.7446012496948242, 'epoch': 13.1}
{'loss': 0.0092, 'grad_norm': 5.622211933135986, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.007397285662591457, 'loss_2': 0.00176239013671875, 'loss_3': -16.28730010986328, 'loss_4': 0.9111330509185791, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 16:13:26,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:26,965 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [56:05<50:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:34,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01020339597016573, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0065798950381577015, 'eval_loss_2': 0.0036235004663467407, 'eval_loss_3': -18.184795379638672, 'eval_loss_4': 0.7526160478591919, 'epoch': 13.11}
{'loss': 0.0209, 'grad_norm': 12.029959678649902, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.016765199601650238, 'loss_2': 0.004116058349609375, 'loss_3': -16.531330108642578, 'loss_4': 0.6985770463943481, 'epoch': 13.12}
{'loss': 0.0099, 'grad_norm': 6.441362380981445, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.008492102846503258, 'loss_2': 0.0014142990112304688, 'loss_3': -16.374975204467773, 'loss_4': 0.8886348605155945, 'epoch': 13.12}
{'loss': 0.0137, 'grad_norm': 6.383805274963379, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.008752094581723213, 'loss_2': 0.00499725341796875, 'loss_3': -16.41459083557129, 'loss_4': 0.48388850688934326, 'epoch': 13.13}
{'loss': 0.0189, 'grad_norm': 5.1306328773498535, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.007763331290334463, 'loss_2': 0.01116180419921875, 'loss_3': -16.507335662841797, 'loss_4': 0.32008856534957886, 'epoch': 13.13}
{'loss': 0.0085, 'grad_norm': 6.314750671386719, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.007858211174607277, 'loss_2': 0.0006122589111328125, 'loss_3': -16.679882049560547, 'loss_4': 0.5474221706390381, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 16:13:34,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:34,311 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [56:12<50:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:41,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012067364528775215, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.858, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.006438600365072489, 'eval_loss_2': 0.005628764629364014, 'eval_loss_3': -18.192094802856445, 'eval_loss_4': 0.6505475640296936, 'epoch': 13.14}
{'loss': 0.0146, 'grad_norm': 8.612194061279297, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.011470281518995762, 'loss_2': 0.0031070709228515625, 'loss_3': -16.323457717895508, 'loss_4': 0.9384350180625916, 'epoch': 13.15}
{'loss': 0.0149, 'grad_norm': 6.4649553298950195, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.01052966807037592, 'loss_2': 0.0043487548828125, 'loss_3': -16.30319595336914, 'loss_4': 0.7737219333648682, 'epoch': 13.15}
{'loss': 0.0084, 'grad_norm': 4.907258033752441, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.005602946504950523, 'loss_2': 0.002838134765625, 'loss_3': -16.46714210510254, 'loss_4': 0.5229445695877075, 'epoch': 13.16}
{'loss': 0.0138, 'grad_norm': 6.993825435638428, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.010090592317283154, 'loss_2': 0.0037078857421875, 'loss_3': -16.453689575195312, 'loss_4': 0.4052097201347351, 'epoch': 13.16}
{'loss': 0.024, 'grad_norm': 8.136914253234863, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.012882156297564507, 'loss_2': 0.0110931396484375, 'loss_3': -16.429141998291016, 'loss_4': 0.9586483240127563, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 16:13:41,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:41,651 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:19<49:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:48,998 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010932015255093575, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006669985130429268, 'eval_loss_2': 0.004262030124664307, 'eval_loss_3': -18.175262451171875, 'eval_loss_4': 0.4660104513168335, 'epoch': 13.17}
{'loss': 0.0101, 'grad_norm': 5.184998989105225, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.00771245127543807, 'loss_2': 0.0023956298828125, 'loss_3': -16.325878143310547, 'loss_4': 0.4513564705848694, 'epoch': 13.17}
{'loss': 0.0171, 'grad_norm': 12.121756553649902, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.013762587681412697, 'loss_2': 0.003353118896484375, 'loss_3': -16.299175262451172, 'loss_4': 0.4861602187156677, 'epoch': 13.18}
{'loss': 0.016, 'grad_norm': 7.2462358474731445, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.013106194324791431, 'loss_2': 0.0029144287109375, 'loss_3': -16.477344512939453, 'loss_4': 0.35518041253089905, 'epoch': 13.19}
{'loss': 0.0066, 'grad_norm': 3.892918348312378, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.003900139592587948, 'loss_2': 0.002666473388671875, 'loss_3': -16.452491760253906, 'loss_4': 0.28290998935699463, 'epoch': 13.19}
{'loss': 0.0174, 'grad_norm': 8.862051963806152, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.013271743431687355, 'loss_2': 0.0041351318359375, 'loss_3': -16.54736328125, 'loss_4': 0.3584667444229126, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 16:13:48,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:48,998 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:27<50:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:56,365 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01594848558306694, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.797, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008825373835861683, 'eval_loss_2': 0.007123112678527832, 'eval_loss_3': -18.15094566345215, 'eval_loss_4': 0.48104482889175415, 'epoch': 13.2}
{'loss': 0.0176, 'grad_norm': 9.342144012451172, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.013442909345030785, 'loss_2': 0.00414276123046875, 'loss_3': -16.527597427368164, 'loss_4': 0.582474946975708, 'epoch': 13.2}
{'loss': 0.0186, 'grad_norm': 5.982241630554199, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.008572417311370373, 'loss_2': 0.01001739501953125, 'loss_3': -16.443115234375, 'loss_4': 0.8717274069786072, 'epoch': 13.21}
{'loss': 0.0065, 'grad_norm': 4.4386186599731445, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.006343591492623091, 'loss_2': 0.00012874603271484375, 'loss_3': -16.609270095825195, 'loss_4': 0.3582162857055664, 'epoch': 13.22}
{'loss': 0.0213, 'grad_norm': 6.837197303771973, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.01985490322113037, 'loss_2': 0.0014657974243164062, 'loss_3': -16.424772262573242, 'loss_4': 0.2801685929298401, 'epoch': 13.22}
{'loss': 0.0143, 'grad_norm': 9.151811599731445, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.010968783870339394, 'loss_2': 0.003330230712890625, 'loss_3': -16.474212646484375, 'loss_4': 0.6062750816345215, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 16:13:56,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:56,365 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:34<49:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:03,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01508183591067791, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.481, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010209901258349419, 'eval_loss_2': 0.004871934652328491, 'eval_loss_3': -18.13867950439453, 'eval_loss_4': 0.45808500051498413, 'epoch': 13.23}
{'loss': 0.0146, 'grad_norm': 5.1156744956970215, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.0118799963966012, 'loss_2': 0.0026912689208984375, 'loss_3': -16.513639450073242, 'loss_4': 0.4517607092857361, 'epoch': 13.23}
{'loss': 0.0198, 'grad_norm': 6.129434108734131, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.01172649022191763, 'loss_2': 0.008026123046875, 'loss_3': -16.625782012939453, 'loss_4': 0.4395265579223633, 'epoch': 13.24}
{'loss': 0.0255, 'grad_norm': 16.983491897583008, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.024131814017891884, 'loss_2': 0.00131988525390625, 'loss_3': -16.41196060180664, 'loss_4': 0.45441216230392456, 'epoch': 13.24}
{'loss': 0.0145, 'grad_norm': 6.470972061157227, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.009786208160221577, 'loss_2': 0.004695892333984375, 'loss_3': -16.551332473754883, 'loss_4': 0.5501946806907654, 'epoch': 13.25}
{'loss': 0.0655, 'grad_norm': 21.02458953857422, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.06362000107765198, 'loss_2': 0.0018701553344726562, 'loss_3': -16.384550094604492, 'loss_4': 0.6478636264801025, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 16:14:03,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:03,728 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:41<49:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:11,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012592431157827377, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.21, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008531789295375347, 'eval_loss_2': 0.004060640931129456, 'eval_loss_3': -18.157001495361328, 'eval_loss_4': 0.35559993982315063, 'epoch': 13.26}
{'loss': 0.0122, 'grad_norm': 6.100612163543701, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.009423009119927883, 'loss_2': 0.0027942657470703125, 'loss_3': -16.331764221191406, 'loss_4': 0.1517007052898407, 'epoch': 13.26}
{'loss': 0.0273, 'grad_norm': 9.355181694030762, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.01974644884467125, 'loss_2': 0.00751495361328125, 'loss_3': -16.52089500427246, 'loss_4': 0.26159074902534485, 'epoch': 13.27}
{'loss': 0.0209, 'grad_norm': 10.78173828125, 'learning_rate': 1.675e-05, 'loss_1': 0.01879461668431759, 'loss_2': 0.00208282470703125, 'loss_3': -16.635019302368164, 'loss_4': 0.15232251584529877, 'epoch': 13.27}
{'loss': 0.0078, 'grad_norm': 4.871933937072754, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.004839872941374779, 'loss_2': 0.002994537353515625, 'loss_3': -16.527843475341797, 'loss_4': 0.19774284958839417, 'epoch': 13.28}
{'loss': 0.0633, 'grad_norm': 6.546308517456055, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.06266652792692184, 'loss_2': 0.0005893707275390625, 'loss_3': -16.506502151489258, 'loss_4': 1.1082782745361328, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 16:14:11,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:11,084 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:49<49:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:18,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012774067930877209, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008266003802418709, 'eval_loss_2': 0.004508063197135925, 'eval_loss_3': -18.157489776611328, 'eval_loss_4': 0.40533989667892456, 'epoch': 13.28}
{'loss': 0.0101, 'grad_norm': 4.663355350494385, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.005500463303178549, 'loss_2': 0.00457000732421875, 'loss_3': -16.583425521850586, 'loss_4': 0.47397029399871826, 'epoch': 13.29}
{'loss': 0.0156, 'grad_norm': 5.0490031242370605, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.006322204135358334, 'loss_2': 0.0093231201171875, 'loss_3': -16.687122344970703, 'loss_4': 0.6758347749710083, 'epoch': 13.3}
{'loss': 0.0129, 'grad_norm': 6.164322376251221, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.009846199303865433, 'loss_2': 0.0030364990234375, 'loss_3': -16.57648468017578, 'loss_4': 0.740478515625, 'epoch': 13.3}
{'loss': 0.012, 'grad_norm': 4.944813251495361, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.00845081266015768, 'loss_2': 0.0035247802734375, 'loss_3': -16.61152458190918, 'loss_4': 0.2919939160346985, 'epoch': 13.31}
{'loss': 0.0231, 'grad_norm': 4.701098918914795, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.008255910128355026, 'loss_2': 0.01482391357421875, 'loss_3': -16.58038330078125, 'loss_4': 0.34539806842803955, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 16:14:18,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:18,441 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:56<49:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:25,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015040787868201733, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.247, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00815478153526783, 'eval_loss_2': 0.006886005401611328, 'eval_loss_3': -18.16326904296875, 'eval_loss_4': 0.42377686500549316, 'epoch': 13.31}
{'loss': 0.015, 'grad_norm': 5.886895179748535, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.008870064280927181, 'loss_2': 0.00612640380859375, 'loss_3': -16.465900421142578, 'loss_4': 0.2685249447822571, 'epoch': 13.32}
{'loss': 0.0175, 'grad_norm': 5.333430290222168, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.006684909574687481, 'loss_2': 0.010833740234375, 'loss_3': -16.498266220092773, 'loss_4': 0.5485379695892334, 'epoch': 13.33}
{'loss': 0.0264, 'grad_norm': 16.459064483642578, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.021115882322192192, 'loss_2': 0.00531768798828125, 'loss_3': -16.47047233581543, 'loss_4': 0.6228371858596802, 'epoch': 13.33}
{'loss': 0.0102, 'grad_norm': 5.105571269989014, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.008830764330923557, 'loss_2': 0.00135040283203125, 'loss_3': -16.52405548095703, 'loss_4': 0.20694419741630554, 'epoch': 13.34}
{'loss': 0.0117, 'grad_norm': 5.210177421569824, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.006242281757295132, 'loss_2': 0.005462646484375, 'loss_3': -16.538936614990234, 'loss_4': 0.3688386082649231, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 16:14:25,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:25,800 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [57:04<49:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:33,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011632012203335762, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008203672245144844, 'eval_loss_2': 0.003428339958190918, 'eval_loss_3': -18.100025177001953, 'eval_loss_4': 0.45493245124816895, 'epoch': 13.34}
{'loss': 0.0116, 'grad_norm': 6.072604656219482, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.010123295709490776, 'loss_2': 0.0014858245849609375, 'loss_3': -16.343585968017578, 'loss_4': 0.3974533677101135, 'epoch': 13.35}
{'loss': 0.0082, 'grad_norm': 6.156538009643555, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.008130820468068123, 'loss_2': 4.0531158447265625e-05, 'loss_3': -16.328943252563477, 'loss_4': -0.011967994272708893, 'epoch': 13.35}
{'loss': 0.0142, 'grad_norm': 5.331510543823242, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.007966109551489353, 'loss_2': 0.0062713623046875, 'loss_3': -16.383405685424805, 'loss_4': 0.24202987551689148, 'epoch': 13.36}
{'loss': 0.0123, 'grad_norm': 6.762345314025879, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.01077958196401596, 'loss_2': 0.001491546630859375, 'loss_3': -16.581466674804688, 'loss_4': -0.23049551248550415, 'epoch': 13.37}
{'loss': 0.0223, 'grad_norm': 6.205462455749512, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.013326052576303482, 'loss_2': 0.00899505615234375, 'loss_3': -16.527273178100586, 'loss_4': -0.13565370440483093, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 16:14:33,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:33,164 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [57:11<49:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:40,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012100482359528542, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007359261158853769, 'eval_loss_2': 0.00474122166633606, 'eval_loss_3': -18.066625595092773, 'eval_loss_4': 0.4867169260978699, 'epoch': 13.37}
{'loss': 0.0109, 'grad_norm': 6.848649978637695, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.0074158222414553165, 'loss_2': 0.003459930419921875, 'loss_3': -16.32120132446289, 'loss_4': 0.7993878722190857, 'epoch': 13.38}
{'loss': 0.0231, 'grad_norm': 12.396990776062012, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.022580699995160103, 'loss_2': 0.0005097389221191406, 'loss_3': -16.5240478515625, 'loss_4': 0.43817073106765747, 'epoch': 13.38}
{'loss': 0.0132, 'grad_norm': 4.87599515914917, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.008106415160000324, 'loss_2': 0.0051422119140625, 'loss_3': -16.303403854370117, 'loss_4': 0.038520678877830505, 'epoch': 13.39}
{'loss': 0.0193, 'grad_norm': 8.509917259216309, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.01372526865452528, 'loss_2': 0.005615234375, 'loss_3': -16.327213287353516, 'loss_4': 0.441562294960022, 'epoch': 13.4}
{'loss': 0.0043, 'grad_norm': 5.534024715423584, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.004132820293307304, 'loss_2': 0.0002092123031616211, 'loss_3': -16.461204528808594, 'loss_4': 0.5283582210540771, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 16:14:40,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:40,517 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:18<49:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:47,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012637445703148842, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.268, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00812741182744503, 'eval_loss_2': 0.004510033875703812, 'eval_loss_3': -18.03436279296875, 'eval_loss_4': 0.5811896920204163, 'epoch': 13.4}
{'loss': 0.007, 'grad_norm': 4.9888105392456055, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.005346118006855249, 'loss_2': 0.0016956329345703125, 'loss_3': -16.516067504882812, 'loss_4': 0.8095788359642029, 'epoch': 13.41}
{'loss': 0.0156, 'grad_norm': 6.137855052947998, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.008536649867892265, 'loss_2': 0.007022857666015625, 'loss_3': -16.488527297973633, 'loss_4': 0.8365907669067383, 'epoch': 13.41}
{'loss': 0.0198, 'grad_norm': 7.074413299560547, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.01708447001874447, 'loss_2': 0.00272369384765625, 'loss_3': -16.408994674682617, 'loss_4': 0.5574598908424377, 'epoch': 13.42}
{'loss': 0.0169, 'grad_norm': 10.536654472351074, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.014401251450181007, 'loss_2': 0.002490997314453125, 'loss_3': -16.44361686706543, 'loss_4': 0.5070087909698486, 'epoch': 13.42}
{'loss': 0.0142, 'grad_norm': 5.179405212402344, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.006672609131783247, 'loss_2': 0.007541656494140625, 'loss_3': -16.454689025878906, 'loss_4': 0.6686236262321472, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 16:14:47,870 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:47,870 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:26<49:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:55,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013033251278102398, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.593, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008737955242395401, 'eval_loss_2': 0.0042952969670295715, 'eval_loss_3': -18.039512634277344, 'eval_loss_4': 0.6550091505050659, 'epoch': 13.43}
{'loss': 0.0139, 'grad_norm': 6.862705230712891, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.010652205906808376, 'loss_2': 0.0032806396484375, 'loss_3': -16.51681137084961, 'loss_4': 0.6502158641815186, 'epoch': 13.44}
{'loss': 0.0141, 'grad_norm': 7.362351894378662, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.014057353138923645, 'loss_2': 8.624792098999023e-05, 'loss_3': -16.09769630432129, 'loss_4': 0.7967787981033325, 'epoch': 13.44}
{'loss': 0.0162, 'grad_norm': 5.493356704711914, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.013661609031260014, 'loss_2': 0.0024967193603515625, 'loss_3': -16.152873992919922, 'loss_4': 0.8051002025604248, 'epoch': 13.45}
{'loss': 0.0803, 'grad_norm': 12.249438285827637, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.07863609492778778, 'loss_2': 0.00165557861328125, 'loss_3': -16.324966430664062, 'loss_4': 0.7003235816955566, 'epoch': 13.45}
{'loss': 0.015, 'grad_norm': 7.138380527496338, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.013327776454389095, 'loss_2': 0.001628875732421875, 'loss_3': -16.312602996826172, 'loss_4': 0.5951101183891296, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 16:14:55,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:55,223 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:33<49:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:02,574 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01459524780511856, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009858645498752594, 'eval_loss_2': 0.004736602306365967, 'eval_loss_3': -18.0657958984375, 'eval_loss_4': 0.6632461547851562, 'epoch': 13.46}
{'loss': 0.0195, 'grad_norm': 7.908891201019287, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.012030655518174171, 'loss_2': 0.007511138916015625, 'loss_3': -16.421398162841797, 'loss_4': 0.8156965970993042, 'epoch': 13.47}
{'loss': 0.0065, 'grad_norm': 5.017873764038086, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.006250038277357817, 'loss_2': 0.0002313852310180664, 'loss_3': -16.437353134155273, 'loss_4': 0.624954342842102, 'epoch': 13.47}
{'loss': 0.0201, 'grad_norm': 5.988986492156982, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.013305195607244968, 'loss_2': 0.00676727294921875, 'loss_3': -16.53268051147461, 'loss_4': 0.35942336916923523, 'epoch': 13.48}
{'loss': 0.012, 'grad_norm': 6.49788761138916, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.010675720870494843, 'loss_2': 0.00128173828125, 'loss_3': -16.460403442382812, 'loss_4': 0.4022586941719055, 'epoch': 13.48}
{'loss': 0.0218, 'grad_norm': 6.097726821899414, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.015918778255581856, 'loss_2': 0.0059051513671875, 'loss_3': -16.355527877807617, 'loss_4': 0.5473960638046265, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 16:15:02,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:02,574 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:40<49:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:09,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013536771759390831, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.646, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008782808668911457, 'eval_loss_2': 0.004753962159156799, 'eval_loss_3': -18.12476348876953, 'eval_loss_4': 0.6439428925514221, 'epoch': 13.49}
{'loss': 0.0077, 'grad_norm': 4.492063522338867, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.007612458895891905, 'loss_2': 0.00011801719665527344, 'loss_3': -16.43656349182129, 'loss_4': 0.6935263872146606, 'epoch': 13.49}
{'loss': 0.005, 'grad_norm': 4.317363739013672, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.004432186484336853, 'loss_2': 0.0005235671997070312, 'loss_3': -16.37242889404297, 'loss_4': 0.7774296998977661, 'epoch': 13.5}
{'loss': 0.0142, 'grad_norm': 5.45662260055542, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.008672001771628857, 'loss_2': 0.005489349365234375, 'loss_3': -16.485858917236328, 'loss_4': 0.7048043012619019, 'epoch': 13.51}
{'loss': 0.0103, 'grad_norm': 5.389102458953857, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.007643797900527716, 'loss_2': 0.002681732177734375, 'loss_3': -16.6237735748291, 'loss_4': 0.800027072429657, 'epoch': 13.51}
{'loss': 0.0126, 'grad_norm': 6.324852466583252, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.010198301635682583, 'loss_2': 0.00235748291015625, 'loss_3': -16.54676055908203, 'loss_4': 0.31663978099823, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 16:15:09,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:09,928 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:48<49:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:17,290 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011885657906532288, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.86, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007426575291901827, 'eval_loss_2': 0.004459083080291748, 'eval_loss_3': -18.17464256286621, 'eval_loss_4': 0.6583342552185059, 'epoch': 13.52}
{'loss': 0.0131, 'grad_norm': 7.042327880859375, 'learning_rate': 1.65e-05, 'loss_1': 0.010477766394615173, 'loss_2': 0.002605438232421875, 'loss_3': -16.379070281982422, 'loss_4': 0.6049813032150269, 'epoch': 13.52}
{'loss': 0.0129, 'grad_norm': 8.207242012023926, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.011216637678444386, 'loss_2': 0.0017147064208984375, 'loss_3': -16.175819396972656, 'loss_4': 0.8111401796340942, 'epoch': 13.53}
{'loss': 0.0136, 'grad_norm': 4.249865531921387, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.00384944723919034, 'loss_2': 0.0097808837890625, 'loss_3': -16.32910919189453, 'loss_4': 0.39101743698120117, 'epoch': 13.53}
{'loss': 0.0263, 'grad_norm': 10.62494945526123, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.016607675701379776, 'loss_2': 0.00970458984375, 'loss_3': -16.51756477355957, 'loss_4': 0.7974133491516113, 'epoch': 13.54}
{'loss': 0.0228, 'grad_norm': 8.399399757385254, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.01542285829782486, 'loss_2': 0.007335662841796875, 'loss_3': -16.447328567504883, 'loss_4': 0.5517075061798096, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 16:15:17,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:17,291 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:55<48:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:24,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013308638706803322, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007365391124039888, 'eval_loss_2': 0.0059432461857795715, 'eval_loss_3': -18.239145278930664, 'eval_loss_4': 0.6685624122619629, 'epoch': 13.55}
{'loss': 0.011, 'grad_norm': 4.992981910705566, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.0061566587537527084, 'loss_2': 0.00479888916015625, 'loss_3': -16.414443969726562, 'loss_4': 0.26356568932533264, 'epoch': 13.55}
{'loss': 0.0227, 'grad_norm': 6.109518527984619, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.012152714654803276, 'loss_2': 0.01050567626953125, 'loss_3': -16.460176467895508, 'loss_4': 0.8066258430480957, 'epoch': 13.56}
{'loss': 0.017, 'grad_norm': 4.958316802978516, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.007446979638189077, 'loss_2': 0.009521484375, 'loss_3': -16.485857009887695, 'loss_4': 0.8403054475784302, 'epoch': 13.56}
{'loss': 0.0131, 'grad_norm': 4.852757453918457, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.006521501578390598, 'loss_2': 0.006565093994140625, 'loss_3': -16.51858139038086, 'loss_4': 0.6301552653312683, 'epoch': 13.57}
{'loss': 0.0168, 'grad_norm': 5.710298538208008, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.011558810248970985, 'loss_2': 0.0052642822265625, 'loss_3': -16.45372200012207, 'loss_4': 0.553270697593689, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 16:15:24,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:24,643 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [58:02<48:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:31,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011097360402345657, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007041097618639469, 'eval_loss_2': 0.004056263715028763, 'eval_loss_3': -18.258657455444336, 'eval_loss_4': 0.6327375173568726, 'epoch': 13.58}
{'loss': 0.0206, 'grad_norm': 8.028105735778809, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.02031623013317585, 'loss_2': 0.0002741813659667969, 'loss_3': -16.469215393066406, 'loss_4': 0.535250186920166, 'epoch': 13.58}
{'loss': 0.0082, 'grad_norm': 4.613559722900391, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.0056845094077289104, 'loss_2': 0.002506256103515625, 'loss_3': -16.683408737182617, 'loss_4': 0.656416654586792, 'epoch': 13.59}
{'loss': 0.0093, 'grad_norm': 4.760715961456299, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.007198152132332325, 'loss_2': 0.00213623046875, 'loss_3': -16.33930206298828, 'loss_4': 0.5297940969467163, 'epoch': 13.59}
{'loss': 0.0176, 'grad_norm': 5.7575178146362305, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.01093632634729147, 'loss_2': 0.00661468505859375, 'loss_3': -16.435901641845703, 'loss_4': 0.38170433044433594, 'epoch': 13.6}
{'loss': 0.0326, 'grad_norm': 13.480009078979492, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.03145544230937958, 'loss_2': 0.0011539459228515625, 'loss_3': -16.62926483154297, 'loss_4': 0.8869060277938843, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 16:15:31,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:31,995 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [58:10<48:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:39,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011094765737652779, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007286811713129282, 'eval_loss_2': 0.003807954490184784, 'eval_loss_3': -18.26453971862793, 'eval_loss_4': 0.5055726766586304, 'epoch': 13.6}
{'loss': 0.006, 'grad_norm': 4.593932151794434, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.004383593797683716, 'loss_2': 0.0015926361083984375, 'loss_3': -16.463756561279297, 'loss_4': 0.15159279108047485, 'epoch': 13.61}
{'loss': 0.0183, 'grad_norm': 11.619955062866211, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.017577704042196274, 'loss_2': 0.0007171630859375, 'loss_3': -16.437965393066406, 'loss_4': 0.6437097191810608, 'epoch': 13.62}
{'loss': 0.023, 'grad_norm': 6.053463935852051, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.014372630044817924, 'loss_2': 0.0086212158203125, 'loss_3': -16.616302490234375, 'loss_4': 0.06660051643848419, 'epoch': 13.62}
{'loss': 0.029, 'grad_norm': 7.204833030700684, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.02249053493142128, 'loss_2': 0.00646209716796875, 'loss_3': -16.479690551757812, 'loss_4': 0.403161883354187, 'epoch': 13.63}
{'loss': 0.0081, 'grad_norm': 5.577575206756592, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.00799555703997612, 'loss_2': 0.0001385211944580078, 'loss_3': -16.485145568847656, 'loss_4': 0.8953152894973755, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 16:15:39,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:39,348 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:17<48:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:46,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011079632677137852, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.578, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00761973112821579, 'eval_loss_2': 0.0034599006175994873, 'eval_loss_3': -18.27899932861328, 'eval_loss_4': 0.37014245986938477, 'epoch': 13.63}
{'loss': 0.0088, 'grad_norm': 5.434527397155762, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.006100042723119259, 'loss_2': 0.002704620361328125, 'loss_3': -16.477285385131836, 'loss_4': 1.0891292095184326, 'epoch': 13.64}
{'loss': 0.0118, 'grad_norm': 5.993868827819824, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.01119241863489151, 'loss_2': 0.0006499290466308594, 'loss_3': -16.4713077545166, 'loss_4': 0.44055429100990295, 'epoch': 13.65}
{'loss': 0.0225, 'grad_norm': 6.991768836975098, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.01440221443772316, 'loss_2': 0.008056640625, 'loss_3': -16.60572624206543, 'loss_4': 0.6039086580276489, 'epoch': 13.65}
{'loss': 0.0207, 'grad_norm': 9.043543815612793, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.016940034925937653, 'loss_2': 0.00371551513671875, 'loss_3': -16.368160247802734, 'loss_4': 0.21272103488445282, 'epoch': 13.66}
{'loss': 0.0304, 'grad_norm': 11.849396705627441, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.02289488911628723, 'loss_2': 0.0074615478515625, 'loss_3': -16.81551742553711, 'loss_4': 0.31285202503204346, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 16:15:46,700 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:46,700 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:24<48:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:54,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013303903862833977, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007839513942599297, 'eval_loss_2': 0.00546438992023468, 'eval_loss_3': -18.282880783081055, 'eval_loss_4': 0.1067906990647316, 'epoch': 13.66}
{'loss': 0.0095, 'grad_norm': 5.339015483856201, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.008247718214988708, 'loss_2': 0.001239776611328125, 'loss_3': -16.330799102783203, 'loss_4': 0.7746270895004272, 'epoch': 13.67}
{'loss': 0.0136, 'grad_norm': 7.846227169036865, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.012793664820492268, 'loss_2': 0.0008015632629394531, 'loss_3': -16.552677154541016, 'loss_4': 0.3706567883491516, 'epoch': 13.67}
{'loss': 0.0255, 'grad_norm': 8.104844093322754, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.02156272530555725, 'loss_2': 0.0039520263671875, 'loss_3': -16.487035751342773, 'loss_4': 0.27051639556884766, 'epoch': 13.68}
{'loss': 0.0333, 'grad_norm': 12.552346229553223, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.0274804700165987, 'loss_2': 0.005779266357421875, 'loss_3': -16.527708053588867, 'loss_4': -0.20865637063980103, 'epoch': 13.69}
{'loss': 0.0088, 'grad_norm': 4.854650020599365, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.008638186380267143, 'loss_2': 0.00020956993103027344, 'loss_3': -16.60647201538086, 'loss_4': 0.041361719369888306, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 16:15:54,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:54,053 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:32<48:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:01,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012051579542458057, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.461, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007494267076253891, 'eval_loss_2': 0.004557311534881592, 'eval_loss_3': -18.277469635009766, 'eval_loss_4': -0.07851983606815338, 'epoch': 13.69}
{'loss': 0.0073, 'grad_norm': 4.717287063598633, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.004972981754690409, 'loss_2': 0.00228118896484375, 'loss_3': -16.67603302001953, 'loss_4': 0.3236843943595886, 'epoch': 13.7}
{'loss': 0.0085, 'grad_norm': 5.529413223266602, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.007386641576886177, 'loss_2': 0.001064300537109375, 'loss_3': -16.390275955200195, 'loss_4': -0.2567565441131592, 'epoch': 13.7}
{'loss': 0.0205, 'grad_norm': 6.115149974822998, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.011073390021920204, 'loss_2': 0.00946044921875, 'loss_3': -16.55520248413086, 'loss_4': 0.48475027084350586, 'epoch': 13.71}
{'loss': 0.0195, 'grad_norm': 6.294027805328369, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.015487860888242722, 'loss_2': 0.00400543212890625, 'loss_3': -16.60511589050293, 'loss_4': 0.030432820320129395, 'epoch': 13.72}
{'loss': 0.0161, 'grad_norm': 6.032195091247559, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.00971639808267355, 'loss_2': 0.00634002685546875, 'loss_3': -16.571468353271484, 'loss_4': 0.7599700689315796, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 16:16:01,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:01,405 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:39<48:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:08,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014112483710050583, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.502, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0073206545785069466, 'eval_loss_2': 0.006791830062866211, 'eval_loss_3': -18.291996002197266, 'eval_loss_4': -0.32501405477523804, 'epoch': 13.72}
{'loss': 0.0217, 'grad_norm': 8.094329833984375, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.013533800840377808, 'loss_2': 0.008148193359375, 'loss_3': -16.407745361328125, 'loss_4': -0.08535827696323395, 'epoch': 13.73}
{'loss': 0.0185, 'grad_norm': 5.587211608886719, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.009966130368411541, 'loss_2': 0.00849151611328125, 'loss_3': -16.58144187927246, 'loss_4': 0.48705270886421204, 'epoch': 13.73}
{'loss': 0.0077, 'grad_norm': 4.916580677032471, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.007313532289117575, 'loss_2': 0.000396728515625, 'loss_3': -16.574783325195312, 'loss_4': -0.10875906050205231, 'epoch': 13.74}
{'loss': 0.0157, 'grad_norm': 5.797354698181152, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.008839515969157219, 'loss_2': 0.00690460205078125, 'loss_3': -16.59701919555664, 'loss_4': -0.32138577103614807, 'epoch': 13.74}
{'loss': 0.0119, 'grad_norm': 5.080350875854492, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.004879736341536045, 'loss_2': 0.007038116455078125, 'loss_3': -16.645856857299805, 'loss_4': -0.3049336373806, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 16:16:08,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:08,763 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:47<48:58,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:16:16,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010847877711057663, 'eval_runtime': 3.9819, 'eval_samples_per_second': 257.165, 'eval_steps_per_second': 4.018, 'eval_loss_1': 0.007040541153401136, 'eval_loss_2': 0.0038073360919952393, 'eval_loss_3': -18.296449661254883, 'eval_loss_4': -0.4640859067440033, 'epoch': 13.75}
{'loss': 0.0152, 'grad_norm': 4.463556289672852, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.004446614068001509, 'loss_2': 0.01070404052734375, 'loss_3': -16.63019561767578, 'loss_4': -0.6335869431495667, 'epoch': 13.76}
{'loss': 0.0074, 'grad_norm': 4.510904788970947, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.0049177431501448154, 'loss_2': 0.0025119781494140625, 'loss_3': -16.536975860595703, 'loss_4': -0.2728269696235657, 'epoch': 13.76}
{'loss': 0.0165, 'grad_norm': 5.304911136627197, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.008902659639716148, 'loss_2': 0.0075531005859375, 'loss_3': -16.430374145507812, 'loss_4': -0.05120353400707245, 'epoch': 13.77}
{'loss': 0.0659, 'grad_norm': 24.531179428100586, 'learning_rate': 1.625e-05, 'loss_1': 0.06452422589063644, 'loss_2': 0.0013856887817382812, 'loss_3': -16.599803924560547, 'loss_4': -0.3551482558250427, 'epoch': 13.77}
{'loss': 0.0193, 'grad_norm': 5.98819637298584, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.015506411902606487, 'loss_2': 0.00382232666015625, 'loss_3': -16.6668701171875, 'loss_4': -0.6383630037307739, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 16:16:16,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:16,298 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:54<48:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:23,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011421839706599712, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.8, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0072267744690179825, 'eval_loss_2': 0.004195064306259155, 'eval_loss_3': -18.289138793945312, 'eval_loss_4': -0.5531221628189087, 'epoch': 13.78}
{'loss': 0.0133, 'grad_norm': 5.6460089683532715, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.008803647011518478, 'loss_2': 0.0045318603515625, 'loss_3': -16.351165771484375, 'loss_4': -1.1950901746749878, 'epoch': 13.78}
{'loss': 0.006, 'grad_norm': 4.547270774841309, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.004845967050641775, 'loss_2': 0.0011920928955078125, 'loss_3': -16.551681518554688, 'loss_4': -0.20772817730903625, 'epoch': 13.79}
{'loss': 0.0083, 'grad_norm': 5.083517074584961, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.0039340234361588955, 'loss_2': 0.004367828369140625, 'loss_3': -16.52300262451172, 'loss_4': -0.09756726026535034, 'epoch': 13.8}
{'loss': 0.0152, 'grad_norm': 8.027271270751953, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.012995364144444466, 'loss_2': 0.002216339111328125, 'loss_3': -16.605384826660156, 'loss_4': -0.6548999547958374, 'epoch': 13.8}
{'loss': 0.0226, 'grad_norm': 10.827716827392578, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.018534818664193153, 'loss_2': 0.00408935546875, 'loss_3': -16.490230560302734, 'loss_4': -0.32676106691360474, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 16:16:23,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:23,642 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [59:01<48:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:31,008 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009475034661591053, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006277930457144976, 'eval_loss_2': 0.00319710373878479, 'eval_loss_3': -18.299955368041992, 'eval_loss_4': -0.5165072679519653, 'epoch': 13.81}
{'loss': 0.0456, 'grad_norm': 25.74997901916504, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.04454626888036728, 'loss_2': 0.001033782958984375, 'loss_3': -16.42654800415039, 'loss_4': -0.1272703856229782, 'epoch': 13.81}
{'loss': 0.0194, 'grad_norm': 12.718363761901855, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.016914837062358856, 'loss_2': 0.002498626708984375, 'loss_3': -16.686628341674805, 'loss_4': -0.16667649149894714, 'epoch': 13.82}
{'loss': 0.0421, 'grad_norm': 19.541500091552734, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.04115508869290352, 'loss_2': 0.0009698867797851562, 'loss_3': -16.356212615966797, 'loss_4': -0.5208441019058228, 'epoch': 13.83}
{'loss': 0.0271, 'grad_norm': 14.211191177368164, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.026890983805060387, 'loss_2': 0.00019478797912597656, 'loss_3': -16.511394500732422, 'loss_4': -0.8745678663253784, 'epoch': 13.83}
{'loss': 0.0246, 'grad_norm': 12.7390775680542, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.023239118978381157, 'loss_2': 0.0013256072998046875, 'loss_3': -16.63193702697754, 'loss_4': -0.5154491662979126, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 16:16:31,008 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:31,008 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [59:09<48:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:38,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009528473019599915, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.579, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006897390354424715, 'eval_loss_2': 0.002631083130836487, 'eval_loss_3': -18.26958656311035, 'eval_loss_4': -0.5215765237808228, 'epoch': 13.84}
{'loss': 0.0136, 'grad_norm': 5.869601726531982, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.007433888502418995, 'loss_2': 0.006134033203125, 'loss_3': -16.58496856689453, 'loss_4': -0.3714689016342163, 'epoch': 13.84}
{'loss': 0.0185, 'grad_norm': 5.253545761108398, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.0124940425157547, 'loss_2': 0.00605010986328125, 'loss_3': -16.44009017944336, 'loss_4': -0.48482465744018555, 'epoch': 13.85}
{'loss': 0.0207, 'grad_norm': 9.370224952697754, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.015056908130645752, 'loss_2': 0.00563812255859375, 'loss_3': -16.48544692993164, 'loss_4': -0.5519630312919617, 'epoch': 13.85}
{'loss': 0.0104, 'grad_norm': 4.470331192016602, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.004439268261194229, 'loss_2': 0.00597381591796875, 'loss_3': -16.509010314941406, 'loss_4': -0.4088905155658722, 'epoch': 13.86}
{'loss': 0.016, 'grad_norm': 5.7095441818237305, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.013599433936178684, 'loss_2': 0.0023651123046875, 'loss_3': -16.361276626586914, 'loss_4': -0.42970725893974304, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 16:16:38,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:38,357 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:16<47:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:45,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011296221986413002, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.447, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007715897634625435, 'eval_loss_2': 0.003580324351787567, 'eval_loss_3': -18.258338928222656, 'eval_loss_4': -0.39069628715515137, 'epoch': 13.87}
{'loss': 0.0217, 'grad_norm': 6.733480930328369, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.014802709221839905, 'loss_2': 0.00691986083984375, 'loss_3': -16.398929595947266, 'loss_4': -0.6625456809997559, 'epoch': 13.87}
{'loss': 0.0245, 'grad_norm': 9.210068702697754, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.023477094247937202, 'loss_2': 0.0010347366333007812, 'loss_3': -16.469829559326172, 'loss_4': -0.3462105691432953, 'epoch': 13.88}
{'loss': 0.0145, 'grad_norm': 8.328230857849121, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.013981944881379604, 'loss_2': 0.0005121231079101562, 'loss_3': -16.388450622558594, 'loss_4': -0.1788199245929718, 'epoch': 13.88}
{'loss': 0.0112, 'grad_norm': 7.214520454406738, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.0088735893368721, 'loss_2': 0.00229644775390625, 'loss_3': -16.548357009887695, 'loss_4': -0.6580921411514282, 'epoch': 13.89}
{'loss': 0.0146, 'grad_norm': 9.975028991699219, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.009888206608593464, 'loss_2': 0.00469970703125, 'loss_3': -16.592124938964844, 'loss_4': -0.7532229423522949, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 16:16:45,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:45,701 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:23<47:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:53,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010945215821266174, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.53, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007895923219621181, 'eval_loss_2': 0.003049291670322418, 'eval_loss_3': -18.237098693847656, 'eval_loss_4': -0.3244980573654175, 'epoch': 13.9}
{'loss': 0.0132, 'grad_norm': 7.069037914276123, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.011205030605196953, 'loss_2': 0.001953125, 'loss_3': -16.408672332763672, 'loss_4': -0.7711703181266785, 'epoch': 13.9}
{'loss': 0.0108, 'grad_norm': 4.790672779083252, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.010182921774685383, 'loss_2': 0.0006351470947265625, 'loss_3': -16.66387176513672, 'loss_4': -1.0525543689727783, 'epoch': 13.91}
{'loss': 0.0099, 'grad_norm': 5.26497745513916, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.0032931470777839422, 'loss_2': 0.006561279296875, 'loss_3': -16.532894134521484, 'loss_4': -0.09810484945774078, 'epoch': 13.91}
{'loss': 0.0092, 'grad_norm': 5.245369911193848, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.00891523715108633, 'loss_2': 0.00026035308837890625, 'loss_3': -16.364513397216797, 'loss_4': -0.6657382249832153, 'epoch': 13.92}
{'loss': 0.0092, 'grad_norm': 4.821162223815918, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.006949602626264095, 'loss_2': 0.0022487640380859375, 'loss_3': -16.54836654663086, 'loss_4': -0.420104444026947, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 16:16:53,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:53,049 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:31<47:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:00,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011591672897338867, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00851853284984827, 'eval_loss_2': 0.0030731409788131714, 'eval_loss_3': -18.224491119384766, 'eval_loss_4': -0.1982157677412033, 'epoch': 13.92}
{'loss': 0.0077, 'grad_norm': 5.66875696182251, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.004839358385652304, 'loss_2': 0.002834320068359375, 'loss_3': -16.620609283447266, 'loss_4': -0.3537619113922119, 'epoch': 13.93}
{'loss': 0.0122, 'grad_norm': 5.917176723480225, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.008362236432731152, 'loss_2': 0.003795623779296875, 'loss_3': -16.458749771118164, 'loss_4': -0.5626493096351624, 'epoch': 13.94}
{'loss': 0.0086, 'grad_norm': 5.006577491760254, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.007316639646887779, 'loss_2': 0.0012989044189453125, 'loss_3': -16.3372859954834, 'loss_4': -0.5080174207687378, 'epoch': 13.94}
{'loss': 0.008, 'grad_norm': 4.3292694091796875, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.0035202528815716505, 'loss_2': 0.004486083984375, 'loss_3': -16.537883758544922, 'loss_4': -0.5064006447792053, 'epoch': 13.95}
{'loss': 0.0089, 'grad_norm': 5.095008373260498, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.005631306674331427, 'loss_2': 0.00323486328125, 'loss_3': -16.658218383789062, 'loss_4': -0.33692675828933716, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 16:17:00,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:00,407 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:38<47:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:07,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012522438541054726, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.952, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009907403960824013, 'eval_loss_2': 0.002615034580230713, 'eval_loss_3': -18.20435333251953, 'eval_loss_4': 0.013962971977889538, 'epoch': 13.95}
{'loss': 0.0121, 'grad_norm': 6.02449893951416, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.010085420683026314, 'loss_2': 0.002010345458984375, 'loss_3': -16.313325881958008, 'loss_4': -0.01366022601723671, 'epoch': 13.96}
{'loss': 0.0159, 'grad_norm': 6.943228244781494, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.010195323266088963, 'loss_2': 0.005706787109375, 'loss_3': -16.44281768798828, 'loss_4': 0.19356991350650787, 'epoch': 13.97}
{'loss': 0.0096, 'grad_norm': 4.720643043518066, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.004927743226289749, 'loss_2': 0.004638671875, 'loss_3': -16.370668411254883, 'loss_4': 0.06202875077724457, 'epoch': 13.97}
{'loss': 0.0075, 'grad_norm': 5.063817501068115, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.006548916455358267, 'loss_2': 0.0009560585021972656, 'loss_3': -16.666318893432617, 'loss_4': 0.4506962299346924, 'epoch': 13.98}
{'loss': 0.0158, 'grad_norm': 5.589229583740234, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.008829783648252487, 'loss_2': 0.006954193115234375, 'loss_3': -16.415489196777344, 'loss_4': 0.26494544744491577, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 16:17:07,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:07,774 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:45<45:45,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 16:17:14,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014045963063836098, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012087005190551281, 'eval_loss_2': 0.0019589588046073914, 'eval_loss_3': -18.160781860351562, 'eval_loss_4': 0.19983424246311188, 'epoch': 13.98}
{'loss': 0.0265, 'grad_norm': 9.937174797058105, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.018352439627051353, 'loss_2': 0.0081939697265625, 'loss_3': -16.41679573059082, 'loss_4': 0.08774492144584656, 'epoch': 13.99}
{'loss': 0.0167, 'grad_norm': 10.077153205871582, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.015035267919301987, 'loss_2': 0.001651763916015625, 'loss_3': -16.554134368896484, 'loss_4': 0.143382266163826, 'epoch': 13.99}
{'loss': 0.0083, 'grad_norm': 6.022511005401611, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.003161222906783223, 'loss_2': 0.005157470703125, 'loss_3': -16.851001739501953, 'loss_4': -0.19270652532577515, 'epoch': 14.0}
{'loss': 0.0138, 'grad_norm': 7.054908275604248, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.013741930015385151, 'loss_2': 3.838539123535156e-05, 'loss_3': -16.440948486328125, 'loss_4': 0.05553365498781204, 'epoch': 14.01}
{'loss': 0.0188, 'grad_norm': 8.48071575164795, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.015307808294892311, 'loss_2': 0.003448486328125, 'loss_3': -16.533893585205078, 'loss_4': 0.26512420177459717, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 16:17:14,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:14,822 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:53<47:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:17:22,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018748993054032326, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016308344900608063, 'eval_loss_2': 0.0024406462907791138, 'eval_loss_3': -18.131057739257812, 'eval_loss_4': 0.33273980021476746, 'epoch': 14.01}
{'loss': 0.0071, 'grad_norm': 4.359931945800781, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.004856093320995569, 'loss_2': 0.0022258758544921875, 'loss_3': -16.38684844970703, 'loss_4': 0.4933454394340515, 'epoch': 14.02}
{'loss': 0.0101, 'grad_norm': 5.36708927154541, 'learning_rate': 1.6e-05, 'loss_1': 0.0085782241076231, 'loss_2': 0.0015048980712890625, 'loss_3': -16.530733108520508, 'loss_4': 0.7736994624137878, 'epoch': 14.02}
{'loss': 0.0085, 'grad_norm': 5.274661064147949, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.006445616018027067, 'loss_2': 0.002101898193359375, 'loss_3': -16.45783805847168, 'loss_4': 0.3830605447292328, 'epoch': 14.03}
{'loss': 0.0158, 'grad_norm': 7.216529369354248, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.013897680677473545, 'loss_2': 0.0019330978393554688, 'loss_3': -16.252147674560547, 'loss_4': 0.2502014935016632, 'epoch': 14.03}
{'loss': 0.0083, 'grad_norm': 5.162208557128906, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.007938490249216557, 'loss_2': 0.0003294944763183594, 'loss_3': -16.389020919799805, 'loss_4': 0.480954110622406, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 16:17:22,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:22,170 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                    | 2420/5160 [1:00:00<47:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:29,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024511266499757767, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.327, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.021459167823195457, 'eval_loss_2': 0.00305209681391716, 'eval_loss_3': -18.115428924560547, 'eval_loss_4': 0.49300241470336914, 'epoch': 14.04}
{'loss': 0.0317, 'grad_norm': 18.131620407104492, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.028873605653643608, 'loss_2': 0.002864837646484375, 'loss_3': -16.533138275146484, 'loss_4': 0.28885364532470703, 'epoch': 14.05}
{'loss': 0.0237, 'grad_norm': 11.944646835327148, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.019042277708649635, 'loss_2': 0.00466156005859375, 'loss_3': -16.38235855102539, 'loss_4': 0.6604980826377869, 'epoch': 14.05}
{'loss': 0.0155, 'grad_norm': 6.993315696716309, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.013799838721752167, 'loss_2': 0.00168609619140625, 'loss_3': -16.478961944580078, 'loss_4': 0.18152625858783722, 'epoch': 14.06}
{'loss': 0.0114, 'grad_norm': 6.7178544998168945, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.010037168860435486, 'loss_2': 0.0013332366943359375, 'loss_3': -16.28993797302246, 'loss_4': 0.6462960839271545, 'epoch': 14.06}
{'loss': 0.0205, 'grad_norm': 6.489872932434082, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.013662396930158138, 'loss_2': 0.00684356689453125, 'loss_3': -16.189451217651367, 'loss_4': 0.18999211490154266, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 16:17:29,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:29,524 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 2425/5160 [1:00:07<47:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:36,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023098690435290337, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.019912539049983025, 'eval_loss_2': 0.003186151385307312, 'eval_loss_3': -18.11920166015625, 'eval_loss_4': 0.5279247760772705, 'epoch': 14.07}
{'loss': 0.0178, 'grad_norm': 9.573793411254883, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.016124939545989037, 'loss_2': 0.0016422271728515625, 'loss_3': -16.394346237182617, 'loss_4': 0.5372075438499451, 'epoch': 14.08}
{'loss': 0.0078, 'grad_norm': 4.345682621002197, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.005395510233938694, 'loss_2': 0.002422332763671875, 'loss_3': -16.172420501708984, 'loss_4': 0.6000430583953857, 'epoch': 14.08}
{'loss': 0.0061, 'grad_norm': 5.539799690246582, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.005328299477696419, 'loss_2': 0.0007839202880859375, 'loss_3': -16.413223266601562, 'loss_4': 0.3796194791793823, 'epoch': 14.09}
{'loss': 0.0194, 'grad_norm': 10.919111251831055, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.013939769938588142, 'loss_2': 0.00543975830078125, 'loss_3': -16.39783477783203, 'loss_4': -0.11884213984012604, 'epoch': 14.09}
{'loss': 0.0103, 'grad_norm': 4.892127990722656, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.004376888740807772, 'loss_2': 0.005878448486328125, 'loss_3': -16.46719741821289, 'loss_4': -0.07084782421588898, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 16:17:36,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:36,890 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:15<47:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:44,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01534315012395382, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.229, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011186405085027218, 'eval_loss_2': 0.004156745970249176, 'eval_loss_3': -18.1954402923584, 'eval_loss_4': 0.3546179234981537, 'epoch': 14.1}
{'loss': 0.0852, 'grad_norm': 13.375449180603027, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.08443693071603775, 'loss_2': 0.0007982254028320312, 'loss_3': -16.40477752685547, 'loss_4': 0.6217396259307861, 'epoch': 14.1}
{'loss': 0.0118, 'grad_norm': 5.454744338989258, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.007490717340260744, 'loss_2': 0.00435638427734375, 'loss_3': -16.39000701904297, 'loss_4': -0.25882747769355774, 'epoch': 14.11}
{'loss': 0.014, 'grad_norm': 5.234091281890869, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.01058801356703043, 'loss_2': 0.00345611572265625, 'loss_3': -16.50782585144043, 'loss_4': 0.19578951597213745, 'epoch': 14.12}
{'loss': 0.0104, 'grad_norm': 5.578176498413086, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.00784812867641449, 'loss_2': 0.002552032470703125, 'loss_3': -16.49966812133789, 'loss_4': 0.015389956533908844, 'epoch': 14.12}
{'loss': 0.0082, 'grad_norm': 4.830835819244385, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.006509208120405674, 'loss_2': 0.0017242431640625, 'loss_3': -16.456037521362305, 'loss_4': 0.14403869211673737, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 16:17:44,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:44,244 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:22<47:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:51,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0141356335952878, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.7, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010705526918172836, 'eval_loss_2': 0.003430105745792389, 'eval_loss_3': -18.22753143310547, 'eval_loss_4': 0.19388674199581146, 'epoch': 14.13}
{'loss': 0.0117, 'grad_norm': 6.522809028625488, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.010940153151750565, 'loss_2': 0.0007238388061523438, 'loss_3': -16.517589569091797, 'loss_4': 0.14460359513759613, 'epoch': 14.13}
{'loss': 0.01, 'grad_norm': 6.1801300048828125, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.009301193058490753, 'loss_2': 0.0007085800170898438, 'loss_3': -16.390256881713867, 'loss_4': -0.21807861328125, 'epoch': 14.14}
{'loss': 0.0142, 'grad_norm': 8.235913276672363, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.010142882354557514, 'loss_2': 0.00405120849609375, 'loss_3': -16.28917121887207, 'loss_4': 0.20473942160606384, 'epoch': 14.15}
{'loss': 0.0089, 'grad_norm': 5.610457420349121, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.00797564722597599, 'loss_2': 0.0009059906005859375, 'loss_3': -16.715736389160156, 'loss_4': 0.02238468825817108, 'epoch': 14.15}
{'loss': 0.0163, 'grad_norm': 9.440382957458496, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.012099572457373142, 'loss_2': 0.00421142578125, 'loss_3': -16.28615379333496, 'loss_4': -0.4659056067466736, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 16:17:51,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:51,606 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:29<47:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:58,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011342344805598259, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008610307238996029, 'eval_loss_2': 0.0027320384979248047, 'eval_loss_3': -18.269065856933594, 'eval_loss_4': 0.052863746881484985, 'epoch': 14.16}
{'loss': 0.016, 'grad_norm': 7.75092077255249, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.013723093084990978, 'loss_2': 0.002307891845703125, 'loss_3': -16.24502944946289, 'loss_4': -0.17068696022033691, 'epoch': 14.16}
{'loss': 0.0304, 'grad_norm': 12.190025329589844, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.027636392042040825, 'loss_2': 0.002719879150390625, 'loss_3': -16.506460189819336, 'loss_4': 0.1967369019985199, 'epoch': 14.17}
{'loss': 0.0197, 'grad_norm': 5.176624774932861, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.008769458159804344, 'loss_2': 0.01093292236328125, 'loss_3': -16.527347564697266, 'loss_4': -0.2722081243991852, 'epoch': 14.17}
{'loss': 0.0083, 'grad_norm': 4.970340251922607, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.005986981559544802, 'loss_2': 0.0023593902587890625, 'loss_3': -16.648876190185547, 'loss_4': -0.45563381910324097, 'epoch': 14.18}
{'loss': 0.0106, 'grad_norm': 7.074185371398926, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.010538443922996521, 'loss_2': 9.417533874511719e-05, 'loss_3': -16.61322784423828, 'loss_4': 0.23763765394687653, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 16:17:58,967 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:58,967 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:37<47:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:06,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012089835479855537, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009516747668385506, 'eval_loss_2': 0.0025730878114700317, 'eval_loss_3': -18.308433532714844, 'eval_loss_4': 0.004209303297102451, 'epoch': 14.19}
{'loss': 0.0203, 'grad_norm': 11.381295204162598, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.018145903944969177, 'loss_2': 0.00214385986328125, 'loss_3': -16.516033172607422, 'loss_4': 0.06740117818117142, 'epoch': 14.19}
{'loss': 0.0157, 'grad_norm': 8.802806854248047, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.0146654536947608, 'loss_2': 0.001071929931640625, 'loss_3': -16.532794952392578, 'loss_4': 0.11865735054016113, 'epoch': 14.2}
{'loss': 0.0169, 'grad_norm': 5.568604946136475, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.010993728414177895, 'loss_2': 0.00589752197265625, 'loss_3': -16.63641357421875, 'loss_4': 0.020584329962730408, 'epoch': 14.2}
{'loss': 0.0125, 'grad_norm': 5.496371746063232, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.009989663027226925, 'loss_2': 0.0025272369384765625, 'loss_3': -16.463542938232422, 'loss_4': 0.6837371587753296, 'epoch': 14.21}
{'loss': 0.0208, 'grad_norm': 6.916947841644287, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.01597798988223076, 'loss_2': 0.00482940673828125, 'loss_3': -16.486177444458008, 'loss_4': 0.4395979046821594, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 16:18:06,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:06,321 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:44<46:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:13,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013161561451852322, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01006721705198288, 'eval_loss_2': 0.0030943453311920166, 'eval_loss_3': -18.34237289428711, 'eval_loss_4': 0.08262966573238373, 'epoch': 14.22}
{'loss': 0.0186, 'grad_norm': 6.450344085693359, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.016550619155168533, 'loss_2': 0.002017974853515625, 'loss_3': -16.49310874938965, 'loss_4': -0.09510134905576706, 'epoch': 14.22}
{'loss': 0.0249, 'grad_norm': 7.304107666015625, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.020956402644515038, 'loss_2': 0.0039825439453125, 'loss_3': -16.53831672668457, 'loss_4': 0.2634100317955017, 'epoch': 14.23}
{'loss': 0.0398, 'grad_norm': 17.863075256347656, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.031782183796167374, 'loss_2': 0.0080108642578125, 'loss_3': -16.426057815551758, 'loss_4': 0.14168983697891235, 'epoch': 14.23}
{'loss': 0.0176, 'grad_norm': 6.681728363037109, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.013462560251355171, 'loss_2': 0.004108428955078125, 'loss_3': -16.674365997314453, 'loss_4': 0.28188440203666687, 'epoch': 14.24}
{'loss': 0.0903, 'grad_norm': 12.008370399475098, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.0790172889828682, 'loss_2': 0.01131439208984375, 'loss_3': -16.770145416259766, 'loss_4': 0.4204445481300354, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 16:18:13,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:13,675 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:51<46:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:21,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01532651111483574, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01281816978007555, 'eval_loss_2': 0.0025083422660827637, 'eval_loss_3': -18.383094787597656, 'eval_loss_4': 0.15181592106819153, 'epoch': 14.24}
{'loss': 0.0285, 'grad_norm': 8.408976554870605, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.024007029831409454, 'loss_2': 0.004459381103515625, 'loss_3': -16.554166793823242, 'loss_4': -0.03017812967300415, 'epoch': 14.25}
{'loss': 0.0119, 'grad_norm': 5.079833030700684, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.010241187177598476, 'loss_2': 0.0016489028930664062, 'loss_3': -16.631105422973633, 'loss_4': 0.34781426191329956, 'epoch': 14.26}
{'loss': 0.0269, 'grad_norm': 8.8522367477417, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.02533268928527832, 'loss_2': 0.001613616943359375, 'loss_3': -16.717880249023438, 'loss_4': -0.09279933571815491, 'epoch': 14.26}
{'loss': 0.0336, 'grad_norm': 12.538515090942383, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.028059760108590126, 'loss_2': 0.00550079345703125, 'loss_3': -16.718299865722656, 'loss_4': 0.23131804168224335, 'epoch': 14.27}
{'loss': 0.021, 'grad_norm': 6.6830315589904785, 'learning_rate': 1.575e-05, 'loss_1': 0.01991376094520092, 'loss_2': 0.0010728836059570312, 'loss_3': -16.726211547851562, 'loss_4': 0.024754587560892105, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 16:18:21,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:21,033 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:59<46:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:28,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016562659293413162, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.919, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013872281648218632, 'eval_loss_2': 0.0026903748512268066, 'eval_loss_3': -18.38729476928711, 'eval_loss_4': 0.04968435317277908, 'epoch': 14.27}
{'loss': 0.0182, 'grad_norm': 7.575178623199463, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.016186755150556564, 'loss_2': 0.0020294189453125, 'loss_3': -16.689788818359375, 'loss_4': 0.14650468528270721, 'epoch': 14.28}
{'loss': 0.0348, 'grad_norm': 10.797080993652344, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.03004296123981476, 'loss_2': 0.0047454833984375, 'loss_3': -16.878206253051758, 'loss_4': -0.09731774032115936, 'epoch': 14.28}
{'loss': 0.0264, 'grad_norm': 7.420451641082764, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.020198680460453033, 'loss_2': 0.00616455078125, 'loss_3': -16.56390953063965, 'loss_4': 0.4064095616340637, 'epoch': 14.29}
{'loss': 0.0283, 'grad_norm': 8.68616771697998, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.023300733417272568, 'loss_2': 0.005001068115234375, 'loss_3': -16.687179565429688, 'loss_4': -0.07912859320640564, 'epoch': 14.3}
{'loss': 0.0481, 'grad_norm': 17.388425827026367, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.04679034650325775, 'loss_2': 0.0013256072998046875, 'loss_3': -16.689666748046875, 'loss_4': -0.5275004506111145, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 16:18:28,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:28,397 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:01:06<46:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:35,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01686996780335903, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014417476020753384, 'eval_loss_2': 0.0024524927139282227, 'eval_loss_3': -18.34612274169922, 'eval_loss_4': 0.023309847339987755, 'epoch': 14.3}
{'loss': 0.0342, 'grad_norm': 14.164852142333984, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.03339775279164314, 'loss_2': 0.0008416175842285156, 'loss_3': -16.56134033203125, 'loss_4': -0.291007399559021, 'epoch': 14.31}
{'loss': 0.0177, 'grad_norm': 6.603730201721191, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.01747080124914646, 'loss_2': 0.0002651214599609375, 'loss_3': -16.69548225402832, 'loss_4': -0.01965433359146118, 'epoch': 14.31}
{'loss': 0.0176, 'grad_norm': 6.061832904815674, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.015494165010750294, 'loss_2': 0.00208282470703125, 'loss_3': -16.67002296447754, 'loss_4': 0.22224754095077515, 'epoch': 14.32}
{'loss': 0.0203, 'grad_norm': 9.784271240234375, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.01910354383289814, 'loss_2': 0.0012445449829101562, 'loss_3': -16.729875564575195, 'loss_4': 0.3657306134700775, 'epoch': 14.33}
{'loss': 0.0296, 'grad_norm': 8.51616382598877, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.02588779851794243, 'loss_2': 0.003688812255859375, 'loss_3': -16.477949142456055, 'loss_4': -0.1895679235458374, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 16:18:35,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:35,753 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:01:13<46:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:43,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017265336588025093, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01475429441779852, 'eval_loss_2': 0.00251103937625885, 'eval_loss_3': -18.336143493652344, 'eval_loss_4': 0.16528794169425964, 'epoch': 14.33}
{'loss': 0.0208, 'grad_norm': 9.680340766906738, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.01649540662765503, 'loss_2': 0.004283905029296875, 'loss_3': -16.630905151367188, 'loss_4': -0.18335719406604767, 'epoch': 14.34}
{'loss': 0.0369, 'grad_norm': 12.577530860900879, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.028954049572348595, 'loss_2': 0.00792694091796875, 'loss_3': -16.55126190185547, 'loss_4': 0.8183326721191406, 'epoch': 14.34}
{'loss': 0.0171, 'grad_norm': 5.066114902496338, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.010364842601120472, 'loss_2': 0.00669097900390625, 'loss_3': -16.680150985717773, 'loss_4': 0.22252941131591797, 'epoch': 14.35}
{'loss': 0.0242, 'grad_norm': 8.12719440460205, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.01641269400715828, 'loss_2': 0.00783538818359375, 'loss_3': -16.762845993041992, 'loss_4': -0.1288861185312271, 'epoch': 14.35}
{'loss': 0.0138, 'grad_norm': 4.7014479637146, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.007737572770565748, 'loss_2': 0.0060577392578125, 'loss_3': -16.67264175415039, 'loss_4': 0.12563470005989075, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 16:18:43,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:43,107 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:21<46:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:50,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016924455761909485, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014426963403820992, 'eval_loss_2': 0.0024974942207336426, 'eval_loss_3': -18.331472396850586, 'eval_loss_4': 0.3639666438102722, 'epoch': 14.36}
{'loss': 0.0132, 'grad_norm': 4.915073394775391, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.012170295231044292, 'loss_2': 0.0010395050048828125, 'loss_3': -16.53013801574707, 'loss_4': 0.29586607217788696, 'epoch': 14.37}
{'loss': 0.0165, 'grad_norm': 5.8010687828063965, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.013097898103296757, 'loss_2': 0.003383636474609375, 'loss_3': -16.525959014892578, 'loss_4': 0.3678070902824402, 'epoch': 14.37}
{'loss': 0.0182, 'grad_norm': 5.552033424377441, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.011755564250051975, 'loss_2': 0.006465911865234375, 'loss_3': -16.782243728637695, 'loss_4': 0.14501425623893738, 'epoch': 14.38}
{'loss': 0.0067, 'grad_norm': 4.86378812789917, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.006321569439023733, 'loss_2': 0.0003628730773925781, 'loss_3': -16.384729385375977, 'loss_4': 0.12207208573818207, 'epoch': 14.38}
{'loss': 0.0169, 'grad_norm': 6.522879600524902, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.014150507748126984, 'loss_2': 0.0027866363525390625, 'loss_3': -16.613685607910156, 'loss_4': -0.022799521684646606, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 16:18:50,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:50,463 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:28<46:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:57,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01566559076309204, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013372722081840038, 'eval_loss_2': 0.0022928714752197266, 'eval_loss_3': -18.28536605834961, 'eval_loss_4': 0.41496968269348145, 'epoch': 14.39}
{'loss': 0.0153, 'grad_norm': 5.727719306945801, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.014925100840628147, 'loss_2': 0.00035762786865234375, 'loss_3': -16.55166244506836, 'loss_4': 0.6019226312637329, 'epoch': 14.4}
{'loss': 0.0178, 'grad_norm': 6.739552974700928, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.01729360967874527, 'loss_2': 0.0005445480346679688, 'loss_3': -16.487253189086914, 'loss_4': 0.2029799222946167, 'epoch': 14.4}
{'loss': 0.0219, 'grad_norm': 12.860639572143555, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.0191908348351717, 'loss_2': 0.0026874542236328125, 'loss_3': -16.537845611572266, 'loss_4': -0.0019540078938007355, 'epoch': 14.41}
{'loss': 0.0205, 'grad_norm': 9.208568572998047, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.019157160073518753, 'loss_2': 0.0013666152954101562, 'loss_3': -16.747665405273438, 'loss_4': 0.3402513563632965, 'epoch': 14.41}
{'loss': 0.0075, 'grad_norm': 5.331269264221191, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.006555784493684769, 'loss_2': 0.0009450912475585938, 'loss_3': -16.48556137084961, 'loss_4': 0.37631797790527344, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 16:18:57,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:57,816 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:36<46:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:05,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015573089942336082, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012699485756456852, 'eval_loss_2': 0.002873603254556656, 'eval_loss_3': -18.270166397094727, 'eval_loss_4': 0.46659019589424133, 'epoch': 14.42}
{'loss': 0.0207, 'grad_norm': 8.99294376373291, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.01785368099808693, 'loss_2': 0.00286102294921875, 'loss_3': -16.722618103027344, 'loss_4': 0.04430317506194115, 'epoch': 14.42}
{'loss': 0.0128, 'grad_norm': 5.010319709777832, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.009201155975461006, 'loss_2': 0.00360870361328125, 'loss_3': -16.700607299804688, 'loss_4': 0.8872450590133667, 'epoch': 14.43}
{'loss': 0.0278, 'grad_norm': 16.47430419921875, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.021460682153701782, 'loss_2': 0.006378173828125, 'loss_3': -16.568069458007812, 'loss_4': 0.6519185304641724, 'epoch': 14.44}
{'loss': 0.0143, 'grad_norm': 6.21938419342041, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.01393052376806736, 'loss_2': 0.0003616809844970703, 'loss_3': -16.463764190673828, 'loss_4': 0.6931674480438232, 'epoch': 14.44}
{'loss': 0.0166, 'grad_norm': 6.160918712615967, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.011116682551801205, 'loss_2': 0.00545501708984375, 'loss_3': -16.579700469970703, 'loss_4': 1.300689458847046, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 16:19:05,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:05,184 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:43<46:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:12,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013837904669344425, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.422, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.010913045145571232, 'eval_loss_2': 0.0029248595237731934, 'eval_loss_3': -18.238216400146484, 'eval_loss_4': 0.5569421648979187, 'epoch': 14.45}
{'loss': 0.014, 'grad_norm': 7.419057369232178, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.013663237914443016, 'loss_2': 0.00032901763916015625, 'loss_3': -16.363550186157227, 'loss_4': 0.7335597276687622, 'epoch': 14.45}
{'loss': 0.0229, 'grad_norm': 11.699234962463379, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.020573008805513382, 'loss_2': 0.002323150634765625, 'loss_3': -16.55166244506836, 'loss_4': 0.09677429497241974, 'epoch': 14.46}
{'loss': 0.0095, 'grad_norm': 7.234051704406738, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.00941148865967989, 'loss_2': 0.00010603666305541992, 'loss_3': -16.556785583496094, 'loss_4': 0.5417691469192505, 'epoch': 14.47}
{'loss': 0.0296, 'grad_norm': 22.348735809326172, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.026477759703993797, 'loss_2': 0.0030975341796875, 'loss_3': -16.428083419799805, 'loss_4': 0.3223510980606079, 'epoch': 14.47}
{'loss': 0.0113, 'grad_norm': 4.741028308868408, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.00783612485975027, 'loss_2': 0.003490447998046875, 'loss_3': -16.486953735351562, 'loss_4': 0.5722897052764893, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 16:19:12,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:12,558 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:50<46:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:19,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013376682996749878, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.959, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010791569948196411, 'eval_loss_2': 0.002585113048553467, 'eval_loss_3': -18.236040115356445, 'eval_loss_4': 0.6044940948486328, 'epoch': 14.48}
{'loss': 0.0183, 'grad_norm': 14.415542602539062, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.010789814405143261, 'loss_2': 0.0075225830078125, 'loss_3': -16.3448486328125, 'loss_4': 0.4993829131126404, 'epoch': 14.48}
{'loss': 0.0272, 'grad_norm': 18.466571807861328, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.023226836696267128, 'loss_2': 0.00397491455078125, 'loss_3': -16.533954620361328, 'loss_4': 0.7051042318344116, 'epoch': 14.49}
{'loss': 0.0307, 'grad_norm': 13.632688522338867, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.022007543593645096, 'loss_2': 0.00870513916015625, 'loss_3': -16.364215850830078, 'loss_4': 0.7346929311752319, 'epoch': 14.49}
{'loss': 0.0182, 'grad_norm': 5.365159511566162, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.007653918117284775, 'loss_2': 0.010589599609375, 'loss_3': -16.411834716796875, 'loss_4': 0.5398634076118469, 'epoch': 14.5}
{'loss': 0.0078, 'grad_norm': 5.407674789428711, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.006596601102501154, 'loss_2': 0.0012359619140625, 'loss_3': -16.486961364746094, 'loss_4': 0.757318377494812, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 16:19:19,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:19,916 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:58<46:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:27,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013805483467876911, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.268, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011672628112137318, 'eval_loss_2': 0.0021328553557395935, 'eval_loss_3': -18.196393966674805, 'eval_loss_4': 0.7298799753189087, 'epoch': 14.51}
{'loss': 0.0137, 'grad_norm': 8.16853141784668, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.013162055052816868, 'loss_2': 0.0005559921264648438, 'loss_3': -16.416881561279297, 'loss_4': 1.0043294429779053, 'epoch': 14.51}
{'loss': 0.0059, 'grad_norm': 4.967957973480225, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.004765183199197054, 'loss_2': 0.0010890960693359375, 'loss_3': -16.322519302368164, 'loss_4': 1.174716591835022, 'epoch': 14.52}
{'loss': 0.0191, 'grad_norm': 5.000028133392334, 'learning_rate': 1.55e-05, 'loss_1': 0.011702228337526321, 'loss_2': 0.007358551025390625, 'loss_3': -16.39396095275879, 'loss_4': 0.6838322281837463, 'epoch': 14.52}
{'loss': 0.011, 'grad_norm': 5.8663153648376465, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.010856938548386097, 'loss_2': 0.00013017654418945312, 'loss_3': -16.523540496826172, 'loss_4': 0.2767500579357147, 'epoch': 14.53}
{'loss': 0.0128, 'grad_norm': 6.5615739822387695, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.010299000889062881, 'loss_2': 0.002471923828125, 'loss_3': -16.52553939819336, 'loss_4': 0.6706182956695557, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 16:19:27,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:27,275 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:02:05<46:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:34,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015275932848453522, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.111, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01254386454820633, 'eval_loss_2': 0.0027320683002471924, 'eval_loss_3': -18.172805786132812, 'eval_loss_4': 0.7958775162696838, 'epoch': 14.53}
{'loss': 0.0135, 'grad_norm': 5.4673590660095215, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.007906910963356495, 'loss_2': 0.00563812255859375, 'loss_3': -16.42984390258789, 'loss_4': 0.402767539024353, 'epoch': 14.54}
{'loss': 0.0174, 'grad_norm': 5.6488471031188965, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.007268745917826891, 'loss_2': 0.010101318359375, 'loss_3': -16.158935546875, 'loss_4': 0.8084046840667725, 'epoch': 14.55}
{'loss': 0.0195, 'grad_norm': 6.702207088470459, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.013667196966707706, 'loss_2': 0.00583648681640625, 'loss_3': -16.519947052001953, 'loss_4': 0.8169929385185242, 'epoch': 14.55}
{'loss': 0.0088, 'grad_norm': 6.276859283447266, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.004940056707710028, 'loss_2': 0.003875732421875, 'loss_3': -16.222320556640625, 'loss_4': 0.6630871295928955, 'epoch': 14.56}
{'loss': 0.0064, 'grad_norm': 4.608310699462891, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.005099027883261442, 'loss_2': 0.0012722015380859375, 'loss_3': -16.46700668334961, 'loss_4': 0.606092095375061, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 16:19:34,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:34,636 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:02:12<45:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:41,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01676887273788452, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.404, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014149396680295467, 'eval_loss_2': 0.0026194751262664795, 'eval_loss_3': -18.15362548828125, 'eval_loss_4': 0.8814049363136292, 'epoch': 14.56}
{'loss': 0.0135, 'grad_norm': 7.036619663238525, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.008283770643174648, 'loss_2': 0.005184173583984375, 'loss_3': -16.457237243652344, 'loss_4': 0.6361055374145508, 'epoch': 14.57}
{'loss': 0.017, 'grad_norm': 6.164771556854248, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.009387966245412827, 'loss_2': 0.0075836181640625, 'loss_3': -16.57958221435547, 'loss_4': 0.5332268476486206, 'epoch': 14.58}
{'loss': 0.0176, 'grad_norm': 6.720315933227539, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.011899370700120926, 'loss_2': 0.005725860595703125, 'loss_3': -16.541282653808594, 'loss_4': 0.9554745554924011, 'epoch': 14.58}
{'loss': 0.0254, 'grad_norm': 7.192083835601807, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.021357404068112373, 'loss_2': 0.0040130615234375, 'loss_3': -16.562461853027344, 'loss_4': 0.7549799680709839, 'epoch': 14.59}
{'loss': 0.0093, 'grad_norm': 5.1456217765808105, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.006790817715227604, 'loss_2': 0.002521514892578125, 'loss_3': -16.151737213134766, 'loss_4': 0.29755899310112, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 16:19:41,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:41,992 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:20<45:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:49,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018421756103634834, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.903, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015583427622914314, 'eval_loss_2': 0.00283832848072052, 'eval_loss_3': -18.151315689086914, 'eval_loss_4': 0.9675392508506775, 'epoch': 14.59}
{'loss': 0.0164, 'grad_norm': 4.77098274230957, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.010271373204886913, 'loss_2': 0.006175994873046875, 'loss_3': -16.468435287475586, 'loss_4': 1.0420374870300293, 'epoch': 14.6}
{'loss': 0.0073, 'grad_norm': 4.893906116485596, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.00455522770062089, 'loss_2': 0.00274658203125, 'loss_3': -16.504505157470703, 'loss_4': 0.4001065790653229, 'epoch': 14.6}
{'loss': 0.0268, 'grad_norm': 11.085036277770996, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.023613616824150085, 'loss_2': 0.0032176971435546875, 'loss_3': -16.512027740478516, 'loss_4': 0.8741498589515686, 'epoch': 14.61}
{'loss': 0.0122, 'grad_norm': 6.102085113525391, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.011742547154426575, 'loss_2': 0.00045490264892578125, 'loss_3': -16.402870178222656, 'loss_4': 0.5720254778862, 'epoch': 14.62}
{'loss': 0.0251, 'grad_norm': 17.524227142333984, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.02111407369375229, 'loss_2': 0.00394439697265625, 'loss_3': -16.61518096923828, 'loss_4': 1.0028393268585205, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 16:19:49,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:49,363 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:27<45:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:56,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020807355642318726, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.018965348601341248, 'eval_loss_2': 0.001842007040977478, 'eval_loss_3': -18.11419677734375, 'eval_loss_4': 0.7262612581253052, 'epoch': 14.62}
{'loss': 0.0166, 'grad_norm': 6.8099045753479, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.014938878826797009, 'loss_2': 0.001678466796875, 'loss_3': -16.37548828125, 'loss_4': 0.8028290271759033, 'epoch': 14.63}
{'loss': 0.0119, 'grad_norm': 6.913057804107666, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.010828248225152493, 'loss_2': 0.0010862350463867188, 'loss_3': -16.166263580322266, 'loss_4': 0.5507195591926575, 'epoch': 14.63}
{'loss': 0.0179, 'grad_norm': 4.847850799560547, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.007507451344281435, 'loss_2': 0.010406494140625, 'loss_3': -16.634862899780273, 'loss_4': 0.4776098430156708, 'epoch': 14.64}
{'loss': 0.0082, 'grad_norm': 4.533669948577881, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.004712742753326893, 'loss_2': 0.0034580230712890625, 'loss_3': -16.19540786743164, 'loss_4': 0.5933648943901062, 'epoch': 14.65}
{'loss': 0.0175, 'grad_norm': 9.632209777832031, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.01693929359316826, 'loss_2': 0.0005903244018554688, 'loss_3': -16.430227279663086, 'loss_4': 0.5824999809265137, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 16:19:56,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:56,719 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:34<45:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:04,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020480651408433914, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.018118631094694138, 'eval_loss_2': 0.0023620203137397766, 'eval_loss_3': -18.070756912231445, 'eval_loss_4': 0.5184371471405029, 'epoch': 14.65}
{'loss': 0.025, 'grad_norm': 11.378552436828613, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.023655865341424942, 'loss_2': 0.0013103485107421875, 'loss_3': -16.39337158203125, 'loss_4': 0.1915600597858429, 'epoch': 14.66}
{'loss': 0.0414, 'grad_norm': 15.862183570861816, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.0407181940972805, 'loss_2': 0.0006513595581054688, 'loss_3': -16.49230194091797, 'loss_4': 0.966942310333252, 'epoch': 14.66}
{'loss': 0.0175, 'grad_norm': 8.44791316986084, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.010691134259104729, 'loss_2': 0.00685882568359375, 'loss_3': -16.34539031982422, 'loss_4': 0.3199004530906677, 'epoch': 14.67}
{'loss': 0.0252, 'grad_norm': 14.209734916687012, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.022898972034454346, 'loss_2': 0.002292633056640625, 'loss_3': -16.561172485351562, 'loss_4': 0.36201661825180054, 'epoch': 14.67}
{'loss': 0.0117, 'grad_norm': 5.0330305099487305, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.006322884000837803, 'loss_2': 0.00537872314453125, 'loss_3': -16.305755615234375, 'loss_4': -0.03912363201379776, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 16:20:04,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:04,075 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:42<45:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:11,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017715133726596832, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.298, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012946759350597858, 'eval_loss_2': 0.00476837158203125, 'eval_loss_3': -18.11052894592285, 'eval_loss_4': 0.4068544805049896, 'epoch': 14.68}
{'loss': 0.0103, 'grad_norm': 5.193287372589111, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.005566657520830631, 'loss_2': 0.004749298095703125, 'loss_3': -16.22087287902832, 'loss_4': 0.29831451177597046, 'epoch': 14.69}
{'loss': 0.0102, 'grad_norm': 4.998680114746094, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.006359608378261328, 'loss_2': 0.003856658935546875, 'loss_3': -16.439748764038086, 'loss_4': 0.20696869492530823, 'epoch': 14.69}
{'loss': 0.0154, 'grad_norm': 4.849527359008789, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.0075761741027235985, 'loss_2': 0.0078125, 'loss_3': -16.384580612182617, 'loss_4': 0.6772274971008301, 'epoch': 14.7}
{'loss': 0.016, 'grad_norm': 6.819540023803711, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.009252642281353474, 'loss_2': 0.00676727294921875, 'loss_3': -16.492496490478516, 'loss_4': 0.3936839997768402, 'epoch': 14.7}
{'loss': 0.0183, 'grad_norm': 6.777418613433838, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.009038662537932396, 'loss_2': 0.009246826171875, 'loss_3': -16.40018653869629, 'loss_4': 0.39937612414360046, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 16:20:11,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:11,435 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:49<45:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:18,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013682223856449127, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009873545728623867, 'eval_loss_2': 0.0038086771965026855, 'eval_loss_3': -18.17738914489746, 'eval_loss_4': 0.4666956961154938, 'epoch': 14.71}
{'loss': 0.0238, 'grad_norm': 10.459826469421387, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.020385967567563057, 'loss_2': 0.00336456298828125, 'loss_3': -16.29098892211914, 'loss_4': 0.6694866418838501, 'epoch': 14.72}
{'loss': 0.0115, 'grad_norm': 6.103996276855469, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.00924693513661623, 'loss_2': 0.0022678375244140625, 'loss_3': -16.55182456970215, 'loss_4': 0.1914432942867279, 'epoch': 14.72}
{'loss': 0.0132, 'grad_norm': 5.670811176300049, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.008395927958190441, 'loss_2': 0.00481414794921875, 'loss_3': -16.343029022216797, 'loss_4': 0.09209832549095154, 'epoch': 14.73}
{'loss': 0.0151, 'grad_norm': 5.3962321281433105, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.011008522473275661, 'loss_2': 0.004055023193359375, 'loss_3': -16.665468215942383, 'loss_4': 0.24200093746185303, 'epoch': 14.73}
{'loss': 0.0081, 'grad_norm': 4.911195278167725, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.007634426467120647, 'loss_2': 0.0005044937133789062, 'loss_3': -16.363712310791016, 'loss_4': 0.8859694004058838, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 16:20:18,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:18,784 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:56<45:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:26,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013396999798715115, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.866, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009161918424069881, 'eval_loss_2': 0.004235081374645233, 'eval_loss_3': -18.239486694335938, 'eval_loss_4': 0.4984620213508606, 'epoch': 14.74}
{'loss': 0.0332, 'grad_norm': 19.404272079467773, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.03071047179400921, 'loss_2': 0.0024623870849609375, 'loss_3': -16.47182273864746, 'loss_4': 0.3807140588760376, 'epoch': 14.74}
{'loss': 0.0199, 'grad_norm': 6.465251922607422, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.01791958697140217, 'loss_2': 0.001983642578125, 'loss_3': -16.544414520263672, 'loss_4': 0.45445266366004944, 'epoch': 14.75}
{'loss': 0.0123, 'grad_norm': 6.711991786956787, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.011592875234782696, 'loss_2': 0.0007181167602539062, 'loss_3': -16.49349594116211, 'loss_4': 0.1942467987537384, 'epoch': 14.76}
{'loss': 0.0282, 'grad_norm': 10.064993858337402, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.027092985808849335, 'loss_2': 0.00112152099609375, 'loss_3': -16.48467254638672, 'loss_4': 0.9819228053092957, 'epoch': 14.76}
{'loss': 0.017, 'grad_norm': 5.4093451499938965, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.00883889477699995, 'loss_2': 0.00812530517578125, 'loss_3': -16.452836990356445, 'loss_4': 0.18637876212596893, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 16:20:26,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:26,153 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:03:04<45:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:33,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01525484211742878, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010907442308962345, 'eval_loss_2': 0.00434739887714386, 'eval_loss_3': -18.30097007751465, 'eval_loss_4': 0.44397687911987305, 'epoch': 14.77}
{'loss': 0.0699, 'grad_norm': 24.533891677856445, 'learning_rate': 1.525e-05, 'loss_1': 0.06707590073347092, 'loss_2': 0.0028018951416015625, 'loss_3': -16.568527221679688, 'loss_4': 1.076669454574585, 'epoch': 14.77}
{'loss': 0.0166, 'grad_norm': 6.022550106048584, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.012667855247855186, 'loss_2': 0.00392913818359375, 'loss_3': -16.517269134521484, 'loss_4': 0.4811275899410248, 'epoch': 14.78}
{'loss': 0.0161, 'grad_norm': 6.055778503417969, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.013925902545452118, 'loss_2': 0.002170562744140625, 'loss_3': -16.225929260253906, 'loss_4': 0.6729896068572998, 'epoch': 14.78}
{'loss': 0.0132, 'grad_norm': 5.216697692871094, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.010629086755216122, 'loss_2': 0.0025234222412109375, 'loss_3': -16.491382598876953, 'loss_4': 0.4410541355609894, 'epoch': 14.79}
{'loss': 0.0503, 'grad_norm': 19.24662208557129, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.05013773962855339, 'loss_2': 0.00013899803161621094, 'loss_3': -16.478134155273438, 'loss_4': 0.33245164155960083, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 16:20:33,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:33,517 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:03:11<45:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:40,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015485187061131, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.412, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012628692202270031, 'eval_loss_2': 0.0028564929962158203, 'eval_loss_3': -18.3366756439209, 'eval_loss_4': 0.33301842212677, 'epoch': 14.8}
{'loss': 0.0228, 'grad_norm': 7.218471050262451, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.019105270504951477, 'loss_2': 0.003673553466796875, 'loss_3': -16.571598052978516, 'loss_4': -0.026974253356456757, 'epoch': 14.8}
{'loss': 0.0161, 'grad_norm': 6.439306735992432, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.012897942215204239, 'loss_2': 0.003223419189453125, 'loss_3': -16.722747802734375, 'loss_4': 0.4086223840713501, 'epoch': 14.81}
{'loss': 0.0122, 'grad_norm': 5.508754730224609, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.010672722943127155, 'loss_2': 0.0015201568603515625, 'loss_3': -16.607189178466797, 'loss_4': 0.2292468398809433, 'epoch': 14.81}
{'loss': 0.0225, 'grad_norm': 6.733646392822266, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.015556185506284237, 'loss_2': 0.00690460205078125, 'loss_3': -16.5313777923584, 'loss_4': 0.09832092374563217, 'epoch': 14.82}
{'loss': 0.0199, 'grad_norm': 6.425625324249268, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.016520123928785324, 'loss_2': 0.003429412841796875, 'loss_3': -16.511058807373047, 'loss_4': 0.3999941647052765, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 16:20:40,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:40,871 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:19<45:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:48,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019094597548246384, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.281, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01295841857790947, 'eval_loss_2': 0.006136178970336914, 'eval_loss_3': -18.349262237548828, 'eval_loss_4': 0.32760387659072876, 'epoch': 14.83}
{'loss': 0.0207, 'grad_norm': 5.383692741394043, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.013551052659749985, 'loss_2': 0.0071258544921875, 'loss_3': -16.763896942138672, 'loss_4': 0.48563501238822937, 'epoch': 14.83}
{'loss': 0.039, 'grad_norm': 11.05699348449707, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.030864916741847992, 'loss_2': 0.0081329345703125, 'loss_3': -16.597766876220703, 'loss_4': 0.6986197233200073, 'epoch': 14.84}
{'loss': 0.0144, 'grad_norm': 5.581625461578369, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.010829482227563858, 'loss_2': 0.0035572052001953125, 'loss_3': -16.55849266052246, 'loss_4': -0.19263914227485657, 'epoch': 14.84}
{'loss': 0.017, 'grad_norm': 6.2814788818359375, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.01321989856660366, 'loss_2': 0.003753662109375, 'loss_3': -16.576988220214844, 'loss_4': 0.6981045603752136, 'epoch': 14.85}
{'loss': 0.0207, 'grad_norm': 5.097142219543457, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.011299720965325832, 'loss_2': 0.0094146728515625, 'loss_3': -16.509201049804688, 'loss_4': 0.01945360004901886, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 16:20:48,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:48,229 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:26<44:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:55,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014490967616438866, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.668, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011006055399775505, 'eval_loss_2': 0.0034849122166633606, 'eval_loss_3': -18.30449676513672, 'eval_loss_4': 0.4025042653083801, 'epoch': 14.85}
{'loss': 0.0277, 'grad_norm': 14.48984146118164, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.023390987887978554, 'loss_2': 0.004344940185546875, 'loss_3': -16.612180709838867, 'loss_4': 0.9808460474014282, 'epoch': 14.86}
{'loss': 0.0174, 'grad_norm': 5.480344295501709, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.015108561143279076, 'loss_2': 0.0023365020751953125, 'loss_3': -16.483516693115234, 'loss_4': 0.3360707759857178, 'epoch': 14.87}
{'loss': 0.023, 'grad_norm': 7.738129615783691, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.018332161009311676, 'loss_2': 0.004638671875, 'loss_3': -16.668495178222656, 'loss_4': -0.3904101848602295, 'epoch': 14.87}
{'loss': 0.0142, 'grad_norm': 5.873554229736328, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.010236972942948341, 'loss_2': 0.00394439697265625, 'loss_3': -16.41042709350586, 'loss_4': 0.13488370180130005, 'epoch': 14.88}
{'loss': 0.0165, 'grad_norm': 5.00848913192749, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.008546898141503334, 'loss_2': 0.00795745849609375, 'loss_3': -16.4545841217041, 'loss_4': 0.06623890995979309, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 16:20:55,575 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:55,576 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:33<44:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:02,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014929123222827911, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009989590384066105, 'eval_loss_2': 0.004939533770084381, 'eval_loss_3': -18.26238250732422, 'eval_loss_4': 0.5175931453704834, 'epoch': 14.88}
{'loss': 0.0171, 'grad_norm': 6.577123165130615, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.013875233009457588, 'loss_2': 0.003253936767578125, 'loss_3': -16.43478775024414, 'loss_4': 0.2840181291103363, 'epoch': 14.89}
{'loss': 0.0219, 'grad_norm': 5.4974141120910645, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.012636955827474594, 'loss_2': 0.0092315673828125, 'loss_3': -16.29043197631836, 'loss_4': -0.09464972466230392, 'epoch': 14.9}
{'loss': 0.0196, 'grad_norm': 5.599462985992432, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.012995363213121891, 'loss_2': 0.006641387939453125, 'loss_3': -16.378173828125, 'loss_4': 0.0705641359090805, 'epoch': 14.9}
{'loss': 0.0118, 'grad_norm': 5.2708964347839355, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.010407372377812862, 'loss_2': 0.0013561248779296875, 'loss_3': -16.323596954345703, 'loss_4': 0.7961458563804626, 'epoch': 14.91}
{'loss': 0.0173, 'grad_norm': 6.113905429840088, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.013990620151162148, 'loss_2': 0.003292083740234375, 'loss_3': -16.37821388244629, 'loss_4': 0.45272013545036316, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 16:21:02,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:02,936 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:41<44:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:10,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013830821961164474, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.010261830873787403, 'eval_loss_2': 0.003568992018699646, 'eval_loss_3': -18.22117042541504, 'eval_loss_4': 0.6110557317733765, 'epoch': 14.91}
{'loss': 0.0175, 'grad_norm': 8.261807441711426, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.015137123875319958, 'loss_2': 0.002410888671875, 'loss_3': -16.416772842407227, 'loss_4': 0.4710789918899536, 'epoch': 14.92}
{'loss': 0.0084, 'grad_norm': 6.089208602905273, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.0068799518048763275, 'loss_2': 0.0015163421630859375, 'loss_3': -16.499359130859375, 'loss_4': 0.47401925921440125, 'epoch': 14.92}
{'loss': 0.0151, 'grad_norm': 6.094707489013672, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.011853895150125027, 'loss_2': 0.003253936767578125, 'loss_3': -16.401567459106445, 'loss_4': 0.08368438482284546, 'epoch': 14.93}
{'loss': 0.0179, 'grad_norm': 6.188419342041016, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.01446322537958622, 'loss_2': 0.0034332275390625, 'loss_3': -16.445415496826172, 'loss_4': -0.001862306147813797, 'epoch': 14.94}
{'loss': 0.0125, 'grad_norm': 4.882752418518066, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.005107824690639973, 'loss_2': 0.0073699951171875, 'loss_3': -16.297645568847656, 'loss_4': 0.5813724398612976, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 16:21:10,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:10,295 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:48<44:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:17,641 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014808015897870064, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.455, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009586649015545845, 'eval_loss_2': 0.005221366882324219, 'eval_loss_3': -18.166553497314453, 'eval_loss_4': 0.6457363367080688, 'epoch': 14.94}
{'loss': 0.0144, 'grad_norm': 5.472426414489746, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.005206813104450703, 'loss_2': 0.00917816162109375, 'loss_3': -16.374393463134766, 'loss_4': 0.2803211212158203, 'epoch': 14.95}
{'loss': 0.0333, 'grad_norm': 11.263025283813477, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.032926689833402634, 'loss_2': 0.00033783912658691406, 'loss_3': -16.498796463012695, 'loss_4': 0.6786690950393677, 'epoch': 14.95}
{'loss': 0.012, 'grad_norm': 4.748431205749512, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.007975441403687, 'loss_2': 0.003997802734375, 'loss_3': -16.279712677001953, 'loss_4': 0.8813134431838989, 'epoch': 14.96}
{'loss': 0.0099, 'grad_norm': 5.950311183929443, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.007391528692096472, 'loss_2': 0.002536773681640625, 'loss_3': -16.574485778808594, 'loss_4': 0.3664645850658417, 'epoch': 14.97}
{'loss': 0.0179, 'grad_norm': 9.061084747314453, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.015803137794137, 'loss_2': 0.002105712890625, 'loss_3': -16.535072326660156, 'loss_4': 0.40324169397354126, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 16:21:17,641 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:17,641 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:55<40:10,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:21:24,640 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013574544340372086, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.503, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010264369659125805, 'eval_loss_2': 0.003310173749923706, 'eval_loss_3': -18.140913009643555, 'eval_loss_4': 0.7785217761993408, 'epoch': 14.97}
{'loss': 0.014, 'grad_norm': 6.026050567626953, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.012615676037967205, 'loss_2': 0.0013628005981445312, 'loss_3': -16.478208541870117, 'loss_4': 0.5821064710617065, 'epoch': 14.98}
{'loss': 0.0118, 'grad_norm': 6.860861301422119, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.010705159977078438, 'loss_2': 0.0010576248168945312, 'loss_3': -16.457279205322266, 'loss_4': 0.5149990320205688, 'epoch': 14.98}
{'loss': 0.0075, 'grad_norm': 4.978865146636963, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.005928366910666227, 'loss_2': 0.001552581787109375, 'loss_3': -16.483442306518555, 'loss_4': 0.689441978931427, 'epoch': 14.99}
{'loss': 0.0185, 'grad_norm': 5.978616714477539, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.010153382085263729, 'loss_2': 0.00832366943359375, 'loss_3': -16.431028366088867, 'loss_4': 0.6492241621017456, 'epoch': 14.99}
{'loss': 0.0065, 'grad_norm': 7.700497627258301, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.0064817629754543304, 'loss_2': 2.8431415557861328e-05, 'loss_3': -16.196252822875977, 'loss_4': 0.394412100315094, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 16:21:24,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:24,640 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:04:02<43:57,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:21:32,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013879198580980301, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.153, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009869094006717205, 'eval_loss_2': 0.004010103642940521, 'eval_loss_3': -18.1215763092041, 'eval_loss_4': 0.7444297075271606, 'epoch': 15.0}
{'loss': 0.0138, 'grad_norm': 4.868403911590576, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.007275553420186043, 'loss_2': 0.00656890869140625, 'loss_3': -16.318227767944336, 'loss_4': 1.1084576845169067, 'epoch': 15.01}
{'loss': 0.0183, 'grad_norm': 9.83895206451416, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.017300082370638847, 'loss_2': 0.0009746551513671875, 'loss_3': -16.380111694335938, 'loss_4': 0.9733497500419617, 'epoch': 15.01}
{'loss': 0.0256, 'grad_norm': 12.441490173339844, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.020221570506691933, 'loss_2': 0.00533294677734375, 'loss_3': -16.270610809326172, 'loss_4': 0.3625984191894531, 'epoch': 15.02}
{'loss': 0.0098, 'grad_norm': 4.934956073760986, 'learning_rate': 1.5e-05, 'loss_1': 0.008118282072246075, 'loss_2': 0.001689910888671875, 'loss_3': -16.432886123657227, 'loss_4': 0.27154743671417236, 'epoch': 15.02}
{'loss': 0.0078, 'grad_norm': 5.403060436248779, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.007743701338768005, 'loss_2': 4.3332576751708984e-05, 'loss_3': -16.44843101501465, 'loss_4': 0.8721864223480225, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 16:21:32,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:32,036 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:04:10<44:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:39,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014696258120238781, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.503, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010644498281180859, 'eval_loss_2': 0.004051759839057922, 'eval_loss_3': -18.120737075805664, 'eval_loss_4': 0.5231842994689941, 'epoch': 15.03}
{'loss': 0.017, 'grad_norm': 5.646065711975098, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.008953378535807133, 'loss_2': 0.00806427001953125, 'loss_3': -16.422346115112305, 'loss_4': -0.03054685890674591, 'epoch': 15.03}
{'loss': 0.0084, 'grad_norm': 4.865097999572754, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.004807573743164539, 'loss_2': 0.00354766845703125, 'loss_3': -16.563722610473633, 'loss_4': 0.2934184670448303, 'epoch': 15.04}
{'loss': 0.0168, 'grad_norm': 5.427069187164307, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.012351097539067268, 'loss_2': 0.0044708251953125, 'loss_3': -16.55392837524414, 'loss_4': 0.1582135707139969, 'epoch': 15.05}
{'loss': 0.0097, 'grad_norm': 4.665494918823242, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.00844483356922865, 'loss_2': 0.0012836456298828125, 'loss_3': -16.29763412475586, 'loss_4': 0.3105756640434265, 'epoch': 15.05}
{'loss': 0.0107, 'grad_norm': 4.987821578979492, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.007433065678924322, 'loss_2': 0.003238677978515625, 'loss_3': -16.37490463256836, 'loss_4': -0.23443052172660828, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 16:21:39,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:39,385 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:17<44:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:46,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014700843952596188, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.599, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011623977683484554, 'eval_loss_2': 0.0030768662691116333, 'eval_loss_3': -18.13627052307129, 'eval_loss_4': 0.19097480177879333, 'epoch': 15.06}
{'loss': 0.0088, 'grad_norm': 4.490828514099121, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.004436070099473, 'loss_2': 0.004344940185546875, 'loss_3': -16.38656234741211, 'loss_4': -0.03457731008529663, 'epoch': 15.06}
{'loss': 0.0149, 'grad_norm': 6.548376560211182, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.010745263658463955, 'loss_2': 0.00420379638671875, 'loss_3': -16.304109573364258, 'loss_4': -0.1081622838973999, 'epoch': 15.07}
{'loss': 0.0141, 'grad_norm': 7.122287273406982, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.011694880202412605, 'loss_2': 0.0023651123046875, 'loss_3': -16.307893753051758, 'loss_4': -0.038461700081825256, 'epoch': 15.08}
{'loss': 0.019, 'grad_norm': 7.276778221130371, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.013629638589918613, 'loss_2': 0.0053863525390625, 'loss_3': -16.416622161865234, 'loss_4': -0.021622024476528168, 'epoch': 15.08}
{'loss': 0.0122, 'grad_norm': 6.933918476104736, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.011293722316622734, 'loss_2': 0.0008764266967773438, 'loss_3': -16.292327880859375, 'loss_4': 0.19865787029266357, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 16:21:46,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:46,758 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:24<44:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:54,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013772232457995415, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.518, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010467496700584888, 'eval_loss_2': 0.0033047348260879517, 'eval_loss_3': -18.140867233276367, 'eval_loss_4': 0.1333303302526474, 'epoch': 15.09}
{'loss': 0.0145, 'grad_norm': 7.755175590515137, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.012569337151944637, 'loss_2': 0.0018825531005859375, 'loss_3': -16.43208885192871, 'loss_4': 0.13191616535186768, 'epoch': 15.09}
{'loss': 0.0127, 'grad_norm': 5.101016521453857, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.009127691388130188, 'loss_2': 0.003528594970703125, 'loss_3': -16.212160110473633, 'loss_4': -0.5350170135498047, 'epoch': 15.1}
{'loss': 0.0098, 'grad_norm': 5.322172164916992, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.006747194565832615, 'loss_2': 0.003093719482421875, 'loss_3': -16.453960418701172, 'loss_4': 0.05879111588001251, 'epoch': 15.1}
{'loss': 0.0151, 'grad_norm': 7.466085433959961, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.010706216096878052, 'loss_2': 0.0043792724609375, 'loss_3': -16.6114501953125, 'loss_4': 0.4763312339782715, 'epoch': 15.11}
{'loss': 0.0083, 'grad_norm': 6.865980625152588, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.006376349367201328, 'loss_2': 0.001972198486328125, 'loss_3': -16.32857894897461, 'loss_4': 0.38850682973861694, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 16:21:54,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:54,115 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:32<44:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:01,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01268922258168459, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.365, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010071087628602982, 'eval_loss_2': 0.002618134021759033, 'eval_loss_3': -18.166154861450195, 'eval_loss_4': 0.3126390874385834, 'epoch': 15.12}
{'loss': 0.0158, 'grad_norm': 6.0908918380737305, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.013342912308871746, 'loss_2': 0.002437591552734375, 'loss_3': -16.29326820373535, 'loss_4': 0.2486402988433838, 'epoch': 15.12}
{'loss': 0.0085, 'grad_norm': 5.455697536468506, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.007196967955678701, 'loss_2': 0.0012569427490234375, 'loss_3': -16.315303802490234, 'loss_4': 0.29579341411590576, 'epoch': 15.13}
{'loss': 0.0269, 'grad_norm': 15.2411527633667, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.02241479977965355, 'loss_2': 0.00447845458984375, 'loss_3': -16.503864288330078, 'loss_4': 0.14815959334373474, 'epoch': 15.13}
{'loss': 0.0047, 'grad_norm': 4.742301940917969, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.003205232322216034, 'loss_2': 0.0014896392822265625, 'loss_3': -16.312767028808594, 'loss_4': 0.35277456045150757, 'epoch': 15.14}
{'loss': 0.005, 'grad_norm': 4.593161582946777, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.004749025218188763, 'loss_2': 0.0002465248107910156, 'loss_3': -16.575408935546875, 'loss_4': 0.22771164774894714, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 16:22:01,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:01,466 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:39<44:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:08,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013726949691772461, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.757, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009487509727478027, 'eval_loss_2': 0.004239439964294434, 'eval_loss_3': -18.172874450683594, 'eval_loss_4': 0.47181376814842224, 'epoch': 15.15}
{'loss': 0.0182, 'grad_norm': 5.553835391998291, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.007555305026471615, 'loss_2': 0.0106353759765625, 'loss_3': -16.5299072265625, 'loss_4': 0.3502473533153534, 'epoch': 15.15}
{'loss': 0.0064, 'grad_norm': 4.698709011077881, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.004473957233130932, 'loss_2': 0.0019683837890625, 'loss_3': -16.51268768310547, 'loss_4': 0.005171742290258408, 'epoch': 15.16}
{'loss': 0.0107, 'grad_norm': 4.49816370010376, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.009730187244713306, 'loss_2': 0.0010099411010742188, 'loss_3': -16.54631233215332, 'loss_4': 0.3688337802886963, 'epoch': 15.16}
{'loss': 0.0813, 'grad_norm': 16.69634246826172, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.07967961579561234, 'loss_2': 0.0016431808471679688, 'loss_3': -16.668262481689453, 'loss_4': 0.4063575863838196, 'epoch': 15.17}
{'loss': 0.0145, 'grad_norm': 5.2786664962768555, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.00982903316617012, 'loss_2': 0.00464630126953125, 'loss_3': -16.556968688964844, 'loss_4': 0.11371198296546936, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 16:22:08,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:08,815 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:47<44:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:16,173 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012919791974127293, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009969779290258884, 'eval_loss_2': 0.002950012683868408, 'eval_loss_3': -18.185588836669922, 'eval_loss_4': 0.5521508455276489, 'epoch': 15.17}
{'loss': 0.0082, 'grad_norm': 5.424246788024902, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.00645587919279933, 'loss_2': 0.0017242431640625, 'loss_3': -16.494647979736328, 'loss_4': 0.07138611376285553, 'epoch': 15.18}
{'loss': 0.0094, 'grad_norm': 4.567200183868408, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.005920832976698875, 'loss_2': 0.0034389495849609375, 'loss_3': -16.457317352294922, 'loss_4': 0.4977579712867737, 'epoch': 15.19}
{'loss': 0.0139, 'grad_norm': 5.7429304122924805, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.00899816770106554, 'loss_2': 0.004878997802734375, 'loss_3': -16.517637252807617, 'loss_4': 0.3053058981895447, 'epoch': 15.19}
{'loss': 0.0142, 'grad_norm': 5.370728492736816, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.009535618126392365, 'loss_2': 0.00461578369140625, 'loss_3': -16.506404876708984, 'loss_4': 0.09737320989370346, 'epoch': 15.2}
{'loss': 0.0332, 'grad_norm': 13.123734474182129, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.027627576142549515, 'loss_2': 0.005615234375, 'loss_3': -16.484642028808594, 'loss_4': 0.7228424549102783, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 16:22:16,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:16,173 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:54<44:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:23,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014120018109679222, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.118, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011082714423537254, 'eval_loss_2': 0.0030373036861419678, 'eval_loss_3': -18.223844528198242, 'eval_loss_4': 0.5733886361122131, 'epoch': 15.2}
{'loss': 0.0158, 'grad_norm': 5.909966945648193, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.01371464692056179, 'loss_2': 0.002132415771484375, 'loss_3': -16.577472686767578, 'loss_4': 0.46283090114593506, 'epoch': 15.21}
{'loss': 0.0102, 'grad_norm': 4.822417259216309, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.005625537596642971, 'loss_2': 0.004589080810546875, 'loss_3': -16.485626220703125, 'loss_4': -0.07713105529546738, 'epoch': 15.22}
{'loss': 0.0306, 'grad_norm': 11.884028434753418, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.030209580436348915, 'loss_2': 0.0004315376281738281, 'loss_3': -16.50603485107422, 'loss_4': 0.29956966638565063, 'epoch': 15.22}
{'loss': 0.0182, 'grad_norm': 5.430139541625977, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.01186265517026186, 'loss_2': 0.00629425048828125, 'loss_3': -16.337955474853516, 'loss_4': 0.7241922616958618, 'epoch': 15.23}
{'loss': 0.0136, 'grad_norm': 6.429309368133545, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.01107859332114458, 'loss_2': 0.0024871826171875, 'loss_3': -16.497875213623047, 'loss_4': 0.5168842077255249, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 16:22:23,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:23,536 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:05:01<43:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:30,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015142417512834072, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011908880434930325, 'eval_loss_2': 0.0032335370779037476, 'eval_loss_3': -18.246173858642578, 'eval_loss_4': 0.46392327547073364, 'epoch': 15.23}
{'loss': 0.074, 'grad_norm': 23.293376922607422, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.07162367552518845, 'loss_2': 0.002346038818359375, 'loss_3': -16.527074813842773, 'loss_4': 0.6153646111488342, 'epoch': 15.24}
{'loss': 0.0168, 'grad_norm': 7.294065952301025, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.013720904476940632, 'loss_2': 0.003047943115234375, 'loss_3': -16.52986717224121, 'loss_4': -0.14404296875, 'epoch': 15.24}
{'loss': 0.0268, 'grad_norm': 8.321216583251953, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.018488969653844833, 'loss_2': 0.008331298828125, 'loss_3': -16.547607421875, 'loss_4': 0.5616872310638428, 'epoch': 15.25}
{'loss': 0.0172, 'grad_norm': 6.142078876495361, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.012092912569642067, 'loss_2': 0.00506591796875, 'loss_3': -16.662147521972656, 'loss_4': 0.2584247887134552, 'epoch': 15.26}
{'loss': 0.0236, 'grad_norm': 11.891067504882812, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.02217276208102703, 'loss_2': 0.0014295578002929688, 'loss_3': -16.542360305786133, 'loss_4': -0.25552529096603394, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 16:22:30,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:30,895 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:05:09<43:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:38,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014607541263103485, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.544, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011631031520664692, 'eval_loss_2': 0.0029765069484710693, 'eval_loss_3': -18.267122268676758, 'eval_loss_4': 0.3989063799381256, 'epoch': 15.26}
{'loss': 0.0248, 'grad_norm': 12.769170761108398, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.023281266912817955, 'loss_2': 0.0014743804931640625, 'loss_3': -16.66769027709961, 'loss_4': 0.3183845281600952, 'epoch': 15.27}
{'loss': 0.0139, 'grad_norm': 4.710894584655762, 'learning_rate': 1.475e-05, 'loss_1': 0.006475473754107952, 'loss_2': 0.00737762451171875, 'loss_3': -16.61067008972168, 'loss_4': 0.430105060338974, 'epoch': 15.27}
{'loss': 0.0154, 'grad_norm': 4.746077537536621, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.005591157823801041, 'loss_2': 0.00982666015625, 'loss_3': -16.386579513549805, 'loss_4': 0.2631147503852844, 'epoch': 15.28}
{'loss': 0.0155, 'grad_norm': 4.730553150177002, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.007145439274609089, 'loss_2': 0.00833892822265625, 'loss_3': -16.481245040893555, 'loss_4': 0.9154049158096313, 'epoch': 15.28}
{'loss': 0.0159, 'grad_norm': 6.963101387023926, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.01460644043982029, 'loss_2': 0.0013074874877929688, 'loss_3': -16.56808090209961, 'loss_4': 0.10301121324300766, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 16:22:38,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:38,244 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:16<43:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:45,594 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01452679093927145, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.405, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012253344058990479, 'eval_loss_2': 0.002273447811603546, 'eval_loss_3': -18.284574508666992, 'eval_loss_4': 0.4458649158477783, 'epoch': 15.29}
{'loss': 0.0108, 'grad_norm': 5.871413230895996, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.009246178902685642, 'loss_2': 0.0015153884887695312, 'loss_3': -16.629730224609375, 'loss_4': 0.293517529964447, 'epoch': 15.3}
{'loss': 0.0136, 'grad_norm': 9.784236907958984, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.011525359936058521, 'loss_2': 0.002033233642578125, 'loss_3': -16.506114959716797, 'loss_4': 0.07262805104255676, 'epoch': 15.3}
{'loss': 0.0063, 'grad_norm': 4.790480136871338, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.005295314360409975, 'loss_2': 0.0009832382202148438, 'loss_3': -16.466720581054688, 'loss_4': 1.0736607313156128, 'epoch': 15.31}
{'loss': 0.0156, 'grad_norm': 8.010344505310059, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.01260291039943695, 'loss_2': 0.002971649169921875, 'loss_3': -16.376052856445312, 'loss_4': 0.2655673623085022, 'epoch': 15.31}
{'loss': 0.0191, 'grad_norm': 6.848646640777588, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.01410942804068327, 'loss_2': 0.004955291748046875, 'loss_3': -16.590974807739258, 'loss_4': 0.4334430694580078, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 16:22:45,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:45,595 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:23<43:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:52,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016226761043071747, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.438, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013675741851329803, 'eval_loss_2': 0.0025510191917419434, 'eval_loss_3': -18.308147430419922, 'eval_loss_4': 0.48130375146865845, 'epoch': 15.32}
{'loss': 0.0147, 'grad_norm': 7.469217300415039, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.013170763850212097, 'loss_2': 0.0015468597412109375, 'loss_3': -16.577789306640625, 'loss_4': 0.5778404474258423, 'epoch': 15.33}
{'loss': 0.0188, 'grad_norm': 6.028659820556641, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.015708843246102333, 'loss_2': 0.003131866455078125, 'loss_3': -16.609697341918945, 'loss_4': 0.3367536664009094, 'epoch': 15.33}
{'loss': 0.0159, 'grad_norm': 5.2947211265563965, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.01272200234234333, 'loss_2': 0.003177642822265625, 'loss_3': -16.43231964111328, 'loss_4': 0.522098183631897, 'epoch': 15.34}
{'loss': 0.0122, 'grad_norm': 6.442008018493652, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.010714265517890453, 'loss_2': 0.0015106201171875, 'loss_3': -16.523380279541016, 'loss_4': 0.5521533489227295, 'epoch': 15.34}
{'loss': 0.0229, 'grad_norm': 10.975580215454102, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.019046194851398468, 'loss_2': 0.003902435302734375, 'loss_3': -16.61865997314453, 'loss_4': 0.41915056109428406, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 16:22:52,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:52,946 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:31<43:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:00,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015895694494247437, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.333, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01327921636402607, 'eval_loss_2': 0.002616479992866516, 'eval_loss_3': -18.295223236083984, 'eval_loss_4': 0.7079785466194153, 'epoch': 15.35}
{'loss': 0.0143, 'grad_norm': 4.960390090942383, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.01039927639067173, 'loss_2': 0.0038776397705078125, 'loss_3': -16.627239227294922, 'loss_4': 0.6003396511077881, 'epoch': 15.35}
{'loss': 0.0194, 'grad_norm': 6.260555744171143, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.014240729622542858, 'loss_2': 0.00511932373046875, 'loss_3': -16.554012298583984, 'loss_4': 0.8053197264671326, 'epoch': 15.36}
{'loss': 0.0179, 'grad_norm': 9.566718101501465, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.012248897925019264, 'loss_2': 0.00562286376953125, 'loss_3': -16.511371612548828, 'loss_4': 0.48868340253829956, 'epoch': 15.37}
{'loss': 0.0125, 'grad_norm': 5.867208480834961, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.011935247108340263, 'loss_2': 0.0005788803100585938, 'loss_3': -16.51439666748047, 'loss_4': 0.6698105931282043, 'epoch': 15.37}
{'loss': 0.0135, 'grad_norm': 5.455006122589111, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.010619213804602623, 'loss_2': 0.0028533935546875, 'loss_3': -16.538589477539062, 'loss_4': 0.5449339747428894, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 16:23:00,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:00,300 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:38<43:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:07,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01791164092719555, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.194, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013651516288518906, 'eval_loss_2': 0.004260122776031494, 'eval_loss_3': -18.277938842773438, 'eval_loss_4': 0.9059516787528992, 'epoch': 15.38}
{'loss': 0.0209, 'grad_norm': 5.253241062164307, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.011685362085700035, 'loss_2': 0.009246826171875, 'loss_3': -16.551130294799805, 'loss_4': 0.24621045589447021, 'epoch': 15.38}
{'loss': 0.0346, 'grad_norm': 9.738757133483887, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.033774830400943756, 'loss_2': 0.0008058547973632812, 'loss_3': -16.488513946533203, 'loss_4': 0.9090681672096252, 'epoch': 15.39}
{'loss': 0.0165, 'grad_norm': 5.406980037689209, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.010647278279066086, 'loss_2': 0.0058441162109375, 'loss_3': -16.52779769897461, 'loss_4': 0.6219174265861511, 'epoch': 15.4}
{'loss': 0.0157, 'grad_norm': 6.247270107269287, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.013932316564023495, 'loss_2': 0.00176239013671875, 'loss_3': -16.576173782348633, 'loss_4': 0.9584200382232666, 'epoch': 15.4}
{'loss': 0.0246, 'grad_norm': 6.343756675720215, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.018632110208272934, 'loss_2': 0.006000518798828125, 'loss_3': -16.29745101928711, 'loss_4': 1.146436095237732, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 16:23:07,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:07,662 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:45<43:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:15,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019198108464479446, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012650835327804089, 'eval_loss_2': 0.006547272205352783, 'eval_loss_3': -18.25754165649414, 'eval_loss_4': 1.0058491230010986, 'epoch': 15.41}
{'loss': 0.0055, 'grad_norm': 4.993377685546875, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.005041189957410097, 'loss_2': 0.0004246234893798828, 'loss_3': -16.54874038696289, 'loss_4': 1.0373247861862183, 'epoch': 15.41}
{'loss': 0.0371, 'grad_norm': 14.902922630310059, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.03119557350873947, 'loss_2': 0.005947113037109375, 'loss_3': -16.6457462310791, 'loss_4': 1.4258992671966553, 'epoch': 15.42}
{'loss': 0.0157, 'grad_norm': 5.589395999908447, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.0068439217284321785, 'loss_2': 0.0088958740234375, 'loss_3': -16.4846248626709, 'loss_4': 1.3782957792282104, 'epoch': 15.42}
{'loss': 0.0107, 'grad_norm': 4.696012020111084, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.005861561745405197, 'loss_2': 0.004791259765625, 'loss_3': -16.464536666870117, 'loss_4': 0.6800731420516968, 'epoch': 15.43}
{'loss': 0.0149, 'grad_norm': 9.696342468261719, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.011422580108046532, 'loss_2': 0.0034389495849609375, 'loss_3': -16.52564239501953, 'loss_4': 0.9455301761627197, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 16:23:15,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:15,019 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:53<43:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:22,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015523762442171574, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012516796588897705, 'eval_loss_2': 0.003006964921951294, 'eval_loss_3': -18.224966049194336, 'eval_loss_4': 1.0568519830703735, 'epoch': 15.44}
{'loss': 0.0172, 'grad_norm': 7.73415994644165, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.013545730151236057, 'loss_2': 0.003612518310546875, 'loss_3': -16.37259292602539, 'loss_4': 0.95168137550354, 'epoch': 15.44}
{'loss': 0.0328, 'grad_norm': 13.391768455505371, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.03024098090827465, 'loss_2': 0.002593994140625, 'loss_3': -16.563377380371094, 'loss_4': 0.9880459308624268, 'epoch': 15.45}
{'loss': 0.0126, 'grad_norm': 5.590339660644531, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.010036124847829342, 'loss_2': 0.002613067626953125, 'loss_3': -16.590587615966797, 'loss_4': 0.891703188419342, 'epoch': 15.45}
{'loss': 0.0067, 'grad_norm': 4.731961727142334, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.006356283091008663, 'loss_2': 0.0003781318664550781, 'loss_3': -16.523170471191406, 'loss_4': 0.9061266183853149, 'epoch': 15.46}
{'loss': 0.0095, 'grad_norm': 4.556937217712402, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.005010782275348902, 'loss_2': 0.004497528076171875, 'loss_3': -16.645366668701172, 'loss_4': 1.0394227504730225, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 16:23:22,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:22,369 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:06:00<43:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:29,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016278330236673355, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.935, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012530865147709846, 'eval_loss_2': 0.0037474632263183594, 'eval_loss_3': -18.244338989257812, 'eval_loss_4': 1.0443854331970215, 'epoch': 15.47}
{'loss': 0.0081, 'grad_norm': 5.751192569732666, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.007172958925366402, 'loss_2': 0.0009636878967285156, 'loss_3': -16.355731964111328, 'loss_4': 0.7917629480361938, 'epoch': 15.47}
{'loss': 0.0134, 'grad_norm': 7.052059173583984, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.011377806775271893, 'loss_2': 0.001979827880859375, 'loss_3': -16.50988006591797, 'loss_4': 0.8923949003219604, 'epoch': 15.48}
{'loss': 0.0074, 'grad_norm': 6.48720645904541, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.0067765177227556705, 'loss_2': 0.0005769729614257812, 'loss_3': -16.50312042236328, 'loss_4': 0.877759575843811, 'epoch': 15.48}
{'loss': 0.0162, 'grad_norm': 6.562877178192139, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.015617834404110909, 'loss_2': 0.0006256103515625, 'loss_3': -16.47998809814453, 'loss_4': 1.080350399017334, 'epoch': 15.49}
{'loss': 0.0351, 'grad_norm': 11.938970565795898, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.024497851729393005, 'loss_2': 0.01058197021484375, 'loss_3': -16.454612731933594, 'loss_4': 1.1011196374893188, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 16:23:29,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:29,716 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:06:07<43:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:37,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017932791262865067, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.704, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013248850591480732, 'eval_loss_2': 0.004683941602706909, 'eval_loss_3': -18.255645751953125, 'eval_loss_4': 1.1871274709701538, 'epoch': 15.49}
{'loss': 0.0148, 'grad_norm': 5.903941631317139, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.01189921610057354, 'loss_2': 0.002864837646484375, 'loss_3': -16.240657806396484, 'loss_4': 1.4792747497558594, 'epoch': 15.5}
{'loss': 0.016, 'grad_norm': 5.265468120574951, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.009928064420819283, 'loss_2': 0.006038665771484375, 'loss_3': -16.444387435913086, 'loss_4': 1.0484851598739624, 'epoch': 15.51}
{'loss': 0.0229, 'grad_norm': 9.000848770141602, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.021276449784636497, 'loss_2': 0.0016660690307617188, 'loss_3': -16.21700096130371, 'loss_4': 1.0146011114120483, 'epoch': 15.51}
{'loss': 0.0145, 'grad_norm': 5.954179763793945, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.010664120316505432, 'loss_2': 0.003856658935546875, 'loss_3': -16.553848266601562, 'loss_4': 1.2502338886260986, 'epoch': 15.52}
{'loss': 0.0049, 'grad_norm': 6.0216474533081055, 'learning_rate': 1.45e-05, 'loss_1': 0.004582973197102547, 'loss_2': 0.0002865791320800781, 'loss_3': -16.36406898498535, 'loss_4': 1.4314100742340088, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 16:23:37,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:37,069 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:15<43:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:44,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016341902315616608, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01321885734796524, 'eval_loss_2': 0.003123044967651367, 'eval_loss_3': -18.266212463378906, 'eval_loss_4': 1.2254350185394287, 'epoch': 15.52}
{'loss': 0.0087, 'grad_norm': 5.714588642120361, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.00813549105077982, 'loss_2': 0.0005345344543457031, 'loss_3': -16.72237777709961, 'loss_4': 1.1611742973327637, 'epoch': 15.53}
{'loss': 0.009, 'grad_norm': 4.831717491149902, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.003374443855136633, 'loss_2': 0.00562286376953125, 'loss_3': -16.707740783691406, 'loss_4': 1.102970838546753, 'epoch': 15.53}
{'loss': 0.024, 'grad_norm': 7.969629764556885, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.016996102407574654, 'loss_2': 0.00699615478515625, 'loss_3': -16.43377685546875, 'loss_4': 1.4463826417922974, 'epoch': 15.54}
{'loss': 0.0141, 'grad_norm': 5.715751647949219, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.011432184837758541, 'loss_2': 0.002696990966796875, 'loss_3': -16.566009521484375, 'loss_4': 1.096186876296997, 'epoch': 15.55}
{'loss': 0.03, 'grad_norm': 16.003585815429688, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.029146241024136543, 'loss_2': 0.0008091926574707031, 'loss_3': -16.675518035888672, 'loss_4': 1.030686855316162, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 16:23:44,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:44,437 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:22<43:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:51,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0171344056725502, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.264, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013541197404265404, 'eval_loss_2': 0.003593210130929947, 'eval_loss_3': -18.28810691833496, 'eval_loss_4': 1.3288092613220215, 'epoch': 15.55}
{'loss': 0.0204, 'grad_norm': 6.0377349853515625, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.012894991785287857, 'loss_2': 0.00751495361328125, 'loss_3': -16.46784019470215, 'loss_4': 1.0620272159576416, 'epoch': 15.56}
{'loss': 0.0219, 'grad_norm': 7.611475944519043, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.019648760557174683, 'loss_2': 0.00226593017578125, 'loss_3': -16.28326988220215, 'loss_4': 1.6335060596466064, 'epoch': 15.56}
{'loss': 0.0244, 'grad_norm': 10.280204772949219, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.023489775136113167, 'loss_2': 0.00093841552734375, 'loss_3': -16.621028900146484, 'loss_4': 1.1418603658676147, 'epoch': 15.57}
{'loss': 0.0127, 'grad_norm': 5.597390651702881, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.009577164426445961, 'loss_2': 0.0031452178955078125, 'loss_3': -16.76618766784668, 'loss_4': 0.8870621919631958, 'epoch': 15.58}
{'loss': 0.0154, 'grad_norm': 5.377329349517822, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.011984642595052719, 'loss_2': 0.00337982177734375, 'loss_3': -16.50460433959961, 'loss_4': 0.7757060527801514, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 16:23:51,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:51,799 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:29<42:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:59,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017125315964221954, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.69, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014079221524298191, 'eval_loss_2': 0.003046095371246338, 'eval_loss_3': -18.2965145111084, 'eval_loss_4': 1.2183458805084229, 'epoch': 15.58}
{'loss': 0.0067, 'grad_norm': 4.621707916259766, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.005759465973824263, 'loss_2': 0.00095367431640625, 'loss_3': -16.669639587402344, 'loss_4': 0.9570062756538391, 'epoch': 15.59}
{'loss': 0.0129, 'grad_norm': 6.091599464416504, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.009211255237460136, 'loss_2': 0.00365447998046875, 'loss_3': -16.60700798034668, 'loss_4': 1.1250696182250977, 'epoch': 15.59}
{'loss': 0.0269, 'grad_norm': 11.465049743652344, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.022809024900197983, 'loss_2': 0.004119873046875, 'loss_3': -16.667888641357422, 'loss_4': 1.2927087545394897, 'epoch': 15.6}
{'loss': 0.0225, 'grad_norm': 8.853707313537598, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.013517084531486034, 'loss_2': 0.0089569091796875, 'loss_3': -16.499614715576172, 'loss_4': 1.336700439453125, 'epoch': 15.6}
{'loss': 0.0169, 'grad_norm': 5.547817707061768, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.01148577407002449, 'loss_2': 0.00545501708984375, 'loss_3': -16.735803604125977, 'loss_4': 1.0327391624450684, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 16:23:59,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:59,152 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:37<42:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:06,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018084712326526642, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014230914413928986, 'eval_loss_2': 0.0038537979125976562, 'eval_loss_3': -18.294652938842773, 'eval_loss_4': 1.1694415807724, 'epoch': 15.61}
{'loss': 0.0189, 'grad_norm': 8.296594619750977, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.01189552154392004, 'loss_2': 0.00701904296875, 'loss_3': -16.576587677001953, 'loss_4': 0.39321184158325195, 'epoch': 15.62}
{'loss': 0.0159, 'grad_norm': 7.245728015899658, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.010354398749768734, 'loss_2': 0.005527496337890625, 'loss_3': -16.378387451171875, 'loss_4': 0.5637892484664917, 'epoch': 15.62}
{'loss': 0.0123, 'grad_norm': 5.6116814613342285, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.010467699728906155, 'loss_2': 0.0018434524536132812, 'loss_3': -16.525009155273438, 'loss_4': 0.8343302011489868, 'epoch': 15.63}
{'loss': 0.0231, 'grad_norm': 11.914063453674316, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.017535284161567688, 'loss_2': 0.00559234619140625, 'loss_3': -16.461273193359375, 'loss_4': 1.2957735061645508, 'epoch': 15.63}
{'loss': 0.0159, 'grad_norm': 6.11580228805542, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.008907048963010311, 'loss_2': 0.0069580078125, 'loss_3': -16.57279396057129, 'loss_4': 1.212478756904602, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 16:24:06,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:06,500 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:44<42:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:13,852 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017683403566479683, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014679179526865482, 'eval_loss_2': 0.003004223108291626, 'eval_loss_3': -18.275745391845703, 'eval_loss_4': 1.0136287212371826, 'epoch': 15.64}
{'loss': 0.0366, 'grad_norm': 16.41351318359375, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.03103122115135193, 'loss_2': 0.005573272705078125, 'loss_3': -16.514127731323242, 'loss_4': 0.6671366095542908, 'epoch': 15.65}
{'loss': 0.0227, 'grad_norm': 9.836690902709961, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.0220024473965168, 'loss_2': 0.00069427490234375, 'loss_3': -16.438541412353516, 'loss_4': 0.37273311614990234, 'epoch': 15.65}
{'loss': 0.0058, 'grad_norm': 4.643155574798584, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.004144524224102497, 'loss_2': 0.001628875732421875, 'loss_3': -16.644960403442383, 'loss_4': 0.5764658451080322, 'epoch': 15.66}
{'loss': 0.0174, 'grad_norm': 11.73431396484375, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.01710331067442894, 'loss_2': 0.0002942085266113281, 'loss_3': -16.383493423461914, 'loss_4': 0.8348824977874756, 'epoch': 15.66}
{'loss': 0.02, 'grad_norm': 6.1611247062683105, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.01250680722296238, 'loss_2': 0.007472991943359375, 'loss_3': -16.404190063476562, 'loss_4': 0.5447685718536377, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 16:24:13,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:13,852 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:52<42:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:21,204 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018010100349783897, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.738, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01386185735464096, 'eval_loss_2': 0.004148244857788086, 'eval_loss_3': -18.255483627319336, 'eval_loss_4': 0.721991240978241, 'epoch': 15.67}
{'loss': 0.0159, 'grad_norm': 6.78633975982666, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.010943060740828514, 'loss_2': 0.0049285888671875, 'loss_3': -16.511425018310547, 'loss_4': 0.720116138458252, 'epoch': 15.67}
{'loss': 0.0236, 'grad_norm': 10.972068786621094, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.01763945445418358, 'loss_2': 0.005977630615234375, 'loss_3': -16.598787307739258, 'loss_4': 1.318166971206665, 'epoch': 15.68}
{'loss': 0.0138, 'grad_norm': 6.109402179718018, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.007689760532230139, 'loss_2': 0.006107330322265625, 'loss_3': -16.349830627441406, 'loss_4': 0.29141268134117126, 'epoch': 15.69}
{'loss': 0.0238, 'grad_norm': 7.6499223709106445, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.01915918104350567, 'loss_2': 0.004608154296875, 'loss_3': -16.638465881347656, 'loss_4': 0.4916715621948242, 'epoch': 15.69}
{'loss': 0.0346, 'grad_norm': 15.601150512695312, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.03216983377933502, 'loss_2': 0.002391815185546875, 'loss_3': -16.765213012695312, 'loss_4': 0.36123526096343994, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 16:24:21,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:21,204 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:59<42:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:28,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019724788144230843, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.868, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014818627387285233, 'eval_loss_2': 0.004906162619590759, 'eval_loss_3': -18.256196975708008, 'eval_loss_4': 0.5217257738113403, 'epoch': 15.7}
{'loss': 0.0087, 'grad_norm': 4.676044940948486, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.004678366705775261, 'loss_2': 0.004024505615234375, 'loss_3': -16.566837310791016, 'loss_4': 0.3921729326248169, 'epoch': 15.7}
{'loss': 0.0158, 'grad_norm': 5.632641792297363, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.00813042838126421, 'loss_2': 0.00765228271484375, 'loss_3': -16.49701690673828, 'loss_4': -0.0695401281118393, 'epoch': 15.71}
{'loss': 0.0065, 'grad_norm': 4.422119140625, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.005515240132808685, 'loss_2': 0.0009851455688476562, 'loss_3': -16.659217834472656, 'loss_4': 0.3892350196838379, 'epoch': 15.72}
{'loss': 0.0327, 'grad_norm': 18.690223693847656, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.026515867561101913, 'loss_2': 0.006229400634765625, 'loss_3': -16.562278747558594, 'loss_4': 0.2572097182273865, 'epoch': 15.72}
{'loss': 0.0104, 'grad_norm': 5.130784511566162, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.006964266300201416, 'loss_2': 0.00342559814453125, 'loss_3': -16.625669479370117, 'loss_4': 0.3698693513870239, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 16:24:28,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:28,569 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:07:06<42:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:35,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018821602687239647, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.259, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014870650134980679, 'eval_loss_2': 0.003950953483581543, 'eval_loss_3': -18.264896392822266, 'eval_loss_4': 0.33229130506515503, 'epoch': 15.73}
{'loss': 0.0211, 'grad_norm': 10.56163501739502, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.018481213599443436, 'loss_2': 0.0025768280029296875, 'loss_3': -16.317825317382812, 'loss_4': 0.06719660013914108, 'epoch': 15.73}
{'loss': 0.0098, 'grad_norm': 5.155725955963135, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.00661802850663662, 'loss_2': 0.003204345703125, 'loss_3': -16.310731887817383, 'loss_4': 0.3763589859008789, 'epoch': 15.74}
{'loss': 0.0229, 'grad_norm': 6.047167778015137, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.014827252365648746, 'loss_2': 0.00807952880859375, 'loss_3': -16.497873306274414, 'loss_4': 0.05918292701244354, 'epoch': 15.74}
{'loss': 0.0231, 'grad_norm': 8.351482391357422, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.018184378743171692, 'loss_2': 0.00493621826171875, 'loss_3': -16.613258361816406, 'loss_4': 0.20273588597774506, 'epoch': 15.75}
{'loss': 0.0136, 'grad_norm': 7.3146562576293945, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.009989588521420956, 'loss_2': 0.0036373138427734375, 'loss_3': -16.57308578491211, 'loss_4': 0.20005950331687927, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 16:24:35,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:35,927 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:07:14<42:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:43,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019373971968889236, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.636, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013694066554307938, 'eval_loss_2': 0.005679905414581299, 'eval_loss_3': -18.250999450683594, 'eval_loss_4': 0.316421240568161, 'epoch': 15.76}
{'loss': 0.0184, 'grad_norm': 5.8102126121521, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.01085865218192339, 'loss_2': 0.0075531005859375, 'loss_3': -16.515567779541016, 'loss_4': 0.042488399893045425, 'epoch': 15.76}
{'loss': 0.0235, 'grad_norm': 6.823232650756836, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.018371310085058212, 'loss_2': 0.005176544189453125, 'loss_3': -16.452415466308594, 'loss_4': 0.0809800922870636, 'epoch': 15.77}
{'loss': 0.0292, 'grad_norm': 8.563304901123047, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.018680138513445854, 'loss_2': 0.0104827880859375, 'loss_3': -16.709049224853516, 'loss_4': 0.14456041157245636, 'epoch': 15.77}
{'loss': 0.0193, 'grad_norm': 7.700984954833984, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.016500981524586678, 'loss_2': 0.0027866363525390625, 'loss_3': -16.57521629333496, 'loss_4': 0.19708281755447388, 'epoch': 15.78}
{'loss': 0.0141, 'grad_norm': 4.558403968811035, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.005999902728945017, 'loss_2': 0.00809478759765625, 'loss_3': -16.45301055908203, 'loss_4': 0.6099451780319214, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 16:24:43,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:43,277 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:21<42:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:50,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018494093790650368, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014562944881618023, 'eval_loss_2': 0.003931149840354919, 'eval_loss_3': -18.225440979003906, 'eval_loss_4': 0.48177370429039, 'epoch': 15.78}
{'loss': 0.0262, 'grad_norm': 14.57224178314209, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.01921048015356064, 'loss_2': 0.0070343017578125, 'loss_3': -16.648632049560547, 'loss_4': -0.1169232577085495, 'epoch': 15.79}
{'loss': 0.0213, 'grad_norm': 10.054986000061035, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.019345290958881378, 'loss_2': 0.001922607421875, 'loss_3': -16.487092971801758, 'loss_4': 1.0823721885681152, 'epoch': 15.8}
{'loss': 0.0059, 'grad_norm': 4.191688537597656, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.0037872917018830776, 'loss_2': 0.0021457672119140625, 'loss_3': -16.497617721557617, 'loss_4': 0.14267778396606445, 'epoch': 15.8}
{'loss': 0.0112, 'grad_norm': 4.073849678039551, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.004765407647937536, 'loss_2': 0.00643157958984375, 'loss_3': -16.30615234375, 'loss_4': 0.39464783668518066, 'epoch': 15.81}
{'loss': 0.0103, 'grad_norm': 5.237730026245117, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.0063056848011910915, 'loss_2': 0.0040283203125, 'loss_3': -16.385448455810547, 'loss_4': -0.18617695569992065, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 16:24:50,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:50,624 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:28<42:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:57,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016643289476633072, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.779, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013107363134622574, 'eval_loss_2': 0.003535926342010498, 'eval_loss_3': -18.178054809570312, 'eval_loss_4': 0.612088680267334, 'epoch': 15.81}
{'loss': 0.006, 'grad_norm': 4.911464214324951, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.004029022064059973, 'loss_2': 0.0019483566284179688, 'loss_3': -16.455768585205078, 'loss_4': 0.3420681655406952, 'epoch': 15.82}
{'loss': 0.0216, 'grad_norm': 5.193659782409668, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.01318206638097763, 'loss_2': 0.00838470458984375, 'loss_3': -16.322040557861328, 'loss_4': 0.35990238189697266, 'epoch': 15.83}
{'loss': 0.0212, 'grad_norm': 5.04288387298584, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.007753366604447365, 'loss_2': 0.013397216796875, 'loss_3': -16.292110443115234, 'loss_4': 0.5526685118675232, 'epoch': 15.83}
{'loss': 0.0041, 'grad_norm': 4.5124616622924805, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.004096622578799725, 'loss_2': 3.457069396972656e-05, 'loss_3': -16.6124267578125, 'loss_4': 0.9557502269744873, 'epoch': 15.84}
{'loss': 0.0126, 'grad_norm': 7.5704545974731445, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.0061997706070542336, 'loss_2': 0.0063934326171875, 'loss_3': -16.3458251953125, 'loss_4': 0.4003447890281677, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 16:24:57,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:57,976 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:36<42:41,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:25:05,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014780986122786999, 'eval_runtime': 4.0021, 'eval_samples_per_second': 255.865, 'eval_steps_per_second': 3.998, 'eval_loss_1': 0.012480455450713634, 'eval_loss_2': 0.0023005306720733643, 'eval_loss_3': -18.163330078125, 'eval_loss_4': 0.8515893816947937, 'epoch': 15.84}
{'loss': 0.008, 'grad_norm': 4.49289083480835, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.005349047482013702, 'loss_2': 0.0026397705078125, 'loss_3': -16.797161102294922, 'loss_4': 0.7033894062042236, 'epoch': 15.85}
{'loss': 0.0089, 'grad_norm': 5.016803741455078, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.006590521428734064, 'loss_2': 0.002346038818359375, 'loss_3': -16.36966323852539, 'loss_4': 0.7607723474502563, 'epoch': 15.85}
{'loss': 0.0085, 'grad_norm': 4.88380765914917, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.003462153719738126, 'loss_2': 0.005031585693359375, 'loss_3': -16.307636260986328, 'loss_4': 0.6330673098564148, 'epoch': 15.86}
{'loss': 0.0091, 'grad_norm': 4.760221004486084, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.004777991212904453, 'loss_2': 0.0042724609375, 'loss_3': -16.47344207763672, 'loss_4': 1.2192662954330444, 'epoch': 15.87}
{'loss': 0.0108, 'grad_norm': 4.416835784912109, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.003340770723298192, 'loss_2': 0.00748443603515625, 'loss_3': -16.52105140686035, 'loss_4': 1.0880427360534668, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 16:25:05,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:05,533 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:43<42:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:12,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019165676087141037, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01584695093333721, 'eval_loss_2': 0.0033187270164489746, 'eval_loss_3': -18.13551902770996, 'eval_loss_4': 1.114277958869934, 'epoch': 15.87}
{'loss': 0.0426, 'grad_norm': 23.032407760620117, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.03976385295391083, 'loss_2': 0.0027904510498046875, 'loss_3': -16.44379425048828, 'loss_4': 0.7752701044082642, 'epoch': 15.88}
{'loss': 0.0053, 'grad_norm': 4.697351932525635, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.003419765504077077, 'loss_2': 0.0019054412841796875, 'loss_3': -16.409835815429688, 'loss_4': 1.2469525337219238, 'epoch': 15.88}
{'loss': 0.0872, 'grad_norm': 19.483749389648438, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.08099056780338287, 'loss_2': 0.0061798095703125, 'loss_3': -16.3221492767334, 'loss_4': 1.2791190147399902, 'epoch': 15.89}
{'loss': 0.0252, 'grad_norm': 6.381113052368164, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.009607957676053047, 'loss_2': 0.0156402587890625, 'loss_3': -16.45006561279297, 'loss_4': 1.1770744323730469, 'epoch': 15.9}
{'loss': 0.0209, 'grad_norm': 4.7674689292907715, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.006567834876477718, 'loss_2': 0.014312744140625, 'loss_3': -16.52838134765625, 'loss_4': 1.1001076698303223, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 16:25:12,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:12,878 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:51<41:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:20,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02297278121113777, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.254, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01654483564198017, 'eval_loss_2': 0.006427943706512451, 'eval_loss_3': -18.1569881439209, 'eval_loss_4': 1.3319077491760254, 'epoch': 15.9}
{'loss': 0.0154, 'grad_norm': 6.127476215362549, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.010170625522732735, 'loss_2': 0.00524139404296875, 'loss_3': -16.350379943847656, 'loss_4': 0.9312247037887573, 'epoch': 15.91}
{'loss': 0.0152, 'grad_norm': 9.638456344604492, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.00910162553191185, 'loss_2': 0.00605010986328125, 'loss_3': -16.447967529296875, 'loss_4': 0.9984315037727356, 'epoch': 15.91}
{'loss': 0.0149, 'grad_norm': 5.160707950592041, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.0068479981273412704, 'loss_2': 0.00807952880859375, 'loss_3': -16.332069396972656, 'loss_4': 1.1981621980667114, 'epoch': 15.92}
{'loss': 0.0094, 'grad_norm': 5.7034173011779785, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.006349734030663967, 'loss_2': 0.0030422210693359375, 'loss_3': -16.399391174316406, 'loss_4': 1.314969539642334, 'epoch': 15.92}
{'loss': 0.004, 'grad_norm': 5.090239524841309, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.0038027639966458082, 'loss_2': 0.0001785755157470703, 'loss_3': -16.606876373291016, 'loss_4': 1.4873971939086914, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 16:25:20,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:20,229 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:58<41:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:27,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01764630898833275, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.338, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013839582912623882, 'eval_loss_2': 0.0038067251443862915, 'eval_loss_3': -18.170827865600586, 'eval_loss_4': 1.3743005990982056, 'epoch': 15.93}
{'loss': 0.0087, 'grad_norm': 5.020603656768799, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.004909707233309746, 'loss_2': 0.003757476806640625, 'loss_3': -16.2977294921875, 'loss_4': 1.473275065422058, 'epoch': 15.94}
{'loss': 0.0168, 'grad_norm': 6.139941692352295, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.0086911516264081, 'loss_2': 0.008087158203125, 'loss_3': -16.375164031982422, 'loss_4': 1.4939541816711426, 'epoch': 15.94}
{'loss': 0.0125, 'grad_norm': 6.114039897918701, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.00651190709322691, 'loss_2': 0.0059814453125, 'loss_3': -16.615455627441406, 'loss_4': 1.349229335784912, 'epoch': 15.95}
{'loss': 0.0061, 'grad_norm': 5.004361152648926, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.004467335529625416, 'loss_2': 0.0016450881958007812, 'loss_3': -16.496347427368164, 'loss_4': 1.5180785655975342, 'epoch': 15.95}
{'loss': 0.0134, 'grad_norm': 5.7291669845581055, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.006519523449242115, 'loss_2': 0.006893157958984375, 'loss_3': -16.47126007080078, 'loss_4': 1.3876079320907593, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 16:25:27,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:27,581 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:08:05<41:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:34,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016341131180524826, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.333, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013595376163721085, 'eval_loss_2': 0.0027457550168037415, 'eval_loss_3': -18.19866943359375, 'eval_loss_4': 1.3393326997756958, 'epoch': 15.96}
{'loss': 0.01, 'grad_norm': 4.646994590759277, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.0041314647532999516, 'loss_2': 0.005855560302734375, 'loss_3': -16.474773406982422, 'loss_4': 1.326002836227417, 'epoch': 15.97}
{'loss': 0.0113, 'grad_norm': 5.5036187171936035, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.006274507846683264, 'loss_2': 0.00505828857421875, 'loss_3': -16.40818214416504, 'loss_4': 1.4462754726409912, 'epoch': 15.97}
{'loss': 0.0157, 'grad_norm': 6.7546706199646, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.009205388836562634, 'loss_2': 0.006481170654296875, 'loss_3': -16.483814239501953, 'loss_4': 1.319030523300171, 'epoch': 15.98}
{'loss': 0.016, 'grad_norm': 5.004732608795166, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.003935841377824545, 'loss_2': 0.01201629638671875, 'loss_3': -16.469820022583008, 'loss_4': 1.2092022895812988, 'epoch': 15.98}
{'loss': 0.0175, 'grad_norm': 6.8261237144470215, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.008624104782938957, 'loss_2': 0.00885772705078125, 'loss_3': -16.300832748413086, 'loss_4': 1.1434400081634521, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 16:25:34,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:34,941 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:08:12<40:30,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:25:41,988 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01714472472667694, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.303, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011677638627588749, 'eval_loss_2': 0.005467087030410767, 'eval_loss_3': -18.181438446044922, 'eval_loss_4': 1.3495198488235474, 'epoch': 15.99}
{'loss': 0.0193, 'grad_norm': 5.403892517089844, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.0068574463948607445, 'loss_2': 0.012481689453125, 'loss_3': -16.474071502685547, 'loss_4': 1.2951852083206177, 'epoch': 15.99}
{'loss': 0.008, 'grad_norm': 6.341331958770752, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.003385592717677355, 'loss_2': 0.004634857177734375, 'loss_3': -16.526676177978516, 'loss_4': 1.100421667098999, 'epoch': 16.0}
{'loss': 0.0204, 'grad_norm': 5.231701374053955, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.007733936887234449, 'loss_2': 0.0126953125, 'loss_3': -16.477874755859375, 'loss_4': 1.2173573970794678, 'epoch': 16.01}
{'loss': 0.026, 'grad_norm': 10.496037483215332, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.023441683501005173, 'loss_2': 0.0025634765625, 'loss_3': -16.35340690612793, 'loss_4': 0.9372968673706055, 'epoch': 16.01}
{'loss': 0.0071, 'grad_norm': 4.599029541015625, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.003065831260755658, 'loss_2': 0.0040130615234375, 'loss_3': -16.68757438659668, 'loss_4': 0.8051763772964478, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 16:25:41,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:41,988 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:20<41:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:25:49,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013332117348909378, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.908, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01067108940333128, 'eval_loss_2': 0.0026610270142555237, 'eval_loss_3': -18.161285400390625, 'eval_loss_4': 1.2541320323944092, 'epoch': 16.02}
{'loss': 0.019, 'grad_norm': 15.142902374267578, 'learning_rate': 1.4e-05, 'loss_1': 0.013533606193959713, 'loss_2': 0.0055084228515625, 'loss_3': -16.62035369873047, 'loss_4': 1.5164909362792969, 'epoch': 16.02}
{'loss': 0.0042, 'grad_norm': 4.6644487380981445, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.0033045154996216297, 'loss_2': 0.0009441375732421875, 'loss_3': -16.329160690307617, 'loss_4': 1.2280923128128052, 'epoch': 16.03}
{'loss': 0.0112, 'grad_norm': 4.666171550750732, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.00354690570384264, 'loss_2': 0.00760650634765625, 'loss_3': -16.547388076782227, 'loss_4': 1.4016040563583374, 'epoch': 16.03}
{'loss': 0.0174, 'grad_norm': 10.354915618896484, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.016103779897093773, 'loss_2': 0.00125885009765625, 'loss_3': -16.179542541503906, 'loss_4': 1.223766565322876, 'epoch': 16.04}
{'loss': 0.0759, 'grad_norm': 21.468942642211914, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.07153929769992828, 'loss_2': 0.004367828369140625, 'loss_3': -16.41562843322754, 'loss_4': 1.308790683746338, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 16:25:49,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:49,344 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:27<41:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:56,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019149400293827057, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011545514687895775, 'eval_loss_2': 0.007603883743286133, 'eval_loss_3': -18.157522201538086, 'eval_loss_4': 1.2687313556671143, 'epoch': 16.05}
{'loss': 0.0061, 'grad_norm': 5.191407203674316, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.0055938721634447575, 'loss_2': 0.0005269050598144531, 'loss_3': -16.46164894104004, 'loss_4': 1.3052185773849487, 'epoch': 16.05}
{'loss': 0.0207, 'grad_norm': 5.963978290557861, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.00843280740082264, 'loss_2': 0.01226806640625, 'loss_3': -16.530866622924805, 'loss_4': 1.0246903896331787, 'epoch': 16.06}
{'loss': 0.0215, 'grad_norm': 6.796329021453857, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.012426991946995258, 'loss_2': 0.00911712646484375, 'loss_3': -16.47791290283203, 'loss_4': 0.9968535900115967, 'epoch': 16.06}
{'loss': 0.0152, 'grad_norm': 5.545570373535156, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.00524758268147707, 'loss_2': 0.00994873046875, 'loss_3': -16.574504852294922, 'loss_4': 1.143254041671753, 'epoch': 16.07}
{'loss': 0.0149, 'grad_norm': 8.400184631347656, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.013919125311076641, 'loss_2': 0.0009393692016601562, 'loss_3': -16.47222137451172, 'loss_4': 1.4203920364379883, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 16:25:56,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:56,697 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:34<41:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:04,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017531704157590866, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.801, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011867683380842209, 'eval_loss_2': 0.005664020776748657, 'eval_loss_3': -18.15097427368164, 'eval_loss_4': 1.4638715982437134, 'epoch': 16.08}
{'loss': 0.0123, 'grad_norm': 6.308701515197754, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.010555418208241463, 'loss_2': 0.0017385482788085938, 'loss_3': -16.443920135498047, 'loss_4': 1.3673924207687378, 'epoch': 16.08}
{'loss': 0.0358, 'grad_norm': 13.190864562988281, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.0324719063937664, 'loss_2': 0.00336456298828125, 'loss_3': -16.535415649414062, 'loss_4': 1.1606918573379517, 'epoch': 16.09}
{'loss': 0.0139, 'grad_norm': 8.073531150817871, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.009511656127870083, 'loss_2': 0.004390716552734375, 'loss_3': -16.42121124267578, 'loss_4': 1.562713384628296, 'epoch': 16.09}
{'loss': 0.0234, 'grad_norm': 9.466710090637207, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.012579645030200481, 'loss_2': 0.01080322265625, 'loss_3': -16.40682601928711, 'loss_4': 1.5815789699554443, 'epoch': 16.1}
{'loss': 0.004, 'grad_norm': 4.785726070404053, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.0039696721360087395, 'loss_2': 2.1457672119140625e-06, 'loss_3': -16.567169189453125, 'loss_4': 1.5003496408462524, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 16:26:04,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:04,051 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:42<41:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:11,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014924764633178711, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.604, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012062444351613522, 'eval_loss_2': 0.0028623193502426147, 'eval_loss_3': -18.168426513671875, 'eval_loss_4': 1.6018116474151611, 'epoch': 16.1}
{'loss': 0.0101, 'grad_norm': 4.9343061447143555, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.005628430284559727, 'loss_2': 0.0045013427734375, 'loss_3': -16.53105354309082, 'loss_4': 1.1670124530792236, 'epoch': 16.11}
{'loss': 0.0076, 'grad_norm': 5.562169075012207, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.0073254723101854324, 'loss_2': 0.00032067298889160156, 'loss_3': -16.531173706054688, 'loss_4': 1.8000520467758179, 'epoch': 16.12}
{'loss': 0.0134, 'grad_norm': 6.176030158996582, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.008974998258054256, 'loss_2': 0.004467010498046875, 'loss_3': -16.5179386138916, 'loss_4': 1.3499584197998047, 'epoch': 16.12}
{'loss': 0.0106, 'grad_norm': 5.020651340484619, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.005486614536494017, 'loss_2': 0.005096435546875, 'loss_3': -16.295299530029297, 'loss_4': 1.003037452697754, 'epoch': 16.13}
{'loss': 0.0072, 'grad_norm': 5.4001569747924805, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.006497906055301428, 'loss_2': 0.0006866455078125, 'loss_3': -16.479717254638672, 'loss_4': 1.3339040279388428, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 16:26:11,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:11,395 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:49<41:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:18,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01421638485044241, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.442, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011400151066482067, 'eval_loss_2': 0.0028162337839603424, 'eval_loss_3': -18.205080032348633, 'eval_loss_4': 1.700092077255249, 'epoch': 16.13}
{'loss': 0.0056, 'grad_norm': 4.908973693847656, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.00444317189976573, 'loss_2': 0.001140594482421875, 'loss_3': -16.60621452331543, 'loss_4': 1.881798267364502, 'epoch': 16.14}
{'loss': 0.0109, 'grad_norm': 4.805524826049805, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.004606645554304123, 'loss_2': 0.0062713623046875, 'loss_3': -16.46136474609375, 'loss_4': 1.2783286571502686, 'epoch': 16.15}
{'loss': 0.0099, 'grad_norm': 4.648791790008545, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.009191048331558704, 'loss_2': 0.0007338523864746094, 'loss_3': -16.459667205810547, 'loss_4': 1.9288995265960693, 'epoch': 16.15}
{'loss': 0.0159, 'grad_norm': 8.702326774597168, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.009845089167356491, 'loss_2': 0.00605010986328125, 'loss_3': -16.599620819091797, 'loss_4': 1.5075666904449463, 'epoch': 16.16}
{'loss': 0.0069, 'grad_norm': 4.47642183303833, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.005050212610512972, 'loss_2': 0.00185394287109375, 'loss_3': -16.54077911376953, 'loss_4': 1.6455771923065186, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 16:26:18,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:18,756 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:56<41:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:26,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013827585615217686, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.58, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010509604588150978, 'eval_loss_2': 0.0033179819583892822, 'eval_loss_3': -18.248733520507812, 'eval_loss_4': 1.7471632957458496, 'epoch': 16.16}
{'loss': 0.0164, 'grad_norm': 10.00393009185791, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.01443298626691103, 'loss_2': 0.00201416015625, 'loss_3': -16.430782318115234, 'loss_4': 1.5450010299682617, 'epoch': 16.17}
{'loss': 0.0284, 'grad_norm': 8.790621757507324, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.02078578807413578, 'loss_2': 0.00762939453125, 'loss_3': -16.545482635498047, 'loss_4': 1.8643176555633545, 'epoch': 16.17}
{'loss': 0.0288, 'grad_norm': 10.77113151550293, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.025638006627559662, 'loss_2': 0.003147125244140625, 'loss_3': -16.370412826538086, 'loss_4': 1.912543773651123, 'epoch': 16.18}
{'loss': 0.0091, 'grad_norm': 5.508256435394287, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.008610112592577934, 'loss_2': 0.0005369186401367188, 'loss_3': -16.490524291992188, 'loss_4': 1.58154296875, 'epoch': 16.19}
{'loss': 0.007, 'grad_norm': 4.5807719230651855, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.004975627176463604, 'loss_2': 0.0020599365234375, 'loss_3': -16.40816879272461, 'loss_4': 1.7669355869293213, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 16:26:26,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:26,126 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:09:04<41:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:33,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013826942071318626, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010597571730613708, 'eval_loss_2': 0.003229372203350067, 'eval_loss_3': -18.270832061767578, 'eval_loss_4': 1.7421636581420898, 'epoch': 16.19}
{'loss': 0.0094, 'grad_norm': 5.153401851654053, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.007108733523637056, 'loss_2': 0.002246856689453125, 'loss_3': -16.636457443237305, 'loss_4': 1.7299690246582031, 'epoch': 16.2}
{'loss': 0.0162, 'grad_norm': 6.23919153213501, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.010361862368881702, 'loss_2': 0.005828857421875, 'loss_3': -16.45260238647461, 'loss_4': 1.3740346431732178, 'epoch': 16.2}
{'loss': 0.0056, 'grad_norm': 4.591647148132324, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.004272102378308773, 'loss_2': 0.0013484954833984375, 'loss_3': -16.50777816772461, 'loss_4': 1.380771517753601, 'epoch': 16.21}
{'loss': 0.0218, 'grad_norm': 7.033192157745361, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.019247449934482574, 'loss_2': 0.00260162353515625, 'loss_3': -16.434417724609375, 'loss_4': 1.4127010107040405, 'epoch': 16.22}
{'loss': 0.0222, 'grad_norm': 10.611419677734375, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.017578139901161194, 'loss_2': 0.00464630126953125, 'loss_3': -16.427459716796875, 'loss_4': 1.9709841012954712, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 16:26:33,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:33,480 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:09:11<41:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:40,840 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013158347457647324, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.368, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010526339523494244, 'eval_loss_2': 0.0026320070028305054, 'eval_loss_3': -18.28921890258789, 'eval_loss_4': 1.6649763584136963, 'epoch': 16.22}
{'loss': 0.0328, 'grad_norm': 15.402175903320312, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.027778765186667442, 'loss_2': 0.005039215087890625, 'loss_3': -16.296260833740234, 'loss_4': 1.5798169374465942, 'epoch': 16.23}
{'loss': 0.0124, 'grad_norm': 6.294140815734863, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.010128948837518692, 'loss_2': 0.0023193359375, 'loss_3': -16.585987091064453, 'loss_4': 1.5191318988800049, 'epoch': 16.23}
{'loss': 0.0125, 'grad_norm': 5.658663749694824, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.012302768416702747, 'loss_2': 0.00021982192993164062, 'loss_3': -16.48088836669922, 'loss_4': 1.5181984901428223, 'epoch': 16.24}
{'loss': 0.0234, 'grad_norm': 12.824174880981445, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.0217987559735775, 'loss_2': 0.00164794921875, 'loss_3': -16.629436492919922, 'loss_4': 2.055267810821533, 'epoch': 16.24}
{'loss': 0.01, 'grad_norm': 5.140108108520508, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.005536837037652731, 'loss_2': 0.00449371337890625, 'loss_3': -16.658292770385742, 'loss_4': 1.6612523794174194, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 16:26:40,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:40,840 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:19<40:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:48,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014257481321692467, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.749, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00970243476331234, 'eval_loss_2': 0.004555046558380127, 'eval_loss_3': -18.299129486083984, 'eval_loss_4': 1.5477412939071655, 'epoch': 16.25}
{'loss': 0.0166, 'grad_norm': 4.574121952056885, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.008796433918178082, 'loss_2': 0.0077972412109375, 'loss_3': -16.44481658935547, 'loss_4': 1.7414507865905762, 'epoch': 16.26}
{'loss': 0.0136, 'grad_norm': 4.787869453430176, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.007904059253633022, 'loss_2': 0.00574493408203125, 'loss_3': -16.578353881835938, 'loss_4': 1.087724208831787, 'epoch': 16.26}
{'loss': 0.0082, 'grad_norm': 5.357644557952881, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.006637449376285076, 'loss_2': 0.0015554428100585938, 'loss_3': -16.571788787841797, 'loss_4': 1.7045385837554932, 'epoch': 16.27}
{'loss': 0.0088, 'grad_norm': 5.5417304039001465, 'learning_rate': 1.375e-05, 'loss_1': 0.007971245795488358, 'loss_2': 0.0008420944213867188, 'loss_3': -16.606218338012695, 'loss_4': 1.4440652132034302, 'epoch': 16.27}
{'loss': 0.0102, 'grad_norm': 5.673256874084473, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.008806837722659111, 'loss_2': 0.001377105712890625, 'loss_3': -16.604211807250977, 'loss_4': 1.6719377040863037, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 16:26:48,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:48,191 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:26<40:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:55,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01329534500837326, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010470852255821228, 'eval_loss_2': 0.0028244927525520325, 'eval_loss_3': -18.28337860107422, 'eval_loss_4': 1.438753366470337, 'epoch': 16.28}
{'loss': 0.0149, 'grad_norm': 8.006141662597656, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.011362003162503242, 'loss_2': 0.00354766845703125, 'loss_3': -16.49701690673828, 'loss_4': 1.6648118495941162, 'epoch': 16.28}
{'loss': 0.0225, 'grad_norm': 8.820082664489746, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.015132657252252102, 'loss_2': 0.007396697998046875, 'loss_3': -16.40367889404297, 'loss_4': 1.4891445636749268, 'epoch': 16.29}
{'loss': 0.02, 'grad_norm': 7.001280307769775, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.017795061692595482, 'loss_2': 0.00218963623046875, 'loss_3': -16.51276969909668, 'loss_4': 1.63625168800354, 'epoch': 16.3}
{'loss': 0.0078, 'grad_norm': 5.0923333168029785, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.004397380631417036, 'loss_2': 0.0034332275390625, 'loss_3': -16.543607711791992, 'loss_4': 1.2254375219345093, 'epoch': 16.3}
{'loss': 0.0166, 'grad_norm': 15.672978401184082, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.015486853197216988, 'loss_2': 0.0010814666748046875, 'loss_3': -16.708955764770508, 'loss_4': 1.2551169395446777, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 16:26:55,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:55,548 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:33<40:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:02,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013328611850738525, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010337083600461483, 'eval_loss_2': 0.0029915273189544678, 'eval_loss_3': -18.264968872070312, 'eval_loss_4': 1.4120538234710693, 'epoch': 16.31}
{'loss': 0.019, 'grad_norm': 8.37305736541748, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.01477109920233488, 'loss_2': 0.004245758056640625, 'loss_3': -16.657140731811523, 'loss_4': 1.2364909648895264, 'epoch': 16.31}
{'loss': 0.0106, 'grad_norm': 6.189701080322266, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.008046092465519905, 'loss_2': 0.002597808837890625, 'loss_3': -16.61372947692871, 'loss_4': 1.4688196182250977, 'epoch': 16.32}
{'loss': 0.0138, 'grad_norm': 5.443473815917969, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.010402783751487732, 'loss_2': 0.003421783447265625, 'loss_3': -16.715055465698242, 'loss_4': 1.511847734451294, 'epoch': 16.33}
{'loss': 0.0097, 'grad_norm': 6.237148284912109, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.007300293073058128, 'loss_2': 0.00241851806640625, 'loss_3': -16.323013305664062, 'loss_4': 0.8099608421325684, 'epoch': 16.33}
{'loss': 0.0048, 'grad_norm': 4.731597423553467, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.003832862013950944, 'loss_2': 0.0009899139404296875, 'loss_3': -16.542627334594727, 'loss_4': 1.3986656665802002, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 16:27:02,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:02,908 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:41<40:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:10,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014277691021561623, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.551, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010699625127017498, 'eval_loss_2': 0.0035780668258666992, 'eval_loss_3': -18.266868591308594, 'eval_loss_4': 1.4181023836135864, 'epoch': 16.34}
{'loss': 0.0227, 'grad_norm': 7.4136576652526855, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.014071636833250523, 'loss_2': 0.0085906982421875, 'loss_3': -16.712966918945312, 'loss_4': 1.5659153461456299, 'epoch': 16.34}
{'loss': 0.0096, 'grad_norm': 5.537311553955078, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.007866203784942627, 'loss_2': 0.0017232894897460938, 'loss_3': -16.64864158630371, 'loss_4': 1.0673502683639526, 'epoch': 16.35}
{'loss': 0.0086, 'grad_norm': 5.294501304626465, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.006232571788132191, 'loss_2': 0.002330780029296875, 'loss_3': -16.561111450195312, 'loss_4': 1.3129549026489258, 'epoch': 16.35}
{'loss': 0.0347, 'grad_norm': 16.275733947753906, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.033812858164310455, 'loss_2': 0.0009369850158691406, 'loss_3': -16.678802490234375, 'loss_4': 1.4564156532287598, 'epoch': 16.36}
{'loss': 0.0107, 'grad_norm': 5.039280414581299, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.00708675105124712, 'loss_2': 0.0036163330078125, 'loss_3': -16.68252182006836, 'loss_4': 0.9871567487716675, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 16:27:10,266 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:10,266 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:48<40:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:17,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014442520216107368, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009855853393673897, 'eval_loss_2': 0.004586666822433472, 'eval_loss_3': -18.247888565063477, 'eval_loss_4': 1.448718786239624, 'epoch': 16.37}
{'loss': 0.0123, 'grad_norm': 5.290690898895264, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.006909754127264023, 'loss_2': 0.00542449951171875, 'loss_3': -16.564462661743164, 'loss_4': 1.3786747455596924, 'epoch': 16.37}
{'loss': 0.0079, 'grad_norm': 4.7802534103393555, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.0070475563406944275, 'loss_2': 0.0008449554443359375, 'loss_3': -16.481616973876953, 'loss_4': 1.7194783687591553, 'epoch': 16.38}
{'loss': 0.0102, 'grad_norm': 4.811562538146973, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.006093177013099194, 'loss_2': 0.00411224365234375, 'loss_3': -16.52470588684082, 'loss_4': 1.468849778175354, 'epoch': 16.38}
{'loss': 0.0068, 'grad_norm': 4.916947364807129, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.0065390076488256454, 'loss_2': 0.0002205371856689453, 'loss_3': -16.45561981201172, 'loss_4': 1.1605908870697021, 'epoch': 16.39}
{'loss': 0.0095, 'grad_norm': 7.893615245819092, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.009098177775740623, 'loss_2': 0.0003638267517089844, 'loss_3': -16.561344146728516, 'loss_4': 1.821724772453308, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 16:27:17,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:17,620 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:55<40:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:24,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015776915475726128, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00950540229678154, 'eval_loss_2': 0.0062715113162994385, 'eval_loss_3': -18.251741409301758, 'eval_loss_4': 1.476542592048645, 'epoch': 16.4}
{'loss': 0.0107, 'grad_norm': 5.55211877822876, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.009217576123774052, 'loss_2': 0.0014429092407226562, 'loss_3': -16.528478622436523, 'loss_4': 1.458221673965454, 'epoch': 16.4}
{'loss': 0.0074, 'grad_norm': 5.404627799987793, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.005744244437664747, 'loss_2': 0.00164794921875, 'loss_3': -16.51616668701172, 'loss_4': 1.4023914337158203, 'epoch': 16.41}
{'loss': 0.0169, 'grad_norm': 13.070856094360352, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.012521729804575443, 'loss_2': 0.00441741943359375, 'loss_3': -16.56277847290039, 'loss_4': 1.6785719394683838, 'epoch': 16.41}
{'loss': 0.006, 'grad_norm': 4.817314624786377, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.004658993799239397, 'loss_2': 0.001384735107421875, 'loss_3': -16.48050308227539, 'loss_4': 1.3432750701904297, 'epoch': 16.42}
{'loss': 0.0164, 'grad_norm': 4.573152542114258, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.004213373176753521, 'loss_2': 0.0122222900390625, 'loss_3': -16.580059051513672, 'loss_4': 1.2249810695648193, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 16:27:24,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:24,973 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:10:03<40:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:32,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015336175449192524, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.63, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008941639214754105, 'eval_loss_2': 0.006394535303115845, 'eval_loss_3': -18.276798248291016, 'eval_loss_4': 1.5913987159729004, 'epoch': 16.42}
{'loss': 0.0051, 'grad_norm': 4.748347759246826, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.004888680297881365, 'loss_2': 0.0002162456512451172, 'loss_3': -16.509571075439453, 'loss_4': 1.171015739440918, 'epoch': 16.43}
{'loss': 0.0044, 'grad_norm': 4.743164539337158, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.0030687495600432158, 'loss_2': 0.0012969970703125, 'loss_3': -16.61725616455078, 'loss_4': 1.5465447902679443, 'epoch': 16.44}
{'loss': 0.0077, 'grad_norm': 5.6420440673828125, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.007509633433073759, 'loss_2': 0.0001926422119140625, 'loss_3': -16.61559295654297, 'loss_4': 1.5278725624084473, 'epoch': 16.44}
{'loss': 0.0125, 'grad_norm': 4.626221656799316, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.00741524389013648, 'loss_2': 0.00510406494140625, 'loss_3': -16.56871795654297, 'loss_4': 1.8209137916564941, 'epoch': 16.45}
{'loss': 0.01, 'grad_norm': 7.18936014175415, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.008780903182923794, 'loss_2': 0.001171112060546875, 'loss_3': -16.671207427978516, 'loss_4': 2.0500917434692383, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 16:27:32,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:32,321 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:10:10<40:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:39,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012075883336365223, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.954, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009227125905454159, 'eval_loss_2': 0.0028487592935562134, 'eval_loss_3': -18.26711654663086, 'eval_loss_4': 1.7237255573272705, 'epoch': 16.45}
{'loss': 0.0139, 'grad_norm': 5.040309906005859, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.006383515428751707, 'loss_2': 0.007541656494140625, 'loss_3': -16.32740020751953, 'loss_4': 1.4913716316223145, 'epoch': 16.46}
{'loss': 0.0284, 'grad_norm': 18.343015670776367, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.022834783419966698, 'loss_2': 0.00559234619140625, 'loss_3': -16.589271545410156, 'loss_4': 1.1279771327972412, 'epoch': 16.47}
{'loss': 0.0074, 'grad_norm': 4.866140842437744, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.005200973246246576, 'loss_2': 0.0021800994873046875, 'loss_3': -16.61797332763672, 'loss_4': 1.6481637954711914, 'epoch': 16.47}
{'loss': 0.0155, 'grad_norm': 9.421192169189453, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.012391258031129837, 'loss_2': 0.00310516357421875, 'loss_3': -16.419654846191406, 'loss_4': 1.6630885601043701, 'epoch': 16.48}
{'loss': 0.0214, 'grad_norm': 5.741000652313232, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.014448312111198902, 'loss_2': 0.006992340087890625, 'loss_3': -16.550914764404297, 'loss_4': 1.8456401824951172, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 16:27:39,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:39,681 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:17<40:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:47,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016107315197587013, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.396, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011861365288496017, 'eval_loss_2': 0.004245951771736145, 'eval_loss_3': -18.244815826416016, 'eval_loss_4': 1.759436845779419, 'epoch': 16.48}
{'loss': 0.0184, 'grad_norm': 9.10849666595459, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.013306078501045704, 'loss_2': 0.005062103271484375, 'loss_3': -16.488712310791016, 'loss_4': 1.6589398384094238, 'epoch': 16.49}
{'loss': 0.0304, 'grad_norm': 15.406601905822754, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.028036043047904968, 'loss_2': 0.002349853515625, 'loss_3': -16.541542053222656, 'loss_4': 1.757726788520813, 'epoch': 16.49}
{'loss': 0.0206, 'grad_norm': 7.2458953857421875, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.01121815387159586, 'loss_2': 0.00942230224609375, 'loss_3': -16.459922790527344, 'loss_4': 1.400557518005371, 'epoch': 16.5}
{'loss': 0.0119, 'grad_norm': 5.10381555557251, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.0047716014087200165, 'loss_2': 0.00710296630859375, 'loss_3': -16.538930892944336, 'loss_4': 1.697250485420227, 'epoch': 16.51}
{'loss': 0.0145, 'grad_norm': 5.392847061157227, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.00476044649258256, 'loss_2': 0.00971221923828125, 'loss_3': -16.30812644958496, 'loss_4': 1.5143673419952393, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 16:27:47,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:47,035 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:25<40:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:54,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016058553010225296, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012816904112696648, 'eval_loss_2': 0.0032416507601737976, 'eval_loss_3': -18.222511291503906, 'eval_loss_4': 1.7901408672332764, 'epoch': 16.51}
{'loss': 0.0148, 'grad_norm': 6.203820705413818, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.00932522863149643, 'loss_2': 0.00548553466796875, 'loss_3': -16.468990325927734, 'loss_4': 1.895397663116455, 'epoch': 16.52}
{'loss': 0.008, 'grad_norm': 4.867252349853516, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.004860314074903727, 'loss_2': 0.00313568115234375, 'loss_3': -16.42475128173828, 'loss_4': 1.7166606187820435, 'epoch': 16.52}
{'loss': 0.0232, 'grad_norm': 11.986242294311523, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.02314160019159317, 'loss_2': 8.881092071533203e-05, 'loss_3': -16.590951919555664, 'loss_4': 1.5418691635131836, 'epoch': 16.53}
{'loss': 0.0112, 'grad_norm': 4.749839782714844, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.006123291794210672, 'loss_2': 0.0050506591796875, 'loss_3': -16.44811248779297, 'loss_4': 1.609778881072998, 'epoch': 16.53}
{'loss': 0.0726, 'grad_norm': 22.455673217773438, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.06752647459506989, 'loss_2': 0.00505828857421875, 'loss_3': -16.326065063476562, 'loss_4': 1.8485966920852661, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 16:27:54,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:54,390 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:32<40:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:01,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01798439770936966, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.727, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01436456199735403, 'eval_loss_2': 0.003619834780693054, 'eval_loss_3': -18.194091796875, 'eval_loss_4': 1.797478437423706, 'epoch': 16.54}
{'loss': 0.0094, 'grad_norm': 4.828127384185791, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.006282234564423561, 'loss_2': 0.003147125244140625, 'loss_3': -16.418033599853516, 'loss_4': 1.5858904123306274, 'epoch': 16.55}
{'loss': 0.0078, 'grad_norm': 5.075291156768799, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.005737987346947193, 'loss_2': 0.002063751220703125, 'loss_3': -16.567352294921875, 'loss_4': 1.6688156127929688, 'epoch': 16.55}
{'loss': 0.0128, 'grad_norm': 4.896563529968262, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.007984552532434464, 'loss_2': 0.004795074462890625, 'loss_3': -16.462242126464844, 'loss_4': 1.7354741096496582, 'epoch': 16.56}
{'loss': 0.0096, 'grad_norm': 5.628450393676758, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.005835460964590311, 'loss_2': 0.0037250518798828125, 'loss_3': -16.49720001220703, 'loss_4': 1.799068570137024, 'epoch': 16.56}
{'loss': 0.0063, 'grad_norm': 5.679448127746582, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.004554302431643009, 'loss_2': 0.00171661376953125, 'loss_3': -16.556840896606445, 'loss_4': 1.5561031103134155, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 16:28:01,740 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:01,740 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:39<39:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:09,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017413802444934845, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01420412864536047, 'eval_loss_2': 0.0032096728682518005, 'eval_loss_3': -18.187620162963867, 'eval_loss_4': 1.8854299783706665, 'epoch': 16.57}
{'loss': 0.0115, 'grad_norm': 4.505028247833252, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.0023356424644589424, 'loss_2': 0.009124755859375, 'loss_3': -16.564292907714844, 'loss_4': 1.4256269931793213, 'epoch': 16.58}
{'loss': 0.0154, 'grad_norm': 16.476022720336914, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.014863001182675362, 'loss_2': 0.0005745887756347656, 'loss_3': -16.598936080932617, 'loss_4': 1.8100881576538086, 'epoch': 16.58}
{'loss': 0.0111, 'grad_norm': 5.811305522918701, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.01073613204061985, 'loss_2': 0.00036525726318359375, 'loss_3': -16.33640480041504, 'loss_4': 1.6818463802337646, 'epoch': 16.59}
{'loss': 0.0204, 'grad_norm': 10.144027709960938, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.016148149967193604, 'loss_2': 0.0042572021484375, 'loss_3': -16.27639389038086, 'loss_4': 1.8927640914916992, 'epoch': 16.59}
{'loss': 0.0089, 'grad_norm': 4.715494632720947, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.007701658643782139, 'loss_2': 0.0011606216430664062, 'loss_3': -16.400142669677734, 'loss_4': 1.9396106004714966, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 16:28:09,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:09,093 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:47<39:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:16,455 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015722598880529404, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.472, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011958729475736618, 'eval_loss_2': 0.0037638694047927856, 'eval_loss_3': -18.209932327270508, 'eval_loss_4': 1.9903295040130615, 'epoch': 16.6}
{'loss': 0.0147, 'grad_norm': 4.607387065887451, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.004481189418584108, 'loss_2': 0.0102386474609375, 'loss_3': -16.572696685791016, 'loss_4': 1.9184770584106445, 'epoch': 16.6}
{'loss': 0.0133, 'grad_norm': 5.887211322784424, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.009699334390461445, 'loss_2': 0.0036106109619140625, 'loss_3': -16.27467155456543, 'loss_4': 1.8907126188278198, 'epoch': 16.61}
{'loss': 0.0202, 'grad_norm': 6.589324951171875, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.014955754391849041, 'loss_2': 0.00522613525390625, 'loss_3': -16.576061248779297, 'loss_4': 2.060852527618408, 'epoch': 16.62}
{'loss': 0.0379, 'grad_norm': 15.230305671691895, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.03685581311583519, 'loss_2': 0.0010623931884765625, 'loss_3': -16.314434051513672, 'loss_4': 2.0310356616973877, 'epoch': 16.62}
{'loss': 0.017, 'grad_norm': 6.229379653930664, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.01335078477859497, 'loss_2': 0.00365447998046875, 'loss_3': -16.506492614746094, 'loss_4': 2.04394793510437, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 16:28:16,456 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:16,456 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:54<39:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:23,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01613323576748371, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.012, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01276479847729206, 'eval_loss_2': 0.0033684372901916504, 'eval_loss_3': -18.249107360839844, 'eval_loss_4': 2.082512617111206, 'epoch': 16.63}
{'loss': 0.0174, 'grad_norm': 7.573572635650635, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.011307073757052422, 'loss_2': 0.006134033203125, 'loss_3': -16.502384185791016, 'loss_4': 1.9982672929763794, 'epoch': 16.63}
{'loss': 0.0213, 'grad_norm': 15.430689811706543, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.018995415419340134, 'loss_2': 0.0022869110107421875, 'loss_3': -16.512924194335938, 'loss_4': 1.8636900186538696, 'epoch': 16.64}
{'loss': 0.0114, 'grad_norm': 5.71539306640625, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.009229054674506187, 'loss_2': 0.00222015380859375, 'loss_3': -16.482269287109375, 'loss_4': 1.9846408367156982, 'epoch': 16.65}
{'loss': 0.0139, 'grad_norm': 5.448347091674805, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.006880070082843304, 'loss_2': 0.00699615478515625, 'loss_3': -16.62055778503418, 'loss_4': 1.6684590578079224, 'epoch': 16.65}
{'loss': 0.0085, 'grad_norm': 6.601074695587158, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.008065370842814445, 'loss_2': 0.000438690185546875, 'loss_3': -16.49262046813965, 'loss_4': 2.073029041290283, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 16:28:23,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:23,822 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:11:02<39:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:31,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018585743382573128, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014572800137102604, 'eval_loss_2': 0.004012942314147949, 'eval_loss_3': -18.268251419067383, 'eval_loss_4': 2.175262212753296, 'epoch': 16.66}
{'loss': 0.0191, 'grad_norm': 13.202527046203613, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.016674375161528587, 'loss_2': 0.002468109130859375, 'loss_3': -16.287094116210938, 'loss_4': 2.084127902984619, 'epoch': 16.66}
{'loss': 0.0105, 'grad_norm': 5.267703056335449, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.0066564069129526615, 'loss_2': 0.0038299560546875, 'loss_3': -16.591064453125, 'loss_4': 1.7643756866455078, 'epoch': 16.67}
{'loss': 0.0089, 'grad_norm': 4.853949069976807, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.005482187960296869, 'loss_2': 0.0034656524658203125, 'loss_3': -16.662710189819336, 'loss_4': 1.905665636062622, 'epoch': 16.67}
{'loss': 0.0198, 'grad_norm': 5.372957706451416, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.010420103557407856, 'loss_2': 0.009368896484375, 'loss_3': -16.575912475585938, 'loss_4': 1.8445762395858765, 'epoch': 16.68}
{'loss': 0.011, 'grad_norm': 5.767958641052246, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.010912656784057617, 'loss_2': 4.184246063232422e-05, 'loss_3': -16.478925704956055, 'loss_4': 2.1252386569976807, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 16:28:31,181 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:31,182 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:11:09<39:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:38,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017221610993146896, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.751, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013512109406292439, 'eval_loss_2': 0.0037095025181770325, 'eval_loss_3': -18.29048728942871, 'eval_loss_4': 2.206310510635376, 'epoch': 16.69}
{'loss': 0.0239, 'grad_norm': 14.50389575958252, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.021606320515275, 'loss_2': 0.0022830963134765625, 'loss_3': -16.286357879638672, 'loss_4': 2.139685869216919, 'epoch': 16.69}
{'loss': 0.0203, 'grad_norm': 8.164307594299316, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.016231512650847435, 'loss_2': 0.00409698486328125, 'loss_3': -16.520896911621094, 'loss_4': 2.1040282249450684, 'epoch': 16.7}
{'loss': 0.0093, 'grad_norm': 5.221324920654297, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.005420712288469076, 'loss_2': 0.0038909912109375, 'loss_3': -16.481481552124023, 'loss_4': 2.22584867477417, 'epoch': 16.7}
{'loss': 0.0191, 'grad_norm': 7.685379981994629, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.011033677496016026, 'loss_2': 0.008056640625, 'loss_3': -16.483610153198242, 'loss_4': 2.2884297370910645, 'epoch': 16.71}
{'loss': 0.0226, 'grad_norm': 6.764183044433594, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.017935432493686676, 'loss_2': 0.004669189453125, 'loss_3': -16.43133544921875, 'loss_4': 2.5059728622436523, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 16:28:38,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:38,536 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:16<39:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:45,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017733892425894737, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.739, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014152472838759422, 'eval_loss_2': 0.003581419587135315, 'eval_loss_3': -18.311859130859375, 'eval_loss_4': 2.2743396759033203, 'epoch': 16.72}
{'loss': 0.0165, 'grad_norm': 5.551185131072998, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.007690856698900461, 'loss_2': 0.0087738037109375, 'loss_3': -16.481666564941406, 'loss_4': 2.221172332763672, 'epoch': 16.72}
{'loss': 0.0127, 'grad_norm': 5.535121917724609, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.011218482628464699, 'loss_2': 0.0014581680297851562, 'loss_3': -16.63098907470703, 'loss_4': 2.302945137023926, 'epoch': 16.73}
{'loss': 0.0121, 'grad_norm': 5.865006923675537, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.010122667998075485, 'loss_2': 0.0019330978393554688, 'loss_3': -16.540271759033203, 'loss_4': 2.484598159790039, 'epoch': 16.73}
{'loss': 0.0136, 'grad_norm': 5.729849815368652, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.008134456351399422, 'loss_2': 0.005504608154296875, 'loss_3': -16.488807678222656, 'loss_4': 2.2956573963165283, 'epoch': 16.74}
{'loss': 0.0137, 'grad_norm': 5.987144470214844, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.011915535666048527, 'loss_2': 0.00180816650390625, 'loss_3': -16.667158126831055, 'loss_4': 2.172454833984375, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 16:28:45,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:45,894 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:24<39:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:53,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01879437267780304, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.015194462612271309, 'eval_loss_2': 0.00359991192817688, 'eval_loss_3': -18.324962615966797, 'eval_loss_4': 2.1567087173461914, 'epoch': 16.74}
{'loss': 0.0182, 'grad_norm': 4.991943359375, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.008442942053079605, 'loss_2': 0.00972747802734375, 'loss_3': -16.50849723815918, 'loss_4': 2.214153289794922, 'epoch': 16.75}
{'loss': 0.0129, 'grad_norm': 4.9357194900512695, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.011699382215738297, 'loss_2': 0.0012149810791015625, 'loss_3': -16.41657066345215, 'loss_4': 2.2078330516815186, 'epoch': 16.76}
{'loss': 0.019, 'grad_norm': 7.508258819580078, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.018121475353837013, 'loss_2': 0.0008516311645507812, 'loss_3': -16.509634017944336, 'loss_4': 2.0863897800445557, 'epoch': 16.76}
{'loss': 0.0141, 'grad_norm': 4.9842424392700195, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.007524701301008463, 'loss_2': 0.0065460205078125, 'loss_3': -16.5576171875, 'loss_4': 1.7716964483261108, 'epoch': 16.77}
{'loss': 0.0265, 'grad_norm': 7.823476791381836, 'learning_rate': 1.325e-05, 'loss_1': 0.0192425474524498, 'loss_2': 0.00725555419921875, 'loss_3': -16.462661743164062, 'loss_4': 2.160071611404419, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 16:28:53,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:53,248 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:31<39:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:00,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020563237369060516, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.607, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.015203704126179218, 'eval_loss_2': 0.005359530448913574, 'eval_loss_3': -18.341466903686523, 'eval_loss_4': 1.9278662204742432, 'epoch': 16.77}
{'loss': 0.0079, 'grad_norm': 4.746151447296143, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.005511503200978041, 'loss_2': 0.00238800048828125, 'loss_3': -16.541772842407227, 'loss_4': 2.0130720138549805, 'epoch': 16.78}
{'loss': 0.0291, 'grad_norm': 12.987211227416992, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.019918926060199738, 'loss_2': 0.009185791015625, 'loss_3': -16.57314109802246, 'loss_4': 1.7738903760910034, 'epoch': 16.78}
{'loss': 0.0213, 'grad_norm': 10.982892990112305, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.017924616113305092, 'loss_2': 0.003345489501953125, 'loss_3': -16.371524810791016, 'loss_4': 1.9011445045471191, 'epoch': 16.79}
{'loss': 0.0271, 'grad_norm': 10.461956977844238, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.018482765182852745, 'loss_2': 0.00860595703125, 'loss_3': -16.350383758544922, 'loss_4': 1.8588699102401733, 'epoch': 16.8}
{'loss': 0.0154, 'grad_norm': 6.533595561981201, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.010807827115058899, 'loss_2': 0.004634857177734375, 'loss_3': -16.341463088989258, 'loss_4': 1.631277322769165, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 16:29:00,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:00,621 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:38<39:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:07,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019149307161569595, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.515, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015029404312372208, 'eval_loss_2': 0.004119902849197388, 'eval_loss_3': -18.341854095458984, 'eval_loss_4': 1.7275539636611938, 'epoch': 16.8}
{'loss': 0.011, 'grad_norm': 6.671989440917969, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.00898392591625452, 'loss_2': 0.001995086669921875, 'loss_3': -16.537431716918945, 'loss_4': 2.060012102127075, 'epoch': 16.81}
{'loss': 0.0112, 'grad_norm': 5.273207187652588, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.007861500605940819, 'loss_2': 0.0033512115478515625, 'loss_3': -16.568702697753906, 'loss_4': 1.5435842275619507, 'epoch': 16.81}
{'loss': 0.0146, 'grad_norm': 5.485561370849609, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.010872527956962585, 'loss_2': 0.0036907196044921875, 'loss_3': -16.56023406982422, 'loss_4': 1.8776158094406128, 'epoch': 16.82}
{'loss': 0.0155, 'grad_norm': 4.8370819091796875, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.00654585612937808, 'loss_2': 0.009002685546875, 'loss_3': -16.68986701965332, 'loss_4': 1.8493918180465698, 'epoch': 16.83}
{'loss': 0.0182, 'grad_norm': 7.299831867218018, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.015804443508386612, 'loss_2': 0.002407073974609375, 'loss_3': -16.322620391845703, 'loss_4': 1.6598800420761108, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 16:29:07,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:07,976 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:46<39:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:15,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01892847940325737, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.42, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015238383784890175, 'eval_loss_2': 0.003690093755722046, 'eval_loss_3': -18.29438591003418, 'eval_loss_4': 1.5859366655349731, 'epoch': 16.83}
{'loss': 0.0165, 'grad_norm': 5.70670223236084, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.010242240503430367, 'loss_2': 0.00628662109375, 'loss_3': -16.279170989990234, 'loss_4': 1.5524687767028809, 'epoch': 16.84}
{'loss': 0.0079, 'grad_norm': 5.03043794631958, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.006331932730972767, 'loss_2': 0.0015649795532226562, 'loss_3': -16.607938766479492, 'loss_4': 1.1710667610168457, 'epoch': 16.84}
{'loss': 0.0112, 'grad_norm': 6.062378406524658, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.010856131091713905, 'loss_2': 0.0003159046173095703, 'loss_3': -16.438846588134766, 'loss_4': 1.6023889780044556, 'epoch': 16.85}
{'loss': 0.0162, 'grad_norm': 7.722474098205566, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.011058502830564976, 'loss_2': 0.005153656005859375, 'loss_3': -16.463218688964844, 'loss_4': 1.1733620166778564, 'epoch': 16.85}
{'loss': 0.084, 'grad_norm': 19.732393264770508, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.08262511342763901, 'loss_2': 0.00138092041015625, 'loss_3': -16.387451171875, 'loss_4': 1.7356786727905273, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 16:29:15,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:15,327 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:53<39:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:22,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01901344396173954, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.562, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015165852382779121, 'eval_loss_2': 0.0038475915789604187, 'eval_loss_3': -18.27016830444336, 'eval_loss_4': 1.42706298828125, 'epoch': 16.86}
{'loss': 0.0122, 'grad_norm': 6.116302967071533, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.012182801030576229, 'loss_2': 1.7285346984863281e-06, 'loss_3': -16.436073303222656, 'loss_4': 1.227808952331543, 'epoch': 16.87}
{'loss': 0.0213, 'grad_norm': 7.200201034545898, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.01836526021361351, 'loss_2': 0.002910614013671875, 'loss_3': -16.42052459716797, 'loss_4': 1.3220641613006592, 'epoch': 16.87}
{'loss': 0.0331, 'grad_norm': 21.458711624145508, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.029688112437725067, 'loss_2': 0.003421783447265625, 'loss_3': -16.404598236083984, 'loss_4': 1.3484255075454712, 'epoch': 16.88}
{'loss': 0.0165, 'grad_norm': 13.260472297668457, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.016288354992866516, 'loss_2': 0.0002598762512207031, 'loss_3': -16.67765235900879, 'loss_4': 1.2311866283416748, 'epoch': 16.88}
{'loss': 0.019, 'grad_norm': 5.060297966003418, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.008996724151074886, 'loss_2': 0.010040283203125, 'loss_3': -16.387479782104492, 'loss_4': 1.501889944076538, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 16:29:22,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:22,678 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:12:00<38:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:30,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023877335712313652, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.019936352968215942, 'eval_loss_2': 0.003940984606742859, 'eval_loss_3': -18.22282600402832, 'eval_loss_4': 1.4717530012130737, 'epoch': 16.89}
{'loss': 0.0236, 'grad_norm': 9.4793062210083, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.01419958844780922, 'loss_2': 0.00936126708984375, 'loss_3': -16.471630096435547, 'loss_4': 1.2729897499084473, 'epoch': 16.9}
{'loss': 0.0178, 'grad_norm': 13.463868141174316, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.016828857362270355, 'loss_2': 0.0009508132934570312, 'loss_3': -16.26266098022461, 'loss_4': 1.2005192041397095, 'epoch': 16.9}
{'loss': 0.0183, 'grad_norm': 10.351852416992188, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.014692284166812897, 'loss_2': 0.0035724639892578125, 'loss_3': -16.469379425048828, 'loss_4': 1.2137819528579712, 'epoch': 16.91}
{'loss': 0.0089, 'grad_norm': 5.162804126739502, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.006144413724541664, 'loss_2': 0.00270843505859375, 'loss_3': -16.290889739990234, 'loss_4': 0.8846060633659363, 'epoch': 16.91}
{'loss': 0.0095, 'grad_norm': 4.623849868774414, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.004254366271197796, 'loss_2': 0.0052642822265625, 'loss_3': -16.421356201171875, 'loss_4': 1.5014570951461792, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 16:29:30,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:30,031 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:12:08<38:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:37,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027101857587695122, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.023428309708833694, 'eval_loss_2': 0.003673546016216278, 'eval_loss_3': -18.192235946655273, 'eval_loss_4': 1.438848614692688, 'epoch': 16.92}
{'loss': 0.0063, 'grad_norm': 4.604026794433594, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.0060841599479317665, 'loss_2': 0.0001665353775024414, 'loss_3': -16.667430877685547, 'loss_4': 1.5780739784240723, 'epoch': 16.92}
{'loss': 0.0155, 'grad_norm': 5.4874396324157715, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.004769556224346161, 'loss_2': 0.010711669921875, 'loss_3': -16.601531982421875, 'loss_4': 1.066450595855713, 'epoch': 16.93}
{'loss': 0.0109, 'grad_norm': 5.029438495635986, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.007855689153075218, 'loss_2': 0.00299835205078125, 'loss_3': -16.251056671142578, 'loss_4': 1.5134223699569702, 'epoch': 16.94}
{'loss': 0.0052, 'grad_norm': 4.948319911956787, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.005042575299739838, 'loss_2': 0.0001475811004638672, 'loss_3': -16.485837936401367, 'loss_4': 1.239193320274353, 'epoch': 16.94}
{'loss': 0.0126, 'grad_norm': 6.094742298126221, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.0068349819630384445, 'loss_2': 0.005764007568359375, 'loss_3': -16.558170318603516, 'loss_4': 1.643738031387329, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 16:29:37,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:37,395 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:15<38:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:44,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02512424811720848, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.020640570670366287, 'eval_loss_2': 0.004483681172132492, 'eval_loss_3': -18.209875106811523, 'eval_loss_4': 1.3712528944015503, 'epoch': 16.95}
{'loss': 0.0367, 'grad_norm': 28.210689544677734, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.033611688762903214, 'loss_2': 0.0030879974365234375, 'loss_3': -16.338382720947266, 'loss_4': 1.0986312627792358, 'epoch': 16.95}
{'loss': 0.0073, 'grad_norm': 4.898782253265381, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.0037266002036631107, 'loss_2': 0.0035247802734375, 'loss_3': -16.478168487548828, 'loss_4': 1.1111191511154175, 'epoch': 16.96}
{'loss': 0.0133, 'grad_norm': 6.390352249145508, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.009063172154128551, 'loss_2': 0.004241943359375, 'loss_3': -16.35022735595703, 'loss_4': 1.3379623889923096, 'epoch': 16.97}
{'loss': 0.0282, 'grad_norm': 15.411309242248535, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.02757277712225914, 'loss_2': 0.0006155967712402344, 'loss_3': -16.373929977416992, 'loss_4': 0.5546348094940186, 'epoch': 16.97}
{'loss': 0.0142, 'grad_norm': 5.786061763763428, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.011379093863070011, 'loss_2': 0.002864837646484375, 'loss_3': -16.596193313598633, 'loss_4': 0.9380803108215332, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 16:29:44,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:44,759 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:22<36:27,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:29:51,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017861850559711456, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.39, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013997175730764866, 'eval_loss_2': 0.003864675760269165, 'eval_loss_3': -18.228036880493164, 'eval_loss_4': 1.354661226272583, 'epoch': 16.98}
{'loss': 0.0338, 'grad_norm': 14.645066261291504, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.02842697687447071, 'loss_2': 0.005340576171875, 'loss_3': -16.253198623657227, 'loss_4': 1.313201665878296, 'epoch': 16.98}
{'loss': 0.0082, 'grad_norm': 5.452609062194824, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.005504189990460873, 'loss_2': 0.00269317626953125, 'loss_3': -16.412935256958008, 'loss_4': 1.4723280668258667, 'epoch': 16.99}
{'loss': 0.0128, 'grad_norm': 4.573850631713867, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.004608071409165859, 'loss_2': 0.0081787109375, 'loss_3': -16.42040252685547, 'loss_4': 1.303112268447876, 'epoch': 16.99}
{'loss': 0.0041, 'grad_norm': 5.913466930389404, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.0034197208005934954, 'loss_2': 0.0007228851318359375, 'loss_3': -16.35239601135254, 'loss_4': 1.5329902172088623, 'epoch': 17.0}
{'loss': 0.0084, 'grad_norm': 5.513729095458984, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.0060042100958526134, 'loss_2': 0.00238037109375, 'loss_3': -16.562929153442383, 'loss_4': 1.3250927925109863, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 16:29:51,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:51,802 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:30<38:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:29:59,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014193138107657433, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.964, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011092133820056915, 'eval_loss_2': 0.0031010061502456665, 'eval_loss_3': -18.245952606201172, 'eval_loss_4': 1.401806116104126, 'epoch': 17.01}
{'loss': 0.0096, 'grad_norm': 4.930044174194336, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.006892648059874773, 'loss_2': 0.0027256011962890625, 'loss_3': -16.60485076904297, 'loss_4': 1.760521411895752, 'epoch': 17.01}
{'loss': 0.0092, 'grad_norm': 5.214612007141113, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.006257165689021349, 'loss_2': 0.00299072265625, 'loss_3': -16.52413558959961, 'loss_4': 1.3753948211669922, 'epoch': 17.02}
{'loss': 0.0107, 'grad_norm': 6.016704082489014, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.008808628655970097, 'loss_2': 0.0019311904907226562, 'loss_3': -16.412498474121094, 'loss_4': 1.385528564453125, 'epoch': 17.02}
{'loss': 0.0131, 'grad_norm': 4.934615612030029, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.004709473345428705, 'loss_2': 0.0083770751953125, 'loss_3': -16.562366485595703, 'loss_4': 0.9313678741455078, 'epoch': 17.03}
{'loss': 0.0089, 'grad_norm': 4.761471271514893, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.008109761402010918, 'loss_2': 0.0007829666137695312, 'loss_3': -16.522113800048828, 'loss_4': 1.4034425020217896, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 16:29:59,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:59,164 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:37<38:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:06,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01571461372077465, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011330303736031055, 'eval_loss_2': 0.0043843090534210205, 'eval_loss_3': -18.251270294189453, 'eval_loss_4': 1.3334242105484009, 'epoch': 17.03}
{'loss': 0.0039, 'grad_norm': 4.817182540893555, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.0037147768307477236, 'loss_2': 0.00015020370483398438, 'loss_3': -16.454986572265625, 'loss_4': 1.0754101276397705, 'epoch': 17.04}
{'loss': 0.0082, 'grad_norm': 12.551413536071777, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.007751198951154947, 'loss_2': 0.0004968643188476562, 'loss_3': -16.501127243041992, 'loss_4': 0.8161759376525879, 'epoch': 17.05}
{'loss': 0.0121, 'grad_norm': 5.743871212005615, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.009686782024800777, 'loss_2': 0.00244903564453125, 'loss_3': -16.33887481689453, 'loss_4': 1.388974666595459, 'epoch': 17.05}
{'loss': 0.0091, 'grad_norm': 5.634557247161865, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.005181634332984686, 'loss_2': 0.003887176513671875, 'loss_3': -16.3048095703125, 'loss_4': 1.4535763263702393, 'epoch': 17.06}
{'loss': 0.0549, 'grad_norm': 30.311927795410156, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.0547432117164135, 'loss_2': 0.00017201900482177734, 'loss_3': -16.401988983154297, 'loss_4': 1.309704303741455, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 16:30:06,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:06,518 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:44<38:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:13,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013150552287697792, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.493, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009490469470620155, 'eval_loss_2': 0.0036600828170776367, 'eval_loss_3': -18.24591064453125, 'eval_loss_4': 1.2834596633911133, 'epoch': 17.06}
{'loss': 0.0114, 'grad_norm': 5.506249904632568, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.008508346043527126, 'loss_2': 0.002910614013671875, 'loss_3': -16.41229820251465, 'loss_4': 1.2193108797073364, 'epoch': 17.07}
{'loss': 0.0083, 'grad_norm': 5.1120452880859375, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.00717155309394002, 'loss_2': 0.0011539459228515625, 'loss_3': -16.34756088256836, 'loss_4': 1.0938925743103027, 'epoch': 17.08}
{'loss': 0.0146, 'grad_norm': 8.302080154418945, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.013191184028983116, 'loss_2': 0.0014371871948242188, 'loss_3': -16.459566116333008, 'loss_4': 0.8430823087692261, 'epoch': 17.08}
{'loss': 0.0104, 'grad_norm': 5.2807087898254395, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.006547778379172087, 'loss_2': 0.0038623809814453125, 'loss_3': -16.398033142089844, 'loss_4': 1.3005449771881104, 'epoch': 17.09}
{'loss': 0.0078, 'grad_norm': 4.642088413238525, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.005367860663682222, 'loss_2': 0.0024433135986328125, 'loss_3': -16.408836364746094, 'loss_4': 1.2797013521194458, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 16:30:13,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:13,872 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:52<38:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:21,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01265203207731247, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.839, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008885554037988186, 'eval_loss_2': 0.003766477108001709, 'eval_loss_3': -18.25299072265625, 'eval_loss_4': 1.2351696491241455, 'epoch': 17.09}
{'loss': 0.011, 'grad_norm': 4.958226203918457, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.004747983068227768, 'loss_2': 0.00623321533203125, 'loss_3': -16.517948150634766, 'loss_4': 1.5041700601577759, 'epoch': 17.1}
{'loss': 0.0073, 'grad_norm': 5.949577331542969, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.006294222082942724, 'loss_2': 0.0009822845458984375, 'loss_3': -16.449613571166992, 'loss_4': 1.2728971242904663, 'epoch': 17.1}
{'loss': 0.0129, 'grad_norm': 7.767026424407959, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.008735117502510548, 'loss_2': 0.00418853759765625, 'loss_3': -16.65699577331543, 'loss_4': 1.319520115852356, 'epoch': 17.11}
{'loss': 0.0163, 'grad_norm': 5.262908458709717, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.008396697230637074, 'loss_2': 0.0079498291015625, 'loss_3': -16.475908279418945, 'loss_4': 1.0566604137420654, 'epoch': 17.12}
{'loss': 0.0206, 'grad_norm': 7.306795120239258, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.015204086899757385, 'loss_2': 0.005420684814453125, 'loss_3': -16.53304672241211, 'loss_4': 1.2523672580718994, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 16:30:21,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:21,246 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:59<38:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:28,611 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01246378943324089, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.081, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008745800703763962, 'eval_loss_2': 0.0037179887294769287, 'eval_loss_3': -18.250072479248047, 'eval_loss_4': 1.1596603393554688, 'epoch': 17.12}
{'loss': 0.0085, 'grad_norm': 5.116517543792725, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.007623064797371626, 'loss_2': 0.0009136199951171875, 'loss_3': -16.47439956665039, 'loss_4': 1.2697679996490479, 'epoch': 17.13}
{'loss': 0.0204, 'grad_norm': 4.901087284088135, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.006910188589245081, 'loss_2': 0.0134429931640625, 'loss_3': -16.60888671875, 'loss_4': 0.985102653503418, 'epoch': 17.13}
{'loss': 0.0167, 'grad_norm': 7.893747806549072, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.008635221049189568, 'loss_2': 0.00804901123046875, 'loss_3': -16.569849014282227, 'loss_4': 1.104461669921875, 'epoch': 17.14}
{'loss': 0.0073, 'grad_norm': 4.026378631591797, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.0027676476165652275, 'loss_2': 0.0045013427734375, 'loss_3': -16.642711639404297, 'loss_4': 1.0951240062713623, 'epoch': 17.15}
{'loss': 0.0146, 'grad_norm': 7.356743812561035, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.014363200403749943, 'loss_2': 0.0002791881561279297, 'loss_3': -16.444602966308594, 'loss_4': 0.9650778770446777, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 16:30:28,611 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:28,611 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:13:06<38:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:35,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014500259421765804, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.225, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009918390773236752, 'eval_loss_2': 0.004581868648529053, 'eval_loss_3': -18.255155563354492, 'eval_loss_4': 1.1207648515701294, 'epoch': 17.15}
{'loss': 0.0115, 'grad_norm': 4.974857330322266, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.008022411726415157, 'loss_2': 0.00345611572265625, 'loss_3': -16.517847061157227, 'loss_4': 0.9588059782981873, 'epoch': 17.16}
{'loss': 0.0098, 'grad_norm': 5.3448309898376465, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.007902446202933788, 'loss_2': 0.0018835067749023438, 'loss_3': -16.29804039001465, 'loss_4': 1.1533188819885254, 'epoch': 17.16}
{'loss': 0.0096, 'grad_norm': 7.0847249031066895, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.008926467970013618, 'loss_2': 0.0007085800170898438, 'loss_3': -16.48073959350586, 'loss_4': 1.193028450012207, 'epoch': 17.17}
{'loss': 0.0159, 'grad_norm': 5.37534236907959, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.009010778740048409, 'loss_2': 0.006885528564453125, 'loss_3': -16.53007698059082, 'loss_4': 1.227364182472229, 'epoch': 17.17}
{'loss': 0.0077, 'grad_norm': 4.718781471252441, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.005447637289762497, 'loss_2': 0.00223541259765625, 'loss_3': -16.645381927490234, 'loss_4': 0.8862911462783813, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 16:30:35,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:35,973 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:13:14<38:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:43,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014042426832020283, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01044016145169735, 'eval_loss_2': 0.003602266311645508, 'eval_loss_3': -18.235811233520508, 'eval_loss_4': 1.1456434726715088, 'epoch': 17.18}
{'loss': 0.0084, 'grad_norm': 5.492044448852539, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.0070291440933942795, 'loss_2': 0.001407623291015625, 'loss_3': -16.603357315063477, 'loss_4': 0.8817281723022461, 'epoch': 17.19}
{'loss': 0.0151, 'grad_norm': 5.796970367431641, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.008742599748075008, 'loss_2': 0.00638580322265625, 'loss_3': -16.67806053161621, 'loss_4': 1.3640813827514648, 'epoch': 17.19}
{'loss': 0.0186, 'grad_norm': 8.682567596435547, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.016632266342639923, 'loss_2': 0.001922607421875, 'loss_3': -16.567129135131836, 'loss_4': 1.5049080848693848, 'epoch': 17.2}
{'loss': 0.009, 'grad_norm': 6.711334705352783, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.008801874704658985, 'loss_2': 0.00014829635620117188, 'loss_3': -16.435501098632812, 'loss_4': 1.1798655986785889, 'epoch': 17.2}
{'loss': 0.0083, 'grad_norm': 5.906132221221924, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.005655517801642418, 'loss_2': 0.00262451171875, 'loss_3': -16.39246368408203, 'loss_4': 0.6134209632873535, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 16:30:43,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:43,330 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:21<38:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:50,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015783347189426422, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.579, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011170038022100925, 'eval_loss_2': 0.004613310098648071, 'eval_loss_3': -18.21425437927246, 'eval_loss_4': 1.136694073677063, 'epoch': 17.21}
{'loss': 0.0158, 'grad_norm': 8.625805854797363, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.008739889599382877, 'loss_2': 0.00701904296875, 'loss_3': -16.283905029296875, 'loss_4': 0.6683956384658813, 'epoch': 17.22}
{'loss': 0.0861, 'grad_norm': 20.336990356445312, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.08411505073308945, 'loss_2': 0.001983642578125, 'loss_3': -16.36158561706543, 'loss_4': 1.4231557846069336, 'epoch': 17.22}
{'loss': 0.0181, 'grad_norm': 5.878377914428711, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.007713735103607178, 'loss_2': 0.01033782958984375, 'loss_3': -16.473281860351562, 'loss_4': 1.320202112197876, 'epoch': 17.23}
{'loss': 0.0162, 'grad_norm': 7.031822681427002, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.010351029224693775, 'loss_2': 0.005893707275390625, 'loss_3': -16.30529022216797, 'loss_4': 0.8276031017303467, 'epoch': 17.23}
{'loss': 0.0252, 'grad_norm': 5.557697772979736, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.00957630854099989, 'loss_2': 0.0156707763671875, 'loss_3': -16.499263763427734, 'loss_4': 1.0853915214538574, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 16:30:50,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:50,689 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:28<38:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:58,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016395362094044685, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.824, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012159646488726139, 'eval_loss_2': 0.004235714673995972, 'eval_loss_3': -18.1966495513916, 'eval_loss_4': 1.147807002067566, 'epoch': 17.24}
{'loss': 0.0236, 'grad_norm': 9.421751976013184, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.01632584258913994, 'loss_2': 0.007259368896484375, 'loss_3': -16.47952651977539, 'loss_4': 0.9615481495857239, 'epoch': 17.24}
{'loss': 0.0072, 'grad_norm': 5.6445207595825195, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.007116710767149925, 'loss_2': 0.00012445449829101562, 'loss_3': -16.45029067993164, 'loss_4': 1.0061473846435547, 'epoch': 17.25}
{'loss': 0.0089, 'grad_norm': 4.956483840942383, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.006042012944817543, 'loss_2': 0.002826690673828125, 'loss_3': -16.60915756225586, 'loss_4': 1.3591347932815552, 'epoch': 17.26}
{'loss': 0.0065, 'grad_norm': 4.6625261306762695, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.0055231014266610146, 'loss_2': 0.00098419189453125, 'loss_3': -16.340030670166016, 'loss_4': 0.8814451694488525, 'epoch': 17.26}
{'loss': 0.0103, 'grad_norm': 5.408270835876465, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.0064209625124931335, 'loss_2': 0.0038299560546875, 'loss_3': -16.381778717041016, 'loss_4': 1.3054641485214233, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 16:30:58,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:58,063 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:36<37:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:05,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01818140596151352, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01478483434766531, 'eval_loss_2': 0.0033965706825256348, 'eval_loss_3': -18.15402603149414, 'eval_loss_4': 1.132491111755371, 'epoch': 17.27}
{'loss': 0.0081, 'grad_norm': 4.541103839874268, 'learning_rate': 1.275e-05, 'loss_1': 0.005394207779318094, 'loss_2': 0.002716064453125, 'loss_3': -16.5858154296875, 'loss_4': 1.3415127992630005, 'epoch': 17.27}
{'loss': 0.01, 'grad_norm': 4.874026298522949, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.005066914018243551, 'loss_2': 0.00495147705078125, 'loss_3': -16.49308204650879, 'loss_4': 0.9640622138977051, 'epoch': 17.28}
{'loss': 0.0165, 'grad_norm': 9.153159141540527, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.012490631081163883, 'loss_2': 0.004058837890625, 'loss_3': -16.523956298828125, 'loss_4': 1.096585750579834, 'epoch': 17.28}
{'loss': 0.0269, 'grad_norm': 8.991339683532715, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.023860931396484375, 'loss_2': 0.0030384063720703125, 'loss_3': -16.384092330932617, 'loss_4': 0.6966392397880554, 'epoch': 17.29}
{'loss': 0.0118, 'grad_norm': 5.101774215698242, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.0077914102002978325, 'loss_2': 0.00403594970703125, 'loss_3': -16.356781005859375, 'loss_4': 1.1145458221435547, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 16:31:05,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:05,433 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:43<37:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:12,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020209014415740967, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.484, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016388725489377975, 'eval_loss_2': 0.003820285201072693, 'eval_loss_3': -18.17446517944336, 'eval_loss_4': 1.131656527519226, 'epoch': 17.3}
{'loss': 0.0137, 'grad_norm': 5.573482036590576, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.007308571133762598, 'loss_2': 0.00640106201171875, 'loss_3': -16.383941650390625, 'loss_4': 0.8650579452514648, 'epoch': 17.3}
{'loss': 0.0148, 'grad_norm': 5.715525150299072, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.00987983401864767, 'loss_2': 0.004886627197265625, 'loss_3': -16.50732421875, 'loss_4': 0.9939824342727661, 'epoch': 17.31}
{'loss': 0.0091, 'grad_norm': 5.136703014373779, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.006855097599327564, 'loss_2': 0.002197265625, 'loss_3': -16.529054641723633, 'loss_4': 1.286313533782959, 'epoch': 17.31}
{'loss': 0.0097, 'grad_norm': 4.71330451965332, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.005652527324855328, 'loss_2': 0.00405120849609375, 'loss_3': -16.534244537353516, 'loss_4': 1.0227402448654175, 'epoch': 17.32}
{'loss': 0.015, 'grad_norm': 10.876928329467773, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.01492946594953537, 'loss_2': 7.826089859008789e-05, 'loss_3': -16.465038299560547, 'loss_4': 1.2382407188415527, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 16:31:12,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:12,784 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:50<37:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:20,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01984679512679577, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.06, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.015847191214561462, 'eval_loss_2': 0.003999605774879456, 'eval_loss_3': -18.166404724121094, 'eval_loss_4': 1.091148018836975, 'epoch': 17.33}
{'loss': 0.0212, 'grad_norm': 7.241119384765625, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.015211486257612705, 'loss_2': 0.00601959228515625, 'loss_3': -16.65182876586914, 'loss_4': 0.8689761161804199, 'epoch': 17.33}
{'loss': 0.0069, 'grad_norm': 4.55297327041626, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.0032906627748161554, 'loss_2': 0.00362396240234375, 'loss_3': -16.57866096496582, 'loss_4': 0.7789554595947266, 'epoch': 17.34}
{'loss': 0.0177, 'grad_norm': 5.2772111892700195, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.014558938331902027, 'loss_2': 0.0031414031982421875, 'loss_3': -16.535263061523438, 'loss_4': 0.8635666370391846, 'epoch': 17.34}
{'loss': 0.0165, 'grad_norm': 5.596920013427734, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.008848454803228378, 'loss_2': 0.007610321044921875, 'loss_3': -16.570280075073242, 'loss_4': 1.039872407913208, 'epoch': 17.35}
{'loss': 0.0138, 'grad_norm': 6.210015773773193, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.010532233864068985, 'loss_2': 0.00328826904296875, 'loss_3': -16.62372589111328, 'loss_4': 1.0375202894210815, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 16:31:20,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:20,146 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:58<37:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:27,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02302318438887596, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01724039949476719, 'eval_loss_2': 0.005782783031463623, 'eval_loss_3': -18.141178131103516, 'eval_loss_4': 0.9757360219955444, 'epoch': 17.35}
{'loss': 0.0141, 'grad_norm': 7.0383734703063965, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.01182912290096283, 'loss_2': 0.002292633056640625, 'loss_3': -16.528841018676758, 'loss_4': 0.8689292073249817, 'epoch': 17.36}
{'loss': 0.012, 'grad_norm': 5.411231994628906, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.008690633811056614, 'loss_2': 0.0033321380615234375, 'loss_3': -16.5665340423584, 'loss_4': 1.0588124990463257, 'epoch': 17.37}
{'loss': 0.0099, 'grad_norm': 5.724982738494873, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.009098328649997711, 'loss_2': 0.0008387565612792969, 'loss_3': -16.28400421142578, 'loss_4': 1.1014381647109985, 'epoch': 17.37}
{'loss': 0.0184, 'grad_norm': 4.243331432342529, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.0047136531211435795, 'loss_2': 0.01372528076171875, 'loss_3': -16.667139053344727, 'loss_4': 1.2266935110092163, 'epoch': 17.38}
{'loss': 0.0088, 'grad_norm': 5.237741947174072, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.007078695110976696, 'loss_2': 0.0017452239990234375, 'loss_3': -16.551368713378906, 'loss_4': 0.8783009052276611, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 16:31:27,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:27,498 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:14:05<37:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:34,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017429083585739136, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01416131854057312, 'eval_loss_2': 0.0032677650451660156, 'eval_loss_3': -18.171541213989258, 'eval_loss_4': 0.8511360883712769, 'epoch': 17.38}
{'loss': 0.019, 'grad_norm': 7.919527530670166, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.016763675957918167, 'loss_2': 0.0021953582763671875, 'loss_3': -16.648910522460938, 'loss_4': 1.0392096042633057, 'epoch': 17.39}
{'loss': 0.0072, 'grad_norm': 5.105327606201172, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.005632318556308746, 'loss_2': 0.001567840576171875, 'loss_3': -16.497331619262695, 'loss_4': 0.9776003360748291, 'epoch': 17.4}
{'loss': 0.0192, 'grad_norm': 9.567502975463867, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.017957346513867378, 'loss_2': 0.0012750625610351562, 'loss_3': -16.43061065673828, 'loss_4': 0.9597396850585938, 'epoch': 17.4}
{'loss': 0.0195, 'grad_norm': 6.946308135986328, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.015658371150493622, 'loss_2': 0.00382232666015625, 'loss_3': -16.521596908569336, 'loss_4': 0.7306268215179443, 'epoch': 17.41}
{'loss': 0.0071, 'grad_norm': 4.914519309997559, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.006889795884490013, 'loss_2': 0.0002181529998779297, 'loss_3': -16.67296600341797, 'loss_4': 0.7138627767562866, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 16:31:34,863 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:34,863 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:14:13<37:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:42,222 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01575465127825737, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.848, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011137854307889938, 'eval_loss_2': 0.004616796970367432, 'eval_loss_3': -18.201242446899414, 'eval_loss_4': 0.9387520551681519, 'epoch': 17.41}
{'loss': 0.0109, 'grad_norm': 5.100100994110107, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.0054383003152906895, 'loss_2': 0.0054779052734375, 'loss_3': -16.58687973022461, 'loss_4': 0.8048781752586365, 'epoch': 17.42}
{'loss': 0.0126, 'grad_norm': 5.428378105163574, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.009213307872414589, 'loss_2': 0.003391265869140625, 'loss_3': -16.51040267944336, 'loss_4': 0.7568982839584351, 'epoch': 17.42}
{'loss': 0.0416, 'grad_norm': 18.350852966308594, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.032139070332050323, 'loss_2': 0.00949859619140625, 'loss_3': -16.435373306274414, 'loss_4': 0.8305841684341431, 'epoch': 17.43}
{'loss': 0.0077, 'grad_norm': 4.911409854888916, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.0072499909438192844, 'loss_2': 0.0004878044128417969, 'loss_3': -16.50553321838379, 'loss_4': 0.734500527381897, 'epoch': 17.44}
{'loss': 0.0134, 'grad_norm': 5.7704973220825195, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.011307009495794773, 'loss_2': 0.0021305084228515625, 'loss_3': -16.615371704101562, 'loss_4': 1.1904855966567993, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 16:31:42,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:42,223 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:20<37:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:49,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009775185957551003, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.373, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007538260892033577, 'eval_loss_2': 0.0022369250655174255, 'eval_loss_3': -18.222049713134766, 'eval_loss_4': 1.0623823404312134, 'epoch': 17.44}
{'loss': 0.0183, 'grad_norm': 6.430150032043457, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.017079100012779236, 'loss_2': 0.0012607574462890625, 'loss_3': -16.482486724853516, 'loss_4': 1.4733076095581055, 'epoch': 17.45}
{'loss': 0.0228, 'grad_norm': 10.011058807373047, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.020990587770938873, 'loss_2': 0.0018472671508789062, 'loss_3': -16.585506439208984, 'loss_4': 1.0123952627182007, 'epoch': 17.45}
{'loss': 0.0162, 'grad_norm': 11.130888938903809, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.01469476893544197, 'loss_2': 0.0015468597412109375, 'loss_3': -16.54909896850586, 'loss_4': 0.7118093967437744, 'epoch': 17.46}
{'loss': 0.0067, 'grad_norm': 4.433741092681885, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.004811205435544252, 'loss_2': 0.0018711090087890625, 'loss_3': -16.54155731201172, 'loss_4': 1.691817283630371, 'epoch': 17.47}
{'loss': 0.0093, 'grad_norm': 5.238824844360352, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.00600625341758132, 'loss_2': 0.0032863616943359375, 'loss_3': -16.51428985595703, 'loss_4': 1.2359296083450317, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 16:31:49,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:49,577 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:27<37:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:56,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009307718835771084, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006284615490585566, 'eval_loss_2': 0.003023102879524231, 'eval_loss_3': -18.238689422607422, 'eval_loss_4': 1.0259311199188232, 'epoch': 17.47}
{'loss': 0.015, 'grad_norm': 6.2492804527282715, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.0114809051156044, 'loss_2': 0.00356292724609375, 'loss_3': -16.482969284057617, 'loss_4': 1.237906575202942, 'epoch': 17.48}
{'loss': 0.0104, 'grad_norm': 4.981839656829834, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.006229926832020283, 'loss_2': 0.00421905517578125, 'loss_3': -16.4400634765625, 'loss_4': 1.2883782386779785, 'epoch': 17.48}
{'loss': 0.0121, 'grad_norm': 6.23775577545166, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.010321740992367268, 'loss_2': 0.00177001953125, 'loss_3': -16.44888687133789, 'loss_4': 1.1201143264770508, 'epoch': 17.49}
{'loss': 0.0166, 'grad_norm': 5.067185878753662, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.009695368818938732, 'loss_2': 0.00688934326171875, 'loss_3': -16.41666603088379, 'loss_4': 0.9890817403793335, 'epoch': 17.49}
{'loss': 0.0178, 'grad_norm': 7.334291934967041, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.013157726265490055, 'loss_2': 0.004638671875, 'loss_3': -16.59388542175293, 'loss_4': 0.8711277842521667, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 16:31:56,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:56,937 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:35<37:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:04,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009011618793010712, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0065764011815190315, 'eval_loss_2': 0.0024352185428142548, 'eval_loss_3': -18.234169006347656, 'eval_loss_4': 0.9595314860343933, 'epoch': 17.5}
{'loss': 0.0133, 'grad_norm': 5.232702732086182, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.007737806066870689, 'loss_2': 0.005523681640625, 'loss_3': -16.6457462310791, 'loss_4': 1.1222426891326904, 'epoch': 17.51}
{'loss': 0.0122, 'grad_norm': 5.197876453399658, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.005454094149172306, 'loss_2': 0.006744384765625, 'loss_3': -16.610511779785156, 'loss_4': 1.2695456743240356, 'epoch': 17.51}
{'loss': 0.094, 'grad_norm': 24.035648345947266, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.08418289572000504, 'loss_2': 0.00983428955078125, 'loss_3': -16.567920684814453, 'loss_4': 1.5193672180175781, 'epoch': 17.52}
{'loss': 0.0102, 'grad_norm': 6.029013633728027, 'learning_rate': 1.25e-05, 'loss_1': 0.007093926426023245, 'loss_2': 0.0031299591064453125, 'loss_3': -16.423810958862305, 'loss_4': 0.9363672137260437, 'epoch': 17.52}
{'loss': 0.0096, 'grad_norm': 5.408325672149658, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.007371990475803614, 'loss_2': 0.00225830078125, 'loss_3': -16.559816360473633, 'loss_4': 0.7478485107421875, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 16:32:04,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:04,287 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:42<37:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:11,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009599139913916588, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.389, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0062194084748625755, 'eval_loss_2': 0.003379732370376587, 'eval_loss_3': -18.217662811279297, 'eval_loss_4': 0.8832495212554932, 'epoch': 17.53}
{'loss': 0.0221, 'grad_norm': 9.60446548461914, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.014638479799032211, 'loss_2': 0.00743865966796875, 'loss_3': -16.53903579711914, 'loss_4': 1.0022552013397217, 'epoch': 17.53}
{'loss': 0.0095, 'grad_norm': 5.3709588050842285, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.005851456895470619, 'loss_2': 0.003627777099609375, 'loss_3': -16.765989303588867, 'loss_4': 0.622898280620575, 'epoch': 17.54}
{'loss': 0.0131, 'grad_norm': 4.741453647613525, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.006456389557570219, 'loss_2': 0.00666046142578125, 'loss_3': -16.62076187133789, 'loss_4': 0.2879570424556732, 'epoch': 17.55}
{'loss': 0.0152, 'grad_norm': 5.1849589347839355, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.009971870109438896, 'loss_2': 0.0052490234375, 'loss_3': -16.439769744873047, 'loss_4': 1.0277249813079834, 'epoch': 17.55}
{'loss': 0.0108, 'grad_norm': 5.508342742919922, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.010115116834640503, 'loss_2': 0.0007038116455078125, 'loss_3': -16.458261489868164, 'loss_4': 0.8331273794174194, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 16:32:11,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:11,646 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:49<37:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:19,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010363474488258362, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.672, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007333875168114901, 'eval_loss_2': 0.0030295997858047485, 'eval_loss_3': -18.184106826782227, 'eval_loss_4': 0.8009384870529175, 'epoch': 17.56}
{'loss': 0.012, 'grad_norm': 4.838449954986572, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.007672290317714214, 'loss_2': 0.00431060791015625, 'loss_3': -16.330434799194336, 'loss_4': 0.8065869808197021, 'epoch': 17.56}
{'loss': 0.0122, 'grad_norm': 7.176321983337402, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.009506280533969402, 'loss_2': 0.002712249755859375, 'loss_3': -16.393680572509766, 'loss_4': 0.8214901685714722, 'epoch': 17.57}
{'loss': 0.0086, 'grad_norm': 5.844668865203857, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.008350788615643978, 'loss_2': 0.00021946430206298828, 'loss_3': -16.715557098388672, 'loss_4': 1.0068840980529785, 'epoch': 17.58}
{'loss': 0.011, 'grad_norm': 6.37094259262085, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.009221307002007961, 'loss_2': 0.00174713134765625, 'loss_3': -16.450897216796875, 'loss_4': 0.9829404354095459, 'epoch': 17.58}
{'loss': 0.0062, 'grad_norm': 5.109623908996582, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.0049188509583473206, 'loss_2': 0.0012607574462890625, 'loss_3': -16.499237060546875, 'loss_4': 0.7835285067558289, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 16:32:19,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:19,020 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:57<36:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:26,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010351237840950489, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.301, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007236061152070761, 'eval_loss_2': 0.0031151771545410156, 'eval_loss_3': -18.175704956054688, 'eval_loss_4': 0.7259835600852966, 'epoch': 17.59}
{'loss': 0.0152, 'grad_norm': 9.668325424194336, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.012707485817372799, 'loss_2': 0.002445220947265625, 'loss_3': -16.514892578125, 'loss_4': 1.143521785736084, 'epoch': 17.59}
{'loss': 0.0224, 'grad_norm': 6.524142742156982, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.016162551939487457, 'loss_2': 0.00620269775390625, 'loss_3': -16.507530212402344, 'loss_4': 0.9944303035736084, 'epoch': 17.6}
{'loss': 0.0117, 'grad_norm': 5.360122203826904, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.007252157665789127, 'loss_2': 0.004425048828125, 'loss_3': -16.46564292907715, 'loss_4': 0.9128949046134949, 'epoch': 17.6}
{'loss': 0.0731, 'grad_norm': 10.396449089050293, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.06909096986055374, 'loss_2': 0.00396728515625, 'loss_3': -16.389989852905273, 'loss_4': 0.8331592082977295, 'epoch': 17.61}
{'loss': 0.0198, 'grad_norm': 7.962161540985107, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.01255662553012371, 'loss_2': 0.0072174072265625, 'loss_3': -16.6624813079834, 'loss_4': 0.5228597521781921, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 16:32:26,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:26,377 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:15:01<36:55,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 16:32:30,180 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3030
[INFO|configuration_utils.py:420] 2025-01-21 16:32:30,181 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3030/config.json                                                                            
{'eval_loss': 0.008672447875142097, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00581854023039341, 'eval_loss_2': 0.0028539076447486877, 'eval_loss_3': -18.16411781311035, 'eval_loss_4': 0.5858527421951294, 'epoch': 17.62}
[INFO|modeling_utils.py:2988] 2025-01-21 16:32:30,674 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3030/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:32:30,676 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3030/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:32:30,676 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3030/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:32:31,699 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-2155] due to args.save_total_limit
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:15:06<40:53,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:32:35,337 >>
{'loss': 0.0061, 'grad_norm': 4.326578140258789, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.00432092510163784, 'loss_2': 0.0017604827880859375, 'loss_3': -16.41150665283203, 'loss_4': 0.3932954668998718, 'epoch': 17.62}
{'loss': 0.0064, 'grad_norm': 4.53541374206543, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.005092565435916185, 'loss_2': 0.001338958740234375, 'loss_3': -16.66097640991211, 'loss_4': 0.7353099584579468, 'epoch': 17.63}
{'loss': 0.0159, 'grad_norm': 5.162574768066406, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.008280498906970024, 'loss_2': 0.007610321044921875, 'loss_3': -16.479795455932617, 'loss_4': 0.5559573173522949, 'epoch': 17.63}
{'loss': 0.0093, 'grad_norm': 7.120372295379639, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.00853387825191021, 'loss_2': 0.0007295608520507812, 'loss_3': -16.234067916870117, 'loss_4': 0.15190263092517853, 'epoch': 17.64}
{'loss': 0.0245, 'grad_norm': 16.50094985961914, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.01921103708446026, 'loss_2': 0.00531005859375, 'loss_3': -16.597068786621094, 'loss_4': 0.8250643014907837, 'epoch': 17.65}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:32:35,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:35,338 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:15:13<37:17,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:32:42,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010180169716477394, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.165, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.006162756122648716, 'eval_loss_2': 0.0040174126625061035, 'eval_loss_3': -18.186967849731445, 'eval_loss_4': 0.6781033873558044, 'epoch': 17.65}
{'loss': 0.015, 'grad_norm': 4.930790424346924, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.006123631726950407, 'loss_2': 0.0088958740234375, 'loss_3': -16.412513732910156, 'loss_4': 0.5006259083747864, 'epoch': 17.65}
{'loss': 0.0113, 'grad_norm': 10.05920124053955, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.01040736772119999, 'loss_2': 0.0009183883666992188, 'loss_3': -16.42970085144043, 'loss_4': 0.7835452556610107, 'epoch': 17.66}
{'loss': 0.0139, 'grad_norm': 5.04722785949707, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.006171249784529209, 'loss_2': 0.007694244384765625, 'loss_3': -16.498790740966797, 'loss_4': 0.7164615988731384, 'epoch': 17.66}
{'loss': 0.0165, 'grad_norm': 7.92609977722168, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.014675948768854141, 'loss_2': 0.0018320083618164062, 'loss_3': -16.429584503173828, 'loss_4': 0.6351809501647949, 'epoch': 17.67}
{'loss': 0.0097, 'grad_norm': 4.591799259185791, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.005610622465610504, 'loss_2': 0.00408172607421875, 'loss_3': -16.541629791259766, 'loss_4': 0.33507809042930603, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 16:32:42,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:42,666 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:20<36:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:50,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009542755782604218, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.963, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006368436850607395, 'eval_loss_2': 0.003174319863319397, 'eval_loss_3': -18.18594741821289, 'eval_loss_4': 0.7802881002426147, 'epoch': 17.67}
{'loss': 0.0125, 'grad_norm': 7.829819202423096, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.011893651448190212, 'loss_2': 0.0005655288696289062, 'loss_3': -16.428741455078125, 'loss_4': 0.9241122007369995, 'epoch': 17.68}
{'loss': 0.018, 'grad_norm': 7.608405590057373, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.013268979266285896, 'loss_2': 0.00475311279296875, 'loss_3': -16.561391830444336, 'loss_4': 0.5067524313926697, 'epoch': 17.69}
{'loss': 0.0089, 'grad_norm': 5.434418678283691, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.007861155085265636, 'loss_2': 0.0010080337524414062, 'loss_3': -16.684791564941406, 'loss_4': 0.9759179353713989, 'epoch': 17.69}
{'loss': 0.0188, 'grad_norm': 7.217167854309082, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.01095978170633316, 'loss_2': 0.00780487060546875, 'loss_3': -16.401142120361328, 'loss_4': 0.9499419927597046, 'epoch': 17.7}
{'loss': 0.0119, 'grad_norm': 4.315784454345703, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.0036710300482809544, 'loss_2': 0.00826263427734375, 'loss_3': -16.5340518951416, 'loss_4': 0.7704513072967529, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 16:32:50,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:50,004 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:28<36:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:57,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01021262165158987, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.582, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0059146275743842125, 'eval_loss_2': 0.004297994077205658, 'eval_loss_3': -18.216552734375, 'eval_loss_4': 0.8600763082504272, 'epoch': 17.7}
{'loss': 0.014, 'grad_norm': 6.197038173675537, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.011050848290324211, 'loss_2': 0.0029926300048828125, 'loss_3': -16.703813552856445, 'loss_4': 0.9409343004226685, 'epoch': 17.71}
{'loss': 0.0147, 'grad_norm': 5.5210490226745605, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.00778365321457386, 'loss_2': 0.006916046142578125, 'loss_3': -16.444211959838867, 'loss_4': 1.1219048500061035, 'epoch': 17.72}
{'loss': 0.0149, 'grad_norm': 4.841488361358643, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.005345410201698542, 'loss_2': 0.0095367431640625, 'loss_3': -16.692705154418945, 'loss_4': 1.0843017101287842, 'epoch': 17.72}
{'loss': 0.0189, 'grad_norm': 9.657576560974121, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.014196624979376793, 'loss_2': 0.00469970703125, 'loss_3': -16.4529972076416, 'loss_4': 0.7741917371749878, 'epoch': 17.73}
{'loss': 0.0088, 'grad_norm': 4.450429439544678, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.007877578027546406, 'loss_2': 0.0009250640869140625, 'loss_3': -16.68029022216797, 'loss_4': 1.6852164268493652, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 16:32:57,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:57,347 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:35<36:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:04,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009436553344130516, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.606, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.005522450432181358, 'eval_loss_2': 0.003914102911949158, 'eval_loss_3': -18.25130844116211, 'eval_loss_4': 0.9263178110122681, 'epoch': 17.73}
{'loss': 0.013, 'grad_norm': 6.039105415344238, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.011410756967961788, 'loss_2': 0.001636505126953125, 'loss_3': -16.49271011352539, 'loss_4': 1.3271781206130981, 'epoch': 17.74}
{'loss': 0.0067, 'grad_norm': 5.766760349273682, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.006629410665482283, 'loss_2': 9.500980377197266e-05, 'loss_3': -16.398639678955078, 'loss_4': 1.1046230792999268, 'epoch': 17.74}
{'loss': 0.0052, 'grad_norm': 6.188976287841797, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.0045760031789541245, 'loss_2': 0.0005750656127929688, 'loss_3': -16.339956283569336, 'loss_4': 1.0388076305389404, 'epoch': 17.75}
{'loss': 0.0204, 'grad_norm': 7.4848246574401855, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.019402626901865005, 'loss_2': 0.0009546279907226562, 'loss_3': -16.416418075561523, 'loss_4': 1.6307148933410645, 'epoch': 17.76}
{'loss': 0.009, 'grad_norm': 12.292163848876953, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.007036090828478336, 'loss_2': 0.001953125, 'loss_3': -16.501359939575195, 'loss_4': 1.2721362113952637, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 16:33:04,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:04,687 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:39<36:22,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 16:33:08,481 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3055
[INFO|configuration_utils.py:420] 2025-01-21 16:33:08,483 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3055/config.json                                                                            
{'eval_loss': 0.006848055403679609, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.977, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.0042063104920089245, 'eval_loss_2': 0.002641744911670685, 'eval_loss_3': -18.243549346923828, 'eval_loss_4': 0.9139963388442993, 'epoch': 17.76}
[INFO|modeling_utils.py:2988] 2025-01-21 16:33:08,962 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3055/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:33:08,963 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3055/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:33:08,963 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3055/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:33:09,951 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3030] due to args.save_total_limit
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:44<40:13,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:33:13,587 >>
{'loss': 0.0125, 'grad_norm': 4.876664161682129, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.0070163956843316555, 'loss_2': 0.0054931640625, 'loss_3': -16.458515167236328, 'loss_4': 1.4032537937164307, 'epoch': 17.77}
{'loss': 0.0213, 'grad_norm': 8.461968421936035, 'learning_rate': 1.225e-05, 'loss_1': 0.01327506359666586, 'loss_2': 0.00800323486328125, 'loss_3': -16.71570587158203, 'loss_4': 1.388995885848999, 'epoch': 17.77}
{'loss': 0.0157, 'grad_norm': 4.756975173950195, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.0055230045691132545, 'loss_2': 0.01020050048828125, 'loss_3': -16.351627349853516, 'loss_4': 1.0511658191680908, 'epoch': 17.78}
{'loss': 0.0084, 'grad_norm': 4.958409309387207, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.007661489304155111, 'loss_2': 0.0007042884826660156, 'loss_3': -16.66287612915039, 'loss_4': 1.0006074905395508, 'epoch': 17.78}
{'loss': 0.0153, 'grad_norm': 6.9841389656066895, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.012149452231824398, 'loss_2': 0.003108978271484375, 'loss_3': -16.537370681762695, 'loss_4': 1.0447418689727783, 'epoch': 17.79}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:33:13,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:13,587 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:51<36:52,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:33:20,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007707150653004646, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.69, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.004532495979219675, 'eval_loss_2': 0.0031746551394462585, 'eval_loss_3': -18.23657989501953, 'eval_loss_4': 0.918609619140625, 'epoch': 17.79}
{'loss': 0.0081, 'grad_norm': 4.7183027267456055, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.005880001932382584, 'loss_2': 0.002254486083984375, 'loss_3': -16.531925201416016, 'loss_4': 1.1497547626495361, 'epoch': 17.8}
{'loss': 0.017, 'grad_norm': 7.524672031402588, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.016640862450003624, 'loss_2': 0.000408172607421875, 'loss_3': -16.57099723815918, 'loss_4': 0.9975656270980835, 'epoch': 17.8}
{'loss': 0.0115, 'grad_norm': 6.015407562255859, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.009149524383246899, 'loss_2': 0.002361297607421875, 'loss_3': -16.77228546142578, 'loss_4': 1.3444545269012451, 'epoch': 17.81}
{'loss': 0.016, 'grad_norm': 7.00673246383667, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.008852319791913033, 'loss_2': 0.007171630859375, 'loss_3': -16.54582977294922, 'loss_4': 1.3344686031341553, 'epoch': 17.81}
{'loss': 0.0078, 'grad_norm': 5.835236549377441, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.006284376140683889, 'loss_2': 0.001476287841796875, 'loss_3': -16.60787010192871, 'loss_4': 0.9567356705665588, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 16:33:20,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:20,930 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:59<36:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:28,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007972615770995617, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005302848760038614, 'eval_loss_2': 0.0026697665452957153, 'eval_loss_3': -18.252275466918945, 'eval_loss_4': 0.9052283763885498, 'epoch': 17.82}
{'loss': 0.0175, 'grad_norm': 9.388384819030762, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.01407625712454319, 'loss_2': 0.003414154052734375, 'loss_3': -16.496877670288086, 'loss_4': 1.3919975757598877, 'epoch': 17.83}
{'loss': 0.0115, 'grad_norm': 5.642244338989258, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.0061237686313688755, 'loss_2': 0.00533294677734375, 'loss_3': -16.567224502563477, 'loss_4': 0.851844072341919, 'epoch': 17.83}
{'loss': 0.0086, 'grad_norm': 5.0351033210754395, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.0062865642830729485, 'loss_2': 0.0022735595703125, 'loss_3': -16.7108154296875, 'loss_4': 1.5814032554626465, 'epoch': 17.84}
{'loss': 0.0108, 'grad_norm': 5.176033973693848, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.009305725805461407, 'loss_2': 0.0014801025390625, 'loss_3': -16.70394515991211, 'loss_4': 1.2767530679702759, 'epoch': 17.84}
{'loss': 0.0075, 'grad_norm': 5.28354024887085, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.007099071517586708, 'loss_2': 0.0003619194030761719, 'loss_3': -16.61119842529297, 'loss_4': 0.7132492065429688, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 16:33:28,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:28,270 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:16:06<36:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:35,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008197801187634468, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.092, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.005916126538068056, 'eval_loss_2': 0.00228167325258255, 'eval_loss_3': -18.266403198242188, 'eval_loss_4': 0.9097830057144165, 'epoch': 17.85}
{'loss': 0.011, 'grad_norm': 4.332559585571289, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.005007956642657518, 'loss_2': 0.0059967041015625, 'loss_3': -16.511789321899414, 'loss_4': 1.0448870658874512, 'epoch': 17.85}
{'loss': 0.0062, 'grad_norm': 5.480704307556152, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.004465824458748102, 'loss_2': 0.0017147064208984375, 'loss_3': -16.741634368896484, 'loss_4': 1.1401255130767822, 'epoch': 17.86}
{'loss': 0.0102, 'grad_norm': 4.975061416625977, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.008667330257594585, 'loss_2': 0.00152587890625, 'loss_3': -16.55788803100586, 'loss_4': 0.8602957725524902, 'epoch': 17.87}
{'loss': 0.0144, 'grad_norm': 6.627676010131836, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.008291145786643028, 'loss_2': 0.006103515625, 'loss_3': -16.60233497619629, 'loss_4': 1.095064640045166, 'epoch': 17.87}
{'loss': 0.0091, 'grad_norm': 6.710043430328369, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.008681271225214005, 'loss_2': 0.00043487548828125, 'loss_3': -16.652193069458008, 'loss_4': 1.485982060432434, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 16:33:35,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:35,606 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:16:13<36:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:42,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010390874929726124, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.006163192447274923, 'eval_loss_2': 0.004227682948112488, 'eval_loss_3': -18.294044494628906, 'eval_loss_4': 0.8594090938568115, 'epoch': 17.88}
{'loss': 0.0215, 'grad_norm': 11.674643516540527, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.014962726272642612, 'loss_2': 0.00656890869140625, 'loss_3': -16.671586990356445, 'loss_4': 0.7064111232757568, 'epoch': 17.88}
{'loss': 0.0192, 'grad_norm': 5.520574569702148, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.0076073636300861835, 'loss_2': 0.0115814208984375, 'loss_3': -16.495946884155273, 'loss_4': 1.2602839469909668, 'epoch': 17.89}
{'loss': 0.0246, 'grad_norm': 8.069978713989258, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.0231161005795002, 'loss_2': 0.0014972686767578125, 'loss_3': -16.682899475097656, 'loss_4': 1.4821279048919678, 'epoch': 17.9}
{'loss': 0.0148, 'grad_norm': 5.803170680999756, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.009277580305933952, 'loss_2': 0.005523681640625, 'loss_3': -16.508878707885742, 'loss_4': 0.8781195878982544, 'epoch': 17.9}
{'loss': 0.0165, 'grad_norm': 6.988905906677246, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.012796648778021336, 'loss_2': 0.00372314453125, 'loss_3': -16.59038734436035, 'loss_4': 1.3753304481506348, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 16:33:42,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:42,954 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:21<37:43,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 16:33:50,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009961040690541267, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.147, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.005760671570897102, 'eval_loss_2': 0.004200369119644165, 'eval_loss_3': -18.29553985595703, 'eval_loss_4': 0.6433115601539612, 'epoch': 17.91}
{'loss': 0.0118, 'grad_norm': 5.494284152984619, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.006212577223777771, 'loss_2': 0.005588531494140625, 'loss_3': -16.500925064086914, 'loss_4': 0.6915768384933472, 'epoch': 17.91}
{'loss': 0.0696, 'grad_norm': 12.08814525604248, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.06454380601644516, 'loss_2': 0.005096435546875, 'loss_3': -16.733997344970703, 'loss_4': 1.0778608322143555, 'epoch': 17.92}
{'loss': 0.0138, 'grad_norm': 5.268190860748291, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.006094979587942362, 'loss_2': 0.00772857666015625, 'loss_3': -16.572895050048828, 'loss_4': 0.5803712606430054, 'epoch': 17.92}
{'loss': 0.0111, 'grad_norm': 5.4596781730651855, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.00976833701133728, 'loss_2': 0.0013561248779296875, 'loss_3': -16.731624603271484, 'loss_4': 1.0454373359680176, 'epoch': 17.93}
{'loss': 0.0117, 'grad_norm': 5.249831199645996, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.00862274318933487, 'loss_2': 0.003078460693359375, 'loss_3': -16.55364227294922, 'loss_4': 0.8404213190078735, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 16:33:50,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:50,469 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:28<36:05,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:33:57,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008547704666852951, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.924, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006111558526754379, 'eval_loss_2': 0.0024361461400985718, 'eval_loss_3': -18.28677749633789, 'eval_loss_4': 0.5088567733764648, 'epoch': 17.94}
{'loss': 0.036, 'grad_norm': 25.90596580505371, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.034889765083789825, 'loss_2': 0.0011053085327148438, 'loss_3': -16.554977416992188, 'loss_4': 0.9832049012184143, 'epoch': 17.94}
{'loss': 0.0119, 'grad_norm': 4.691644668579102, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.004055855330079794, 'loss_2': 0.00787353515625, 'loss_3': -16.66667938232422, 'loss_4': 0.5840157270431519, 'epoch': 17.95}
{'loss': 0.0082, 'grad_norm': 4.737719535827637, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.00640762597322464, 'loss_2': 0.0017604827880859375, 'loss_3': -16.6422061920166, 'loss_4': 0.666615903377533, 'epoch': 17.95}
{'loss': 0.0119, 'grad_norm': 5.899726390838623, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.008301029913127422, 'loss_2': 0.00362396240234375, 'loss_3': -16.546276092529297, 'loss_4': 0.4332957863807678, 'epoch': 17.96}
{'loss': 0.01, 'grad_norm': 5.885128974914551, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.006762068253010511, 'loss_2': 0.0032405853271484375, 'loss_3': -16.56166648864746, 'loss_4': 0.4872913956642151, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 16:33:57,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:57,808 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:35<35:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:05,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009897280484437943, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007355541922152042, 'eval_loss_2': 0.0025417394936084747, 'eval_loss_3': -18.266244888305664, 'eval_loss_4': 0.36803820729255676, 'epoch': 17.97}
{'loss': 0.0167, 'grad_norm': 7.885863780975342, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.013202453963458538, 'loss_2': 0.0035457611083984375, 'loss_3': -16.684558868408203, 'loss_4': 0.45102280378341675, 'epoch': 17.97}
{'loss': 0.0163, 'grad_norm': 4.718328952789307, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.0038169880863279104, 'loss_2': 0.0125274658203125, 'loss_3': -16.569602966308594, 'loss_4': 0.31607216596603394, 'epoch': 17.98}
{'loss': 0.0112, 'grad_norm': 5.284096717834473, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.006089060101658106, 'loss_2': 0.00508880615234375, 'loss_3': -16.5543212890625, 'loss_4': 0.6213927268981934, 'epoch': 17.98}
{'loss': 0.0127, 'grad_norm': 5.22682523727417, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.007511748466640711, 'loss_2': 0.00518035888671875, 'loss_3': -16.716960906982422, 'loss_4': 0.17864274978637695, 'epoch': 17.99}
{'loss': 0.0067, 'grad_norm': 4.904689311981201, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.004882976412773132, 'loss_2': 0.00183868408203125, 'loss_3': -16.664514541625977, 'loss_4': 0.5866255760192871, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 16:34:05,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:05,140 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:43<34:53,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:34:12,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011461073532700539, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.715, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008197451941668987, 'eval_loss_2': 0.003263622522354126, 'eval_loss_3': -18.244220733642578, 'eval_loss_4': 0.2652117609977722, 'epoch': 17.99}
{'loss': 0.0078, 'grad_norm': 6.73084831237793, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.001511607551947236, 'loss_2': 0.00624847412109375, 'loss_3': -16.62108039855957, 'loss_4': 0.8533048033714294, 'epoch': 18.0}
{'loss': 0.0136, 'grad_norm': 6.690830230712891, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.0099153658375144, 'loss_2': 0.003643035888671875, 'loss_3': -16.412845611572266, 'loss_4': 0.1427682638168335, 'epoch': 18.01}
{'loss': 0.0061, 'grad_norm': 5.020914077758789, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.002764612901955843, 'loss_2': 0.0032901763916015625, 'loss_3': -16.592411041259766, 'loss_4': 0.28059136867523193, 'epoch': 18.01}
{'loss': 0.0035, 'grad_norm': 4.127537727355957, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.003412076039239764, 'loss_2': 4.214048385620117e-05, 'loss_3': -16.708507537841797, 'loss_4': 0.45009440183639526, 'epoch': 18.02}
{'loss': 0.007, 'grad_norm': 4.558624744415283, 'learning_rate': 1.2e-05, 'loss_1': 0.003137218998745084, 'loss_2': 0.0038890838623046875, 'loss_3': -16.62133026123047, 'loss_4': 0.1180809885263443, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 16:34:12,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:12,188 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:50<35:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:19,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0151857640594244, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.55, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010545899160206318, 'eval_loss_2': 0.004639863967895508, 'eval_loss_3': -18.213523864746094, 'eval_loss_4': 0.20015676319599152, 'epoch': 18.02}
{'loss': 0.0071, 'grad_norm': 4.966912269592285, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.004759998992085457, 'loss_2': 0.00232696533203125, 'loss_3': -16.348785400390625, 'loss_4': -0.19322770833969116, 'epoch': 18.03}
{'loss': 0.0066, 'grad_norm': 5.174218654632568, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.005374556872993708, 'loss_2': 0.0012607574462890625, 'loss_3': -16.492910385131836, 'loss_4': 0.14387260377407074, 'epoch': 18.03}
{'loss': 0.0056, 'grad_norm': 4.422703742980957, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.0021011633798480034, 'loss_2': 0.00351715087890625, 'loss_3': -16.543888092041016, 'loss_4': 0.4807355999946594, 'epoch': 18.04}
{'loss': 0.0084, 'grad_norm': 5.501891613006592, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.005004693754017353, 'loss_2': 0.0034275054931640625, 'loss_3': -16.60253143310547, 'loss_4': 0.36718007922172546, 'epoch': 18.05}
{'loss': 0.0127, 'grad_norm': 8.687332153320312, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.011165322735905647, 'loss_2': 0.0015544891357421875, 'loss_3': -16.540746688842773, 'loss_4': 0.34318190813064575, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 16:34:19,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:19,531 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:57<35:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:26,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012941336259245872, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.183, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009896751493215561, 'eval_loss_2': 0.0030445829033851624, 'eval_loss_3': -18.2039852142334, 'eval_loss_4': 0.28297334909439087, 'epoch': 18.05}
{'loss': 0.0147, 'grad_norm': 6.05172061920166, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.010418446734547615, 'loss_2': 0.00423431396484375, 'loss_3': -16.371591567993164, 'loss_4': 0.04178636521100998, 'epoch': 18.06}
{'loss': 0.0126, 'grad_norm': 5.569747447967529, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.007045601960271597, 'loss_2': 0.0055389404296875, 'loss_3': -16.243793487548828, 'loss_4': -0.15599489212036133, 'epoch': 18.06}
{'loss': 0.005, 'grad_norm': 5.172064781188965, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.004614897537976503, 'loss_2': 0.0003833770751953125, 'loss_3': -16.42333221435547, 'loss_4': 0.037490807473659515, 'epoch': 18.07}
{'loss': 0.0138, 'grad_norm': 9.65280532836914, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.011497081257402897, 'loss_2': 0.002288818359375, 'loss_3': -16.4295654296875, 'loss_4': 0.5362234115600586, 'epoch': 18.08}
{'loss': 0.0156, 'grad_norm': 10.521383285522461, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.012580241076648235, 'loss_2': 0.0029754638671875, 'loss_3': -16.504047393798828, 'loss_4': 0.8802284598350525, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 16:34:26,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:26,883 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:17:05<35:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:34,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014776651747524738, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.823, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012583297677338123, 'eval_loss_2': 0.002193354070186615, 'eval_loss_3': -18.187488555908203, 'eval_loss_4': 0.3748628795146942, 'epoch': 18.08}
{'loss': 0.0082, 'grad_norm': 5.111870765686035, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.005532626528292894, 'loss_2': 0.0026531219482421875, 'loss_3': -16.722396850585938, 'loss_4': 0.3278704285621643, 'epoch': 18.09}
{'loss': 0.0061, 'grad_norm': 4.76915979385376, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.0032279440201818943, 'loss_2': 0.00286102294921875, 'loss_3': -16.708759307861328, 'loss_4': -0.17086678743362427, 'epoch': 18.09}
{'loss': 0.0129, 'grad_norm': 6.667262554168701, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.008033301681280136, 'loss_2': 0.00485992431640625, 'loss_3': -16.495574951171875, 'loss_4': 0.17176443338394165, 'epoch': 18.1}
{'loss': 0.0152, 'grad_norm': 5.983373641967773, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.014012007042765617, 'loss_2': 0.0011692047119140625, 'loss_3': -16.67460060119629, 'loss_4': 0.31446370482444763, 'epoch': 18.1}
{'loss': 0.0835, 'grad_norm': 16.994617462158203, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.076863594353199, 'loss_2': 0.0066680908203125, 'loss_3': -16.436954498291016, 'loss_4': 0.7556747198104858, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 16:34:34,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:34,226 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:17:12<35:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:41,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015837285667657852, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.859, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013056954368948936, 'eval_loss_2': 0.002780333161354065, 'eval_loss_3': -18.169771194458008, 'eval_loss_4': 0.37663397192955017, 'epoch': 18.11}
{'loss': 0.0325, 'grad_norm': 18.650190353393555, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.0324413999915123, 'loss_2': 8.672475814819336e-05, 'loss_3': -16.634212493896484, 'loss_4': 0.3418268859386444, 'epoch': 18.12}
{'loss': 0.0089, 'grad_norm': 4.195827007293701, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.0031054476276040077, 'loss_2': 0.00579071044921875, 'loss_3': -16.690994262695312, 'loss_4': 0.11000393331050873, 'epoch': 18.12}
{'loss': 0.0145, 'grad_norm': 6.326141834259033, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.008996043354272842, 'loss_2': 0.00547027587890625, 'loss_3': -16.5844783782959, 'loss_4': 0.10795517265796661, 'epoch': 18.13}
{'loss': 0.0263, 'grad_norm': 11.409249305725098, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.025217028334736824, 'loss_2': 0.0011310577392578125, 'loss_3': -16.33637237548828, 'loss_4': 0.18946649134159088, 'epoch': 18.13}
{'loss': 0.0069, 'grad_norm': 5.037001609802246, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.006627502851188183, 'loss_2': 0.00031065940856933594, 'loss_3': -16.437015533447266, 'loss_4': 0.18924564123153687, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 16:34:41,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:41,557 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:19<35:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:48,901 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014959131367504597, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.457, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012381401844322681, 'eval_loss_2': 0.0025777295231819153, 'eval_loss_3': -18.184900283813477, 'eval_loss_4': 0.30338722467422485, 'epoch': 18.14}
{'loss': 0.0153, 'grad_norm': 6.062539577484131, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.00958969909697771, 'loss_2': 0.00576019287109375, 'loss_3': -16.527057647705078, 'loss_4': 0.39558279514312744, 'epoch': 18.15}
{'loss': 0.0122, 'grad_norm': 10.01638412475586, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.009013173170387745, 'loss_2': 0.003223419189453125, 'loss_3': -16.63544464111328, 'loss_4': 0.32646772265434265, 'epoch': 18.15}
{'loss': 0.0112, 'grad_norm': 5.18380069732666, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.006234988570213318, 'loss_2': 0.0049285888671875, 'loss_3': -16.618165969848633, 'loss_4': -0.0541081428527832, 'epoch': 18.16}
{'loss': 0.0219, 'grad_norm': 12.990758895874023, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.020245520398020744, 'loss_2': 0.0016717910766601562, 'loss_3': -16.64394760131836, 'loss_4': -0.08429229259490967, 'epoch': 18.16}
{'loss': 0.0131, 'grad_norm': 6.307920932769775, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.011038688011467457, 'loss_2': 0.0020294189453125, 'loss_3': -16.63776969909668, 'loss_4': -0.18846449255943298, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 16:34:48,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:48,902 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:27<35:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:56,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015565386973321438, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.78, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012888751924037933, 'eval_loss_2': 0.002676635980606079, 'eval_loss_3': -18.18984603881836, 'eval_loss_4': 0.3099874258041382, 'epoch': 18.17}
{'loss': 0.0055, 'grad_norm': 4.833845138549805, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.005505476612597704, 'loss_2': 2.2172927856445312e-05, 'loss_3': -16.394287109375, 'loss_4': 0.5935139656066895, 'epoch': 18.17}
{'loss': 0.0105, 'grad_norm': 4.910587787628174, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.004582208581268787, 'loss_2': 0.00592041015625, 'loss_3': -16.599613189697266, 'loss_4': 0.01588405668735504, 'epoch': 18.18}
{'loss': 0.0095, 'grad_norm': 4.459778785705566, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.0027412085328251123, 'loss_2': 0.00676727294921875, 'loss_3': -16.675018310546875, 'loss_4': 0.44087621569633484, 'epoch': 18.19}
{'loss': 0.0378, 'grad_norm': 15.228256225585938, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.02877744659781456, 'loss_2': 0.0090484619140625, 'loss_3': -16.486717224121094, 'loss_4': 0.15036803483963013, 'epoch': 18.19}
{'loss': 0.0129, 'grad_norm': 7.634810924530029, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.00777776911854744, 'loss_2': 0.005126953125, 'loss_3': -16.544946670532227, 'loss_4': 0.38669291138648987, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 16:34:56,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:56,239 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:34<35:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:03,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020834852010011673, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013974359259009361, 'eval_loss_2': 0.006860494613647461, 'eval_loss_3': -18.18998146057129, 'eval_loss_4': 0.3978622257709503, 'epoch': 18.2}
{'loss': 0.0129, 'grad_norm': 4.564623832702637, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.002936408156529069, 'loss_2': 0.009979248046875, 'loss_3': -16.410301208496094, 'loss_4': 0.6022774577140808, 'epoch': 18.2}
{'loss': 0.0072, 'grad_norm': 4.704803466796875, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.004162425175309181, 'loss_2': 0.0030670166015625, 'loss_3': -16.503398895263672, 'loss_4': 0.5965813398361206, 'epoch': 18.21}
{'loss': 0.0127, 'grad_norm': 4.4169111251831055, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.004302189219743013, 'loss_2': 0.00836181640625, 'loss_3': -16.538570404052734, 'loss_4': 0.3269442915916443, 'epoch': 18.22}
{'loss': 0.0161, 'grad_norm': 4.956000328063965, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.005235751625150442, 'loss_2': 0.0108184814453125, 'loss_3': -16.703657150268555, 'loss_4': 0.1781407594680786, 'epoch': 18.22}
{'loss': 0.006, 'grad_norm': 5.534726142883301, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.005128825549036264, 'loss_2': 0.0008802413940429688, 'loss_3': -16.494531631469727, 'loss_4': 0.6223206520080566, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 16:35:03,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:03,592 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:41<34:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:10,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016885913908481598, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.759, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011496550403535366, 'eval_loss_2': 0.005389362573623657, 'eval_loss_3': -18.22014045715332, 'eval_loss_4': 0.38984131813049316, 'epoch': 18.23}
{'loss': 0.0151, 'grad_norm': 8.41896915435791, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.0114511763677001, 'loss_2': 0.003627777099609375, 'loss_3': -16.71271514892578, 'loss_4': 0.6409749984741211, 'epoch': 18.23}
{'loss': 0.0251, 'grad_norm': 11.815960884094238, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.015519386157393456, 'loss_2': 0.009552001953125, 'loss_3': -16.564586639404297, 'loss_4': 0.2450859099626541, 'epoch': 18.24}
{'loss': 0.0085, 'grad_norm': 5.308663368225098, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.007548943627625704, 'loss_2': 0.0009531974792480469, 'loss_3': -16.565732955932617, 'loss_4': 0.4708838164806366, 'epoch': 18.24}
{'loss': 0.0181, 'grad_norm': 8.308032035827637, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.014748468063771725, 'loss_2': 0.00330352783203125, 'loss_3': -16.59979820251465, 'loss_4': 0.47172248363494873, 'epoch': 18.25}
{'loss': 0.0114, 'grad_norm': 5.106086730957031, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.008826930075883865, 'loss_2': 0.0025463104248046875, 'loss_3': -16.445999145507812, 'loss_4': 0.3495579659938812, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 16:35:10,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:10,934 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:49<34:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:18,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014158204197883606, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.921, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.011598302982747555, 'eval_loss_2': 0.0025599002838134766, 'eval_loss_3': -18.235248565673828, 'eval_loss_4': 0.32722678780555725, 'epoch': 18.26}
{'loss': 0.0095, 'grad_norm': 4.667643070220947, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.005370421800762415, 'loss_2': 0.004100799560546875, 'loss_3': -16.494972229003906, 'loss_4': 0.44908174872398376, 'epoch': 18.26}
{'loss': 0.0247, 'grad_norm': 9.756291389465332, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.022959738969802856, 'loss_2': 0.0017900466918945312, 'loss_3': -16.460737228393555, 'loss_4': -0.14822252094745636, 'epoch': 18.27}
{'loss': 0.0721, 'grad_norm': 12.051660537719727, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.0708753690123558, 'loss_2': 0.0012445449829101562, 'loss_3': -16.71016502380371, 'loss_4': 0.463623970746994, 'epoch': 18.27}
{'loss': 0.0101, 'grad_norm': 9.178705215454102, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.009740636684000492, 'loss_2': 0.0003237724304199219, 'loss_3': -16.684680938720703, 'loss_4': 0.32577237486839294, 'epoch': 18.28}
{'loss': 0.0167, 'grad_norm': 4.602341175079346, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.003896661102771759, 'loss_2': 0.0128173828125, 'loss_3': -16.505882263183594, 'loss_4': -0.12156465649604797, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 16:35:18,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:18,275 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:56<34:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:25,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012122704647481441, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.686, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00927035417407751, 'eval_loss_2': 0.0028523504734039307, 'eval_loss_3': -18.2581729888916, 'eval_loss_4': 0.32781437039375305, 'epoch': 18.28}
{'loss': 0.012, 'grad_norm': 5.928138732910156, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.00752714928239584, 'loss_2': 0.004520416259765625, 'loss_3': -16.684711456298828, 'loss_4': -0.0009729154407978058, 'epoch': 18.29}
{'loss': 0.017, 'grad_norm': 4.978061676025391, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.007567408960312605, 'loss_2': 0.00939178466796875, 'loss_3': -16.58733367919922, 'loss_4': 0.33318114280700684, 'epoch': 18.3}
{'loss': 0.0204, 'grad_norm': 8.523481369018555, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.01873364858329296, 'loss_2': 0.00167083740234375, 'loss_3': -16.429168701171875, 'loss_4': 0.24979957938194275, 'epoch': 18.3}
{'loss': 0.0095, 'grad_norm': 4.886926174163818, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.006497821770608425, 'loss_2': 0.0029582977294921875, 'loss_3': -16.503894805908203, 'loss_4': 0.28494372963905334, 'epoch': 18.31}
{'loss': 0.0162, 'grad_norm': 5.8381266593933105, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.01353007834404707, 'loss_2': 0.00266265869140625, 'loss_3': -16.741493225097656, 'loss_4': 0.3647157549858093, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 16:35:25,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:25,619 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:18:03<34:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:32,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012099570594727993, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.233, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0088943000882864, 'eval_loss_2': 0.0032052695751190186, 'eval_loss_3': -18.272993087768555, 'eval_loss_4': 0.4507921040058136, 'epoch': 18.31}
{'loss': 0.02, 'grad_norm': 5.97120475769043, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.009794516488909721, 'loss_2': 0.01023101806640625, 'loss_3': -16.787731170654297, 'loss_4': 0.27637386322021484, 'epoch': 18.32}
{'loss': 0.0071, 'grad_norm': 4.745405673980713, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.005721624009311199, 'loss_2': 0.00140380859375, 'loss_3': -16.597309112548828, 'loss_4': 0.4317943751811981, 'epoch': 18.33}
{'loss': 0.006, 'grad_norm': 5.313927173614502, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.005291965324431658, 'loss_2': 0.0007305145263671875, 'loss_3': -16.64768409729004, 'loss_4': 0.6786832809448242, 'epoch': 18.33}
{'loss': 0.0152, 'grad_norm': 6.47318172454834, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.01159147173166275, 'loss_2': 0.0035724639892578125, 'loss_3': -16.624439239501953, 'loss_4': 0.8926533460617065, 'epoch': 18.34}
{'loss': 0.0048, 'grad_norm': 4.482941627502441, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.0038974734488874674, 'loss_2': 0.0008831024169921875, 'loss_3': -16.60745620727539, 'loss_4': 0.33607393503189087, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 16:35:32,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:32,951 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:18:11<34:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:40,293 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011758712120354176, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.578, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008713889867067337, 'eval_loss_2': 0.003044821321964264, 'eval_loss_3': -18.30685043334961, 'eval_loss_4': 0.5361130237579346, 'epoch': 18.34}
{'loss': 0.0138, 'grad_norm': 5.824554443359375, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.007374671753495932, 'loss_2': 0.006465911865234375, 'loss_3': -16.42502212524414, 'loss_4': 0.2557041645050049, 'epoch': 18.35}
{'loss': 0.0169, 'grad_norm': 4.894948959350586, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.004944430198520422, 'loss_2': 0.01195526123046875, 'loss_3': -16.606555938720703, 'loss_4': 0.10869422554969788, 'epoch': 18.35}
{'loss': 0.0112, 'grad_norm': 4.673998832702637, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.0032086370047181845, 'loss_2': 0.0080108642578125, 'loss_3': -16.714820861816406, 'loss_4': 0.275761216878891, 'epoch': 18.36}
{'loss': 0.0115, 'grad_norm': 5.474457740783691, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.010132690891623497, 'loss_2': 0.0013523101806640625, 'loss_3': -16.661563873291016, 'loss_4': 0.6199747323989868, 'epoch': 18.37}
{'loss': 0.016, 'grad_norm': 6.543003559112549, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.013190193101763725, 'loss_2': 0.00276947021484375, 'loss_3': -16.615169525146484, 'loss_4': 0.35958462953567505, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 16:35:40,293 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:40,293 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:18<34:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:47,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011724984273314476, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.905, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008165066130459309, 'eval_loss_2': 0.0035599172115325928, 'eval_loss_3': -18.3070125579834, 'eval_loss_4': 0.5589067935943604, 'epoch': 18.37}
{'loss': 0.0042, 'grad_norm': 3.872300624847412, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.0033201980404555798, 'loss_2': 0.000835418701171875, 'loss_3': -16.52149200439453, 'loss_4': 0.15867719054222107, 'epoch': 18.38}
{'loss': 0.0142, 'grad_norm': 6.110051155090332, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.009390020743012428, 'loss_2': 0.004852294921875, 'loss_3': -16.56861114501953, 'loss_4': 0.3205966651439667, 'epoch': 18.38}
{'loss': 0.0165, 'grad_norm': 6.854484558105469, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.010094997473061085, 'loss_2': 0.006412506103515625, 'loss_3': -16.625587463378906, 'loss_4': 0.5009429454803467, 'epoch': 18.39}
{'loss': 0.0254, 'grad_norm': 13.376919746398926, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.020519331097602844, 'loss_2': 0.0049285888671875, 'loss_3': -16.692001342773438, 'loss_4': 0.5079730749130249, 'epoch': 18.4}
{'loss': 0.0177, 'grad_norm': 8.803926467895508, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.014250264503061771, 'loss_2': 0.003475189208984375, 'loss_3': -16.572017669677734, 'loss_4': 0.050313301384449005, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 16:35:47,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:47,636 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:25<34:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:54,974 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013597112149000168, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.035, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008118820376694202, 'eval_loss_2': 0.00547829270362854, 'eval_loss_3': -18.301435470581055, 'eval_loss_4': 0.5013477802276611, 'epoch': 18.4}
{'loss': 0.0066, 'grad_norm': 5.815246105194092, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.00585644505918026, 'loss_2': 0.000789642333984375, 'loss_3': -16.7166690826416, 'loss_4': 0.6860706806182861, 'epoch': 18.41}
{'loss': 0.0171, 'grad_norm': 6.997640609741211, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.016331927850842476, 'loss_2': 0.0007772445678710938, 'loss_3': -16.446495056152344, 'loss_4': 0.5950894951820374, 'epoch': 18.41}
{'loss': 0.0147, 'grad_norm': 5.410135269165039, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.008765860460698605, 'loss_2': 0.0059814453125, 'loss_3': -16.533437728881836, 'loss_4': 0.16539624333381653, 'epoch': 18.42}
{'loss': 0.0116, 'grad_norm': 5.373917579650879, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.006636754609644413, 'loss_2': 0.00499725341796875, 'loss_3': -16.58509063720703, 'loss_4': 0.7872294187545776, 'epoch': 18.42}
{'loss': 0.0177, 'grad_norm': 5.167029857635498, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.007279609329998493, 'loss_2': 0.01041412353515625, 'loss_3': -16.723024368286133, 'loss_4': 0.22163599729537964, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 16:35:54,974 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:54,974 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:33<34:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:02,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015575135126709938, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.837, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007929360494017601, 'eval_loss_2': 0.007645774632692337, 'eval_loss_3': -18.28765869140625, 'eval_loss_4': 0.5351523160934448, 'epoch': 18.43}
{'loss': 0.0165, 'grad_norm': 7.771546363830566, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.010693101212382317, 'loss_2': 0.00583648681640625, 'loss_3': -16.658058166503906, 'loss_4': 0.3251050114631653, 'epoch': 18.44}
{'loss': 0.0151, 'grad_norm': 6.157700538635254, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.008340264670550823, 'loss_2': 0.0067291259765625, 'loss_3': -16.634979248046875, 'loss_4': 0.4717712700366974, 'epoch': 18.44}
{'loss': 0.0115, 'grad_norm': 6.307948589324951, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.007650258485227823, 'loss_2': 0.003849029541015625, 'loss_3': -16.405250549316406, 'loss_4': 0.521664023399353, 'epoch': 18.45}
{'loss': 0.0122, 'grad_norm': 4.839119911193848, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.008220620453357697, 'loss_2': 0.0039825439453125, 'loss_3': -16.67181396484375, 'loss_4': 0.6538287997245789, 'epoch': 18.45}
{'loss': 0.0091, 'grad_norm': 5.3161091804504395, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.006038636900484562, 'loss_2': 0.00304412841796875, 'loss_3': -16.682619094848633, 'loss_4': 0.334482342004776, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 16:36:02,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:02,332 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:40<34:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:09,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013262266293168068, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.837, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.00804051198065281, 'eval_loss_2': 0.005221754312515259, 'eval_loss_3': -18.267738342285156, 'eval_loss_4': 0.6167062520980835, 'epoch': 18.46}
{'loss': 0.0143, 'grad_norm': 5.453622817993164, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.007260717451572418, 'loss_2': 0.00701141357421875, 'loss_3': -16.506616592407227, 'loss_4': 0.9711259603500366, 'epoch': 18.47}
{'loss': 0.0086, 'grad_norm': 5.260161399841309, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.006494516506791115, 'loss_2': 0.002086639404296875, 'loss_3': -16.558774948120117, 'loss_4': 0.7662547826766968, 'epoch': 18.47}
{'loss': 0.0143, 'grad_norm': 13.441108703613281, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.01315845362842083, 'loss_2': 0.001125335693359375, 'loss_3': -16.497941970825195, 'loss_4': 0.2682126760482788, 'epoch': 18.48}
{'loss': 0.0154, 'grad_norm': 5.386672019958496, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.006785411853343248, 'loss_2': 0.0085906982421875, 'loss_3': -16.569570541381836, 'loss_4': 0.9957627058029175, 'epoch': 18.48}
{'loss': 0.0099, 'grad_norm': 4.791464805603027, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.00767027260735631, 'loss_2': 0.002223968505859375, 'loss_3': -16.483434677124023, 'loss_4': 0.01165260374546051, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 16:36:09,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:09,668 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:47<34:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:17,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011603765189647675, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.141, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.007392741274088621, 'eval_loss_2': 0.004211023449897766, 'eval_loss_3': -18.266721725463867, 'eval_loss_4': 0.5989561676979065, 'epoch': 18.49}
{'loss': 0.0059, 'grad_norm': 4.670749664306641, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.004686183296144009, 'loss_2': 0.0012140274047851562, 'loss_3': -16.584810256958008, 'loss_4': 0.8111695051193237, 'epoch': 18.49}
{'loss': 0.0118, 'grad_norm': 5.076346397399902, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.010713217779994011, 'loss_2': 0.0011224746704101562, 'loss_3': -16.67816162109375, 'loss_4': 0.8919187188148499, 'epoch': 18.5}
{'loss': 0.0176, 'grad_norm': 9.364675521850586, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.017289739102125168, 'loss_2': 0.00030112266540527344, 'loss_3': -16.570980072021484, 'loss_4': 0.4029152989387512, 'epoch': 18.51}
{'loss': 0.0157, 'grad_norm': 5.763377666473389, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.009059508331120014, 'loss_2': 0.00661468505859375, 'loss_3': -16.672351837158203, 'loss_4': 0.17333652079105377, 'epoch': 18.51}
{'loss': 0.012, 'grad_norm': 6.048218727111816, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.006316323298960924, 'loss_2': 0.005718231201171875, 'loss_3': -16.580482482910156, 'loss_4': 0.8738213181495667, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 16:36:17,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:17,004 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:55<34:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:24,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011606387794017792, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007453971076756716, 'eval_loss_2': 0.004152417182922363, 'eval_loss_3': -18.2513370513916, 'eval_loss_4': 0.5801176428794861, 'epoch': 18.52}
{'loss': 0.0058, 'grad_norm': 4.754910469055176, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.004338376224040985, 'loss_2': 0.001430511474609375, 'loss_3': -16.617835998535156, 'loss_4': 0.7270697951316833, 'epoch': 18.52}
{'loss': 0.0087, 'grad_norm': 4.95416784286499, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.0059732841327786446, 'loss_2': 0.0027256011962890625, 'loss_3': -16.577524185180664, 'loss_4': 0.5338772535324097, 'epoch': 18.53}
{'loss': 0.0111, 'grad_norm': 7.131577968597412, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.005493988748639822, 'loss_2': 0.005615234375, 'loss_3': -16.62999725341797, 'loss_4': 0.3674032986164093, 'epoch': 18.53}
{'loss': 0.0107, 'grad_norm': 6.650073528289795, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.007186961360275745, 'loss_2': 0.003543853759765625, 'loss_3': -16.816787719726562, 'loss_4': -0.014665529131889343, 'epoch': 18.54}
{'loss': 0.0156, 'grad_norm': 8.98196029663086, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.012881937436759472, 'loss_2': 0.0027008056640625, 'loss_3': -16.50216293334961, 'loss_4': 0.09809291362762451, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 16:36:24,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:24,352 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:19:02<33:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:31,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013351989910006523, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.046, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007752788718789816, 'eval_loss_2': 0.00559920072555542, 'eval_loss_3': -18.2691707611084, 'eval_loss_4': 0.5968839526176453, 'epoch': 18.55}
{'loss': 0.008, 'grad_norm': 4.676573753356934, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.006167801097035408, 'loss_2': 0.001873016357421875, 'loss_3': -16.80419158935547, 'loss_4': 0.48253417015075684, 'epoch': 18.55}
{'loss': 0.0095, 'grad_norm': 9.836567878723145, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.00904172845184803, 'loss_2': 0.000507354736328125, 'loss_3': -16.604999542236328, 'loss_4': 0.08232173323631287, 'epoch': 18.56}
{'loss': 0.0505, 'grad_norm': 24.121259689331055, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.040628813207149506, 'loss_2': 0.00982666015625, 'loss_3': -16.32044792175293, 'loss_4': 0.4489736557006836, 'epoch': 18.56}
{'loss': 0.0199, 'grad_norm': 6.9960618019104, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.010959109291434288, 'loss_2': 0.00896453857421875, 'loss_3': -16.66994285583496, 'loss_4': 0.6165792346000671, 'epoch': 18.57}
{'loss': 0.0064, 'grad_norm': 4.439848899841309, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.00600254675373435, 'loss_2': 0.0004258155822753906, 'loss_3': -16.665857315063477, 'loss_4': 0.8839792013168335, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 16:36:31,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:31,691 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:19:09<33:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:39,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01587114855647087, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.886, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008555632084608078, 'eval_loss_2': 0.007315516471862793, 'eval_loss_3': -18.257301330566406, 'eval_loss_4': 0.6346161365509033, 'epoch': 18.58}
{'loss': 0.0183, 'grad_norm': 10.43631362915039, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.013299173675477505, 'loss_2': 0.00498199462890625, 'loss_3': -16.542810440063477, 'loss_4': 0.6585988402366638, 'epoch': 18.58}
{'loss': 0.0207, 'grad_norm': 10.533160209655762, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.01802203245460987, 'loss_2': 0.002643585205078125, 'loss_3': -16.582412719726562, 'loss_4': 0.6481869220733643, 'epoch': 18.59}
{'loss': 0.0088, 'grad_norm': 6.138166904449463, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.005478689447045326, 'loss_2': 0.0032806396484375, 'loss_3': -16.59082794189453, 'loss_4': 0.1480749249458313, 'epoch': 18.59}
{'loss': 0.011, 'grad_norm': 5.6631927490234375, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.007204147987067699, 'loss_2': 0.0037517547607421875, 'loss_3': -16.63983917236328, 'loss_4': 0.20480720698833466, 'epoch': 18.6}
{'loss': 0.0058, 'grad_norm': 5.117759704589844, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.0027246843092143536, 'loss_2': 0.00312042236328125, 'loss_3': -16.624248504638672, 'loss_4': 0.5352720022201538, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 16:36:39,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:39,026 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:17<33:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:46,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014661354944109917, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.026, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010252966545522213, 'eval_loss_2': 0.004408389329910278, 'eval_loss_3': -18.25295066833496, 'eval_loss_4': 0.6118394136428833, 'epoch': 18.6}
{'loss': 0.0709, 'grad_norm': 26.020030975341797, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.06793614476919174, 'loss_2': 0.002964019775390625, 'loss_3': -16.61513900756836, 'loss_4': 0.6507290005683899, 'epoch': 18.61}
{'loss': 0.005, 'grad_norm': 4.613894939422607, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.0040527889505028725, 'loss_2': 0.0009708404541015625, 'loss_3': -16.620990753173828, 'loss_4': 0.1768631935119629, 'epoch': 18.62}
{'loss': 0.0099, 'grad_norm': 4.992481708526611, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.007187704090029001, 'loss_2': 0.002719879150390625, 'loss_3': -16.523300170898438, 'loss_4': 0.7148941159248352, 'epoch': 18.62}
{'loss': 0.006, 'grad_norm': 5.411922454833984, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.004391863010823727, 'loss_2': 0.00160980224609375, 'loss_3': -16.580352783203125, 'loss_4': 0.8577437996864319, 'epoch': 18.63}
{'loss': 0.0122, 'grad_norm': 5.886845588684082, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.009627072140574455, 'loss_2': 0.00254058837890625, 'loss_3': -16.8681697845459, 'loss_4': 0.22122490406036377, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 16:36:46,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:46,363 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:24<33:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:53,699 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01763654686510563, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.662, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013794193044304848, 'eval_loss_2': 0.0038423538208007812, 'eval_loss_3': -18.25479507446289, 'eval_loss_4': 0.649570643901825, 'epoch': 18.63}
{'loss': 0.0071, 'grad_norm': 4.667521953582764, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.0037264199927449226, 'loss_2': 0.00341033935546875, 'loss_3': -16.565052032470703, 'loss_4': 0.2861575484275818, 'epoch': 18.64}
{'loss': 0.0211, 'grad_norm': 6.900575160980225, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.009143304079771042, 'loss_2': 0.0119476318359375, 'loss_3': -16.87381362915039, 'loss_4': 0.2597305178642273, 'epoch': 18.65}
{'loss': 0.0114, 'grad_norm': 6.513403415679932, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.008820177055895329, 'loss_2': 0.00258636474609375, 'loss_3': -16.595672607421875, 'loss_4': 0.22857224941253662, 'epoch': 18.65}
{'loss': 0.0098, 'grad_norm': 4.5968732833862305, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.004526486620306969, 'loss_2': 0.00527191162109375, 'loss_3': -16.388858795166016, 'loss_4': 0.35547739267349243, 'epoch': 18.66}
{'loss': 0.012, 'grad_norm': 5.689026832580566, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.01012486033141613, 'loss_2': 0.001861572265625, 'loss_3': -16.353961944580078, 'loss_4': 0.5438015460968018, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 16:36:53,699 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:53,699 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:31<33:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:01,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02006014809012413, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.641, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01715082675218582, 'eval_loss_2': 0.0029093213379383087, 'eval_loss_3': -18.221742630004883, 'eval_loss_4': 0.7084404826164246, 'epoch': 18.66}
{'loss': 0.0236, 'grad_norm': 11.056073188781738, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.017654163762927055, 'loss_2': 0.0059661865234375, 'loss_3': -16.52731704711914, 'loss_4': 0.8728950619697571, 'epoch': 18.67}
{'loss': 0.0225, 'grad_norm': 10.396814346313477, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.016903653740882874, 'loss_2': 0.005634307861328125, 'loss_3': -16.481590270996094, 'loss_4': 0.5692680478096008, 'epoch': 18.67}
{'loss': 0.0107, 'grad_norm': 4.832492351531982, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.005455466452986002, 'loss_2': 0.0052032470703125, 'loss_3': -16.62390899658203, 'loss_4': 0.6238479614257812, 'epoch': 18.68}
{'loss': 0.0089, 'grad_norm': 5.172433376312256, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.007203779648989439, 'loss_2': 0.001728057861328125, 'loss_3': -16.78717803955078, 'loss_4': 0.8706583380699158, 'epoch': 18.69}
{'loss': 0.0085, 'grad_norm': 4.206925868988037, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.004072515293955803, 'loss_2': 0.00445556640625, 'loss_3': -16.582258224487305, 'loss_4': 0.48394930362701416, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 16:37:01,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:01,042 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:39<33:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:08,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023278340697288513, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.589, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019005700945854187, 'eval_loss_2': 0.004272639751434326, 'eval_loss_3': -18.207080841064453, 'eval_loss_4': 0.690727949142456, 'epoch': 18.69}
{'loss': 0.0071, 'grad_norm': 6.522124767303467, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.005276620853692293, 'loss_2': 0.00177764892578125, 'loss_3': -16.72819709777832, 'loss_4': 0.27581721544265747, 'epoch': 18.7}
{'loss': 0.0073, 'grad_norm': 5.32667875289917, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.005498866084963083, 'loss_2': 0.0017642974853515625, 'loss_3': -16.654541015625, 'loss_4': 0.5665403604507446, 'epoch': 18.7}
{'loss': 0.0097, 'grad_norm': 5.479531288146973, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.006565380841493607, 'loss_2': 0.003139495849609375, 'loss_3': -16.37925148010254, 'loss_4': 0.23503708839416504, 'epoch': 18.71}
{'loss': 0.0074, 'grad_norm': 4.878830432891846, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.004206841811537743, 'loss_2': 0.00316619873046875, 'loss_3': -16.68206024169922, 'loss_4': 0.5013188123703003, 'epoch': 18.72}
{'loss': 0.0073, 'grad_norm': 4.493468761444092, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.006326889619231224, 'loss_2': 0.0010013580322265625, 'loss_3': -16.77292251586914, 'loss_4': 0.4299287497997284, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 16:37:08,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:08,386 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:46<33:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:15,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02314058318734169, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01969321444630623, 'eval_loss_2': 0.0034473687410354614, 'eval_loss_3': -18.190664291381836, 'eval_loss_4': 0.6943795680999756, 'epoch': 18.72}
{'loss': 0.0119, 'grad_norm': 6.573877334594727, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.010673468932509422, 'loss_2': 0.001239776611328125, 'loss_3': -16.508617401123047, 'loss_4': 0.6521598100662231, 'epoch': 18.73}
{'loss': 0.0056, 'grad_norm': 4.590322494506836, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.00446692481637001, 'loss_2': 0.0011796951293945312, 'loss_3': -16.446611404418945, 'loss_4': 0.8183563947677612, 'epoch': 18.73}
{'loss': 0.0111, 'grad_norm': 5.353468894958496, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.007908400148153305, 'loss_2': 0.003208160400390625, 'loss_3': -16.432025909423828, 'loss_4': 0.6793534755706787, 'epoch': 18.74}
{'loss': 0.0092, 'grad_norm': 6.016816139221191, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.007090033497661352, 'loss_2': 0.0020618438720703125, 'loss_3': -16.27027130126953, 'loss_4': 0.45362791419029236, 'epoch': 18.74}
{'loss': 0.0042, 'grad_norm': 4.796909332275391, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.0037692624609917402, 'loss_2': 0.00044655799865722656, 'loss_3': -16.429506301879883, 'loss_4': 0.7151875495910645, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 16:37:15,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:15,728 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:53<33:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:23,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02464180439710617, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.721, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.021760243922472, 'eval_loss_2': 0.0028815604746341705, 'eval_loss_3': -18.175111770629883, 'eval_loss_4': 0.7328286170959473, 'epoch': 18.75}
{'loss': 0.0096, 'grad_norm': 4.746135711669922, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.002742812968790531, 'loss_2': 0.006900787353515625, 'loss_3': -16.724973678588867, 'loss_4': 0.6763275861740112, 'epoch': 18.76}
{'loss': 0.0108, 'grad_norm': 4.245500087738037, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.003157952567562461, 'loss_2': 0.0076446533203125, 'loss_3': -16.66046142578125, 'loss_4': 0.6604719161987305, 'epoch': 18.76}
{'loss': 0.0095, 'grad_norm': 5.4057841300964355, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.003389873541891575, 'loss_2': 0.00609588623046875, 'loss_3': -16.469829559326172, 'loss_4': 0.7936133742332458, 'epoch': 18.77}
{'loss': 0.0075, 'grad_norm': 4.603830814361572, 'learning_rate': 1.125e-05, 'loss_1': 0.004413309507071972, 'loss_2': 0.003116607666015625, 'loss_3': -16.704151153564453, 'loss_4': 0.6647090911865234, 'epoch': 18.77}
{'loss': 0.0126, 'grad_norm': 5.007325172424316, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.005730644799768925, 'loss_2': 0.00685882568359375, 'loss_3': -16.567968368530273, 'loss_4': 0.6590225696563721, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 16:37:23,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:23,065 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:20:01<33:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:30,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024668054655194283, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.021715689450502396, 'eval_loss_2': 0.002952367067337036, 'eval_loss_3': -18.178653717041016, 'eval_loss_4': 0.8217176795005798, 'epoch': 18.78}
{'loss': 0.0146, 'grad_norm': 6.977245807647705, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.013291550800204277, 'loss_2': 0.00135040283203125, 'loss_3': -16.279132843017578, 'loss_4': 0.30219483375549316, 'epoch': 18.78}
{'loss': 0.0087, 'grad_norm': 4.543098449707031, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.004345311783254147, 'loss_2': 0.0043792724609375, 'loss_3': -16.515256881713867, 'loss_4': 0.9468098878860474, 'epoch': 18.79}
{'loss': 0.004, 'grad_norm': 4.561368942260742, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.0028196205385029316, 'loss_2': 0.0012264251708984375, 'loss_3': -16.58452606201172, 'loss_4': 0.5975897312164307, 'epoch': 18.8}
{'loss': 0.005, 'grad_norm': 4.374228000640869, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.002915747929364443, 'loss_2': 0.0020771026611328125, 'loss_3': -16.436805725097656, 'loss_4': 0.8396978378295898, 'epoch': 18.8}
{'loss': 0.0108, 'grad_norm': 4.784012317657471, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.0031952455174177885, 'loss_2': 0.007556915283203125, 'loss_3': -16.511533737182617, 'loss_4': 0.5569480657577515, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 16:37:30,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:30,407 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:20:08<33:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:37,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023635849356651306, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018498731777071953, 'eval_loss_2': 0.005137115716934204, 'eval_loss_3': -18.185977935791016, 'eval_loss_4': 0.8888750076293945, 'epoch': 18.81}
{'loss': 0.0084, 'grad_norm': 4.79596471786499, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.003101515583693981, 'loss_2': 0.00531005859375, 'loss_3': -16.567840576171875, 'loss_4': 1.061249017715454, 'epoch': 18.81}
{'loss': 0.0089, 'grad_norm': 4.616562843322754, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.0037435777485370636, 'loss_2': 0.00519561767578125, 'loss_3': -16.733726501464844, 'loss_4': 0.9225873947143555, 'epoch': 18.82}
{'loss': 0.0126, 'grad_norm': 6.062403202056885, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.007443850394338369, 'loss_2': 0.0051116943359375, 'loss_3': -16.731311798095703, 'loss_4': 0.49702805280685425, 'epoch': 18.83}
{'loss': 0.0128, 'grad_norm': 4.694919109344482, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.0035181953571736813, 'loss_2': 0.009307861328125, 'loss_3': -16.61545181274414, 'loss_4': 0.6800938844680786, 'epoch': 18.83}
{'loss': 0.0073, 'grad_norm': 5.559665203094482, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.005021256860345602, 'loss_2': 0.00223541259765625, 'loss_3': -16.485855102539062, 'loss_4': 0.5066751837730408, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 16:37:37,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:37,745 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:20:15<33:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:45,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01982063800096512, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01508826483041048, 'eval_loss_2': 0.004732370376586914, 'eval_loss_3': -18.20934295654297, 'eval_loss_4': 0.8838886022567749, 'epoch': 18.84}
{'loss': 0.0081, 'grad_norm': 5.361967086791992, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.006740460637956858, 'loss_2': 0.0013675689697265625, 'loss_3': -16.47598648071289, 'loss_4': 0.9088997840881348, 'epoch': 18.84}
{'loss': 0.0125, 'grad_norm': 4.439163684844971, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.00570055702701211, 'loss_2': 0.006801605224609375, 'loss_3': -16.54650115966797, 'loss_4': 0.875046968460083, 'epoch': 18.85}
{'loss': 0.0098, 'grad_norm': 6.0194993019104, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.004738521296530962, 'loss_2': 0.005031585693359375, 'loss_3': -16.35685157775879, 'loss_4': 0.3096248507499695, 'epoch': 18.85}
{'loss': 0.0213, 'grad_norm': 5.914970397949219, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.01608605869114399, 'loss_2': 0.0051727294921875, 'loss_3': -16.570629119873047, 'loss_4': 0.8172188401222229, 'epoch': 18.86}
{'loss': 0.0276, 'grad_norm': 20.684663772583008, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.02537204697728157, 'loss_2': 0.0022068023681640625, 'loss_3': -16.516992568969727, 'loss_4': 0.43677034974098206, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 16:37:45,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:45,096 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:23<33:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:52,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01640394702553749, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.755, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013967396691441536, 'eval_loss_2': 0.0024365484714508057, 'eval_loss_3': -18.220972061157227, 'eval_loss_4': 0.8173513412475586, 'epoch': 18.87}
{'loss': 0.0177, 'grad_norm': 7.353911876678467, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.01214507780969143, 'loss_2': 0.00551605224609375, 'loss_3': -16.602262496948242, 'loss_4': 0.7284184694290161, 'epoch': 18.87}
{'loss': 0.0216, 'grad_norm': 9.417346954345703, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.019300052896142006, 'loss_2': 0.002277374267578125, 'loss_3': -16.254730224609375, 'loss_4': 0.6199231147766113, 'epoch': 18.88}
{'loss': 0.0142, 'grad_norm': 8.734539031982422, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.008053810335695744, 'loss_2': 0.00612640380859375, 'loss_3': -16.3125057220459, 'loss_4': 0.6799681186676025, 'epoch': 18.88}
{'loss': 0.0096, 'grad_norm': 3.9833548069000244, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.0018688112031668425, 'loss_2': 0.0077667236328125, 'loss_3': -16.538402557373047, 'loss_4': 0.7966803312301636, 'epoch': 18.89}
{'loss': 0.0084, 'grad_norm': 4.7512335777282715, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.002523580100387335, 'loss_2': 0.00586700439453125, 'loss_3': -16.650306701660156, 'loss_4': 0.9627765417098999, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 16:37:52,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:52,432 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:30<32:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:59,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019922424107789993, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.874, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01615581102669239, 'eval_loss_2': 0.0037666112184524536, 'eval_loss_3': -18.217323303222656, 'eval_loss_4': 0.7394244074821472, 'epoch': 18.9}
{'loss': 0.0052, 'grad_norm': 4.945851802825928, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.0048013729974627495, 'loss_2': 0.0004372596740722656, 'loss_3': -16.324857711791992, 'loss_4': 0.753115177154541, 'epoch': 18.9}
{'loss': 0.0105, 'grad_norm': 5.1719160079956055, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.008202084340155125, 'loss_2': 0.0023021697998046875, 'loss_3': -16.59794807434082, 'loss_4': 0.800835132598877, 'epoch': 18.91}
{'loss': 0.0152, 'grad_norm': 6.374282360076904, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.008971206843852997, 'loss_2': 0.006275177001953125, 'loss_3': -16.452045440673828, 'loss_4': 0.3093409538269043, 'epoch': 18.91}
{'loss': 0.0179, 'grad_norm': 16.097932815551758, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.013426962308585644, 'loss_2': 0.00445556640625, 'loss_3': -16.645126342773438, 'loss_4': 0.6304669976234436, 'epoch': 18.92}
{'loss': 0.0043, 'grad_norm': 4.40203332901001, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.0024242631625384092, 'loss_2': 0.0018596649169921875, 'loss_3': -16.536846160888672, 'loss_4': 0.7032188177108765, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 16:37:59,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:59,768 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:37<32:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:07,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02164406143128872, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.696, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.019350387156009674, 'eval_loss_2': 0.0022936761379241943, 'eval_loss_3': -18.200653076171875, 'eval_loss_4': 0.6518610715866089, 'epoch': 18.92}
{'loss': 0.0362, 'grad_norm': 16.10602378845215, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.035886019468307495, 'loss_2': 0.0002856254577636719, 'loss_3': -16.330209732055664, 'loss_4': 0.6007966995239258, 'epoch': 18.93}
{'loss': 0.0137, 'grad_norm': 6.176433086395264, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.010398326441645622, 'loss_2': 0.003292083740234375, 'loss_3': -16.763050079345703, 'loss_4': 0.25793057680130005, 'epoch': 18.94}
{'loss': 0.0135, 'grad_norm': 11.48514175415039, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.01292379293590784, 'loss_2': 0.0005998611450195312, 'loss_3': -16.282089233398438, 'loss_4': 0.7098069190979004, 'epoch': 18.94}
{'loss': 0.019, 'grad_norm': 6.636361598968506, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.013949749991297722, 'loss_2': 0.005096435546875, 'loss_3': -16.6702880859375, 'loss_4': -0.05623173713684082, 'epoch': 18.95}
{'loss': 0.0144, 'grad_norm': 4.679866313934326, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.0047679562121629715, 'loss_2': 0.00958251953125, 'loss_3': -16.74964141845703, 'loss_4': 0.4747265577316284, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 16:38:07,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:07,107 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:45<32:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:14,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015436513349413872, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012612750753760338, 'eval_loss_2': 0.002823762595653534, 'eval_loss_3': -18.249666213989258, 'eval_loss_4': 0.641279399394989, 'epoch': 18.95}
{'loss': 0.007, 'grad_norm': 5.097597599029541, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.004789052996784449, 'loss_2': 0.002197265625, 'loss_3': -16.597187042236328, 'loss_4': 0.5738565921783447, 'epoch': 18.96}
{'loss': 0.0076, 'grad_norm': 5.225189208984375, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.005270959343761206, 'loss_2': 0.0023021697998046875, 'loss_3': -16.653642654418945, 'loss_4': 0.2902297377586365, 'epoch': 18.97}
{'loss': 0.0053, 'grad_norm': 5.723092079162598, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.005233469884842634, 'loss_2': 7.081031799316406e-05, 'loss_3': -16.785625457763672, 'loss_4': 0.5883821249008179, 'epoch': 18.97}
{'loss': 0.0211, 'grad_norm': 5.17018985748291, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.006585798226296902, 'loss_2': 0.01448822021484375, 'loss_3': -16.63037872314453, 'loss_4': 0.29806190729141235, 'epoch': 18.98}
{'loss': 0.0064, 'grad_norm': 5.1106462478637695, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.0044440897181630135, 'loss_2': 0.0019702911376953125, 'loss_3': -16.66973876953125, 'loss_4': 0.4448544979095459, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 16:38:14,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:14,448 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:52<31:22,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 16:38:21,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014289021492004395, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00960649736225605, 'eval_loss_2': 0.004682525992393494, 'eval_loss_3': -18.282238006591797, 'eval_loss_4': 0.6714580059051514, 'epoch': 18.98}
{'loss': 0.0079, 'grad_norm': 4.510752201080322, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.0048046051524579525, 'loss_2': 0.0031070709228515625, 'loss_3': -16.590919494628906, 'loss_4': 0.594822883605957, 'epoch': 18.99}
{'loss': 0.01, 'grad_norm': 4.525969505310059, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.0037231806199997663, 'loss_2': 0.0062408447265625, 'loss_3': -16.585519790649414, 'loss_4': 0.9311781525611877, 'epoch': 18.99}
{'loss': 0.0218, 'grad_norm': 9.396430969238281, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.011963481083512306, 'loss_2': 0.00984954833984375, 'loss_3': -16.480209350585938, 'loss_4': 0.4250141680240631, 'epoch': 19.0}
{'loss': 0.0168, 'grad_norm': 11.692651748657227, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.012365642935037613, 'loss_2': 0.00446319580078125, 'loss_3': -16.65713119506836, 'loss_4': 0.8715598583221436, 'epoch': 19.01}
{'loss': 0.0727, 'grad_norm': 15.284778594970703, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.06681010872125626, 'loss_2': 0.00586700439453125, 'loss_3': -16.76091957092285, 'loss_4': 0.9169825911521912, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 16:38:21,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:21,489 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:59<32:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:38:28,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012471674010157585, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00929707195609808, 'eval_loss_2': 0.00317460298538208, 'eval_loss_3': -18.319021224975586, 'eval_loss_4': 0.7934808135032654, 'epoch': 19.01}
{'loss': 0.0042, 'grad_norm': 4.658966541290283, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.003983483649790287, 'loss_2': 0.00020420551300048828, 'loss_3': -16.440914154052734, 'loss_4': 0.5822277069091797, 'epoch': 19.02}
{'loss': 0.0112, 'grad_norm': 5.082582950592041, 'learning_rate': 1.1e-05, 'loss_1': 0.005465762689709663, 'loss_2': 0.00574493408203125, 'loss_3': -16.38472557067871, 'loss_4': 0.9729057550430298, 'epoch': 19.02}
{'loss': 0.0064, 'grad_norm': 4.768833160400391, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.005822852253913879, 'loss_2': 0.0005617141723632812, 'loss_3': -16.7104434967041, 'loss_4': 1.0606800317764282, 'epoch': 19.03}
{'loss': 0.0103, 'grad_norm': 5.145567417144775, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.005003479775041342, 'loss_2': 0.00531005859375, 'loss_3': -16.49367904663086, 'loss_4': 0.7890205383300781, 'epoch': 19.03}
{'loss': 0.0144, 'grad_norm': 6.9423017501831055, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.007805588189512491, 'loss_2': 0.006572723388671875, 'loss_3': -16.735607147216797, 'loss_4': 1.0487656593322754, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 16:38:28,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:28,829 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:21:07<32:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:36,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011623576283454895, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.41, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008728377521038055, 'eval_loss_2': 0.0028951987624168396, 'eval_loss_3': -18.318992614746094, 'eval_loss_4': 0.863111674785614, 'epoch': 19.04}
{'loss': 0.0029, 'grad_norm': 4.891728401184082, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.002510144142434001, 'loss_2': 0.0004360675811767578, 'loss_3': -16.831722259521484, 'loss_4': 0.5822688937187195, 'epoch': 19.05}
{'loss': 0.0035, 'grad_norm': 5.029651165008545, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.0022840595338493586, 'loss_2': 0.0012493133544921875, 'loss_3': -16.78681182861328, 'loss_4': 1.007750391960144, 'epoch': 19.05}
{'loss': 0.0704, 'grad_norm': 13.478034019470215, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.06275121867656708, 'loss_2': 0.00765228271484375, 'loss_3': -16.52609634399414, 'loss_4': 0.8391819000244141, 'epoch': 19.06}
{'loss': 0.0137, 'grad_norm': 6.75224494934082, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.009395625442266464, 'loss_2': 0.00434112548828125, 'loss_3': -16.624065399169922, 'loss_4': 1.0457669496536255, 'epoch': 19.06}
{'loss': 0.0074, 'grad_norm': 5.418636322021484, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.007156196050345898, 'loss_2': 0.000213623046875, 'loss_3': -16.573246002197266, 'loss_4': 0.5383603572845459, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 16:38:36,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:36,172 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:21:14<32:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:43,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011196497827768326, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.921, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.007997844368219376, 'eval_loss_2': 0.00319865345954895, 'eval_loss_3': -18.330825805664062, 'eval_loss_4': 0.9357728958129883, 'epoch': 19.07}
{'loss': 0.0054, 'grad_norm': 5.716061592102051, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.005373237654566765, 'loss_2': 2.944469451904297e-05, 'loss_3': -16.676633834838867, 'loss_4': 0.676885724067688, 'epoch': 19.08}
{'loss': 0.0082, 'grad_norm': 5.617765426635742, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.006601307075470686, 'loss_2': 0.00159454345703125, 'loss_3': -16.5916805267334, 'loss_4': 0.7225854396820068, 'epoch': 19.08}
{'loss': 0.0076, 'grad_norm': 5.643519401550293, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.007078084629029036, 'loss_2': 0.0005078315734863281, 'loss_3': -16.6781005859375, 'loss_4': 0.6160266995429993, 'epoch': 19.09}
{'loss': 0.0095, 'grad_norm': 5.216517448425293, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.005867832340300083, 'loss_2': 0.0036773681640625, 'loss_3': -16.58254051208496, 'loss_4': 0.7520003318786621, 'epoch': 19.09}
{'loss': 0.0065, 'grad_norm': 5.0626091957092285, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.004753303248435259, 'loss_2': 0.0017566680908203125, 'loss_3': -16.609458923339844, 'loss_4': 0.5205320119857788, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 16:38:43,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:43,518 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:21<32:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:50,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011613152921199799, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.125, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008570484817028046, 'eval_loss_2': 0.003042668104171753, 'eval_loss_3': -18.343074798583984, 'eval_loss_4': 1.0190978050231934, 'epoch': 19.1}
{'loss': 0.0107, 'grad_norm': 5.218600749969482, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.005690597463399172, 'loss_2': 0.0050048828125, 'loss_3': -16.550220489501953, 'loss_4': 1.1155493259429932, 'epoch': 19.1}
{'loss': 0.0105, 'grad_norm': 5.27490758895874, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.007679067086428404, 'loss_2': 0.0027923583984375, 'loss_3': -16.592226028442383, 'loss_4': 0.9268431663513184, 'epoch': 19.11}
{'loss': 0.0059, 'grad_norm': 5.433220863342285, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.0057043409906327724, 'loss_2': 0.00022220611572265625, 'loss_3': -16.543357849121094, 'loss_4': 0.9777843356132507, 'epoch': 19.12}
{'loss': 0.0143, 'grad_norm': 5.371904373168945, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.007839424535632133, 'loss_2': 0.006488800048828125, 'loss_3': -16.63113021850586, 'loss_4': 1.0948066711425781, 'epoch': 19.12}
{'loss': 0.0124, 'grad_norm': 5.074952602386475, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.007103182375431061, 'loss_2': 0.005336761474609375, 'loss_3': -16.601713180541992, 'loss_4': 1.0291826725006104, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 16:38:50,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:50,855 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:29<32:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:58,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012320865876972675, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009165320545434952, 'eval_loss_2': 0.003155544400215149, 'eval_loss_3': -18.343242645263672, 'eval_loss_4': 1.0678576231002808, 'epoch': 19.13}
{'loss': 0.0099, 'grad_norm': 7.3067545890808105, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.009065371006727219, 'loss_2': 0.000858306884765625, 'loss_3': -16.582481384277344, 'loss_4': 0.8642526268959045, 'epoch': 19.13}
{'loss': 0.0082, 'grad_norm': 4.760519504547119, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.005672336556017399, 'loss_2': 0.002513885498046875, 'loss_3': -16.813617706298828, 'loss_4': 1.2885103225708008, 'epoch': 19.14}
{'loss': 0.0114, 'grad_norm': 5.188591480255127, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.005188764072954655, 'loss_2': 0.0062255859375, 'loss_3': -16.886615753173828, 'loss_4': 1.0481455326080322, 'epoch': 19.15}
{'loss': 0.01, 'grad_norm': 4.586914539337158, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.00637018820270896, 'loss_2': 0.0036716461181640625, 'loss_3': -16.72815704345703, 'loss_4': 1.353745937347412, 'epoch': 19.15}
{'loss': 0.027, 'grad_norm': 13.109038352966309, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.02629907615482807, 'loss_2': 0.0006551742553710938, 'loss_3': -16.62093162536621, 'loss_4': 1.009448528289795, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 16:38:58,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:58,198 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:36<32:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:05,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012237124145030975, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.797, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.00891178846359253, 'eval_loss_2': 0.003325335681438446, 'eval_loss_3': -18.33452796936035, 'eval_loss_4': 1.1426424980163574, 'epoch': 19.16}
{'loss': 0.0091, 'grad_norm': 4.984246253967285, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.006494684144854546, 'loss_2': 0.002628326416015625, 'loss_3': -16.62187957763672, 'loss_4': 0.7892681956291199, 'epoch': 19.16}
{'loss': 0.0461, 'grad_norm': 18.32291030883789, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.041175782680511475, 'loss_2': 0.0048980712890625, 'loss_3': -16.50582504272461, 'loss_4': 1.5860981941223145, 'epoch': 19.17}
{'loss': 0.0111, 'grad_norm': 8.224230766296387, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.010911052115261555, 'loss_2': 0.0002167224884033203, 'loss_3': -16.57313346862793, 'loss_4': 0.7604153156280518, 'epoch': 19.17}
{'loss': 0.0176, 'grad_norm': 7.6166839599609375, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.01576145365834236, 'loss_2': 0.0018329620361328125, 'loss_3': -16.661357879638672, 'loss_4': 0.8981858491897583, 'epoch': 19.18}
{'loss': 0.0114, 'grad_norm': 4.752385139465332, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.007160636596381664, 'loss_2': 0.0041961669921875, 'loss_3': -16.715442657470703, 'loss_4': 0.9486823081970215, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 16:39:05,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:05,534 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:43<32:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:12,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0122474804520607, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008939005434513092, 'eval_loss_2': 0.0033084750175476074, 'eval_loss_3': -18.33481788635254, 'eval_loss_4': 1.2226040363311768, 'epoch': 19.19}
{'loss': 0.0063, 'grad_norm': 5.3317365646362305, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.0061640567146241665, 'loss_2': 0.0001201629638671875, 'loss_3': -16.746122360229492, 'loss_4': 1.2452516555786133, 'epoch': 19.19}
{'loss': 0.0081, 'grad_norm': 5.067755699157715, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.0037291597109287977, 'loss_2': 0.00432586669921875, 'loss_3': -16.929964065551758, 'loss_4': 0.8157525062561035, 'epoch': 19.2}
{'loss': 0.0152, 'grad_norm': 4.9270548820495605, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.010215050540864468, 'loss_2': 0.005008697509765625, 'loss_3': -16.426738739013672, 'loss_4': 0.9277212619781494, 'epoch': 19.2}
{'loss': 0.01, 'grad_norm': 6.254116058349609, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.008373265154659748, 'loss_2': 0.001590728759765625, 'loss_3': -16.602130889892578, 'loss_4': 1.6050258874893188, 'epoch': 19.21}
{'loss': 0.0084, 'grad_norm': 4.713481903076172, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.004938651341944933, 'loss_2': 0.0034313201904296875, 'loss_3': -16.78645133972168, 'loss_4': 0.9502012729644775, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 16:39:12,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:12,868 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:51<31:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:20,207 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014488279819488525, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.712, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009462473914027214, 'eval_loss_2': 0.005025804042816162, 'eval_loss_3': -18.3355770111084, 'eval_loss_4': 1.3038427829742432, 'epoch': 19.22}
{'loss': 0.0081, 'grad_norm': 5.448500156402588, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.006341441534459591, 'loss_2': 0.0017642974853515625, 'loss_3': -16.34477424621582, 'loss_4': 1.1956983804702759, 'epoch': 19.22}
{'loss': 0.0127, 'grad_norm': 4.7968220710754395, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.004001979250460863, 'loss_2': 0.0086822509765625, 'loss_3': -16.603267669677734, 'loss_4': 1.239965558052063, 'epoch': 19.23}
{'loss': 0.0154, 'grad_norm': 8.257539749145508, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.010834341868758202, 'loss_2': 0.004608154296875, 'loss_3': -16.515108108520508, 'loss_4': 1.2978764772415161, 'epoch': 19.23}
{'loss': 0.0069, 'grad_norm': 4.399418354034424, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.005131773184984922, 'loss_2': 0.0017642974853515625, 'loss_3': -16.68459701538086, 'loss_4': 1.0252528190612793, 'epoch': 19.24}
{'loss': 0.0086, 'grad_norm': 5.588491439819336, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.008452442474663258, 'loss_2': 0.00013184547424316406, 'loss_3': -16.604476928710938, 'loss_4': 1.1981860399246216, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 16:39:20,207 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:20,207 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:58<31:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:27,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01393453124910593, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.9, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009625544771552086, 'eval_loss_2': 0.004308987408876419, 'eval_loss_3': -18.316242218017578, 'eval_loss_4': 1.3200567960739136, 'epoch': 19.24}
{'loss': 0.0168, 'grad_norm': 5.806716442108154, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.007732512429356575, 'loss_2': 0.00904083251953125, 'loss_3': -16.589004516601562, 'loss_4': 0.6519562005996704, 'epoch': 19.25}
{'loss': 0.0067, 'grad_norm': 4.404872417449951, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.004191109910607338, 'loss_2': 0.002460479736328125, 'loss_3': -16.550783157348633, 'loss_4': 0.7793884873390198, 'epoch': 19.26}
{'loss': 0.0101, 'grad_norm': 4.956803321838379, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.006495379377156496, 'loss_2': 0.003570556640625, 'loss_3': -16.820232391357422, 'loss_4': 1.2388508319854736, 'epoch': 19.26}
{'loss': 0.0075, 'grad_norm': 5.246749401092529, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.0066848024725914, 'loss_2': 0.0008540153503417969, 'loss_3': -16.69625473022461, 'loss_4': 1.059785008430481, 'epoch': 19.27}
{'loss': 0.0053, 'grad_norm': 5.11138916015625, 'learning_rate': 1.075e-05, 'loss_1': 0.005130421370267868, 'loss_2': 0.00019276142120361328, 'loss_3': -16.80605697631836, 'loss_4': 0.8356399536132812, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 16:39:27,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:27,542 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:22:05<31:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:34,881 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012797221541404724, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.839, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009355380199849606, 'eval_loss_2': 0.003441840410232544, 'eval_loss_3': -18.312206268310547, 'eval_loss_4': 1.2912479639053345, 'epoch': 19.27}
{'loss': 0.0083, 'grad_norm': 4.538920879364014, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.004746673163026571, 'loss_2': 0.00354766845703125, 'loss_3': -16.59780502319336, 'loss_4': 1.1439402103424072, 'epoch': 19.28}
{'loss': 0.0098, 'grad_norm': 4.906050682067871, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.005471356678754091, 'loss_2': 0.00428009033203125, 'loss_3': -16.629596710205078, 'loss_4': 1.0826711654663086, 'epoch': 19.28}
{'loss': 0.0071, 'grad_norm': 4.437385082244873, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.004180070944130421, 'loss_2': 0.00287628173828125, 'loss_3': -16.613229751586914, 'loss_4': 1.5697487592697144, 'epoch': 19.29}
{'loss': 0.0105, 'grad_norm': 4.651038646697998, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.008092418313026428, 'loss_2': 0.002361297607421875, 'loss_3': -16.563560485839844, 'loss_4': 1.1633895635604858, 'epoch': 19.3}
{'loss': 0.0063, 'grad_norm': 5.409182548522949, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.005097001791000366, 'loss_2': 0.0012006759643554688, 'loss_3': -16.525379180908203, 'loss_4': 1.337835669517517, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 16:39:34,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:34,881 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:22:13<31:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:42,222 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015014411881566048, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01013209205120802, 'eval_loss_2': 0.004882320761680603, 'eval_loss_3': -18.325881958007812, 'eval_loss_4': 1.3275691270828247, 'epoch': 19.3}
{'loss': 0.015, 'grad_norm': 4.807624816894531, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.006788140162825584, 'loss_2': 0.0081939697265625, 'loss_3': -16.75847625732422, 'loss_4': 1.222293734550476, 'epoch': 19.31}
{'loss': 0.0154, 'grad_norm': 5.938343524932861, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.00831584632396698, 'loss_2': 0.0071258544921875, 'loss_3': -16.740997314453125, 'loss_4': 0.9560630321502686, 'epoch': 19.31}
{'loss': 0.0131, 'grad_norm': 12.0309419631958, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.012711047194898129, 'loss_2': 0.000392913818359375, 'loss_3': -16.83039665222168, 'loss_4': 0.9684468507766724, 'epoch': 19.32}
{'loss': 0.006, 'grad_norm': 4.223984241485596, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.004342439118772745, 'loss_2': 0.0016498565673828125, 'loss_3': -16.496641159057617, 'loss_4': 1.3867785930633545, 'epoch': 19.33}
{'loss': 0.0166, 'grad_norm': 4.721592903137207, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.007955579087138176, 'loss_2': 0.00864410400390625, 'loss_3': -16.42037010192871, 'loss_4': 1.2454239130020142, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 16:39:42,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:42,222 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:20<31:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:49,561 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013233453035354614, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.812, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010019553825259209, 'eval_loss_2': 0.0032138973474502563, 'eval_loss_3': -18.315441131591797, 'eval_loss_4': 1.3271641731262207, 'epoch': 19.33}
{'loss': 0.0136, 'grad_norm': 8.080406188964844, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.011222227476537228, 'loss_2': 0.002422332763671875, 'loss_3': -16.751087188720703, 'loss_4': 0.8235000967979431, 'epoch': 19.34}
{'loss': 0.0112, 'grad_norm': 5.340287208557129, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.007661402225494385, 'loss_2': 0.0035247802734375, 'loss_3': -16.660552978515625, 'loss_4': 1.0723141431808472, 'epoch': 19.34}
{'loss': 0.0203, 'grad_norm': 6.065860271453857, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.014293053187429905, 'loss_2': 0.005977630615234375, 'loss_3': -16.660999298095703, 'loss_4': 1.2374892234802246, 'epoch': 19.35}
{'loss': 0.0103, 'grad_norm': 9.110817909240723, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.009196947328746319, 'loss_2': 0.001117706298828125, 'loss_3': -16.63936996459961, 'loss_4': 1.5627272129058838, 'epoch': 19.35}
{'loss': 0.014, 'grad_norm': 10.619012832641602, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.013494863174855709, 'loss_2': 0.00047588348388671875, 'loss_3': -16.54271697998047, 'loss_4': 1.2063353061676025, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 16:39:49,561 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:49,561 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:27<31:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:56,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013812607154250145, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010122439824044704, 'eval_loss_2': 0.003690168261528015, 'eval_loss_3': -18.302410125732422, 'eval_loss_4': 1.3230611085891724, 'epoch': 19.36}
{'loss': 0.0227, 'grad_norm': 9.144471168518066, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.018458962440490723, 'loss_2': 0.00421142578125, 'loss_3': -16.51241111755371, 'loss_4': 0.8612372875213623, 'epoch': 19.37}
{'loss': 0.0149, 'grad_norm': 7.644113540649414, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.012346549890935421, 'loss_2': 0.00255584716796875, 'loss_3': -16.744783401489258, 'loss_4': 0.7360593676567078, 'epoch': 19.37}
{'loss': 0.0104, 'grad_norm': 5.421594619750977, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.007238088175654411, 'loss_2': 0.003173828125, 'loss_3': -16.750404357910156, 'loss_4': 0.767577052116394, 'epoch': 19.38}
{'loss': 0.0294, 'grad_norm': 12.159558296203613, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.0190983135253191, 'loss_2': 0.0102996826171875, 'loss_3': -16.589942932128906, 'loss_4': 1.4018739461898804, 'epoch': 19.38}
{'loss': 0.0126, 'grad_norm': 6.614909648895264, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.010164819657802582, 'loss_2': 0.002407073974609375, 'loss_3': -16.662425994873047, 'loss_4': 1.3440146446228027, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 16:39:56,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:56,902 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:35<31:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:04,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015369332395493984, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.912, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00955436285585165, 'eval_loss_2': 0.005814969539642334, 'eval_loss_3': -18.290119171142578, 'eval_loss_4': 1.238814115524292, 'epoch': 19.39}
{'loss': 0.0076, 'grad_norm': 5.180721282958984, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.007440119981765747, 'loss_2': 0.0001608133316040039, 'loss_3': -16.784496307373047, 'loss_4': 1.4026985168457031, 'epoch': 19.4}
{'loss': 0.0177, 'grad_norm': 4.822561740875244, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.006842363625764847, 'loss_2': 0.0108795166015625, 'loss_3': -16.659622192382812, 'loss_4': 0.7135331630706787, 'epoch': 19.4}
{'loss': 0.0165, 'grad_norm': 5.848007678985596, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.00912652537226677, 'loss_2': 0.007354736328125, 'loss_3': -16.609092712402344, 'loss_4': 1.221860647201538, 'epoch': 19.41}
{'loss': 0.0147, 'grad_norm': 8.969173431396484, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.008168035186827183, 'loss_2': 0.006488800048828125, 'loss_3': -16.681209564208984, 'loss_4': 0.8489422798156738, 'epoch': 19.41}
{'loss': 0.0194, 'grad_norm': 6.1932291984558105, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.009966133162379265, 'loss_2': 0.0093994140625, 'loss_3': -16.617359161376953, 'loss_4': 1.0586599111557007, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 16:40:04,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:04,240 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:42<31:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:11,574 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014924826100468636, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.841, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009257899597287178, 'eval_loss_2': 0.0056669265031814575, 'eval_loss_3': -18.31760025024414, 'eval_loss_4': 1.1294292211532593, 'epoch': 19.42}
{'loss': 0.0189, 'grad_norm': 13.213295936584473, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.01536376029253006, 'loss_2': 0.0035858154296875, 'loss_3': -16.745479583740234, 'loss_4': 0.5792327523231506, 'epoch': 19.42}
{'loss': 0.0167, 'grad_norm': 6.173485279083252, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.012043352238833904, 'loss_2': 0.004638671875, 'loss_3': -16.52643394470215, 'loss_4': 0.9909608364105225, 'epoch': 19.43}
{'loss': 0.0143, 'grad_norm': 6.480489253997803, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.009402606636285782, 'loss_2': 0.00487518310546875, 'loss_3': -16.73093032836914, 'loss_4': 0.6672114133834839, 'epoch': 19.44}
{'loss': 0.0041, 'grad_norm': 4.370832920074463, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.0031510419212281704, 'loss_2': 0.0009093284606933594, 'loss_3': -16.709373474121094, 'loss_4': 0.7613382339477539, 'epoch': 19.44}
{'loss': 0.007, 'grad_norm': 5.536059856414795, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.005509127397090197, 'loss_2': 0.0015201568603515625, 'loss_3': -16.633773803710938, 'loss_4': 1.290733814239502, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 16:40:11,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:11,574 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:49<31:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:18,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01399795152246952, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.423, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009898067452013493, 'eval_loss_2': 0.004099883139133453, 'eval_loss_3': -18.312122344970703, 'eval_loss_4': 1.0755845308303833, 'epoch': 19.45}
{'loss': 0.0042, 'grad_norm': 4.6305060386657715, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.0037784595042467117, 'loss_2': 0.0004391670227050781, 'loss_3': -16.61090087890625, 'loss_4': 0.9720361232757568, 'epoch': 19.45}
{'loss': 0.0062, 'grad_norm': 4.555850028991699, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.006146641448140144, 'loss_2': 7.927417755126953e-05, 'loss_3': -16.71839141845703, 'loss_4': 0.9633253812789917, 'epoch': 19.46}
{'loss': 0.0207, 'grad_norm': 8.05731201171875, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.012689223513007164, 'loss_2': 0.00798797607421875, 'loss_3': -16.876449584960938, 'loss_4': 0.6025776863098145, 'epoch': 19.47}
{'loss': 0.0062, 'grad_norm': 4.748568534851074, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.005016280338168144, 'loss_2': 0.0011529922485351562, 'loss_3': -16.558353424072266, 'loss_4': 1.0419155359268188, 'epoch': 19.47}
{'loss': 0.0063, 'grad_norm': 4.790535926818848, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.003293695393949747, 'loss_2': 0.00296783447265625, 'loss_3': -16.711721420288086, 'loss_4': 1.223214864730835, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 16:40:18,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:18,926 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:57<31:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:26,262 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01274086907505989, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009397968649864197, 'eval_loss_2': 0.003342900425195694, 'eval_loss_3': -18.312538146972656, 'eval_loss_4': 0.9716653823852539, 'epoch': 19.48}
{'loss': 0.0164, 'grad_norm': 5.44890022277832, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.006582678761333227, 'loss_2': 0.009857177734375, 'loss_3': -16.60968589782715, 'loss_4': 0.7704340815544128, 'epoch': 19.48}
{'loss': 0.01, 'grad_norm': 6.203494071960449, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.006942687090486288, 'loss_2': 0.0031032562255859375, 'loss_3': -16.49835777282715, 'loss_4': 0.45078855752944946, 'epoch': 19.49}
{'loss': 0.0066, 'grad_norm': 4.45807409286499, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.0038101861719042063, 'loss_2': 0.0027618408203125, 'loss_3': -16.63253402709961, 'loss_4': 0.5518440008163452, 'epoch': 19.49}
{'loss': 0.0075, 'grad_norm': 4.155346393585205, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.0035286087077111006, 'loss_2': 0.0039825439453125, 'loss_3': -16.707489013671875, 'loss_4': 0.5928456783294678, 'epoch': 19.5}
{'loss': 0.0062, 'grad_norm': 4.60013484954834, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.004851113073527813, 'loss_2': 0.0013647079467773438, 'loss_3': -16.689708709716797, 'loss_4': 0.5717381834983826, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 16:40:26,263 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:26,263 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:23:04<31:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:33,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011552220210433006, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.966, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008303528651595116, 'eval_loss_2': 0.0032486915588378906, 'eval_loss_3': -18.30219268798828, 'eval_loss_4': 0.9279717803001404, 'epoch': 19.51}
{'loss': 0.0116, 'grad_norm': 5.172962188720703, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.0067914631217718124, 'loss_2': 0.004779815673828125, 'loss_3': -16.660425186157227, 'loss_4': 0.7812159657478333, 'epoch': 19.51}
{'loss': 0.0211, 'grad_norm': 21.88104248046875, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.016862355172634125, 'loss_2': 0.004215240478515625, 'loss_3': -16.50975227355957, 'loss_4': 0.6301030516624451, 'epoch': 19.52}
{'loss': 0.0117, 'grad_norm': 4.942640781402588, 'learning_rate': 1.05e-05, 'loss_1': 0.0038133380003273487, 'loss_2': 0.007843017578125, 'loss_3': -16.647193908691406, 'loss_4': 0.835139274597168, 'epoch': 19.52}
{'loss': 0.0064, 'grad_norm': 4.319352149963379, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.006237884983420372, 'loss_2': 0.0001747608184814453, 'loss_3': -16.747529983520508, 'loss_4': 1.024501085281372, 'epoch': 19.53}
{'loss': 0.0137, 'grad_norm': 5.212545871734619, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.00764658534899354, 'loss_2': 0.006072998046875, 'loss_3': -16.600515365600586, 'loss_4': 0.32204797863960266, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 16:40:33,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:33,602 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:23:11<31:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:40,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013601605780422688, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.941, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008888727985322475, 'eval_loss_2': 0.004712879657745361, 'eval_loss_3': -18.293466567993164, 'eval_loss_4': 0.9498243927955627, 'epoch': 19.53}
{'loss': 0.0161, 'grad_norm': 4.724849224090576, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.0038184889126569033, 'loss_2': 0.01230621337890625, 'loss_3': -17.05126190185547, 'loss_4': 0.9582027196884155, 'epoch': 19.54}
{'loss': 0.0129, 'grad_norm': 5.16719388961792, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.005008095875382423, 'loss_2': 0.00788116455078125, 'loss_3': -16.672420501708984, 'loss_4': 0.6284364461898804, 'epoch': 19.55}
{'loss': 0.0173, 'grad_norm': 6.3034539222717285, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.008869918994605541, 'loss_2': 0.0084381103515625, 'loss_3': -16.713361740112305, 'loss_4': 0.6284977197647095, 'epoch': 19.55}
{'loss': 0.0091, 'grad_norm': 4.84921407699585, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.004966047126799822, 'loss_2': 0.00412750244140625, 'loss_3': -16.618606567382812, 'loss_4': 0.7141148447990417, 'epoch': 19.56}
{'loss': 0.0143, 'grad_norm': 6.093873023986816, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.00824994221329689, 'loss_2': 0.006061553955078125, 'loss_3': -16.670913696289062, 'loss_4': 0.2266598343849182, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 16:40:40,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:40,944 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:19<30:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:48,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01201056782156229, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.627, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008622879162430763, 'eval_loss_2': 0.0033876895904541016, 'eval_loss_3': -18.279035568237305, 'eval_loss_4': 0.8939300775527954, 'epoch': 19.56}
{'loss': 0.0106, 'grad_norm': 5.221948146820068, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.00432988628745079, 'loss_2': 0.00630950927734375, 'loss_3': -16.61009407043457, 'loss_4': 0.5133333206176758, 'epoch': 19.57}
{'loss': 0.0074, 'grad_norm': 4.697734832763672, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.005341751035302877, 'loss_2': 0.00202178955078125, 'loss_3': -16.770402908325195, 'loss_4': 0.5826916098594666, 'epoch': 19.58}
{'loss': 0.0085, 'grad_norm': 5.137528896331787, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.004534493200480938, 'loss_2': 0.003936767578125, 'loss_3': -16.659852981567383, 'loss_4': 0.11940724402666092, 'epoch': 19.58}
{'loss': 0.0103, 'grad_norm': 6.497917652130127, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.008234720677137375, 'loss_2': 0.0020503997802734375, 'loss_3': -16.529855728149414, 'loss_4': 0.5757221579551697, 'epoch': 19.59}
{'loss': 0.0045, 'grad_norm': 4.568127155303955, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.002881841966882348, 'loss_2': 0.0016307830810546875, 'loss_3': -16.537975311279297, 'loss_4': 0.8278132677078247, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 16:40:48,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:48,282 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:26<30:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:55,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014174486510455608, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.838, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009523744694888592, 'eval_loss_2': 0.004650741815567017, 'eval_loss_3': -18.254802703857422, 'eval_loss_4': 0.7914283871650696, 'epoch': 19.59}
{'loss': 0.0062, 'grad_norm': 5.409257888793945, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.003568656276911497, 'loss_2': 0.00263214111328125, 'loss_3': -16.49339485168457, 'loss_4': 0.5593187808990479, 'epoch': 19.6}
{'loss': 0.015, 'grad_norm': 4.762626647949219, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.0045233010314404964, 'loss_2': 0.01052093505859375, 'loss_3': -16.75574493408203, 'loss_4': 0.5672780275344849, 'epoch': 19.6}
{'loss': 0.0042, 'grad_norm': 4.577027320861816, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.003887360682711005, 'loss_2': 0.0002865791320800781, 'loss_3': -16.74738311767578, 'loss_4': 0.44653216004371643, 'epoch': 19.61}
{'loss': 0.0326, 'grad_norm': 11.894309043884277, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.026393111795186996, 'loss_2': 0.00616455078125, 'loss_3': -16.766315460205078, 'loss_4': 0.12480398267507553, 'epoch': 19.62}
{'loss': 0.015, 'grad_norm': 11.846619606018066, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.01490333117544651, 'loss_2': 8.159875869750977e-05, 'loss_3': -16.544939041137695, 'loss_4': 0.5621917247772217, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 16:40:55,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:55,626 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:33<30:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:02,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015538012608885765, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.482, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01022147573530674, 'eval_loss_2': 0.005316536873579025, 'eval_loss_3': -18.254074096679688, 'eval_loss_4': 0.792264997959137, 'epoch': 19.62}
{'loss': 0.0147, 'grad_norm': 6.701241493225098, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.00943527277559042, 'loss_2': 0.00527191162109375, 'loss_3': -16.643001556396484, 'loss_4': 0.45750463008880615, 'epoch': 19.63}
{'loss': 0.0122, 'grad_norm': 5.5289740562438965, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.008646618574857712, 'loss_2': 0.003570556640625, 'loss_3': -16.72333335876465, 'loss_4': 0.914874792098999, 'epoch': 19.63}
{'loss': 0.0095, 'grad_norm': 5.216804504394531, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.007834009826183319, 'loss_2': 0.0016307830810546875, 'loss_3': -16.64028549194336, 'loss_4': 0.4740660786628723, 'epoch': 19.64}
{'loss': 0.0224, 'grad_norm': 10.853707313537598, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.01732649654150009, 'loss_2': 0.00511932373046875, 'loss_3': -16.30596923828125, 'loss_4': 0.7069358825683594, 'epoch': 19.65}
{'loss': 0.0228, 'grad_norm': 10.193291664123535, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.01877078227698803, 'loss_2': 0.00402069091796875, 'loss_3': -16.401973724365234, 'loss_4': 0.5120377540588379, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 16:41:02,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:02,962 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:41<30:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:10,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01536514051258564, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.749, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01079205609858036, 'eval_loss_2': 0.0045730844140052795, 'eval_loss_3': -18.25132942199707, 'eval_loss_4': 0.8136674165725708, 'epoch': 19.65}
{'loss': 0.0127, 'grad_norm': 5.081295967102051, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.004873307887464762, 'loss_2': 0.00778961181640625, 'loss_3': -16.668441772460938, 'loss_4': 0.48444825410842896, 'epoch': 19.66}
{'loss': 0.0194, 'grad_norm': 5.682776927947998, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.011344817467033863, 'loss_2': 0.0080108642578125, 'loss_3': -16.739734649658203, 'loss_4': 0.5944021940231323, 'epoch': 19.66}
{'loss': 0.0267, 'grad_norm': 13.946208000183105, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.016575157642364502, 'loss_2': 0.01012420654296875, 'loss_3': -16.559310913085938, 'loss_4': 0.16746357083320618, 'epoch': 19.67}
{'loss': 0.0085, 'grad_norm': 5.615652084350586, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.008332555182278156, 'loss_2': 0.00020503997802734375, 'loss_3': -16.630178451538086, 'loss_4': 0.4681270718574524, 'epoch': 19.67}
{'loss': 0.0116, 'grad_norm': 4.960575103759766, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.003286059247329831, 'loss_2': 0.0082855224609375, 'loss_3': -16.460830688476562, 'loss_4': 0.3527418076992035, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 16:41:10,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:10,301 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:48<30:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:17,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013312719762325287, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.815, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.00986386090517044, 'eval_loss_2': 0.003448858857154846, 'eval_loss_3': -18.241928100585938, 'eval_loss_4': 0.8981940746307373, 'epoch': 19.68}
{'loss': 0.0142, 'grad_norm': 6.200184345245361, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.011167417280375957, 'loss_2': 0.003002166748046875, 'loss_3': -16.55547332763672, 'loss_4': 0.9881318807601929, 'epoch': 19.69}
{'loss': 0.0226, 'grad_norm': 13.429008483886719, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.019893828779459, 'loss_2': 0.002750396728515625, 'loss_3': -16.44236946105957, 'loss_4': 0.8131226897239685, 'epoch': 19.69}
{'loss': 0.0045, 'grad_norm': 4.38331937789917, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.0034652750473469496, 'loss_2': 0.001071929931640625, 'loss_3': -16.612098693847656, 'loss_4': 0.8415940999984741, 'epoch': 19.7}
{'loss': 0.014, 'grad_norm': 5.066030025482178, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.005612723995000124, 'loss_2': 0.00836181640625, 'loss_3': -16.65023422241211, 'loss_4': 0.9851617813110352, 'epoch': 19.7}
{'loss': 0.006, 'grad_norm': 4.80050802230835, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.004928149748593569, 'loss_2': 0.001041412353515625, 'loss_3': -16.52243995666504, 'loss_4': 0.8138258457183838, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 16:41:17,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:17,643 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:55<30:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:24,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013511396944522858, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.897, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010035820305347443, 'eval_loss_2': 0.003475576639175415, 'eval_loss_3': -18.250713348388672, 'eval_loss_4': 0.9981055855751038, 'epoch': 19.71}
{'loss': 0.0092, 'grad_norm': 4.723647117614746, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.007180655375123024, 'loss_2': 0.00203704833984375, 'loss_3': -16.49790382385254, 'loss_4': 0.8273162841796875, 'epoch': 19.72}
{'loss': 0.0185, 'grad_norm': 5.451303005218506, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.0076761553063988686, 'loss_2': 0.0107879638671875, 'loss_3': -16.653684616088867, 'loss_4': 0.22601298987865448, 'epoch': 19.72}
{'loss': 0.0097, 'grad_norm': 4.4504523277282715, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.006828600540757179, 'loss_2': 0.002826690673828125, 'loss_3': -16.706172943115234, 'loss_4': 0.8279941082000732, 'epoch': 19.73}
{'loss': 0.007, 'grad_norm': 4.694365501403809, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.005492385011166334, 'loss_2': 0.0015554428100585938, 'loss_3': -16.607868194580078, 'loss_4': 0.7808022499084473, 'epoch': 19.73}
{'loss': 0.012, 'grad_norm': 5.522093296051025, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.0071770427748560905, 'loss_2': 0.00481414794921875, 'loss_3': -16.628026962280273, 'loss_4': 0.8006600141525269, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 16:41:24,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:24,980 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:24:03<30:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:32,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014344032853841782, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010857667773962021, 'eval_loss_2': 0.0034863650798797607, 'eval_loss_3': -18.23469352722168, 'eval_loss_4': 1.0739322900772095, 'epoch': 19.74}
{'loss': 0.0041, 'grad_norm': 4.991959571838379, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.003043690463528037, 'loss_2': 0.0010175704956054688, 'loss_3': -16.660247802734375, 'loss_4': 0.7804039716720581, 'epoch': 19.74}
{'loss': 0.0189, 'grad_norm': 11.394648551940918, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.01848076656460762, 'loss_2': 0.0003998279571533203, 'loss_3': -16.715065002441406, 'loss_4': 0.9492603540420532, 'epoch': 19.75}
{'loss': 0.0123, 'grad_norm': 5.170170307159424, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.005909567233175039, 'loss_2': 0.00640869140625, 'loss_3': -16.548938751220703, 'loss_4': 0.9775694608688354, 'epoch': 19.76}
{'loss': 0.0226, 'grad_norm': 7.155276775360107, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.019787659868597984, 'loss_2': 0.002765655517578125, 'loss_3': -16.54228973388672, 'loss_4': 0.6795930862426758, 'epoch': 19.76}
{'loss': 0.0148, 'grad_norm': 6.54011869430542, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.009915207512676716, 'loss_2': 0.00490570068359375, 'loss_3': -16.355756759643555, 'loss_4': 0.8077861666679382, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 16:41:32,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:32,328 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:24:10<30:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:39,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015267625451087952, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.53, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012230172753334045, 'eval_loss_2': 0.0030374526977539062, 'eval_loss_3': -18.199094772338867, 'eval_loss_4': 1.1281371116638184, 'epoch': 19.77}
{'loss': 0.0051, 'grad_norm': 4.5391845703125, 'learning_rate': 1.025e-05, 'loss_1': 0.004384211264550686, 'loss_2': 0.0006971359252929688, 'loss_3': -16.44461441040039, 'loss_4': 0.5946425795555115, 'epoch': 19.77}
{'loss': 0.0049, 'grad_norm': 5.996520519256592, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.004503330215811729, 'loss_2': 0.00043511390686035156, 'loss_3': -16.544044494628906, 'loss_4': 0.7814288139343262, 'epoch': 19.78}
{'loss': 0.006, 'grad_norm': 5.015620231628418, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.0048798746429383755, 'loss_2': 0.0011348724365234375, 'loss_3': -16.42361068725586, 'loss_4': 1.0522905588150024, 'epoch': 19.78}
{'loss': 0.0117, 'grad_norm': 5.7863359451293945, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.0087397126480937, 'loss_2': 0.002956390380859375, 'loss_3': -16.74932098388672, 'loss_4': 0.7768051624298096, 'epoch': 19.79}
{'loss': 0.0044, 'grad_norm': 4.2569451332092285, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.002713985973969102, 'loss_2': 0.0016412734985351562, 'loss_3': -16.496028900146484, 'loss_4': 0.813814103603363, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 16:41:39,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:39,675 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:17<30:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:47,016 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01992742531001568, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.932, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01735014282166958, 'eval_loss_2': 0.0025772824883461, 'eval_loss_3': -18.178050994873047, 'eval_loss_4': 1.1968015432357788, 'epoch': 19.8}
{'loss': 0.0146, 'grad_norm': 8.085862159729004, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.01170499436557293, 'loss_2': 0.002910614013671875, 'loss_3': -16.52008819580078, 'loss_4': 1.0352429151535034, 'epoch': 19.8}
{'loss': 0.0089, 'grad_norm': 5.32457160949707, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.007359636481851339, 'loss_2': 0.0015125274658203125, 'loss_3': -16.43897247314453, 'loss_4': 1.0923445224761963, 'epoch': 19.81}
{'loss': 0.0098, 'grad_norm': 5.8812031745910645, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.006065322086215019, 'loss_2': 0.0037746429443359375, 'loss_3': -16.554275512695312, 'loss_4': 0.9930384159088135, 'epoch': 19.81}
{'loss': 0.0097, 'grad_norm': 4.392289161682129, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.0056627909652888775, 'loss_2': 0.00402069091796875, 'loss_3': -16.362716674804688, 'loss_4': 0.9864920973777771, 'epoch': 19.82}
{'loss': 0.0699, 'grad_norm': 34.71616744995117, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.06012675538659096, 'loss_2': 0.00981903076171875, 'loss_3': -16.58987045288086, 'loss_4': 1.0936200618743896, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 16:41:47,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:47,016 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:25<30:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:54,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026370760053396225, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.023431001231074333, 'eval_loss_2': 0.002939760684967041, 'eval_loss_3': -18.14059829711914, 'eval_loss_4': 1.249640703201294, 'epoch': 19.83}
{'loss': 0.0107, 'grad_norm': 4.690176486968994, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.0035718027502298355, 'loss_2': 0.00708770751953125, 'loss_3': -16.595779418945312, 'loss_4': 1.0706846714019775, 'epoch': 19.83}
{'loss': 0.0089, 'grad_norm': 6.126368522644043, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.007466260809451342, 'loss_2': 0.0014591217041015625, 'loss_3': -16.426456451416016, 'loss_4': 0.7638969421386719, 'epoch': 19.84}
{'loss': 0.0148, 'grad_norm': 5.888769149780273, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.008674310520291328, 'loss_2': 0.00612640380859375, 'loss_3': -16.400310516357422, 'loss_4': 0.9730843901634216, 'epoch': 19.84}
{'loss': 0.0084, 'grad_norm': 5.718242168426514, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.005523966159671545, 'loss_2': 0.0028362274169921875, 'loss_3': -16.43842315673828, 'loss_4': 1.141431212425232, 'epoch': 19.85}
{'loss': 0.0048, 'grad_norm': 5.260922431945801, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.004393535200506449, 'loss_2': 0.00043487548828125, 'loss_3': -16.567392349243164, 'loss_4': 0.9347589015960693, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 16:41:54,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:54,356 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:32<30:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:01,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037572696805000305, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.024, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.03464409336447716, 'eval_loss_2': 0.002928599715232849, 'eval_loss_3': -18.098413467407227, 'eval_loss_4': 1.2668213844299316, 'epoch': 19.85}
{'loss': 0.0244, 'grad_norm': 10.609434127807617, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.02238619700074196, 'loss_2': 0.002017974853515625, 'loss_3': -16.56493377685547, 'loss_4': 1.0910558700561523, 'epoch': 19.86}
{'loss': 0.0109, 'grad_norm': 5.369913578033447, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.007561408448964357, 'loss_2': 0.003376007080078125, 'loss_3': -16.47429084777832, 'loss_4': 0.8130416870117188, 'epoch': 19.87}
{'loss': 0.0034, 'grad_norm': 4.219873905181885, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.0019802884198725224, 'loss_2': 0.00139617919921875, 'loss_3': -16.718271255493164, 'loss_4': 0.9772506356239319, 'epoch': 19.87}
{'loss': 0.0108, 'grad_norm': 5.767762184143066, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.0085684135556221, 'loss_2': 0.0022735595703125, 'loss_3': -16.441802978515625, 'loss_4': 1.2099504470825195, 'epoch': 19.88}
{'loss': 0.0117, 'grad_norm': 5.5460028648376465, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.008548875339329243, 'loss_2': 0.003185272216796875, 'loss_3': -16.5130558013916, 'loss_4': 1.4757272005081177, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 16:42:01,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:01,695 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:39<30:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:09,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03947966545820236, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.692, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.035428158938884735, 'eval_loss_2': 0.004051506519317627, 'eval_loss_3': -18.07781410217285, 'eval_loss_4': 1.3803346157073975, 'epoch': 19.88}
{'loss': 0.0099, 'grad_norm': 5.960631370544434, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.006036164239048958, 'loss_2': 0.0038280487060546875, 'loss_3': -16.70669937133789, 'loss_4': 1.1362459659576416, 'epoch': 19.89}
{'loss': 0.014, 'grad_norm': 6.90230655670166, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.01034502126276493, 'loss_2': 0.003673553466796875, 'loss_3': -16.39801025390625, 'loss_4': 0.7975813150405884, 'epoch': 19.9}
{'loss': 0.0073, 'grad_norm': 4.719318866729736, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.004934811498969793, 'loss_2': 0.00232696533203125, 'loss_3': -16.620250701904297, 'loss_4': 0.686631441116333, 'epoch': 19.9}
{'loss': 0.0102, 'grad_norm': 5.328892230987549, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.005378188565373421, 'loss_2': 0.00482177734375, 'loss_3': -16.56049346923828, 'loss_4': 0.9462790489196777, 'epoch': 19.91}
{'loss': 0.0085, 'grad_norm': 4.622949123382568, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.005444585811346769, 'loss_2': 0.003086090087890625, 'loss_3': -16.723421096801758, 'loss_4': 1.0920642614364624, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 16:42:09,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:09,037 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:47<29:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:16,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022828638553619385, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.52, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01917889341711998, 'eval_loss_2': 0.0036497414112091064, 'eval_loss_3': -18.14666175842285, 'eval_loss_4': 1.354246735572815, 'epoch': 19.91}
{'loss': 0.0123, 'grad_norm': 5.339085102081299, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.004567458759993315, 'loss_2': 0.007781982421875, 'loss_3': -16.60326385498047, 'loss_4': 1.0398941040039062, 'epoch': 19.92}
{'loss': 0.008, 'grad_norm': 4.789463996887207, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.003275710390880704, 'loss_2': 0.0047607421875, 'loss_3': -16.593196868896484, 'loss_4': 0.9001305103302002, 'epoch': 19.92}
{'loss': 0.0128, 'grad_norm': 5.270793437957764, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.006038804072886705, 'loss_2': 0.006809234619140625, 'loss_3': -16.655256271362305, 'loss_4': 1.1620861291885376, 'epoch': 19.93}
{'loss': 0.0135, 'grad_norm': 5.66731595993042, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.008907722309231758, 'loss_2': 0.004638671875, 'loss_3': -16.50859260559082, 'loss_4': 0.684411883354187, 'epoch': 19.94}
{'loss': 0.0337, 'grad_norm': 22.535810470581055, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.02804083377122879, 'loss_2': 0.0056304931640625, 'loss_3': -16.527807235717773, 'loss_4': 1.1995435953140259, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 16:42:16,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:16,382 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:54<29:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:23,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0114238066598773, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.542, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008926145732402802, 'eval_loss_2': 0.0024976618587970734, 'eval_loss_3': -18.19966697692871, 'eval_loss_4': 1.2903002500534058, 'epoch': 19.94}
{'loss': 0.01, 'grad_norm': 6.657907009124756, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.008144810795783997, 'loss_2': 0.0018711090087890625, 'loss_3': -16.516746520996094, 'loss_4': 1.2060542106628418, 'epoch': 19.95}
{'loss': 0.0093, 'grad_norm': 5.076868057250977, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.007224131841212511, 'loss_2': 0.0020904541015625, 'loss_3': -16.630908966064453, 'loss_4': 0.9846593737602234, 'epoch': 19.95}
{'loss': 0.0065, 'grad_norm': 4.545290946960449, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.003931167535483837, 'loss_2': 0.0025234222412109375, 'loss_3': -16.597976684570312, 'loss_4': 0.8357539176940918, 'epoch': 19.96}
{'loss': 0.0149, 'grad_norm': 9.667577743530273, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.010128038935363293, 'loss_2': 0.00478363037109375, 'loss_3': -16.643325805664062, 'loss_4': 0.8045085668563843, 'epoch': 19.97}
{'loss': 0.0654, 'grad_norm': 19.41197967529297, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.05817055702209473, 'loss_2': 0.00727081298828125, 'loss_3': -16.58142852783203, 'loss_4': 1.2160502672195435, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 16:42:23,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:23,725 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:25:01<26:43,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:42:30,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011868240311741829, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.135, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008378327824175358, 'eval_loss_2': 0.0034899115562438965, 'eval_loss_3': -18.214513778686523, 'eval_loss_4': 1.2365168333053589, 'epoch': 19.97}
{'loss': 0.0166, 'grad_norm': 13.292686462402344, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.015589665621519089, 'loss_2': 0.0009984970092773438, 'loss_3': -16.579669952392578, 'loss_4': 0.8935598134994507, 'epoch': 19.98}
{'loss': 0.0155, 'grad_norm': 6.820377349853516, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.011579254642128944, 'loss_2': 0.00388336181640625, 'loss_3': -16.49580955505371, 'loss_4': 0.877918004989624, 'epoch': 19.98}
{'loss': 0.0111, 'grad_norm': 5.68263053894043, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.007217485457658768, 'loss_2': 0.00386810302734375, 'loss_3': -16.323558807373047, 'loss_4': 0.9330081939697266, 'epoch': 19.99}
{'loss': 0.0166, 'grad_norm': 6.914128303527832, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.011259837076067924, 'loss_2': 0.005329132080078125, 'loss_3': -16.4979190826416, 'loss_4': 1.2416831254959106, 'epoch': 19.99}
{'loss': 0.0091, 'grad_norm': 5.836887836456299, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.0023267227225005627, 'loss_2': 0.00675201416015625, 'loss_3': -16.54445457458496, 'loss_4': 1.0551221370697021, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 16:42:30,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:30,708 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:25:08<29:16,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:42:38,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011884251609444618, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.33, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008996743708848953, 'eval_loss_2': 0.002887509763240814, 'eval_loss_3': -18.24187469482422, 'eval_loss_4': 1.2600795030593872, 'epoch': 20.0}
{'loss': 0.0042, 'grad_norm': 4.5230021476745605, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.002783147618174553, 'loss_2': 0.0014667510986328125, 'loss_3': -16.535282135009766, 'loss_4': 1.0067155361175537, 'epoch': 20.01}
{'loss': 0.0203, 'grad_norm': 7.455471038818359, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.01138169877231121, 'loss_2': 0.008941650390625, 'loss_3': -16.55164337158203, 'loss_4': 1.1405893564224243, 'epoch': 20.01}
{'loss': 0.003, 'grad_norm': 4.02748441696167, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.0020354276057332754, 'loss_2': 0.0010013580322265625, 'loss_3': -16.854663848876953, 'loss_4': 0.9596929550170898, 'epoch': 20.02}
{'loss': 0.0307, 'grad_norm': 11.341277122497559, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.030059458687901497, 'loss_2': 0.0006127357482910156, 'loss_3': -16.379709243774414, 'loss_4': 0.6682416796684265, 'epoch': 20.02}
{'loss': 0.0069, 'grad_norm': 4.692439556121826, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.006383017171174288, 'loss_2': 0.0004906654357910156, 'loss_3': -16.374914169311523, 'loss_4': 0.9031112790107727, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 16:42:38,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:38,099 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:25:16<29:56,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:42:45,641 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01070298533886671, 'eval_runtime': 3.9905, 'eval_samples_per_second': 256.61, 'eval_steps_per_second': 4.01, 'eval_loss_1': 0.008294272236526012, 'eval_loss_2': 0.0024087131023406982, 'eval_loss_3': -18.242353439331055, 'eval_loss_4': 1.2610979080200195, 'epoch': 20.03}
{'loss': 0.0064, 'grad_norm': 4.823787689208984, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.004812655970454216, 'loss_2': 0.00160980224609375, 'loss_3': -16.686370849609375, 'loss_4': 0.6777492165565491, 'epoch': 20.03}
{'loss': 0.0144, 'grad_norm': 4.756091594696045, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.007805529050529003, 'loss_2': 0.0066070556640625, 'loss_3': -16.523988723754883, 'loss_4': 1.0232237577438354, 'epoch': 20.04}
{'loss': 0.0103, 'grad_norm': 5.270326614379883, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.009744729846715927, 'loss_2': 0.0005931854248046875, 'loss_3': -16.552417755126953, 'loss_4': 0.9769717454910278, 'epoch': 20.05}
{'loss': 0.0073, 'grad_norm': 4.332089424133301, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.004203565418720245, 'loss_2': 0.00305938720703125, 'loss_3': -16.37777328491211, 'loss_4': 0.9291768670082092, 'epoch': 20.05}
{'loss': 0.0067, 'grad_norm': 4.232753753662109, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.004997987765818834, 'loss_2': 0.0017223358154296875, 'loss_3': -16.623422622680664, 'loss_4': 0.945895791053772, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 16:42:45,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:45,642 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:23<29:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:53,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011805463582277298, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.215, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009114938788115978, 'eval_loss_2': 0.002690523862838745, 'eval_loss_3': -18.25436782836914, 'eval_loss_4': 1.3049473762512207, 'epoch': 20.06}
{'loss': 0.0045, 'grad_norm': 5.018285274505615, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.00376925989985466, 'loss_2': 0.0007009506225585938, 'loss_3': -16.517959594726562, 'loss_4': 1.1492470502853394, 'epoch': 20.06}
{'loss': 0.0119, 'grad_norm': 6.744620323181152, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.00856934767216444, 'loss_2': 0.003353118896484375, 'loss_3': -16.64215660095215, 'loss_4': 1.1307306289672852, 'epoch': 20.07}
{'loss': 0.0145, 'grad_norm': 4.983931541442871, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.006833825260400772, 'loss_2': 0.00765228271484375, 'loss_3': -16.56450080871582, 'loss_4': 1.6603097915649414, 'epoch': 20.08}
{'loss': 0.0083, 'grad_norm': 4.880002021789551, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.007732597645372152, 'loss_2': 0.0005512237548828125, 'loss_3': -16.641468048095703, 'loss_4': 1.0117789506912231, 'epoch': 20.08}
{'loss': 0.0095, 'grad_norm': 5.530046463012695, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.006470284424722195, 'loss_2': 0.00299835205078125, 'loss_3': -16.665706634521484, 'loss_4': 1.075465202331543, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 16:42:53,001 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:53,001 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:31<29:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:00,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011529301293194294, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.746, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008830386213958263, 'eval_loss_2': 0.00269891694188118, 'eval_loss_3': -18.252513885498047, 'eval_loss_4': 1.3146034479141235, 'epoch': 20.09}
{'loss': 0.0087, 'grad_norm': 4.205567836761475, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.004120734520256519, 'loss_2': 0.004547119140625, 'loss_3': -16.634944915771484, 'loss_4': 0.9144476056098938, 'epoch': 20.09}
{'loss': 0.0807, 'grad_norm': 18.648035049438477, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.07201851904392242, 'loss_2': 0.00872039794921875, 'loss_3': -16.572566986083984, 'loss_4': 1.3123178482055664, 'epoch': 20.1}
{'loss': 0.0077, 'grad_norm': 4.7907395362854, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.003834025003015995, 'loss_2': 0.00389862060546875, 'loss_3': -16.50908088684082, 'loss_4': 0.9728421568870544, 'epoch': 20.1}
{'loss': 0.0069, 'grad_norm': 4.435091495513916, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.005046912934631109, 'loss_2': 0.0018444061279296875, 'loss_3': -16.70534896850586, 'loss_4': 1.1105729341506958, 'epoch': 20.11}
{'loss': 0.0063, 'grad_norm': 5.028194427490234, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.005627642385661602, 'loss_2': 0.0007190704345703125, 'loss_3': -16.627729415893555, 'loss_4': 0.5717383623123169, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 16:43:00,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:00,364 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:38<29:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:07,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010360968299210072, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008052711375057697, 'eval_loss_2': 0.0023082569241523743, 'eval_loss_3': -18.263385772705078, 'eval_loss_4': 1.2504469156265259, 'epoch': 20.12}
{'loss': 0.0119, 'grad_norm': 4.711764812469482, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.005689481273293495, 'loss_2': 0.006221771240234375, 'loss_3': -16.590482711791992, 'loss_4': 1.304612398147583, 'epoch': 20.12}
{'loss': 0.0064, 'grad_norm': 5.554499626159668, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.005566488020122051, 'loss_2': 0.000835418701171875, 'loss_3': -16.523136138916016, 'loss_4': 0.8304616212844849, 'epoch': 20.13}
{'loss': 0.0279, 'grad_norm': 5.789520263671875, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.012227032333612442, 'loss_2': 0.01568603515625, 'loss_3': -16.569869995117188, 'loss_4': 1.2959773540496826, 'epoch': 20.13}
{'loss': 0.0102, 'grad_norm': 5.5434441566467285, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.007753182668238878, 'loss_2': 0.0024871826171875, 'loss_3': -16.572277069091797, 'loss_4': 1.0373581647872925, 'epoch': 20.14}
{'loss': 0.0109, 'grad_norm': 5.770580768585205, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.010129797272384167, 'loss_2': 0.000751495361328125, 'loss_3': -16.529447555541992, 'loss_4': 1.2247931957244873, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 16:43:07,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:07,709 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:45<29:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:15,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011861013248562813, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008481668308377266, 'eval_loss_2': 0.003379344940185547, 'eval_loss_3': -18.2515811920166, 'eval_loss_4': 1.2077280282974243, 'epoch': 20.15}
{'loss': 0.007, 'grad_norm': 4.225864410400391, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.002687655622139573, 'loss_2': 0.0043182373046875, 'loss_3': -16.80553436279297, 'loss_4': 0.8805680274963379, 'epoch': 20.15}
{'loss': 0.0091, 'grad_norm': 5.186237335205078, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.005917981266975403, 'loss_2': 0.003185272216796875, 'loss_3': -16.935665130615234, 'loss_4': 0.6879936456680298, 'epoch': 20.16}
{'loss': 0.0156, 'grad_norm': 4.325271129608154, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.004371449816972017, 'loss_2': 0.0112762451171875, 'loss_3': -16.750885009765625, 'loss_4': 1.1677286624908447, 'epoch': 20.16}
{'loss': 0.0157, 'grad_norm': 7.827997207641602, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.014695665799081326, 'loss_2': 0.0009613037109375, 'loss_3': -16.508066177368164, 'loss_4': 0.6618886590003967, 'epoch': 20.17}
{'loss': 0.0156, 'grad_norm': 11.222143173217773, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.012036018073558807, 'loss_2': 0.00351715087890625, 'loss_3': -16.738370895385742, 'loss_4': 0.666968822479248, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 16:43:15,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:15,058 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:53<29:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:22,413 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010796396061778069, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.835, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008025198243558407, 'eval_loss_2': 0.0027711987495422363, 'eval_loss_3': -18.257680892944336, 'eval_loss_4': 1.1941676139831543, 'epoch': 20.17}
{'loss': 0.0225, 'grad_norm': 13.098398208618164, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.02212386392056942, 'loss_2': 0.0004153251647949219, 'loss_3': -16.68701171875, 'loss_4': 1.1609468460083008, 'epoch': 20.18}
{'loss': 0.0073, 'grad_norm': 5.459242820739746, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.0032724475022405386, 'loss_2': 0.00399017333984375, 'loss_3': -16.572235107421875, 'loss_4': 0.9119536876678467, 'epoch': 20.19}
{'loss': 0.0244, 'grad_norm': 11.679380416870117, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.017320282757282257, 'loss_2': 0.00705718994140625, 'loss_3': -16.551237106323242, 'loss_4': 1.1062052249908447, 'epoch': 20.19}
{'loss': 0.0118, 'grad_norm': 6.918455123901367, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.010112844407558441, 'loss_2': 0.0016918182373046875, 'loss_3': -16.490262985229492, 'loss_4': 0.7100728154182434, 'epoch': 20.2}
{'loss': 0.0124, 'grad_norm': 4.451850414276123, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.001954806037247181, 'loss_2': 0.01039886474609375, 'loss_3': -16.712703704833984, 'loss_4': 1.1927764415740967, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 16:43:22,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:22,414 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:26:00<29:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:29,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01112508587539196, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.076, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007414987310767174, 'eval_loss_2': 0.0037100985646247864, 'eval_loss_3': -18.268037796020508, 'eval_loss_4': 1.1982982158660889, 'epoch': 20.2}
{'loss': 0.0115, 'grad_norm': 4.182131767272949, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.00340656447224319, 'loss_2': 0.00811767578125, 'loss_3': -16.66143035888672, 'loss_4': 0.9931023716926575, 'epoch': 20.21}
{'loss': 0.0153, 'grad_norm': 5.5816521644592285, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.007039808202534914, 'loss_2': 0.00827789306640625, 'loss_3': -16.462947845458984, 'loss_4': 0.8795996904373169, 'epoch': 20.22}
{'loss': 0.0161, 'grad_norm': 6.273265838623047, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.0100741321220994, 'loss_2': 0.006008148193359375, 'loss_3': -16.519981384277344, 'loss_4': 0.32088202238082886, 'epoch': 20.22}
{'loss': 0.0225, 'grad_norm': 8.619080543518066, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.014836526475846767, 'loss_2': 0.00768280029296875, 'loss_3': -16.531986236572266, 'loss_4': 0.5529139041900635, 'epoch': 20.23}
{'loss': 0.0082, 'grad_norm': 4.637462615966797, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.004660135600715876, 'loss_2': 0.0034999847412109375, 'loss_3': -16.6133975982666, 'loss_4': 1.2111998796463013, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 16:43:29,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:29,774 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:26:07<29:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:37,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010747663676738739, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007472530007362366, 'eval_loss_2': 0.0032751336693763733, 'eval_loss_3': -18.2613468170166, 'eval_loss_4': 1.2257483005523682, 'epoch': 20.23}
{'loss': 0.0092, 'grad_norm': 5.331652641296387, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.007337994407862425, 'loss_2': 0.0018863677978515625, 'loss_3': -16.58576774597168, 'loss_4': 1.4050942659378052, 'epoch': 20.24}
{'loss': 0.009, 'grad_norm': 5.127717018127441, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.007261304184794426, 'loss_2': 0.0017604827880859375, 'loss_3': -16.519695281982422, 'loss_4': 0.9686985611915588, 'epoch': 20.24}
{'loss': 0.0152, 'grad_norm': 5.400674343109131, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.00786396861076355, 'loss_2': 0.007343292236328125, 'loss_3': -16.585298538208008, 'loss_4': 1.2238109111785889, 'epoch': 20.25}
{'loss': 0.0079, 'grad_norm': 4.659934997558594, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.004913355223834515, 'loss_2': 0.0030040740966796875, 'loss_3': -16.512298583984375, 'loss_4': 0.7673351764678955, 'epoch': 20.26}
{'loss': 0.0047, 'grad_norm': 4.772866249084473, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.004237158223986626, 'loss_2': 0.0005068778991699219, 'loss_3': -16.59905433654785, 'loss_4': 1.130434513092041, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 16:43:37,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:37,137 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:26:15<28:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:44,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010640623047947884, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007442998234182596, 'eval_loss_2': 0.0031976252794265747, 'eval_loss_3': -18.269676208496094, 'eval_loss_4': 1.3222485780715942, 'epoch': 20.26}
{'loss': 0.0067, 'grad_norm': 4.979650497436523, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.00446490989997983, 'loss_2': 0.002185821533203125, 'loss_3': -16.74636459350586, 'loss_4': 1.2535655498504639, 'epoch': 20.27}
{'loss': 0.0112, 'grad_norm': 4.935507774353027, 'learning_rate': 9.75e-06, 'loss_1': 0.004854986909776926, 'loss_2': 0.00630950927734375, 'loss_3': -16.486835479736328, 'loss_4': 0.9492184519767761, 'epoch': 20.27}
{'loss': 0.013, 'grad_norm': 7.831191062927246, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.008992728777229786, 'loss_2': 0.0039825439453125, 'loss_3': -16.80084228515625, 'loss_4': 1.1749801635742188, 'epoch': 20.28}
{'loss': 0.0157, 'grad_norm': 8.283132553100586, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.014491362497210503, 'loss_2': 0.0011682510375976562, 'loss_3': -16.714052200317383, 'loss_4': 1.1315877437591553, 'epoch': 20.28}
{'loss': 0.0103, 'grad_norm': 7.5998430252075195, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.00930548645555973, 'loss_2': 0.0009493827819824219, 'loss_3': -16.69354248046875, 'loss_4': 1.3067716360092163, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 16:43:44,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:44,490 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:22<28:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:51,841 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010319752618670464, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.637, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007329910062253475, 'eval_loss_2': 0.002989843487739563, 'eval_loss_3': -18.271129608154297, 'eval_loss_4': 1.3140316009521484, 'epoch': 20.29}
{'loss': 0.0066, 'grad_norm': 5.230995178222656, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.006153419613838196, 'loss_2': 0.0004038810729980469, 'loss_3': -16.516067504882812, 'loss_4': 0.998375415802002, 'epoch': 20.3}
{'loss': 0.0283, 'grad_norm': 12.961816787719727, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.020645128563046455, 'loss_2': 0.00766754150390625, 'loss_3': -16.65841293334961, 'loss_4': 0.9271169900894165, 'epoch': 20.3}
{'loss': 0.0057, 'grad_norm': 4.580522537231445, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.003412385703995824, 'loss_2': 0.0023040771484375, 'loss_3': -16.524873733520508, 'loss_4': 1.2774051427841187, 'epoch': 20.31}
{'loss': 0.0133, 'grad_norm': 8.173198699951172, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.01316806860268116, 'loss_2': 0.00017333030700683594, 'loss_3': -16.567495346069336, 'loss_4': 1.1690568923950195, 'epoch': 20.31}
{'loss': 0.007, 'grad_norm': 4.768389701843262, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.0028122407384216785, 'loss_2': 0.00421905517578125, 'loss_3': -16.53038787841797, 'loss_4': 1.4445359706878662, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 16:43:51,841 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:51,841 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:30<28:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:59,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011214826256036758, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.488, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007525118999183178, 'eval_loss_2': 0.003689706325531006, 'eval_loss_3': -18.277151107788086, 'eval_loss_4': 1.4213298559188843, 'epoch': 20.32}
{'loss': 0.003, 'grad_norm': 4.585024356842041, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.0029713937547057867, 'loss_2': 4.398822784423828e-05, 'loss_3': -16.56545066833496, 'loss_4': 1.018786907196045, 'epoch': 20.33}
{'loss': 0.013, 'grad_norm': 7.366803169250488, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.01230586413294077, 'loss_2': 0.0006542205810546875, 'loss_3': -16.740678787231445, 'loss_4': 1.5902471542358398, 'epoch': 20.33}
{'loss': 0.0152, 'grad_norm': 8.164297103881836, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.01374729536473751, 'loss_2': 0.0014095306396484375, 'loss_3': -16.772998809814453, 'loss_4': 1.1980390548706055, 'epoch': 20.34}
{'loss': 0.0112, 'grad_norm': 5.053533554077148, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.006502085831016302, 'loss_2': 0.00466156005859375, 'loss_3': -16.733985900878906, 'loss_4': 1.3795335292816162, 'epoch': 20.34}
{'loss': 0.0046, 'grad_norm': 4.246520042419434, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.004197477828711271, 'loss_2': 0.000392913818359375, 'loss_3': -16.523435592651367, 'loss_4': 1.0556695461273193, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 16:43:59,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:59,199 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:37<28:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:06,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011476777493953705, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.591, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007894926704466343, 'eval_loss_2': 0.0035818517208099365, 'eval_loss_3': -18.275869369506836, 'eval_loss_4': 1.4720377922058105, 'epoch': 20.35}
{'loss': 0.0499, 'grad_norm': 19.898536682128906, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.04970063269138336, 'loss_2': 0.0002231597900390625, 'loss_3': -16.73573875427246, 'loss_4': 1.1531603336334229, 'epoch': 20.35}
{'loss': 0.0337, 'grad_norm': 19.80135154724121, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.03266998380422592, 'loss_2': 0.001003265380859375, 'loss_3': -16.70366096496582, 'loss_4': 1.2965362071990967, 'epoch': 20.36}
{'loss': 0.0185, 'grad_norm': 6.355204105377197, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.010942084714770317, 'loss_2': 0.007537841796875, 'loss_3': -16.67125701904297, 'loss_4': 1.7673578262329102, 'epoch': 20.37}
{'loss': 0.0114, 'grad_norm': 6.9031758308410645, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.007809159811586142, 'loss_2': 0.003551483154296875, 'loss_3': -16.45646858215332, 'loss_4': 1.2628729343414307, 'epoch': 20.37}
{'loss': 0.02, 'grad_norm': 5.671647548675537, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.0075147137977182865, 'loss_2': 0.01250457763671875, 'loss_3': -16.523120880126953, 'loss_4': 0.7838754057884216, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 16:44:06,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:06,559 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:44<28:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:13,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012532231397926807, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.925, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008941467851400375, 'eval_loss_2': 0.0035907626152038574, 'eval_loss_3': -18.288480758666992, 'eval_loss_4': 1.5077931880950928, 'epoch': 20.38}
{'loss': 0.0099, 'grad_norm': 4.707557678222656, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.007737583480775356, 'loss_2': 0.002140045166015625, 'loss_3': -16.457162857055664, 'loss_4': 1.9922374486923218, 'epoch': 20.38}
{'loss': 0.0085, 'grad_norm': 5.001962661743164, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.0044320933520793915, 'loss_2': 0.004058837890625, 'loss_3': -16.646759033203125, 'loss_4': 1.2936947345733643, 'epoch': 20.39}
{'loss': 0.0145, 'grad_norm': 9.202292442321777, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.012200532481074333, 'loss_2': 0.002338409423828125, 'loss_3': -16.653888702392578, 'loss_4': 1.4233468770980835, 'epoch': 20.4}
{'loss': 0.0057, 'grad_norm': 5.204686164855957, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.005465574096888304, 'loss_2': 0.0002689361572265625, 'loss_3': -16.680192947387695, 'loss_4': 1.3150279521942139, 'epoch': 20.4}
{'loss': 0.0041, 'grad_norm': 5.62246036529541, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.0038132721092551947, 'loss_2': 0.000335693359375, 'loss_3': -16.713542938232422, 'loss_4': 1.575392484664917, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 16:44:13,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:13,925 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:52<28:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:21,281 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010537391528487206, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008206641301512718, 'eval_loss_2': 0.0023307502269744873, 'eval_loss_3': -18.310733795166016, 'eval_loss_4': 1.5385417938232422, 'epoch': 20.41}
{'loss': 0.0216, 'grad_norm': 8.302163124084473, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.016569705680012703, 'loss_2': 0.005039215087890625, 'loss_3': -16.693899154663086, 'loss_4': 1.8234522342681885, 'epoch': 20.41}
{'loss': 0.008, 'grad_norm': 4.6337809562683105, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.004759038332849741, 'loss_2': 0.0032501220703125, 'loss_3': -16.621490478515625, 'loss_4': 1.3582398891448975, 'epoch': 20.42}
{'loss': 0.0119, 'grad_norm': 5.921428680419922, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.009739246219396591, 'loss_2': 0.00220489501953125, 'loss_3': -16.76081085205078, 'loss_4': 1.6041817665100098, 'epoch': 20.42}
{'loss': 0.0083, 'grad_norm': 5.019206523895264, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.006616802420467138, 'loss_2': 0.001636505126953125, 'loss_3': -16.45798110961914, 'loss_4': 1.7076513767242432, 'epoch': 20.43}
{'loss': 0.0109, 'grad_norm': 7.678067207336426, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.009674221277236938, 'loss_2': 0.0011959075927734375, 'loss_3': -16.616455078125, 'loss_4': 1.4495617151260376, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 16:44:21,281 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:21,281 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:59<28:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:28,638 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010409621521830559, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.408, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007630696054548025, 'eval_loss_2': 0.0027789250016212463, 'eval_loss_3': -18.294649124145508, 'eval_loss_4': 1.5961084365844727, 'epoch': 20.44}
{'loss': 0.0209, 'grad_norm': 9.94697380065918, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.015504136681556702, 'loss_2': 0.00537872314453125, 'loss_3': -16.74660873413086, 'loss_4': 1.5407806634902954, 'epoch': 20.44}
{'loss': 0.0123, 'grad_norm': 5.699099540710449, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.007666357792913914, 'loss_2': 0.00460052490234375, 'loss_3': -16.671695709228516, 'loss_4': 1.331744909286499, 'epoch': 20.45}
{'loss': 0.0053, 'grad_norm': 4.586867809295654, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.004177973140031099, 'loss_2': 0.0011243820190429688, 'loss_3': -16.757328033447266, 'loss_4': 1.8210493326187134, 'epoch': 20.45}
{'loss': 0.0177, 'grad_norm': 9.150514602661133, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.015567120164632797, 'loss_2': 0.002155303955078125, 'loss_3': -16.90281105041504, 'loss_4': 1.1904797554016113, 'epoch': 20.46}
{'loss': 0.0071, 'grad_norm': 6.038999557495117, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.005558688193559647, 'loss_2': 0.0014934539794921875, 'loss_3': -16.652036666870117, 'loss_4': 1.5493733882904053, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 16:44:28,638 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:28,638 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:27:06<28:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:35,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010815135203301907, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.357, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007407314144074917, 'eval_loss_2': 0.0034078210592269897, 'eval_loss_3': -18.285308837890625, 'eval_loss_4': 1.5952166318893433, 'epoch': 20.47}
{'loss': 0.0119, 'grad_norm': 4.7945356369018555, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.006419757846742868, 'loss_2': 0.00547027587890625, 'loss_3': -16.255584716796875, 'loss_4': 1.9075886011123657, 'epoch': 20.47}
{'loss': 0.0085, 'grad_norm': 4.425414085388184, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.007676858454942703, 'loss_2': 0.00080108642578125, 'loss_3': -16.701101303100586, 'loss_4': 1.9173893928527832, 'epoch': 20.48}
{'loss': 0.0721, 'grad_norm': 15.691932678222656, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.07136362046003342, 'loss_2': 0.0007185935974121094, 'loss_3': -16.805923461914062, 'loss_4': 1.8365261554718018, 'epoch': 20.48}
{'loss': 0.0101, 'grad_norm': 5.797029495239258, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.006581162568181753, 'loss_2': 0.003551483154296875, 'loss_3': -16.62972068786621, 'loss_4': 1.3545655012130737, 'epoch': 20.49}
{'loss': 0.0122, 'grad_norm': 5.044364929199219, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.0038982888218015432, 'loss_2': 0.0083465576171875, 'loss_3': -16.698406219482422, 'loss_4': 1.6582139730453491, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 16:44:35,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:35,994 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:27:14<28:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:43,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011359996162354946, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.342, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008393329568207264, 'eval_loss_2': 0.002966664731502533, 'eval_loss_3': -18.27118682861328, 'eval_loss_4': 1.5310367345809937, 'epoch': 20.49}
{'loss': 0.0082, 'grad_norm': 5.2155442237854, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.0026940233074128628, 'loss_2': 0.0055389404296875, 'loss_3': -16.66367530822754, 'loss_4': 1.2189512252807617, 'epoch': 20.5}
{'loss': 0.0097, 'grad_norm': 5.232174873352051, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.0064550102688372135, 'loss_2': 0.003269195556640625, 'loss_3': -16.551816940307617, 'loss_4': 1.3188774585723877, 'epoch': 20.51}
{'loss': 0.0085, 'grad_norm': 5.797211647033691, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.006540011148899794, 'loss_2': 0.0019121170043945312, 'loss_3': -16.497587203979492, 'loss_4': 1.2756948471069336, 'epoch': 20.51}
{'loss': 0.0054, 'grad_norm': 4.6364946365356445, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.0038134658243507147, 'loss_2': 0.001544952392578125, 'loss_3': -16.560415267944336, 'loss_4': 1.4045186042785645, 'epoch': 20.52}
{'loss': 0.033, 'grad_norm': 9.080116271972656, 'learning_rate': 9.5e-06, 'loss_1': 0.023780301213264465, 'loss_2': 0.00920867919921875, 'loss_3': -16.672191619873047, 'loss_4': 1.8385741710662842, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 16:44:43,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:43,353 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:21<28:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:50,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010537722148001194, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.185, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0071188583970069885, 'eval_loss_2': 0.003418862819671631, 'eval_loss_3': -18.276081085205078, 'eval_loss_4': 1.5132386684417725, 'epoch': 20.52}
{'loss': 0.0149, 'grad_norm': 8.294204711914062, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.009647115133702755, 'loss_2': 0.0052490234375, 'loss_3': -16.644121170043945, 'loss_4': 1.4869450330734253, 'epoch': 20.53}
{'loss': 0.0056, 'grad_norm': 5.4119873046875, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.004328569397330284, 'loss_2': 0.0013103485107421875, 'loss_3': -16.5609188079834, 'loss_4': 1.3291382789611816, 'epoch': 20.53}
{'loss': 0.0066, 'grad_norm': 4.9673686027526855, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.004456765949726105, 'loss_2': 0.0021343231201171875, 'loss_3': -16.601465225219727, 'loss_4': 1.6201941967010498, 'epoch': 20.54}
{'loss': 0.0141, 'grad_norm': 8.119668006896973, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.01308298110961914, 'loss_2': 0.0010023117065429688, 'loss_3': -16.480043411254883, 'loss_4': 1.4328123331069946, 'epoch': 20.55}
{'loss': 0.0196, 'grad_norm': 8.380072593688965, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.013896213844418526, 'loss_2': 0.00566864013671875, 'loss_3': -16.465574264526367, 'loss_4': 1.325047492980957, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 16:44:50,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:50,708 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:28<28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:58,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010263742879033089, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006917999126017094, 'eval_loss_2': 0.0033457428216934204, 'eval_loss_3': -18.279953002929688, 'eval_loss_4': 1.4718148708343506, 'epoch': 20.55}
{'loss': 0.0142, 'grad_norm': 4.743073463439941, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.005535688251256943, 'loss_2': 0.0086517333984375, 'loss_3': -16.47062873840332, 'loss_4': 1.3337204456329346, 'epoch': 20.56}
{'loss': 0.0088, 'grad_norm': 5.402993679046631, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.007164699956774712, 'loss_2': 0.001613616943359375, 'loss_3': -16.628005981445312, 'loss_4': 0.8245089054107666, 'epoch': 20.56}
{'loss': 0.0185, 'grad_norm': 7.664999008178711, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.014992055483162403, 'loss_2': 0.003467559814453125, 'loss_3': -16.451398849487305, 'loss_4': 1.1159555912017822, 'epoch': 20.57}
{'loss': 0.0122, 'grad_norm': 5.204351425170898, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.0045146518386900425, 'loss_2': 0.00765228271484375, 'loss_3': -16.52931785583496, 'loss_4': 1.3930187225341797, 'epoch': 20.58}
{'loss': 0.0059, 'grad_norm': 4.804808139801025, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.004770511295646429, 'loss_2': 0.0011663436889648438, 'loss_3': -16.54929542541504, 'loss_4': 1.745115041732788, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 16:44:58,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:58,077 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:36<28:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:05,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009427491575479507, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.449, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006229598540812731, 'eval_loss_2': 0.003197893500328064, 'eval_loss_3': -18.27679443359375, 'eval_loss_4': 1.4044241905212402, 'epoch': 20.58}
{'loss': 0.0139, 'grad_norm': 5.715605735778809, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.008858073502779007, 'loss_2': 0.0050201416015625, 'loss_3': -16.675933837890625, 'loss_4': 1.3426252603530884, 'epoch': 20.59}
{'loss': 0.0112, 'grad_norm': 4.915956974029541, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.004198095761239529, 'loss_2': 0.00701141357421875, 'loss_3': -16.56867218017578, 'loss_4': 1.2897999286651611, 'epoch': 20.59}
{'loss': 0.014, 'grad_norm': 4.823455333709717, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.006526782643049955, 'loss_2': 0.0074920654296875, 'loss_3': -16.496356964111328, 'loss_4': 1.9499781131744385, 'epoch': 20.6}
{'loss': 0.0079, 'grad_norm': 4.873104095458984, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.00327209010720253, 'loss_2': 0.00464630126953125, 'loss_3': -16.454891204833984, 'loss_4': 1.2279471158981323, 'epoch': 20.6}
{'loss': 0.0728, 'grad_norm': 12.988130569458008, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.06692367792129517, 'loss_2': 0.0058746337890625, 'loss_3': -16.722143173217773, 'loss_4': 1.7732758522033691, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 16:45:05,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:05,434 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:43<27:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:12,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010793116874992847, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.83, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.006847170181572437, 'eval_loss_2': 0.00394594669342041, 'eval_loss_3': -18.27304458618164, 'eval_loss_4': 1.30217444896698, 'epoch': 20.61}
{'loss': 0.0148, 'grad_norm': 11.292314529418945, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.011935215443372726, 'loss_2': 0.0028934478759765625, 'loss_3': -16.556072235107422, 'loss_4': 1.368883728981018, 'epoch': 20.62}
{'loss': 0.0118, 'grad_norm': 5.21889066696167, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.006097238976508379, 'loss_2': 0.0056610107421875, 'loss_3': -16.51605987548828, 'loss_4': 1.2084059715270996, 'epoch': 20.62}
{'loss': 0.011, 'grad_norm': 8.174809455871582, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.010755842551589012, 'loss_2': 0.00024020671844482422, 'loss_3': -16.576419830322266, 'loss_4': 0.7417142391204834, 'epoch': 20.63}
{'loss': 0.0082, 'grad_norm': 5.011409282684326, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.0045578135177493095, 'loss_2': 0.0036468505859375, 'loss_3': -16.636516571044922, 'loss_4': 0.8600929975509644, 'epoch': 20.63}
{'loss': 0.0134, 'grad_norm': 5.102207660675049, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.005764254834502935, 'loss_2': 0.007595062255859375, 'loss_3': -16.33643341064453, 'loss_4': 1.039416790008545, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 16:45:12,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:12,783 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:50<27:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:20,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010108652524650097, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.393, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00764049869030714, 'eval_loss_2': 0.0024681538343429565, 'eval_loss_3': -18.27414894104004, 'eval_loss_4': 1.1603368520736694, 'epoch': 20.64}
{'loss': 0.0036, 'grad_norm': 4.493930339813232, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.00328264944255352, 'loss_2': 0.0002987384796142578, 'loss_3': -16.417821884155273, 'loss_4': 1.2066761255264282, 'epoch': 20.65}
{'loss': 0.0192, 'grad_norm': 16.835086822509766, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.015312508679926395, 'loss_2': 0.00392913818359375, 'loss_3': -16.60006332397461, 'loss_4': 1.642876148223877, 'epoch': 20.65}
{'loss': 0.0161, 'grad_norm': 4.985808849334717, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.010258815251290798, 'loss_2': 0.005859375, 'loss_3': -16.617422103881836, 'loss_4': 1.1055512428283691, 'epoch': 20.66}
{'loss': 0.0135, 'grad_norm': 6.035220146179199, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.006840015295892954, 'loss_2': 0.00664520263671875, 'loss_3': -16.555740356445312, 'loss_4': 0.7138856649398804, 'epoch': 20.66}
{'loss': 0.0138, 'grad_norm': 4.816357612609863, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.004427175037562847, 'loss_2': 0.00934600830078125, 'loss_3': -16.592769622802734, 'loss_4': 1.188001036643982, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 16:45:20,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:20,136 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:58<27:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:27,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014438070356845856, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.592, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008019722066819668, 'eval_loss_2': 0.006418347358703613, 'eval_loss_3': -18.257349014282227, 'eval_loss_4': 1.0735105276107788, 'epoch': 20.67}
{'loss': 0.0113, 'grad_norm': 5.29289436340332, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.005766136106103659, 'loss_2': 0.00554656982421875, 'loss_3': -16.48696517944336, 'loss_4': 0.9652919769287109, 'epoch': 20.67}
{'loss': 0.0192, 'grad_norm': 4.981921195983887, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.003822814440354705, 'loss_2': 0.0153961181640625, 'loss_3': -16.596933364868164, 'loss_4': 0.8569090366363525, 'epoch': 20.68}
{'loss': 0.0219, 'grad_norm': 6.174236297607422, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.007501072250306606, 'loss_2': 0.0143890380859375, 'loss_3': -16.569244384765625, 'loss_4': 0.9230384826660156, 'epoch': 20.69}
{'loss': 0.0169, 'grad_norm': 4.53146505355835, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.004888610914349556, 'loss_2': 0.0119781494140625, 'loss_3': -16.623699188232422, 'loss_4': 0.848182201385498, 'epoch': 20.69}
{'loss': 0.013, 'grad_norm': 4.927496910095215, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.008523531258106232, 'loss_2': 0.00450897216796875, 'loss_3': -16.660327911376953, 'loss_4': 1.431208848953247, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 16:45:27,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:27,493 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:28:05<27:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:34,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014649081975221634, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.769, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007914591580629349, 'eval_loss_2': 0.006734490394592285, 'eval_loss_3': -18.262332916259766, 'eval_loss_4': 1.0583930015563965, 'epoch': 20.7}
{'loss': 0.0079, 'grad_norm': 5.246633052825928, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.0061258780770003796, 'loss_2': 0.001739501953125, 'loss_3': -16.43951416015625, 'loss_4': 1.073304533958435, 'epoch': 20.7}
{'loss': 0.0105, 'grad_norm': 4.714868068695068, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.007391499821096659, 'loss_2': 0.003108978271484375, 'loss_3': -16.659502029418945, 'loss_4': 1.4890344142913818, 'epoch': 20.71}
{'loss': 0.0173, 'grad_norm': 6.691154479980469, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.00853658840060234, 'loss_2': 0.00872039794921875, 'loss_3': -16.615842819213867, 'loss_4': 1.469481110572815, 'epoch': 20.72}
{'loss': 0.0126, 'grad_norm': 5.973838806152344, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.006167435087263584, 'loss_2': 0.006404876708984375, 'loss_3': -16.630338668823242, 'loss_4': 0.7781396508216858, 'epoch': 20.72}
{'loss': 0.0155, 'grad_norm': 7.9605937004089355, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.01116250455379486, 'loss_2': 0.004306793212890625, 'loss_3': -16.52777099609375, 'loss_4': 1.0153690576553345, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 16:45:34,859 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:34,859 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:28:13<27:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:42,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011289212852716446, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.43, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00830006878823042, 'eval_loss_2': 0.002989143133163452, 'eval_loss_3': -18.249282836914062, 'eval_loss_4': 0.9914257526397705, 'epoch': 20.73}
{'loss': 0.0123, 'grad_norm': 6.6046929359436035, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.011135532520711422, 'loss_2': 0.0011615753173828125, 'loss_3': -16.62653923034668, 'loss_4': 1.0471296310424805, 'epoch': 20.73}
{'loss': 0.007, 'grad_norm': 4.238998889923096, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.002737663220614195, 'loss_2': 0.00421905517578125, 'loss_3': -16.728410720825195, 'loss_4': 0.7275524139404297, 'epoch': 20.74}
{'loss': 0.006, 'grad_norm': 4.900420188903809, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.0056466516107320786, 'loss_2': 0.00032711029052734375, 'loss_3': -16.530460357666016, 'loss_4': 0.7142617702484131, 'epoch': 20.74}
{'loss': 0.0055, 'grad_norm': 5.048535346984863, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.002914146054536104, 'loss_2': 0.0025482177734375, 'loss_3': -16.656190872192383, 'loss_4': 1.0079573392868042, 'epoch': 20.75}
{'loss': 0.0055, 'grad_norm': 5.430520534515381, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.004885646514594555, 'loss_2': 0.00066375732421875, 'loss_3': -16.54475212097168, 'loss_4': 1.210900902748108, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 16:45:42,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:42,217 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:20<27:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:49,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011051150038838387, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008084448985755444, 'eval_loss_2': 0.0029667019844055176, 'eval_loss_3': -18.244510650634766, 'eval_loss_4': 0.8908793926239014, 'epoch': 20.76}
{'loss': 0.0122, 'grad_norm': 5.138766288757324, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.009278040379285812, 'loss_2': 0.002872467041015625, 'loss_3': -16.419795989990234, 'loss_4': 0.8072835803031921, 'epoch': 20.76}
{'loss': 0.0048, 'grad_norm': 5.1132707595825195, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.0030681276693940163, 'loss_2': 0.0017642974853515625, 'loss_3': -16.684324264526367, 'loss_4': 0.839439868927002, 'epoch': 20.77}
{'loss': 0.0094, 'grad_norm': 5.276071071624756, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.006321525666862726, 'loss_2': 0.003032684326171875, 'loss_3': -16.743289947509766, 'loss_4': 0.9514319896697998, 'epoch': 20.77}
{'loss': 0.0059, 'grad_norm': 4.943869113922119, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.004883365239948034, 'loss_2': 0.0010223388671875, 'loss_3': -16.441709518432617, 'loss_4': 0.7540496587753296, 'epoch': 20.78}
{'loss': 0.006, 'grad_norm': 4.675045013427734, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.0035714227706193924, 'loss_2': 0.002437591552734375, 'loss_3': -16.525299072265625, 'loss_4': 0.9930934309959412, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 16:45:49,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:49,572 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:27<27:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:56,922 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010927067138254642, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.407, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007817137986421585, 'eval_loss_2': 0.003109928220510483, 'eval_loss_3': -18.250537872314453, 'eval_loss_4': 0.786151647567749, 'epoch': 20.78}
{'loss': 0.01, 'grad_norm': 4.459378242492676, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.004097107332199812, 'loss_2': 0.005950927734375, 'loss_3': -16.546546936035156, 'loss_4': 0.7919228076934814, 'epoch': 20.79}
{'loss': 0.0064, 'grad_norm': 5.101419448852539, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.004987696651369333, 'loss_2': 0.0013818740844726562, 'loss_3': -16.73932456970215, 'loss_4': 0.982169508934021, 'epoch': 20.8}
{'loss': 0.008, 'grad_norm': 4.535172462463379, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.004090097267180681, 'loss_2': 0.00391387939453125, 'loss_3': -16.72797966003418, 'loss_4': 0.5623733997344971, 'epoch': 20.8}
{'loss': 0.0163, 'grad_norm': 7.502146244049072, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.013395069167017937, 'loss_2': 0.00292205810546875, 'loss_3': -16.572677612304688, 'loss_4': 0.523638904094696, 'epoch': 20.81}
{'loss': 0.0119, 'grad_norm': 7.60703182220459, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.00946230348199606, 'loss_2': 0.0023975372314453125, 'loss_3': -16.681346893310547, 'loss_4': 0.667965292930603, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 16:45:56,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:56,922 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:35<27:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:04,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009796910919249058, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.473, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007011481560766697, 'eval_loss_2': 0.002785429358482361, 'eval_loss_3': -18.25765609741211, 'eval_loss_4': 0.6942390203475952, 'epoch': 20.81}
{'loss': 0.0077, 'grad_norm': 4.505070209503174, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.003830208443105221, 'loss_2': 0.003887176513671875, 'loss_3': -16.56825828552246, 'loss_4': 0.7072693109512329, 'epoch': 20.82}
{'loss': 0.0049, 'grad_norm': 4.261889934539795, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.004325937479734421, 'loss_2': 0.0005426406860351562, 'loss_3': -16.563505172729492, 'loss_4': 0.7950232028961182, 'epoch': 20.83}
{'loss': 0.01, 'grad_norm': 5.0553812980651855, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.007488182745873928, 'loss_2': 0.002529144287109375, 'loss_3': -16.6138973236084, 'loss_4': 0.6082079410552979, 'epoch': 20.83}
{'loss': 0.0124, 'grad_norm': 4.795506477355957, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.0040199607610702515, 'loss_2': 0.0084075927734375, 'loss_3': -16.76974105834961, 'loss_4': 0.6509774923324585, 'epoch': 20.84}
{'loss': 0.0094, 'grad_norm': 5.300384521484375, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.006088541820645332, 'loss_2': 0.003330230712890625, 'loss_3': -16.628562927246094, 'loss_4': 0.6246818900108337, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 16:46:04,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:04,268 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:42<27:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:11,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011292366310954094, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.995, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007861152291297913, 'eval_loss_2': 0.0034312158823013306, 'eval_loss_3': -18.261125564575195, 'eval_loss_4': 0.6247228384017944, 'epoch': 20.84}
{'loss': 0.0077, 'grad_norm': 4.623571872711182, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.005595088936388493, 'loss_2': 0.00206756591796875, 'loss_3': -16.82082748413086, 'loss_4': 1.113865613937378, 'epoch': 20.85}
{'loss': 0.0178, 'grad_norm': 5.923018932342529, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.01509585790336132, 'loss_2': 0.002716064453125, 'loss_3': -16.677404403686523, 'loss_4': 0.43375083804130554, 'epoch': 20.85}
{'loss': 0.0085, 'grad_norm': 4.13676643371582, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.003672915045171976, 'loss_2': 0.00482177734375, 'loss_3': -16.881065368652344, 'loss_4': 0.5112963318824768, 'epoch': 20.86}
{'loss': 0.0064, 'grad_norm': 4.530500411987305, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.00556880421936512, 'loss_2': 0.0008630752563476562, 'loss_3': -16.958553314208984, 'loss_4': 0.5286396145820618, 'epoch': 20.87}
{'loss': 0.0121, 'grad_norm': 4.858057498931885, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.007089280057698488, 'loss_2': 0.005046844482421875, 'loss_3': -16.773120880126953, 'loss_4': 0.6201932430267334, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 16:46:11,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:11,629 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:49<27:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:18,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011026188731193542, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.268, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00792597234249115, 'eval_loss_2': 0.0031002163887023926, 'eval_loss_3': -18.26787757873535, 'eval_loss_4': 0.6133512258529663, 'epoch': 20.87}
{'loss': 0.0104, 'grad_norm': 5.529958724975586, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.010028749704360962, 'loss_2': 0.0004038810729980469, 'loss_3': -16.607257843017578, 'loss_4': 0.3557717800140381, 'epoch': 20.88}
{'loss': 0.0159, 'grad_norm': 6.067831516265869, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.01572219282388687, 'loss_2': 0.00013697147369384766, 'loss_3': -16.6368408203125, 'loss_4': 0.478705495595932, 'epoch': 20.88}
{'loss': 0.0193, 'grad_norm': 7.20915412902832, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.012178465723991394, 'loss_2': 0.00707244873046875, 'loss_3': -16.628097534179688, 'loss_4': 0.6696709990501404, 'epoch': 20.89}
{'loss': 0.0186, 'grad_norm': 9.715797424316406, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.013236810453236103, 'loss_2': 0.00537872314453125, 'loss_3': -16.56867218017578, 'loss_4': 0.5743170380592346, 'epoch': 20.9}
{'loss': 0.0129, 'grad_norm': 4.685990333557129, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.005899511277675629, 'loss_2': 0.00698089599609375, 'loss_3': -16.82823944091797, 'loss_4': 0.5851662158966064, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 16:46:18,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:18,980 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:57<27:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:26,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011737324297428131, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.359, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007808484602719545, 'eval_loss_2': 0.003928840160369873, 'eval_loss_3': -18.26582908630371, 'eval_loss_4': 0.6240670084953308, 'epoch': 20.9}
{'loss': 0.0103, 'grad_norm': 5.4756388664245605, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.009578597731888294, 'loss_2': 0.0006728172302246094, 'loss_3': -16.719560623168945, 'loss_4': 0.853178083896637, 'epoch': 20.91}
{'loss': 0.0077, 'grad_norm': 4.908149242401123, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.004933472722768784, 'loss_2': 0.0028076171875, 'loss_3': -16.78370475769043, 'loss_4': 0.6899794340133667, 'epoch': 20.91}
{'loss': 0.0099, 'grad_norm': 4.831150531768799, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.007550335489213467, 'loss_2': 0.00237274169921875, 'loss_3': -16.88071060180664, 'loss_4': 0.5359102487564087, 'epoch': 20.92}
{'loss': 0.0162, 'grad_norm': 5.481106758117676, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.009224404580891132, 'loss_2': 0.0069732666015625, 'loss_3': -16.697341918945312, 'loss_4': 0.49838873744010925, 'epoch': 20.92}
{'loss': 0.0172, 'grad_norm': 7.7075371742248535, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.015780000016093254, 'loss_2': 0.001415252685546875, 'loss_3': -16.755802154541016, 'loss_4': 0.9300826787948608, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 16:46:26,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:26,338 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:29:04<26:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:33,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01215122640132904, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007771000266075134, 'eval_loss_2': 0.004380226135253906, 'eval_loss_3': -18.26849365234375, 'eval_loss_4': 0.6532838344573975, 'epoch': 20.93}
{'loss': 0.0151, 'grad_norm': 4.800961494445801, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.0059277815744280815, 'loss_2': 0.009185791015625, 'loss_3': -16.783042907714844, 'loss_4': 0.21739020943641663, 'epoch': 20.94}
{'loss': 0.0055, 'grad_norm': 4.880062103271484, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.004048261325806379, 'loss_2': 0.001483917236328125, 'loss_3': -16.65938377380371, 'loss_4': 0.645121157169342, 'epoch': 20.94}
{'loss': 0.0059, 'grad_norm': 5.092016220092773, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.00558383809402585, 'loss_2': 0.00033855438232421875, 'loss_3': -16.716522216796875, 'loss_4': 0.7730237245559692, 'epoch': 20.95}
{'loss': 0.0089, 'grad_norm': 4.288192272186279, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.0036957638803869486, 'loss_2': 0.005218505859375, 'loss_3': -16.76736068725586, 'loss_4': 1.2396395206451416, 'epoch': 20.95}
{'loss': 0.0174, 'grad_norm': 5.160849571228027, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.010527613572776318, 'loss_2': 0.0068511962890625, 'loss_3': -16.475414276123047, 'loss_4': 0.5064750909805298, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 16:46:33,685 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:33,685 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:29:11<26:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:41,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010068610310554504, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006811540108174086, 'eval_loss_2': 0.0032570697367191315, 'eval_loss_3': -18.27727699279785, 'eval_loss_4': 0.7136347889900208, 'epoch': 20.96}
{'loss': 0.0174, 'grad_norm': 13.941629409790039, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.013518745079636574, 'loss_2': 0.003856658935546875, 'loss_3': -16.699905395507812, 'loss_4': 1.0554935932159424, 'epoch': 20.97}
{'loss': 0.0113, 'grad_norm': 5.577580451965332, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.010028751567006111, 'loss_2': 0.0012874603271484375, 'loss_3': -16.69139862060547, 'loss_4': 0.7627710700035095, 'epoch': 20.97}
{'loss': 0.0123, 'grad_norm': 5.323150157928467, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.006761890836060047, 'loss_2': 0.00556182861328125, 'loss_3': -16.668437957763672, 'loss_4': 0.668529748916626, 'epoch': 20.98}
{'loss': 0.0088, 'grad_norm': 4.946623802185059, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.007111983839422464, 'loss_2': 0.0016460418701171875, 'loss_3': -16.504291534423828, 'loss_4': 0.5128080248832703, 'epoch': 20.98}
{'loss': 0.0141, 'grad_norm': 6.199059009552002, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.010359784588217735, 'loss_2': 0.003765106201171875, 'loss_3': -16.579143524169922, 'loss_4': 0.4983910322189331, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 16:46:41,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:41,035 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:18<25:59,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:46:48,074 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009622152894735336, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.324, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006331693846732378, 'eval_loss_2': 0.0032904595136642456, 'eval_loss_3': -18.299827575683594, 'eval_loss_4': 0.7688481211662292, 'epoch': 20.99}
{'loss': 0.015, 'grad_norm': 8.26041030883789, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.010997318662703037, 'loss_2': 0.003963470458984375, 'loss_3': -16.699504852294922, 'loss_4': 0.874851644039154, 'epoch': 20.99}
{'loss': 0.0065, 'grad_norm': 6.581302642822266, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.0023462981916964054, 'loss_2': 0.0041656494140625, 'loss_3': -16.91923713684082, 'loss_4': 0.5473043918609619, 'epoch': 21.0}
{'loss': 0.0088, 'grad_norm': 5.167418956756592, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.005306467413902283, 'loss_2': 0.003528594970703125, 'loss_3': -16.70697021484375, 'loss_4': 0.9763212203979492, 'epoch': 21.01}
{'loss': 0.0071, 'grad_norm': 4.7695441246032715, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.005038883071392775, 'loss_2': 0.002094268798828125, 'loss_3': -16.506629943847656, 'loss_4': 0.9581210017204285, 'epoch': 21.01}
{'loss': 0.0092, 'grad_norm': 4.521603107452393, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.005883349571377039, 'loss_2': 0.003345489501953125, 'loss_3': -16.786808013916016, 'loss_4': 1.060335636138916, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 16:46:48,074 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:48,074 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:26<26:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:55,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010602163150906563, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.575, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006776022259145975, 'eval_loss_2': 0.003826141357421875, 'eval_loss_3': -18.281269073486328, 'eval_loss_4': 0.8989381790161133, 'epoch': 21.02}
{'loss': 0.0181, 'grad_norm': 12.643773078918457, 'learning_rate': 9e-06, 'loss_1': 0.015275375917553902, 'loss_2': 0.002796173095703125, 'loss_3': -16.49634552001953, 'loss_4': 0.9019225835800171, 'epoch': 21.02}
{'loss': 0.0248, 'grad_norm': 20.65743637084961, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.020579146221280098, 'loss_2': 0.004261016845703125, 'loss_3': -16.633480072021484, 'loss_4': 0.3607500195503235, 'epoch': 21.03}
{'loss': 0.0127, 'grad_norm': 4.688638687133789, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.0038157468661665916, 'loss_2': 0.008880615234375, 'loss_3': -16.546733856201172, 'loss_4': 1.1197528839111328, 'epoch': 21.03}
{'loss': 0.0144, 'grad_norm': 4.803693771362305, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.005220711696892977, 'loss_2': 0.0091705322265625, 'loss_3': -16.58277130126953, 'loss_4': 1.0530034303665161, 'epoch': 21.04}
{'loss': 0.015, 'grad_norm': 7.262115955352783, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.01443782914429903, 'loss_2': 0.0005125999450683594, 'loss_3': -16.693546295166016, 'loss_4': 0.44637829065322876, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 16:46:55,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:55,442 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:33<26:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:02,794 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00989161804318428, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0059807198122143745, 'eval_loss_2': 0.0039108991622924805, 'eval_loss_3': -18.279796600341797, 'eval_loss_4': 0.999686598777771, 'epoch': 21.05}
{'loss': 0.0169, 'grad_norm': 5.32408332824707, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.008401467464864254, 'loss_2': 0.0084686279296875, 'loss_3': -16.638626098632812, 'loss_4': 1.1443238258361816, 'epoch': 21.05}
{'loss': 0.014, 'grad_norm': 5.798623561859131, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.009017198346555233, 'loss_2': 0.004962921142578125, 'loss_3': -16.580190658569336, 'loss_4': 0.4905649423599243, 'epoch': 21.06}
{'loss': 0.0093, 'grad_norm': 5.451161861419678, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.008150754496455193, 'loss_2': 0.001178741455078125, 'loss_3': -16.64710807800293, 'loss_4': 1.4446260929107666, 'epoch': 21.06}
{'loss': 0.0101, 'grad_norm': 4.735063076019287, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.004616701044142246, 'loss_2': 0.005462646484375, 'loss_3': -16.714845657348633, 'loss_4': 1.261742115020752, 'epoch': 21.07}
{'loss': 0.0091, 'grad_norm': 4.414754390716553, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.0029409073758870363, 'loss_2': 0.006206512451171875, 'loss_3': -16.758159637451172, 'loss_4': 1.4896578788757324, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 16:47:02,794 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:02,795 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:40<26:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:10,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009406762197613716, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.62, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00557288620620966, 'eval_loss_2': 0.003833875060081482, 'eval_loss_3': -18.266529083251953, 'eval_loss_4': 1.0623183250427246, 'epoch': 21.08}
{'loss': 0.0115, 'grad_norm': 7.333319664001465, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.00842572096735239, 'loss_2': 0.003040313720703125, 'loss_3': -16.467876434326172, 'loss_4': 0.6163815855979919, 'epoch': 21.08}
{'loss': 0.0072, 'grad_norm': 5.1841278076171875, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.0071297334507107735, 'loss_2': 5.501508712768555e-05, 'loss_3': -16.6438045501709, 'loss_4': 0.8774120211601257, 'epoch': 21.09}
{'loss': 0.0076, 'grad_norm': 5.015137195587158, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.004696718882769346, 'loss_2': 0.00290679931640625, 'loss_3': -16.725994110107422, 'loss_4': 1.1863943338394165, 'epoch': 21.09}
{'loss': 0.0137, 'grad_norm': 8.856807708740234, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.009669545106589794, 'loss_2': 0.00403594970703125, 'loss_3': -16.548297882080078, 'loss_4': 0.8280134201049805, 'epoch': 21.1}
{'loss': 0.013, 'grad_norm': 5.754810333251953, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.008459930308163166, 'loss_2': 0.0045166015625, 'loss_3': -16.717927932739258, 'loss_4': 1.236635446548462, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 16:47:10,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:10,141 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:48<26:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:17,501 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011898932978510857, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005971251055598259, 'eval_loss_2': 0.005927681922912598, 'eval_loss_3': -18.274070739746094, 'eval_loss_4': 1.0594562292099, 'epoch': 21.1}
{'loss': 0.079, 'grad_norm': 24.280941009521484, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.07420504838228226, 'loss_2': 0.00484466552734375, 'loss_3': -16.52736473083496, 'loss_4': 1.2569022178649902, 'epoch': 21.11}
{'loss': 0.0347, 'grad_norm': 14.433013916015625, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.024698011577129364, 'loss_2': 0.01003265380859375, 'loss_3': -16.672401428222656, 'loss_4': 0.9476715922355652, 'epoch': 21.12}
{'loss': 0.0193, 'grad_norm': 17.52361488342285, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.01447331253439188, 'loss_2': 0.0048370361328125, 'loss_3': -16.48443603515625, 'loss_4': 1.3242231607437134, 'epoch': 21.12}
{'loss': 0.0074, 'grad_norm': 4.390028953552246, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.0063299802131950855, 'loss_2': 0.0010242462158203125, 'loss_3': -16.57144546508789, 'loss_4': 0.7982345223426819, 'epoch': 21.13}
{'loss': 0.0131, 'grad_norm': 5.11821174621582, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.005335180088877678, 'loss_2': 0.00777435302734375, 'loss_3': -16.769737243652344, 'loss_4': 0.670382022857666, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 16:47:17,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:17,501 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:55<26:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:24,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012556223198771477, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.78, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0061926525086164474, 'eval_loss_2': 0.006363570690155029, 'eval_loss_3': -18.27449607849121, 'eval_loss_4': 1.0217316150665283, 'epoch': 21.13}
{'loss': 0.0162, 'grad_norm': 5.072432994842529, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.005057201720774174, 'loss_2': 0.01110076904296875, 'loss_3': -16.451641082763672, 'loss_4': 0.8127991557121277, 'epoch': 21.14}
{'loss': 0.0062, 'grad_norm': 7.10072135925293, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.006099237594753504, 'loss_2': 8.547306060791016e-05, 'loss_3': -16.730815887451172, 'loss_4': 0.9684416651725769, 'epoch': 21.15}
{'loss': 0.0104, 'grad_norm': 5.983163356781006, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.008591849356889725, 'loss_2': 0.0017652511596679688, 'loss_3': -16.4727840423584, 'loss_4': 1.2481374740600586, 'epoch': 21.15}
{'loss': 0.0081, 'grad_norm': 5.9348626136779785, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.004670601338148117, 'loss_2': 0.003467559814453125, 'loss_3': -16.635377883911133, 'loss_4': 1.2441084384918213, 'epoch': 21.16}
{'loss': 0.0183, 'grad_norm': 6.223737716674805, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.00836542621254921, 'loss_2': 0.0098876953125, 'loss_3': -16.606876373291016, 'loss_4': 0.7758285403251648, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 16:47:24,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:24,849 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:30:03<26:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:32,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010861353017389774, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.881, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006265715695917606, 'eval_loss_2': 0.004595637321472168, 'eval_loss_3': -18.273685455322266, 'eval_loss_4': 1.0234931707382202, 'epoch': 21.16}
{'loss': 0.0172, 'grad_norm': 10.525666236877441, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.01376164797693491, 'loss_2': 0.0034046173095703125, 'loss_3': -16.498964309692383, 'loss_4': 1.0571820735931396, 'epoch': 21.17}
{'loss': 0.0189, 'grad_norm': 6.115586280822754, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.010342518799006939, 'loss_2': 0.008544921875, 'loss_3': -16.675594329833984, 'loss_4': 1.2774381637573242, 'epoch': 21.17}
{'loss': 0.0056, 'grad_norm': 5.120026111602783, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.0038345290813595057, 'loss_2': 0.0017871856689453125, 'loss_3': -16.695266723632812, 'loss_4': 0.7927486896514893, 'epoch': 21.18}
{'loss': 0.0076, 'grad_norm': 5.556071758270264, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.00707931537181139, 'loss_2': 0.0005550384521484375, 'loss_3': -16.560989379882812, 'loss_4': 1.065856695175171, 'epoch': 21.19}
{'loss': 0.0096, 'grad_norm': 4.830357074737549, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.005742174107581377, 'loss_2': 0.0038890838623046875, 'loss_3': -16.755268096923828, 'loss_4': 1.0135518312454224, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 16:47:32,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:32,221 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:10<26:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:39,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009183297865092754, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006290250923484564, 'eval_loss_2': 0.0028930455446243286, 'eval_loss_3': -18.269386291503906, 'eval_loss_4': 0.9797285795211792, 'epoch': 21.19}
{'loss': 0.0064, 'grad_norm': 4.299928665161133, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.004154898226261139, 'loss_2': 0.00225830078125, 'loss_3': -16.773340225219727, 'loss_4': 0.8918911218643188, 'epoch': 21.2}
{'loss': 0.0073, 'grad_norm': 6.289391040802002, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.007223291788250208, 'loss_2': 3.629922866821289e-05, 'loss_3': -16.5391788482666, 'loss_4': 0.9624844193458557, 'epoch': 21.2}
{'loss': 0.0252, 'grad_norm': 14.993911743164062, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.025184281170368195, 'loss_2': 5.352497100830078e-05, 'loss_3': -16.442136764526367, 'loss_4': 1.2085723876953125, 'epoch': 21.21}
{'loss': 0.0146, 'grad_norm': 6.549316883087158, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.01083108689635992, 'loss_2': 0.00379180908203125, 'loss_3': -16.83424949645996, 'loss_4': 0.9504976272583008, 'epoch': 21.22}
{'loss': 0.0141, 'grad_norm': 7.084360122680664, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.007821593433618546, 'loss_2': 0.006313323974609375, 'loss_3': -16.652881622314453, 'loss_4': 0.9391154050827026, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 16:47:39,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:39,576 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:17<26:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:46,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01064289826899767, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.664, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006782603450119495, 'eval_loss_2': 0.003860294818878174, 'eval_loss_3': -18.262760162353516, 'eval_loss_4': 0.9649763107299805, 'epoch': 21.22}
{'loss': 0.0124, 'grad_norm': 5.1637372970581055, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.004466668702661991, 'loss_2': 0.00789642333984375, 'loss_3': -16.68442726135254, 'loss_4': 0.7299929261207581, 'epoch': 21.23}
{'loss': 0.018, 'grad_norm': 6.217016220092773, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.008409381844103336, 'loss_2': 0.00958251953125, 'loss_3': -16.76474952697754, 'loss_4': 0.729171872138977, 'epoch': 21.23}
{'loss': 0.0117, 'grad_norm': 5.841060161590576, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.009592213667929173, 'loss_2': 0.00214385986328125, 'loss_3': -16.533885955810547, 'loss_4': 1.0754334926605225, 'epoch': 21.24}
{'loss': 0.014, 'grad_norm': 6.471435546875, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.008211289532482624, 'loss_2': 0.0057830810546875, 'loss_3': -16.414539337158203, 'loss_4': 0.8635973334312439, 'epoch': 21.24}
{'loss': 0.0111, 'grad_norm': 4.627264976501465, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.006296536419540644, 'loss_2': 0.00484466552734375, 'loss_3': -16.623979568481445, 'loss_4': 0.7890582084655762, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 16:47:46,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:46,929 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:25<25:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:54,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009612608700990677, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.683, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006423656828701496, 'eval_loss_2': 0.0031889528036117554, 'eval_loss_3': -18.257606506347656, 'eval_loss_4': 0.9010070562362671, 'epoch': 21.25}
{'loss': 0.0137, 'grad_norm': 4.324527263641357, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.007670330815017223, 'loss_2': 0.00600433349609375, 'loss_3': -16.789506912231445, 'loss_4': 0.8463127017021179, 'epoch': 21.26}
{'loss': 0.0036, 'grad_norm': 4.251872539520264, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.002972767688333988, 'loss_2': 0.0005850791931152344, 'loss_3': -16.76255226135254, 'loss_4': 0.44442564249038696, 'epoch': 21.26}
{'loss': 0.0055, 'grad_norm': 4.470208644866943, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.003317877184599638, 'loss_2': 0.002216339111328125, 'loss_3': -16.69389533996582, 'loss_4': 0.725054144859314, 'epoch': 21.27}
{'loss': 0.0126, 'grad_norm': 5.665475845336914, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.008427144028246403, 'loss_2': 0.0041351318359375, 'loss_3': -16.5930118560791, 'loss_4': 0.7362457513809204, 'epoch': 21.27}
{'loss': 0.0093, 'grad_norm': 4.87444543838501, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.007354754954576492, 'loss_2': 0.0019130706787109375, 'loss_3': -16.602842330932617, 'loss_4': 0.833594560623169, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 16:47:54,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:54,279 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:32<25:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:01,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010018213652074337, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.792, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0070457011461257935, 'eval_loss_2': 0.002972513437271118, 'eval_loss_3': -18.254098892211914, 'eval_loss_4': 0.8579708933830261, 'epoch': 21.28}
{'loss': 0.019, 'grad_norm': 8.582155227661133, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.015337271615862846, 'loss_2': 0.0037059783935546875, 'loss_3': -16.672094345092773, 'loss_4': 0.2849138379096985, 'epoch': 21.28}
{'loss': 0.0167, 'grad_norm': 7.3236188888549805, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.011637242510914803, 'loss_2': 0.0051116943359375, 'loss_3': -16.391498565673828, 'loss_4': 0.6076058745384216, 'epoch': 21.29}
{'loss': 0.0173, 'grad_norm': 12.009361267089844, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.017053496092557907, 'loss_2': 0.00022494792938232422, 'loss_3': -16.494564056396484, 'loss_4': 0.6983186602592468, 'epoch': 21.3}
{'loss': 0.0088, 'grad_norm': 7.66840934753418, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.007918940857052803, 'loss_2': 0.0008492469787597656, 'loss_3': -16.679420471191406, 'loss_4': 0.6667323708534241, 'epoch': 21.3}
{'loss': 0.0043, 'grad_norm': 4.85783052444458, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.001807764987461269, 'loss_2': 0.00251007080078125, 'loss_3': -16.554624557495117, 'loss_4': 0.6183274984359741, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 16:48:01,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:01,623 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:39<25:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:08,974 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009726880118250847, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.68, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006734966766089201, 'eval_loss_2': 0.002991914749145508, 'eval_loss_3': -18.247629165649414, 'eval_loss_4': 0.8695515394210815, 'epoch': 21.31}
{'loss': 0.0074, 'grad_norm': 4.589761734008789, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.003911816049367189, 'loss_2': 0.003490447998046875, 'loss_3': -16.635854721069336, 'loss_4': 0.5274800658226013, 'epoch': 21.31}
{'loss': 0.0129, 'grad_norm': 7.144017696380615, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.010322594083845615, 'loss_2': 0.0025577545166015625, 'loss_3': -16.63029670715332, 'loss_4': 0.7181621789932251, 'epoch': 21.32}
{'loss': 0.0119, 'grad_norm': 6.488806247711182, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.00845970306545496, 'loss_2': 0.003444671630859375, 'loss_3': -16.63528823852539, 'loss_4': 0.771262526512146, 'epoch': 21.33}
{'loss': 0.0085, 'grad_norm': 5.1033854484558105, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.006778829265385866, 'loss_2': 0.001758575439453125, 'loss_3': -16.73184585571289, 'loss_4': 1.1130497455596924, 'epoch': 21.33}
{'loss': 0.0054, 'grad_norm': 4.493319988250732, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.0029596330132335424, 'loss_2': 0.0024871826171875, 'loss_3': -16.352375030517578, 'loss_4': 1.207979440689087, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 16:48:08,974 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:08,974 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:47<25:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:16,333 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009514919482171535, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006839610170572996, 'eval_loss_2': 0.0026753097772598267, 'eval_loss_3': -18.249113082885742, 'eval_loss_4': 0.9340853095054626, 'epoch': 21.34}
{'loss': 0.0184, 'grad_norm': 6.617207050323486, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.01390075869858265, 'loss_2': 0.0045318603515625, 'loss_3': -16.63277816772461, 'loss_4': 0.550208330154419, 'epoch': 21.34}
{'loss': 0.0226, 'grad_norm': 9.707691192626953, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.01768864318728447, 'loss_2': 0.004932403564453125, 'loss_3': -16.7454891204834, 'loss_4': 0.980638325214386, 'epoch': 21.35}
{'loss': 0.018, 'grad_norm': 7.881061553955078, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.01742706261575222, 'loss_2': 0.0005388259887695312, 'loss_3': -16.498973846435547, 'loss_4': 1.0663878917694092, 'epoch': 21.35}
{'loss': 0.0054, 'grad_norm': 4.550023555755615, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.0029559258837252855, 'loss_2': 0.002410888671875, 'loss_3': -16.44645118713379, 'loss_4': 0.8600443005561829, 'epoch': 21.36}
{'loss': 0.0056, 'grad_norm': 4.462286472320557, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.002103957114741206, 'loss_2': 0.00347900390625, 'loss_3': -16.782251358032227, 'loss_4': 1.1407766342163086, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 16:48:16,333 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:16,333 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:54<25:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:23,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009599260985851288, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0075165098533034325, 'eval_loss_2': 0.0020827502012252808, 'eval_loss_3': -18.251482009887695, 'eval_loss_4': 1.0303312540054321, 'epoch': 21.37}
{'loss': 0.0094, 'grad_norm': 4.775351524353027, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.005943767726421356, 'loss_2': 0.0034770965576171875, 'loss_3': -16.693923950195312, 'loss_4': 1.1157608032226562, 'epoch': 21.37}
{'loss': 0.0074, 'grad_norm': 4.946990966796875, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.004525741562247276, 'loss_2': 0.002857208251953125, 'loss_3': -16.61425018310547, 'loss_4': 0.3139882981777191, 'epoch': 21.38}
{'loss': 0.0101, 'grad_norm': 7.210033893585205, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.008764375001192093, 'loss_2': 0.0013141632080078125, 'loss_3': -16.739700317382812, 'loss_4': 0.6386287212371826, 'epoch': 21.38}
{'loss': 0.0166, 'grad_norm': 10.976421356201172, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.012637922540307045, 'loss_2': 0.00400543212890625, 'loss_3': -16.638113021850586, 'loss_4': 0.76894611120224, 'epoch': 21.39}
{'loss': 0.0097, 'grad_norm': 6.047826290130615, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.008145415224134922, 'loss_2': 0.0015087127685546875, 'loss_3': -16.498882293701172, 'loss_4': 0.6124597787857056, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 16:48:23,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:23,682 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:31:01<25:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:31,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00984552875161171, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.707, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007124308496713638, 'eval_loss_2': 0.0027212202548980713, 'eval_loss_3': -18.257463455200195, 'eval_loss_4': 1.1237390041351318, 'epoch': 21.4}
{'loss': 0.0085, 'grad_norm': 4.72628927230835, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.003806208958849311, 'loss_2': 0.004650115966796875, 'loss_3': -16.685949325561523, 'loss_4': 0.9889064431190491, 'epoch': 21.4}
{'loss': 0.0164, 'grad_norm': 5.183393955230713, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.00717907352373004, 'loss_2': 0.009246826171875, 'loss_3': -16.57830810546875, 'loss_4': 0.7660654783248901, 'epoch': 21.41}
{'loss': 0.0108, 'grad_norm': 5.883190631866455, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.007635260466486216, 'loss_2': 0.003162384033203125, 'loss_3': -16.662254333496094, 'loss_4': 1.0567806959152222, 'epoch': 21.41}
{'loss': 0.0152, 'grad_norm': 7.127015590667725, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.009283254854381084, 'loss_2': 0.00592041015625, 'loss_3': -16.56243896484375, 'loss_4': 1.1000444889068604, 'epoch': 21.42}
{'loss': 0.0129, 'grad_norm': 5.570724010467529, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.00753362663090229, 'loss_2': 0.00540924072265625, 'loss_3': -16.776975631713867, 'loss_4': 0.9038767218589783, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 16:48:31,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:31,035 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:31:09<25:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:38,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00911729782819748, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.516, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006936207413673401, 'eval_loss_2': 0.0021810904145240784, 'eval_loss_3': -18.258159637451172, 'eval_loss_4': 1.1840180158615112, 'epoch': 21.42}
{'loss': 0.0203, 'grad_norm': 5.70013952255249, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.00903111882507801, 'loss_2': 0.0112457275390625, 'loss_3': -16.693763732910156, 'loss_4': 0.9037355184555054, 'epoch': 21.43}
{'loss': 0.0116, 'grad_norm': 4.745020866394043, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.004238455556333065, 'loss_2': 0.007354736328125, 'loss_3': -16.413423538208008, 'loss_4': 0.9615626335144043, 'epoch': 21.44}
{'loss': 0.0067, 'grad_norm': 4.961272239685059, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.0032411308493465185, 'loss_2': 0.003505706787109375, 'loss_3': -16.69974136352539, 'loss_4': 1.211151361465454, 'epoch': 21.44}
{'loss': 0.0065, 'grad_norm': 4.940182685852051, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.00433349097147584, 'loss_2': 0.002193450927734375, 'loss_3': -16.609020233154297, 'loss_4': 1.068102478981018, 'epoch': 21.45}
{'loss': 0.011, 'grad_norm': 5.3566975593566895, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.006505484692752361, 'loss_2': 0.00450897216796875, 'loss_3': -16.714393615722656, 'loss_4': 1.1795194149017334, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 16:48:38,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:38,393 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:31:16<25:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:45,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010321956127882004, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.516, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006852043326944113, 'eval_loss_2': 0.003469914197921753, 'eval_loss_3': -18.25887680053711, 'eval_loss_4': 1.2051684856414795, 'epoch': 21.45}
{'loss': 0.0212, 'grad_norm': 9.076611518859863, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.019028184935450554, 'loss_2': 0.00217437744140625, 'loss_3': -16.494312286376953, 'loss_4': 0.9793844819068909, 'epoch': 21.46}
{'loss': 0.0044, 'grad_norm': 4.970284938812256, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.003936020657420158, 'loss_2': 0.000469207763671875, 'loss_3': -16.7460994720459, 'loss_4': 1.054602861404419, 'epoch': 21.47}
{'loss': 0.0118, 'grad_norm': 5.989764213562012, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.007344027049839497, 'loss_2': 0.004421234130859375, 'loss_3': -16.41379737854004, 'loss_4': 0.9527182579040527, 'epoch': 21.47}
{'loss': 0.0186, 'grad_norm': 5.121666431427002, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.00527688954025507, 'loss_2': 0.0133209228515625, 'loss_3': -16.66485595703125, 'loss_4': 0.9541540145874023, 'epoch': 21.48}
{'loss': 0.0056, 'grad_norm': 4.471108913421631, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.004210831597447395, 'loss_2': 0.0014066696166992188, 'loss_3': -16.819652557373047, 'loss_4': 1.226613998413086, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 16:48:45,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:45,750 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:23<25:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:53,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013450216501951218, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.175, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006230187136679888, 'eval_loss_2': 0.007220029830932617, 'eval_loss_3': -18.274757385253906, 'eval_loss_4': 1.1834948062896729, 'epoch': 21.48}
{'loss': 0.0123, 'grad_norm': 5.529576301574707, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.0052945856004953384, 'loss_2': 0.006984710693359375, 'loss_3': -16.715354919433594, 'loss_4': 0.8484929800033569, 'epoch': 21.49}
{'loss': 0.0076, 'grad_norm': 5.026734352111816, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.004829866345971823, 'loss_2': 0.002811431884765625, 'loss_3': -16.66704559326172, 'loss_4': 1.366581678390503, 'epoch': 21.49}
{'loss': 0.0112, 'grad_norm': 5.185425281524658, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0067789130844175816, 'loss_2': 0.00445556640625, 'loss_3': -16.65365219116211, 'loss_4': 0.9049239754676819, 'epoch': 21.5}
{'loss': 0.0063, 'grad_norm': 4.734804630279541, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.0025693236384540796, 'loss_2': 0.003772735595703125, 'loss_3': -16.559616088867188, 'loss_4': 0.9146901369094849, 'epoch': 21.51}
{'loss': 0.0234, 'grad_norm': 5.179710865020752, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.005289795808494091, 'loss_2': 0.01812744140625, 'loss_3': -16.589252471923828, 'loss_4': 1.177290439605713, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 16:48:53,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:53,103 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:31<25:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:00,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012204998172819614, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.905, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005985253490507603, 'eval_loss_2': 0.006219744682312012, 'eval_loss_3': -18.258760452270508, 'eval_loss_4': 1.0981653928756714, 'epoch': 21.51}
{'loss': 0.0129, 'grad_norm': 6.451353549957275, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.009348000399768353, 'loss_2': 0.003520965576171875, 'loss_3': -16.594301223754883, 'loss_4': 0.9098452925682068, 'epoch': 21.52}
{'loss': 0.011, 'grad_norm': 4.690986633300781, 'learning_rate': 8.5e-06, 'loss_1': 0.0036345140542834997, 'loss_2': 0.007320404052734375, 'loss_3': -16.67776870727539, 'loss_4': 1.1088258028030396, 'epoch': 21.52}
{'loss': 0.0048, 'grad_norm': 5.174831390380859, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.0039809588342905045, 'loss_2': 0.0007696151733398438, 'loss_3': -16.555116653442383, 'loss_4': 0.8132180571556091, 'epoch': 21.53}
{'loss': 0.0047, 'grad_norm': 4.851609706878662, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.00407689344137907, 'loss_2': 0.0006561279296875, 'loss_3': -16.6728458404541, 'loss_4': 0.7766231298446655, 'epoch': 21.53}
{'loss': 0.0108, 'grad_norm': 5.087664604187012, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.00621938519179821, 'loss_2': 0.0045318603515625, 'loss_3': -16.68366050720215, 'loss_4': 1.1534526348114014, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 16:49:00,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:00,468 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:38<25:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:07,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009344973601400852, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006497715134173632, 'eval_loss_2': 0.0028472580015659332, 'eval_loss_3': -18.24791145324707, 'eval_loss_4': 1.0403451919555664, 'epoch': 21.54}
{'loss': 0.0049, 'grad_norm': 4.608527183532715, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.003027305705472827, 'loss_2': 0.00186920166015625, 'loss_3': -16.54412841796875, 'loss_4': 0.8972378969192505, 'epoch': 21.55}
{'loss': 0.0071, 'grad_norm': 4.820820331573486, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.0029515745118260384, 'loss_2': 0.00414276123046875, 'loss_3': -16.69454002380371, 'loss_4': 1.0680046081542969, 'epoch': 21.55}
{'loss': 0.0035, 'grad_norm': 4.457753658294678, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.002854852471500635, 'loss_2': 0.0006551742553710938, 'loss_3': -16.737197875976562, 'loss_4': 1.1326417922973633, 'epoch': 21.56}
{'loss': 0.0048, 'grad_norm': 4.656370639801025, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.004291940946131945, 'loss_2': 0.0005130767822265625, 'loss_3': -16.64344024658203, 'loss_4': 1.2281453609466553, 'epoch': 21.56}
{'loss': 0.0176, 'grad_norm': 5.972268104553223, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.008914533071219921, 'loss_2': 0.00872802734375, 'loss_3': -16.779247283935547, 'loss_4': 0.5464929938316345, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 16:49:07,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:07,831 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:46<25:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:15,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012202761135995388, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.48, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008177017793059349, 'eval_loss_2': 0.004025742411613464, 'eval_loss_3': -18.23243522644043, 'eval_loss_4': 1.0186127424240112, 'epoch': 21.57}
{'loss': 0.0152, 'grad_norm': 10.123648643493652, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.014649352058768272, 'loss_2': 0.0005288124084472656, 'loss_3': -16.452980041503906, 'loss_4': 1.2333790063858032, 'epoch': 21.58}
{'loss': 0.0131, 'grad_norm': 4.616901397705078, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.0036192990373820066, 'loss_2': 0.0094757080078125, 'loss_3': -16.523475646972656, 'loss_4': 0.6950952410697937, 'epoch': 21.58}
{'loss': 0.0159, 'grad_norm': 4.908668041229248, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.006173054222017527, 'loss_2': 0.009765625, 'loss_3': -16.544166564941406, 'loss_4': 1.156088948249817, 'epoch': 21.59}
{'loss': 0.0118, 'grad_norm': 6.6398725509643555, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.006872451864182949, 'loss_2': 0.004913330078125, 'loss_3': -16.61980628967285, 'loss_4': 1.0057036876678467, 'epoch': 21.59}
{'loss': 0.0783, 'grad_norm': 12.26272964477539, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.06690909713506699, 'loss_2': 0.01143646240234375, 'loss_3': -16.556377410888672, 'loss_4': 1.0825257301330566, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 16:49:15,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:15,182 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:53<24:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:22,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01243654265999794, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.171, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007608447689563036, 'eval_loss_2': 0.004828095436096191, 'eval_loss_3': -18.22867202758789, 'eval_loss_4': 0.9637181162834167, 'epoch': 21.6}
{'loss': 0.0112, 'grad_norm': 4.903413772583008, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.004186035133898258, 'loss_2': 0.007015228271484375, 'loss_3': -16.638879776000977, 'loss_4': 0.9715895652770996, 'epoch': 21.6}
{'loss': 0.0127, 'grad_norm': 4.844457149505615, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.003957576584070921, 'loss_2': 0.0087890625, 'loss_3': -16.601089477539062, 'loss_4': 1.0866742134094238, 'epoch': 21.61}
{'loss': 0.0107, 'grad_norm': 5.633137226104736, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.007385475095361471, 'loss_2': 0.003330230712890625, 'loss_3': -16.47835922241211, 'loss_4': 0.6941435933113098, 'epoch': 21.62}
{'loss': 0.024, 'grad_norm': 13.362204551696777, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.015755344182252884, 'loss_2': 0.008209228515625, 'loss_3': -16.64301300048828, 'loss_4': 0.4451298117637634, 'epoch': 21.62}
{'loss': 0.0065, 'grad_norm': 4.62685489654541, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.005869819782674313, 'loss_2': 0.0006427764892578125, 'loss_3': -16.62447738647461, 'loss_4': 0.8829659223556519, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 16:49:22,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:22,536 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:32:00<24:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:29,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012171220034360886, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.906, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008543919771909714, 'eval_loss_2': 0.003627300262451172, 'eval_loss_3': -18.2131290435791, 'eval_loss_4': 0.8914740085601807, 'epoch': 21.63}
{'loss': 0.0133, 'grad_norm': 4.662321090698242, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.00454742880538106, 'loss_2': 0.00876617431640625, 'loss_3': -16.59546661376953, 'loss_4': 1.1537202596664429, 'epoch': 21.63}
{'loss': 0.0108, 'grad_norm': 8.814286231994629, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.010514049790799618, 'loss_2': 0.0002841949462890625, 'loss_3': -16.44527816772461, 'loss_4': 0.9237812757492065, 'epoch': 21.64}
{'loss': 0.0223, 'grad_norm': 8.038206100463867, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.021664686501026154, 'loss_2': 0.00067138671875, 'loss_3': -16.536582946777344, 'loss_4': 0.9055442810058594, 'epoch': 21.65}
{'loss': 0.0108, 'grad_norm': 5.537814140319824, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.006525259464979172, 'loss_2': 0.00424957275390625, 'loss_3': -16.572834014892578, 'loss_4': 0.39478302001953125, 'epoch': 21.65}
{'loss': 0.0153, 'grad_norm': 7.519173622131348, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.012671376578509808, 'loss_2': 0.002635955810546875, 'loss_3': -16.51190757751465, 'loss_4': 0.8608163595199585, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 16:49:29,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:29,895 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:32:08<24:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:37,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011701686307787895, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.915, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008632495999336243, 'eval_loss_2': 0.0030691921710968018, 'eval_loss_3': -18.21401596069336, 'eval_loss_4': 0.8354271650314331, 'epoch': 21.66}
{'loss': 0.0196, 'grad_norm': 8.228043556213379, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.018362868577241898, 'loss_2': 0.001239776611328125, 'loss_3': -16.43930435180664, 'loss_4': 0.6516086459159851, 'epoch': 21.66}
{'loss': 0.0275, 'grad_norm': 12.745909690856934, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.023854421451687813, 'loss_2': 0.003597259521484375, 'loss_3': -16.562068939208984, 'loss_4': 1.0380867719650269, 'epoch': 21.67}
{'loss': 0.0148, 'grad_norm': 13.210302352905273, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.010797803290188313, 'loss_2': 0.00396728515625, 'loss_3': -16.58486557006836, 'loss_4': 0.7448684573173523, 'epoch': 21.67}
{'loss': 0.0038, 'grad_norm': 5.000540256500244, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.003743081586435437, 'loss_2': 3.647804260253906e-05, 'loss_3': -16.682554244995117, 'loss_4': 0.934088408946991, 'epoch': 21.68}
{'loss': 0.0108, 'grad_norm': 5.130930423736572, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.008084225468337536, 'loss_2': 0.002765655517578125, 'loss_3': -16.510581970214844, 'loss_4': 0.6423799991607666, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 16:49:37,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:37,264 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:32:15<24:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:44,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010886646807193756, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.565, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007946766912937164, 'eval_loss_2': 0.002939879894256592, 'eval_loss_3': -18.220699310302734, 'eval_loss_4': 0.7651666402816772, 'epoch': 21.69}
{'loss': 0.0021, 'grad_norm': 4.4970479011535645, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.002066434593871236, 'loss_2': 1.4185905456542969e-05, 'loss_3': -16.50727081298828, 'loss_4': 0.791275143623352, 'epoch': 21.69}
{'loss': 0.0067, 'grad_norm': 5.077888011932373, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.004848778247833252, 'loss_2': 0.0018701553344726562, 'loss_3': -16.674575805664062, 'loss_4': 0.34302666783332825, 'epoch': 21.7}
{'loss': 0.0098, 'grad_norm': 4.958382606506348, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.003840370336547494, 'loss_2': 0.0059661865234375, 'loss_3': -16.397199630737305, 'loss_4': 0.5525971055030823, 'epoch': 21.7}
{'loss': 0.0096, 'grad_norm': 5.88173770904541, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.008003250695765018, 'loss_2': 0.001560211181640625, 'loss_3': -16.582529067993164, 'loss_4': 0.7345168590545654, 'epoch': 21.71}
{'loss': 0.0159, 'grad_norm': 11.207566261291504, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.015157121233642101, 'loss_2': 0.0007753372192382812, 'loss_3': -16.323217391967773, 'loss_4': 0.48943445086479187, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 16:49:44,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:44,619 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:22<24:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:51,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010751264169812202, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007624882273375988, 'eval_loss_2': 0.003126382827758789, 'eval_loss_3': -18.22429656982422, 'eval_loss_4': 0.6973266005516052, 'epoch': 21.72}
{'loss': 0.016, 'grad_norm': 7.897507667541504, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.01566842757165432, 'loss_2': 0.000293731689453125, 'loss_3': -16.6395320892334, 'loss_4': 0.5800014734268188, 'epoch': 21.72}
{'loss': 0.0108, 'grad_norm': 6.075995445251465, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.009399431757628918, 'loss_2': 0.0013580322265625, 'loss_3': -16.15536117553711, 'loss_4': -0.037134088575839996, 'epoch': 21.73}
{'loss': 0.0056, 'grad_norm': 4.4180588722229, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.004837640095502138, 'loss_2': 0.0007643699645996094, 'loss_3': -16.572710037231445, 'loss_4': 0.6044273376464844, 'epoch': 21.73}
{'loss': 0.0125, 'grad_norm': 5.841013431549072, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.009321656078100204, 'loss_2': 0.003185272216796875, 'loss_3': -16.70185661315918, 'loss_4': 0.14912322163581848, 'epoch': 21.74}
{'loss': 0.0089, 'grad_norm': 4.448399066925049, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.0033314956817775965, 'loss_2': 0.005603790283203125, 'loss_3': -16.538070678710938, 'loss_4': 0.5625491142272949, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 16:49:51,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:51,979 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:30<24:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:59,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012132791802287102, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.093, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007598130498081446, 'eval_loss_2': 0.004534661769866943, 'eval_loss_3': -18.227678298950195, 'eval_loss_4': 0.5902246832847595, 'epoch': 21.74}
{'loss': 0.0145, 'grad_norm': 5.5209245681762695, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.009271360002458096, 'loss_2': 0.005245208740234375, 'loss_3': -16.472875595092773, 'loss_4': 0.6193503737449646, 'epoch': 21.75}
{'loss': 0.0154, 'grad_norm': 6.256835460662842, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.0092173982411623, 'loss_2': 0.0061492919921875, 'loss_3': -16.681350708007812, 'loss_4': 0.39829006791114807, 'epoch': 21.76}
{'loss': 0.0127, 'grad_norm': 5.5261125564575195, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.006403263192623854, 'loss_2': 0.006313323974609375, 'loss_3': -16.593196868896484, 'loss_4': 0.6973370313644409, 'epoch': 21.76}
{'loss': 0.0123, 'grad_norm': 6.709966659545898, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.011619003489613533, 'loss_2': 0.0006937980651855469, 'loss_3': -16.6458740234375, 'loss_4': 0.21845631301403046, 'epoch': 21.77}
{'loss': 0.0087, 'grad_norm': 6.015655517578125, 'learning_rate': 8.25e-06, 'loss_1': 0.006164861842989922, 'loss_2': 0.0025081634521484375, 'loss_3': -16.511327743530273, 'loss_4': 0.37418073415756226, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 16:49:59,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:59,346 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:37<24:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:06,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010221559554338455, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007691164035350084, 'eval_loss_2': 0.002530395984649658, 'eval_loss_3': -18.25208854675293, 'eval_loss_4': 0.47616687417030334, 'epoch': 21.77}
{'loss': 0.0093, 'grad_norm': 6.070920944213867, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.006517215631902218, 'loss_2': 0.00276947021484375, 'loss_3': -16.559860229492188, 'loss_4': 0.48303359746932983, 'epoch': 21.78}
{'loss': 0.0186, 'grad_norm': 9.288931846618652, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.01824512891471386, 'loss_2': 0.0003466606140136719, 'loss_3': -16.54414176940918, 'loss_4': 0.8372513651847839, 'epoch': 21.78}
{'loss': 0.0123, 'grad_norm': 6.820115566253662, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.007498181890696287, 'loss_2': 0.00482177734375, 'loss_3': -16.58941078186035, 'loss_4': 0.6572731733322144, 'epoch': 21.79}
{'loss': 0.0163, 'grad_norm': 5.469810962677002, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.00913393497467041, 'loss_2': 0.007152557373046875, 'loss_3': -16.607257843017578, 'loss_4': 0.770987868309021, 'epoch': 21.8}
{'loss': 0.0052, 'grad_norm': 4.463886260986328, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.0033444019500166178, 'loss_2': 0.0018949508666992188, 'loss_3': -16.740386962890625, 'loss_4': 0.8272513151168823, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 16:50:06,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:06,698 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:44<24:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:14,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009870192967355251, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.136, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007970128208398819, 'eval_loss_2': 0.001900065690279007, 'eval_loss_3': -18.253124237060547, 'eval_loss_4': 0.43737345933914185, 'epoch': 21.8}
{'loss': 0.0081, 'grad_norm': 5.073440074920654, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.0055089122615754604, 'loss_2': 0.002613067626953125, 'loss_3': -16.631683349609375, 'loss_4': 0.5550024509429932, 'epoch': 21.81}
{'loss': 0.006, 'grad_norm': 4.45705509185791, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.0036077473778277636, 'loss_2': 0.00238037109375, 'loss_3': -16.84722900390625, 'loss_4': 0.387470543384552, 'epoch': 21.81}
{'loss': 0.0148, 'grad_norm': 6.887371063232422, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.008583851158618927, 'loss_2': 0.00620269775390625, 'loss_3': -16.48859405517578, 'loss_4': 0.16625815629959106, 'epoch': 21.82}
{'loss': 0.0047, 'grad_norm': 4.021294593811035, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.0035355878062546253, 'loss_2': 0.00119781494140625, 'loss_3': -16.80008888244629, 'loss_4': 0.4178202152252197, 'epoch': 21.83}
{'loss': 0.0044, 'grad_norm': 4.71701192855835, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.004094666335731745, 'loss_2': 0.0003304481506347656, 'loss_3': -16.53160858154297, 'loss_4': 0.1139737218618393, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 16:50:14,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:14,061 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:52<24:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:21,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010191229172050953, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.032, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008066866546869278, 'eval_loss_2': 0.0021243616938591003, 'eval_loss_3': -18.249279022216797, 'eval_loss_4': 0.36434200406074524, 'epoch': 21.83}
{'loss': 0.0099, 'grad_norm': 4.264457702636719, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.003946976736187935, 'loss_2': 0.00591278076171875, 'loss_3': -16.515451431274414, 'loss_4': 0.6686387658119202, 'epoch': 21.84}
{'loss': 0.0108, 'grad_norm': 4.614932537078857, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.004924524575471878, 'loss_2': 0.005886077880859375, 'loss_3': -16.585180282592773, 'loss_4': 0.21127226948738098, 'epoch': 21.84}
{'loss': 0.0188, 'grad_norm': 7.720694065093994, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.013990402221679688, 'loss_2': 0.00476837158203125, 'loss_3': -16.651519775390625, 'loss_4': 0.3573882579803467, 'epoch': 21.85}
{'loss': 0.0089, 'grad_norm': 5.522757530212402, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.007118359673768282, 'loss_2': 0.0017604827880859375, 'loss_3': -16.738574981689453, 'loss_4': -0.013937026262283325, 'epoch': 21.85}
{'loss': 0.0088, 'grad_norm': 5.881443500518799, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.008489358238875866, 'loss_2': 0.0003216266632080078, 'loss_3': -16.62347412109375, 'loss_4': 0.1657605767250061, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 16:50:21,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:21,414 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:59<24:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:28,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01090143620967865, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008540370501577854, 'eval_loss_2': 0.0023610666394233704, 'eval_loss_3': -18.2414493560791, 'eval_loss_4': 0.31520071625709534, 'epoch': 21.86}
{'loss': 0.0173, 'grad_norm': 6.9267683029174805, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.017312968149781227, 'loss_2': 3.337860107421875e-05, 'loss_3': -16.427419662475586, 'loss_4': -0.05657094717025757, 'epoch': 21.87}
{'loss': 0.0177, 'grad_norm': 11.732726097106934, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.015668345615267754, 'loss_2': 0.0020275115966796875, 'loss_3': -16.534873962402344, 'loss_4': 0.02305499091744423, 'epoch': 21.87}
{'loss': 0.0096, 'grad_norm': 4.760428428649902, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.006470066029578447, 'loss_2': 0.0031585693359375, 'loss_3': -16.632326126098633, 'loss_4': 0.29512423276901245, 'epoch': 21.88}
{'loss': 0.0258, 'grad_norm': 12.312737464904785, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.02232363261282444, 'loss_2': 0.00345611572265625, 'loss_3': -16.531177520751953, 'loss_4': 0.22051917016506195, 'epoch': 21.88}
{'loss': 0.0103, 'grad_norm': 7.5598225593566895, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.008377576246857643, 'loss_2': 0.0018768310546875, 'loss_3': -16.543760299682617, 'loss_4': 0.15198013186454773, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 16:50:28,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:28,758 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:33:06<24:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:36,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012803416699171066, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010097159072756767, 'eval_loss_2': 0.0027062594890594482, 'eval_loss_3': -18.223129272460938, 'eval_loss_4': 0.24795235693454742, 'epoch': 21.89}
{'loss': 0.0091, 'grad_norm': 4.2913384437561035, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.003049937542527914, 'loss_2': 0.00605010986328125, 'loss_3': -16.670053482055664, 'loss_4': 0.027188852429389954, 'epoch': 21.9}
{'loss': 0.0089, 'grad_norm': 4.585886001586914, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.005292548332363367, 'loss_2': 0.0036296844482421875, 'loss_3': -16.599525451660156, 'loss_4': -0.22156167030334473, 'epoch': 21.9}
{'loss': 0.0032, 'grad_norm': 5.122627258300781, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.0024835874792188406, 'loss_2': 0.0007123947143554688, 'loss_3': -16.510395050048828, 'loss_4': -0.01950410008430481, 'epoch': 21.91}
{'loss': 0.0069, 'grad_norm': 4.973140716552734, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.0037227629218250513, 'loss_2': 0.00318145751953125, 'loss_3': -16.582426071166992, 'loss_4': 0.021149855107069016, 'epoch': 21.91}
{'loss': 0.0079, 'grad_norm': 4.941649913787842, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.005193336866796017, 'loss_2': 0.002704620361328125, 'loss_3': -16.78273582458496, 'loss_4': 0.37760981917381287, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 16:50:36,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:36,107 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:33:14<24:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:43,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01366735901683569, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.299, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011411978863179684, 'eval_loss_2': 0.002255380153656006, 'eval_loss_3': -18.220367431640625, 'eval_loss_4': 0.2943137586116791, 'epoch': 21.92}
{'loss': 0.0104, 'grad_norm': 5.3301682472229, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.006348320282995701, 'loss_2': 0.00406646728515625, 'loss_3': -16.549955368041992, 'loss_4': -0.06144077703356743, 'epoch': 21.92}
{'loss': 0.0092, 'grad_norm': 8.515472412109375, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.00885073933750391, 'loss_2': 0.0003476142883300781, 'loss_3': -16.54505157470703, 'loss_4': 0.4567226469516754, 'epoch': 21.93}
{'loss': 0.0072, 'grad_norm': 4.7866926193237305, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.0032197716645896435, 'loss_2': 0.00395965576171875, 'loss_3': -16.566295623779297, 'loss_4': -0.003741266205906868, 'epoch': 21.94}
{'loss': 0.0098, 'grad_norm': 4.892185688018799, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.0061806850135326385, 'loss_2': 0.00362396240234375, 'loss_3': -16.507287979125977, 'loss_4': 0.4179852604866028, 'epoch': 21.94}
{'loss': 0.0086, 'grad_norm': 4.479345321655273, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.007020604331046343, 'loss_2': 0.001613616943359375, 'loss_3': -16.648962020874023, 'loss_4': 0.06960262358188629, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 16:50:43,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:43,465 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:21<23:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:50,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013538177125155926, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.494, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011508013121783733, 'eval_loss_2': 0.0020301640033721924, 'eval_loss_3': -18.214908599853516, 'eval_loss_4': 0.36146268248558044, 'epoch': 21.95}
{'loss': 0.0111, 'grad_norm': 4.881052494049072, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.0077580539509654045, 'loss_2': 0.003292083740234375, 'loss_3': -16.441234588623047, 'loss_4': -0.11355315893888474, 'epoch': 21.95}
{'loss': 0.0065, 'grad_norm': 5.253518104553223, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.004808119963854551, 'loss_2': 0.0017213821411132812, 'loss_3': -16.594200134277344, 'loss_4': 0.2666248381137848, 'epoch': 21.96}
{'loss': 0.009, 'grad_norm': 5.2671380043029785, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.004343527369201183, 'loss_2': 0.004608154296875, 'loss_3': -16.652618408203125, 'loss_4': 0.20987743139266968, 'epoch': 21.97}
{'loss': 0.0781, 'grad_norm': 15.182611465454102, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.07619226723909378, 'loss_2': 0.0019044876098632812, 'loss_3': -16.424320220947266, 'loss_4': 0.4959496259689331, 'epoch': 21.97}
{'loss': 0.0096, 'grad_norm': 7.441975116729736, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.0027952331583946943, 'loss_2': 0.006793975830078125, 'loss_3': -16.536663055419922, 'loss_4': 0.12408535182476044, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 16:50:50,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:50,820 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:28<22:27,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:50:57,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0145079605281353, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011720133014023304, 'eval_loss_2': 0.0027878284454345703, 'eval_loss_3': -18.213655471801758, 'eval_loss_4': 0.44504377245903015, 'epoch': 21.98}
{'loss': 0.0099, 'grad_norm': 6.60657262802124, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.00952035654336214, 'loss_2': 0.000400543212890625, 'loss_3': -16.35140609741211, 'loss_4': 0.44026005268096924, 'epoch': 21.98}
{'loss': 0.0102, 'grad_norm': 7.40338659286499, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.006559096742421389, 'loss_2': 0.003627777099609375, 'loss_3': -16.734397888183594, 'loss_4': 0.3092730939388275, 'epoch': 21.99}
{'loss': 0.0051, 'grad_norm': 4.4950761795043945, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.003694470040500164, 'loss_2': 0.0014476776123046875, 'loss_3': -16.625436782836914, 'loss_4': 0.04633353650569916, 'epoch': 21.99}
{'loss': 0.0173, 'grad_norm': 15.167078971862793, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.014757663011550903, 'loss_2': 0.00254058837890625, 'loss_3': -16.516908645629883, 'loss_4': 0.4816450774669647, 'epoch': 22.0}
{'loss': 0.0098, 'grad_norm': 5.1514410972595215, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.002669933717697859, 'loss_2': 0.007080078125, 'loss_3': -16.645294189453125, 'loss_4': 0.6768046617507935, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 16:50:57,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:57,873 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:36<23:28,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:51:05,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01373824942857027, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.681, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011444803327322006, 'eval_loss_2': 0.002293448895215988, 'eval_loss_3': -18.2026309967041, 'eval_loss_4': 0.5690978169441223, 'epoch': 22.01}
{'loss': 0.0063, 'grad_norm': 4.598496913909912, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.003498626174405217, 'loss_2': 0.002826690673828125, 'loss_3': -16.567115783691406, 'loss_4': 0.41666144132614136, 'epoch': 22.01}
{'loss': 0.0045, 'grad_norm': 4.133046627044678, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.003343317424878478, 'loss_2': 0.0011377334594726562, 'loss_3': -16.606647491455078, 'loss_4': 0.6022827625274658, 'epoch': 22.02}
{'loss': 0.0138, 'grad_norm': 8.747612953186035, 'learning_rate': 8e-06, 'loss_1': 0.008471093140542507, 'loss_2': 0.005359649658203125, 'loss_3': -16.733749389648438, 'loss_4': 0.4638548195362091, 'epoch': 22.02}
{'loss': 0.0045, 'grad_norm': 4.34839391708374, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.00260048802010715, 'loss_2': 0.0018672943115234375, 'loss_3': -16.668045043945312, 'loss_4': 0.6385990977287292, 'epoch': 22.03}
{'loss': 0.0055, 'grad_norm': 4.7737908363342285, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.004699268378317356, 'loss_2': 0.0007572174072265625, 'loss_3': -16.35424041748047, 'loss_4': 0.380526602268219, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 16:51:05,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:05,215 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:43<23:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:12,565 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013845562934875488, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.722, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011208595708012581, 'eval_loss_2': 0.0026369690895080566, 'eval_loss_3': -18.233779907226562, 'eval_loss_4': 0.7055788636207581, 'epoch': 22.03}
{'loss': 0.0023, 'grad_norm': 4.317570209503174, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.0013863021740689874, 'loss_2': 0.0009469985961914062, 'loss_3': -16.574831008911133, 'loss_4': 0.5297442674636841, 'epoch': 22.04}
{'loss': 0.0085, 'grad_norm': 5.044944763183594, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.005638898350298405, 'loss_2': 0.002811431884765625, 'loss_3': -16.535324096679688, 'loss_4': 0.7981694340705872, 'epoch': 22.05}
{'loss': 0.0106, 'grad_norm': 4.599985122680664, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.005660035647451878, 'loss_2': 0.0049591064453125, 'loss_3': -16.623477935791016, 'loss_4': 0.8331584930419922, 'epoch': 22.05}
{'loss': 0.0137, 'grad_norm': 7.743191242218018, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.006959420163184404, 'loss_2': 0.006744384765625, 'loss_3': -16.591352462768555, 'loss_4': 0.5956354141235352, 'epoch': 22.06}
{'loss': 0.0036, 'grad_norm': 4.950717449188232, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.003453195095062256, 'loss_2': 0.00011456012725830078, 'loss_3': -16.59258460998535, 'loss_4': 0.2602002024650574, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 16:51:12,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:12,566 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:50<23:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:19,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012291353195905685, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.724, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009615924209356308, 'eval_loss_2': 0.0026754289865493774, 'eval_loss_3': -18.23387336730957, 'eval_loss_4': 0.7067371606826782, 'epoch': 22.06}
{'loss': 0.0058, 'grad_norm': 4.947775840759277, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.004019361920654774, 'loss_2': 0.0017347335815429688, 'loss_3': -16.59540557861328, 'loss_4': 0.5115513205528259, 'epoch': 22.07}
{'loss': 0.0087, 'grad_norm': 5.499133110046387, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.007308257278054953, 'loss_2': 0.0014390945434570312, 'loss_3': -16.54038429260254, 'loss_4': 0.839808464050293, 'epoch': 22.08}
{'loss': 0.0145, 'grad_norm': 5.978165149688721, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.012807825580239296, 'loss_2': 0.0016803741455078125, 'loss_3': -16.429033279418945, 'loss_4': 0.8101124167442322, 'epoch': 22.08}
{'loss': 0.0079, 'grad_norm': 5.2820258140563965, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.005607029423117638, 'loss_2': 0.0023403167724609375, 'loss_3': -16.536067962646484, 'loss_4': 0.4291948974132538, 'epoch': 22.09}
{'loss': 0.0106, 'grad_norm': 8.339162826538086, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.009228158742189407, 'loss_2': 0.0013723373413085938, 'loss_3': -16.29427719116211, 'loss_4': 0.2599625885486603, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 16:51:19,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:19,910 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:58<23:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:27,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010715782642364502, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.439, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008771573193371296, 'eval_loss_2': 0.0019442103803157806, 'eval_loss_3': -18.23265266418457, 'eval_loss_4': 0.6890064477920532, 'epoch': 22.09}
{'loss': 0.0089, 'grad_norm': 4.226863384246826, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.0026863606180995703, 'loss_2': 0.006237030029296875, 'loss_3': -16.479528427124023, 'loss_4': 0.5794471502304077, 'epoch': 22.1}
{'loss': 0.0135, 'grad_norm': 8.669273376464844, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.011721799150109291, 'loss_2': 0.0017328262329101562, 'loss_3': -16.494850158691406, 'loss_4': 0.5677675008773804, 'epoch': 22.1}
{'loss': 0.0126, 'grad_norm': 5.213447093963623, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.008801979944109917, 'loss_2': 0.00376129150390625, 'loss_3': -16.650981903076172, 'loss_4': 1.006788969039917, 'epoch': 22.11}
{'loss': 0.0042, 'grad_norm': 4.339210033416748, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.00297105242498219, 'loss_2': 0.0011949539184570312, 'loss_3': -16.52165985107422, 'loss_4': 0.29505959153175354, 'epoch': 22.12}
{'loss': 0.0052, 'grad_norm': 4.804664134979248, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.0049665458500385284, 'loss_2': 0.00026416778564453125, 'loss_3': -16.259140014648438, 'loss_4': 0.4716344177722931, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 16:51:27,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:27,261 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:34:05<23:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:34,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01036951132118702, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.568, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008240358904004097, 'eval_loss_2': 0.0021291524171829224, 'eval_loss_3': -18.226303100585938, 'eval_loss_4': 0.6693880558013916, 'epoch': 22.12}
{'loss': 0.0073, 'grad_norm': 5.808243751525879, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.004731336608529091, 'loss_2': 0.002544403076171875, 'loss_3': -16.44711685180664, 'loss_4': 0.6155264377593994, 'epoch': 22.13}
{'loss': 0.0074, 'grad_norm': 4.57039737701416, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.0030906996689736843, 'loss_2': 0.0042877197265625, 'loss_3': -16.413631439208984, 'loss_4': 0.5277553796768188, 'epoch': 22.13}
{'loss': 0.0082, 'grad_norm': 5.060182094573975, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.004877882078289986, 'loss_2': 0.0033111572265625, 'loss_3': -16.50800323486328, 'loss_4': 0.4912312626838684, 'epoch': 22.14}
{'loss': 0.0046, 'grad_norm': 4.844578266143799, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.003766808193176985, 'loss_2': 0.0008649826049804688, 'loss_3': -16.36956024169922, 'loss_4': 0.09243344515562057, 'epoch': 22.15}
{'loss': 0.0736, 'grad_norm': 13.197775840759277, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.07171984016895294, 'loss_2': 0.0019092559814453125, 'loss_3': -16.741485595703125, 'loss_4': 0.8966605067253113, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 16:51:34,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:34,630 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:34:12<23:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:41,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010732587426900864, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.816, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007897462695837021, 'eval_loss_2': 0.0028351247310638428, 'eval_loss_3': -18.230789184570312, 'eval_loss_4': 0.6224761009216309, 'epoch': 22.15}
{'loss': 0.0144, 'grad_norm': 5.562963485717773, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.008361422456800938, 'loss_2': 0.0059967041015625, 'loss_3': -16.555702209472656, 'loss_4': 0.1575072854757309, 'epoch': 22.16}
{'loss': 0.0072, 'grad_norm': 4.949423789978027, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.0036284870002418756, 'loss_2': 0.00357818603515625, 'loss_3': -16.489164352416992, 'loss_4': 0.27202337980270386, 'epoch': 22.16}
{'loss': 0.0183, 'grad_norm': 12.603899002075195, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.018310219049453735, 'loss_2': 2.849102020263672e-05, 'loss_3': -16.566864013671875, 'loss_4': 0.760430097579956, 'epoch': 22.17}
{'loss': 0.0121, 'grad_norm': 5.462441921234131, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.005667501594871283, 'loss_2': 0.006397247314453125, 'loss_3': -16.58261489868164, 'loss_4': 0.4644884467124939, 'epoch': 22.17}
{'loss': 0.0067, 'grad_norm': 6.2908406257629395, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.006058305036276579, 'loss_2': 0.0006814002990722656, 'loss_3': -16.627418518066406, 'loss_4': 0.33603909611701965, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 16:51:41,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:41,975 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:20<23:32,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:51:49,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009829560294747353, 'eval_runtime': 3.9946, 'eval_samples_per_second': 256.349, 'eval_steps_per_second': 4.005, 'eval_loss_1': 0.007065264508128166, 'eval_loss_2': 0.0027642957866191864, 'eval_loss_3': -18.231821060180664, 'eval_loss_4': 0.6152576208114624, 'epoch': 22.18}
{'loss': 0.0107, 'grad_norm': 5.497860908508301, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.007857576943933964, 'loss_2': 0.002857208251953125, 'loss_3': -16.427207946777344, 'loss_4': 0.3902629017829895, 'epoch': 22.19}
{'loss': 0.0145, 'grad_norm': 7.125017166137695, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.009859638288617134, 'loss_2': 0.004638671875, 'loss_3': -16.532148361206055, 'loss_4': 0.5332925319671631, 'epoch': 22.19}
{'loss': 0.0115, 'grad_norm': 5.391274452209473, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.006119103170931339, 'loss_2': 0.005390167236328125, 'loss_3': -16.52272605895996, 'loss_4': 0.2534206509590149, 'epoch': 22.2}
{'loss': 0.0731, 'grad_norm': 18.759857177734375, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.07156357914209366, 'loss_2': 0.00156402587890625, 'loss_3': -16.555591583251953, 'loss_4': 0.5633675456047058, 'epoch': 22.2}
{'loss': 0.0083, 'grad_norm': 6.39066743850708, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.004568277858197689, 'loss_2': 0.0037384033203125, 'loss_3': -16.53270721435547, 'loss_4': 0.8032029271125793, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 16:51:49,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:49,525 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:27<23:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:56,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00938456878066063, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007235300727188587, 'eval_loss_2': 0.0021492689847946167, 'eval_loss_3': -18.225486755371094, 'eval_loss_4': 0.6542473435401917, 'epoch': 22.21}
{'loss': 0.0113, 'grad_norm': 5.395229339599609, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.0073676640167832375, 'loss_2': 0.003887176513671875, 'loss_3': -16.60015296936035, 'loss_4': 0.5600185394287109, 'epoch': 22.22}
{'loss': 0.0034, 'grad_norm': 7.875415802001953, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.003368825651705265, 'loss_2': 3.266334533691406e-05, 'loss_3': -16.64748764038086, 'loss_4': 0.5595090389251709, 'epoch': 22.22}
{'loss': 0.0217, 'grad_norm': 7.80780029296875, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.013084346428513527, 'loss_2': 0.0086212158203125, 'loss_3': -16.680404663085938, 'loss_4': 0.4731978178024292, 'epoch': 22.23}
{'loss': 0.0059, 'grad_norm': 5.000471591949463, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.005693058483302593, 'loss_2': 0.00017642974853515625, 'loss_3': -16.45926284790039, 'loss_4': 0.7020949721336365, 'epoch': 22.23}
{'loss': 0.0212, 'grad_norm': 11.187783241271973, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.013313409872353077, 'loss_2': 0.0078887939453125, 'loss_3': -16.601388931274414, 'loss_4': 0.657556414604187, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 16:51:56,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:56,885 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:35<23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:04,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008785462006926537, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.48, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006529292091727257, 'eval_loss_2': 0.00225616991519928, 'eval_loss_3': -18.225341796875, 'eval_loss_4': 0.6964488625526428, 'epoch': 22.24}
{'loss': 0.0083, 'grad_norm': 5.7203688621521, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.0061528184451162815, 'loss_2': 0.0021762847900390625, 'loss_3': -16.52688980102539, 'loss_4': 0.28438591957092285, 'epoch': 22.24}
{'loss': 0.014, 'grad_norm': 5.226138591766357, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.00726260244846344, 'loss_2': 0.006717681884765625, 'loss_3': -16.56065559387207, 'loss_4': 0.478206992149353, 'epoch': 22.25}
{'loss': 0.0059, 'grad_norm': 4.735026836395264, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.0033037657849490643, 'loss_2': 0.002635955810546875, 'loss_3': -16.645923614501953, 'loss_4': 0.5715688467025757, 'epoch': 22.26}
{'loss': 0.0173, 'grad_norm': 9.813582420349121, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.013240909203886986, 'loss_2': 0.004058837890625, 'loss_3': -16.542417526245117, 'loss_4': 0.12305527180433273, 'epoch': 22.26}
{'loss': 0.006, 'grad_norm': 4.646573543548584, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.003538326360285282, 'loss_2': 0.002445220947265625, 'loss_3': -16.562170028686523, 'loss_4': 0.40126073360443115, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 16:52:04,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:04,240 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:42<22:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:11,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009197762235999107, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0067246402613818645, 'eval_loss_2': 0.0024731233716011047, 'eval_loss_3': -18.213157653808594, 'eval_loss_4': 0.7054495811462402, 'epoch': 22.27}
{'loss': 0.0091, 'grad_norm': 4.682624340057373, 'learning_rate': 7.75e-06, 'loss_1': 0.0027194011490792036, 'loss_2': 0.006427764892578125, 'loss_3': -16.523969650268555, 'loss_4': 0.3393220901489258, 'epoch': 22.27}
{'loss': 0.0055, 'grad_norm': 4.717037677764893, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.0027910079807043076, 'loss_2': 0.0026988983154296875, 'loss_3': -16.30472755432129, 'loss_4': 0.6392826437950134, 'epoch': 22.28}
{'loss': 0.013, 'grad_norm': 6.628971099853516, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.011014603078365326, 'loss_2': 0.0019683837890625, 'loss_3': -16.54660415649414, 'loss_4': 0.6245936155319214, 'epoch': 22.28}
{'loss': 0.0237, 'grad_norm': 9.466957092285156, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.01994965225458145, 'loss_2': 0.00371551513671875, 'loss_3': -16.60016632080078, 'loss_4': 0.5249037742614746, 'epoch': 22.29}
{'loss': 0.0085, 'grad_norm': 5.16334867477417, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.00568162789568305, 'loss_2': 0.002796173095703125, 'loss_3': -16.39259910583496, 'loss_4': 0.5659828782081604, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 16:52:11,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:11,593 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:49<22:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:18,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009925903752446175, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007564786355942488, 'eval_loss_2': 0.002361118793487549, 'eval_loss_3': -18.23648452758789, 'eval_loss_4': 0.738105297088623, 'epoch': 22.3}
{'loss': 0.0073, 'grad_norm': 5.317505359649658, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.005737925413995981, 'loss_2': 0.0015716552734375, 'loss_3': -16.48888397216797, 'loss_4': 0.7061866521835327, 'epoch': 22.3}
{'loss': 0.0047, 'grad_norm': 4.803918838500977, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.0037693462800234556, 'loss_2': 0.0009369850158691406, 'loss_3': -16.443418502807617, 'loss_4': 0.02701808139681816, 'epoch': 22.31}
{'loss': 0.0077, 'grad_norm': 4.563149929046631, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.003336766269057989, 'loss_2': 0.0044097900390625, 'loss_3': -16.39742088317871, 'loss_4': -0.026737354695796967, 'epoch': 22.31}
{'loss': 0.0057, 'grad_norm': 4.707372188568115, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.0052688391879200935, 'loss_2': 0.00047016143798828125, 'loss_3': -16.65137481689453, 'loss_4': 0.4272463917732239, 'epoch': 22.32}
{'loss': 0.0141, 'grad_norm': 9.312524795532227, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.011705493554472923, 'loss_2': 0.002422332763671875, 'loss_3': -16.34194564819336, 'loss_4': 0.3190464675426483, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 16:52:18,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:18,954 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:57<22:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:26,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011372175067663193, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.646, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007425065618008375, 'eval_loss_2': 0.00394710898399353, 'eval_loss_3': -18.22980308532715, 'eval_loss_4': 0.7563453912734985, 'epoch': 22.33}
{'loss': 0.006, 'grad_norm': 5.135872840881348, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.0037073553539812565, 'loss_2': 0.0023174285888671875, 'loss_3': -16.487531661987305, 'loss_4': 0.4963337182998657, 'epoch': 22.33}
{'loss': 0.0069, 'grad_norm': 5.355815887451172, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.0048882002010941505, 'loss_2': 0.002002716064453125, 'loss_3': -16.56240463256836, 'loss_4': 0.2975344657897949, 'epoch': 22.34}
{'loss': 0.0146, 'grad_norm': 6.146540641784668, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.011321913450956345, 'loss_2': 0.003265380859375, 'loss_3': -16.533939361572266, 'loss_4': 0.5562562346458435, 'epoch': 22.34}
{'loss': 0.0039, 'grad_norm': 4.767908096313477, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.003330852836370468, 'loss_2': 0.00060272216796875, 'loss_3': -16.499950408935547, 'loss_4': 0.18253761529922485, 'epoch': 22.35}
{'loss': 0.0168, 'grad_norm': 7.600834369659424, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.015533104538917542, 'loss_2': 0.001247406005859375, 'loss_3': -16.737897872924805, 'loss_4': 0.7520003318786621, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 16:52:26,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:26,308 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:35:04<22:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:33,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011923147365450859, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007066544145345688, 'eval_loss_2': 0.004856601357460022, 'eval_loss_3': -18.232540130615234, 'eval_loss_4': 0.7693390846252441, 'epoch': 22.35}
{'loss': 0.0109, 'grad_norm': 4.995878219604492, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.0047656092792749405, 'loss_2': 0.00615692138671875, 'loss_3': -16.477466583251953, 'loss_4': 0.28053924441337585, 'epoch': 22.36}
{'loss': 0.0164, 'grad_norm': 4.584443092346191, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.006341386586427689, 'loss_2': 0.01003265380859375, 'loss_3': -16.575536727905273, 'loss_4': 0.11208721995353699, 'epoch': 22.37}
{'loss': 0.0075, 'grad_norm': 4.229013919830322, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.00668236892670393, 'loss_2': 0.0008301734924316406, 'loss_3': -16.59269142150879, 'loss_4': 0.5698654651641846, 'epoch': 22.37}
{'loss': 0.0111, 'grad_norm': 5.889591693878174, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.006570632569491863, 'loss_2': 0.00457000732421875, 'loss_3': -16.56427001953125, 'loss_4': 0.3840219974517822, 'epoch': 22.38}
{'loss': 0.0097, 'grad_norm': 7.100564479827881, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.006181851029396057, 'loss_2': 0.00354766845703125, 'loss_3': -16.382614135742188, 'loss_4': 0.3614339828491211, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 16:52:33,663 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:33,663 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:35:11<22:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:41,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012791057117283344, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.568, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00740974023938179, 'eval_loss_2': 0.0053813159465789795, 'eval_loss_3': -18.22162628173828, 'eval_loss_4': 0.7811427116394043, 'epoch': 22.38}
{'loss': 0.0103, 'grad_norm': 5.168879508972168, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.008012285456061363, 'loss_2': 0.0022869110107421875, 'loss_3': -16.408836364746094, 'loss_4': 0.8217123746871948, 'epoch': 22.39}
{'loss': 0.013, 'grad_norm': 5.314942836761475, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.008687520399689674, 'loss_2': 0.004268646240234375, 'loss_3': -16.557281494140625, 'loss_4': 0.4411351978778839, 'epoch': 22.4}
{'loss': 0.0285, 'grad_norm': 14.913657188415527, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.01957799308001995, 'loss_2': 0.0089263916015625, 'loss_3': -16.323631286621094, 'loss_4': 0.6480699181556702, 'epoch': 22.4}
{'loss': 0.0109, 'grad_norm': 4.495551586151123, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.004286045208573341, 'loss_2': 0.00658416748046875, 'loss_3': -16.66932487487793, 'loss_4': 0.5354867577552795, 'epoch': 22.41}
{'loss': 0.0171, 'grad_norm': 5.970227241516113, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.008596431463956833, 'loss_2': 0.00846099853515625, 'loss_3': -16.42202377319336, 'loss_4': 0.32009613513946533, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 16:52:41,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:41,018 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:19<22:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:48,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010688750073313713, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.514, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007224200759083033, 'eval_loss_2': 0.0034645497798919678, 'eval_loss_3': -18.24916648864746, 'eval_loss_4': 0.8528561592102051, 'epoch': 22.41}
{'loss': 0.0235, 'grad_norm': 12.930397987365723, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.016277918592095375, 'loss_2': 0.00717926025390625, 'loss_3': -16.54766273498535, 'loss_4': 0.7439192533493042, 'epoch': 22.42}
{'loss': 0.005, 'grad_norm': 4.750843048095703, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.0043990733101964, 'loss_2': 0.0005965232849121094, 'loss_3': -16.314437866210938, 'loss_4': 0.6234487295150757, 'epoch': 22.42}
{'loss': 0.0042, 'grad_norm': 4.384800434112549, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.0041051884181797504, 'loss_2': 6.198883056640625e-05, 'loss_3': -16.484375, 'loss_4': 1.0858559608459473, 'epoch': 22.43}
{'loss': 0.0099, 'grad_norm': 5.5689167976379395, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.006972467992454767, 'loss_2': 0.0028839111328125, 'loss_3': -16.6101016998291, 'loss_4': 0.7584644556045532, 'epoch': 22.44}
{'loss': 0.0066, 'grad_norm': 5.286175727844238, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.004621567670255899, 'loss_2': 0.0019512176513671875, 'loss_3': -16.538265228271484, 'loss_4': 0.8967387080192566, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 16:52:48,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:48,366 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:26<22:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:55,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010681954212486744, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.97, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00807170383632183, 'eval_loss_2': 0.002610251307487488, 'eval_loss_3': -18.250228881835938, 'eval_loss_4': 0.9179503917694092, 'epoch': 22.44}
{'loss': 0.0066, 'grad_norm': 5.255234718322754, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.006546060089021921, 'loss_2': 8.368492126464844e-05, 'loss_3': -16.579181671142578, 'loss_4': 0.9270346164703369, 'epoch': 22.45}
{'loss': 0.0313, 'grad_norm': 18.25828742980957, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.02954362891614437, 'loss_2': 0.0017404556274414062, 'loss_3': -16.46792984008789, 'loss_4': 0.8150336742401123, 'epoch': 22.45}
{'loss': 0.0074, 'grad_norm': 6.052778720855713, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.0068171885795891285, 'loss_2': 0.000621795654296875, 'loss_3': -16.46794891357422, 'loss_4': 0.7590237855911255, 'epoch': 22.46}
{'loss': 0.0087, 'grad_norm': 6.115825653076172, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.008380317129194736, 'loss_2': 0.0003352165222167969, 'loss_3': -16.564117431640625, 'loss_4': 1.1146790981292725, 'epoch': 22.47}
{'loss': 0.0089, 'grad_norm': 5.507069110870361, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.007864298298954964, 'loss_2': 0.0010271072387695312, 'loss_3': -16.572452545166016, 'loss_4': 0.6150211095809937, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 16:52:55,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:55,726 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:33<22:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:03,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011417314410209656, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.386, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008506014943122864, 'eval_loss_2': 0.002911299467086792, 'eval_loss_3': -18.26706314086914, 'eval_loss_4': 0.9640218019485474, 'epoch': 22.47}
{'loss': 0.0077, 'grad_norm': 5.209521293640137, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.00751044787466526, 'loss_2': 0.00016427040100097656, 'loss_3': -16.505382537841797, 'loss_4': 0.9212052822113037, 'epoch': 22.48}
{'loss': 0.0057, 'grad_norm': 4.599413871765137, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.004087223205715418, 'loss_2': 0.0016622543334960938, 'loss_3': -16.703716278076172, 'loss_4': 0.7788785099983215, 'epoch': 22.48}
{'loss': 0.0067, 'grad_norm': 4.9969329833984375, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.006072713062167168, 'loss_2': 0.0006437301635742188, 'loss_3': -16.38170051574707, 'loss_4': 1.0737109184265137, 'epoch': 22.49}
{'loss': 0.0126, 'grad_norm': 6.012094974517822, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.00963276345282793, 'loss_2': 0.0029754638671875, 'loss_3': -16.54884910583496, 'loss_4': 0.9851258993148804, 'epoch': 22.49}
{'loss': 0.0124, 'grad_norm': 4.629789352416992, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.003347311168909073, 'loss_2': 0.0090484619140625, 'loss_3': -16.685775756835938, 'loss_4': 0.8185017108917236, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 16:53:03,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:03,080 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:41<22:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:10,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013033885508775711, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009440560825169086, 'eval_loss_2': 0.0035933256149291992, 'eval_loss_3': -18.260501861572266, 'eval_loss_4': 0.959490954875946, 'epoch': 22.5}
{'loss': 0.0076, 'grad_norm': 5.081913948059082, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.006165138445794582, 'loss_2': 0.001468658447265625, 'loss_3': -16.467021942138672, 'loss_4': 0.7430813312530518, 'epoch': 22.51}
{'loss': 0.008, 'grad_norm': 5.0927653312683105, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.006837737280875444, 'loss_2': 0.0011749267578125, 'loss_3': -16.616737365722656, 'loss_4': 1.1376590728759766, 'epoch': 22.51}
{'loss': 0.0161, 'grad_norm': 7.188035011291504, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.01350596733391285, 'loss_2': 0.00258636474609375, 'loss_3': -16.566131591796875, 'loss_4': 1.2065409421920776, 'epoch': 22.52}
{'loss': 0.0595, 'grad_norm': 27.32158851623535, 'learning_rate': 7.5e-06, 'loss_1': 0.05389130860567093, 'loss_2': 0.005626678466796875, 'loss_3': -16.63108253479004, 'loss_4': 0.9651389718055725, 'epoch': 22.52}
{'loss': 0.0065, 'grad_norm': 5.063574314117432, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.005608106032013893, 'loss_2': 0.0008802413940429688, 'loss_3': -16.35354232788086, 'loss_4': 0.9498136043548584, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 16:53:10,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:10,434 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:48<22:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:17,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011615244671702385, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.494, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008595449849963188, 'eval_loss_2': 0.0030197948217391968, 'eval_loss_3': -18.24691390991211, 'eval_loss_4': 0.8854008913040161, 'epoch': 22.53}
{'loss': 0.0095, 'grad_norm': 5.400475025177002, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.007592903915792704, 'loss_2': 0.0019130706787109375, 'loss_3': -16.489986419677734, 'loss_4': 0.36309099197387695, 'epoch': 22.53}
{'loss': 0.016, 'grad_norm': 4.994823932647705, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.006797518581151962, 'loss_2': 0.00917816162109375, 'loss_3': -16.374256134033203, 'loss_4': 0.052962034940719604, 'epoch': 22.54}
{'loss': 0.0102, 'grad_norm': 7.142270565032959, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.0064776502549648285, 'loss_2': 0.0037097930908203125, 'loss_3': -16.414230346679688, 'loss_4': 0.6932132244110107, 'epoch': 22.55}
{'loss': 0.0086, 'grad_norm': 5.485263824462891, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.006061631254851818, 'loss_2': 0.0025482177734375, 'loss_3': -16.50530242919922, 'loss_4': 0.8574652671813965, 'epoch': 22.55}
{'loss': 0.0077, 'grad_norm': 4.577864170074463, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.004291645251214504, 'loss_2': 0.0033721923828125, 'loss_3': -16.41036605834961, 'loss_4': 0.893361508846283, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 16:53:17,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:17,793 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:55<22:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:25,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010011928156018257, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007435516454279423, 'eval_loss_2': 0.0025764107704162598, 'eval_loss_3': -18.215545654296875, 'eval_loss_4': 0.7398392558097839, 'epoch': 22.56}
{'loss': 0.0078, 'grad_norm': 5.931957721710205, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.007253995630890131, 'loss_2': 0.0005083084106445312, 'loss_3': -16.65540313720703, 'loss_4': 0.8285722136497498, 'epoch': 22.56}
{'loss': 0.0068, 'grad_norm': 4.880009174346924, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.0028346434701234102, 'loss_2': 0.003997802734375, 'loss_3': -16.341632843017578, 'loss_4': 0.48343396186828613, 'epoch': 22.57}
{'loss': 0.0084, 'grad_norm': 4.656496524810791, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.004212612751871347, 'loss_2': 0.00417327880859375, 'loss_3': -16.45999526977539, 'loss_4': 0.5512988567352295, 'epoch': 22.58}
{'loss': 0.0078, 'grad_norm': 5.097097873687744, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.006037295795977116, 'loss_2': 0.0017986297607421875, 'loss_3': -16.438068389892578, 'loss_4': 0.9013799428939819, 'epoch': 22.58}
{'loss': 0.005, 'grad_norm': 4.439635753631592, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.0031393845565617085, 'loss_2': 0.0018482208251953125, 'loss_3': -16.364349365234375, 'loss_4': 0.49998098611831665, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 16:53:25,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:25,154 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:36:03<22:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:32,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009634873829782009, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007292176131159067, 'eval_loss_2': 0.0023426972329616547, 'eval_loss_3': -18.20537567138672, 'eval_loss_4': 0.6448233723640442, 'epoch': 22.59}
{'loss': 0.0081, 'grad_norm': 5.310495853424072, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.0074391793459653854, 'loss_2': 0.0006494522094726562, 'loss_3': -16.3233642578125, 'loss_4': 0.7114455103874207, 'epoch': 22.59}
{'loss': 0.0136, 'grad_norm': 4.487166881561279, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.006435069255530834, 'loss_2': 0.007152557373046875, 'loss_3': -16.40991973876953, 'loss_4': 0.6104629039764404, 'epoch': 22.6}
{'loss': 0.0045, 'grad_norm': 5.279567718505859, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.004025714471936226, 'loss_2': 0.00046253204345703125, 'loss_3': -16.549358367919922, 'loss_4': 0.5394365191459656, 'epoch': 22.6}
{'loss': 0.0054, 'grad_norm': 5.039034843444824, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.005250769667327404, 'loss_2': 0.00014472007751464844, 'loss_3': -16.446205139160156, 'loss_4': 0.24634970724582672, 'epoch': 22.61}
{'loss': 0.0133, 'grad_norm': 6.850180625915527, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.009192046709358692, 'loss_2': 0.004077911376953125, 'loss_3': -16.567914962768555, 'loss_4': 0.2960112690925598, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 16:53:32,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:32,517 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:36:10<21:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:39,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009313570335507393, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0070771523751318455, 'eval_loss_2': 0.0022364184260368347, 'eval_loss_3': -18.209917068481445, 'eval_loss_4': 0.5697933435440063, 'epoch': 22.62}
{'loss': 0.0096, 'grad_norm': 5.405156135559082, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.00524439150467515, 'loss_2': 0.0043792724609375, 'loss_3': -16.608369827270508, 'loss_4': 0.5565318465232849, 'epoch': 22.62}
{'loss': 0.0111, 'grad_norm': 7.928820610046387, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.007192781660705805, 'loss_2': 0.00392913818359375, 'loss_3': -16.534164428710938, 'loss_4': 0.3360857367515564, 'epoch': 22.63}
{'loss': 0.0101, 'grad_norm': 5.293970584869385, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.006714205723255873, 'loss_2': 0.003360748291015625, 'loss_3': -16.422080993652344, 'loss_4': 0.5239238739013672, 'epoch': 22.63}
{'loss': 0.0245, 'grad_norm': 12.332683563232422, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.023278113454580307, 'loss_2': 0.0012035369873046875, 'loss_3': -16.402603149414062, 'loss_4': 0.6505749225616455, 'epoch': 22.64}
{'loss': 0.005, 'grad_norm': 4.740721225738525, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.004004769958555698, 'loss_2': 0.00098419189453125, 'loss_3': -16.466297149658203, 'loss_4': 0.5634815692901611, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 16:53:39,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:39,874 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:18<21:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:47,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00928327813744545, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007478001527488232, 'eval_loss_2': 0.0018052756786346436, 'eval_loss_3': -18.19144630432129, 'eval_loss_4': 0.49103444814682007, 'epoch': 22.65}
{'loss': 0.0087, 'grad_norm': 4.465841770172119, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.003330509876832366, 'loss_2': 0.005374908447265625, 'loss_3': -16.650985717773438, 'loss_4': 0.5451942086219788, 'epoch': 22.65}
{'loss': 0.0087, 'grad_norm': 6.156074523925781, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.006900631356984377, 'loss_2': 0.0018033981323242188, 'loss_3': -16.424728393554688, 'loss_4': 0.41668543219566345, 'epoch': 22.66}
{'loss': 0.0171, 'grad_norm': 9.819316864013672, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.016295943409204483, 'loss_2': 0.0008220672607421875, 'loss_3': -16.402740478515625, 'loss_4': 0.4651055335998535, 'epoch': 22.66}
{'loss': 0.0095, 'grad_norm': 5.215960502624512, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.006199979688972235, 'loss_2': 0.003307342529296875, 'loss_3': -16.46625328063965, 'loss_4': 0.3747466504573822, 'epoch': 22.67}
{'loss': 0.0099, 'grad_norm': 6.104212284088135, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.008165259845554829, 'loss_2': 0.001773834228515625, 'loss_3': -16.344467163085938, 'loss_4': 0.10378649830818176, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 16:53:47,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:47,228 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:25<21:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:54,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009873413480818272, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007085525430738926, 'eval_loss_2': 0.0027878880500793457, 'eval_loss_3': -18.198081970214844, 'eval_loss_4': 0.37457019090652466, 'epoch': 22.67}
{'loss': 0.0107, 'grad_norm': 4.62009334564209, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.003167931456118822, 'loss_2': 0.007556915283203125, 'loss_3': -16.61852264404297, 'loss_4': 0.3591892123222351, 'epoch': 22.68}
{'loss': 0.0036, 'grad_norm': 4.4527764320373535, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.0033123597968369722, 'loss_2': 0.0002586841583251953, 'loss_3': -16.47757339477539, 'loss_4': 0.5122820138931274, 'epoch': 22.69}
{'loss': 0.0067, 'grad_norm': 5.648216247558594, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.0065141720697283745, 'loss_2': 0.00014960765838623047, 'loss_3': -16.66860008239746, 'loss_4': 0.32382169365882874, 'epoch': 22.69}
{'loss': 0.0167, 'grad_norm': 10.133971214294434, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.016366630792617798, 'loss_2': 0.0002906322479248047, 'loss_3': -16.508731842041016, 'loss_4': 0.030151166021823883, 'epoch': 22.7}
{'loss': 0.003, 'grad_norm': 4.842245578765869, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.002828268799930811, 'loss_2': 0.00021517276763916016, 'loss_3': -16.644594192504883, 'loss_4': 0.2878263294696808, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 16:53:54,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:54,576 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:32<21:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:01,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009277857840061188, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.623, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007468111347407103, 'eval_loss_2': 0.0018097460269927979, 'eval_loss_3': -18.212697982788086, 'eval_loss_4': 0.27904006838798523, 'epoch': 22.7}
{'loss': 0.0157, 'grad_norm': 7.971837997436523, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.011840864084661007, 'loss_2': 0.00385284423828125, 'loss_3': -16.354639053344727, 'loss_4': -0.28874021768569946, 'epoch': 22.71}
{'loss': 0.019, 'grad_norm': 7.842986583709717, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.013189895078539848, 'loss_2': 0.005859375, 'loss_3': -16.479158401489258, 'loss_4': 0.39917826652526855, 'epoch': 22.72}
{'loss': 0.0136, 'grad_norm': 10.105453491210938, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.011713938787579536, 'loss_2': 0.001911163330078125, 'loss_3': -16.733612060546875, 'loss_4': 0.34545326232910156, 'epoch': 22.72}
{'loss': 0.0069, 'grad_norm': 5.4727888107299805, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.005414492450654507, 'loss_2': 0.0014591217041015625, 'loss_3': -16.436046600341797, 'loss_4': 0.48142844438552856, 'epoch': 22.73}
{'loss': 0.0134, 'grad_norm': 4.382538318634033, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.0022911166306585073, 'loss_2': 0.0111083984375, 'loss_3': -16.747865676879883, 'loss_4': 0.14917701482772827, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 16:54:01,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:01,923 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:40<21:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:09,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009456822648644447, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.303, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007604340091347694, 'eval_loss_2': 0.001852482557296753, 'eval_loss_3': -18.22046661376953, 'eval_loss_4': 0.21039773523807526, 'epoch': 22.73}
{'loss': 0.0111, 'grad_norm': 5.651853084564209, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.007730869576334953, 'loss_2': 0.0034046173095703125, 'loss_3': -16.40583038330078, 'loss_4': 0.08863714337348938, 'epoch': 22.74}
{'loss': 0.0063, 'grad_norm': 4.757041931152344, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.004459548741579056, 'loss_2': 0.0018014907836914062, 'loss_3': -16.765119552612305, 'loss_4': 0.41391217708587646, 'epoch': 22.74}
{'loss': 0.0114, 'grad_norm': 5.958812713623047, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.009246871806681156, 'loss_2': 0.00213623046875, 'loss_3': -16.477603912353516, 'loss_4': 0.237684965133667, 'epoch': 22.75}
{'loss': 0.0098, 'grad_norm': 6.418205738067627, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.009170040488243103, 'loss_2': 0.0006465911865234375, 'loss_3': -16.541465759277344, 'loss_4': 0.3302749991416931, 'epoch': 22.76}
{'loss': 0.009, 'grad_norm': 5.108607769012451, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.003959347493946552, 'loss_2': 0.0050811767578125, 'loss_3': -16.369476318359375, 'loss_4': 0.30636075139045715, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 16:54:09,280 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:09,280 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:47<21:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:16,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010649052448570728, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.648, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007686284836381674, 'eval_loss_2': 0.002962768077850342, 'eval_loss_3': -18.22036361694336, 'eval_loss_4': 0.1628834456205368, 'epoch': 22.76}
{'loss': 0.0055, 'grad_norm': 4.859688758850098, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.004856295883655548, 'loss_2': 0.0006198883056640625, 'loss_3': -16.632923126220703, 'loss_4': -0.05524243041872978, 'epoch': 22.77}
{'loss': 0.0094, 'grad_norm': 4.957346439361572, 'learning_rate': 7.25e-06, 'loss_1': 0.005028253886848688, 'loss_2': 0.004390716552734375, 'loss_3': -16.59811019897461, 'loss_4': 0.2236958146095276, 'epoch': 22.77}
{'loss': 0.0059, 'grad_norm': 4.490750312805176, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.0028375338297337294, 'loss_2': 0.003017425537109375, 'loss_3': -16.59022331237793, 'loss_4': -0.10299442708492279, 'epoch': 22.78}
{'loss': 0.0079, 'grad_norm': 4.710699081420898, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.0020686902571469545, 'loss_2': 0.00579071044921875, 'loss_3': -16.390138626098633, 'loss_4': 0.15119577944278717, 'epoch': 22.78}
{'loss': 0.0038, 'grad_norm': 4.907027244567871, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.0036701662465929985, 'loss_2': 9.047985076904297e-05, 'loss_3': -16.303844451904297, 'loss_4': 0.17718914151191711, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 16:54:16,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:16,643 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:54<21:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:23,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010500321164727211, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.656, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007789174560457468, 'eval_loss_2': 0.0027111470699310303, 'eval_loss_3': -18.228567123413086, 'eval_loss_4': 0.15474896132946014, 'epoch': 22.79}
{'loss': 0.0848, 'grad_norm': 19.27318000793457, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.07414022088050842, 'loss_2': 0.0106658935546875, 'loss_3': -16.58731460571289, 'loss_4': 0.606606662273407, 'epoch': 22.8}
{'loss': 0.0044, 'grad_norm': 4.883406639099121, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.004206886515021324, 'loss_2': 0.00021028518676757812, 'loss_3': -16.481815338134766, 'loss_4': -0.11905119568109512, 'epoch': 22.8}
{'loss': 0.0124, 'grad_norm': 7.271747589111328, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.009964761324226856, 'loss_2': 0.0024738311767578125, 'loss_3': -16.542795181274414, 'loss_4': 0.15352584421634674, 'epoch': 22.81}
{'loss': 0.0077, 'grad_norm': 6.403381824493408, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.006460810080170631, 'loss_2': 0.001190185546875, 'loss_3': -16.614608764648438, 'loss_4': 0.3205764889717102, 'epoch': 22.81}
{'loss': 0.0066, 'grad_norm': 4.577383995056152, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.003737709252163768, 'loss_2': 0.00284576416015625, 'loss_3': -16.51993179321289, 'loss_4': 0.1872340887784958, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 16:54:23,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:23,994 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:37:02<21:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:31,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010466223582625389, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.237, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00801546685397625, 'eval_loss_2': 0.0024507567286491394, 'eval_loss_3': -18.226652145385742, 'eval_loss_4': 0.12902823090553284, 'epoch': 22.82}
{'loss': 0.0039, 'grad_norm': 4.736109733581543, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.0036570164375007153, 'loss_2': 0.00028896331787109375, 'loss_3': -16.540077209472656, 'loss_4': 0.2394048273563385, 'epoch': 22.83}
{'loss': 0.0076, 'grad_norm': 4.785308837890625, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.002898408565670252, 'loss_2': 0.004673004150390625, 'loss_3': -16.411279678344727, 'loss_4': 0.005904659628868103, 'epoch': 22.83}
{'loss': 0.0096, 'grad_norm': 4.603997707366943, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.00387625303119421, 'loss_2': 0.00574493408203125, 'loss_3': -16.581035614013672, 'loss_4': 0.1859668791294098, 'epoch': 22.84}
{'loss': 0.0068, 'grad_norm': 4.835535049438477, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.003109668381512165, 'loss_2': 0.003704071044921875, 'loss_3': -16.6909122467041, 'loss_4': -0.27127355337142944, 'epoch': 22.84}
{'loss': 0.0062, 'grad_norm': 4.869959831237793, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.003331704530864954, 'loss_2': 0.00290679931640625, 'loss_3': -16.559574127197266, 'loss_4': -0.1389356553554535, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 16:54:31,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:31,349 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:37:09<21:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:38,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0108915064483881, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.479, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008310596458613873, 'eval_loss_2': 0.0025809109210968018, 'eval_loss_3': -18.229015350341797, 'eval_loss_4': 0.12705440819263458, 'epoch': 22.85}
{'loss': 0.0051, 'grad_norm': 4.610706329345703, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.004522839095443487, 'loss_2': 0.0005893707275390625, 'loss_3': -16.340890884399414, 'loss_4': -0.06926825642585754, 'epoch': 22.85}
{'loss': 0.0057, 'grad_norm': 4.567802906036377, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.0038927500136196613, 'loss_2': 0.0018205642700195312, 'loss_3': -16.635560989379883, 'loss_4': 0.13542816042900085, 'epoch': 22.86}
{'loss': 0.0097, 'grad_norm': 5.272405624389648, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.005208933260291815, 'loss_2': 0.004512786865234375, 'loss_3': -16.453655242919922, 'loss_4': -0.026730254292488098, 'epoch': 22.87}
{'loss': 0.0103, 'grad_norm': 5.044246196746826, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.0036073450464755297, 'loss_2': 0.00673675537109375, 'loss_3': -16.55795669555664, 'loss_4': -0.11473837494850159, 'epoch': 22.87}
{'loss': 0.0055, 'grad_norm': 4.8433637619018555, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.0033019520342350006, 'loss_2': 0.00215911865234375, 'loss_3': -16.439199447631836, 'loss_4': 0.1696169078350067, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 16:54:38,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:38,696 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:37:16<21:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:46,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010556444525718689, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008231251500546932, 'eval_loss_2': 0.002325192093849182, 'eval_loss_3': -18.214824676513672, 'eval_loss_4': 0.048895463347435, 'epoch': 22.88}
{'loss': 0.0161, 'grad_norm': 6.344034194946289, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.009640965610742569, 'loss_2': 0.006496429443359375, 'loss_3': -16.62786102294922, 'loss_4': 0.47765839099884033, 'epoch': 22.88}
{'loss': 0.0053, 'grad_norm': 4.651819705963135, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.0036542636808007956, 'loss_2': 0.001621246337890625, 'loss_3': -16.680837631225586, 'loss_4': -0.1096004843711853, 'epoch': 22.89}
{'loss': 0.0073, 'grad_norm': 4.923413276672363, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.003885797690600157, 'loss_2': 0.003429412841796875, 'loss_3': -16.458471298217773, 'loss_4': 0.15610042214393616, 'epoch': 22.9}
{'loss': 0.004, 'grad_norm': 4.275644779205322, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.003188173985108733, 'loss_2': 0.0008058547973632812, 'loss_3': -16.650619506835938, 'loss_4': -0.3425602316856384, 'epoch': 22.9}
{'loss': 0.0065, 'grad_norm': 5.613640308380127, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.005875068251043558, 'loss_2': 0.0006737709045410156, 'loss_3': -16.723451614379883, 'loss_4': 0.15004558861255646, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 16:54:46,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:46,048 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:24<21:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:53,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009991077706217766, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00770349707454443, 'eval_loss_2': 0.0022875815629959106, 'eval_loss_3': -18.22333526611328, 'eval_loss_4': -0.001721944659948349, 'epoch': 22.91}
{'loss': 0.0086, 'grad_norm': 6.296063423156738, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.004822399467229843, 'loss_2': 0.0037860870361328125, 'loss_3': -16.6018123626709, 'loss_4': -0.3170677423477173, 'epoch': 22.91}
{'loss': 0.0101, 'grad_norm': 6.057516098022461, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.007976100780069828, 'loss_2': 0.0021686553955078125, 'loss_3': -16.614601135253906, 'loss_4': -0.25835198163986206, 'epoch': 22.92}
{'loss': 0.0074, 'grad_norm': 5.551723480224609, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.003623955650255084, 'loss_2': 0.003818511962890625, 'loss_3': -16.59622573852539, 'loss_4': 0.1490943431854248, 'epoch': 22.92}
{'loss': 0.0326, 'grad_norm': 16.010379791259766, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.02621881663799286, 'loss_2': 0.00640106201171875, 'loss_3': -16.485309600830078, 'loss_4': -0.08576184511184692, 'epoch': 22.93}
{'loss': 0.0035, 'grad_norm': 4.650404930114746, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.0012943004257977009, 'loss_2': 0.00215911865234375, 'loss_3': -16.67241668701172, 'loss_4': 0.22056283056735992, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 16:54:53,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:53,397 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:31<20:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:00,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009815833531320095, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007708661258220673, 'eval_loss_2': 0.002107173204421997, 'eval_loss_3': -18.194683074951172, 'eval_loss_4': 0.003973487764596939, 'epoch': 22.94}
{'loss': 0.0096, 'grad_norm': 5.488542079925537, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.005315528716892004, 'loss_2': 0.0042724609375, 'loss_3': -16.6086483001709, 'loss_4': 0.01361064612865448, 'epoch': 22.94}
{'loss': 0.0062, 'grad_norm': 4.967127323150635, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.004379038233309984, 'loss_2': 0.0018291473388671875, 'loss_3': -16.49652099609375, 'loss_4': 0.16895738244056702, 'epoch': 22.95}
{'loss': 0.0044, 'grad_norm': 5.2141008377075195, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.004052503500133753, 'loss_2': 0.0003871917724609375, 'loss_3': -16.647857666015625, 'loss_4': -0.1688409149646759, 'epoch': 22.95}
{'loss': 0.0092, 'grad_norm': 5.023055553436279, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.007130174897611141, 'loss_2': 0.00211334228515625, 'loss_3': -16.607070922851562, 'loss_4': 0.1425803303718567, 'epoch': 22.96}
{'loss': 0.0119, 'grad_norm': 5.48429012298584, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.004516017623245716, 'loss_2': 0.00736236572265625, 'loss_3': -16.363128662109375, 'loss_4': -0.13118374347686768, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 16:55:00,744 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:00,744 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:38<20:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:08,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010183688253164291, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.683, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007904751226305962, 'eval_loss_2': 0.002278938889503479, 'eval_loss_3': -18.19210433959961, 'eval_loss_4': 0.02643275447189808, 'epoch': 22.97}
{'loss': 0.0133, 'grad_norm': 5.436916828155518, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.005838723853230476, 'loss_2': 0.00749969482421875, 'loss_3': -16.632474899291992, 'loss_4': -0.33471551537513733, 'epoch': 22.97}
{'loss': 0.0146, 'grad_norm': 12.029986381530762, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.01420362014323473, 'loss_2': 0.00041174888610839844, 'loss_3': -16.613731384277344, 'loss_4': -0.20319625735282898, 'epoch': 22.98}
{'loss': 0.0158, 'grad_norm': 4.860544681549072, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.009635779075324535, 'loss_2': 0.00615692138671875, 'loss_3': -16.45176887512207, 'loss_4': -0.06922123581171036, 'epoch': 22.98}
{'loss': 0.0121, 'grad_norm': 5.20980167388916, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.005216110963374376, 'loss_2': 0.0068511962890625, 'loss_3': -16.557357788085938, 'loss_4': -0.11723083257675171, 'epoch': 22.99}
{'loss': 0.0222, 'grad_norm': 7.712955951690674, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.01712617091834545, 'loss_2': 0.005046844482421875, 'loss_3': -16.523509979248047, 'loss_4': -0.14258162677288055, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 16:55:08,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:08,071 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:45<20:21,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:55:15,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009926501661539078, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.339, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007389117497950792, 'eval_loss_2': 0.0025373846292495728, 'eval_loss_3': -18.18938446044922, 'eval_loss_4': 0.09468057006597519, 'epoch': 22.99}
{'loss': 0.0051, 'grad_norm': 6.276818752288818, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.0017511624610051513, 'loss_2': 0.003299713134765625, 'loss_3': -16.417377471923828, 'loss_4': 0.04080209136009216, 'epoch': 23.0}
{'loss': 0.0097, 'grad_norm': 4.113570213317871, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.004429065156728029, 'loss_2': 0.005245208740234375, 'loss_3': -16.582904815673828, 'loss_4': 0.11586914211511612, 'epoch': 23.01}
{'loss': 0.0097, 'grad_norm': 4.691739082336426, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.005772372242063284, 'loss_2': 0.003887176513671875, 'loss_3': -16.68777847290039, 'loss_4': 0.11851251125335693, 'epoch': 23.01}
{'loss': 0.0091, 'grad_norm': 4.870683193206787, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.003327466081827879, 'loss_2': 0.00579071044921875, 'loss_3': -16.610504150390625, 'loss_4': 0.1054488867521286, 'epoch': 23.02}
{'loss': 0.0111, 'grad_norm': 4.449474334716797, 'learning_rate': 7e-06, 'loss_1': 0.004722331650555134, 'loss_2': 0.00634002685546875, 'loss_3': -16.590503692626953, 'loss_4': 0.09396672248840332, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 16:55:15,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:15,132 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:53<20:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:22,485 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011275445111095905, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007987653836607933, 'eval_loss_2': 0.003287792205810547, 'eval_loss_3': -18.193927764892578, 'eval_loss_4': 0.15739411115646362, 'epoch': 23.02}
{'loss': 0.0096, 'grad_norm': 4.974735736846924, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.007935142144560814, 'loss_2': 0.001636505126953125, 'loss_3': -16.53445816040039, 'loss_4': -0.11548483371734619, 'epoch': 23.03}
{'loss': 0.0227, 'grad_norm': 7.162112712860107, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.018476437777280807, 'loss_2': 0.00421905517578125, 'loss_3': -16.538244247436523, 'loss_4': -0.23868338763713837, 'epoch': 23.03}
{'loss': 0.0078, 'grad_norm': 4.636394500732422, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.003561967285349965, 'loss_2': 0.00428009033203125, 'loss_3': -16.538724899291992, 'loss_4': -0.20149904489517212, 'epoch': 23.04}
{'loss': 0.006, 'grad_norm': 5.007919788360596, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.004844193812459707, 'loss_2': 0.00112152099609375, 'loss_3': -16.620464324951172, 'loss_4': -0.16749323904514313, 'epoch': 23.05}
{'loss': 0.0079, 'grad_norm': 4.576880931854248, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.004461652133613825, 'loss_2': 0.003459930419921875, 'loss_3': -16.406179428100586, 'loss_4': 0.3719117045402527, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 16:55:22,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:22,485 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:38:00<20:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:29,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013048439286649227, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008226498030126095, 'eval_loss_2': 0.004821941256523132, 'eval_loss_3': -18.20795440673828, 'eval_loss_4': 0.1865989863872528, 'epoch': 23.05}
{'loss': 0.0055, 'grad_norm': 4.5674872398376465, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.00430923281237483, 'loss_2': 0.0012254714965820312, 'loss_3': -16.76643943786621, 'loss_4': -0.14311595261096954, 'epoch': 23.06}
{'loss': 0.0111, 'grad_norm': 5.953771591186523, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.0075662098824977875, 'loss_2': 0.003543853759765625, 'loss_3': -16.65866470336914, 'loss_4': 0.3068169355392456, 'epoch': 23.06}
{'loss': 0.0044, 'grad_norm': 4.92766809463501, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.0039902846328914165, 'loss_2': 0.0003757476806640625, 'loss_3': -16.678720474243164, 'loss_4': 0.2535651624202728, 'epoch': 23.07}
{'loss': 0.0189, 'grad_norm': 10.802665710449219, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.012175128795206547, 'loss_2': 0.006744384765625, 'loss_3': -16.558300018310547, 'loss_4': 0.047935932874679565, 'epoch': 23.08}
{'loss': 0.0122, 'grad_norm': 5.24537467956543, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.005861957557499409, 'loss_2': 0.0063018798828125, 'loss_3': -16.631954193115234, 'loss_4': -0.07077330350875854, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 16:55:29,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:29,845 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:38:08<20:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:37,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013552427291870117, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.021, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008168041706085205, 'eval_loss_2': 0.005384385585784912, 'eval_loss_3': -18.224571228027344, 'eval_loss_4': 0.21278367936611176, 'epoch': 23.08}
{'loss': 0.01, 'grad_norm': 4.817058563232422, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.002215096727013588, 'loss_2': 0.00775146484375, 'loss_3': -16.833065032958984, 'loss_4': 0.0653388500213623, 'epoch': 23.09}
{'loss': 0.0133, 'grad_norm': 7.466148376464844, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.012271015904843807, 'loss_2': 0.0010585784912109375, 'loss_3': -16.440906524658203, 'loss_4': 0.10575252771377563, 'epoch': 23.09}
{'loss': 0.0071, 'grad_norm': 4.729928493499756, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.0029458634089678526, 'loss_2': 0.004169464111328125, 'loss_3': -16.66063117980957, 'loss_4': -0.031056735664606094, 'epoch': 23.1}
{'loss': 0.0165, 'grad_norm': 5.470221996307373, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.004688575863838196, 'loss_2': 0.0118560791015625, 'loss_3': -16.596500396728516, 'loss_4': -0.027412209659814835, 'epoch': 23.1}
{'loss': 0.0113, 'grad_norm': 4.612189292907715, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.0046811397187411785, 'loss_2': 0.0066375732421875, 'loss_3': -16.366600036621094, 'loss_4': 0.17371223866939545, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 16:55:37,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:37,206 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:38:15<20:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:44,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01308172382414341, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008126283064484596, 'eval_loss_2': 0.0049554407596588135, 'eval_loss_3': -18.249725341796875, 'eval_loss_4': 0.2642589211463928, 'epoch': 23.11}
{'loss': 0.0203, 'grad_norm': 8.582781791687012, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.013141976669430733, 'loss_2': 0.00719451904296875, 'loss_3': -16.64291763305664, 'loss_4': 0.14816506206989288, 'epoch': 23.12}
{'loss': 0.0068, 'grad_norm': 4.136175632476807, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.003431941382586956, 'loss_2': 0.003337860107421875, 'loss_3': -16.63118553161621, 'loss_4': 0.2170879989862442, 'epoch': 23.12}
{'loss': 0.0064, 'grad_norm': 5.19234561920166, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.00564687279984355, 'loss_2': 0.0007386207580566406, 'loss_3': -16.75467872619629, 'loss_4': 0.5073695778846741, 'epoch': 23.13}
{'loss': 0.0081, 'grad_norm': 4.683587551116943, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.007484594825655222, 'loss_2': 0.0005855560302734375, 'loss_3': -16.521142959594727, 'loss_4': 0.0007946118712425232, 'epoch': 23.13}
{'loss': 0.078, 'grad_norm': 23.93832015991211, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.07430292665958405, 'loss_2': 0.003662109375, 'loss_3': -16.672000885009766, 'loss_4': 0.5277121067047119, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 16:55:44,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:44,555 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:22<20:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:51,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010256368666887283, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.552, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007449910044670105, 'eval_loss_2': 0.0028064586222171783, 'eval_loss_3': -18.256717681884766, 'eval_loss_4': 0.27015405893325806, 'epoch': 23.14}
{'loss': 0.0107, 'grad_norm': 6.37811279296875, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.009301808662712574, 'loss_2': 0.0014247894287109375, 'loss_3': -16.53289794921875, 'loss_4': 0.6183812022209167, 'epoch': 23.15}
{'loss': 0.0105, 'grad_norm': 4.796442031860352, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.004330246709287167, 'loss_2': 0.0061492919921875, 'loss_3': -16.74253273010254, 'loss_4': 0.29556670784950256, 'epoch': 23.15}
{'loss': 0.0076, 'grad_norm': 5.259255886077881, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.007211158983409405, 'loss_2': 0.0004093647003173828, 'loss_3': -16.538429260253906, 'loss_4': 0.1389952003955841, 'epoch': 23.16}
{'loss': 0.0078, 'grad_norm': 5.007822036743164, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.0054250662215054035, 'loss_2': 0.00238800048828125, 'loss_3': -16.680648803710938, 'loss_4': 0.5603021383285522, 'epoch': 23.16}
{'loss': 0.0094, 'grad_norm': 6.498825550079346, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.008995717391371727, 'loss_2': 0.0004277229309082031, 'loss_3': -16.71964454650879, 'loss_4': 0.4685663878917694, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 16:55:51,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:51,908 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:30<20:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:59,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011143877170979977, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00821740087121725, 'eval_loss_2': 0.002926476299762726, 'eval_loss_3': -18.27083396911621, 'eval_loss_4': 0.32674258947372437, 'epoch': 23.17}
{'loss': 0.0115, 'grad_norm': 4.941431999206543, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.006400111131370068, 'loss_2': 0.005107879638671875, 'loss_3': -16.619733810424805, 'loss_4': 0.11072543263435364, 'epoch': 23.17}
{'loss': 0.0033, 'grad_norm': 5.30420446395874, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.002662254963070154, 'loss_2': 0.00061798095703125, 'loss_3': -16.666301727294922, 'loss_4': 0.35882025957107544, 'epoch': 23.18}
{'loss': 0.0076, 'grad_norm': 5.516793251037598, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.005849183537065983, 'loss_2': 0.00176239013671875, 'loss_3': -16.677021026611328, 'loss_4': 0.354577898979187, 'epoch': 23.19}
{'loss': 0.0122, 'grad_norm': 8.751413345336914, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.008401645347476006, 'loss_2': 0.003803253173828125, 'loss_3': -16.757530212402344, 'loss_4': 0.13862982392311096, 'epoch': 23.19}
{'loss': 0.0079, 'grad_norm': 4.6926398277282715, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.006420905701816082, 'loss_2': 0.0015048980712890625, 'loss_3': -16.77029037475586, 'loss_4': 0.34717777371406555, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 16:55:59,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:59,259 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:37<20:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:06,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01112576387822628, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008041759952902794, 'eval_loss_2': 0.0030840039253234863, 'eval_loss_3': -18.262937545776367, 'eval_loss_4': 0.34489864110946655, 'epoch': 23.2}
{'loss': 0.0041, 'grad_norm': 4.534722805023193, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.003685452276840806, 'loss_2': 0.0004382133483886719, 'loss_3': -16.640974044799805, 'loss_4': 0.08815640211105347, 'epoch': 23.2}
{'loss': 0.0106, 'grad_norm': 4.856922149658203, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.005905330181121826, 'loss_2': 0.004669189453125, 'loss_3': -16.653423309326172, 'loss_4': 0.010813876986503601, 'epoch': 23.21}
{'loss': 0.0071, 'grad_norm': 5.525968074798584, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.006840948481112719, 'loss_2': 0.0002989768981933594, 'loss_3': -16.75263786315918, 'loss_4': 0.2500357925891876, 'epoch': 23.22}
{'loss': 0.0097, 'grad_norm': 4.73481559753418, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.003671613521873951, 'loss_2': 0.0060577392578125, 'loss_3': -16.63065528869629, 'loss_4': 0.38786935806274414, 'epoch': 23.22}
{'loss': 0.0105, 'grad_norm': 5.524961948394775, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.008778250776231289, 'loss_2': 0.0017223358154296875, 'loss_3': -16.512653350830078, 'loss_4': 0.010206349194049835, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 16:56:06,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:06,618 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:44<20:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:13,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010384020395576954, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007735529448837042, 'eval_loss_2': 0.0026484914124011993, 'eval_loss_3': -18.252904891967773, 'eval_loss_4': 0.38241031765937805, 'epoch': 23.23}
{'loss': 0.0132, 'grad_norm': 8.51071548461914, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.011533021926879883, 'loss_2': 0.0017118453979492188, 'loss_3': -16.561479568481445, 'loss_4': 0.4092349410057068, 'epoch': 23.23}
{'loss': 0.0079, 'grad_norm': 4.59462308883667, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.004548946395516396, 'loss_2': 0.003353118896484375, 'loss_3': -16.687997817993164, 'loss_4': 0.2354382574558258, 'epoch': 23.24}
{'loss': 0.0093, 'grad_norm': 8.142913818359375, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.007644049357622862, 'loss_2': 0.001617431640625, 'loss_3': -16.50765609741211, 'loss_4': 0.37696367502212524, 'epoch': 23.24}
{'loss': 0.0077, 'grad_norm': 4.634013652801514, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.004704898688942194, 'loss_2': 0.003032684326171875, 'loss_3': -16.586278915405273, 'loss_4': -0.1310175657272339, 'epoch': 23.25}
{'loss': 0.0068, 'grad_norm': 4.827164173126221, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.00533868046477437, 'loss_2': 0.0014352798461914062, 'loss_3': -16.59165382385254, 'loss_4': 0.3503160774707794, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 16:56:13,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:13,979 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:52<19:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:21,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009313182905316353, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.822, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007104860618710518, 'eval_loss_2': 0.002208322286605835, 'eval_loss_3': -18.257368087768555, 'eval_loss_4': 0.43586674332618713, 'epoch': 23.26}
{'loss': 0.0066, 'grad_norm': 5.451742649078369, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.005874658469110727, 'loss_2': 0.0006923675537109375, 'loss_3': -16.5592098236084, 'loss_4': 0.6192878484725952, 'epoch': 23.26}
{'loss': 0.0053, 'grad_norm': 5.0547966957092285, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.004039814230054617, 'loss_2': 0.0012197494506835938, 'loss_3': -16.67796516418457, 'loss_4': 0.2835257649421692, 'epoch': 23.27}
{'loss': 0.0104, 'grad_norm': 6.767215251922607, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.008235125802457333, 'loss_2': 0.0021724700927734375, 'loss_3': -16.605436325073242, 'loss_4': 0.1442180871963501, 'epoch': 23.27}
{'loss': 0.0045, 'grad_norm': 4.663207530975342, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.002639628481119871, 'loss_2': 0.0018186569213867188, 'loss_3': -16.709278106689453, 'loss_4': 0.5042660236358643, 'epoch': 23.28}
{'loss': 0.0194, 'grad_norm': 11.186092376708984, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.018273839727044106, 'loss_2': 0.001079559326171875, 'loss_3': -16.780532836914062, 'loss_4': 0.32306143641471863, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 16:56:21,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:21,324 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:59<19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:28,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011473902501165867, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.342, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006742038298398256, 'eval_loss_2': 0.004731863737106323, 'eval_loss_3': -18.255733489990234, 'eval_loss_4': 0.42200520634651184, 'epoch': 23.28}
{'loss': 0.0081, 'grad_norm': 5.405451774597168, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.005033819004893303, 'loss_2': 0.0031147003173828125, 'loss_3': -16.54196548461914, 'loss_4': 0.31710267066955566, 'epoch': 23.29}
{'loss': 0.0126, 'grad_norm': 4.931127548217773, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.009053670801222324, 'loss_2': 0.003589630126953125, 'loss_3': -16.34758949279785, 'loss_4': 0.16244247555732727, 'epoch': 23.3}
{'loss': 0.0096, 'grad_norm': 4.918455600738525, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.0062167407013475895, 'loss_2': 0.00342559814453125, 'loss_3': -16.62472915649414, 'loss_4': 0.5469375252723694, 'epoch': 23.3}
{'loss': 0.0055, 'grad_norm': 5.173103332519531, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.0038321849424391985, 'loss_2': 0.0016450881958007812, 'loss_3': -16.67263412475586, 'loss_4': 0.41552743315696716, 'epoch': 23.31}
{'loss': 0.0178, 'grad_norm': 4.7913336753845215, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.007160800043493509, 'loss_2': 0.0106658935546875, 'loss_3': -16.555294036865234, 'loss_4': 0.4729248285293579, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 16:56:28,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:28,675 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:39:06<19:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:36,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012677831575274467, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.739, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.006848139222711325, 'eval_loss_2': 0.0058296918869018555, 'eval_loss_3': -18.254074096679688, 'eval_loss_4': 0.3752478063106537, 'epoch': 23.31}
{'loss': 0.0069, 'grad_norm': 5.141564846038818, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.0049433279782533646, 'loss_2': 0.0020046234130859375, 'loss_3': -16.606609344482422, 'loss_4': 0.1722974181175232, 'epoch': 23.32}
{'loss': 0.0146, 'grad_norm': 4.483391284942627, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.003739697393029928, 'loss_2': 0.0108795166015625, 'loss_3': -16.453269958496094, 'loss_4': 0.24675007164478302, 'epoch': 23.33}
{'loss': 0.0138, 'grad_norm': 8.749953269958496, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.008561499416828156, 'loss_2': 0.005218505859375, 'loss_3': -16.641578674316406, 'loss_4': 0.26091548800468445, 'epoch': 23.33}
{'loss': 0.0161, 'grad_norm': 4.5360894203186035, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.003983606118708849, 'loss_2': 0.0121307373046875, 'loss_3': -16.658172607421875, 'loss_4': -0.17351014912128448, 'epoch': 23.34}
{'loss': 0.0112, 'grad_norm': 6.0949506759643555, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.008922755718231201, 'loss_2': 0.002307891845703125, 'loss_3': -16.567123413085938, 'loss_4': 0.03673821687698364, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 16:56:36,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:36,020 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:39:14<19:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:43,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01102745532989502, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006862580310553312, 'eval_loss_2': 0.00416487455368042, 'eval_loss_3': -18.258686065673828, 'eval_loss_4': 0.2659377157688141, 'epoch': 23.34}
{'loss': 0.0041, 'grad_norm': 4.798669338226318, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.003437499515712261, 'loss_2': 0.0006923675537109375, 'loss_3': -16.706960678100586, 'loss_4': 0.25814810395240784, 'epoch': 23.35}
{'loss': 0.0197, 'grad_norm': 11.586687088012695, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.01752481237053871, 'loss_2': 0.0021915435791015625, 'loss_3': -16.74957275390625, 'loss_4': -0.364399790763855, 'epoch': 23.35}
{'loss': 0.0146, 'grad_norm': 5.1324052810668945, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.008723330684006214, 'loss_2': 0.00583648681640625, 'loss_3': -16.719470977783203, 'loss_4': 0.38321343064308167, 'epoch': 23.36}
{'loss': 0.0063, 'grad_norm': 4.862155437469482, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.005450950004160404, 'loss_2': 0.0008249282836914062, 'loss_3': -16.727027893066406, 'loss_4': 0.14868074655532837, 'epoch': 23.37}
{'loss': 0.0107, 'grad_norm': 4.336742401123047, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.0068757859990000725, 'loss_2': 0.003803253173828125, 'loss_3': -16.599151611328125, 'loss_4': 0.020475585013628006, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 16:56:43,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:43,373 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:21<19:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:50,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010120808146893978, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.048, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006706504616886377, 'eval_loss_2': 0.0034143030643463135, 'eval_loss_3': -18.25444793701172, 'eval_loss_4': 0.15499243140220642, 'epoch': 23.37}
{'loss': 0.0077, 'grad_norm': 5.175844669342041, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.006645148620009422, 'loss_2': 0.001049041748046875, 'loss_3': -16.66115379333496, 'loss_4': -0.015607357025146484, 'epoch': 23.38}
{'loss': 0.0338, 'grad_norm': 16.84969139099121, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.03013511374592781, 'loss_2': 0.0036773681640625, 'loss_3': -16.55782127380371, 'loss_4': 0.40217477083206177, 'epoch': 23.38}
{'loss': 0.0093, 'grad_norm': 5.0210723876953125, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.00780222425237298, 'loss_2': 0.0014514923095703125, 'loss_3': -16.74687957763672, 'loss_4': -0.0037008821964263916, 'epoch': 23.39}
{'loss': 0.0123, 'grad_norm': 5.576528072357178, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.007716592866927385, 'loss_2': 0.00455474853515625, 'loss_3': -16.43135643005371, 'loss_4': -0.0523906871676445, 'epoch': 23.4}
{'loss': 0.0101, 'grad_norm': 4.294412136077881, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.004908743314445019, 'loss_2': 0.005214691162109375, 'loss_3': -16.560688018798828, 'loss_4': -0.32734042406082153, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 16:56:50,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:50,731 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:28<19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:58,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009463708847761154, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00725472392514348, 'eval_loss_2': 0.002208985388278961, 'eval_loss_3': -18.26046371459961, 'eval_loss_4': 0.037492647767066956, 'epoch': 23.4}
{'loss': 0.006, 'grad_norm': 5.491084575653076, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.005581577308475971, 'loss_2': 0.00046515464782714844, 'loss_3': -16.716712951660156, 'loss_4': 0.1594405174255371, 'epoch': 23.41}
{'loss': 0.0107, 'grad_norm': 4.44251823425293, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.004027592483907938, 'loss_2': 0.00665283203125, 'loss_3': -16.62868881225586, 'loss_4': -0.5130571126937866, 'epoch': 23.41}
{'loss': 0.0066, 'grad_norm': 6.280337333679199, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.006430048029869795, 'loss_2': 0.0001308917999267578, 'loss_3': -16.79460906982422, 'loss_4': -0.1298055648803711, 'epoch': 23.42}
{'loss': 0.01, 'grad_norm': 5.480157375335693, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.006610298994928598, 'loss_2': 0.003345489501953125, 'loss_3': -16.84235382080078, 'loss_4': -0.08588172495365143, 'epoch': 23.42}
{'loss': 0.0102, 'grad_norm': 5.063459396362305, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.006426697596907616, 'loss_2': 0.003810882568359375, 'loss_3': -16.630157470703125, 'loss_4': -0.5033468008041382, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 16:56:58,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:58,089 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:36<19:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:05,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010800831019878387, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.605, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007997356355190277, 'eval_loss_2': 0.0028034746646881104, 'eval_loss_3': -18.267484664916992, 'eval_loss_4': -0.0030322372913360596, 'epoch': 23.43}
{'loss': 0.0093, 'grad_norm': 5.831117630004883, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.006984170526266098, 'loss_2': 0.00231170654296875, 'loss_3': -16.75196075439453, 'loss_4': 0.11204805970191956, 'epoch': 23.44}
{'loss': 0.0163, 'grad_norm': 4.851919174194336, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.006476050242781639, 'loss_2': 0.009796142578125, 'loss_3': -16.59120750427246, 'loss_4': -0.08176735043525696, 'epoch': 23.44}
{'loss': 0.0098, 'grad_norm': 4.959867000579834, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.0047676642425358295, 'loss_2': 0.0050811767578125, 'loss_3': -16.543563842773438, 'loss_4': -0.12134595215320587, 'epoch': 23.45}
{'loss': 0.0269, 'grad_norm': 15.533417701721191, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.024433385580778122, 'loss_2': 0.00243377685546875, 'loss_3': -16.623741149902344, 'loss_4': 0.11874765902757645, 'epoch': 23.45}
{'loss': 0.006, 'grad_norm': 4.626885414123535, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.005573818925768137, 'loss_2': 0.0004253387451171875, 'loss_3': -16.621055603027344, 'loss_4': 0.07237361371517181, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 16:57:05,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:05,440 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:43<19:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:12,790 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011150876060128212, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.767, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007974917069077492, 'eval_loss_2': 0.00317595899105072, 'eval_loss_3': -18.253524780273438, 'eval_loss_4': 0.008807135745882988, 'epoch': 23.46}
{'loss': 0.0128, 'grad_norm': 5.786782741546631, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.008361902087926865, 'loss_2': 0.004451751708984375, 'loss_3': -16.469642639160156, 'loss_4': -0.09810450673103333, 'epoch': 23.47}
{'loss': 0.0811, 'grad_norm': 17.475889205932617, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.07551005482673645, 'loss_2': 0.00555419921875, 'loss_3': -16.425174713134766, 'loss_4': 0.08958645164966583, 'epoch': 23.47}
{'loss': 0.0252, 'grad_norm': 5.719773769378662, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.012343250215053558, 'loss_2': 0.0128631591796875, 'loss_3': -16.66350555419922, 'loss_4': -0.2755052149295807, 'epoch': 23.48}
{'loss': 0.0136, 'grad_norm': 5.535009384155273, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.0067878831177949905, 'loss_2': 0.0067901611328125, 'loss_3': -16.661373138427734, 'loss_4': -0.15985922515392303, 'epoch': 23.48}
{'loss': 0.0089, 'grad_norm': 4.387526512145996, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.006577165797352791, 'loss_2': 0.00228118896484375, 'loss_3': -16.470455169677734, 'loss_4': -0.3285812735557556, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 16:57:12,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:12,790 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:50<19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:20,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010496499948203564, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.51, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008290807716548443, 'eval_loss_2': 0.002205692231655121, 'eval_loss_3': -18.241777420043945, 'eval_loss_4': -0.02327112853527069, 'epoch': 23.49}
{'loss': 0.0123, 'grad_norm': 6.85883903503418, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.00838733371347189, 'loss_2': 0.00391387939453125, 'loss_3': -16.576448440551758, 'loss_4': -0.022293344140052795, 'epoch': 23.49}
{'loss': 0.01, 'grad_norm': 6.98231840133667, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.008077076636254787, 'loss_2': 0.0019130706787109375, 'loss_3': -16.335411071777344, 'loss_4': 0.41954150795936584, 'epoch': 23.5}
{'loss': 0.0065, 'grad_norm': 5.0423808097839355, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.006060346961021423, 'loss_2': 0.0004291534423828125, 'loss_3': -16.744911193847656, 'loss_4': 0.1578039973974228, 'epoch': 23.51}
{'loss': 0.0073, 'grad_norm': 5.669107913970947, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.006864466704428196, 'loss_2': 0.0004317760467529297, 'loss_3': -16.608522415161133, 'loss_4': 0.06351588666439056, 'epoch': 23.51}
{'loss': 0.0082, 'grad_norm': 5.344832897186279, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.006845938507467508, 'loss_2': 0.0013952255249023438, 'loss_3': -16.545743942260742, 'loss_4': -0.5966248512268066, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 16:57:20,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:20,141 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:58<19:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:27,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011161284521222115, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.393, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008339719846844673, 'eval_loss_2': 0.0028215646743774414, 'eval_loss_3': -18.21883201599121, 'eval_loss_4': 0.007724238559603691, 'epoch': 23.52}
{'loss': 0.0126, 'grad_norm': 7.605432987213135, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.009502517059445381, 'loss_2': 0.0030727386474609375, 'loss_3': -16.316099166870117, 'loss_4': 0.029095876961946487, 'epoch': 23.52}
{'loss': 0.007, 'grad_norm': 4.852453231811523, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.005652895662933588, 'loss_2': 0.00136566162109375, 'loss_3': -16.491466522216797, 'loss_4': -0.10058683156967163, 'epoch': 23.53}
{'loss': 0.01, 'grad_norm': 5.264270305633545, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.00880140159279108, 'loss_2': 0.00119781494140625, 'loss_3': -16.552536010742188, 'loss_4': -0.47544777393341064, 'epoch': 23.53}
{'loss': 0.0123, 'grad_norm': 4.822588920593262, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.008054918609559536, 'loss_2': 0.004207611083984375, 'loss_3': -16.44557762145996, 'loss_4': -0.11799009889364243, 'epoch': 23.54}
{'loss': 0.0087, 'grad_norm': 4.833917140960693, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.00537507887929678, 'loss_2': 0.003292083740234375, 'loss_3': -16.635604858398438, 'loss_4': -0.758142352104187, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 16:57:27,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:27,499 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:40:05<19:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:34,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013505736365914345, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.115, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009512515738606453, 'eval_loss_2': 0.003993220627307892, 'eval_loss_3': -18.21137046813965, 'eval_loss_4': -0.005054417997598648, 'epoch': 23.55}
{'loss': 0.0131, 'grad_norm': 6.255499362945557, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.00906454212963581, 'loss_2': 0.004070281982421875, 'loss_3': -16.6699275970459, 'loss_4': -0.31877028942108154, 'epoch': 23.55}
{'loss': 0.0146, 'grad_norm': 6.445176124572754, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.009171328507363796, 'loss_2': 0.005474090576171875, 'loss_3': -16.636581420898438, 'loss_4': -0.47585856914520264, 'epoch': 23.56}
{'loss': 0.0074, 'grad_norm': 5.002212047576904, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.004584191832691431, 'loss_2': 0.002819061279296875, 'loss_3': -16.681718826293945, 'loss_4': -0.07889358699321747, 'epoch': 23.56}
{'loss': 0.0124, 'grad_norm': 5.819530010223389, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.0076265279203653336, 'loss_2': 0.004749298095703125, 'loss_3': -16.72570037841797, 'loss_4': -0.2022985816001892, 'epoch': 23.57}
{'loss': 0.0049, 'grad_norm': 5.3345770835876465, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.0045872824266552925, 'loss_2': 0.0003101825714111328, 'loss_3': -16.704492568969727, 'loss_4': -0.24704989790916443, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 16:57:34,852 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:34,852 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:40:13<19:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:42,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01395251415669918, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.275, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010012736544013023, 'eval_loss_2': 0.003939777612686157, 'eval_loss_3': -18.195791244506836, 'eval_loss_4': 0.05065576732158661, 'epoch': 23.58}
{'loss': 0.0192, 'grad_norm': 7.460288047790527, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.013375993818044662, 'loss_2': 0.00580596923828125, 'loss_3': -16.397275924682617, 'loss_4': 0.07250182330608368, 'epoch': 23.58}
{'loss': 0.005, 'grad_norm': 4.674899101257324, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.00400173757225275, 'loss_2': 0.001018524169921875, 'loss_3': -16.59813117980957, 'loss_4': -0.3576364517211914, 'epoch': 23.59}
{'loss': 0.0058, 'grad_norm': 4.760470390319824, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.0037208804860711098, 'loss_2': 0.00211334228515625, 'loss_3': -16.54846954345703, 'loss_4': -0.09802611172199249, 'epoch': 23.59}
{'loss': 0.0171, 'grad_norm': 7.164646148681641, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.010012649931013584, 'loss_2': 0.007045745849609375, 'loss_3': -16.55066680908203, 'loss_4': -0.02670309692621231, 'epoch': 23.6}
{'loss': 0.0083, 'grad_norm': 4.475703239440918, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.003494266187772155, 'loss_2': 0.00481414794921875, 'loss_3': -16.594390869140625, 'loss_4': -0.3934723138809204, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 16:57:42,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:42,209 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:20<18:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:49,570 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013422893360257149, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01096642017364502, 'eval_loss_2': 0.00245647132396698, 'eval_loss_3': -18.183204650878906, 'eval_loss_4': 0.06753654778003693, 'epoch': 23.6}
{'loss': 0.0126, 'grad_norm': 4.492823123931885, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.0052797142416238785, 'loss_2': 0.007343292236328125, 'loss_3': -16.56086540222168, 'loss_4': 0.17049667239189148, 'epoch': 23.61}
{'loss': 0.0048, 'grad_norm': 5.520321846008301, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.0038527604192495346, 'loss_2': 0.0009760856628417969, 'loss_3': -16.399240493774414, 'loss_4': -0.16260182857513428, 'epoch': 23.62}
{'loss': 0.0095, 'grad_norm': 5.030128002166748, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.004719203338027, 'loss_2': 0.00482177734375, 'loss_3': -16.663188934326172, 'loss_4': -0.2240675389766693, 'epoch': 23.62}
{'loss': 0.0102, 'grad_norm': 5.1256537437438965, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.00636292016133666, 'loss_2': 0.003833770751953125, 'loss_3': -16.444610595703125, 'loss_4': -0.18584273755550385, 'epoch': 23.63}
{'loss': 0.0222, 'grad_norm': 10.551153182983398, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.02099454402923584, 'loss_2': 0.001201629638671875, 'loss_3': -16.668025970458984, 'loss_4': -0.45902860164642334, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 16:57:49,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:49,570 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:27<18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:56,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013414731249213219, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.705, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010922588407993317, 'eval_loss_2': 0.0024921447038650513, 'eval_loss_3': -18.168556213378906, 'eval_loss_4': 0.0428733266890049, 'epoch': 23.63}
{'loss': 0.0076, 'grad_norm': 5.419961929321289, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.006906408816576004, 'loss_2': 0.0006709098815917969, 'loss_3': -16.658044815063477, 'loss_4': -0.007673874497413635, 'epoch': 23.64}
{'loss': 0.0113, 'grad_norm': 5.415224075317383, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.008139834739267826, 'loss_2': 0.003162384033203125, 'loss_3': -16.43947410583496, 'loss_4': 0.03493129462003708, 'epoch': 23.65}
{'loss': 0.0234, 'grad_norm': 8.308575630187988, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.013569040223956108, 'loss_2': 0.0098114013671875, 'loss_3': -16.570398330688477, 'loss_4': -0.25010067224502563, 'epoch': 23.65}
{'loss': 0.0057, 'grad_norm': 4.490236282348633, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.004968519322574139, 'loss_2': 0.0007171630859375, 'loss_3': -16.465473175048828, 'loss_4': -0.08475163578987122, 'epoch': 23.66}
{'loss': 0.0082, 'grad_norm': 4.6950788497924805, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.004139785189181566, 'loss_2': 0.00402069091796875, 'loss_3': -16.515968322753906, 'loss_4': -0.35719120502471924, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 16:57:56,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:56,928 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:35<18:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:04,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014337530359625816, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011071747168898582, 'eval_loss_2': 0.003265783190727234, 'eval_loss_3': -18.181705474853516, 'eval_loss_4': 0.029091648757457733, 'epoch': 23.66}
{'loss': 0.0115, 'grad_norm': 5.40896463394165, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.010740440338850021, 'loss_2': 0.0007371902465820312, 'loss_3': -16.685123443603516, 'loss_4': -0.09238007664680481, 'epoch': 23.67}
{'loss': 0.0047, 'grad_norm': 4.846765995025635, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.003957066684961319, 'loss_2': 0.0007047653198242188, 'loss_3': -16.511699676513672, 'loss_4': 0.11062469333410263, 'epoch': 23.67}
{'loss': 0.016, 'grad_norm': 8.578104019165039, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.011982232332229614, 'loss_2': 0.004001617431640625, 'loss_3': -16.53213882446289, 'loss_4': -0.36451661586761475, 'epoch': 23.68}
{'loss': 0.0117, 'grad_norm': 5.4422125816345215, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.008855948224663734, 'loss_2': 0.002880096435546875, 'loss_3': -16.464210510253906, 'loss_4': -0.14863283932209015, 'epoch': 23.69}
{'loss': 0.0083, 'grad_norm': 5.892252445220947, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.006608279421925545, 'loss_2': 0.0017213821411132812, 'loss_3': -16.467208862304688, 'loss_4': -0.3714182376861572, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 16:58:04,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:04,296 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:42<18:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:11,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014572818763554096, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011002038605511189, 'eval_loss_2': 0.0035707801580429077, 'eval_loss_3': -18.17868995666504, 'eval_loss_4': 0.05716416984796524, 'epoch': 23.69}
{'loss': 0.0041, 'grad_norm': 5.033102989196777, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.002810174599289894, 'loss_2': 0.0013332366943359375, 'loss_3': -16.53147315979004, 'loss_4': -0.17840257287025452, 'epoch': 23.7}
{'loss': 0.0124, 'grad_norm': 4.918570518493652, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.005750931333750486, 'loss_2': 0.006622314453125, 'loss_3': -16.771360397338867, 'loss_4': 0.18028084933757782, 'epoch': 23.7}
{'loss': 0.0666, 'grad_norm': 10.1338529586792, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.06420324742794037, 'loss_2': 0.002353668212890625, 'loss_3': -16.344736099243164, 'loss_4': -0.07774761319160461, 'epoch': 23.71}
{'loss': 0.0072, 'grad_norm': 4.587637901306152, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.005205291323363781, 'loss_2': 0.0020294189453125, 'loss_3': -16.429744720458984, 'loss_4': 0.36136871576309204, 'epoch': 23.72}
{'loss': 0.0068, 'grad_norm': 4.782484531402588, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.003447731025516987, 'loss_2': 0.0033512115478515625, 'loss_3': -16.526065826416016, 'loss_4': -0.07075822353363037, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 16:58:11,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:11,663 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:49<18:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:19,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015828505158424377, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.524, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011924756690859795, 'eval_loss_2': 0.0039037466049194336, 'eval_loss_3': -18.18201446533203, 'eval_loss_4': 0.08139221370220184, 'epoch': 23.72}
{'loss': 0.009, 'grad_norm': 5.056276798248291, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.0046157026663422585, 'loss_2': 0.004375457763671875, 'loss_3': -16.495529174804688, 'loss_4': -0.2572811543941498, 'epoch': 23.73}
{'loss': 0.0101, 'grad_norm': 5.72774600982666, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.008203371427953243, 'loss_2': 0.0018596649169921875, 'loss_3': -16.558597564697266, 'loss_4': -0.1007101982831955, 'epoch': 23.73}
{'loss': 0.0124, 'grad_norm': 7.258403301239014, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.010818995535373688, 'loss_2': 0.001613616943359375, 'loss_3': -16.407699584960938, 'loss_4': -0.5957039594650269, 'epoch': 23.74}
{'loss': 0.0122, 'grad_norm': 5.176228046417236, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.006027019117027521, 'loss_2': 0.0061492919921875, 'loss_3': -16.38668441772461, 'loss_4': -0.14011117815971375, 'epoch': 23.74}
{'loss': 0.0053, 'grad_norm': 4.819780349731445, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.004208703991025686, 'loss_2': 0.0010623931884765625, 'loss_3': -16.35635757446289, 'loss_4': -0.2350112348794937, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 16:58:19,021 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:19,021 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:57<18:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:26,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016112033277750015, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.482, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011681546457111835, 'eval_loss_2': 0.004430487751960754, 'eval_loss_3': -18.18411636352539, 'eval_loss_4': 0.054874237626791, 'epoch': 23.75}
{'loss': 0.0075, 'grad_norm': 6.381372928619385, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.0025676169898360968, 'loss_2': 0.004962921142578125, 'loss_3': -16.5091552734375, 'loss_4': -0.19357265532016754, 'epoch': 23.76}
{'loss': 0.0128, 'grad_norm': 6.280584812164307, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.010043236427009106, 'loss_2': 0.00278472900390625, 'loss_3': -16.334474563598633, 'loss_4': -0.18383245170116425, 'epoch': 23.76}
{'loss': 0.0119, 'grad_norm': 4.426535129547119, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.0036551151424646378, 'loss_2': 0.008209228515625, 'loss_3': -16.614866256713867, 'loss_4': 0.10499007999897003, 'epoch': 23.77}
{'loss': 0.0031, 'grad_norm': 4.502361297607422, 'learning_rate': 6.25e-06, 'loss_1': 0.0025593878235667944, 'loss_2': 0.0005583763122558594, 'loss_3': -16.60354995727539, 'loss_4': 0.09661899507045746, 'epoch': 23.77}
{'loss': 0.0289, 'grad_norm': 14.473443984985352, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.01829850859940052, 'loss_2': 0.0106048583984375, 'loss_3': -16.528026580810547, 'loss_4': -0.2605561912059784, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 16:58:26,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:26,375 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:41:04<18:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:33,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015464071184396744, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.386, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010701541788876057, 'eval_loss_2': 0.004762530326843262, 'eval_loss_3': -18.17776870727539, 'eval_loss_4': -0.011389875784516335, 'epoch': 23.78}
{'loss': 0.0202, 'grad_norm': 6.7934041023254395, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.012034823186695576, 'loss_2': 0.0081329345703125, 'loss_3': -16.52808952331543, 'loss_4': -0.5348823666572571, 'epoch': 23.78}
{'loss': 0.006, 'grad_norm': 4.756130695343018, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.0023124224971979856, 'loss_2': 0.00363922119140625, 'loss_3': -16.54379653930664, 'loss_4': -0.01349707692861557, 'epoch': 23.79}
{'loss': 0.0077, 'grad_norm': 4.343099117279053, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.003493365366011858, 'loss_2': 0.0041656494140625, 'loss_3': -16.531906127929688, 'loss_4': -0.2399909645318985, 'epoch': 23.8}
{'loss': 0.0148, 'grad_norm': 6.378564357757568, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.006429045461118221, 'loss_2': 0.008331298828125, 'loss_3': -16.750337600708008, 'loss_4': -0.017906785011291504, 'epoch': 23.8}
{'loss': 0.0072, 'grad_norm': 6.2089667320251465, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.007111106999218464, 'loss_2': 7.331371307373047e-05, 'loss_3': -16.72521209716797, 'loss_4': -0.01896815001964569, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 16:58:33,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:33,732 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:41:11<18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:41,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014295605942606926, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00982084684073925, 'eval_loss_2': 0.004474759101867676, 'eval_loss_3': -18.176780700683594, 'eval_loss_4': -0.007653540000319481, 'epoch': 23.81}
{'loss': 0.0094, 'grad_norm': 4.370811462402344, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.0046149264089763165, 'loss_2': 0.0047760009765625, 'loss_3': -16.452686309814453, 'loss_4': 0.1005672961473465, 'epoch': 23.81}
{'loss': 0.0123, 'grad_norm': 5.987070083618164, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.008093062788248062, 'loss_2': 0.004222869873046875, 'loss_3': -16.583127975463867, 'loss_4': -0.08421163260936737, 'epoch': 23.82}
{'loss': 0.0121, 'grad_norm': 4.741580963134766, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.0034847354982048273, 'loss_2': 0.00862884521484375, 'loss_3': -16.62328338623047, 'loss_4': 0.04372593015432358, 'epoch': 23.83}
{'loss': 0.0055, 'grad_norm': 4.670522689819336, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.0036530436482280493, 'loss_2': 0.0018739700317382812, 'loss_3': -16.402462005615234, 'loss_4': -0.09267492592334747, 'epoch': 23.83}
{'loss': 0.0111, 'grad_norm': 4.763195514678955, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.007028374820947647, 'loss_2': 0.00411224365234375, 'loss_3': -16.44270896911621, 'loss_4': 0.10311803221702576, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 16:58:41,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:41,087 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:19<18:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:48,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01196536235511303, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009098334237933159, 'eval_loss_2': 0.0028670281171798706, 'eval_loss_3': -18.18868637084961, 'eval_loss_4': -0.00605957955121994, 'epoch': 23.84}
{'loss': 0.0081, 'grad_norm': 5.712591648101807, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.007089128252118826, 'loss_2': 0.0010585784912109375, 'loss_3': -16.41044807434082, 'loss_4': 0.16335205733776093, 'epoch': 23.84}
{'loss': 0.0042, 'grad_norm': 4.0843048095703125, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.003671713639050722, 'loss_2': 0.0004992485046386719, 'loss_3': -16.55721664428711, 'loss_4': -0.04736870527267456, 'epoch': 23.85}
{'loss': 0.0226, 'grad_norm': 8.158096313476562, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.01611725240945816, 'loss_2': 0.006439208984375, 'loss_3': -16.47690773010254, 'loss_4': 0.15654094517230988, 'epoch': 23.85}
{'loss': 0.0148, 'grad_norm': 6.0405120849609375, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.008194494061172009, 'loss_2': 0.00658416748046875, 'loss_3': -16.70885467529297, 'loss_4': -0.12353522330522537, 'epoch': 23.86}
{'loss': 0.0076, 'grad_norm': 4.745667934417725, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.0024810621980577707, 'loss_2': 0.00511932373046875, 'loss_3': -16.562244415283203, 'loss_4': -0.1971389502286911, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 16:58:48,452 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:48,452 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:26<18:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:55,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011769669130444527, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.737, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008706615306437016, 'eval_loss_2': 0.0030630528926849365, 'eval_loss_3': -18.20864486694336, 'eval_loss_4': 0.00742715410888195, 'epoch': 23.87}
{'loss': 0.0056, 'grad_norm': 4.688347816467285, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.0035397137980908155, 'loss_2': 0.002040863037109375, 'loss_3': -16.826248168945312, 'loss_4': 0.10845449566841125, 'epoch': 23.87}
{'loss': 0.0128, 'grad_norm': 5.60151481628418, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.006218446884304285, 'loss_2': 0.0066070556640625, 'loss_3': -16.565710067749023, 'loss_4': -0.22198423743247986, 'epoch': 23.88}
{'loss': 0.0092, 'grad_norm': 5.23635196685791, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.006649153307080269, 'loss_2': 0.0025577545166015625, 'loss_3': -16.487348556518555, 'loss_4': -0.23736163973808289, 'epoch': 23.88}
{'loss': 0.0151, 'grad_norm': 4.443497657775879, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.003833841998130083, 'loss_2': 0.01126861572265625, 'loss_3': -16.628564834594727, 'loss_4': -0.28037601709365845, 'epoch': 23.89}
{'loss': 0.0283, 'grad_norm': 19.628068923950195, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.02549165114760399, 'loss_2': 0.0028533935546875, 'loss_3': -16.587684631347656, 'loss_4': -0.26663869619369507, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 16:58:55,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:55,822 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:34<18:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:03,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011527977883815765, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.088, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008781074546277523, 'eval_loss_2': 0.0027469024062156677, 'eval_loss_3': -18.206401824951172, 'eval_loss_4': 0.05553123354911804, 'epoch': 23.9}
{'loss': 0.0103, 'grad_norm': 6.122344017028809, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.006764167454093695, 'loss_2': 0.00350189208984375, 'loss_3': -16.545639038085938, 'loss_4': -0.14901478588581085, 'epoch': 23.9}
{'loss': 0.0115, 'grad_norm': 5.6221818923950195, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.009667637757956982, 'loss_2': 0.0018672943115234375, 'loss_3': -16.279029846191406, 'loss_4': 0.0011926740407943726, 'epoch': 23.91}
{'loss': 0.0028, 'grad_norm': 4.303028583526611, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.0026265964843332767, 'loss_2': 0.00016450881958007812, 'loss_3': -16.54391098022461, 'loss_4': 0.2307680994272232, 'epoch': 23.91}
{'loss': 0.0061, 'grad_norm': 4.818504810333252, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.005456665996462107, 'loss_2': 0.000667572021484375, 'loss_3': -16.493196487426758, 'loss_4': 0.027752019464969635, 'epoch': 23.92}
{'loss': 0.0093, 'grad_norm': 5.637179374694824, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.006388418842107058, 'loss_2': 0.002941131591796875, 'loss_3': -16.64523696899414, 'loss_4': -0.3354162275791168, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 16:59:03,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:03,184 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:41<18:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:10,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010628869757056236, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.173, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008188165724277496, 'eval_loss_2': 0.002440705895423889, 'eval_loss_3': -18.206340789794922, 'eval_loss_4': 0.10809802263975143, 'epoch': 23.92}
{'loss': 0.0105, 'grad_norm': 6.112616539001465, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.007059141062200069, 'loss_2': 0.0034332275390625, 'loss_3': -16.555137634277344, 'loss_4': -0.16841796040534973, 'epoch': 23.93}
{'loss': 0.0042, 'grad_norm': 4.5070295333862305, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.00338676362298429, 'loss_2': 0.0007958412170410156, 'loss_3': -16.63024139404297, 'loss_4': -0.1155523806810379, 'epoch': 23.94}
{'loss': 0.0178, 'grad_norm': 7.11626672744751, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.005459976848214865, 'loss_2': 0.01238250732421875, 'loss_3': -16.571847915649414, 'loss_4': 0.31964248418807983, 'epoch': 23.94}
{'loss': 0.0058, 'grad_norm': 4.559444427490234, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.00513024115934968, 'loss_2': 0.0006456375122070312, 'loss_3': -16.482852935791016, 'loss_4': 0.23805727064609528, 'epoch': 23.95}
{'loss': 0.0149, 'grad_norm': 7.296325206756592, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.01342720165848732, 'loss_2': 0.001438140869140625, 'loss_3': -16.429466247558594, 'loss_4': -0.7400180697441101, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 16:59:10,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:10,546 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:48<17:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:17,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010766059160232544, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007935629226267338, 'eval_loss_2': 0.0028304308652877808, 'eval_loss_3': -18.210250854492188, 'eval_loss_4': 0.10657147318124771, 'epoch': 23.95}
{'loss': 0.0114, 'grad_norm': 3.955559492111206, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.0027729137800633907, 'loss_2': 0.0086212158203125, 'loss_3': -16.399446487426758, 'loss_4': -0.008118204772472382, 'epoch': 23.96}
{'loss': 0.0274, 'grad_norm': 13.140434265136719, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.020439062267541885, 'loss_2': 0.00698089599609375, 'loss_3': -16.463207244873047, 'loss_4': -0.18051357567310333, 'epoch': 23.97}
{'loss': 0.0099, 'grad_norm': 7.2156171798706055, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.007324736099690199, 'loss_2': 0.0025348663330078125, 'loss_3': -16.656082153320312, 'loss_4': 0.2317025363445282, 'epoch': 23.97}
{'loss': 0.0127, 'grad_norm': 5.292151927947998, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.0047170426696538925, 'loss_2': 0.00801849365234375, 'loss_3': -16.474166870117188, 'loss_4': 0.04772317409515381, 'epoch': 23.98}
{'loss': 0.0048, 'grad_norm': 4.638789653778076, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.0032211565412580967, 'loss_2': 0.0015869140625, 'loss_3': -16.389362335205078, 'loss_4': -0.32706159353256226, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 16:59:17,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:17,902 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:55<17:07,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 16:59:24,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0104648657143116, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007772673387080431, 'eval_loss_2': 0.002692192792892456, 'eval_loss_3': -18.202674865722656, 'eval_loss_4': 0.06816954165697098, 'epoch': 23.98}
{'loss': 0.0076, 'grad_norm': 5.371190547943115, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.005211938638240099, 'loss_2': 0.002399444580078125, 'loss_3': -16.43390464782715, 'loss_4': -0.03717106953263283, 'epoch': 23.99}
{'loss': 0.0056, 'grad_norm': 4.662573337554932, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.0036401895340532064, 'loss_2': 0.001995086669921875, 'loss_3': -16.541547775268555, 'loss_4': 0.3251810669898987, 'epoch': 23.99}
{'loss': 0.0101, 'grad_norm': 6.159453868865967, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.0028417296707630157, 'loss_2': 0.0072479248046875, 'loss_3': -16.671504974365234, 'loss_4': -0.18929077684879303, 'epoch': 24.0}
{'loss': 0.0106, 'grad_norm': 5.92482852935791, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.007455059327185154, 'loss_2': 0.003162384033203125, 'loss_3': -16.407339096069336, 'loss_4': -0.04750082641839981, 'epoch': 24.01}
{'loss': 0.0052, 'grad_norm': 4.634289264678955, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.004090143367648125, 'loss_2': 0.0010890960693359375, 'loss_3': -16.438032150268555, 'loss_4': -0.24990667402744293, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 16:59:24,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:24,949 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:42:03<17:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:32,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010345002636313438, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007607964798808098, 'eval_loss_2': 0.0027370378375053406, 'eval_loss_3': -18.201595306396484, 'eval_loss_4': 0.05975394695997238, 'epoch': 24.01}
{'loss': 0.0161, 'grad_norm': 7.3878254890441895, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.011826755478978157, 'loss_2': 0.00424957275390625, 'loss_3': -16.364028930664062, 'loss_4': -0.07038943469524384, 'epoch': 24.02}
{'loss': 0.0081, 'grad_norm': 7.173283100128174, 'learning_rate': 6e-06, 'loss_1': 0.0071654426865279675, 'loss_2': 0.0009675025939941406, 'loss_3': -16.57613754272461, 'loss_4': -0.44894224405288696, 'epoch': 24.02}
{'loss': 0.0167, 'grad_norm': 8.820661544799805, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.008973927237093449, 'loss_2': 0.0077056884765625, 'loss_3': -16.649959564208984, 'loss_4': -0.2889251410961151, 'epoch': 24.03}
{'loss': 0.0158, 'grad_norm': 5.245584487915039, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.007334102876484394, 'loss_2': 0.008453369140625, 'loss_3': -16.619709014892578, 'loss_4': 0.1120600774884224, 'epoch': 24.03}
{'loss': 0.0106, 'grad_norm': 6.225133419036865, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.004962210543453693, 'loss_2': 0.00567626953125, 'loss_3': -16.555912017822266, 'loss_4': -0.06432774662971497, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 16:59:32,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:32,325 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:42:10<17:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:39,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010595235042273998, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007872510701417923, 'eval_loss_2': 0.00272272527217865, 'eval_loss_3': -18.2045955657959, 'eval_loss_4': 0.053826767951250076, 'epoch': 24.04}
{'loss': 0.0091, 'grad_norm': 4.932193279266357, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.0042935567907989025, 'loss_2': 0.00484466552734375, 'loss_3': -16.716638565063477, 'loss_4': 0.011630211025476456, 'epoch': 24.05}
{'loss': 0.0175, 'grad_norm': 12.959428787231445, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.01264079287648201, 'loss_2': 0.00482177734375, 'loss_3': -16.488309860229492, 'loss_4': 0.32323169708251953, 'epoch': 24.05}
{'loss': 0.0121, 'grad_norm': 5.326491832733154, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.006198722869157791, 'loss_2': 0.005859375, 'loss_3': -16.442882537841797, 'loss_4': 0.06991217285394669, 'epoch': 24.06}
{'loss': 0.008, 'grad_norm': 4.872300624847412, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.007005975116044283, 'loss_2': 0.0009598731994628906, 'loss_3': -16.36395263671875, 'loss_4': -0.0035075843334198, 'epoch': 24.06}
{'loss': 0.0195, 'grad_norm': 7.33736515045166, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.01174210011959076, 'loss_2': 0.0077667236328125, 'loss_3': -16.48130989074707, 'loss_4': -0.20619459450244904, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 16:59:39,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:39,686 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:17<17:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:47,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01114356517791748, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.934, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007657796144485474, 'eval_loss_2': 0.003485769033432007, 'eval_loss_3': -18.202611923217773, 'eval_loss_4': 0.08034645020961761, 'epoch': 24.07}
{'loss': 0.0042, 'grad_norm': 4.54121732711792, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.002657906385138631, 'loss_2': 0.0015840530395507812, 'loss_3': -16.587299346923828, 'loss_4': -0.11983294039964676, 'epoch': 24.08}
{'loss': 0.01, 'grad_norm': 5.092896461486816, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.007370796054601669, 'loss_2': 0.0026378631591796875, 'loss_3': -16.406049728393555, 'loss_4': -0.16436725854873657, 'epoch': 24.08}
{'loss': 0.0107, 'grad_norm': 5.12711763381958, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.0051573957316577435, 'loss_2': 0.00557708740234375, 'loss_3': -16.600772857666016, 'loss_4': -0.46417737007141113, 'epoch': 24.09}
{'loss': 0.0102, 'grad_norm': 7.096665859222412, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.00722014345228672, 'loss_2': 0.002960205078125, 'loss_3': -16.526203155517578, 'loss_4': -0.09517943859100342, 'epoch': 24.09}
{'loss': 0.0083, 'grad_norm': 5.204799175262451, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.0071709672920405865, 'loss_2': 0.0010833740234375, 'loss_3': -16.56218147277832, 'loss_4': 0.06202562525868416, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 16:59:47,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:47,049 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:25<17:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:54,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011624493636190891, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.228, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0077982330694794655, 'eval_loss_2': 0.0038262605667114258, 'eval_loss_3': -18.202857971191406, 'eval_loss_4': 0.04870406538248062, 'epoch': 24.1}
{'loss': 0.0124, 'grad_norm': 6.9854960441589355, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.011707710102200508, 'loss_2': 0.0006427764892578125, 'loss_3': -16.73373794555664, 'loss_4': -0.08454936742782593, 'epoch': 24.1}
{'loss': 0.0375, 'grad_norm': 19.835554122924805, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.03536897152662277, 'loss_2': 0.0021305084228515625, 'loss_3': -16.393375396728516, 'loss_4': 0.15952704846858978, 'epoch': 24.11}
{'loss': 0.0114, 'grad_norm': 4.742796897888184, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.004646580200642347, 'loss_2': 0.0067138671875, 'loss_3': -16.534503936767578, 'loss_4': -0.23625698685646057, 'epoch': 24.12}
{'loss': 0.0204, 'grad_norm': 8.564966201782227, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.009942879900336266, 'loss_2': 0.0104217529296875, 'loss_3': -16.71058464050293, 'loss_4': 0.0379066988825798, 'epoch': 24.12}
{'loss': 0.0101, 'grad_norm': 4.888094902038574, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.005593729671090841, 'loss_2': 0.004486083984375, 'loss_3': -16.544822692871094, 'loss_4': -0.2446271777153015, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 16:59:54,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:54,411 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:32<17:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:01,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01220532413572073, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.245, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007997952401638031, 'eval_loss_2': 0.0042073726654052734, 'eval_loss_3': -18.2069034576416, 'eval_loss_4': 0.03580138087272644, 'epoch': 24.13}
{'loss': 0.0037, 'grad_norm': 4.00361442565918, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.002871481468901038, 'loss_2': 0.0008220672607421875, 'loss_3': -16.601802825927734, 'loss_4': -0.1797349900007248, 'epoch': 24.13}
{'loss': 0.0043, 'grad_norm': 4.560318946838379, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.0032994390930980444, 'loss_2': 0.001010894775390625, 'loss_3': -16.609935760498047, 'loss_4': 0.23478931188583374, 'epoch': 24.14}
{'loss': 0.0117, 'grad_norm': 7.269094944000244, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.010171459056437016, 'loss_2': 0.0015420913696289062, 'loss_3': -16.459369659423828, 'loss_4': -0.28539568185806274, 'epoch': 24.15}
{'loss': 0.01, 'grad_norm': 6.2126264572143555, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.006204828154295683, 'loss_2': 0.003795623779296875, 'loss_3': -16.57714080810547, 'loss_4': 0.012966915965080261, 'epoch': 24.15}
{'loss': 0.0054, 'grad_norm': 4.54186487197876, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.0035603567957878113, 'loss_2': 0.0017938613891601562, 'loss_3': -16.562641143798828, 'loss_4': 0.33052414655685425, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 17:00:01,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:01,779 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:39<17:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:09,149 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011980291455984116, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007728453725576401, 'eval_loss_2': 0.004251837730407715, 'eval_loss_3': -18.209075927734375, 'eval_loss_4': 0.05459748953580856, 'epoch': 24.16}
{'loss': 0.0106, 'grad_norm': 5.636720180511475, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.004388453904539347, 'loss_2': 0.00617218017578125, 'loss_3': -16.460552215576172, 'loss_4': -0.40327274799346924, 'epoch': 24.16}
{'loss': 0.0157, 'grad_norm': 6.510435581207275, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.00548590486869216, 'loss_2': 0.01020050048828125, 'loss_3': -16.358264923095703, 'loss_4': -0.07585260272026062, 'epoch': 24.17}
{'loss': 0.0083, 'grad_norm': 6.14558744430542, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.006457979790866375, 'loss_2': 0.001811981201171875, 'loss_3': -16.490676879882812, 'loss_4': 0.060957275331020355, 'epoch': 24.17}
{'loss': 0.0106, 'grad_norm': 4.578273296356201, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.004284669179469347, 'loss_2': 0.0062713623046875, 'loss_3': -16.525501251220703, 'loss_4': 0.20915885269641876, 'epoch': 24.18}
{'loss': 0.0102, 'grad_norm': 5.332846164703369, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.0076303244568407536, 'loss_2': 0.0025844573974609375, 'loss_3': -16.593189239501953, 'loss_4': -0.06609731912612915, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 17:00:09,149 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:09,149 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:47<17:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:16,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011495491489768028, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007797425612807274, 'eval_loss_2': 0.0036980658769607544, 'eval_loss_3': -18.2132625579834, 'eval_loss_4': 0.14101490378379822, 'epoch': 24.19}
{'loss': 0.0047, 'grad_norm': 4.875199317932129, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.0025650563184171915, 'loss_2': 0.0021648406982421875, 'loss_3': -16.498632431030273, 'loss_4': 0.7014344930648804, 'epoch': 24.19}
{'loss': 0.0675, 'grad_norm': 18.176212310791016, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.06123073399066925, 'loss_2': 0.00630950927734375, 'loss_3': -16.580257415771484, 'loss_4': 0.7351329326629639, 'epoch': 24.2}
{'loss': 0.01, 'grad_norm': 5.072219371795654, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.005341063253581524, 'loss_2': 0.004638671875, 'loss_3': -16.34584617614746, 'loss_4': -0.30774223804473877, 'epoch': 24.2}
{'loss': 0.0123, 'grad_norm': 6.122697830200195, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.010195747949182987, 'loss_2': 0.002086639404296875, 'loss_3': -16.402587890625, 'loss_4': 0.002730701118707657, 'epoch': 24.21}
{'loss': 0.0119, 'grad_norm': 5.432046890258789, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.00650535523891449, 'loss_2': 0.00543212890625, 'loss_3': -16.54206085205078, 'loss_4': 0.32548201084136963, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 17:00:16,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:16,511 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:54<17:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:23,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010479610413312912, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.497, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007437155116349459, 'eval_loss_2': 0.0030424557626247406, 'eval_loss_3': -18.21488380432129, 'eval_loss_4': 0.1995294988155365, 'epoch': 24.22}
{'loss': 0.0121, 'grad_norm': 4.9610514640808105, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.007290109992027283, 'loss_2': 0.004791259765625, 'loss_3': -16.42197036743164, 'loss_4': 0.29109251499176025, 'epoch': 24.22}
{'loss': 0.0092, 'grad_norm': 4.3859148025512695, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.004494549706578255, 'loss_2': 0.004669189453125, 'loss_3': -16.63235092163086, 'loss_4': 0.37547796964645386, 'epoch': 24.23}
{'loss': 0.007, 'grad_norm': 4.745660781860352, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.0025699161924421787, 'loss_2': 0.00440216064453125, 'loss_3': -16.680564880371094, 'loss_4': -0.018317826092243195, 'epoch': 24.23}
{'loss': 0.0107, 'grad_norm': 11.582623481750488, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.0106369499117136, 'loss_2': 9.775161743164062e-05, 'loss_3': -16.453399658203125, 'loss_4': -0.16196662187576294, 'epoch': 24.24}
{'loss': 0.0114, 'grad_norm': 9.567047119140625, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.009508580900728703, 'loss_2': 0.0019245147705078125, 'loss_3': -16.44888687133789, 'loss_4': -0.022740811109542847, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 17:00:23,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:23,872 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:43:02<17:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:31,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009926775470376015, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.939, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.006946565117686987, 'eval_loss_2': 0.0029802098870277405, 'eval_loss_3': -18.217866897583008, 'eval_loss_4': 0.2406993955373764, 'epoch': 24.24}
{'loss': 0.0101, 'grad_norm': 4.671613693237305, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.004634850192815065, 'loss_2': 0.00543212890625, 'loss_3': -16.424236297607422, 'loss_4': 0.09688319265842438, 'epoch': 24.25}
{'loss': 0.0055, 'grad_norm': 4.606854438781738, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.0053582689724862576, 'loss_2': 0.0001652240753173828, 'loss_3': -16.594886779785156, 'loss_4': 0.019549205899238586, 'epoch': 24.26}
{'loss': 0.0061, 'grad_norm': 5.116794586181641, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.004822180140763521, 'loss_2': 0.0012302398681640625, 'loss_3': -16.566173553466797, 'loss_4': 0.6608021855354309, 'epoch': 24.26}
{'loss': 0.0052, 'grad_norm': 4.544977188110352, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.003915642388164997, 'loss_2': 0.0012521743774414062, 'loss_3': -16.262805938720703, 'loss_4': 0.14363020658493042, 'epoch': 24.27}
{'loss': 0.0054, 'grad_norm': 4.737115383148193, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.0036479535046964884, 'loss_2': 0.0017147064208984375, 'loss_3': -16.56516456604004, 'loss_4': 0.09961951524019241, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 17:00:31,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:31,223 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:43:09<16:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:38,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009788191877305508, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.0071186041459441185, 'eval_loss_2': 0.002669587731361389, 'eval_loss_3': -18.213367462158203, 'eval_loss_4': 0.31458261609077454, 'epoch': 24.27}
{'loss': 0.0112, 'grad_norm': 4.687028408050537, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.0030712781008332968, 'loss_2': 0.00809478759765625, 'loss_3': -16.66577911376953, 'loss_4': 0.007372312247753143, 'epoch': 24.28}
{'loss': 0.0099, 'grad_norm': 4.655431747436523, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.005057291127741337, 'loss_2': 0.00484466552734375, 'loss_3': -16.346439361572266, 'loss_4': 0.08132956176996231, 'epoch': 24.28}
{'loss': 0.0113, 'grad_norm': 4.598209857940674, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.005090340971946716, 'loss_2': 0.0061798095703125, 'loss_3': -16.6525821685791, 'loss_4': 0.8323594331741333, 'epoch': 24.29}
{'loss': 0.0109, 'grad_norm': 4.770840644836426, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.005707134027034044, 'loss_2': 0.00514984130859375, 'loss_3': -16.420032501220703, 'loss_4': 0.5146501660346985, 'epoch': 24.3}
{'loss': 0.01, 'grad_norm': 4.9058966636657715, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.005754874553531408, 'loss_2': 0.0041961669921875, 'loss_3': -16.547637939453125, 'loss_4': 0.6035680770874023, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 17:00:38,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:38,576 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:43:16<17:22,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 17:00:46,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01039046049118042, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007696911692619324, 'eval_loss_2': 0.002693548798561096, 'eval_loss_3': -18.217500686645508, 'eval_loss_4': 0.3734405040740967, 'epoch': 24.3}
{'loss': 0.0085, 'grad_norm': 4.646780967712402, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.0035586312878876925, 'loss_2': 0.004962921142578125, 'loss_3': -16.569198608398438, 'loss_4': 0.8469622731208801, 'epoch': 24.31}
{'loss': 0.0113, 'grad_norm': 5.108573913574219, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.0030314528848975897, 'loss_2': 0.0083160400390625, 'loss_3': -16.73088836669922, 'loss_4': 0.18597133457660675, 'epoch': 24.31}
{'loss': 0.019, 'grad_norm': 11.288256645202637, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.013824444264173508, 'loss_2': 0.0051727294921875, 'loss_3': -16.50023651123047, 'loss_4': 0.4305244982242584, 'epoch': 24.32}
{'loss': 0.0064, 'grad_norm': 4.224691390991211, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.002514926018193364, 'loss_2': 0.0038909912109375, 'loss_3': -16.309307098388672, 'loss_4': 0.25996196269989014, 'epoch': 24.33}
{'loss': 0.0107, 'grad_norm': 6.496702194213867, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.00892713200300932, 'loss_2': 0.0017871856689453125, 'loss_3': -16.471345901489258, 'loss_4': -0.117743119597435, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 17:00:46,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:46,133 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:24<16:55,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:00:53,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009592819027602673, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.675, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006722244434058666, 'eval_loss_2': 0.0028705745935440063, 'eval_loss_3': -18.21149253845215, 'eval_loss_4': 0.4005751609802246, 'epoch': 24.33}
{'loss': 0.0088, 'grad_norm': 5.111961841583252, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.0031100835185498, 'loss_2': 0.00567626953125, 'loss_3': -16.60910415649414, 'loss_4': 0.11676234006881714, 'epoch': 24.34}
{'loss': 0.0155, 'grad_norm': 6.262986660003662, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.013344425708055496, 'loss_2': 0.002109527587890625, 'loss_3': -16.403074264526367, 'loss_4': 0.12774333357810974, 'epoch': 24.34}
{'loss': 0.0142, 'grad_norm': 5.01636266708374, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.007025616709142923, 'loss_2': 0.007144927978515625, 'loss_3': -16.437641143798828, 'loss_4': 0.20043225586414337, 'epoch': 24.35}
{'loss': 0.0062, 'grad_norm': 5.160934925079346, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.0057110246270895, 'loss_2': 0.0004849433898925781, 'loss_3': -16.476972579956055, 'loss_4': 0.14088961482048035, 'epoch': 24.35}
{'loss': 0.0317, 'grad_norm': 21.99420738220215, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.030498545616865158, 'loss_2': 0.00119781494140625, 'loss_3': -16.38257598876953, 'loss_4': 0.6542002558708191, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 17:00:53,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:53,508 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:31<16:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:00,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009472755715250969, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.045, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006438878830522299, 'eval_loss_2': 0.003033876419067383, 'eval_loss_3': -18.222909927368164, 'eval_loss_4': 0.43819931149482727, 'epoch': 24.36}
{'loss': 0.0106, 'grad_norm': 5.013875484466553, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.004213571082800627, 'loss_2': 0.00640106201171875, 'loss_3': -16.320783615112305, 'loss_4': -0.018941234797239304, 'epoch': 24.37}
{'loss': 0.01, 'grad_norm': 5.066575527191162, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.003829758381471038, 'loss_2': 0.006175994873046875, 'loss_3': -16.609235763549805, 'loss_4': 0.35234561562538147, 'epoch': 24.37}
{'loss': 0.0863, 'grad_norm': 17.47996711730957, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.08406385034322739, 'loss_2': 0.0022678375244140625, 'loss_3': -16.611331939697266, 'loss_4': 0.719081461429596, 'epoch': 24.38}
{'loss': 0.0273, 'grad_norm': 15.205089569091797, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.02027960866689682, 'loss_2': 0.00698089599609375, 'loss_3': -16.52024269104004, 'loss_4': 0.6036930084228516, 'epoch': 24.38}
{'loss': 0.0063, 'grad_norm': 6.62986421585083, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.005322963930666447, 'loss_2': 0.00093841552734375, 'loss_3': -16.60177993774414, 'loss_4': 0.0027709007263183594, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 17:01:00,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:00,878 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:39<16:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:08,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009249765425920486, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.231, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00646893959492445, 'eval_loss_2': 0.002780824899673462, 'eval_loss_3': -18.215330123901367, 'eval_loss_4': 0.47846996784210205, 'epoch': 24.39}
{'loss': 0.0096, 'grad_norm': 4.865220546722412, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0051868068985641, 'loss_2': 0.004444122314453125, 'loss_3': -16.363658905029297, 'loss_4': 0.7109798192977905, 'epoch': 24.4}
{'loss': 0.0069, 'grad_norm': 4.3549394607543945, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.003130831988528371, 'loss_2': 0.0037479400634765625, 'loss_3': -16.502399444580078, 'loss_4': 0.4405209422111511, 'epoch': 24.4}
{'loss': 0.0105, 'grad_norm': 12.888779640197754, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.007224416825920343, 'loss_2': 0.003299713134765625, 'loss_3': -16.564937591552734, 'loss_4': 0.7074240446090698, 'epoch': 24.41}
{'loss': 0.0044, 'grad_norm': 4.3703484535217285, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.003479192964732647, 'loss_2': 0.000911712646484375, 'loss_3': -16.381807327270508, 'loss_4': 0.5307044982910156, 'epoch': 24.41}
{'loss': 0.0171, 'grad_norm': 11.216407775878906, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.013673290610313416, 'loss_2': 0.00342559814453125, 'loss_3': -16.563926696777344, 'loss_4': 0.3506210446357727, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 17:01:08,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:08,253 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:46<16:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:15,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00969467032700777, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.428, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006501039490103722, 'eval_loss_2': 0.0031936317682266235, 'eval_loss_3': -18.21817970275879, 'eval_loss_4': 0.5275055170059204, 'epoch': 24.42}
{'loss': 0.008, 'grad_norm': 5.67105770111084, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.0077934255823493, 'loss_2': 0.0002243518829345703, 'loss_3': -16.643474578857422, 'loss_4': 0.8387504816055298, 'epoch': 24.42}
{'loss': 0.0106, 'grad_norm': 7.173831462860107, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.0072237905114889145, 'loss_2': 0.003368377685546875, 'loss_3': -16.425594329833984, 'loss_4': 0.17357879877090454, 'epoch': 24.43}
{'loss': 0.0063, 'grad_norm': 5.153112888336182, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.005686933174729347, 'loss_2': 0.0006003379821777344, 'loss_3': -16.513774871826172, 'loss_4': 0.38115426898002625, 'epoch': 24.44}
{'loss': 0.0123, 'grad_norm': 4.5583319664001465, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.003817360382527113, 'loss_2': 0.0084381103515625, 'loss_3': -16.56804084777832, 'loss_4': 0.4763317108154297, 'epoch': 24.44}
{'loss': 0.0159, 'grad_norm': 6.584219455718994, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.007669157348573208, 'loss_2': 0.0081939697265625, 'loss_3': -16.458148956298828, 'loss_4': 0.3773750066757202, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 17:01:15,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:15,618 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:53<16:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:22,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009636934846639633, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.22, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006075393874198198, 'eval_loss_2': 0.003561541438102722, 'eval_loss_3': -18.22111701965332, 'eval_loss_4': 0.5805317163467407, 'epoch': 24.45}
{'loss': 0.0096, 'grad_norm': 5.36506462097168, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.00491007836535573, 'loss_2': 0.00466156005859375, 'loss_3': -16.572973251342773, 'loss_4': 0.42123109102249146, 'epoch': 24.45}
{'loss': 0.0048, 'grad_norm': 4.822322368621826, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.00338955270126462, 'loss_2': 0.0014057159423828125, 'loss_3': -16.66774559020996, 'loss_4': 0.31387948989868164, 'epoch': 24.46}
{'loss': 0.0079, 'grad_norm': 5.27053165435791, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.005278972443193197, 'loss_2': 0.002628326416015625, 'loss_3': -16.484188079833984, 'loss_4': 0.42177674174308777, 'epoch': 24.47}
{'loss': 0.0103, 'grad_norm': 5.246282577514648, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.006362864747643471, 'loss_2': 0.003963470458984375, 'loss_3': -16.53614044189453, 'loss_4': 0.5606343150138855, 'epoch': 24.47}
{'loss': 0.0078, 'grad_norm': 6.191721439361572, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.006628788076341152, 'loss_2': 0.001178741455078125, 'loss_3': -16.807960510253906, 'loss_4': 0.6894066333770752, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 17:01:22,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:22,993 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:44:01<16:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:30,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009077999740839005, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.699, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005959581583738327, 'eval_loss_2': 0.0031184181571006775, 'eval_loss_3': -18.223644256591797, 'eval_loss_4': 0.6074575185775757, 'epoch': 24.48}
{'loss': 0.0271, 'grad_norm': 15.979021072387695, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.020564163103699684, 'loss_2': 0.00650787353515625, 'loss_3': -16.47206687927246, 'loss_4': 0.3496509790420532, 'epoch': 24.48}
{'loss': 0.0063, 'grad_norm': 4.837066173553467, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.003542213933542371, 'loss_2': 0.002727508544921875, 'loss_3': -16.591915130615234, 'loss_4': 0.304577112197876, 'epoch': 24.49}
{'loss': 0.0074, 'grad_norm': 4.2873711585998535, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.0026764420326799154, 'loss_2': 0.00473785400390625, 'loss_3': -16.554759979248047, 'loss_4': 0.7555084824562073, 'epoch': 24.49}
{'loss': 0.0148, 'grad_norm': 5.3917036056518555, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.007183173671364784, 'loss_2': 0.00763702392578125, 'loss_3': -16.45511817932129, 'loss_4': 0.7004795074462891, 'epoch': 24.5}
{'loss': 0.0097, 'grad_norm': 7.710764408111572, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.007821177132427692, 'loss_2': 0.00185394287109375, 'loss_3': -16.558210372924805, 'loss_4': 0.6558352708816528, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 17:01:30,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:30,365 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:44:08<16:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:37,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009310891851782799, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006055048201233149, 'eval_loss_2': 0.0032558441162109375, 'eval_loss_3': -18.213796615600586, 'eval_loss_4': 0.6079515218734741, 'epoch': 24.51}
{'loss': 0.013, 'grad_norm': 5.40308952331543, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.005986334756016731, 'loss_2': 0.006999969482421875, 'loss_3': -16.574710845947266, 'loss_4': 0.8379311561584473, 'epoch': 24.51}
{'loss': 0.0062, 'grad_norm': 4.8869242668151855, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.004111510701477528, 'loss_2': 0.002040863037109375, 'loss_3': -16.476425170898438, 'loss_4': 0.8472109436988831, 'epoch': 24.52}
{'loss': 0.0068, 'grad_norm': 4.922360897064209, 'learning_rate': 5.5e-06, 'loss_1': 0.003455212339758873, 'loss_2': 0.00330352783203125, 'loss_3': -16.546459197998047, 'loss_4': 0.40609169006347656, 'epoch': 24.52}
{'loss': 0.0425, 'grad_norm': 12.826422691345215, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.04011007398366928, 'loss_2': 0.002429962158203125, 'loss_3': -16.449302673339844, 'loss_4': 0.4390442967414856, 'epoch': 24.53}
{'loss': 0.0192, 'grad_norm': 7.628555774688721, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.007786203641444445, 'loss_2': 0.01137542724609375, 'loss_3': -16.72882080078125, 'loss_4': 0.3167422115802765, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 17:01:37,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:37,729 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:44:15<16:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:45,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010361187160015106, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.438, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006261564791202545, 'eval_loss_2': 0.004099622368812561, 'eval_loss_3': -18.216903686523438, 'eval_loss_4': 0.5498180389404297, 'epoch': 24.53}
{'loss': 0.0222, 'grad_norm': 8.218135833740234, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.015257885679602623, 'loss_2': 0.00696563720703125, 'loss_3': -16.607894897460938, 'loss_4': 0.43906521797180176, 'epoch': 24.54}
{'loss': 0.0159, 'grad_norm': 7.939896583557129, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.009657622314989567, 'loss_2': 0.0062103271484375, 'loss_3': -16.52120590209961, 'loss_4': 0.2989672124385834, 'epoch': 24.55}
{'loss': 0.0143, 'grad_norm': 5.463573932647705, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.006998552940785885, 'loss_2': 0.00727081298828125, 'loss_3': -16.542272567749023, 'loss_4': 0.587852954864502, 'epoch': 24.55}
{'loss': 0.0116, 'grad_norm': 5.027437686920166, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.004743460565805435, 'loss_2': 0.0068359375, 'loss_3': -16.523876190185547, 'loss_4': 0.27215296030044556, 'epoch': 24.56}
{'loss': 0.0115, 'grad_norm': 6.60995626449585, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.006943653337657452, 'loss_2': 0.00450897216796875, 'loss_3': -16.596004486083984, 'loss_4': 0.530763566493988, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 17:01:45,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:45,083 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:23<16:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:52,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009200187399983406, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.176, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005793945863842964, 'eval_loss_2': 0.003406241536140442, 'eval_loss_3': -18.215391159057617, 'eval_loss_4': 0.5635033845901489, 'epoch': 24.56}
{'loss': 0.0118, 'grad_norm': 5.389392852783203, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.010413006879389286, 'loss_2': 0.0013532638549804688, 'loss_3': -16.376115798950195, 'loss_4': 0.8293694257736206, 'epoch': 24.57}
{'loss': 0.0101, 'grad_norm': 4.966448783874512, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.0069025675766170025, 'loss_2': 0.0032062530517578125, 'loss_3': -16.466472625732422, 'loss_4': 0.03998277708888054, 'epoch': 24.58}
{'loss': 0.0065, 'grad_norm': 4.887516498565674, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.002602821681648493, 'loss_2': 0.00388336181640625, 'loss_3': -16.57394790649414, 'loss_4': 0.2111908197402954, 'epoch': 24.58}
{'loss': 0.0095, 'grad_norm': 5.5544328689575195, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.005998017266392708, 'loss_2': 0.003520965576171875, 'loss_3': -16.31920051574707, 'loss_4': 0.3995201587677002, 'epoch': 24.59}
{'loss': 0.0092, 'grad_norm': 6.668797016143799, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.008746327832341194, 'loss_2': 0.0004215240478515625, 'loss_3': -16.526294708251953, 'loss_4': 0.5866062045097351, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 17:01:52,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:52,439 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:30<16:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:59,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008673485368490219, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.434, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005419577471911907, 'eval_loss_2': 0.0032539069652557373, 'eval_loss_3': -18.21744728088379, 'eval_loss_4': 0.5795019865036011, 'epoch': 24.59}
{'loss': 0.0051, 'grad_norm': 4.73491096496582, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.002546018688008189, 'loss_2': 0.002532958984375, 'loss_3': -16.653356552124023, 'loss_4': 0.2668127417564392, 'epoch': 24.6}
{'loss': 0.006, 'grad_norm': 5.964595794677734, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.005715036299079657, 'loss_2': 0.0003342628479003906, 'loss_3': -16.63633155822754, 'loss_4': 0.8654992580413818, 'epoch': 24.6}
{'loss': 0.0107, 'grad_norm': 4.943370342254639, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.004679783247411251, 'loss_2': 0.00603485107421875, 'loss_3': -16.48695182800293, 'loss_4': 0.26370182633399963, 'epoch': 24.61}
{'loss': 0.0072, 'grad_norm': 4.924561023712158, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.00488815875723958, 'loss_2': 0.002288818359375, 'loss_3': -16.53289794921875, 'loss_4': 0.10650419443845749, 'epoch': 24.62}
{'loss': 0.007, 'grad_norm': 5.405492782592773, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.005380167160183191, 'loss_2': 0.0016431808471679688, 'loss_3': -16.701194763183594, 'loss_4': 0.723477840423584, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 17:01:59,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:59,795 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:37<15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:07,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008578147739171982, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.307, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.005399305839091539, 'eval_loss_2': 0.0031788423657417297, 'eval_loss_3': -18.216964721679688, 'eval_loss_4': 0.5942495465278625, 'epoch': 24.62}
{'loss': 0.0133, 'grad_norm': 7.41878604888916, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.010967983864247799, 'loss_2': 0.0023632049560546875, 'loss_3': -16.538942337036133, 'loss_4': 0.13969352841377258, 'epoch': 24.63}
{'loss': 0.0037, 'grad_norm': 4.409825325012207, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.0019367104396224022, 'loss_2': 0.0018100738525390625, 'loss_3': -16.464757919311523, 'loss_4': 0.11258330941200256, 'epoch': 24.63}
{'loss': 0.0067, 'grad_norm': 5.031279563903809, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.0030969632789492607, 'loss_2': 0.003604888916015625, 'loss_3': -16.46401023864746, 'loss_4': 0.46850693225860596, 'epoch': 24.64}
{'loss': 0.0792, 'grad_norm': 16.705669403076172, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.07858172804117203, 'loss_2': 0.0006003379821777344, 'loss_3': -16.72677230834961, 'loss_4': 0.6967377066612244, 'epoch': 24.65}
{'loss': 0.0047, 'grad_norm': 4.1946258544921875, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.003237631404772401, 'loss_2': 0.00146484375, 'loss_3': -16.552831649780273, 'loss_4': 0.21283510327339172, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 17:02:07,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:07,153 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:45<15:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:14,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00904855690896511, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.5, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005750676617026329, 'eval_loss_2': 0.0032978802919387817, 'eval_loss_3': -18.212785720825195, 'eval_loss_4': 0.5942074060440063, 'epoch': 24.65}
{'loss': 0.0071, 'grad_norm': 6.068785190582275, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.005062046926468611, 'loss_2': 0.0019969940185546875, 'loss_3': -16.56503677368164, 'loss_4': 0.569606602191925, 'epoch': 24.66}
{'loss': 0.0069, 'grad_norm': 4.590730667114258, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.003549274755641818, 'loss_2': 0.003376007080078125, 'loss_3': -16.653404235839844, 'loss_4': 0.6752305030822754, 'epoch': 24.66}
{'loss': 0.0126, 'grad_norm': 6.9695515632629395, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.007573192473500967, 'loss_2': 0.0050048828125, 'loss_3': -16.610157012939453, 'loss_4': 0.9537845253944397, 'epoch': 24.67}
{'loss': 0.0215, 'grad_norm': 9.928808212280273, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.018621062859892845, 'loss_2': 0.002899169921875, 'loss_3': -16.58867645263672, 'loss_4': 0.2215491086244583, 'epoch': 24.67}
{'loss': 0.0051, 'grad_norm': 4.715517997741699, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.0028631072491407394, 'loss_2': 0.002227783203125, 'loss_3': -16.569236755371094, 'loss_4': 0.4434910714626312, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 17:02:14,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:14,517 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:52<15:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:21,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009659763425588608, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.681, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0064496807754039764, 'eval_loss_2': 0.0032100826501846313, 'eval_loss_3': -18.212263107299805, 'eval_loss_4': 0.6163191795349121, 'epoch': 24.68}
{'loss': 0.0099, 'grad_norm': 4.79185676574707, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.005713007878512144, 'loss_2': 0.00420379638671875, 'loss_3': -16.49043083190918, 'loss_4': 0.9380616545677185, 'epoch': 24.69}
{'loss': 0.0068, 'grad_norm': 4.693491458892822, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.004517823923379183, 'loss_2': 0.0022449493408203125, 'loss_3': -16.558765411376953, 'loss_4': 0.18085481226444244, 'epoch': 24.69}
{'loss': 0.0059, 'grad_norm': 5.249635219573975, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.005015259608626366, 'loss_2': 0.0008940696716308594, 'loss_3': -16.49510383605957, 'loss_4': 0.42433908581733704, 'epoch': 24.7}
{'loss': 0.0099, 'grad_norm': 4.505677223205566, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.0036678132601082325, 'loss_2': 0.0062255859375, 'loss_3': -16.468387603759766, 'loss_4': 0.2543509304523468, 'epoch': 24.7}
{'loss': 0.0089, 'grad_norm': 6.453910827636719, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.008671872317790985, 'loss_2': 0.0002002716064453125, 'loss_3': -16.46051788330078, 'loss_4': 0.3848731219768524, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 17:02:21,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:21,864 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:45:00<15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:29,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009363105520606041, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006229547783732414, 'eval_loss_2': 0.0031335577368736267, 'eval_loss_3': -18.207294464111328, 'eval_loss_4': 0.6521788239479065, 'epoch': 24.71}
{'loss': 0.0073, 'grad_norm': 5.523317337036133, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.005200084764510393, 'loss_2': 0.0020599365234375, 'loss_3': -16.4428768157959, 'loss_4': 0.20967617630958557, 'epoch': 24.72}
{'loss': 0.0086, 'grad_norm': 5.844163417816162, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.004965866915881634, 'loss_2': 0.0036468505859375, 'loss_3': -16.62821388244629, 'loss_4': 0.6541478633880615, 'epoch': 24.72}
{'loss': 0.0175, 'grad_norm': 7.426761150360107, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.015449712984263897, 'loss_2': 0.0020961761474609375, 'loss_3': -16.37795639038086, 'loss_4': 0.3892609775066376, 'epoch': 24.73}
{'loss': 0.0104, 'grad_norm': 4.874887943267822, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.0048090326599776745, 'loss_2': 0.0055694580078125, 'loss_3': -16.5614013671875, 'loss_4': 0.8378407955169678, 'epoch': 24.73}
{'loss': 0.0091, 'grad_norm': 5.216501712799072, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.008206889033317566, 'loss_2': 0.0008726119995117188, 'loss_3': -16.54014778137207, 'loss_4': 0.5870591998100281, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 17:02:29,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:29,220 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:45:07<15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:36,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009134924039244652, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.005944534204900265, 'eval_loss_2': 0.0031903907656669617, 'eval_loss_3': -18.201210021972656, 'eval_loss_4': 0.6832594871520996, 'epoch': 24.74}
{'loss': 0.0105, 'grad_norm': 5.044178485870361, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.004757976159453392, 'loss_2': 0.00577545166015625, 'loss_3': -16.62342071533203, 'loss_4': 0.10166791081428528, 'epoch': 24.74}
{'loss': 0.0141, 'grad_norm': 5.2161102294921875, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.00553862564265728, 'loss_2': 0.0085601806640625, 'loss_3': -16.590747833251953, 'loss_4': 0.5691225528717041, 'epoch': 24.75}
{'loss': 0.0074, 'grad_norm': 4.261107444763184, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.0030646363738924265, 'loss_2': 0.004306793212890625, 'loss_3': -16.402145385742188, 'loss_4': 0.5915001034736633, 'epoch': 24.76}
{'loss': 0.0063, 'grad_norm': 5.110970973968506, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.00470286700874567, 'loss_2': 0.001598358154296875, 'loss_3': -16.470401763916016, 'loss_4': 0.7850438356399536, 'epoch': 24.76}
{'loss': 0.0164, 'grad_norm': 5.464014053344727, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.008615536615252495, 'loss_2': 0.007778167724609375, 'loss_3': -16.641586303710938, 'loss_4': 0.7253860235214233, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 17:02:36,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:36,569 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:45:14<15:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:43,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008703134953975677, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.739, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0056618377566337585, 'eval_loss_2': 0.003041297197341919, 'eval_loss_3': -18.207107543945312, 'eval_loss_4': 0.6574786901473999, 'epoch': 24.77}
{'loss': 0.0152, 'grad_norm': 12.173989295959473, 'learning_rate': 5.25e-06, 'loss_1': 0.013560800813138485, 'loss_2': 0.0016307830810546875, 'loss_3': -16.65202522277832, 'loss_4': 0.5860762000083923, 'epoch': 24.77}
{'loss': 0.0095, 'grad_norm': 5.373040199279785, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.008980139158666134, 'loss_2': 0.0005106925964355469, 'loss_3': -16.53469467163086, 'loss_4': 0.542861819267273, 'epoch': 24.78}
{'loss': 0.0046, 'grad_norm': 4.359483242034912, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.0028251640032976866, 'loss_2': 0.001750946044921875, 'loss_3': -16.91419792175293, 'loss_4': 0.30937281250953674, 'epoch': 24.78}
{'loss': 0.0063, 'grad_norm': 5.297663688659668, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.004244018346071243, 'loss_2': 0.00208282470703125, 'loss_3': -16.544513702392578, 'loss_4': 0.6656757593154907, 'epoch': 24.79}
{'loss': 0.007, 'grad_norm': 4.639409065246582, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.003926881123334169, 'loss_2': 0.00308990478515625, 'loss_3': -16.757244110107422, 'loss_4': 0.31398677825927734, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 17:02:43,921 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:43,921 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:22<15:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:51,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009584775194525719, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005818127188831568, 'eval_loss_2': 0.0037666484713554382, 'eval_loss_3': -18.218290328979492, 'eval_loss_4': 0.6367717385292053, 'epoch': 24.8}
{'loss': 0.0198, 'grad_norm': 12.530435562133789, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.01444221567362547, 'loss_2': 0.005344390869140625, 'loss_3': -16.583969116210938, 'loss_4': 0.16022370755672455, 'epoch': 24.8}
{'loss': 0.0054, 'grad_norm': 4.431822299957275, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.0036657892633229494, 'loss_2': 0.0017833709716796875, 'loss_3': -16.673458099365234, 'loss_4': 0.6876608729362488, 'epoch': 24.81}
{'loss': 0.0097, 'grad_norm': 7.853439807891846, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.007714279927313328, 'loss_2': 0.0019931793212890625, 'loss_3': -16.45412826538086, 'loss_4': 0.7406355142593384, 'epoch': 24.81}
{'loss': 0.0124, 'grad_norm': 7.121642112731934, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.008769739419221878, 'loss_2': 0.00366973876953125, 'loss_3': -16.47989845275879, 'loss_4': 0.23698359727859497, 'epoch': 24.82}
{'loss': 0.0068, 'grad_norm': 4.622457027435303, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.004509965423494577, 'loss_2': 0.002323150634765625, 'loss_3': -16.493144989013672, 'loss_4': 0.697018027305603, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 17:02:51,285 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:51,285 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:29<15:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:58,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009615438990294933, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.696, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0056408969685435295, 'eval_loss_2': 0.003974542021751404, 'eval_loss_3': -18.217926025390625, 'eval_loss_4': 0.5913164019584656, 'epoch': 24.83}
{'loss': 0.0065, 'grad_norm': 4.613669395446777, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.0028789066709578037, 'loss_2': 0.0035800933837890625, 'loss_3': -16.576675415039062, 'loss_4': 0.9125646352767944, 'epoch': 24.83}
{'loss': 0.0075, 'grad_norm': 5.87850284576416, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.004673269111663103, 'loss_2': 0.00286865234375, 'loss_3': -16.532352447509766, 'loss_4': 0.3286615014076233, 'epoch': 24.84}
{'loss': 0.0114, 'grad_norm': 4.997023582458496, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.0058344039134681225, 'loss_2': 0.00553131103515625, 'loss_3': -16.55535888671875, 'loss_4': 0.12170011550188065, 'epoch': 24.84}
{'loss': 0.0042, 'grad_norm': 4.495871067047119, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.003350520506501198, 'loss_2': 0.00080108642578125, 'loss_3': -16.486011505126953, 'loss_4': 0.7464559674263, 'epoch': 24.85}
{'loss': 0.0081, 'grad_norm': 4.669524192810059, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.004036861006170511, 'loss_2': 0.004077911376953125, 'loss_3': -16.743968963623047, 'loss_4': 0.46580275893211365, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 17:02:58,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:58,642 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:36<15:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:06,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009402239695191383, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.227, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.006087386514991522, 'eval_loss_2': 0.0033148527145385742, 'eval_loss_3': -18.223119735717773, 'eval_loss_4': 0.5922556519508362, 'epoch': 24.85}
{'loss': 0.0073, 'grad_norm': 4.439481735229492, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.003062998643144965, 'loss_2': 0.00428009033203125, 'loss_3': -16.51279067993164, 'loss_4': 0.8321441411972046, 'epoch': 24.86}
{'loss': 0.0036, 'grad_norm': 4.453958034515381, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.0034710895270109177, 'loss_2': 0.00015807151794433594, 'loss_3': -16.639604568481445, 'loss_4': 0.26037025451660156, 'epoch': 24.87}
{'loss': 0.0105, 'grad_norm': 4.509437084197998, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.00351330591365695, 'loss_2': 0.006954193115234375, 'loss_3': -16.585784912109375, 'loss_4': 0.892231822013855, 'epoch': 24.87}
{'loss': 0.0029, 'grad_norm': 4.309247016906738, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.002490117447450757, 'loss_2': 0.0004105567932128906, 'loss_3': -16.642189025878906, 'loss_4': 0.3450767397880554, 'epoch': 24.88}
{'loss': 0.0095, 'grad_norm': 5.961640357971191, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.009422261267900467, 'loss_2': 3.9637088775634766e-05, 'loss_3': -16.514358520507812, 'loss_4': 0.44310659170150757, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 17:03:06,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:06,002 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:44<15:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:13,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008865167386829853, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006283452268689871, 'eval_loss_2': 0.0025817155838012695, 'eval_loss_3': -18.23041343688965, 'eval_loss_4': 0.5947703719139099, 'epoch': 24.88}
{'loss': 0.014, 'grad_norm': 4.504459381103516, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.002978866221383214, 'loss_2': 0.01097869873046875, 'loss_3': -16.687271118164062, 'loss_4': 0.7956205010414124, 'epoch': 24.89}
{'loss': 0.0217, 'grad_norm': 6.1004743576049805, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.011263640597462654, 'loss_2': 0.010467529296875, 'loss_3': -16.478370666503906, 'loss_4': 0.8188142776489258, 'epoch': 24.9}
{'loss': 0.0102, 'grad_norm': 5.600794315338135, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.006647723261266947, 'loss_2': 0.003551483154296875, 'loss_3': -16.525054931640625, 'loss_4': 0.5798496007919312, 'epoch': 24.9}
{'loss': 0.0093, 'grad_norm': 4.2999749183654785, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.0032575211953371763, 'loss_2': 0.006011962890625, 'loss_3': -16.562061309814453, 'loss_4': 0.5368952751159668, 'epoch': 24.91}
{'loss': 0.0036, 'grad_norm': 4.440201759338379, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.0023924096021801233, 'loss_2': 0.0011835098266601562, 'loss_3': -16.51951789855957, 'loss_4': 0.4235033690929413, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 17:03:13,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:13,356 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:51<15:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:20,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008721517398953438, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.594, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.006136256270110607, 'eval_loss_2': 0.0025852620601654053, 'eval_loss_3': -18.212017059326172, 'eval_loss_4': 0.5525578260421753, 'epoch': 24.91}
{'loss': 0.0059, 'grad_norm': 5.159092903137207, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.0036690488923341036, 'loss_2': 0.00218963623046875, 'loss_3': -16.522323608398438, 'loss_4': 0.2040124535560608, 'epoch': 24.92}
{'loss': 0.0067, 'grad_norm': 5.342269420623779, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.005045485682785511, 'loss_2': 0.001674652099609375, 'loss_3': -16.645435333251953, 'loss_4': 0.5701587796211243, 'epoch': 24.92}
{'loss': 0.0051, 'grad_norm': 4.500162601470947, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.0046570817939937115, 'loss_2': 0.0004291534423828125, 'loss_3': -16.682537078857422, 'loss_4': 0.3479771316051483, 'epoch': 24.93}
{'loss': 0.0069, 'grad_norm': 5.027616500854492, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.0029924132395535707, 'loss_2': 0.00389862060546875, 'loss_3': -16.802001953125, 'loss_4': 0.6346120834350586, 'epoch': 24.94}
{'loss': 0.0187, 'grad_norm': 7.599910259246826, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.01128541398793459, 'loss_2': 0.0074005126953125, 'loss_3': -16.492450714111328, 'loss_4': 0.23137104511260986, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 17:03:20,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:20,713 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:58<14:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:28,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009562116116285324, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.242, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.00685266125947237, 'eval_loss_2': 0.0027094557881355286, 'eval_loss_3': -18.212533950805664, 'eval_loss_4': 0.5255417227745056, 'epoch': 24.94}
{'loss': 0.0097, 'grad_norm': 4.028066158294678, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.004336085170507431, 'loss_2': 0.00537872314453125, 'loss_3': -16.57611656188965, 'loss_4': 0.7433662414550781, 'epoch': 24.95}
{'loss': 0.0139, 'grad_norm': 4.717348575592041, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.007374243810772896, 'loss_2': 0.00656890869140625, 'loss_3': -16.583236694335938, 'loss_4': 0.25543540716171265, 'epoch': 24.95}
{'loss': 0.009, 'grad_norm': 4.795741081237793, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.004527681041508913, 'loss_2': 0.00446319580078125, 'loss_3': -16.313539505004883, 'loss_4': 0.222895085811615, 'epoch': 24.96}
{'loss': 0.0143, 'grad_norm': 4.901535511016846, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.00535580376163125, 'loss_2': 0.0088958740234375, 'loss_3': -16.53354835510254, 'loss_4': 0.25292155146598816, 'epoch': 24.97}
{'loss': 0.0058, 'grad_norm': 5.132928848266602, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.004099484533071518, 'loss_2': 0.0017213821411132812, 'loss_3': -16.522598266601562, 'loss_4': 0.19018185138702393, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 17:03:28,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:28,068 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:46:05<13:23,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 17:03:35,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009644693695008755, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.006912137847393751, 'eval_loss_2': 0.002732556313276291, 'eval_loss_3': -18.206438064575195, 'eval_loss_4': 0.5062212347984314, 'epoch': 24.97}
{'loss': 0.0156, 'grad_norm': 9.782781600952148, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.014211378991603851, 'loss_2': 0.0014133453369140625, 'loss_3': -16.59990882873535, 'loss_4': 0.17390620708465576, 'epoch': 24.98}
{'loss': 0.0091, 'grad_norm': 4.905875205993652, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.003693066071718931, 'loss_2': 0.005401611328125, 'loss_3': -16.561687469482422, 'loss_4': 0.42644715309143066, 'epoch': 24.98}
{'loss': 0.0027, 'grad_norm': 4.547646999359131, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.002612923737615347, 'loss_2': 0.0001246929168701172, 'loss_3': -16.46761703491211, 'loss_4': 0.018576428294181824, 'epoch': 24.99}
{'loss': 0.0055, 'grad_norm': 4.757030487060547, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.003928357735276222, 'loss_2': 0.0016021728515625, 'loss_3': -16.66461181640625, 'loss_4': 0.08632215857505798, 'epoch': 24.99}
{'loss': 0.0079, 'grad_norm': 6.119699954986572, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0005685873329639435, 'loss_2': 0.0073699951171875, 'loss_3': -16.72369384765625, 'loss_4': 0.511179506778717, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 17:03:35,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:35,066 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:46:13<14:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:03:42,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01004364900290966, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.931, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007542429957538843, 'eval_loss_2': 0.0025012195110321045, 'eval_loss_3': -18.186979293823242, 'eval_loss_4': 0.46711090207099915, 'epoch': 25.0}
{'loss': 0.0325, 'grad_norm': 11.2593994140625, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.02379756234586239, 'loss_2': 0.00865936279296875, 'loss_3': -16.392959594726562, 'loss_4': 0.3552670180797577, 'epoch': 25.01}
{'loss': 0.0092, 'grad_norm': 4.907357692718506, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.00627180328592658, 'loss_2': 0.00296783447265625, 'loss_3': -16.45188331604004, 'loss_4': 0.5253077745437622, 'epoch': 25.01}
{'loss': 0.0054, 'grad_norm': 5.193665504455566, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.0036708610132336617, 'loss_2': 0.001773834228515625, 'loss_3': -16.65285873413086, 'loss_4': 0.5092949271202087, 'epoch': 25.02}
{'loss': 0.0056, 'grad_norm': 4.720798492431641, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.004744512494653463, 'loss_2': 0.0008063316345214844, 'loss_3': -16.480316162109375, 'loss_4': -0.08019661903381348, 'epoch': 25.02}
{'loss': 0.0722, 'grad_norm': 27.617176055908203, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.06654713302850723, 'loss_2': 0.0056610107421875, 'loss_3': -16.60388946533203, 'loss_4': 0.279587984085083, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 17:03:42,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:42,470 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:20<14:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:49,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010893341153860092, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00809168629348278, 'eval_loss_2': 0.002801656723022461, 'eval_loss_3': -18.191381454467773, 'eval_loss_4': 0.4647159278392792, 'epoch': 25.03}
{'loss': 0.0093, 'grad_norm': 4.986749649047852, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.006227628327906132, 'loss_2': 0.0030956268310546875, 'loss_3': -16.62220001220703, 'loss_4': 0.6241140365600586, 'epoch': 25.03}
{'loss': 0.0104, 'grad_norm': 4.922596454620361, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.008581305854022503, 'loss_2': 0.0018672943115234375, 'loss_3': -16.621946334838867, 'loss_4': 0.586484432220459, 'epoch': 25.04}
{'loss': 0.0072, 'grad_norm': 5.549348831176758, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.006684767547994852, 'loss_2': 0.0005006790161132812, 'loss_3': -16.522417068481445, 'loss_4': 0.4810102880001068, 'epoch': 25.05}
{'loss': 0.0123, 'grad_norm': 4.922073841094971, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.006302316673099995, 'loss_2': 0.00597381591796875, 'loss_3': -16.498390197753906, 'loss_4': 0.4081939458847046, 'epoch': 25.05}
{'loss': 0.0086, 'grad_norm': 4.692910671234131, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.003688066964969039, 'loss_2': 0.00489044189453125, 'loss_3': -16.472572326660156, 'loss_4': 0.09955938160419464, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 17:03:49,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:49,824 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:28<14:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:57,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01114276796579361, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.44, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008117981255054474, 'eval_loss_2': 0.0030247867107391357, 'eval_loss_3': -18.181758880615234, 'eval_loss_4': 0.39031898975372314, 'epoch': 25.06}
{'loss': 0.0097, 'grad_norm': 4.471911907196045, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.00361015391536057, 'loss_2': 0.006069183349609375, 'loss_3': -16.71756362915039, 'loss_4': 0.6074955463409424, 'epoch': 25.06}
{'loss': 0.0084, 'grad_norm': 4.73634672164917, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.003558394266292453, 'loss_2': 0.00479888916015625, 'loss_3': -16.598674774169922, 'loss_4': 0.5914982557296753, 'epoch': 25.07}
{'loss': 0.0093, 'grad_norm': 4.953444957733154, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.006421406753361225, 'loss_2': 0.002838134765625, 'loss_3': -16.527759552001953, 'loss_4': 0.06171208992600441, 'epoch': 25.08}
{'loss': 0.0027, 'grad_norm': 4.939758777618408, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.0013463860377669334, 'loss_2': 0.001373291015625, 'loss_3': -16.622190475463867, 'loss_4': -0.11693847179412842, 'epoch': 25.08}
{'loss': 0.0212, 'grad_norm': 9.77530288696289, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.016940627247095108, 'loss_2': 0.00423431396484375, 'loss_3': -16.627208709716797, 'loss_4': -0.06774759292602539, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 17:03:57,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:57,177 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:35<14:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:04,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010778642259538174, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007798587903380394, 'eval_loss_2': 0.002980053424835205, 'eval_loss_3': -18.179668426513672, 'eval_loss_4': 0.3577743172645569, 'epoch': 25.09}
{'loss': 0.0165, 'grad_norm': 9.010326385498047, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.013023678213357925, 'loss_2': 0.00344085693359375, 'loss_3': -16.66519546508789, 'loss_4': 0.16140234470367432, 'epoch': 25.09}
{'loss': 0.0104, 'grad_norm': 4.651437759399414, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.0029868227429687977, 'loss_2': 0.00745391845703125, 'loss_3': -16.59356689453125, 'loss_4': 0.23070958256721497, 'epoch': 25.1}
{'loss': 0.0051, 'grad_norm': 5.031490802764893, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.002612780313938856, 'loss_2': 0.00249481201171875, 'loss_3': -16.775047302246094, 'loss_4': 0.4783612787723541, 'epoch': 25.1}
{'loss': 0.0146, 'grad_norm': 11.16404914855957, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.012723964639008045, 'loss_2': 0.0018367767333984375, 'loss_3': -16.53075408935547, 'loss_4': 0.20189547538757324, 'epoch': 25.11}
{'loss': 0.0113, 'grad_norm': 5.546961784362793, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.006091713905334473, 'loss_2': 0.005218505859375, 'loss_3': -16.476394653320312, 'loss_4': 0.5801637172698975, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 17:04:04,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:04,530 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:42<14:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:11,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010004876181483269, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0074526648968458176, 'eval_loss_2': 0.002552211284637451, 'eval_loss_3': -18.188493728637695, 'eval_loss_4': 0.3695264458656311, 'epoch': 25.12}
{'loss': 0.0105, 'grad_norm': 4.756227493286133, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.0054121376015245914, 'loss_2': 0.00511932373046875, 'loss_3': -16.556381225585938, 'loss_4': 0.3601728677749634, 'epoch': 25.12}
{'loss': 0.0088, 'grad_norm': 4.680116653442383, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.004626808222383261, 'loss_2': 0.004138946533203125, 'loss_3': -16.46226692199707, 'loss_4': 0.33509501814842224, 'epoch': 25.13}
{'loss': 0.0076, 'grad_norm': 6.169629096984863, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.006123580038547516, 'loss_2': 0.001476287841796875, 'loss_3': -16.497234344482422, 'loss_4': 0.6119981408119202, 'epoch': 25.13}
{'loss': 0.0059, 'grad_norm': 5.008264541625977, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.004488839767873287, 'loss_2': 0.0014476776123046875, 'loss_3': -16.482776641845703, 'loss_4': 0.3342576026916504, 'epoch': 25.14}
{'loss': 0.0111, 'grad_norm': 5.249975681304932, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.0046632601879537106, 'loss_2': 0.006450653076171875, 'loss_3': -16.80050277709961, 'loss_4': 0.25663116574287415, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 17:04:11,893 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:11,893 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:50<14:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:19,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010672129690647125, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00780150992795825, 'eval_loss_2': 0.002870619297027588, 'eval_loss_3': -18.183120727539062, 'eval_loss_4': 0.40059664845466614, 'epoch': 25.15}
{'loss': 0.0027, 'grad_norm': 4.2822265625, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.0026289259549230337, 'loss_2': 2.574920654296875e-05, 'loss_3': -16.508983612060547, 'loss_4': 0.4427065849304199, 'epoch': 25.15}
{'loss': 0.0104, 'grad_norm': 5.049915313720703, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.005117238964885473, 'loss_2': 0.00525665283203125, 'loss_3': -16.45448875427246, 'loss_4': 0.3098675310611725, 'epoch': 25.16}
{'loss': 0.007, 'grad_norm': 4.203522682189941, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.005696112755686045, 'loss_2': 0.0012969970703125, 'loss_3': -16.483293533325195, 'loss_4': -0.09696459025144577, 'epoch': 25.16}
{'loss': 0.0055, 'grad_norm': 4.495612144470215, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.00392186688259244, 'loss_2': 0.0016269683837890625, 'loss_3': -16.56376075744629, 'loss_4': 0.2591581642627716, 'epoch': 25.17}
{'loss': 0.0106, 'grad_norm': 5.7246294021606445, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.008173028938472271, 'loss_2': 0.002475738525390625, 'loss_3': -16.42357635498047, 'loss_4': 0.06050337105989456, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 17:04:19,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:19,246 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:57<14:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:26,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01112013403326273, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00812035147100687, 'eval_loss_2': 0.0029997825622558594, 'eval_loss_3': -18.19906997680664, 'eval_loss_4': 0.43457579612731934, 'epoch': 25.17}
{'loss': 0.0112, 'grad_norm': 4.182957649230957, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.002516768639907241, 'loss_2': 0.008697509765625, 'loss_3': -16.56271743774414, 'loss_4': 0.5175062417984009, 'epoch': 25.18}
{'loss': 0.0093, 'grad_norm': 4.297683238983154, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.003044900018721819, 'loss_2': 0.00629425048828125, 'loss_3': -16.536148071289062, 'loss_4': 0.20081141591072083, 'epoch': 25.19}
{'loss': 0.0073, 'grad_norm': 4.479065418243408, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.004794715903699398, 'loss_2': 0.002471923828125, 'loss_3': -16.69876480102539, 'loss_4': 0.006376028060913086, 'epoch': 25.19}
{'loss': 0.0124, 'grad_norm': 5.952063083648682, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.009703765623271465, 'loss_2': 0.002727508544921875, 'loss_3': -16.51828384399414, 'loss_4': 0.5975397825241089, 'epoch': 25.2}
{'loss': 0.0184, 'grad_norm': 9.138551712036133, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.01475093886256218, 'loss_2': 0.00365447998046875, 'loss_3': -16.476428985595703, 'loss_4': -0.05611025542020798, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 17:04:26,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:26,595 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:47:04<14:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:33,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011351133696734905, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008392746560275555, 'eval_loss_2': 0.0029583871364593506, 'eval_loss_3': -18.195838928222656, 'eval_loss_4': 0.469913512468338, 'epoch': 25.2}
{'loss': 0.0133, 'grad_norm': 5.839751720428467, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.00677828025072813, 'loss_2': 0.0065155029296875, 'loss_3': -16.280200958251953, 'loss_4': -0.04624903202056885, 'epoch': 25.21}
{'loss': 0.0105, 'grad_norm': 4.517533302307129, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.003037253627553582, 'loss_2': 0.0074615478515625, 'loss_3': -16.594139099121094, 'loss_4': -0.0016409847885370255, 'epoch': 25.22}
{'loss': 0.0155, 'grad_norm': 9.096901893615723, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.014985405839979649, 'loss_2': 0.0004973411560058594, 'loss_3': -16.526718139648438, 'loss_4': 0.2389444261789322, 'epoch': 25.22}
{'loss': 0.0064, 'grad_norm': 4.437046051025391, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.004388257395476103, 'loss_2': 0.002010345458984375, 'loss_3': -16.414188385009766, 'loss_4': 0.39719757437705994, 'epoch': 25.23}
{'loss': 0.0133, 'grad_norm': 4.982888221740723, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.0068207052536308765, 'loss_2': 0.006439208984375, 'loss_3': -16.587594985961914, 'loss_4': 0.26605701446533203, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 17:04:33,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:33,945 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:47:12<14:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:41,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01179693266749382, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.892, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009043526835739613, 'eval_loss_2': 0.0027534067630767822, 'eval_loss_3': -18.190326690673828, 'eval_loss_4': 0.5113512277603149, 'epoch': 25.23}
{'loss': 0.0056, 'grad_norm': 4.400277137756348, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.00363748986274004, 'loss_2': 0.001949310302734375, 'loss_3': -16.528282165527344, 'loss_4': 0.3511468768119812, 'epoch': 25.24}
{'loss': 0.0063, 'grad_norm': 4.385495185852051, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.003514644457027316, 'loss_2': 0.002765655517578125, 'loss_3': -16.54464340209961, 'loss_4': 0.5287317037582397, 'epoch': 25.24}
{'loss': 0.0056, 'grad_norm': 5.77490758895874, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.004806658253073692, 'loss_2': 0.0007967948913574219, 'loss_3': -16.53526496887207, 'loss_4': 0.21360136568546295, 'epoch': 25.25}
{'loss': 0.0551, 'grad_norm': 9.792811393737793, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.05417767912149429, 'loss_2': 0.0009546279907226562, 'loss_3': -16.628841400146484, 'loss_4': 0.8095223903656006, 'epoch': 25.26}
{'loss': 0.0114, 'grad_norm': 4.641372203826904, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.00635746493935585, 'loss_2': 0.005023956298828125, 'loss_3': -16.550537109375, 'loss_4': 0.7345886826515198, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 17:04:41,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:41,302 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:19<14:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:48,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012498026713728905, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009093791246414185, 'eval_loss_2': 0.0034042373299598694, 'eval_loss_3': -18.194839477539062, 'eval_loss_4': 0.5748433470726013, 'epoch': 25.26}
{'loss': 0.016, 'grad_norm': 7.71323823928833, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.012885360978543758, 'loss_2': 0.00310516357421875, 'loss_3': -16.635482788085938, 'loss_4': 0.5742651224136353, 'epoch': 25.27}
{'loss': 0.0072, 'grad_norm': 5.692243576049805, 'learning_rate': 4.75e-06, 'loss_1': 0.006472292356193066, 'loss_2': 0.0007038116455078125, 'loss_3': -16.660165786743164, 'loss_4': 0.5971665978431702, 'epoch': 25.27}
{'loss': 0.01, 'grad_norm': 5.1714653968811035, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.00914069451391697, 'loss_2': 0.0008101463317871094, 'loss_3': -16.561904907226562, 'loss_4': 0.29586178064346313, 'epoch': 25.28}
{'loss': 0.0064, 'grad_norm': 4.6541900634765625, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.0027458854019641876, 'loss_2': 0.0036163330078125, 'loss_3': -16.323928833007812, 'loss_4': 0.34035202860832214, 'epoch': 25.28}
{'loss': 0.0713, 'grad_norm': 14.886808395385742, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.06801993399858475, 'loss_2': 0.0033111572265625, 'loss_3': -16.446815490722656, 'loss_4': 0.5993124842643738, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 17:04:48,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:48,660 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:26<13:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:56,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013109005056321621, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009068002924323082, 'eval_loss_2': 0.004041001200675964, 'eval_loss_3': -18.183019638061523, 'eval_loss_4': 0.5768071413040161, 'epoch': 25.29}
{'loss': 0.0067, 'grad_norm': 5.372118949890137, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.004358409903943539, 'loss_2': 0.0023040771484375, 'loss_3': -16.64664077758789, 'loss_4': 0.5165983438491821, 'epoch': 25.3}
{'loss': 0.0083, 'grad_norm': 4.521669387817383, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.0039895991794764996, 'loss_2': 0.00432586669921875, 'loss_3': -16.584423065185547, 'loss_4': 0.8665862083435059, 'epoch': 25.3}
{'loss': 0.0111, 'grad_norm': 4.694274425506592, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.0037260849494487047, 'loss_2': 0.00737762451171875, 'loss_3': -16.623558044433594, 'loss_4': 0.5025661587715149, 'epoch': 25.31}
{'loss': 0.0061, 'grad_norm': 4.911153793334961, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.00569568108767271, 'loss_2': 0.00044727325439453125, 'loss_3': -16.570295333862305, 'loss_4': 0.4312102794647217, 'epoch': 25.31}
{'loss': 0.0066, 'grad_norm': 5.294376850128174, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.006429783068597317, 'loss_2': 0.00016069412231445312, 'loss_3': -16.506101608276367, 'loss_4': 0.07483556866645813, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 17:04:56,016 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:56,016 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:34<13:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:03,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013361005112528801, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.643, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008919743821024895, 'eval_loss_2': 0.004441261291503906, 'eval_loss_3': -18.17353057861328, 'eval_loss_4': 0.5380315184593201, 'epoch': 25.32}
{'loss': 0.0122, 'grad_norm': 5.977837085723877, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.006106155924499035, 'loss_2': 0.006134033203125, 'loss_3': -16.367305755615234, 'loss_4': 0.6442222595214844, 'epoch': 25.33}
{'loss': 0.0099, 'grad_norm': 4.969768047332764, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.005841024685651064, 'loss_2': 0.00402069091796875, 'loss_3': -16.63888168334961, 'loss_4': 0.6287233233451843, 'epoch': 25.33}
{'loss': 0.0061, 'grad_norm': 5.062553882598877, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.004677826538681984, 'loss_2': 0.00145721435546875, 'loss_3': -16.697580337524414, 'loss_4': 0.4957176446914673, 'epoch': 25.34}
{'loss': 0.0078, 'grad_norm': 4.364501476287842, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.003495027543976903, 'loss_2': 0.00429534912109375, 'loss_3': -16.602527618408203, 'loss_4': 0.44174134731292725, 'epoch': 25.34}
{'loss': 0.0057, 'grad_norm': 5.036850929260254, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.004526232369244099, 'loss_2': 0.0011444091796875, 'loss_3': -16.607038497924805, 'loss_4': 0.4028463363647461, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 17:05:03,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:03,369 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:41<13:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:10,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013420110568404198, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009819054044783115, 'eval_loss_2': 0.003601059317588806, 'eval_loss_3': -18.155546188354492, 'eval_loss_4': 0.4843856692314148, 'epoch': 25.35}
{'loss': 0.0066, 'grad_norm': 4.670137405395508, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.003554853843525052, 'loss_2': 0.0030536651611328125, 'loss_3': -16.35831069946289, 'loss_4': 0.25503554940223694, 'epoch': 25.35}
{'loss': 0.0233, 'grad_norm': 9.530653953552246, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.022356390953063965, 'loss_2': 0.000949859619140625, 'loss_3': -16.60928726196289, 'loss_4': 0.5835248231887817, 'epoch': 25.36}
{'loss': 0.0128, 'grad_norm': 5.327234745025635, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.005524712149053812, 'loss_2': 0.00728607177734375, 'loss_3': -16.63650131225586, 'loss_4': 0.6365737915039062, 'epoch': 25.37}
{'loss': 0.0124, 'grad_norm': 7.760744571685791, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.01218404434621334, 'loss_2': 0.00020813941955566406, 'loss_3': -16.533702850341797, 'loss_4': 0.061692092567682266, 'epoch': 25.37}
{'loss': 0.0049, 'grad_norm': 5.390934467315674, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.004238530062139034, 'loss_2': 0.0006880760192871094, 'loss_3': -16.27562713623047, 'loss_4': 0.13200777769088745, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 17:05:10,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:10,715 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:48<13:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:18,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012856093235313892, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.431, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009831269271671772, 'eval_loss_2': 0.0030248239636421204, 'eval_loss_3': -18.14765739440918, 'eval_loss_4': 0.4741140604019165, 'epoch': 25.38}
{'loss': 0.0133, 'grad_norm': 6.755409240722656, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.011638371273875237, 'loss_2': 0.0016489028930664062, 'loss_3': -16.591041564941406, 'loss_4': 0.3947142958641052, 'epoch': 25.38}
{'loss': 0.005, 'grad_norm': 5.239079475402832, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.004483966156840324, 'loss_2': 0.0004665851593017578, 'loss_3': -16.635915756225586, 'loss_4': -0.17340050637722015, 'epoch': 25.39}
{'loss': 0.0038, 'grad_norm': 4.795464992523193, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.0031950189732015133, 'loss_2': 0.0005578994750976562, 'loss_3': -16.553707122802734, 'loss_4': 0.6444734334945679, 'epoch': 25.4}
{'loss': 0.0141, 'grad_norm': 8.315796852111816, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.008386170491576195, 'loss_2': 0.00571441650390625, 'loss_3': -16.72531509399414, 'loss_4': 0.2493518739938736, 'epoch': 25.4}
{'loss': 0.0074, 'grad_norm': 4.599322319030762, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.003443625755608082, 'loss_2': 0.004001617431640625, 'loss_3': -16.496295928955078, 'loss_4': 0.672903835773468, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 17:05:18,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:18,067 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:56<13:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:25,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012421911582350731, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.192, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0095371650531888, 'eval_loss_2': 0.0028847455978393555, 'eval_loss_3': -18.150711059570312, 'eval_loss_4': 0.5008543133735657, 'epoch': 25.41}
{'loss': 0.0079, 'grad_norm': 7.2034592628479, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.007474146317690611, 'loss_2': 0.0004642009735107422, 'loss_3': -16.426111221313477, 'loss_4': 0.6417382955551147, 'epoch': 25.41}
{'loss': 0.0042, 'grad_norm': 4.782048225402832, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.004053057171404362, 'loss_2': 0.00015151500701904297, 'loss_3': -16.42241668701172, 'loss_4': 0.26964807510375977, 'epoch': 25.42}
{'loss': 0.0059, 'grad_norm': 4.37465763092041, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.005152789410203695, 'loss_2': 0.0007467269897460938, 'loss_3': -16.46874237060547, 'loss_4': 0.40224575996398926, 'epoch': 25.42}
{'loss': 0.0238, 'grad_norm': 16.01671600341797, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.021426599472761154, 'loss_2': 0.002368927001953125, 'loss_3': -16.478897094726562, 'loss_4': 0.41660448908805847, 'epoch': 25.43}
{'loss': 0.01, 'grad_norm': 5.23831033706665, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.007104007992893457, 'loss_2': 0.0029449462890625, 'loss_3': -16.658733367919922, 'loss_4': 0.29660823941230774, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 17:05:25,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:25,430 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:48:03<13:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:32,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012265735305845737, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.398, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009535960853099823, 'eval_loss_2': 0.00272977352142334, 'eval_loss_3': -18.147762298583984, 'eval_loss_4': 0.5127202868461609, 'epoch': 25.44}
{'loss': 0.0061, 'grad_norm': 5.458945274353027, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.0046772765927016735, 'loss_2': 0.0014486312866210938, 'loss_3': -16.440841674804688, 'loss_4': 0.5041404962539673, 'epoch': 25.44}
{'loss': 0.0087, 'grad_norm': 5.216413974761963, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.00730350473895669, 'loss_2': 0.0014057159423828125, 'loss_3': -16.74873924255371, 'loss_4': 0.43411943316459656, 'epoch': 25.45}
{'loss': 0.0074, 'grad_norm': 5.877476692199707, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.005077519919723272, 'loss_2': 0.0023670196533203125, 'loss_3': -16.614337921142578, 'loss_4': 0.3408086895942688, 'epoch': 25.45}
{'loss': 0.0039, 'grad_norm': 5.024468898773193, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.0031733582727611065, 'loss_2': 0.0007729530334472656, 'loss_3': -16.455148696899414, 'loss_4': 0.1499015837907791, 'epoch': 25.46}
{'loss': 0.0033, 'grad_norm': 4.540156841278076, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.002897207858040929, 'loss_2': 0.0004448890686035156, 'loss_3': -16.310964584350586, 'loss_4': 0.30086585879325867, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 17:05:32,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:32,783 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:48:10<13:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:40,129 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013156021013855934, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.621, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010460126213729382, 'eval_loss_2': 0.002695895731449127, 'eval_loss_3': -18.13753890991211, 'eval_loss_4': 0.5300694704055786, 'epoch': 25.47}
{'loss': 0.0096, 'grad_norm': 4.846508979797363, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.005997719243168831, 'loss_2': 0.003650665283203125, 'loss_3': -16.576066970825195, 'loss_4': 0.6643768548965454, 'epoch': 25.47}
{'loss': 0.0061, 'grad_norm': 4.595639228820801, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.0027655521407723427, 'loss_2': 0.003284454345703125, 'loss_3': -16.50650405883789, 'loss_4': 0.4738065004348755, 'epoch': 25.48}
{'loss': 0.0143, 'grad_norm': 7.0203537940979, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.01008331123739481, 'loss_2': 0.00423431396484375, 'loss_3': -16.54387092590332, 'loss_4': 0.39895403385162354, 'epoch': 25.48}
{'loss': 0.0057, 'grad_norm': 5.488302707672119, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.002608709502965212, 'loss_2': 0.003055572509765625, 'loss_3': -16.62728500366211, 'loss_4': 0.5202497243881226, 'epoch': 25.49}
{'loss': 0.0072, 'grad_norm': 4.720094203948975, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.003157074796035886, 'loss_2': 0.0040740966796875, 'loss_3': -16.274612426757812, 'loss_4': 0.082903653383255, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 17:05:40,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:40,129 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:18<13:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:47,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013641780242323875, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.719, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011022531427443027, 'eval_loss_2': 0.0026192478835582733, 'eval_loss_3': -18.1379451751709, 'eval_loss_4': 0.5242813229560852, 'epoch': 25.49}
{'loss': 0.006, 'grad_norm': 4.750317573547363, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.0026839172933250666, 'loss_2': 0.0032901763916015625, 'loss_3': -16.594703674316406, 'loss_4': 0.23881104588508606, 'epoch': 25.5}
{'loss': 0.0085, 'grad_norm': 4.859735488891602, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.00446984963491559, 'loss_2': 0.0040435791015625, 'loss_3': -16.43771743774414, 'loss_4': 0.5290026068687439, 'epoch': 25.51}
{'loss': 0.0148, 'grad_norm': 7.545882225036621, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.010460768826305866, 'loss_2': 0.00435638427734375, 'loss_3': -16.456058502197266, 'loss_4': 0.36224856972694397, 'epoch': 25.51}
{'loss': 0.0084, 'grad_norm': 5.725162982940674, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.006044479552656412, 'loss_2': 0.0023956298828125, 'loss_3': -16.39716911315918, 'loss_4': 0.4709218740463257, 'epoch': 25.52}
{'loss': 0.0042, 'grad_norm': 4.243936538696289, 'learning_rate': 4.5e-06, 'loss_1': 0.0018619584152475, 'loss_2': 0.0023632049560546875, 'loss_3': -16.537330627441406, 'loss_4': 0.5445846319198608, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 17:05:47,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:47,479 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:25<13:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:54,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01417151652276516, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011181658133864403, 'eval_loss_2': 0.002989858388900757, 'eval_loss_3': -18.137693405151367, 'eval_loss_4': 0.49364495277404785, 'epoch': 25.52}
{'loss': 0.0194, 'grad_norm': 10.091145515441895, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.015067489817738533, 'loss_2': 0.00433349609375, 'loss_3': -16.581418991088867, 'loss_4': 0.13637742400169373, 'epoch': 25.53}
{'loss': 0.004, 'grad_norm': 4.583261966705322, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.003324721707031131, 'loss_2': 0.0007009506225585938, 'loss_3': -16.318317413330078, 'loss_4': 0.39887136220932007, 'epoch': 25.53}
{'loss': 0.0053, 'grad_norm': 4.439661502838135, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.0019408892840147018, 'loss_2': 0.003314971923828125, 'loss_3': -16.664276123046875, 'loss_4': 0.5873032212257385, 'epoch': 25.54}
{'loss': 0.0159, 'grad_norm': 9.034704208374023, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.01231065671890974, 'loss_2': 0.0035400390625, 'loss_3': -16.53064727783203, 'loss_4': 0.44544947147369385, 'epoch': 25.55}
{'loss': 0.0064, 'grad_norm': 5.596951007843018, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.005763339344412088, 'loss_2': 0.0006780624389648438, 'loss_3': -16.519620895385742, 'loss_4': 0.1715872883796692, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 17:05:54,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:54,834 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:33<13:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:02,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013961566612124443, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.551, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011617934331297874, 'eval_loss_2': 0.0023436322808265686, 'eval_loss_3': -18.12721824645996, 'eval_loss_4': 0.44511616230010986, 'epoch': 25.55}
{'loss': 0.0089, 'grad_norm': 4.766292095184326, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.0038355498109012842, 'loss_2': 0.00502777099609375, 'loss_3': -16.719816207885742, 'loss_4': 0.2778460383415222, 'epoch': 25.56}
{'loss': 0.0044, 'grad_norm': 4.625490665435791, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.003160448744893074, 'loss_2': 0.001270294189453125, 'loss_3': -16.39165496826172, 'loss_4': 0.32625943422317505, 'epoch': 25.56}
{'loss': 0.0115, 'grad_norm': 7.619792938232422, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.011126484721899033, 'loss_2': 0.0004076957702636719, 'loss_3': -16.643455505371094, 'loss_4': 0.127475768327713, 'epoch': 25.57}
{'loss': 0.0144, 'grad_norm': 9.585444450378418, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.009937668219208717, 'loss_2': 0.004505157470703125, 'loss_3': -16.46133804321289, 'loss_4': 0.5941097736358643, 'epoch': 25.58}
{'loss': 0.0035, 'grad_norm': 4.271927833557129, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.002541854977607727, 'loss_2': 0.0009260177612304688, 'loss_3': -16.532655715942383, 'loss_4': 0.15276947617530823, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 17:06:02,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:02,185 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:40<13:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:09,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013530229218304157, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.627, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011270065791904926, 'eval_loss_2': 0.002260163426399231, 'eval_loss_3': -18.130170822143555, 'eval_loss_4': 0.4080503582954407, 'epoch': 25.58}
{'loss': 0.0072, 'grad_norm': 4.567490100860596, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.0030681376811116934, 'loss_2': 0.00411224365234375, 'loss_3': -16.52150535583496, 'loss_4': 0.34321069717407227, 'epoch': 25.59}
{'loss': 0.0068, 'grad_norm': 4.97696590423584, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.004377863835543394, 'loss_2': 0.00246429443359375, 'loss_3': -16.589824676513672, 'loss_4': 0.11297864466905594, 'epoch': 25.59}
{'loss': 0.0083, 'grad_norm': 4.41178035736084, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.00449775904417038, 'loss_2': 0.00380706787109375, 'loss_3': -16.616374969482422, 'loss_4': 0.3335423767566681, 'epoch': 25.6}
{'loss': 0.0081, 'grad_norm': 5.709854602813721, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.007791049312800169, 'loss_2': 0.00028896331787109375, 'loss_3': -16.359607696533203, 'loss_4': 0.34025120735168457, 'epoch': 25.6}
{'loss': 0.008, 'grad_norm': 4.610891819000244, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.0038098650984466076, 'loss_2': 0.004184722900390625, 'loss_3': -16.420841217041016, 'loss_4': 0.2930797338485718, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 17:06:09,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:09,542 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:47<12:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:16,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012987226247787476, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.698, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010594763793051243, 'eval_loss_2': 0.0023924633860588074, 'eval_loss_3': -18.132976531982422, 'eval_loss_4': 0.3841273784637451, 'epoch': 25.61}
{'loss': 0.0109, 'grad_norm': 6.103919506072998, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.006784047465771437, 'loss_2': 0.0041656494140625, 'loss_3': -16.562747955322266, 'loss_4': 0.26949501037597656, 'epoch': 25.62}
{'loss': 0.0078, 'grad_norm': 4.699234962463379, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.0017272928962484002, 'loss_2': 0.006023406982421875, 'loss_3': -16.810768127441406, 'loss_4': 0.022080078721046448, 'epoch': 25.62}
{'loss': 0.0099, 'grad_norm': 4.368967533111572, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.0022399353329092264, 'loss_2': 0.007633209228515625, 'loss_3': -16.577499389648438, 'loss_4': 0.25112268328666687, 'epoch': 25.63}
{'loss': 0.0125, 'grad_norm': 4.626688480377197, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.0037183277308940887, 'loss_2': 0.008758544921875, 'loss_3': -16.387493133544922, 'loss_4': 0.2756589949131012, 'epoch': 25.63}
{'loss': 0.0061, 'grad_norm': 4.647364616394043, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.0050357794389128685, 'loss_2': 0.0010805130004882812, 'loss_3': -16.431026458740234, 'loss_4': 0.17488554120063782, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 17:06:16,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:16,894 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:55<12:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:24,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013589972630143166, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.728, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010989570058882236, 'eval_loss_2': 0.0026004016399383545, 'eval_loss_3': -18.136764526367188, 'eval_loss_4': 0.3115960955619812, 'epoch': 25.64}
{'loss': 0.005, 'grad_norm': 4.852059841156006, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.003894316963851452, 'loss_2': 0.0010671615600585938, 'loss_3': -16.50470542907715, 'loss_4': -0.020597875118255615, 'epoch': 25.65}
{'loss': 0.0076, 'grad_norm': 5.77407693862915, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.007046468090265989, 'loss_2': 0.0005249977111816406, 'loss_3': -16.564889907836914, 'loss_4': 0.10679402947425842, 'epoch': 25.65}
{'loss': 0.0256, 'grad_norm': 18.4395694732666, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.023185970261693, 'loss_2': 0.002437591552734375, 'loss_3': -16.654708862304688, 'loss_4': 0.375868022441864, 'epoch': 25.66}
{'loss': 0.0218, 'grad_norm': 16.543197631835938, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.017486030235886574, 'loss_2': 0.00433349609375, 'loss_3': -16.543880462646484, 'loss_4': 0.054986193776130676, 'epoch': 25.66}
{'loss': 0.0055, 'grad_norm': 5.198843955993652, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.005238524172455072, 'loss_2': 0.00022232532501220703, 'loss_3': -16.429845809936523, 'loss_4': 0.12614032626152039, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 17:06:24,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:24,244 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:49:02<12:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:31,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013726748526096344, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010764993727207184, 'eval_loss_2': 0.00296175479888916, 'eval_loss_3': -18.13384437561035, 'eval_loss_4': 0.23620936274528503, 'epoch': 25.67}
{'loss': 0.0033, 'grad_norm': 4.557166576385498, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.0027068224735558033, 'loss_2': 0.0006246566772460938, 'loss_3': -16.49686050415039, 'loss_4': 0.020604994148015976, 'epoch': 25.67}
{'loss': 0.0047, 'grad_norm': 4.671539306640625, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.002610965631902218, 'loss_2': 0.00211334228515625, 'loss_3': -16.460796356201172, 'loss_4': 0.43638747930526733, 'epoch': 25.68}
{'loss': 0.0095, 'grad_norm': 5.8716864585876465, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.007951611652970314, 'loss_2': 0.0015506744384765625, 'loss_3': -16.58405303955078, 'loss_4': 0.012756992131471634, 'epoch': 25.69}
{'loss': 0.0103, 'grad_norm': 8.251580238342285, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.00824305322021246, 'loss_2': 0.0020427703857421875, 'loss_3': -16.576772689819336, 'loss_4': -0.2214587926864624, 'epoch': 25.69}
{'loss': 0.0414, 'grad_norm': 17.16153335571289, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.03410503268241882, 'loss_2': 0.00726318359375, 'loss_3': -16.647369384765625, 'loss_4': -0.20176151394844055, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 17:06:31,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:31,589 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:49:09<12:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:38,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0140211908146739, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.674, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011415231972932816, 'eval_loss_2': 0.0026059597730636597, 'eval_loss_3': -18.130271911621094, 'eval_loss_4': 0.1825246512889862, 'epoch': 25.7}
{'loss': 0.008, 'grad_norm': 5.084072113037109, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.004779516253620386, 'loss_2': 0.0032501220703125, 'loss_3': -16.656494140625, 'loss_4': -0.3193613886833191, 'epoch': 25.7}
{'loss': 0.0109, 'grad_norm': 10.660231590270996, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.007007003296166658, 'loss_2': 0.0038928985595703125, 'loss_3': -16.59299087524414, 'loss_4': -0.0815158486366272, 'epoch': 25.71}
{'loss': 0.0031, 'grad_norm': 4.580733776092529, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.0018807601882144809, 'loss_2': 0.00119781494140625, 'loss_3': -16.54751205444336, 'loss_4': 0.09480243176221848, 'epoch': 25.72}
{'loss': 0.0089, 'grad_norm': 4.191609859466553, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.0022114564199000597, 'loss_2': 0.00665283203125, 'loss_3': -16.629732131958008, 'loss_4': 0.10622063279151917, 'epoch': 25.72}
{'loss': 0.0112, 'grad_norm': 6.114291191101074, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.007846720516681671, 'loss_2': 0.00334930419921875, 'loss_3': -16.432830810546875, 'loss_4': -0.14428597688674927, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 17:06:38,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:38,936 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:49:17<12:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:46,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01425289548933506, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.374, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011437558569014072, 'eval_loss_2': 0.002815335988998413, 'eval_loss_3': -18.133930206298828, 'eval_loss_4': 0.14542096853256226, 'epoch': 25.73}
{'loss': 0.0104, 'grad_norm': 5.52057409286499, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.006599693559110165, 'loss_2': 0.0037670135498046875, 'loss_3': -16.77235221862793, 'loss_4': -0.04980194941163063, 'epoch': 25.73}
{'loss': 0.0091, 'grad_norm': 5.567010879516602, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.006630043499171734, 'loss_2': 0.0025196075439453125, 'loss_3': -16.56414794921875, 'loss_4': 0.24776077270507812, 'epoch': 25.74}
{'loss': 0.0056, 'grad_norm': 4.182016372680664, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.0016123011009767652, 'loss_2': 0.0039520263671875, 'loss_3': -16.503223419189453, 'loss_4': 0.011619649827480316, 'epoch': 25.74}
{'loss': 0.0068, 'grad_norm': 4.730344772338867, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.0012447568587958813, 'loss_2': 0.005584716796875, 'loss_3': -16.615121841430664, 'loss_4': 0.32948994636535645, 'epoch': 25.75}
{'loss': 0.0074, 'grad_norm': 4.960502624511719, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.0030136907007545233, 'loss_2': 0.0043792724609375, 'loss_3': -16.557846069335938, 'loss_4': -0.1717861443758011, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 17:06:46,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:46,297 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:24<12:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:53,649 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013856587931513786, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010912297293543816, 'eval_loss_2': 0.0029442906379699707, 'eval_loss_3': -18.14289093017578, 'eval_loss_4': 0.12022582441568375, 'epoch': 25.76}
{'loss': 0.0052, 'grad_norm': 4.415802955627441, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.0029263680335134268, 'loss_2': 0.0023097991943359375, 'loss_3': -16.634632110595703, 'loss_4': -0.173861563205719, 'epoch': 25.76}
{'loss': 0.0114, 'grad_norm': 5.452086925506592, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.006377622485160828, 'loss_2': 0.0050506591796875, 'loss_3': -16.544538497924805, 'loss_4': 0.07315284758806229, 'epoch': 25.77}
{'loss': 0.0063, 'grad_norm': 5.3737053871154785, 'learning_rate': 4.25e-06, 'loss_1': 0.005817751865833998, 'loss_2': 0.0004851818084716797, 'loss_3': -16.399131774902344, 'loss_4': 0.15912455320358276, 'epoch': 25.77}
{'loss': 0.0183, 'grad_norm': 12.644675254821777, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.017120743170380592, 'loss_2': 0.001201629638671875, 'loss_3': -16.44357681274414, 'loss_4': 0.033979177474975586, 'epoch': 25.78}
{'loss': 0.0082, 'grad_norm': 4.639671802520752, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.00431071687489748, 'loss_2': 0.003871917724609375, 'loss_3': -16.61795997619629, 'loss_4': -0.015425246208906174, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 17:06:53,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:53,649 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:31<12:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:00,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013457224704325199, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.769, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010675303637981415, 'eval_loss_2': 0.0027819201350212097, 'eval_loss_3': -18.151844024658203, 'eval_loss_4': 0.12446464598178864, 'epoch': 25.78}
{'loss': 0.0101, 'grad_norm': 8.899700164794922, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.009206284768879414, 'loss_2': 0.00093841552734375, 'loss_3': -16.57714080810547, 'loss_4': -0.06802509725093842, 'epoch': 25.79}
{'loss': 0.0122, 'grad_norm': 7.386364459991455, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.009683220647275448, 'loss_2': 0.002529144287109375, 'loss_3': -16.485729217529297, 'loss_4': 0.03846598044037819, 'epoch': 25.8}
{'loss': 0.0133, 'grad_norm': 5.849003791809082, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.003547308035194874, 'loss_2': 0.00975799560546875, 'loss_3': -16.52202606201172, 'loss_4': 0.11386894434690475, 'epoch': 25.8}
{'loss': 0.007, 'grad_norm': 4.779109477996826, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.004785067867487669, 'loss_2': 0.002246856689453125, 'loss_3': -16.575042724609375, 'loss_4': -0.042787790298461914, 'epoch': 25.81}
{'loss': 0.0024, 'grad_norm': 4.271910190582275, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.002275875536724925, 'loss_2': 0.0001189112663269043, 'loss_3': -16.747528076171875, 'loss_4': 0.1814076006412506, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 17:07:00,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:00,994 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:39<12:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:08,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01351942215114832, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.78, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010691092349588871, 'eval_loss_2': 0.0028283298015594482, 'eval_loss_3': -18.159616470336914, 'eval_loss_4': 0.1294182986021042, 'epoch': 25.81}
{'loss': 0.008, 'grad_norm': 4.82135009765625, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.004100089892745018, 'loss_2': 0.003902435302734375, 'loss_3': -16.446792602539062, 'loss_4': 0.13991712033748627, 'epoch': 25.82}
{'loss': 0.0096, 'grad_norm': 4.647737503051758, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.004809417761862278, 'loss_2': 0.0047454833984375, 'loss_3': -16.538795471191406, 'loss_4': -0.1572207361459732, 'epoch': 25.83}
{'loss': 0.0246, 'grad_norm': 18.298954010009766, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.023177389055490494, 'loss_2': 0.0013980865478515625, 'loss_3': -16.72040367126465, 'loss_4': -0.17857441306114197, 'epoch': 25.83}
{'loss': 0.0067, 'grad_norm': 4.759931564331055, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.003616881091147661, 'loss_2': 0.003116607666015625, 'loss_3': -16.438390731811523, 'loss_4': -0.06976631283760071, 'epoch': 25.84}
{'loss': 0.0127, 'grad_norm': 13.097489356994629, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.010267461650073528, 'loss_2': 0.002475738525390625, 'loss_3': -16.35877227783203, 'loss_4': 0.1342364251613617, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 17:07:08,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:08,349 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:46<12:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:15,700 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013452931307256222, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.266, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010387889109551907, 'eval_loss_2': 0.003065042197704315, 'eval_loss_3': -18.153276443481445, 'eval_loss_4': 0.10419594496488571, 'epoch': 25.84}
{'loss': 0.0109, 'grad_norm': 4.339949607849121, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.003236031159758568, 'loss_2': 0.0076141357421875, 'loss_3': -16.429224014282227, 'loss_4': 0.14440704882144928, 'epoch': 25.85}
{'loss': 0.0133, 'grad_norm': 5.472736835479736, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.004809604957699776, 'loss_2': 0.0084991455078125, 'loss_3': -16.42732048034668, 'loss_4': -0.008695989847183228, 'epoch': 25.85}
{'loss': 0.0129, 'grad_norm': 5.901312351226807, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.005851305089890957, 'loss_2': 0.007038116455078125, 'loss_3': -16.611597061157227, 'loss_4': 0.10148332267999649, 'epoch': 25.86}
{'loss': 0.0101, 'grad_norm': 5.466438293457031, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.0045836749486625195, 'loss_2': 0.00555419921875, 'loss_3': -16.434295654296875, 'loss_4': -0.00845356285572052, 'epoch': 25.87}
{'loss': 0.0111, 'grad_norm': 33.15154266357422, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.006425104103982449, 'loss_2': 0.004703521728515625, 'loss_3': -16.63373565673828, 'loss_4': 0.2987242341041565, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 17:07:15,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:15,701 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:53<12:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:23,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013170437887310982, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010449320077896118, 'eval_loss_2': 0.0027211159467697144, 'eval_loss_3': -18.15399169921875, 'eval_loss_4': 0.089800626039505, 'epoch': 25.87}
{'loss': 0.0061, 'grad_norm': 4.692046165466309, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.004547251854091883, 'loss_2': 0.001537322998046875, 'loss_3': -16.584455490112305, 'loss_4': 0.5358015298843384, 'epoch': 25.88}
{'loss': 0.0085, 'grad_norm': 5.722373962402344, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.004228814505040646, 'loss_2': 0.004302978515625, 'loss_3': -16.566951751708984, 'loss_4': 0.0635203868150711, 'epoch': 25.88}
{'loss': 0.0166, 'grad_norm': 5.836245059967041, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.008266046643257141, 'loss_2': 0.0083160400390625, 'loss_3': -16.694997787475586, 'loss_4': 0.08540113270282745, 'epoch': 25.89}
{'loss': 0.016, 'grad_norm': 9.210716247558594, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.014217082411050797, 'loss_2': 0.0017824172973632812, 'loss_3': -16.691192626953125, 'loss_4': 0.1792972832918167, 'epoch': 25.9}
{'loss': 0.0034, 'grad_norm': 5.097702980041504, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.003054521745070815, 'loss_2': 0.0003337860107421875, 'loss_3': -16.505569458007812, 'loss_4': 0.05619892477989197, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 17:07:23,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:23,064 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:50:01<12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:30,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013529229909181595, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.436, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009919021278619766, 'eval_loss_2': 0.0036102086305618286, 'eval_loss_3': -18.167808532714844, 'eval_loss_4': 0.07062314450740814, 'epoch': 25.9}
{'loss': 0.0057, 'grad_norm': 5.21905517578125, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.004349307622760534, 'loss_2': 0.001392364501953125, 'loss_3': -16.6055908203125, 'loss_4': 0.033924996852874756, 'epoch': 25.91}
{'loss': 0.0132, 'grad_norm': 7.166631698608398, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.0113937146961689, 'loss_2': 0.001758575439453125, 'loss_3': -16.642562866210938, 'loss_4': -0.3762591481208801, 'epoch': 25.91}
{'loss': 0.0155, 'grad_norm': 5.164155960083008, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.005815514829009771, 'loss_2': 0.00972747802734375, 'loss_3': -16.52153778076172, 'loss_4': 0.2258278727531433, 'epoch': 25.92}
{'loss': 0.0124, 'grad_norm': 4.995862007141113, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.009846203029155731, 'loss_2': 0.00260162353515625, 'loss_3': -16.4549560546875, 'loss_4': -0.13236136734485626, 'epoch': 25.92}
{'loss': 0.0074, 'grad_norm': 4.479836940765381, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.004766277968883514, 'loss_2': 0.00266265869140625, 'loss_3': -16.572296142578125, 'loss_4': -0.5596930980682373, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 17:07:30,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:30,416 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:50:08<12:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:37,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01405770517885685, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.561, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009455988183617592, 'eval_loss_2': 0.004601716995239258, 'eval_loss_3': -18.174509048461914, 'eval_loss_4': 0.004899468272924423, 'epoch': 25.93}
{'loss': 0.0154, 'grad_norm': 5.43265438079834, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.01132114976644516, 'loss_2': 0.00408935546875, 'loss_3': -16.4832706451416, 'loss_4': -0.2806382477283478, 'epoch': 25.94}
{'loss': 0.004, 'grad_norm': 4.508874893188477, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.0026957306545227766, 'loss_2': 0.001323699951171875, 'loss_3': -16.53342628479004, 'loss_4': -0.02434014528989792, 'epoch': 25.94}
{'loss': 0.0103, 'grad_norm': 5.060205459594727, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.0039060155395418406, 'loss_2': 0.0063629150390625, 'loss_3': -16.51054573059082, 'loss_4': -0.42778435349464417, 'epoch': 25.95}
{'loss': 0.0092, 'grad_norm': 5.093652248382568, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.0043001724407076836, 'loss_2': 0.0048675537109375, 'loss_3': -16.662723541259766, 'loss_4': -0.12284081429243088, 'epoch': 25.95}
{'loss': 0.0106, 'grad_norm': 6.253245830535889, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.008678719401359558, 'loss_2': 0.00196075439453125, 'loss_3': -16.620656967163086, 'loss_4': 0.06686895340681076, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 17:07:37,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:37,756 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:50:15<11:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:45,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013073173351585865, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009013679809868336, 'eval_loss_2': 0.004059493541717529, 'eval_loss_3': -18.17701530456543, 'eval_loss_4': -0.01932595483958721, 'epoch': 25.96}
{'loss': 0.006, 'grad_norm': 4.680370807647705, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.003306080587208271, 'loss_2': 0.00270843505859375, 'loss_3': -16.478099822998047, 'loss_4': -0.22093209624290466, 'epoch': 25.97}
{'loss': 0.0131, 'grad_norm': 7.416350364685059, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.00818176381289959, 'loss_2': 0.004924774169921875, 'loss_3': -16.514135360717773, 'loss_4': -0.4721231162548065, 'epoch': 25.97}
{'loss': 0.0137, 'grad_norm': 4.874680042266846, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.0021278546191751957, 'loss_2': 0.01155853271484375, 'loss_3': -16.48943328857422, 'loss_4': -0.26220041513442993, 'epoch': 25.98}
{'loss': 0.0188, 'grad_norm': 8.44393539428711, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.016958871856331825, 'loss_2': 0.0018215179443359375, 'loss_3': -16.37859535217285, 'loss_4': 0.018269836902618408, 'epoch': 25.98}
{'loss': 0.007, 'grad_norm': 4.819375038146973, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.0035324322525411844, 'loss_2': 0.0034332275390625, 'loss_3': -16.663803100585938, 'loss_4': -0.19774079322814941, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 17:07:45,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:45,101 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:22<11:31,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 17:07:52,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011482162401080132, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.536, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00825689546763897, 'eval_loss_2': 0.003225266933441162, 'eval_loss_3': -18.16726303100586, 'eval_loss_4': -0.02003100886940956, 'epoch': 25.99}
{'loss': 0.0075, 'grad_norm': 5.459743022918701, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.004782389383763075, 'loss_2': 0.0027313232421875, 'loss_3': -16.42133140563965, 'loss_4': -0.31438151001930237, 'epoch': 25.99}
{'loss': 0.0041, 'grad_norm': 6.586166858673096, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.003923025913536549, 'loss_2': 0.00016808509826660156, 'loss_3': -16.303104400634766, 'loss_4': -0.011792491190135479, 'epoch': 26.0}
{'loss': 0.0043, 'grad_norm': 4.291579246520996, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.0036826098803430796, 'loss_2': 0.0005903244018554688, 'loss_3': -16.579700469970703, 'loss_4': 0.33498528599739075, 'epoch': 26.01}
{'loss': 0.0144, 'grad_norm': 6.548865795135498, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.009082374162971973, 'loss_2': 0.00536346435546875, 'loss_3': -16.572914123535156, 'loss_4': 0.03244929760694504, 'epoch': 26.01}
{'loss': 0.0769, 'grad_norm': 25.062095642089844, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.07411564141511917, 'loss_2': 0.002777099609375, 'loss_3': -16.53936767578125, 'loss_4': 0.10091400146484375, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 17:07:52,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:52,140 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:30<11:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:59,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011114202439785004, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.282, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008187903091311455, 'eval_loss_2': 0.0029262974858283997, 'eval_loss_3': -18.173141479492188, 'eval_loss_4': -0.0037834986578673124, 'epoch': 26.02}
{'loss': 0.0096, 'grad_norm': 4.988133907318115, 'learning_rate': 4e-06, 'loss_1': 0.005040569696575403, 'loss_2': 0.00452423095703125, 'loss_3': -16.562650680541992, 'loss_4': -0.6336424946784973, 'epoch': 26.02}
{'loss': 0.0124, 'grad_norm': 9.771223068237305, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.011613404378294945, 'loss_2': 0.0007762908935546875, 'loss_3': -16.593788146972656, 'loss_4': 0.12735970318317413, 'epoch': 26.03}
{'loss': 0.0082, 'grad_norm': 5.19473934173584, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.0018905879696831107, 'loss_2': 0.00634002685546875, 'loss_3': -16.565946578979492, 'loss_4': -0.21312671899795532, 'epoch': 26.03}
{'loss': 0.0051, 'grad_norm': 4.311171531677246, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.003169587580487132, 'loss_2': 0.00189971923828125, 'loss_3': -16.654518127441406, 'loss_4': 0.14849883317947388, 'epoch': 26.04}
{'loss': 0.0073, 'grad_norm': 4.586602210998535, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.003906643018126488, 'loss_2': 0.0034389495849609375, 'loss_3': -16.434066772460938, 'loss_4': -0.1313246339559555, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 17:07:59,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:59,500 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:37<11:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:06,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01125006377696991, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.752, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008365735411643982, 'eval_loss_2': 0.0028843283653259277, 'eval_loss_3': -18.182964324951172, 'eval_loss_4': 0.048323750495910645, 'epoch': 26.05}
{'loss': 0.0203, 'grad_norm': 9.932348251342773, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.012015270069241524, 'loss_2': 0.0082855224609375, 'loss_3': -16.579856872558594, 'loss_4': 0.12338913977146149, 'epoch': 26.05}
{'loss': 0.0619, 'grad_norm': 12.035565376281738, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.060587696731090546, 'loss_2': 0.0012722015380859375, 'loss_3': -16.435117721557617, 'loss_4': 0.49019142985343933, 'epoch': 26.06}
{'loss': 0.0086, 'grad_norm': 4.277068614959717, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.004323299508541822, 'loss_2': 0.00426483154296875, 'loss_3': -16.498779296875, 'loss_4': 0.15774574875831604, 'epoch': 26.06}
{'loss': 0.0109, 'grad_norm': 5.061694622039795, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.007287215907126665, 'loss_2': 0.00365447998046875, 'loss_3': -16.399234771728516, 'loss_4': -0.03312564641237259, 'epoch': 26.07}
{'loss': 0.0072, 'grad_norm': 4.672563552856445, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.0026373525615781546, 'loss_2': 0.00455474853515625, 'loss_3': -16.70818328857422, 'loss_4': -0.19962310791015625, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 17:08:06,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:06,857 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:45<11:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:14,208 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012008477002382278, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.517, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008476885966956615, 'eval_loss_2': 0.0035315901041030884, 'eval_loss_3': -18.188798904418945, 'eval_loss_4': 0.10222955793142319, 'epoch': 26.08}
{'loss': 0.0102, 'grad_norm': 4.7919487953186035, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.004625747911632061, 'loss_2': 0.005580902099609375, 'loss_3': -16.54800033569336, 'loss_4': -0.18642473220825195, 'epoch': 26.08}
{'loss': 0.0086, 'grad_norm': 4.208652019500732, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.00421883026137948, 'loss_2': 0.004367828369140625, 'loss_3': -16.50870132446289, 'loss_4': -0.35348430275917053, 'epoch': 26.09}
{'loss': 0.0122, 'grad_norm': 4.307844161987305, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.0024766474962234497, 'loss_2': 0.009674072265625, 'loss_3': -16.71181869506836, 'loss_4': -0.1647544503211975, 'epoch': 26.09}
{'loss': 0.0115, 'grad_norm': 5.473590850830078, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.004131167195737362, 'loss_2': 0.007381439208984375, 'loss_3': -16.54210662841797, 'loss_4': 0.23431065678596497, 'epoch': 26.1}
{'loss': 0.0104, 'grad_norm': 5.368912220001221, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.00460407929494977, 'loss_2': 0.0057525634765625, 'loss_3': -16.590089797973633, 'loss_4': 0.011722791939973831, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 17:08:14,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:14,209 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:52<11:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:21,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010905828326940536, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007795731537044048, 'eval_loss_2': 0.0031100958585739136, 'eval_loss_3': -18.193716049194336, 'eval_loss_4': 0.13670292496681213, 'epoch': 26.1}
{'loss': 0.0127, 'grad_norm': 4.487188339233398, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.003679637797176838, 'loss_2': 0.009002685546875, 'loss_3': -16.474353790283203, 'loss_4': -0.061262719333171844, 'epoch': 26.11}
{'loss': 0.0096, 'grad_norm': 4.768021583557129, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.004637197125703096, 'loss_2': 0.004985809326171875, 'loss_3': -16.461830139160156, 'loss_4': 0.27036410570144653, 'epoch': 26.12}
{'loss': 0.0077, 'grad_norm': 5.387673854827881, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.00617340998724103, 'loss_2': 0.0015287399291992188, 'loss_3': -16.586923599243164, 'loss_4': 0.35407182574272156, 'epoch': 26.12}
{'loss': 0.0131, 'grad_norm': 5.630647659301758, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.00868237018585205, 'loss_2': 0.00441741943359375, 'loss_3': -16.54109001159668, 'loss_4': -0.2113049179315567, 'epoch': 26.13}
{'loss': 0.0125, 'grad_norm': 4.798395156860352, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.0038333407137542963, 'loss_2': 0.008636474609375, 'loss_3': -16.581642150878906, 'loss_4': 0.3644922375679016, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 17:08:21,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:21,580 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:59<11:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:28,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010301945731043816, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.246, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007677553221583366, 'eval_loss_2': 0.0026243925094604492, 'eval_loss_3': -18.191207885742188, 'eval_loss_4': 0.11927400529384613, 'epoch': 26.13}
{'loss': 0.0047, 'grad_norm': 4.517256259918213, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.004677738528698683, 'loss_2': 6.794929504394531e-06, 'loss_3': -16.548391342163086, 'loss_4': -0.16709010303020477, 'epoch': 26.14}
{'loss': 0.0074, 'grad_norm': 5.6577067375183105, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.00599222956225276, 'loss_2': 0.00136566162109375, 'loss_3': -16.478008270263672, 'loss_4': 0.09330444782972336, 'epoch': 26.15}
{'loss': 0.011, 'grad_norm': 6.311673641204834, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.006049229763448238, 'loss_2': 0.004985809326171875, 'loss_3': -16.445419311523438, 'loss_4': -0.015839703381061554, 'epoch': 26.15}
{'loss': 0.0061, 'grad_norm': 4.2701215744018555, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.0030811468604952097, 'loss_2': 0.00299835205078125, 'loss_3': -16.730342864990234, 'loss_4': -0.012041106820106506, 'epoch': 26.16}
{'loss': 0.0043, 'grad_norm': 4.536108493804932, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.0014566534664481878, 'loss_2': 0.0028400421142578125, 'loss_3': -16.636489868164062, 'loss_4': -0.2537911534309387, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 17:08:28,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:28,940 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:51:07<11:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:36,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01057327352464199, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00820152647793293, 'eval_loss_2': 0.0023717470467090607, 'eval_loss_3': -18.193302154541016, 'eval_loss_4': 0.11471495032310486, 'epoch': 26.16}
{'loss': 0.0114, 'grad_norm': 6.255203723907471, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.007928209379315376, 'loss_2': 0.0034637451171875, 'loss_3': -16.61227798461914, 'loss_4': 0.2522768974304199, 'epoch': 26.17}
{'loss': 0.0079, 'grad_norm': 5.026513576507568, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.007115765940397978, 'loss_2': 0.0007619857788085938, 'loss_3': -16.416332244873047, 'loss_4': -0.020421594381332397, 'epoch': 26.17}
{'loss': 0.01, 'grad_norm': 8.89381217956543, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.008627768605947495, 'loss_2': 0.0013713836669921875, 'loss_3': -16.511629104614258, 'loss_4': 0.02908894419670105, 'epoch': 26.18}
{'loss': 0.0063, 'grad_norm': 4.882513046264648, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.003751740325242281, 'loss_2': 0.00251007080078125, 'loss_3': -16.63150405883789, 'loss_4': 0.21191947162151337, 'epoch': 26.19}
{'loss': 0.0079, 'grad_norm': 4.840632438659668, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.0028222089167684317, 'loss_2': 0.005107879638671875, 'loss_3': -16.51688575744629, 'loss_4': -0.05729787051677704, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 17:08:36,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:36,302 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:51:14<11:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:43,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01051128190010786, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.767, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008293765597045422, 'eval_loss_2': 0.002217516303062439, 'eval_loss_3': -18.18768882751465, 'eval_loss_4': 0.13131292164325714, 'epoch': 26.19}
{'loss': 0.0086, 'grad_norm': 4.679359436035156, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.005794876255095005, 'loss_2': 0.0028018951416015625, 'loss_3': -16.42995262145996, 'loss_4': -0.29616567492485046, 'epoch': 26.2}
{'loss': 0.0052, 'grad_norm': 4.615443706512451, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.003162039676681161, 'loss_2': 0.002002716064453125, 'loss_3': -16.666393280029297, 'loss_4': -0.0882183387875557, 'epoch': 26.2}
{'loss': 0.0101, 'grad_norm': 4.97012996673584, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.0024371943436563015, 'loss_2': 0.0076141357421875, 'loss_3': -16.55987548828125, 'loss_4': 0.33212190866470337, 'epoch': 26.21}
{'loss': 0.0046, 'grad_norm': 5.793620586395264, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.00443592993542552, 'loss_2': 0.00011581182479858398, 'loss_3': -16.555004119873047, 'loss_4': -0.06110570579767227, 'epoch': 26.22}
{'loss': 0.007, 'grad_norm': 7.027121067047119, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.006612480152398348, 'loss_2': 0.0003504753112792969, 'loss_3': -16.328868865966797, 'loss_4': -0.10566973686218262, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 17:08:43,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:43,667 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:21<11:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:51,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01019333302974701, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.003, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007973493076860905, 'eval_loss_2': 0.002219840884208679, 'eval_loss_3': -18.19256019592285, 'eval_loss_4': 0.14619126915931702, 'epoch': 26.22}
{'loss': 0.0098, 'grad_norm': 4.948318958282471, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.005003978498280048, 'loss_2': 0.0048370361328125, 'loss_3': -16.44214630126953, 'loss_4': 0.28846079111099243, 'epoch': 26.23}
{'loss': 0.0081, 'grad_norm': 7.001649379730225, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.0054617072455585, 'loss_2': 0.002620697021484375, 'loss_3': -16.47037696838379, 'loss_4': -0.067239910364151, 'epoch': 26.23}
{'loss': 0.0103, 'grad_norm': 5.803611755371094, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.006683072075247765, 'loss_2': 0.00363922119140625, 'loss_3': -16.49158477783203, 'loss_4': -0.06374133378267288, 'epoch': 26.24}
{'loss': 0.0043, 'grad_norm': 4.800121307373047, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.0032544820569455624, 'loss_2': 0.0010042190551757812, 'loss_3': -16.531471252441406, 'loss_4': 0.23334729671478271, 'epoch': 26.24}
{'loss': 0.0038, 'grad_norm': 5.052035808563232, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.0029042481910437346, 'loss_2': 0.00086212158203125, 'loss_3': -16.459970474243164, 'loss_4': -0.03558117896318436, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 17:08:51,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:51,027 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:29<11:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:58,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00931042991578579, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.44, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006976610980927944, 'eval_loss_2': 0.00233381986618042, 'eval_loss_3': -18.18378448486328, 'eval_loss_4': 0.17537084221839905, 'epoch': 26.25}
{'loss': 0.009, 'grad_norm': 4.933627605438232, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.007229153998196125, 'loss_2': 0.001773834228515625, 'loss_3': -16.275558471679688, 'loss_4': -0.10438306629657745, 'epoch': 26.26}
{'loss': 0.0099, 'grad_norm': 5.524296283721924, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.009931913577020168, 'loss_2': 1.52587890625e-05, 'loss_3': -16.378841400146484, 'loss_4': 0.31595975160598755, 'epoch': 26.26}
{'loss': 0.0112, 'grad_norm': 5.097087383270264, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.006090926937758923, 'loss_2': 0.005062103271484375, 'loss_3': -16.538352966308594, 'loss_4': -0.07653097063302994, 'epoch': 26.27}
{'loss': 0.0077, 'grad_norm': 4.753662586212158, 'learning_rate': 3.75e-06, 'loss_1': 0.0027079975698143244, 'loss_2': 0.00501251220703125, 'loss_3': -16.63416862487793, 'loss_4': -0.1631404161453247, 'epoch': 26.27}
{'loss': 0.0063, 'grad_norm': 4.668558120727539, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.003512985771521926, 'loss_2': 0.002742767333984375, 'loss_3': -16.486083984375, 'loss_4': 0.16355068981647491, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 17:08:58,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:58,378 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:36<10:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:05,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009546964429318905, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007039569318294525, 'eval_loss_2': 0.0025073960423469543, 'eval_loss_3': -18.17725944519043, 'eval_loss_4': 0.21264687180519104, 'epoch': 26.28}
{'loss': 0.0148, 'grad_norm': 5.357210159301758, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.014315610751509666, 'loss_2': 0.0004649162292480469, 'loss_3': -16.68306541442871, 'loss_4': -0.0543656125664711, 'epoch': 26.28}
{'loss': 0.0048, 'grad_norm': 5.066991806030273, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.0037348943296819925, 'loss_2': 0.001049041748046875, 'loss_3': -16.534664154052734, 'loss_4': 0.10255768895149231, 'epoch': 26.29}
{'loss': 0.0823, 'grad_norm': 14.126452445983887, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.0756351500749588, 'loss_2': 0.00662994384765625, 'loss_3': -16.38064956665039, 'loss_4': -0.1392519772052765, 'epoch': 26.3}
{'loss': 0.0073, 'grad_norm': 4.745062351226807, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.004375182557851076, 'loss_2': 0.002880096435546875, 'loss_3': -16.474910736083984, 'loss_4': 0.0924871638417244, 'epoch': 26.3}
{'loss': 0.0075, 'grad_norm': 5.300880432128906, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.005049606319516897, 'loss_2': 0.0024051666259765625, 'loss_3': -16.271156311035156, 'loss_4': 0.46437686681747437, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 17:09:05,731 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:05,731 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:43<10:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:13,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010223796591162682, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.323, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007733633276075125, 'eval_loss_2': 0.0024901628494262695, 'eval_loss_3': -18.164886474609375, 'eval_loss_4': 0.21586070954799652, 'epoch': 26.31}
{'loss': 0.0042, 'grad_norm': 4.472115993499756, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.0028198673389852047, 'loss_2': 0.0013933181762695312, 'loss_3': -16.573333740234375, 'loss_4': 0.40626540780067444, 'epoch': 26.31}
{'loss': 0.0165, 'grad_norm': 5.417289733886719, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.007640363182872534, 'loss_2': 0.00881195068359375, 'loss_3': -16.54254913330078, 'loss_4': 0.03676272928714752, 'epoch': 26.32}
{'loss': 0.0053, 'grad_norm': 4.532737731933594, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.0034907974768429995, 'loss_2': 0.0017871856689453125, 'loss_3': -16.744571685791016, 'loss_4': 0.061220020055770874, 'epoch': 26.33}
{'loss': 0.0157, 'grad_norm': 6.453364849090576, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.009166071191430092, 'loss_2': 0.0065155029296875, 'loss_3': -16.34233283996582, 'loss_4': 0.26280760765075684, 'epoch': 26.33}
{'loss': 0.0182, 'grad_norm': 5.779550552368164, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.005974750965833664, 'loss_2': 0.01221466064453125, 'loss_3': -16.61260986328125, 'loss_4': 0.2510724663734436, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 17:09:13,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:13,095 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:51<10:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:20,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011153122410178185, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.85, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0086061405017972, 'eval_loss_2': 0.0025469809770584106, 'eval_loss_3': -18.165184020996094, 'eval_loss_4': 0.1894475668668747, 'epoch': 26.34}
{'loss': 0.0021, 'grad_norm': 4.212062835693359, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.0018285991391167045, 'loss_2': 0.00022530555725097656, 'loss_3': -16.66583251953125, 'loss_4': 0.15746676921844482, 'epoch': 26.34}
{'loss': 0.0037, 'grad_norm': 4.8311591148376465, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.0026774201542139053, 'loss_2': 0.0010585784912109375, 'loss_3': -16.56743812561035, 'loss_4': 0.3278902471065521, 'epoch': 26.35}
{'loss': 0.0122, 'grad_norm': 5.098817348480225, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.007855232805013657, 'loss_2': 0.00434112548828125, 'loss_3': -16.643922805786133, 'loss_4': 0.23161903023719788, 'epoch': 26.35}
{'loss': 0.0036, 'grad_norm': 4.95650577545166, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.0027618566527962685, 'loss_2': 0.0007982254028320312, 'loss_3': -16.605457305908203, 'loss_4': -0.03146372735500336, 'epoch': 26.36}
{'loss': 0.0038, 'grad_norm': 4.857396602630615, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.003177992533892393, 'loss_2': 0.0006127357482910156, 'loss_3': -16.399085998535156, 'loss_4': 0.24630466103553772, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 17:09:20,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:20,462 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:58<10:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:27,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012545611709356308, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.755, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009470652788877487, 'eval_loss_2': 0.003074958920478821, 'eval_loss_3': -18.15836524963379, 'eval_loss_4': 0.20060913264751434, 'epoch': 26.37}
{'loss': 0.0079, 'grad_norm': 5.779470920562744, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.006961200386285782, 'loss_2': 0.0009870529174804688, 'loss_3': -16.51949119567871, 'loss_4': 0.18322435021400452, 'epoch': 26.37}
{'loss': 0.0067, 'grad_norm': 4.947480201721191, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.005331689491868019, 'loss_2': 0.0013942718505859375, 'loss_3': -16.463817596435547, 'loss_4': 0.08031770586967468, 'epoch': 26.38}
{'loss': 0.019, 'grad_norm': 12.139368057250977, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.016492251306772232, 'loss_2': 0.0025463104248046875, 'loss_3': -16.39633560180664, 'loss_4': 0.03585842251777649, 'epoch': 26.38}
{'loss': 0.0077, 'grad_norm': 6.705414295196533, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.006407795939594507, 'loss_2': 0.0012912750244140625, 'loss_3': -16.536338806152344, 'loss_4': 0.0883110910654068, 'epoch': 26.39}
{'loss': 0.0075, 'grad_norm': 4.498077392578125, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.005929542705416679, 'loss_2': 0.001529693603515625, 'loss_3': -16.40460205078125, 'loss_4': 0.16516374051570892, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 17:09:27,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:27,828 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:52:06<10:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:35,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012318966910243034, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009529231116175652, 'eval_loss_2': 0.002789735794067383, 'eval_loss_3': -18.1626033782959, 'eval_loss_4': 0.22358769178390503, 'epoch': 26.4}
{'loss': 0.0054, 'grad_norm': 6.0433669090271, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.004096414893865585, 'loss_2': 0.001338958740234375, 'loss_3': -16.441246032714844, 'loss_4': 0.07045711576938629, 'epoch': 26.4}
{'loss': 0.0105, 'grad_norm': 4.727319240570068, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.0016018323367461562, 'loss_2': 0.0089263916015625, 'loss_3': -16.55323600769043, 'loss_4': 0.19513370096683502, 'epoch': 26.41}
{'loss': 0.0177, 'grad_norm': 14.260055541992188, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.01609058491885662, 'loss_2': 0.001567840576171875, 'loss_3': -16.528823852539062, 'loss_4': 0.37590688467025757, 'epoch': 26.41}
{'loss': 0.0138, 'grad_norm': 7.314602851867676, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.0093669593334198, 'loss_2': 0.00441741943359375, 'loss_3': -16.508638381958008, 'loss_4': 0.522702693939209, 'epoch': 26.42}
{'loss': 0.0096, 'grad_norm': 4.610018253326416, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.0018486101180315018, 'loss_2': 0.00778961181640625, 'loss_3': -16.639362335205078, 'loss_4': 0.3218814432621002, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 17:09:35,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:35,198 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:52:13<10:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:42,554 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012823900207877159, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010393297299742699, 'eval_loss_2': 0.0024306029081344604, 'eval_loss_3': -18.15366554260254, 'eval_loss_4': 0.25082626938819885, 'epoch': 26.42}
{'loss': 0.0094, 'grad_norm': 6.518532752990723, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.007113576401025057, 'loss_2': 0.0023097991943359375, 'loss_3': -16.433719635009766, 'loss_4': 0.040075454860925674, 'epoch': 26.43}
{'loss': 0.0028, 'grad_norm': 4.627455234527588, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.0020090912003070116, 'loss_2': 0.0007519721984863281, 'loss_3': -16.485698699951172, 'loss_4': 0.07728978991508484, 'epoch': 26.44}
{'loss': 0.0086, 'grad_norm': 5.69976806640625, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.006559119559824467, 'loss_2': 0.0020046234130859375, 'loss_3': -16.643945693969727, 'loss_4': 0.6506292223930359, 'epoch': 26.44}
{'loss': 0.0107, 'grad_norm': 5.606031894683838, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.005896280519664288, 'loss_2': 0.00479888916015625, 'loss_3': -16.6299991607666, 'loss_4': 0.1981964260339737, 'epoch': 26.45}
{'loss': 0.0028, 'grad_norm': 4.913976669311523, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.001912827487103641, 'loss_2': 0.0009293556213378906, 'loss_3': -16.412261962890625, 'loss_4': 0.25307631492614746, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 17:09:42,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:42,555 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:20<10:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:49,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013313019648194313, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.324, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010979901999235153, 'eval_loss_2': 0.002333119511604309, 'eval_loss_3': -18.14704704284668, 'eval_loss_4': 0.2866029143333435, 'epoch': 26.45}
{'loss': 0.0121, 'grad_norm': 4.563451766967773, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.0017037102952599525, 'loss_2': 0.0103607177734375, 'loss_3': -16.379240036010742, 'loss_4': 0.3948799967765808, 'epoch': 26.46}
{'loss': 0.0049, 'grad_norm': 5.12141227722168, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0031117363832890987, 'loss_2': 0.0018129348754882812, 'loss_3': -16.506267547607422, 'loss_4': 0.007821664214134216, 'epoch': 26.47}
{'loss': 0.0107, 'grad_norm': 4.973909378051758, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.003963277209550142, 'loss_2': 0.006687164306640625, 'loss_3': -16.508544921875, 'loss_4': 0.10677678883075714, 'epoch': 26.47}
{'loss': 0.0123, 'grad_norm': 6.742440223693848, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.005858703050762415, 'loss_2': 0.0064697265625, 'loss_3': -16.49686050415039, 'loss_4': 0.15950530767440796, 'epoch': 26.48}
{'loss': 0.0051, 'grad_norm': 4.64337158203125, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.005013872403651476, 'loss_2': 5.3882598876953125e-05, 'loss_3': -16.512969970703125, 'loss_4': 0.03039442002773285, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 17:09:49,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:49,916 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:28<10:31,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:09:57,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013824893161654472, 'eval_runtime': 4.0, 'eval_samples_per_second': 256.002, 'eval_steps_per_second': 4.0, 'eval_loss_1': 0.011254530400037766, 'eval_loss_2': 0.0025703608989715576, 'eval_loss_3': -18.142498016357422, 'eval_loss_4': 0.29389727115631104, 'epoch': 26.48}
{'loss': 0.0161, 'grad_norm': 12.312898635864258, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.016039054840803146, 'loss_2': 8.32676887512207e-05, 'loss_3': -16.665040969848633, 'loss_4': 0.05362026393413544, 'epoch': 26.49}
{'loss': 0.018, 'grad_norm': 6.0447258949279785, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.00972909014672041, 'loss_2': 0.00823974609375, 'loss_3': -16.525232315063477, 'loss_4': 0.35385626554489136, 'epoch': 26.49}
{'loss': 0.0041, 'grad_norm': 4.9836201667785645, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.003254186362028122, 'loss_2': 0.0008807182312011719, 'loss_3': -16.54653549194336, 'loss_4': 0.1269080936908722, 'epoch': 26.5}
{'loss': 0.0065, 'grad_norm': 4.833131313323975, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.005517586600035429, 'loss_2': 0.0010194778442382812, 'loss_3': -16.421581268310547, 'loss_4': 0.30884313583374023, 'epoch': 26.51}
{'loss': 0.0054, 'grad_norm': 4.6557297706604, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.0041726576164364815, 'loss_2': 0.0011959075927734375, 'loss_3': -16.403182983398438, 'loss_4': 0.255785197019577, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 17:09:57,463 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:57,463 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:35<10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:04,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013408854603767395, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.481, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01129066850990057, 'eval_loss_2': 0.0021181851625442505, 'eval_loss_3': -18.14667510986328, 'eval_loss_4': 0.2652249038219452, 'epoch': 26.51}
{'loss': 0.0122, 'grad_norm': 5.27678108215332, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.005073505453765392, 'loss_2': 0.007091522216796875, 'loss_3': -16.458642959594727, 'loss_4': 0.25628188252449036, 'epoch': 26.52}
{'loss': 0.0159, 'grad_norm': 12.28095531463623, 'learning_rate': 3.5e-06, 'loss_1': 0.015120495110750198, 'loss_2': 0.0007925033569335938, 'loss_3': -16.380220413208008, 'loss_4': 0.05923193693161011, 'epoch': 26.52}
{'loss': 0.0136, 'grad_norm': 6.621129989624023, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.005735582672059536, 'loss_2': 0.007843017578125, 'loss_3': -16.421470642089844, 'loss_4': 0.22141551971435547, 'epoch': 26.53}
{'loss': 0.0034, 'grad_norm': 4.965498924255371, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.0031668737065047026, 'loss_2': 0.00025200843811035156, 'loss_3': -16.540681838989258, 'loss_4': 0.323556125164032, 'epoch': 26.53}
{'loss': 0.0056, 'grad_norm': 5.5765180587768555, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.004793661646544933, 'loss_2': 0.0007810592651367188, 'loss_3': -16.46807098388672, 'loss_4': 0.09967860579490662, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 17:10:04,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:04,837 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:43<10:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:12,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013186480849981308, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.211, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010620493441820145, 'eval_loss_2': 0.0025659874081611633, 'eval_loss_3': -18.150789260864258, 'eval_loss_4': 0.2520557940006256, 'epoch': 26.54}
{'loss': 0.004, 'grad_norm': 4.666558742523193, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.0018451292999088764, 'loss_2': 0.0022029876708984375, 'loss_3': -16.387645721435547, 'loss_4': -0.018539782613515854, 'epoch': 26.55}
{'loss': 0.01, 'grad_norm': 6.300917625427246, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.008670253679156303, 'loss_2': 0.001285552978515625, 'loss_3': -16.482120513916016, 'loss_4': 0.278347909450531, 'epoch': 26.55}
{'loss': 0.007, 'grad_norm': 4.912950038909912, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.0054928576573729515, 'loss_2': 0.0014696121215820312, 'loss_3': -16.482187271118164, 'loss_4': 0.04822060465812683, 'epoch': 26.56}
{'loss': 0.0051, 'grad_norm': 4.57414436340332, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.002138565294444561, 'loss_2': 0.0029773712158203125, 'loss_3': -16.46590805053711, 'loss_4': 0.19668909907341003, 'epoch': 26.56}
{'loss': 0.0058, 'grad_norm': 4.734166145324707, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.0037093376740813255, 'loss_2': 0.00208282470703125, 'loss_3': -16.514373779296875, 'loss_4': 0.27697762846946716, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 17:10:12,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:12,199 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:50<10:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:19,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01324394065886736, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.875, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010319236665964127, 'eval_loss_2': 0.002924703061580658, 'eval_loss_3': -18.149606704711914, 'eval_loss_4': 0.26069319248199463, 'epoch': 26.57}
{'loss': 0.013, 'grad_norm': 5.72950553894043, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.007394424639642239, 'loss_2': 0.00557708740234375, 'loss_3': -16.62982177734375, 'loss_4': -0.0020026862621307373, 'epoch': 26.58}
{'loss': 0.0374, 'grad_norm': 20.723785400390625, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.031965527683496475, 'loss_2': 0.0054473876953125, 'loss_3': -16.668487548828125, 'loss_4': 0.07277160882949829, 'epoch': 26.58}
{'loss': 0.0055, 'grad_norm': 5.2856764793396, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.004596910905092955, 'loss_2': 0.0009169578552246094, 'loss_3': -16.337207794189453, 'loss_4': 0.6113916635513306, 'epoch': 26.59}
{'loss': 0.0269, 'grad_norm': 14.700295448303223, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.02172623574733734, 'loss_2': 0.0051727294921875, 'loss_3': -16.46161651611328, 'loss_4': -0.07473147660493851, 'epoch': 26.59}
{'loss': 0.0075, 'grad_norm': 5.327068328857422, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.004174939822405577, 'loss_2': 0.00330352783203125, 'loss_3': -16.388118743896484, 'loss_4': -0.0048848651349544525, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 17:10:19,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:19,560 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:57<10:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:26,915 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012995450757443905, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.295, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010078579187393188, 'eval_loss_2': 0.002916872501373291, 'eval_loss_3': -18.153030395507812, 'eval_loss_4': 0.2700207531452179, 'epoch': 26.6}
{'loss': 0.0062, 'grad_norm': 5.308643817901611, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.004879659041762352, 'loss_2': 0.001323699951171875, 'loss_3': -16.400461196899414, 'loss_4': 0.14918354153633118, 'epoch': 26.6}
{'loss': 0.0065, 'grad_norm': 4.677901744842529, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.002060333965346217, 'loss_2': 0.0044708251953125, 'loss_3': -16.34204864501953, 'loss_4': 0.23742139339447021, 'epoch': 26.61}
{'loss': 0.0116, 'grad_norm': 5.014472961425781, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.005959103349596262, 'loss_2': 0.005615234375, 'loss_3': -16.399747848510742, 'loss_4': 0.31838321685791016, 'epoch': 26.62}
{'loss': 0.0058, 'grad_norm': 5.31785249710083, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.0036390030290931463, 'loss_2': 0.0021514892578125, 'loss_3': -16.523143768310547, 'loss_4': 0.6989440321922302, 'epoch': 26.62}
{'loss': 0.0069, 'grad_norm': 4.841854572296143, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.006564356852322817, 'loss_2': 0.0002865791320800781, 'loss_3': -16.471721649169922, 'loss_4': 0.05983272194862366, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 17:10:26,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:26,916 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:53:05<09:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:34,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01268867775797844, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009887817315757275, 'eval_loss_2': 0.00280085951089859, 'eval_loss_3': -18.15412139892578, 'eval_loss_4': 0.25557950139045715, 'epoch': 26.63}
{'loss': 0.0192, 'grad_norm': 9.841158866882324, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.011068690568208694, 'loss_2': 0.00809478759765625, 'loss_3': -16.736303329467773, 'loss_4': 0.3667474091053009, 'epoch': 26.63}
{'loss': 0.0044, 'grad_norm': 4.383457183837891, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.00223565474152565, 'loss_2': 0.00218963623046875, 'loss_3': -16.604110717773438, 'loss_4': 0.6202563643455505, 'epoch': 26.64}
{'loss': 0.0082, 'grad_norm': 4.578811168670654, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.005609853193163872, 'loss_2': 0.00254058837890625, 'loss_3': -16.5689697265625, 'loss_4': 0.19885143637657166, 'epoch': 26.65}
{'loss': 0.0076, 'grad_norm': 4.4330267906188965, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.0031851078383624554, 'loss_2': 0.00444793701171875, 'loss_3': -16.509958267211914, 'loss_4': 0.22430723905563354, 'epoch': 26.65}
{'loss': 0.0252, 'grad_norm': 12.58792781829834, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.019055582582950592, 'loss_2': 0.006145477294921875, 'loss_3': -16.55570411682129, 'loss_4': 0.027977406978607178, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 17:10:34,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:34,277 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:53:12<09:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:41,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012260211631655693, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.051, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009844322688877583, 'eval_loss_2': 0.002415888011455536, 'eval_loss_3': -18.148685455322266, 'eval_loss_4': 0.22694797813892365, 'epoch': 26.66}
{'loss': 0.0127, 'grad_norm': 5.165016174316406, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.0038491024170070887, 'loss_2': 0.00884246826171875, 'loss_3': -16.835712432861328, 'loss_4': 0.4849628210067749, 'epoch': 26.66}
{'loss': 0.0097, 'grad_norm': 5.440380573272705, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.005182084161788225, 'loss_2': 0.00453948974609375, 'loss_3': -16.517139434814453, 'loss_4': 0.35589683055877686, 'epoch': 26.67}
{'loss': 0.011, 'grad_norm': 4.736301898956299, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.004513241350650787, 'loss_2': 0.00647735595703125, 'loss_3': -16.361820220947266, 'loss_4': 0.2389478236436844, 'epoch': 26.67}
{'loss': 0.0025, 'grad_norm': 4.4569411277771, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.0016094394959509373, 'loss_2': 0.0009217262268066406, 'loss_3': -16.650230407714844, 'loss_4': 0.3354249596595764, 'epoch': 26.68}
{'loss': 0.0036, 'grad_norm': 4.533094882965088, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.0018026523757725954, 'loss_2': 0.0018415451049804688, 'loss_3': -16.3624210357666, 'loss_4': 0.12222600728273392, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 17:10:41,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:41,645 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:19<09:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:49,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012296798638999462, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.051, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010055476799607277, 'eval_loss_2': 0.0022413209080696106, 'eval_loss_3': -18.149150848388672, 'eval_loss_4': 0.1832171529531479, 'epoch': 26.69}
{'loss': 0.0047, 'grad_norm': 5.201338768005371, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.00464007630944252, 'loss_2': 4.3332576751708984e-05, 'loss_3': -16.723392486572266, 'loss_4': 0.10374520719051361, 'epoch': 26.69}
{'loss': 0.0105, 'grad_norm': 5.1496968269348145, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.0038373691495507956, 'loss_2': 0.0066375732421875, 'loss_3': -16.477312088012695, 'loss_4': -0.08130796253681183, 'epoch': 26.7}
{'loss': 0.0082, 'grad_norm': 4.714092254638672, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.005930849816650152, 'loss_2': 0.00229644775390625, 'loss_3': -16.554351806640625, 'loss_4': 0.6094897389411926, 'epoch': 26.7}
{'loss': 0.0238, 'grad_norm': 9.484560012817383, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.021130703389644623, 'loss_2': 0.002716064453125, 'loss_3': -16.6804141998291, 'loss_4': -0.37017622590065, 'epoch': 26.71}
{'loss': 0.0062, 'grad_norm': 5.009533882141113, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.004570533987134695, 'loss_2': 0.0016613006591796875, 'loss_3': -16.304088592529297, 'loss_4': 0.12157028168439865, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 17:10:49,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:49,012 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:27<09:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:56,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013157157227396965, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010827271267771721, 'eval_loss_2': 0.002329885959625244, 'eval_loss_3': -18.151226043701172, 'eval_loss_4': 0.16991421580314636, 'epoch': 26.72}
{'loss': 0.0053, 'grad_norm': 4.845474720001221, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.002245564479380846, 'loss_2': 0.003055572509765625, 'loss_3': -16.564659118652344, 'loss_4': -0.09056708216667175, 'epoch': 26.72}
{'loss': 0.0078, 'grad_norm': 4.912642478942871, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.005757477600127459, 'loss_2': 0.0020599365234375, 'loss_3': -16.467050552368164, 'loss_4': 0.16166922450065613, 'epoch': 26.73}
{'loss': 0.0146, 'grad_norm': 12.084966659545898, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.013704853132367134, 'loss_2': 0.0009374618530273438, 'loss_3': -16.680908203125, 'loss_4': 0.036448586732149124, 'epoch': 26.73}
{'loss': 0.0086, 'grad_norm': 5.006206035614014, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.005135626532137394, 'loss_2': 0.00347900390625, 'loss_3': -16.65420150756836, 'loss_4': 0.42146599292755127, 'epoch': 26.74}
{'loss': 0.0092, 'grad_norm': 6.01538610458374, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.008500735275447369, 'loss_2': 0.0007410049438476562, 'loss_3': -16.396324157714844, 'loss_4': 0.33586934208869934, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 17:10:56,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:56,374 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:34<09:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:03,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013626478612422943, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.313, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011413895525038242, 'eval_loss_2': 0.0022125840187072754, 'eval_loss_3': -18.134082794189453, 'eval_loss_4': 0.13157358765602112, 'epoch': 26.74}
{'loss': 0.0065, 'grad_norm': 6.635519981384277, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.004458669573068619, 'loss_2': 0.001995086669921875, 'loss_3': -16.62891387939453, 'loss_4': 0.3336969017982483, 'epoch': 26.75}
{'loss': 0.0025, 'grad_norm': 4.689811706542969, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.0017076876247301698, 'loss_2': 0.000782012939453125, 'loss_3': -16.573898315429688, 'loss_4': 0.025910094380378723, 'epoch': 26.76}
{'loss': 0.0044, 'grad_norm': 4.717039108276367, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.002434312365949154, 'loss_2': 0.0019235610961914062, 'loss_3': -16.427349090576172, 'loss_4': 0.16776366531848907, 'epoch': 26.76}
{'loss': 0.0046, 'grad_norm': 4.633488178253174, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.003759673098102212, 'loss_2': 0.000843048095703125, 'loss_3': -16.538921356201172, 'loss_4': -0.1273617148399353, 'epoch': 26.77}
{'loss': 0.0109, 'grad_norm': 6.133519172668457, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.005519527941942215, 'loss_2': 0.00534820556640625, 'loss_3': -16.631776809692383, 'loss_4': 0.2127789705991745, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 17:11:03,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:03,727 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:41<09:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:11,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013871029019355774, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.572, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011628655716776848, 'eval_loss_2': 0.002242371439933777, 'eval_loss_3': -18.131855010986328, 'eval_loss_4': 0.08694837242364883, 'epoch': 26.77}
{'loss': 0.0065, 'grad_norm': 5.153324604034424, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.004918238613754511, 'loss_2': 0.0015716552734375, 'loss_3': -16.500022888183594, 'loss_4': 0.11984880268573761, 'epoch': 26.78}
{'loss': 0.0045, 'grad_norm': 4.751934051513672, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.003019255818799138, 'loss_2': 0.0014734268188476562, 'loss_3': -16.397497177124023, 'loss_4': -0.03617938607931137, 'epoch': 26.78}
{'loss': 0.0048, 'grad_norm': 4.927593231201172, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.003279526252299547, 'loss_2': 0.001522064208984375, 'loss_3': -16.54326629638672, 'loss_4': 0.19312557578086853, 'epoch': 26.79}
{'loss': 0.0124, 'grad_norm': 4.917290210723877, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.0023392264265567064, 'loss_2': 0.01006317138671875, 'loss_3': -16.640501022338867, 'loss_4': 0.2620121240615845, 'epoch': 26.8}
{'loss': 0.0048, 'grad_norm': 4.716139316558838, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.0037024668417871, 'loss_2': 0.0011444091796875, 'loss_3': -16.365318298339844, 'loss_4': -0.3966274559497833, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 17:11:11,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:11,083 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:49<09:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:18,438 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014093847945332527, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.494, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011511250399053097, 'eval_loss_2': 0.002582598477602005, 'eval_loss_3': -18.125513076782227, 'eval_loss_4': 0.05221838131546974, 'epoch': 26.8}
{'loss': 0.0145, 'grad_norm': 14.817411422729492, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.01318584755063057, 'loss_2': 0.0012874603271484375, 'loss_3': -16.397167205810547, 'loss_4': -0.17038235068321228, 'epoch': 26.81}
{'loss': 0.0101, 'grad_norm': 5.535221576690674, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.006901812274008989, 'loss_2': 0.0031681060791015625, 'loss_3': -16.40009307861328, 'loss_4': 0.06264755129814148, 'epoch': 26.81}
{'loss': 0.0061, 'grad_norm': 4.7851409912109375, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.0025358626153320074, 'loss_2': 0.0035266876220703125, 'loss_3': -16.430591583251953, 'loss_4': 0.06905718892812729, 'epoch': 26.82}
{'loss': 0.011, 'grad_norm': 5.986760139465332, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.00803200900554657, 'loss_2': 0.003017425537109375, 'loss_3': -16.50259780883789, 'loss_4': -0.19672954082489014, 'epoch': 26.83}
{'loss': 0.0046, 'grad_norm': 4.860414028167725, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.002923769410699606, 'loss_2': 0.0017261505126953125, 'loss_3': -16.503740310668945, 'loss_4': -0.2663199305534363, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 17:11:18,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:18,439 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:56<09:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:25,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014993482269346714, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.078, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011741691268980503, 'eval_loss_2': 0.003251791000366211, 'eval_loss_3': -18.12094497680664, 'eval_loss_4': 0.04091363400220871, 'epoch': 26.83}
{'loss': 0.005, 'grad_norm': 4.5363264083862305, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.0041258973069489, 'loss_2': 0.0008754730224609375, 'loss_3': -16.493356704711914, 'loss_4': 0.5497512817382812, 'epoch': 26.84}
{'loss': 0.0098, 'grad_norm': 4.936650276184082, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.006249135360121727, 'loss_2': 0.0035400390625, 'loss_3': -16.44926643371582, 'loss_4': 0.20036767423152924, 'epoch': 26.84}
{'loss': 0.0106, 'grad_norm': 5.867712020874023, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.0060233729891479015, 'loss_2': 0.00457763671875, 'loss_3': -16.286067962646484, 'loss_4': -0.19138966500759125, 'epoch': 26.85}
{'loss': 0.0026, 'grad_norm': 4.611918926239014, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.0013990587322041392, 'loss_2': 0.0012302398681640625, 'loss_3': -16.661640167236328, 'loss_4': -0.002538144588470459, 'epoch': 26.85}
{'loss': 0.0162, 'grad_norm': 7.711700439453125, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.014092210680246353, 'loss_2': 0.002147674560546875, 'loss_3': -16.37926483154297, 'loss_4': 0.0702039822936058, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 17:11:25,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:25,797 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:54:03<09:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:33,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014691767282783985, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.39, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011560749262571335, 'eval_loss_2': 0.0031310170888900757, 'eval_loss_3': -18.125173568725586, 'eval_loss_4': 0.00453934445977211, 'epoch': 26.86}
{'loss': 0.0063, 'grad_norm': 4.858456611633301, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.005248939618468285, 'loss_2': 0.0010271072387695312, 'loss_3': -16.481258392333984, 'loss_4': 0.17261633276939392, 'epoch': 26.87}
{'loss': 0.0102, 'grad_norm': 6.0955634117126465, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.009278140030801296, 'loss_2': 0.0009584426879882812, 'loss_3': -16.603879928588867, 'loss_4': 0.05110470950603485, 'epoch': 26.87}
{'loss': 0.0118, 'grad_norm': 4.410742282867432, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.004459303803741932, 'loss_2': 0.00732421875, 'loss_3': -16.279197692871094, 'loss_4': -0.1830616295337677, 'epoch': 26.88}
{'loss': 0.0056, 'grad_norm': 4.675807476043701, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.0030476818792521954, 'loss_2': 0.002582550048828125, 'loss_3': -16.62482452392578, 'loss_4': -0.2560603618621826, 'epoch': 26.88}
{'loss': 0.0232, 'grad_norm': 11.906996726989746, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.021071432158350945, 'loss_2': 0.002140045166015625, 'loss_3': -16.50624656677246, 'loss_4': -0.05003826320171356, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 17:11:33,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:33,157 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:54:11<09:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:40,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01517269667237997, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011743060313165188, 'eval_loss_2': 0.0034296363592147827, 'eval_loss_3': -18.12626075744629, 'eval_loss_4': -0.02525196596980095, 'epoch': 26.89}
{'loss': 0.0054, 'grad_norm': 5.1544084548950195, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.004190604202449322, 'loss_2': 0.0012111663818359375, 'loss_3': -16.584882736206055, 'loss_4': 0.42643773555755615, 'epoch': 26.9}
{'loss': 0.0102, 'grad_norm': 6.324423789978027, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.0071471454575657845, 'loss_2': 0.00301361083984375, 'loss_3': -16.43365478515625, 'loss_4': 0.16373825073242188, 'epoch': 26.9}
{'loss': 0.0077, 'grad_norm': 5.826684951782227, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.00488848052918911, 'loss_2': 0.00279998779296875, 'loss_3': -16.2537841796875, 'loss_4': 0.10181805491447449, 'epoch': 26.91}
{'loss': 0.0148, 'grad_norm': 6.857201099395752, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.012591328471899033, 'loss_2': 0.0022449493408203125, 'loss_3': -16.52022933959961, 'loss_4': -0.027560606598854065, 'epoch': 26.91}
{'loss': 0.0115, 'grad_norm': 7.683627605438232, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.009023335762321949, 'loss_2': 0.0024509429931640625, 'loss_3': -16.656204223632812, 'loss_4': -0.265973299741745, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 17:11:40,504 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:40,504 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:54:18<09:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:47,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015362292528152466, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.633, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011853883974254131, 'eval_loss_2': 0.00350840762257576, 'eval_loss_3': -18.130393981933594, 'eval_loss_4': -0.0349116325378418, 'epoch': 26.92}
{'loss': 0.0048, 'grad_norm': 4.817852020263672, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.0015048586064949632, 'loss_2': 0.00328826904296875, 'loss_3': -16.568256378173828, 'loss_4': 0.009587693959474564, 'epoch': 26.92}
{'loss': 0.0117, 'grad_norm': 4.637474536895752, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.00397166283801198, 'loss_2': 0.007678985595703125, 'loss_3': -16.468944549560547, 'loss_4': -0.05082389712333679, 'epoch': 26.93}
{'loss': 0.0063, 'grad_norm': 6.271531105041504, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.004086183849722147, 'loss_2': 0.00218963623046875, 'loss_3': -16.353599548339844, 'loss_4': 0.07419739663600922, 'epoch': 26.94}
{'loss': 0.0123, 'grad_norm': 4.176196098327637, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.004475862253457308, 'loss_2': 0.00787353515625, 'loss_3': -16.385799407958984, 'loss_4': -0.3691199719905853, 'epoch': 26.94}
{'loss': 0.0195, 'grad_norm': 9.029409408569336, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.014293202199041843, 'loss_2': 0.00519561767578125, 'loss_3': -16.489665985107422, 'loss_4': -0.10776190459728241, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 17:11:47,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:47,856 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:26<09:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:55,208 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015541281551122665, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012222841382026672, 'eval_loss_2': 0.003318440169095993, 'eval_loss_3': -18.122716903686523, 'eval_loss_4': -0.04493020474910736, 'epoch': 26.95}
{'loss': 0.0089, 'grad_norm': 5.281312942504883, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.006529542151838541, 'loss_2': 0.0023212432861328125, 'loss_3': -16.6450252532959, 'loss_4': -0.31716394424438477, 'epoch': 26.95}
{'loss': 0.0024, 'grad_norm': 4.227128505706787, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.002146586310118437, 'loss_2': 0.0002257823944091797, 'loss_3': -16.47412872314453, 'loss_4': 0.22448864579200745, 'epoch': 26.96}
{'loss': 0.0069, 'grad_norm': 4.625668048858643, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.002786804921925068, 'loss_2': 0.004161834716796875, 'loss_3': -16.574338912963867, 'loss_4': -0.6252574920654297, 'epoch': 26.97}
{'loss': 0.0112, 'grad_norm': 4.935268878936768, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.004292700905352831, 'loss_2': 0.006870269775390625, 'loss_3': -16.547405242919922, 'loss_4': 0.28325068950653076, 'epoch': 26.97}
{'loss': 0.0074, 'grad_norm': 7.942192554473877, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.007313834968954325, 'loss_2': 9.149312973022461e-05, 'loss_3': -16.42864990234375, 'loss_4': -0.05089830979704857, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 17:11:55,208 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:55,208 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:33<08:24,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 17:12:02,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015422388911247253, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.169, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01215904951095581, 'eval_loss_2': 0.003263339400291443, 'eval_loss_3': -18.121234893798828, 'eval_loss_4': -0.05655283108353615, 'epoch': 26.98}
{'loss': 0.0051, 'grad_norm': 5.307810306549072, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.003059063572436571, 'loss_2': 0.0020427703857421875, 'loss_3': -16.554771423339844, 'loss_4': 0.14917214214801788, 'epoch': 26.98}
{'loss': 0.0052, 'grad_norm': 4.422740936279297, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0028456738218665123, 'loss_2': 0.00232696533203125, 'loss_3': -16.57152557373047, 'loss_4': -0.07803010940551758, 'epoch': 26.99}
{'loss': 0.0044, 'grad_norm': 4.675342559814453, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.0030848898459225893, 'loss_2': 0.0013599395751953125, 'loss_3': -16.63058090209961, 'loss_4': 0.08277317881584167, 'epoch': 26.99}
{'loss': 0.0148, 'grad_norm': 8.362890243530273, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.008819391019642353, 'loss_2': 0.0059814453125, 'loss_3': -16.674177169799805, 'loss_4': -0.3446660339832306, 'epoch': 27.0}
{'loss': 0.0046, 'grad_norm': 5.200972080230713, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.004127291031181812, 'loss_2': 0.00048041343688964844, 'loss_3': -16.36632537841797, 'loss_4': 0.4006918668746948, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 17:12:02,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:02,256 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:40<08:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:12:09,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01584632694721222, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.418, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012153556570410728, 'eval_loss_2': 0.00369277223944664, 'eval_loss_3': -18.122394561767578, 'eval_loss_4': -0.07042868435382843, 'epoch': 27.01}
{'loss': 0.0076, 'grad_norm': 4.959118843078613, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.00658941688016057, 'loss_2': 0.0010499954223632812, 'loss_3': -16.39215660095215, 'loss_4': 0.4806946814060211, 'epoch': 27.01}
{'loss': 0.0114, 'grad_norm': 4.710325241088867, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.003305091056972742, 'loss_2': 0.0081329345703125, 'loss_3': -16.622451782226562, 'loss_4': -0.23808512091636658, 'epoch': 27.02}
{'loss': 0.0065, 'grad_norm': 5.409483432769775, 'learning_rate': 3e-06, 'loss_1': 0.004002726636826992, 'loss_2': 0.00254058837890625, 'loss_3': -16.52092742919922, 'loss_4': -0.06849256157875061, 'epoch': 27.02}
{'loss': 0.013, 'grad_norm': 6.625213146209717, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.010806702077388763, 'loss_2': 0.0022430419921875, 'loss_3': -16.600379943847656, 'loss_4': -0.3907398581504822, 'epoch': 27.03}
{'loss': 0.0124, 'grad_norm': 6.47326135635376, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.008898451924324036, 'loss_2': 0.00347900390625, 'loss_3': -16.59322166442871, 'loss_4': -0.012031633406877518, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 17:12:09,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:09,610 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:47<08:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:16,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016347650438547134, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.508, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012828665785491467, 'eval_loss_2': 0.0035189837217330933, 'eval_loss_3': -18.127052307128906, 'eval_loss_4': -0.09863926470279694, 'epoch': 27.03}
{'loss': 0.0058, 'grad_norm': 5.518439769744873, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.005752192344516516, 'loss_2': 8.344650268554688e-06, 'loss_3': -16.44024085998535, 'loss_4': -0.16697552800178528, 'epoch': 27.04}
{'loss': 0.0055, 'grad_norm': 4.678589344024658, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.0017813976155593991, 'loss_2': 0.003688812255859375, 'loss_3': -16.63033676147461, 'loss_4': -0.016363617032766342, 'epoch': 27.05}
{'loss': 0.0105, 'grad_norm': 7.275078773498535, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.008149969391524792, 'loss_2': 0.0023021697998046875, 'loss_3': -16.732421875, 'loss_4': 0.3754381239414215, 'epoch': 27.05}
{'loss': 0.0104, 'grad_norm': 7.408452987670898, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.006478538736701012, 'loss_2': 0.003879547119140625, 'loss_3': -16.461017608642578, 'loss_4': -0.43225452303886414, 'epoch': 27.06}
{'loss': 0.011, 'grad_norm': 7.181275367736816, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.010544092394411564, 'loss_2': 0.00041985511779785156, 'loss_3': -16.625812530517578, 'loss_4': -0.05208764970302582, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 17:12:16,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:16,965 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:55<08:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:24,313 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015396321192383766, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.696, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012376392260193825, 'eval_loss_2': 0.0030199289321899414, 'eval_loss_3': -18.12908935546875, 'eval_loss_4': -0.13400058448314667, 'epoch': 27.06}
{'loss': 0.0164, 'grad_norm': 7.24977970123291, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.012678556144237518, 'loss_2': 0.003704071044921875, 'loss_3': -16.540918350219727, 'loss_4': 0.11011559516191483, 'epoch': 27.07}
{'loss': 0.0058, 'grad_norm': 4.618587493896484, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.0028104449156671762, 'loss_2': 0.00299835205078125, 'loss_3': -16.388893127441406, 'loss_4': 0.0018033534288406372, 'epoch': 27.08}
{'loss': 0.005, 'grad_norm': 4.8352227210998535, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.0032020036596804857, 'loss_2': 0.00177764892578125, 'loss_3': -16.581192016601562, 'loss_4': 0.05858933925628662, 'epoch': 27.08}
{'loss': 0.0028, 'grad_norm': 4.400073528289795, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.002449379302561283, 'loss_2': 0.00036907196044921875, 'loss_3': -16.56041717529297, 'loss_4': -0.42109209299087524, 'epoch': 27.09}
{'loss': 0.0072, 'grad_norm': 5.079306125640869, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.004791907034814358, 'loss_2': 0.002376556396484375, 'loss_3': -16.453901290893555, 'loss_4': -0.2881799340248108, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 17:12:24,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:24,313 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:55:02<08:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:31,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015159839764237404, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.581, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0120578333735466, 'eval_loss_2': 0.0031020045280456543, 'eval_loss_3': -18.132970809936523, 'eval_loss_4': -0.13722258806228638, 'epoch': 27.09}
{'loss': 0.0108, 'grad_norm': 4.751802444458008, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.002403517486527562, 'loss_2': 0.00843048095703125, 'loss_3': -16.762676239013672, 'loss_4': 0.04898320883512497, 'epoch': 27.1}
{'loss': 0.0238, 'grad_norm': 6.366785526275635, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.012498535215854645, 'loss_2': 0.011322021484375, 'loss_3': -16.445606231689453, 'loss_4': -0.527916669845581, 'epoch': 27.1}
{'loss': 0.0098, 'grad_norm': 5.362522125244141, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.0038598657120019197, 'loss_2': 0.00598907470703125, 'loss_3': -16.540225982666016, 'loss_4': -0.40415796637535095, 'epoch': 27.11}
{'loss': 0.0031, 'grad_norm': 4.672485828399658, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.0029658216517418623, 'loss_2': 0.00017774105072021484, 'loss_3': -16.435829162597656, 'loss_4': -0.5007461309432983, 'epoch': 27.12}
{'loss': 0.0108, 'grad_norm': 5.40709114074707, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.007166638970375061, 'loss_2': 0.0036468505859375, 'loss_3': -16.492267608642578, 'loss_4': -0.3735570013523102, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 17:12:31,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:31,660 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:55:09<08:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:39,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01532702799886465, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.149, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012247227132320404, 'eval_loss_2': 0.0030798017978668213, 'eval_loss_3': -18.13164520263672, 'eval_loss_4': -0.14810341596603394, 'epoch': 27.12}
{'loss': 0.009, 'grad_norm': 5.274805068969727, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.008600277826189995, 'loss_2': 0.00037550926208496094, 'loss_3': -16.51873779296875, 'loss_4': -0.2846889793872833, 'epoch': 27.13}
{'loss': 0.0113, 'grad_norm': 4.670184135437012, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.0032274797558784485, 'loss_2': 0.008056640625, 'loss_3': -16.68899154663086, 'loss_4': -0.1753433644771576, 'epoch': 27.13}
{'loss': 0.0037, 'grad_norm': 4.704506874084473, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.0032515591010451317, 'loss_2': 0.0004482269287109375, 'loss_3': -16.612335205078125, 'loss_4': -0.37525975704193115, 'epoch': 27.14}
{'loss': 0.0055, 'grad_norm': 4.397314548492432, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.0028704002033919096, 'loss_2': 0.0026531219482421875, 'loss_3': -16.530166625976562, 'loss_4': -0.32731395959854126, 'epoch': 27.15}
{'loss': 0.0154, 'grad_norm': 6.113646984100342, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.010990972630679607, 'loss_2': 0.00441741943359375, 'loss_3': -16.51042938232422, 'loss_4': -0.21244733035564423, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 17:12:39,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:39,018 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:55:17<08:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:46,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01563555747270584, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012625759467482567, 'eval_loss_2': 0.003009796142578125, 'eval_loss_3': -18.127540588378906, 'eval_loss_4': -0.1980954110622406, 'epoch': 27.15}
{'loss': 0.0289, 'grad_norm': 14.077619552612305, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.02549627423286438, 'loss_2': 0.0033588409423828125, 'loss_3': -16.350013732910156, 'loss_4': -0.18613512814044952, 'epoch': 27.16}
{'loss': 0.0311, 'grad_norm': 16.088693618774414, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.025202877819538116, 'loss_2': 0.005889892578125, 'loss_3': -16.549476623535156, 'loss_4': -0.43456435203552246, 'epoch': 27.16}
{'loss': 0.0037, 'grad_norm': 4.3999128341674805, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.002429674845188856, 'loss_2': 0.001247406005859375, 'loss_3': -16.559646606445312, 'loss_4': -0.4754657745361328, 'epoch': 27.17}
{'loss': 0.0083, 'grad_norm': 4.471862316131592, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.0028968791011720896, 'loss_2': 0.00537109375, 'loss_3': -16.403820037841797, 'loss_4': -0.13430358469486237, 'epoch': 27.17}
{'loss': 0.0072, 'grad_norm': 4.437778949737549, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.0033031925559043884, 'loss_2': 0.003917694091796875, 'loss_3': -16.57132339477539, 'loss_4': -0.4597525894641876, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 17:12:46,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:46,373 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:24<08:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:53,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015417037531733513, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.526, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012387154623866081, 'eval_loss_2': 0.0030298829078674316, 'eval_loss_3': -18.123014450073242, 'eval_loss_4': -0.2291620969772339, 'epoch': 27.18}
{'loss': 0.0114, 'grad_norm': 5.533562660217285, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.006972977425903082, 'loss_2': 0.0044097900390625, 'loss_3': -16.403799057006836, 'loss_4': -0.5496465563774109, 'epoch': 27.19}
{'loss': 0.007, 'grad_norm': 4.799038410186768, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.005999684799462557, 'loss_2': 0.000980377197265625, 'loss_3': -16.35903549194336, 'loss_4': -0.5004919171333313, 'epoch': 27.19}
{'loss': 0.0192, 'grad_norm': 6.464449405670166, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.015195784159004688, 'loss_2': 0.004039764404296875, 'loss_3': -16.61029815673828, 'loss_4': -0.39361780881881714, 'epoch': 27.2}
{'loss': 0.003, 'grad_norm': 4.6849164962768555, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.0021583724301308393, 'loss_2': 0.0008807182312011719, 'loss_3': -16.5070858001709, 'loss_4': -0.08378053456544876, 'epoch': 27.2}
{'loss': 0.0044, 'grad_norm': 4.512304306030273, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.00136798364110291, 'loss_2': 0.00299835205078125, 'loss_3': -16.467384338378906, 'loss_4': -0.33924248814582825, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 17:12:53,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:53,723 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:31<08:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:01,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014944926835596561, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.049, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01190610509365797, 'eval_loss_2': 0.0030388236045837402, 'eval_loss_3': -18.1314754486084, 'eval_loss_4': -0.21330347657203674, 'epoch': 27.21}
{'loss': 0.0099, 'grad_norm': 6.149136543273926, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.009192521683871746, 'loss_2': 0.0006742477416992188, 'loss_3': -16.463977813720703, 'loss_4': -0.4460821747779846, 'epoch': 27.22}
{'loss': 0.0109, 'grad_norm': 5.084612846374512, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.00571077736094594, 'loss_2': 0.00518035888671875, 'loss_3': -16.65239715576172, 'loss_4': -0.716966986656189, 'epoch': 27.22}
{'loss': 0.0093, 'grad_norm': 5.979565620422363, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.004504301119595766, 'loss_2': 0.00479888916015625, 'loss_3': -16.63261604309082, 'loss_4': -0.031828224658966064, 'epoch': 27.23}
{'loss': 0.0125, 'grad_norm': 6.056394100189209, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.004372551571577787, 'loss_2': 0.008087158203125, 'loss_3': -16.558391571044922, 'loss_4': -0.3897767663002014, 'epoch': 27.23}
{'loss': 0.0088, 'grad_norm': 5.091729164123535, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.0035077249631285667, 'loss_2': 0.005260467529296875, 'loss_3': -16.46072006225586, 'loss_4': -0.137864351272583, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 17:13:01,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:01,068 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:39<08:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:08,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01399865560233593, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.725, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01138312928378582, 'eval_loss_2': 0.00261552631855011, 'eval_loss_3': -18.140653610229492, 'eval_loss_4': -0.20305517315864563, 'epoch': 27.24}
{'loss': 0.0104, 'grad_norm': 4.901989936828613, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.004939893260598183, 'loss_2': 0.0054168701171875, 'loss_3': -16.573888778686523, 'loss_4': -0.025981992483139038, 'epoch': 27.24}
{'loss': 0.0046, 'grad_norm': 4.463797569274902, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.0032298665028065443, 'loss_2': 0.001354217529296875, 'loss_3': -16.551687240600586, 'loss_4': 0.042016565799713135, 'epoch': 27.25}
{'loss': 0.0137, 'grad_norm': 6.940573692321777, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.013071904890239239, 'loss_2': 0.0006465911865234375, 'loss_3': -16.521913528442383, 'loss_4': 0.08470827341079712, 'epoch': 27.26}
{'loss': 0.0075, 'grad_norm': 5.527284622192383, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.006161963101476431, 'loss_2': 0.0012969970703125, 'loss_3': -16.622426986694336, 'loss_4': -0.6148436069488525, 'epoch': 27.26}
{'loss': 0.0114, 'grad_norm': 5.279516696929932, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.006484797690063715, 'loss_2': 0.004886627197265625, 'loss_3': -16.33553695678711, 'loss_4': -0.5564146637916565, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 17:13:08,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:08,417 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:46<08:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:15,764 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013649096712470055, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011625713668763638, 'eval_loss_2': 0.0020233839750289917, 'eval_loss_3': -18.14266586303711, 'eval_loss_4': -0.2143450528383255, 'epoch': 27.27}
{'loss': 0.0098, 'grad_norm': 6.388337135314941, 'learning_rate': 2.75e-06, 'loss_1': 0.00760459853336215, 'loss_2': 0.0021610260009765625, 'loss_3': -16.72797966003418, 'loss_4': -0.06907016038894653, 'epoch': 27.27}
{'loss': 0.01, 'grad_norm': 6.440850734710693, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.009040816687047482, 'loss_2': 0.0009517669677734375, 'loss_3': -16.614477157592773, 'loss_4': 0.06904266774654388, 'epoch': 27.28}
{'loss': 0.0093, 'grad_norm': 4.253254413604736, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.0025115739554166794, 'loss_2': 0.0068206787109375, 'loss_3': -16.680015563964844, 'loss_4': -0.2090400755405426, 'epoch': 27.28}
{'loss': 0.0157, 'grad_norm': 8.206680297851562, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.011416975408792496, 'loss_2': 0.004283905029296875, 'loss_3': -16.402355194091797, 'loss_4': -0.10552234947681427, 'epoch': 27.29}
{'loss': 0.0073, 'grad_norm': 4.986865997314453, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.0032593272626399994, 'loss_2': 0.004077911376953125, 'loss_3': -16.731842041015625, 'loss_4': -0.07794123888015747, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 17:13:15,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:15,764 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:53<07:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:23,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013603780418634415, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011296992190182209, 'eval_loss_2': 0.0023067891597747803, 'eval_loss_3': -18.152313232421875, 'eval_loss_4': -0.216110959649086, 'epoch': 27.3}
{'loss': 0.0107, 'grad_norm': 5.181763648986816, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.004121056292206049, 'loss_2': 0.0065460205078125, 'loss_3': -16.55164337158203, 'loss_4': -0.14418211579322815, 'epoch': 27.3}
{'loss': 0.0779, 'grad_norm': 10.920745849609375, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.07566870003938675, 'loss_2': 0.002227783203125, 'loss_3': -16.91936492919922, 'loss_4': -0.027981162071228027, 'epoch': 27.31}
{'loss': 0.005, 'grad_norm': 4.915322303771973, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.004770350176841021, 'loss_2': 0.0002446174621582031, 'loss_3': -16.424535751342773, 'loss_4': -0.19573889672756195, 'epoch': 27.31}
{'loss': 0.0206, 'grad_norm': 10.066624641418457, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.01702065020799637, 'loss_2': 0.003604888916015625, 'loss_3': -16.522764205932617, 'loss_4': -0.16235555708408356, 'epoch': 27.32}
{'loss': 0.011, 'grad_norm': 5.1959919929504395, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.005907136481255293, 'loss_2': 0.00513458251953125, 'loss_3': -16.667682647705078, 'loss_4': -0.5374177694320679, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 17:13:23,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:23,121 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:56:01<07:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:30,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012989229522645473, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010706005617976189, 'eval_loss_2': 0.00228322297334671, 'eval_loss_3': -18.158458709716797, 'eval_loss_4': -0.22299417853355408, 'epoch': 27.33}
{'loss': 0.0072, 'grad_norm': 4.49920129776001, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.0057146442122757435, 'loss_2': 0.0015048980712890625, 'loss_3': -16.669633865356445, 'loss_4': -0.12783439457416534, 'epoch': 27.33}
{'loss': 0.0038, 'grad_norm': 4.859042644500732, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.0031951291020959616, 'loss_2': 0.0006070137023925781, 'loss_3': -16.46314811706543, 'loss_4': -0.41814106702804565, 'epoch': 27.34}
{'loss': 0.0046, 'grad_norm': 5.251285076141357, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.0035544836428016424, 'loss_2': 0.0010194778442382812, 'loss_3': -16.434099197387695, 'loss_4': -0.4130547344684601, 'epoch': 27.34}
{'loss': 0.0109, 'grad_norm': 5.371396541595459, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.0050779362209141254, 'loss_2': 0.005840301513671875, 'loss_3': -16.57878875732422, 'loss_4': 0.13095398247241974, 'epoch': 27.35}
{'loss': 0.0044, 'grad_norm': 4.746761798858643, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.0037112811114639044, 'loss_2': 0.000675201416015625, 'loss_3': -16.4549560546875, 'loss_4': -0.16408905386924744, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 17:13:30,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:30,471 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:56:08<07:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:37,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013258158229291439, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.888, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01096427533775568, 'eval_loss_2': 0.002293884754180908, 'eval_loss_3': -18.162574768066406, 'eval_loss_4': -0.21403726935386658, 'epoch': 27.35}
{'loss': 0.0132, 'grad_norm': 5.649220943450928, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.0063965232111513615, 'loss_2': 0.0068511962890625, 'loss_3': -16.619369506835938, 'loss_4': -0.50287926197052, 'epoch': 27.36}
{'loss': 0.007, 'grad_norm': 4.546064376831055, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.003837107913568616, 'loss_2': 0.0031185150146484375, 'loss_3': -16.46774673461914, 'loss_4': -0.20084762573242188, 'epoch': 27.37}
{'loss': 0.0063, 'grad_norm': 4.992835998535156, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.0036070155911147594, 'loss_2': 0.00266265869140625, 'loss_3': -16.438446044921875, 'loss_4': -0.4420822858810425, 'epoch': 27.37}
{'loss': 0.0075, 'grad_norm': 8.621156692504883, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.006050080060958862, 'loss_2': 0.001445770263671875, 'loss_3': -16.535381317138672, 'loss_4': -0.04708041250705719, 'epoch': 27.38}
{'loss': 0.0141, 'grad_norm': 6.747278213500977, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.008626972325146198, 'loss_2': 0.0054779052734375, 'loss_3': -16.46955108642578, 'loss_4': -0.4773188531398773, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 17:13:37,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:37,819 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:56:16<07:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:45,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01279030367732048, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010030712001025677, 'eval_loss_2': 0.002759590744972229, 'eval_loss_3': -18.159420013427734, 'eval_loss_4': -0.20692408084869385, 'epoch': 27.38}
{'loss': 0.0034, 'grad_norm': 4.669955730438232, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.0028128386475145817, 'loss_2': 0.000637054443359375, 'loss_3': -16.574373245239258, 'loss_4': -0.3613424301147461, 'epoch': 27.39}
{'loss': 0.0047, 'grad_norm': 4.672463417053223, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.003804978681728244, 'loss_2': 0.0009446144104003906, 'loss_3': -16.313100814819336, 'loss_4': -0.031502269208431244, 'epoch': 27.4}
{'loss': 0.0745, 'grad_norm': 27.273099899291992, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.0732230395078659, 'loss_2': 0.001316070556640625, 'loss_3': -16.516551971435547, 'loss_4': 0.06960989534854889, 'epoch': 27.4}
{'loss': 0.0055, 'grad_norm': 4.663100242614746, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.004306428600102663, 'loss_2': 0.0012178421020507812, 'loss_3': -16.258913040161133, 'loss_4': -0.5543752908706665, 'epoch': 27.41}
{'loss': 0.0081, 'grad_norm': 5.441750526428223, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.006732839159667492, 'loss_2': 0.0014162063598632812, 'loss_3': -16.560482025146484, 'loss_4': -0.6079630851745605, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 17:13:45,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:45,169 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:23<07:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:52,514 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012279557064175606, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.623, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009149479679763317, 'eval_loss_2': 0.0031300783157348633, 'eval_loss_3': -18.1693058013916, 'eval_loss_4': -0.20284222066402435, 'epoch': 27.41}
{'loss': 0.008, 'grad_norm': 5.208978652954102, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.006000283639878035, 'loss_2': 0.0019893646240234375, 'loss_3': -16.76592254638672, 'loss_4': -0.22678710520267487, 'epoch': 27.42}
{'loss': 0.0087, 'grad_norm': 4.683424949645996, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.0045587834902107716, 'loss_2': 0.004150390625, 'loss_3': -16.76344108581543, 'loss_4': -0.4011252522468567, 'epoch': 27.42}
{'loss': 0.0137, 'grad_norm': 11.110337257385254, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.013698861002922058, 'loss_2': 2.759695053100586e-05, 'loss_3': -16.683570861816406, 'loss_4': -0.38651639223098755, 'epoch': 27.43}
{'loss': 0.0107, 'grad_norm': 5.813137531280518, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.00967547670006752, 'loss_2': 0.001064300537109375, 'loss_3': -16.46474838256836, 'loss_4': 0.00011269748210906982, 'epoch': 27.44}
{'loss': 0.0046, 'grad_norm': 4.927098751068115, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.004514098633080721, 'loss_2': 7.843971252441406e-05, 'loss_3': -16.39702033996582, 'loss_4': -0.18049994111061096, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 17:13:52,514 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:52,514 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:30<07:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:59,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011852276511490345, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008900237269699574, 'eval_loss_2': 0.0029520392417907715, 'eval_loss_3': -18.168338775634766, 'eval_loss_4': -0.2067076563835144, 'epoch': 27.44}
{'loss': 0.0028, 'grad_norm': 5.000185489654541, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.002255356637760997, 'loss_2': 0.0005807876586914062, 'loss_3': -16.546525955200195, 'loss_4': -0.42923659086227417, 'epoch': 27.45}
{'loss': 0.0061, 'grad_norm': 4.426591873168945, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.003935172688215971, 'loss_2': 0.00215911865234375, 'loss_3': -16.490966796875, 'loss_4': -0.29719942808151245, 'epoch': 27.45}
{'loss': 0.0135, 'grad_norm': 7.690255165100098, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.006731859873980284, 'loss_2': 0.00678253173828125, 'loss_3': -16.51740264892578, 'loss_4': -0.21145854890346527, 'epoch': 27.46}
{'loss': 0.0035, 'grad_norm': 4.60499906539917, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.0025025715585798025, 'loss_2': 0.0010156631469726562, 'loss_3': -16.50049591064453, 'loss_4': -0.01153421401977539, 'epoch': 27.47}
{'loss': 0.007, 'grad_norm': 5.822704315185547, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.006867351941764355, 'loss_2': 0.00012302398681640625, 'loss_3': -16.456871032714844, 'loss_4': -0.144875168800354, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 17:13:59,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:59,869 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:38<07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:07,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010968364775180817, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008611668832600117, 'eval_loss_2': 0.0023566968739032745, 'eval_loss_3': -18.167089462280273, 'eval_loss_4': -0.24105724692344666, 'epoch': 27.47}
{'loss': 0.0059, 'grad_norm': 4.656810760498047, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.004395206458866596, 'loss_2': 0.0014982223510742188, 'loss_3': -16.448619842529297, 'loss_4': 0.023326031863689423, 'epoch': 27.48}
{'loss': 0.0053, 'grad_norm': 4.501582622528076, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.0021207595709711313, 'loss_2': 0.00313568115234375, 'loss_3': -16.508060455322266, 'loss_4': -0.22113269567489624, 'epoch': 27.48}
{'loss': 0.0039, 'grad_norm': 4.721973419189453, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.0032898886129260063, 'loss_2': 0.0006093978881835938, 'loss_3': -16.559680938720703, 'loss_4': -0.508759617805481, 'epoch': 27.49}
{'loss': 0.0063, 'grad_norm': 5.0350518226623535, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.0033314914908260107, 'loss_2': 0.0029201507568359375, 'loss_3': -16.681177139282227, 'loss_4': -0.6265617609024048, 'epoch': 27.49}
{'loss': 0.0044, 'grad_norm': 4.419550895690918, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.004301887471228838, 'loss_2': 0.00014162063598632812, 'loss_3': -16.565216064453125, 'loss_4': 0.37841659784317017, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 17:14:07,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:07,221 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:45<07:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:14,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010650597512722015, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00845898687839508, 'eval_loss_2': 0.002191610634326935, 'eval_loss_3': -18.175071716308594, 'eval_loss_4': -0.2666780948638916, 'epoch': 27.5}
{'loss': 0.0096, 'grad_norm': 5.134266376495361, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.007286585867404938, 'loss_2': 0.002330780029296875, 'loss_3': -16.47893524169922, 'loss_4': -0.6440479755401611, 'epoch': 27.51}
{'loss': 0.0095, 'grad_norm': 4.879065990447998, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.0037937858141958714, 'loss_2': 0.005748748779296875, 'loss_3': -16.499189376831055, 'loss_4': -0.2885720431804657, 'epoch': 27.51}
{'loss': 0.0072, 'grad_norm': 4.491593837738037, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.0040036276914179325, 'loss_2': 0.0032444000244140625, 'loss_3': -16.656307220458984, 'loss_4': -0.1558789312839508, 'epoch': 27.52}
{'loss': 0.0095, 'grad_norm': 5.504665851593018, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.006545491516590118, 'loss_2': 0.00299072265625, 'loss_3': -16.58049774169922, 'loss_4': -0.03135833144187927, 'epoch': 27.52}
{'loss': 0.0077, 'grad_norm': 5.6151533126831055, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.005787428468465805, 'loss_2': 0.001956939697265625, 'loss_3': -16.74958038330078, 'loss_4': -0.522508978843689, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 17:14:14,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:14,569 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:52<07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:21,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010493692010641098, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.597, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008396091870963573, 'eval_loss_2': 0.00209759920835495, 'eval_loss_3': -18.176420211791992, 'eval_loss_4': -0.25648847222328186, 'epoch': 27.53}
{'loss': 0.004, 'grad_norm': 5.012217998504639, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.003472068812698126, 'loss_2': 0.0005412101745605469, 'loss_3': -16.445003509521484, 'loss_4': -0.05490742623806, 'epoch': 27.53}
{'loss': 0.0123, 'grad_norm': 4.536474227905273, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.003583415411412716, 'loss_2': 0.00872802734375, 'loss_3': -16.62969970703125, 'loss_4': 0.12832799553871155, 'epoch': 27.54}
{'loss': 0.0074, 'grad_norm': 4.696974754333496, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.0026644703466445208, 'loss_2': 0.00469207763671875, 'loss_3': -16.517850875854492, 'loss_4': -0.06260716915130615, 'epoch': 27.55}
{'loss': 0.0078, 'grad_norm': 4.4244608879089355, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.002768181264400482, 'loss_2': 0.0050201416015625, 'loss_3': -16.763151168823242, 'loss_4': -0.21059398353099823, 'epoch': 27.55}
{'loss': 0.0039, 'grad_norm': 5.0559401512146, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.0038692571688443422, 'loss_2': 1.806020736694336e-05, 'loss_3': -16.408870697021484, 'loss_4': -0.4999958276748657, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 17:14:21,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:21,928 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:57:00<07:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:29,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010864028707146645, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.316, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008315431885421276, 'eval_loss_2': 0.002548597753047943, 'eval_loss_3': -18.167905807495117, 'eval_loss_4': -0.2391432821750641, 'epoch': 27.56}
{'loss': 0.0057, 'grad_norm': 5.138907432556152, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.005252519156783819, 'loss_2': 0.0004963874816894531, 'loss_3': -16.605106353759766, 'loss_4': -0.10785426944494247, 'epoch': 27.56}
{'loss': 0.0143, 'grad_norm': 6.095673561096191, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.008970056660473347, 'loss_2': 0.0053253173828125, 'loss_3': -16.411523818969727, 'loss_4': -0.4431576728820801, 'epoch': 27.57}
{'loss': 0.01, 'grad_norm': 5.6269049644470215, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.009166892617940903, 'loss_2': 0.000858306884765625, 'loss_3': -16.707855224609375, 'loss_4': 0.15598319470882416, 'epoch': 27.58}
{'loss': 0.0058, 'grad_norm': 5.14850378036499, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.005410382524132729, 'loss_2': 0.0003952980041503906, 'loss_3': -16.48265266418457, 'loss_4': -0.12581723928451538, 'epoch': 27.58}
{'loss': 0.0094, 'grad_norm': 6.182347297668457, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.005151736084371805, 'loss_2': 0.00423431396484375, 'loss_3': -16.592546463012695, 'loss_4': -0.53643399477005, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 17:14:29,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:29,296 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:57:07<07:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:36,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011311346665024757, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.776, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008163267746567726, 'eval_loss_2': 0.0031480789184570312, 'eval_loss_3': -18.16180992126465, 'eval_loss_4': -0.23640498518943787, 'epoch': 27.59}
{'loss': 0.005, 'grad_norm': 5.975826740264893, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.004602047614753246, 'loss_2': 0.0004363059997558594, 'loss_3': -16.369537353515625, 'loss_4': -0.2840539216995239, 'epoch': 27.59}
{'loss': 0.009, 'grad_norm': 6.277893543243408, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.008343019522726536, 'loss_2': 0.0006084442138671875, 'loss_3': -16.61754608154297, 'loss_4': -0.441115140914917, 'epoch': 27.6}
{'loss': 0.0051, 'grad_norm': 4.895075798034668, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.004424108657985926, 'loss_2': 0.0007123947143554688, 'loss_3': -16.528181076049805, 'loss_4': -0.4734630584716797, 'epoch': 27.6}
{'loss': 0.0102, 'grad_norm': 4.789855480194092, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.0033577713184058666, 'loss_2': 0.00684356689453125, 'loss_3': -16.5510196685791, 'loss_4': 0.12636762857437134, 'epoch': 27.61}
{'loss': 0.0091, 'grad_norm': 8.384420394897461, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.007607821375131607, 'loss_2': 0.0014543533325195312, 'loss_3': -16.45322608947754, 'loss_4': -0.17893092334270477, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 17:14:36,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:36,662 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:57:14<07:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:44,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010796803049743176, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.325, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007741737179458141, 'eval_loss_2': 0.003055065870285034, 'eval_loss_3': -18.168373107910156, 'eval_loss_4': -0.2246232032775879, 'epoch': 27.62}
{'loss': 0.007, 'grad_norm': 4.32116174697876, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.00214539491571486, 'loss_2': 0.00484466552734375, 'loss_3': -16.53761863708496, 'loss_4': -0.6273593902587891, 'epoch': 27.62}
{'loss': 0.0046, 'grad_norm': 4.408740997314453, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0017376935575157404, 'loss_2': 0.002872467041015625, 'loss_3': -16.52194595336914, 'loss_4': -0.24351270496845245, 'epoch': 27.63}
{'loss': 0.0098, 'grad_norm': 5.275654315948486, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.006967664230614901, 'loss_2': 0.002788543701171875, 'loss_3': -16.525760650634766, 'loss_4': -0.2170814871788025, 'epoch': 27.63}
{'loss': 0.0093, 'grad_norm': 4.73484992980957, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.004101034253835678, 'loss_2': 0.00522613525390625, 'loss_3': -16.444299697875977, 'loss_4': -0.3687009811401367, 'epoch': 27.64}
{'loss': 0.0041, 'grad_norm': 4.6743998527526855, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.0031350443605333567, 'loss_2': 0.0009403228759765625, 'loss_3': -16.369199752807617, 'loss_4': -0.14676794409751892, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 17:14:44,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:44,010 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:22<06:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:51,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010660748928785324, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007888738065958023, 'eval_loss_2': 0.002772010862827301, 'eval_loss_3': -18.16976547241211, 'eval_loss_4': -0.20423832535743713, 'epoch': 27.65}
{'loss': 0.0071, 'grad_norm': 5.1972126960754395, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.005915864836424589, 'loss_2': 0.0011386871337890625, 'loss_3': -16.72515106201172, 'loss_4': -0.5609675645828247, 'epoch': 27.65}
{'loss': 0.0057, 'grad_norm': 5.971076965332031, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.00476657971739769, 'loss_2': 0.0009217262268066406, 'loss_3': -16.38125991821289, 'loss_4': -0.05240563303232193, 'epoch': 27.66}
{'loss': 0.0155, 'grad_norm': 5.446387767791748, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.008036097511649132, 'loss_2': 0.00745391845703125, 'loss_3': -16.41000747680664, 'loss_4': -0.1410684883594513, 'epoch': 27.66}
{'loss': 0.008, 'grad_norm': 6.525380611419678, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.005176319740712643, 'loss_2': 0.00278472900390625, 'loss_3': -16.53082275390625, 'loss_4': -0.5106579065322876, 'epoch': 27.67}
{'loss': 0.0033, 'grad_norm': 5.375569820404053, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.0030692415311932564, 'loss_2': 0.0002307891845703125, 'loss_3': -16.627883911132812, 'loss_4': -0.06498298048973083, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 17:14:51,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:51,368 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:29<06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:58,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010516742244362831, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.543, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.007972009479999542, 'eval_loss_2': 0.002544734627008438, 'eval_loss_3': -18.16800880432129, 'eval_loss_4': -0.19826948642730713, 'epoch': 27.67}
{'loss': 0.0048, 'grad_norm': 4.124693870544434, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.0019520996138453484, 'loss_2': 0.0028285980224609375, 'loss_3': -16.53426170349121, 'loss_4': 0.17880530655384064, 'epoch': 27.68}
{'loss': 0.0094, 'grad_norm': 5.195102691650391, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.0030593383125960827, 'loss_2': 0.00629425048828125, 'loss_3': -16.545394897460938, 'loss_4': 0.41231846809387207, 'epoch': 27.69}
{'loss': 0.0055, 'grad_norm': 4.855681419372559, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.0035138793755322695, 'loss_2': 0.0019512176513671875, 'loss_3': -16.585140228271484, 'loss_4': -0.13654860854148865, 'epoch': 27.69}
{'loss': 0.0033, 'grad_norm': 4.344934463500977, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.001960426103323698, 'loss_2': 0.001377105712890625, 'loss_3': -16.68858528137207, 'loss_4': -0.31428417563438416, 'epoch': 27.7}
{'loss': 0.0063, 'grad_norm': 5.123488426208496, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.0028559465426951647, 'loss_2': 0.0034332275390625, 'loss_3': -16.530517578125, 'loss_4': 0.04815036058425903, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 17:14:58,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:58,717 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:36<06:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:06,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010507652536034584, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007849762216210365, 'eval_loss_2': 0.0026578903198242188, 'eval_loss_3': -18.165725708007812, 'eval_loss_4': -0.19131526350975037, 'epoch': 27.7}
{'loss': 0.0071, 'grad_norm': 5.0526957511901855, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.0030543855391442776, 'loss_2': 0.0040435791015625, 'loss_3': -16.574188232421875, 'loss_4': -0.22418202459812164, 'epoch': 27.71}
{'loss': 0.0072, 'grad_norm': 4.154528617858887, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.002950304187834263, 'loss_2': 0.0042266845703125, 'loss_3': -16.529741287231445, 'loss_4': -0.44290047883987427, 'epoch': 27.72}
{'loss': 0.0078, 'grad_norm': 4.894770622253418, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.004557576961815357, 'loss_2': 0.0032444000244140625, 'loss_3': -16.42977523803711, 'loss_4': -0.09965662658214569, 'epoch': 27.72}
{'loss': 0.0038, 'grad_norm': 4.6157708168029785, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.0022444422356784344, 'loss_2': 0.001506805419921875, 'loss_3': -16.53304672241211, 'loss_4': -0.6072585582733154, 'epoch': 27.73}
{'loss': 0.012, 'grad_norm': 7.470396041870117, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.009896094910800457, 'loss_2': 0.0020809173583984375, 'loss_3': -16.590970993041992, 'loss_4': -0.635798990726471, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 17:15:06,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:06,066 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:44<06:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:13,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010823829099535942, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.778, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008029562421143055, 'eval_loss_2': 0.0027942657470703125, 'eval_loss_3': -18.162424087524414, 'eval_loss_4': -0.20815414190292358, 'epoch': 27.73}
{'loss': 0.0084, 'grad_norm': 4.766353130340576, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.006863567046821117, 'loss_2': 0.0015716552734375, 'loss_3': -16.68010711669922, 'loss_4': -0.11768720299005508, 'epoch': 27.74}
{'loss': 0.0065, 'grad_norm': 4.722814559936523, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.004081541672348976, 'loss_2': 0.00243377685546875, 'loss_3': -16.6109561920166, 'loss_4': -0.03161322697997093, 'epoch': 27.74}
{'loss': 0.0063, 'grad_norm': 4.90540885925293, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.0039743990637362, 'loss_2': 0.00235748291015625, 'loss_3': -16.58350372314453, 'loss_4': 0.021757803857326508, 'epoch': 27.75}
{'loss': 0.0086, 'grad_norm': 4.863407135009766, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.0039388258010149, 'loss_2': 0.004611968994140625, 'loss_3': -16.58065414428711, 'loss_4': 0.17087537050247192, 'epoch': 27.76}
{'loss': 0.0092, 'grad_norm': 5.49859619140625, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.00830654427409172, 'loss_2': 0.0009260177612304688, 'loss_3': -16.51951789855957, 'loss_4': -0.4292982816696167, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 17:15:13,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:13,416 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:51<06:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:20,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010968027636408806, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008051752112805843, 'eval_loss_2': 0.002916276454925537, 'eval_loss_3': -18.156387329101562, 'eval_loss_4': -0.22217725217342377, 'epoch': 27.76}
{'loss': 0.0064, 'grad_norm': 5.121007919311523, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.005019485484808683, 'loss_2': 0.001373291015625, 'loss_3': -16.54967498779297, 'loss_4': -0.2419130951166153, 'epoch': 27.77}
{'loss': 0.0064, 'grad_norm': 4.408522605895996, 'learning_rate': 2.25e-06, 'loss_1': 0.0029759572353214025, 'loss_2': 0.003387451171875, 'loss_3': -16.30852508544922, 'loss_4': -0.07142522931098938, 'epoch': 27.77}
{'loss': 0.0118, 'grad_norm': 5.594576358795166, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.005805928725749254, 'loss_2': 0.006000518798828125, 'loss_3': -16.586471557617188, 'loss_4': -0.6785738468170166, 'epoch': 27.78}
{'loss': 0.015, 'grad_norm': 11.400955200195312, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.012915085069835186, 'loss_2': 0.002044677734375, 'loss_3': -16.671018600463867, 'loss_4': -0.0814058780670166, 'epoch': 27.78}
{'loss': 0.0048, 'grad_norm': 4.301610946655273, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.003031322965398431, 'loss_2': 0.0017347335815429688, 'loss_3': -16.59772491455078, 'loss_4': 0.07668547332286835, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 17:15:20,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:20,780 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:58<06:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:28,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010959891602396965, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007979480549693108, 'eval_loss_2': 0.0029804110527038574, 'eval_loss_3': -18.15777587890625, 'eval_loss_4': -0.22104701399803162, 'epoch': 27.79}
{'loss': 0.0057, 'grad_norm': 4.8592634201049805, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.0027091375086456537, 'loss_2': 0.0029544830322265625, 'loss_3': -16.477567672729492, 'loss_4': -0.07499441504478455, 'epoch': 27.8}
{'loss': 0.0057, 'grad_norm': 4.73688268661499, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.002954882336780429, 'loss_2': 0.002716064453125, 'loss_3': -16.640506744384766, 'loss_4': -0.16539552807807922, 'epoch': 27.8}
{'loss': 0.0037, 'grad_norm': 4.157013893127441, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.002438813680782914, 'loss_2': 0.0012979507446289062, 'loss_3': -16.719301223754883, 'loss_4': -0.1875522881746292, 'epoch': 27.81}
{'loss': 0.0091, 'grad_norm': 5.026652812957764, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.00407683290541172, 'loss_2': 0.0050201416015625, 'loss_3': -16.52560043334961, 'loss_4': -0.6649354100227356, 'epoch': 27.81}
{'loss': 0.007, 'grad_norm': 5.220226764678955, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.004737870767712593, 'loss_2': 0.00223541259765625, 'loss_3': -16.498138427734375, 'loss_4': -0.46161365509033203, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 17:15:28,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:28,124 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:58:06<06:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:35,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011106666177511215, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.314, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008076216094195843, 'eval_loss_2': 0.003030449151992798, 'eval_loss_3': -18.16378402709961, 'eval_loss_4': -0.21995809674263, 'epoch': 27.82}
{'loss': 0.0104, 'grad_norm': 5.907607555389404, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.006229802500456572, 'loss_2': 0.004154205322265625, 'loss_3': -16.60234832763672, 'loss_4': -0.47354310750961304, 'epoch': 27.83}
{'loss': 0.0065, 'grad_norm': 5.012681484222412, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.0033182722982019186, 'loss_2': 0.0032215118408203125, 'loss_3': -16.4272518157959, 'loss_4': -0.1459406018257141, 'epoch': 27.83}
{'loss': 0.0167, 'grad_norm': 6.5412373542785645, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.00822746753692627, 'loss_2': 0.00852203369140625, 'loss_3': -16.48737335205078, 'loss_4': -0.46474403142929077, 'epoch': 27.84}
{'loss': 0.0332, 'grad_norm': 14.885082244873047, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.03074886091053486, 'loss_2': 0.002437591552734375, 'loss_3': -16.59992218017578, 'loss_4': 0.01282849907875061, 'epoch': 27.84}
{'loss': 0.007, 'grad_norm': 5.580695629119873, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.004512378014624119, 'loss_2': 0.002468109130859375, 'loss_3': -16.48836326599121, 'loss_4': -0.24480584263801575, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 17:15:35,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:35,478 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:58:13<06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:42,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01134401559829712, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.8, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008239597082138062, 'eval_loss_2': 0.0031044185161590576, 'eval_loss_3': -18.172895431518555, 'eval_loss_4': -0.2205924391746521, 'epoch': 27.85}
{'loss': 0.0096, 'grad_norm': 4.923900604248047, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.007377672474831343, 'loss_2': 0.0021820068359375, 'loss_3': -16.602998733520508, 'loss_4': -0.24012784659862518, 'epoch': 27.85}
{'loss': 0.0084, 'grad_norm': 8.872346878051758, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.0075223385356366634, 'loss_2': 0.0009226799011230469, 'loss_3': -16.695011138916016, 'loss_4': -0.6360999345779419, 'epoch': 27.86}
{'loss': 0.0102, 'grad_norm': 5.328428745269775, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.004356723744422197, 'loss_2': 0.005832672119140625, 'loss_3': -16.479801177978516, 'loss_4': -0.32053184509277344, 'epoch': 27.87}
{'loss': 0.0145, 'grad_norm': 6.450263977050781, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.009378411807119846, 'loss_2': 0.0051422119140625, 'loss_3': -16.5784854888916, 'loss_4': -0.05476291477680206, 'epoch': 27.87}
{'loss': 0.0049, 'grad_norm': 4.234668731689453, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.0035073410253971815, 'loss_2': 0.0014362335205078125, 'loss_3': -16.484085083007812, 'loss_4': -0.15969164669513702, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 17:15:42,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:42,819 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:21<06:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:50,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011493252590298653, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.5, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008405701257288456, 'eval_loss_2': 0.003087550401687622, 'eval_loss_3': -18.17562484741211, 'eval_loss_4': -0.21830281615257263, 'epoch': 27.88}
{'loss': 0.0069, 'grad_norm': 6.610787391662598, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.006152693182229996, 'loss_2': 0.00070953369140625, 'loss_3': -16.789854049682617, 'loss_4': -0.38148534297943115, 'epoch': 27.88}
{'loss': 0.0058, 'grad_norm': 4.712830543518066, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.0032194512896239758, 'loss_2': 0.0025806427001953125, 'loss_3': -16.642459869384766, 'loss_4': 0.1399964988231659, 'epoch': 27.89}
{'loss': 0.0038, 'grad_norm': 4.6413445472717285, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.0032303116749972105, 'loss_2': 0.000583648681640625, 'loss_3': -16.508018493652344, 'loss_4': -0.02582792192697525, 'epoch': 27.9}
{'loss': 0.0046, 'grad_norm': 5.089510440826416, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.004409571178257465, 'loss_2': 0.0002315044403076172, 'loss_3': -16.4930362701416, 'loss_4': -0.28624966740608215, 'epoch': 27.9}
{'loss': 0.0077, 'grad_norm': 5.471588611602783, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.005164141766726971, 'loss_2': 0.0024929046630859375, 'loss_3': -16.53063201904297, 'loss_4': -0.07037530094385147, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 17:15:50,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:50,172 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:28<06:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:57,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011480716988444328, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.252, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008711529895663261, 'eval_loss_2': 0.002769187092781067, 'eval_loss_3': -18.167762756347656, 'eval_loss_4': -0.21356602013111115, 'epoch': 27.91}
{'loss': 0.0066, 'grad_norm': 4.485838890075684, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.003778007347136736, 'loss_2': 0.0028095245361328125, 'loss_3': -16.528278350830078, 'loss_4': -0.4671817123889923, 'epoch': 27.91}
{'loss': 0.0094, 'grad_norm': 4.628124713897705, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.005467510316520929, 'loss_2': 0.003978729248046875, 'loss_3': -16.503353118896484, 'loss_4': -0.25358396768569946, 'epoch': 27.92}
{'loss': 0.0054, 'grad_norm': 4.890611171722412, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.002722420496866107, 'loss_2': 0.002685546875, 'loss_3': -16.59226417541504, 'loss_4': -0.284824937582016, 'epoch': 27.92}
{'loss': 0.0894, 'grad_norm': 11.114889144897461, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.08591151982545853, 'loss_2': 0.0035152435302734375, 'loss_3': -16.594730377197266, 'loss_4': 0.12379822134971619, 'epoch': 27.93}
{'loss': 0.0108, 'grad_norm': 4.518665313720703, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.004008597694337368, 'loss_2': 0.006805419921875, 'loss_3': -16.585403442382812, 'loss_4': -0.3778403401374817, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 17:15:57,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:57,536 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:35<06:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:04,899 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011898812837898731, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.903, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009156052023172379, 'eval_loss_2': 0.002742759883403778, 'eval_loss_3': -18.167964935302734, 'eval_loss_4': -0.19743949174880981, 'epoch': 27.94}
{'loss': 0.0074, 'grad_norm': 4.373753547668457, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.0031442572362720966, 'loss_2': 0.00421905517578125, 'loss_3': -16.550729751586914, 'loss_4': -0.07228638976812363, 'epoch': 27.94}
{'loss': 0.0138, 'grad_norm': 8.926358222961426, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.01013021357357502, 'loss_2': 0.003704071044921875, 'loss_3': -16.492259979248047, 'loss_4': -0.27028387784957886, 'epoch': 27.95}
{'loss': 0.0091, 'grad_norm': 4.692918300628662, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.0022386114578694105, 'loss_2': 0.00687408447265625, 'loss_3': -16.550567626953125, 'loss_4': 0.05076323449611664, 'epoch': 27.95}
{'loss': 0.0074, 'grad_norm': 4.77488374710083, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.002763923956081271, 'loss_2': 0.004608154296875, 'loss_3': -16.47724723815918, 'loss_4': -0.18139268457889557, 'epoch': 27.96}
{'loss': 0.0188, 'grad_norm': 8.305319786071777, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.014452227391302586, 'loss_2': 0.0043182373046875, 'loss_3': -16.455303192138672, 'loss_4': -0.2786991596221924, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 17:16:04,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:04,899 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:43<05:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:16:12,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011706482619047165, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.461, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008894908241927624, 'eval_loss_2': 0.0028115734457969666, 'eval_loss_3': -18.162675857543945, 'eval_loss_4': -0.20472487807273865, 'epoch': 27.97}
{'loss': 0.0135, 'grad_norm': 4.194751739501953, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.004684251267462969, 'loss_2': 0.00879669189453125, 'loss_3': -16.602474212646484, 'loss_4': -0.2369292974472046, 'epoch': 27.97}
{'loss': 0.0068, 'grad_norm': 4.932192325592041, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.0021139674354344606, 'loss_2': 0.00470733642578125, 'loss_3': -16.50502586364746, 'loss_4': 0.07314860820770264, 'epoch': 27.98}
{'loss': 0.0069, 'grad_norm': 5.1221818923950195, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.0030754138715565205, 'loss_2': 0.0038604736328125, 'loss_3': -16.52729034423828, 'loss_4': -0.21794047951698303, 'epoch': 27.98}
{'loss': 0.0101, 'grad_norm': 4.569077491760254, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.002976415678858757, 'loss_2': 0.00714111328125, 'loss_3': -16.553390502929688, 'loss_4': -0.5229740738868713, 'epoch': 27.99}
{'loss': 0.0037, 'grad_norm': 5.141026496887207, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.0029658747371286154, 'loss_2': 0.0007624626159667969, 'loss_3': -16.603418350219727, 'loss_4': -0.610958456993103, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 17:16:12,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:12,236 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:50<05:46,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 17:16:19,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011632455512881279, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008859303779900074, 'eval_loss_2': 0.0027731508016586304, 'eval_loss_3': -18.159029006958008, 'eval_loss_4': -0.20174604654312134, 'epoch': 27.99}
{'loss': 0.0015, 'grad_norm': 6.285523414611816, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0004946495755575597, 'loss_2': 0.0010013580322265625, 'loss_3': -16.65630340576172, 'loss_4': 0.48275476694107056, 'epoch': 28.0}
{'loss': 0.014, 'grad_norm': 13.497030258178711, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.012606284581124783, 'loss_2': 0.001361846923828125, 'loss_3': -16.58267593383789, 'loss_4': -0.2529461085796356, 'epoch': 28.01}
{'loss': 0.0038, 'grad_norm': 4.2927350997924805, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.002051763469353318, 'loss_2': 0.001728057861328125, 'loss_3': -16.63029670715332, 'loss_4': -0.12024154514074326, 'epoch': 28.01}
{'loss': 0.0078, 'grad_norm': 4.904865264892578, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.0024216079618781805, 'loss_2': 0.00537872314453125, 'loss_3': -16.598175048828125, 'loss_4': -0.08052035421133041, 'epoch': 28.02}
{'loss': 0.0106, 'grad_norm': 5.221923828125, 'learning_rate': 2e-06, 'loss_1': 0.005091401748359203, 'loss_2': 0.005519866943359375, 'loss_3': -16.497020721435547, 'loss_4': -0.18984946608543396, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 17:16:19,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:19,300 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:57<05:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:26,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011745166033506393, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008936483412981033, 'eval_loss_2': 0.00280868262052536, 'eval_loss_3': -18.159671783447266, 'eval_loss_4': -0.19227562844753265, 'epoch': 28.02}
{'loss': 0.0083, 'grad_norm': 6.047344207763672, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.004808354657143354, 'loss_2': 0.003528594970703125, 'loss_3': -16.433822631835938, 'loss_4': -0.15055906772613525, 'epoch': 28.03}
{'loss': 0.0061, 'grad_norm': 4.867050647735596, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.003768532769754529, 'loss_2': 0.002349853515625, 'loss_3': -16.587139129638672, 'loss_4': -0.2063186913728714, 'epoch': 28.03}
{'loss': 0.0102, 'grad_norm': 4.774392604827881, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.003061292925849557, 'loss_2': 0.00714874267578125, 'loss_3': -16.597209930419922, 'loss_4': -0.49857860803604126, 'epoch': 28.04}
{'loss': 0.0103, 'grad_norm': 4.58209228515625, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.002629760419949889, 'loss_2': 0.007640838623046875, 'loss_3': -16.441444396972656, 'loss_4': -0.401597261428833, 'epoch': 28.05}
{'loss': 0.01, 'grad_norm': 6.08026123046875, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.007565571926534176, 'loss_2': 0.00244903564453125, 'loss_3': -16.55907440185547, 'loss_4': -0.2679038345813751, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 17:16:26,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:26,654 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:59:04<05:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:34,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011343728750944138, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.478, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008608336560428143, 'eval_loss_2': 0.0027353912591934204, 'eval_loss_3': -18.162511825561523, 'eval_loss_4': -0.18381154537200928, 'epoch': 28.05}
{'loss': 0.0166, 'grad_norm': 5.723888874053955, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.009570922702550888, 'loss_2': 0.0070343017578125, 'loss_3': -16.577964782714844, 'loss_4': -0.35524189472198486, 'epoch': 28.06}
{'loss': 0.002, 'grad_norm': 4.365279197692871, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.0016534028109163046, 'loss_2': 0.0003209114074707031, 'loss_3': -16.605117797851562, 'loss_4': -0.1406041532754898, 'epoch': 28.06}
{'loss': 0.0048, 'grad_norm': 4.930476188659668, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.0024130644742399454, 'loss_2': 0.002353668212890625, 'loss_3': -16.562231063842773, 'loss_4': 0.062373027205467224, 'epoch': 28.07}
{'loss': 0.008, 'grad_norm': 6.598496437072754, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.005947385914623737, 'loss_2': 0.002086639404296875, 'loss_3': -16.420896530151367, 'loss_4': 0.1466139853000641, 'epoch': 28.08}
{'loss': 0.0032, 'grad_norm': 5.071186065673828, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.0007922391523607075, 'loss_2': 0.0024261474609375, 'loss_3': -16.591876983642578, 'loss_4': -0.21733954548835754, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 17:16:34,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:34,011 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:59:12<05:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:41,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011039108037948608, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.21, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008578762412071228, 'eval_loss_2': 0.0024603456258773804, 'eval_loss_3': -18.164453506469727, 'eval_loss_4': -0.18516108393669128, 'epoch': 28.08}
{'loss': 0.0054, 'grad_norm': 4.780946731567383, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.002343441592529416, 'loss_2': 0.0030422210693359375, 'loss_3': -16.639060974121094, 'loss_4': -0.26425284147262573, 'epoch': 28.09}
{'loss': 0.0052, 'grad_norm': 4.084290027618408, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.004289429634809494, 'loss_2': 0.0008907318115234375, 'loss_3': -16.70220184326172, 'loss_4': -0.09218753129243851, 'epoch': 28.09}
{'loss': 0.0037, 'grad_norm': 4.845359802246094, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.001950783422216773, 'loss_2': 0.0017566680908203125, 'loss_3': -16.60098648071289, 'loss_4': -0.34186214208602905, 'epoch': 28.1}
{'loss': 0.0102, 'grad_norm': 4.556190013885498, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.0019961404614150524, 'loss_2': 0.00823974609375, 'loss_3': -16.7446346282959, 'loss_4': -0.5885922312736511, 'epoch': 28.1}
{'loss': 0.0045, 'grad_norm': 4.785709857940674, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.004098590463399887, 'loss_2': 0.00037026405334472656, 'loss_3': -16.45475959777832, 'loss_4': -0.2650323510169983, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 17:16:41,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:41,375 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:19<05:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:48,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010728400200605392, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00849230121821165, 'eval_loss_2': 0.002236098051071167, 'eval_loss_3': -18.168304443359375, 'eval_loss_4': -0.20558854937553406, 'epoch': 28.11}
{'loss': 0.0072, 'grad_norm': 4.273069381713867, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.0029662486631423235, 'loss_2': 0.00421142578125, 'loss_3': -16.531301498413086, 'loss_4': -0.26748964190483093, 'epoch': 28.12}
{'loss': 0.0062, 'grad_norm': 4.480489253997803, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.0020589325577020645, 'loss_2': 0.00409698486328125, 'loss_3': -16.764623641967773, 'loss_4': -0.33921104669570923, 'epoch': 28.12}
{'loss': 0.0029, 'grad_norm': 4.273032188415527, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.002146300161257386, 'loss_2': 0.0007734298706054688, 'loss_3': -16.71280860900879, 'loss_4': -0.02264101803302765, 'epoch': 28.13}
{'loss': 0.022, 'grad_norm': 9.774076461791992, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.017933212220668793, 'loss_2': 0.004024505615234375, 'loss_3': -16.63890266418457, 'loss_4': -0.686068594455719, 'epoch': 28.13}
{'loss': 0.0026, 'grad_norm': 5.113715648651123, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.0022639832459390163, 'loss_2': 0.0003266334533691406, 'loss_3': -16.69025230407715, 'loss_4': -0.3455260097980499, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 17:16:48,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:48,722 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:26<05:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:56,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010350842028856277, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008316371589899063, 'eval_loss_2': 0.0020344704389572144, 'eval_loss_3': -18.172569274902344, 'eval_loss_4': -0.21919068694114685, 'epoch': 28.14}
{'loss': 0.0113, 'grad_norm': 4.249491214752197, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.004188002552837133, 'loss_2': 0.0070648193359375, 'loss_3': -16.563716888427734, 'loss_4': 0.14354637265205383, 'epoch': 28.15}
{'loss': 0.0088, 'grad_norm': 4.988559246063232, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.007538655307143927, 'loss_2': 0.0012569427490234375, 'loss_3': -16.445674896240234, 'loss_4': -0.15689592063426971, 'epoch': 28.15}
{'loss': 0.0055, 'grad_norm': 4.800890922546387, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.004997156094759703, 'loss_2': 0.0004987716674804688, 'loss_3': -16.44011116027832, 'loss_4': -0.02161252498626709, 'epoch': 28.16}
{'loss': 0.0781, 'grad_norm': 20.833288192749023, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.07760246098041534, 'loss_2': 0.00048828125, 'loss_3': -16.5826416015625, 'loss_4': -0.2062816321849823, 'epoch': 28.16}
{'loss': 0.0077, 'grad_norm': 5.641266345977783, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.005268704611808062, 'loss_2': 0.0023860931396484375, 'loss_3': -16.529258728027344, 'loss_4': -0.1924997866153717, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 17:16:56,071 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:56,071 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:34<05:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:03,421 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009607909247279167, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.317, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00754604022949934, 'eval_loss_2': 0.0020618699491024017, 'eval_loss_3': -18.175716400146484, 'eval_loss_4': -0.23355524241924286, 'epoch': 28.17}
{'loss': 0.0041, 'grad_norm': 4.758686542510986, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.0039102439768612385, 'loss_2': 0.0001964569091796875, 'loss_3': -16.39881134033203, 'loss_4': -0.4035835862159729, 'epoch': 28.17}
{'loss': 0.0044, 'grad_norm': 4.52728796005249, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.0032958541996777058, 'loss_2': 0.0011119842529296875, 'loss_3': -16.525890350341797, 'loss_4': 0.07942941784858704, 'epoch': 28.18}
{'loss': 0.011, 'grad_norm': 6.218188285827637, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.008033028803765774, 'loss_2': 0.00296783447265625, 'loss_3': -16.462949752807617, 'loss_4': -0.3568311035633087, 'epoch': 28.19}
{'loss': 0.0079, 'grad_norm': 4.520565032958984, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.002981912810355425, 'loss_2': 0.00489044189453125, 'loss_3': -16.473825454711914, 'loss_4': -0.2008107602596283, 'epoch': 28.19}
{'loss': 0.0023, 'grad_norm': 4.958128452301025, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.0016064730007201433, 'loss_2': 0.0006499290466308594, 'loss_3': -16.504751205444336, 'loss_4': 0.2635883390903473, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 17:17:03,421 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:03,421 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:41<05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:10,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009381581097841263, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.682, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.007502764463424683, 'eval_loss_2': 0.0018788166344165802, 'eval_loss_3': -18.18401336669922, 'eval_loss_4': -0.2322099208831787, 'epoch': 28.2}
{'loss': 0.007, 'grad_norm': 4.971938610076904, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.00617194315418601, 'loss_2': 0.0008497238159179688, 'loss_3': -16.570316314697266, 'loss_4': -0.2620810270309448, 'epoch': 28.2}
{'loss': 0.0068, 'grad_norm': 5.671112060546875, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.003383968025445938, 'loss_2': 0.00341033935546875, 'loss_3': -16.405078887939453, 'loss_4': 0.06915630400180817, 'epoch': 28.21}
{'loss': 0.0124, 'grad_norm': 7.773449897766113, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.010235864669084549, 'loss_2': 0.002178192138671875, 'loss_3': -16.655874252319336, 'loss_4': 0.15218126773834229, 'epoch': 28.22}
{'loss': 0.0098, 'grad_norm': 5.250616073608398, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.0035576976370066404, 'loss_2': 0.006198883056640625, 'loss_3': -16.53380584716797, 'loss_4': -0.06457959115505219, 'epoch': 28.22}
{'loss': 0.0067, 'grad_norm': 5.807291507720947, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.00520725641399622, 'loss_2': 0.0014972686767578125, 'loss_3': -16.509891510009766, 'loss_4': -0.4024254381656647, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 17:17:10,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:10,769 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:48<05:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:18,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008954405784606934, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.122, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007227777503430843, 'eval_loss_2': 0.0017266273498535156, 'eval_loss_3': -18.18667221069336, 'eval_loss_4': -0.232969269156456, 'epoch': 28.23}
{'loss': 0.0063, 'grad_norm': 4.517653465270996, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.0023584694135934114, 'loss_2': 0.003978729248046875, 'loss_3': -16.739274978637695, 'loss_4': -0.004587128758430481, 'epoch': 28.23}
{'loss': 0.0081, 'grad_norm': 8.602400779724121, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.007689558435231447, 'loss_2': 0.0004029273986816406, 'loss_3': -16.56485366821289, 'loss_4': -0.4940396249294281, 'epoch': 28.24}
{'loss': 0.0077, 'grad_norm': 5.201676368713379, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.006807234138250351, 'loss_2': 0.0008449554443359375, 'loss_3': -16.665637969970703, 'loss_4': -0.9335835576057434, 'epoch': 28.24}
{'loss': 0.0055, 'grad_norm': 4.5639967918396, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.002666750457137823, 'loss_2': 0.0028820037841796875, 'loss_3': -16.715391159057617, 'loss_4': -0.16354413330554962, 'epoch': 28.25}
{'loss': 0.0122, 'grad_norm': 6.350466728210449, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.010980281047523022, 'loss_2': 0.0012454986572265625, 'loss_3': -16.47909927368164, 'loss_4': -0.16811132431030273, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 17:17:18,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:18,133 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:56<05:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:25,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008955152705311775, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.272, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007219241466373205, 'eval_loss_2': 0.0017359107732772827, 'eval_loss_3': -18.187744140625, 'eval_loss_4': -0.2378392368555069, 'epoch': 28.26}
{'loss': 0.083, 'grad_norm': 14.508865356445312, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.08111441135406494, 'loss_2': 0.001880645751953125, 'loss_3': -16.491607666015625, 'loss_4': 0.43025025725364685, 'epoch': 28.26}
{'loss': 0.0068, 'grad_norm': 4.55638313293457, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.002491322346031666, 'loss_2': 0.004329681396484375, 'loss_3': -16.623443603515625, 'loss_4': -0.11911609768867493, 'epoch': 28.27}
{'loss': 0.0143, 'grad_norm': 4.488788604736328, 'learning_rate': 1.75e-06, 'loss_1': 0.006618494167923927, 'loss_2': 0.00768280029296875, 'loss_3': -16.39752197265625, 'loss_4': -0.24325557053089142, 'epoch': 28.27}
{'loss': 0.0066, 'grad_norm': 4.574561595916748, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.0046201348304748535, 'loss_2': 0.002010345458984375, 'loss_3': -16.443004608154297, 'loss_4': -0.15563087165355682, 'epoch': 28.28}
{'loss': 0.0071, 'grad_norm': 4.828183174133301, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.002548876218497753, 'loss_2': 0.0045013427734375, 'loss_3': -16.445947647094727, 'loss_4': -0.09566851705312729, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 17:17:25,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:25,487 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [2:00:03<05:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:32,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008814580738544464, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.631, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.006969603709876537, 'eval_loss_2': 0.0018449760973453522, 'eval_loss_3': -18.18326187133789, 'eval_loss_4': -0.2508852481842041, 'epoch': 28.28}
{'loss': 0.0149, 'grad_norm': 8.108339309692383, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.011985321529209614, 'loss_2': 0.002933502197265625, 'loss_3': -16.58639144897461, 'loss_4': -0.28998175263404846, 'epoch': 28.29}
{'loss': 0.0072, 'grad_norm': 4.590707302093506, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.0064028175547719, 'loss_2': 0.0008063316345214844, 'loss_3': -16.556171417236328, 'loss_4': -0.2783551514148712, 'epoch': 28.3}
{'loss': 0.0065, 'grad_norm': 4.97739315032959, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.005430732853710651, 'loss_2': 0.001079559326171875, 'loss_3': -16.520824432373047, 'loss_4': -0.02529609203338623, 'epoch': 28.3}
{'loss': 0.0035, 'grad_norm': 4.866620063781738, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.002634800272062421, 'loss_2': 0.0008792877197265625, 'loss_3': -16.418622970581055, 'loss_4': -0.6717898845672607, 'epoch': 28.31}
{'loss': 0.0073, 'grad_norm': 4.299051761627197, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.002060870872810483, 'loss_2': 0.005260467529296875, 'loss_3': -16.54640007019043, 'loss_4': 0.002361983060836792, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 17:17:32,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:32,837 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [2:00:11<04:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:40,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008776298724114895, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006903446279466152, 'eval_loss_2': 0.0018728524446487427, 'eval_loss_3': -18.183879852294922, 'eval_loss_4': -0.2507185935974121, 'epoch': 28.31}
{'loss': 0.0034, 'grad_norm': 4.5650553703308105, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.001632622559554875, 'loss_2': 0.0017309188842773438, 'loss_3': -16.726465225219727, 'loss_4': -0.5327979326248169, 'epoch': 28.32}
{'loss': 0.077, 'grad_norm': 13.138741493225098, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.07083483785390854, 'loss_2': 0.00620269775390625, 'loss_3': -16.46044158935547, 'loss_4': 0.20633281767368317, 'epoch': 28.33}
{'loss': 0.0071, 'grad_norm': 5.556307792663574, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.006064540706574917, 'loss_2': 0.001018524169921875, 'loss_3': -16.482765197753906, 'loss_4': -0.4646950364112854, 'epoch': 28.33}
{'loss': 0.005, 'grad_norm': 4.604119300842285, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.0030287320259958506, 'loss_2': 0.0019378662109375, 'loss_3': -16.392955780029297, 'loss_4': -0.18444430828094482, 'epoch': 28.34}
{'loss': 0.0087, 'grad_norm': 6.199273586273193, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.004520106595009565, 'loss_2': 0.004150390625, 'loss_3': -16.57855224609375, 'loss_4': 0.004518620669841766, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 17:17:40,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:40,188 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [2:00:18<04:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:47,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008905365131795406, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006970374379307032, 'eval_loss_2': 0.0019349902868270874, 'eval_loss_3': -18.186378479003906, 'eval_loss_4': -0.2577269673347473, 'epoch': 28.34}
{'loss': 0.0067, 'grad_norm': 4.760084629058838, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.0017233443213626742, 'loss_2': 0.005016326904296875, 'loss_3': -16.511859893798828, 'loss_4': 0.06990700960159302, 'epoch': 28.35}
{'loss': 0.016, 'grad_norm': 4.758996963500977, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.003672370919957757, 'loss_2': 0.012298583984375, 'loss_3': -16.600982666015625, 'loss_4': -0.07616225630044937, 'epoch': 28.35}
{'loss': 0.0067, 'grad_norm': 4.638187885284424, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.003703504800796509, 'loss_2': 0.00302886962890625, 'loss_3': -16.354827880859375, 'loss_4': -0.09031026065349579, 'epoch': 28.36}
{'loss': 0.0044, 'grad_norm': 4.898006916046143, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.003910886123776436, 'loss_2': 0.0004944801330566406, 'loss_3': -16.561500549316406, 'loss_4': -0.3425024151802063, 'epoch': 28.37}
{'loss': 0.0107, 'grad_norm': 6.933051109313965, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.008578506298363209, 'loss_2': 0.002109527587890625, 'loss_3': -16.589218139648438, 'loss_4': -0.28321021795272827, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 17:17:47,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:47,539 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:25<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:54,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009128478355705738, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.463, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007149187847971916, 'eval_loss_2': 0.0019792914390563965, 'eval_loss_3': -18.19350814819336, 'eval_loss_4': -0.2657581865787506, 'epoch': 28.37}
{'loss': 0.0049, 'grad_norm': 4.8260393142700195, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.0037398890126496553, 'loss_2': 0.0011224746704101562, 'loss_3': -16.463191986083984, 'loss_4': -0.0446089506149292, 'epoch': 28.38}
{'loss': 0.0056, 'grad_norm': 4.661088466644287, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.001959058456122875, 'loss_2': 0.003643035888671875, 'loss_3': -16.635009765625, 'loss_4': -0.2743891775608063, 'epoch': 28.38}
{'loss': 0.0227, 'grad_norm': 9.11872386932373, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.017897361889481544, 'loss_2': 0.004852294921875, 'loss_3': -16.48138427734375, 'loss_4': -0.5153095722198486, 'epoch': 28.39}
{'loss': 0.0092, 'grad_norm': 4.565032958984375, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.00256575015373528, 'loss_2': 0.00665283203125, 'loss_3': -16.481964111328125, 'loss_4': -0.15314394235610962, 'epoch': 28.4}
{'loss': 0.0026, 'grad_norm': 4.472784996032715, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.0016530074644833803, 'loss_2': 0.0009741783142089844, 'loss_3': -16.685428619384766, 'loss_4': -0.16793793439865112, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 17:17:54,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:54,894 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:33<04:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:02,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008717690594494343, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.967, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006707214750349522, 'eval_loss_2': 0.002010475844144821, 'eval_loss_3': -18.20209503173828, 'eval_loss_4': -0.26901504397392273, 'epoch': 28.4}
{'loss': 0.0058, 'grad_norm': 5.109285831451416, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.004888611845672131, 'loss_2': 0.000934600830078125, 'loss_3': -16.572925567626953, 'loss_4': -0.4369477331638336, 'epoch': 28.41}
{'loss': 0.0103, 'grad_norm': 7.677117347717285, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.005750278010964394, 'loss_2': 0.00452423095703125, 'loss_3': -16.605609893798828, 'loss_4': -0.45771193504333496, 'epoch': 28.41}
{'loss': 0.0188, 'grad_norm': 5.2079548835754395, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.012003244832158089, 'loss_2': 0.00682830810546875, 'loss_3': -16.56905746459961, 'loss_4': -0.3157893717288971, 'epoch': 28.42}
{'loss': 0.0091, 'grad_norm': 5.251166343688965, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.004110078793019056, 'loss_2': 0.00499725341796875, 'loss_3': -16.55767250061035, 'loss_4': 0.09213948994874954, 'epoch': 28.42}
{'loss': 0.0122, 'grad_norm': 5.384200096130371, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.004714715760201216, 'loss_2': 0.00748443603515625, 'loss_3': -16.59475326538086, 'loss_4': -0.2575201392173767, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 17:18:02,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:02,261 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:40<04:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:09,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008759325370192528, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.421, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.006662887055426836, 'eval_loss_2': 0.00209643691778183, 'eval_loss_3': -18.20766258239746, 'eval_loss_4': -0.26747745275497437, 'epoch': 28.43}
{'loss': 0.0055, 'grad_norm': 5.039556503295898, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.004172741901129484, 'loss_2': 0.001323699951171875, 'loss_3': -16.645565032958984, 'loss_4': -0.11803093552589417, 'epoch': 28.44}
{'loss': 0.007, 'grad_norm': 4.899625301361084, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.0011907239677384496, 'loss_2': 0.0057830810546875, 'loss_3': -16.481508255004883, 'loss_4': -0.24362309277057648, 'epoch': 28.44}
{'loss': 0.0055, 'grad_norm': 4.821121692657471, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.0047068833373487, 'loss_2': 0.0008215904235839844, 'loss_3': -16.512794494628906, 'loss_4': 0.24936307966709137, 'epoch': 28.45}
{'loss': 0.0068, 'grad_norm': 4.47650671005249, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.0015359101817011833, 'loss_2': 0.0052337646484375, 'loss_3': -16.582571029663086, 'loss_4': -0.015107940882444382, 'epoch': 28.45}
{'loss': 0.0086, 'grad_norm': 5.077739715576172, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.004243975970894098, 'loss_2': 0.00435638427734375, 'loss_3': -16.387428283691406, 'loss_4': -0.09714681655168533, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 17:18:09,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:09,613 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:47<04:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:16,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008556959219276905, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0063903299160301685, 'eval_loss_2': 0.0021666288375854492, 'eval_loss_3': -18.209552764892578, 'eval_loss_4': -0.2741156220436096, 'epoch': 28.46}
{'loss': 0.0104, 'grad_norm': 4.97568416595459, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.004268496762961149, 'loss_2': 0.006175994873046875, 'loss_3': -16.584409713745117, 'loss_4': -0.2347324788570404, 'epoch': 28.47}
{'loss': 0.0165, 'grad_norm': 7.4041314125061035, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.009965510107576847, 'loss_2': 0.0065460205078125, 'loss_3': -16.340229034423828, 'loss_4': -0.07497432827949524, 'epoch': 28.47}
{'loss': 0.0153, 'grad_norm': 8.706069946289062, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.009803296998143196, 'loss_2': 0.00547027587890625, 'loss_3': -16.467018127441406, 'loss_4': -0.05555898696184158, 'epoch': 28.48}
{'loss': 0.0081, 'grad_norm': 5.836520671844482, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.007537848316133022, 'loss_2': 0.0005578994750976562, 'loss_3': -16.43877410888672, 'loss_4': -0.2719533443450928, 'epoch': 28.48}
{'loss': 0.0083, 'grad_norm': 5.9450602531433105, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.006942690350115299, 'loss_2': 0.0013446807861328125, 'loss_3': -16.518333435058594, 'loss_4': -0.28369230031967163, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 17:18:16,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:16,960 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:55<04:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:24,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008643273264169693, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.527, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.006384733598679304, 'eval_loss_2': 0.0022585391998291016, 'eval_loss_3': -18.209585189819336, 'eval_loss_4': -0.26793426275253296, 'epoch': 28.49}
{'loss': 0.0201, 'grad_norm': 14.403885841369629, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.019272591918706894, 'loss_2': 0.0008225440979003906, 'loss_3': -16.61547088623047, 'loss_4': 0.4483107924461365, 'epoch': 28.49}
{'loss': 0.0066, 'grad_norm': 7.03169059753418, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.00447541568428278, 'loss_2': 0.0021305084228515625, 'loss_3': -16.54587173461914, 'loss_4': -0.31934696435928345, 'epoch': 28.5}
{'loss': 0.0079, 'grad_norm': 5.66716194152832, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.004184022080153227, 'loss_2': 0.003757476806640625, 'loss_3': -16.503944396972656, 'loss_4': -0.2870965600013733, 'epoch': 28.51}
{'loss': 0.0068, 'grad_norm': 4.762554168701172, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0034245538990944624, 'loss_2': 0.0034008026123046875, 'loss_3': -16.483970642089844, 'loss_4': -0.3077506124973297, 'epoch': 28.51}
{'loss': 0.0101, 'grad_norm': 4.191402912139893, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.0038447706028819084, 'loss_2': 0.0062103271484375, 'loss_3': -16.616865158081055, 'loss_4': -0.31757694482803345, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 17:18:24,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:24,310 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:01:02<04:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:31,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009100457653403282, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.006690299138426781, 'eval_loss_2': 0.0024101585149765015, 'eval_loss_3': -18.207046508789062, 'eval_loss_4': -0.2450113296508789, 'epoch': 28.52}
{'loss': 0.0059, 'grad_norm': 4.286401748657227, 'learning_rate': 1.5e-06, 'loss_1': 0.0025895743165165186, 'loss_2': 0.0033588409423828125, 'loss_3': -16.489341735839844, 'loss_4': -0.14840005338191986, 'epoch': 28.52}
{'loss': 0.0075, 'grad_norm': 4.327981472015381, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.0040644812397658825, 'loss_2': 0.0034465789794921875, 'loss_3': -16.73784828186035, 'loss_4': -0.38861551880836487, 'epoch': 28.53}
{'loss': 0.0069, 'grad_norm': 4.659650802612305, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.004120915196835995, 'loss_2': 0.0027294158935546875, 'loss_3': -16.436710357666016, 'loss_4': -0.06349886208772659, 'epoch': 28.53}
{'loss': 0.0026, 'grad_norm': 4.176272869110107, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.0023527326993644238, 'loss_2': 0.00028061866760253906, 'loss_3': -16.64258575439453, 'loss_4': -0.08619429171085358, 'epoch': 28.54}
{'loss': 0.0078, 'grad_norm': 4.585781097412109, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.003024605568498373, 'loss_2': 0.004726409912109375, 'loss_3': -16.654010772705078, 'loss_4': -0.16985155642032623, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 17:18:31,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:31,663 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:01:09<04:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:39,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009755406528711319, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.483, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007070842664688826, 'eval_loss_2': 0.002684563398361206, 'eval_loss_3': -18.204557418823242, 'eval_loss_4': -0.23889799416065216, 'epoch': 28.55}
{'loss': 0.0077, 'grad_norm': 5.548628807067871, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.004516272339969873, 'loss_2': 0.003162384033203125, 'loss_3': -16.4808349609375, 'loss_4': -0.22775030136108398, 'epoch': 28.55}
{'loss': 0.0017, 'grad_norm': 4.6757988929748535, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.0014747106470167637, 'loss_2': 0.0002143383026123047, 'loss_3': -16.665109634399414, 'loss_4': -0.23934942483901978, 'epoch': 28.56}
{'loss': 0.0081, 'grad_norm': 5.312624454498291, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.004738752730190754, 'loss_2': 0.003368377685546875, 'loss_3': -16.444408416748047, 'loss_4': -0.2934965193271637, 'epoch': 28.56}
{'loss': 0.0039, 'grad_norm': 5.201675891876221, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.0026977171655744314, 'loss_2': 0.0012369155883789062, 'loss_3': -16.426780700683594, 'loss_4': 0.12457302212715149, 'epoch': 28.57}
{'loss': 0.0056, 'grad_norm': 4.783947467803955, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.0054970914497971535, 'loss_2': 0.00014603137969970703, 'loss_3': -16.378173828125, 'loss_4': 0.36085301637649536, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 17:18:39,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:39,017 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:01:17<04:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:46,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010161066427826881, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.776, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007289139088243246, 'eval_loss_2': 0.002871926873922348, 'eval_loss_3': -18.201648712158203, 'eval_loss_4': -0.24434223771095276, 'epoch': 28.58}
{'loss': 0.0044, 'grad_norm': 5.313244819641113, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.002898269332945347, 'loss_2': 0.0015172958374023438, 'loss_3': -16.49537467956543, 'loss_4': -0.23566989600658417, 'epoch': 28.58}
{'loss': 0.0033, 'grad_norm': 4.410989284515381, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.002217244589701295, 'loss_2': 0.0010890960693359375, 'loss_3': -16.509334564208984, 'loss_4': -0.4524950683116913, 'epoch': 28.59}
{'loss': 0.0116, 'grad_norm': 4.957079887390137, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.0033145416527986526, 'loss_2': 0.00823974609375, 'loss_3': -16.612346649169922, 'loss_4': -0.1555975377559662, 'epoch': 28.59}
{'loss': 0.0094, 'grad_norm': 4.688480854034424, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.0042935325764119625, 'loss_2': 0.0050811767578125, 'loss_3': -16.651165008544922, 'loss_4': 0.09183412790298462, 'epoch': 28.6}
{'loss': 0.0087, 'grad_norm': 4.828403949737549, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.004794621374458075, 'loss_2': 0.003936767578125, 'loss_3': -16.679168701171875, 'loss_4': 0.1280425488948822, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 17:18:46,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:46,362 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:24<04:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:53,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010561120696365833, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.64, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007603940553963184, 'eval_loss_2': 0.002957180142402649, 'eval_loss_3': -18.200613021850586, 'eval_loss_4': -0.24669672548770905, 'epoch': 28.6}
{'loss': 0.0017, 'grad_norm': 4.182358741760254, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.00149565062019974, 'loss_2': 0.0001704692840576172, 'loss_3': -16.671375274658203, 'loss_4': -0.13512998819351196, 'epoch': 28.61}
{'loss': 0.0189, 'grad_norm': 6.354925155639648, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.013981926254928112, 'loss_2': 0.0048980712890625, 'loss_3': -16.67230987548828, 'loss_4': -0.6124482750892639, 'epoch': 28.62}
{'loss': 0.0129, 'grad_norm': 9.408635139465332, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.010866745375096798, 'loss_2': 0.0020732879638671875, 'loss_3': -16.700408935546875, 'loss_4': -0.16904979944229126, 'epoch': 28.62}
{'loss': 0.01, 'grad_norm': 5.873653888702393, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.006156859453767538, 'loss_2': 0.003856658935546875, 'loss_3': -16.467294692993164, 'loss_4': -0.458904892206192, 'epoch': 28.63}
{'loss': 0.0046, 'grad_norm': 4.984500885009766, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.0024423401337116957, 'loss_2': 0.002162933349609375, 'loss_3': -16.54358673095703, 'loss_4': -0.3401866555213928, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 17:18:53,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:53,717 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:32<04:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:19:01,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01064873207360506, 'eval_runtime': 3.9957, 'eval_samples_per_second': 256.274, 'eval_steps_per_second': 4.004, 'eval_loss_1': 0.007841323502361774, 'eval_loss_2': 0.002807408571243286, 'eval_loss_3': -18.19742202758789, 'eval_loss_4': -0.25529566407203674, 'epoch': 28.63}
{'loss': 0.0079, 'grad_norm': 4.625268936157227, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.003923214040696621, 'loss_2': 0.003971099853515625, 'loss_3': -16.43816566467285, 'loss_4': -0.2133333683013916, 'epoch': 28.64}
{'loss': 0.0159, 'grad_norm': 8.79917049407959, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.014457526616752148, 'loss_2': 0.0014820098876953125, 'loss_3': -16.68088150024414, 'loss_4': -0.025585660710930824, 'epoch': 28.65}
{'loss': 0.0059, 'grad_norm': 4.555205821990967, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.0030852321069687605, 'loss_2': 0.0028553009033203125, 'loss_3': -16.68667984008789, 'loss_4': -0.13886067271232605, 'epoch': 28.65}
{'loss': 0.0065, 'grad_norm': 5.839158535003662, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.005900874733924866, 'loss_2': 0.0006198883056640625, 'loss_3': -16.41986846923828, 'loss_4': 0.09248563647270203, 'epoch': 28.66}
{'loss': 0.0042, 'grad_norm': 4.48181676864624, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.0030385302379727364, 'loss_2': 0.0011768341064453125, 'loss_3': -16.48575210571289, 'loss_4': -0.2971893548965454, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 17:19:01,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:01,268 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:39<03:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:08,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010574017651379108, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.378, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00796221662312746, 'eval_loss_2': 0.002611801028251648, 'eval_loss_3': -18.197341918945312, 'eval_loss_4': -0.26093563437461853, 'epoch': 28.66}
{'loss': 0.0093, 'grad_norm': 5.505452632904053, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.0037248514126986265, 'loss_2': 0.005584716796875, 'loss_3': -16.593852996826172, 'loss_4': -0.20067906379699707, 'epoch': 28.67}
{'loss': 0.003, 'grad_norm': 4.558877944946289, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.0023024999536573887, 'loss_2': 0.0006704330444335938, 'loss_3': -16.460376739501953, 'loss_4': -0.4692344069480896, 'epoch': 28.67}
{'loss': 0.0093, 'grad_norm': 5.525315761566162, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.0069245207123458385, 'loss_2': 0.002399444580078125, 'loss_3': -16.555871963500977, 'loss_4': -0.38575488328933716, 'epoch': 28.68}
{'loss': 0.0065, 'grad_norm': 4.505778789520264, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.001686283154413104, 'loss_2': 0.0047760009765625, 'loss_3': -16.607852935791016, 'loss_4': -0.5981931686401367, 'epoch': 28.69}
{'loss': 0.0056, 'grad_norm': 4.761743068695068, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.0034550288692116737, 'loss_2': 0.002147674560546875, 'loss_3': -16.50218391418457, 'loss_4': -0.122266486287117, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 17:19:08,627 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:08,627 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:46<03:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:15,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0108331348747015, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008312547579407692, 'eval_loss_2': 0.002520587295293808, 'eval_loss_3': -18.19271469116211, 'eval_loss_4': -0.2683561444282532, 'epoch': 28.69}
{'loss': 0.0135, 'grad_norm': 4.330087184906006, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.004573104903101921, 'loss_2': 0.008941650390625, 'loss_3': -16.447452545166016, 'loss_4': -0.18840597569942474, 'epoch': 28.7}
{'loss': 0.0058, 'grad_norm': 5.057220458984375, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.0022117062471807003, 'loss_2': 0.0035858154296875, 'loss_3': -16.54336929321289, 'loss_4': -0.2760941982269287, 'epoch': 28.7}
{'loss': 0.0108, 'grad_norm': 7.06935977935791, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.008985303342342377, 'loss_2': 0.0018415451049804688, 'loss_3': -16.43002700805664, 'loss_4': -0.756230354309082, 'epoch': 28.71}
{'loss': 0.0057, 'grad_norm': 4.7907562255859375, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.0025694880168884993, 'loss_2': 0.003147125244140625, 'loss_3': -16.65047836303711, 'loss_4': -0.5317362546920776, 'epoch': 28.72}
{'loss': 0.0045, 'grad_norm': 4.674693584442139, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.002184109063819051, 'loss_2': 0.00228118896484375, 'loss_3': -16.694053649902344, 'loss_4': -0.5114636421203613, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 17:19:15,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:15,987 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:54<03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:23,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010906117036938667, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008435332216322422, 'eval_loss_2': 0.0024707838892936707, 'eval_loss_3': -18.18720817565918, 'eval_loss_4': -0.2763652801513672, 'epoch': 28.72}
{'loss': 0.018, 'grad_norm': 11.4005708694458, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.013342429883778095, 'loss_2': 0.0046844482421875, 'loss_3': -16.665630340576172, 'loss_4': -0.503189742565155, 'epoch': 28.73}
{'loss': 0.0025, 'grad_norm': 4.907331466674805, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.001558154122903943, 'loss_2': 0.0009603500366210938, 'loss_3': -16.488964080810547, 'loss_4': 0.18129101395606995, 'epoch': 28.73}
{'loss': 0.0058, 'grad_norm': 4.396552085876465, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.002566009061411023, 'loss_2': 0.003231048583984375, 'loss_3': -16.56222915649414, 'loss_4': -0.650855302810669, 'epoch': 28.74}
{'loss': 0.0026, 'grad_norm': 4.4589715003967285, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.001748202252201736, 'loss_2': 0.0008144378662109375, 'loss_3': -16.52857208251953, 'loss_4': -0.2473447024822235, 'epoch': 28.74}
{'loss': 0.0053, 'grad_norm': 4.429711818695068, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.002079390687867999, 'loss_2': 0.003269195556640625, 'loss_3': -16.51898765563965, 'loss_4': -0.20267602801322937, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 17:19:23,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:23,340 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:02:01<03:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:30,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010662984102964401, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.85, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008226667530834675, 'eval_loss_2': 0.002436317503452301, 'eval_loss_3': -18.182186126708984, 'eval_loss_4': -0.2813835144042969, 'epoch': 28.75}
{'loss': 0.0133, 'grad_norm': 5.198818683624268, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.005726325325667858, 'loss_2': 0.007602691650390625, 'loss_3': -16.5253963470459, 'loss_4': -0.3767889440059662, 'epoch': 28.76}
{'loss': 0.0069, 'grad_norm': 4.713902473449707, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.0034679376985877752, 'loss_2': 0.003475189208984375, 'loss_3': -16.670658111572266, 'loss_4': -0.22993293404579163, 'epoch': 28.76}
{'loss': 0.0136, 'grad_norm': 5.103919982910156, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.005942689720541239, 'loss_2': 0.0076446533203125, 'loss_3': -16.561344146728516, 'loss_4': -0.34157314896583557, 'epoch': 28.77}
{'loss': 0.0056, 'grad_norm': 4.4987406730651855, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.003116046544164419, 'loss_2': 0.002471923828125, 'loss_3': -16.650726318359375, 'loss_4': -0.11190817505121231, 'epoch': 28.77}
{'loss': 0.0055, 'grad_norm': 4.265421390533447, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.0034830961376428604, 'loss_2': 0.001972198486328125, 'loss_3': -16.554819107055664, 'loss_4': -0.22762256860733032, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 17:19:30,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:30,688 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:02:08<03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:38,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010825986042618752, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.576, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008412743918597698, 'eval_loss_2': 0.002413243055343628, 'eval_loss_3': -18.18250846862793, 'eval_loss_4': -0.28308725357055664, 'epoch': 28.78}
{'loss': 0.0095, 'grad_norm': 5.746889114379883, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.0071192351169884205, 'loss_2': 0.002349853515625, 'loss_3': -16.788270950317383, 'loss_4': -0.5035751461982727, 'epoch': 28.78}
{'loss': 0.0138, 'grad_norm': 4.894467353820801, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.0036838483065366745, 'loss_2': 0.01007080078125, 'loss_3': -16.62985610961914, 'loss_4': -0.22972336411476135, 'epoch': 28.79}
{'loss': 0.0042, 'grad_norm': 4.5717267990112305, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.002925039501860738, 'loss_2': 0.00128173828125, 'loss_3': -16.62084197998047, 'loss_4': -0.24182510375976562, 'epoch': 28.8}
{'loss': 0.0087, 'grad_norm': 4.991170883178711, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.003898233873769641, 'loss_2': 0.004817962646484375, 'loss_3': -16.589183807373047, 'loss_4': -0.571372389793396, 'epoch': 28.8}
{'loss': 0.0163, 'grad_norm': 8.49973201751709, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.013239051215350628, 'loss_2': 0.00301361083984375, 'loss_3': -16.52621078491211, 'loss_4': -0.05883745104074478, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 17:19:38,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:38,038 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:02:16<03:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:45,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011064713820815086, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.624, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008506251499056816, 'eval_loss_2': 0.0025584623217582703, 'eval_loss_3': -18.182064056396484, 'eval_loss_4': -0.2852459251880646, 'epoch': 28.81}
{'loss': 0.0112, 'grad_norm': 6.022871494293213, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.009349347092211246, 'loss_2': 0.0018901824951171875, 'loss_3': -16.57960319519043, 'loss_4': -0.23886846005916595, 'epoch': 28.81}
{'loss': 0.004, 'grad_norm': 5.9212751388549805, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.0025933883152902126, 'loss_2': 0.0014362335205078125, 'loss_3': -16.63970947265625, 'loss_4': -0.13650882244110107, 'epoch': 28.82}
{'loss': 0.0065, 'grad_norm': 4.723114490509033, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.002707112580537796, 'loss_2': 0.003814697265625, 'loss_3': -16.44656753540039, 'loss_4': -0.12686650454998016, 'epoch': 28.83}
{'loss': 0.0044, 'grad_norm': 5.02345609664917, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.0037185391411185265, 'loss_2': 0.0007009506225585938, 'loss_3': -16.60413360595703, 'loss_4': -0.7588475942611694, 'epoch': 28.83}
{'loss': 0.0055, 'grad_norm': 4.504331111907959, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.002407148014754057, 'loss_2': 0.00310516357421875, 'loss_3': -16.374893188476562, 'loss_4': -0.25405240058898926, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 17:19:45,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:45,396 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:23<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:52,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01127736084163189, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.636, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008576853200793266, 'eval_loss_2': 0.002700507640838623, 'eval_loss_3': -18.183507919311523, 'eval_loss_4': -0.2858242094516754, 'epoch': 28.84}
{'loss': 0.0065, 'grad_norm': 4.878936290740967, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.004713758826255798, 'loss_2': 0.0018339157104492188, 'loss_3': -16.475849151611328, 'loss_4': -0.5703434944152832, 'epoch': 28.84}
{'loss': 0.0054, 'grad_norm': 5.061555862426758, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.004274625796824694, 'loss_2': 0.001117706298828125, 'loss_3': -16.500890731811523, 'loss_4': -0.623525857925415, 'epoch': 28.85}
{'loss': 0.009, 'grad_norm': 4.821139812469482, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.005786004941910505, 'loss_2': 0.00324249267578125, 'loss_3': -16.396190643310547, 'loss_4': -0.6053959727287292, 'epoch': 28.85}
{'loss': 0.0157, 'grad_norm': 6.175816535949707, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.009782304055988789, 'loss_2': 0.00588226318359375, 'loss_3': -16.51628875732422, 'loss_4': -0.7849768400192261, 'epoch': 28.86}
{'loss': 0.0106, 'grad_norm': 4.6666789054870605, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.004317430779337883, 'loss_2': 0.00630950927734375, 'loss_3': -16.331003189086914, 'loss_4': -0.4846586287021637, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 17:19:52,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:52,747 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:30<03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:00,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011099196039140224, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.507, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008408098481595516, 'eval_loss_2': 0.0026910975575447083, 'eval_loss_3': -18.18794059753418, 'eval_loss_4': -0.2951580882072449, 'epoch': 28.87}
{'loss': 0.0083, 'grad_norm': 4.830676555633545, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.002637967001646757, 'loss_2': 0.005645751953125, 'loss_3': -16.53725242614746, 'loss_4': -0.29832369089126587, 'epoch': 28.87}
{'loss': 0.0047, 'grad_norm': 4.543721675872803, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.003178885905072093, 'loss_2': 0.0015516281127929688, 'loss_3': -16.458011627197266, 'loss_4': -0.22996769845485687, 'epoch': 28.88}
{'loss': 0.0051, 'grad_norm': 4.7180023193359375, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.003238055622205138, 'loss_2': 0.0018978118896484375, 'loss_3': -16.661813735961914, 'loss_4': -0.4865322709083557, 'epoch': 28.88}
{'loss': 0.0083, 'grad_norm': 5.140888214111328, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.003154275706037879, 'loss_2': 0.00511932373046875, 'loss_3': -16.409072875976562, 'loss_4': -0.4053446352481842, 'epoch': 28.89}
{'loss': 0.0162, 'grad_norm': 12.757303237915039, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.014592643827199936, 'loss_2': 0.001583099365234375, 'loss_3': -16.572830200195312, 'loss_4': -0.5447276830673218, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 17:20:00,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:00,102 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:38<03:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:07,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011040745303034782, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.589, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008245972916483879, 'eval_loss_2': 0.0027947723865509033, 'eval_loss_3': -18.190282821655273, 'eval_loss_4': -0.29542919993400574, 'epoch': 28.9}
{'loss': 0.003, 'grad_norm': 4.611151218414307, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.0027349882293492556, 'loss_2': 0.0003046989440917969, 'loss_3': -16.533958435058594, 'loss_4': -0.24232082068920135, 'epoch': 28.9}
{'loss': 0.0083, 'grad_norm': 5.521310329437256, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.0031284720171242952, 'loss_2': 0.005157470703125, 'loss_3': -16.42418098449707, 'loss_4': -0.41576769948005676, 'epoch': 28.91}
{'loss': 0.0109, 'grad_norm': 4.8445940017700195, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.0067518530413508415, 'loss_2': 0.0041351318359375, 'loss_3': -16.678504943847656, 'loss_4': -0.2540830671787262, 'epoch': 28.91}
{'loss': 0.0101, 'grad_norm': 4.619908332824707, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.002487790072336793, 'loss_2': 0.007640838623046875, 'loss_3': -16.447729110717773, 'loss_4': -0.2588019371032715, 'epoch': 28.92}
{'loss': 0.0082, 'grad_norm': 4.890834331512451, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.0034255438949912786, 'loss_2': 0.0047760009765625, 'loss_3': -16.616275787353516, 'loss_4': -0.3655807673931122, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 17:20:07,452 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:07,453 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:45<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:14,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01112045906484127, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.533, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.00831898208707571, 'eval_loss_2': 0.0028014779090881348, 'eval_loss_3': -18.192110061645508, 'eval_loss_4': -0.29443949460983276, 'epoch': 28.92}
{'loss': 0.0113, 'grad_norm': 4.478938579559326, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.004428660497069359, 'loss_2': 0.006885528564453125, 'loss_3': -16.442237854003906, 'loss_4': -0.9250574111938477, 'epoch': 28.93}
{'loss': 0.0155, 'grad_norm': 7.799658298492432, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.007847942411899567, 'loss_2': 0.007659912109375, 'loss_3': -16.50849723815918, 'loss_4': -0.5249500274658203, 'epoch': 28.94}
{'loss': 0.0047, 'grad_norm': 4.697391033172607, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.002910095499828458, 'loss_2': 0.001796722412109375, 'loss_3': -16.654037475585938, 'loss_4': -0.6026017665863037, 'epoch': 28.94}
{'loss': 0.0065, 'grad_norm': 4.342639923095703, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.0034935148432850838, 'loss_2': 0.003032684326171875, 'loss_3': -16.435993194580078, 'loss_4': -0.4839779734611511, 'epoch': 28.95}
{'loss': 0.0104, 'grad_norm': 5.143640995025635, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.004319659899920225, 'loss_2': 0.0060577392578125, 'loss_3': -16.470458984375, 'loss_4': -0.6769995093345642, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 17:20:14,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:14,799 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:52<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:22,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011045427992939949, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.93, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008362689055502415, 'eval_loss_2': 0.0026827380061149597, 'eval_loss_3': -18.191789627075195, 'eval_loss_4': -0.2834452986717224, 'epoch': 28.95}
{'loss': 0.0098, 'grad_norm': 5.0585150718688965, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.0034066555090248585, 'loss_2': 0.006435394287109375, 'loss_3': -16.483877182006836, 'loss_4': -0.3597496747970581, 'epoch': 28.96}
{'loss': 0.0055, 'grad_norm': 5.413201332092285, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.00514215836301446, 'loss_2': 0.0004029273986816406, 'loss_3': -16.488359451293945, 'loss_4': -0.6809991598129272, 'epoch': 28.97}
{'loss': 0.0077, 'grad_norm': 4.0838623046875, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.0029608982149511576, 'loss_2': 0.0047454833984375, 'loss_3': -16.470434188842773, 'loss_4': 0.02757270634174347, 'epoch': 28.97}
{'loss': 0.0027, 'grad_norm': 5.023871421813965, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.0024017191026359797, 'loss_2': 0.0003120899200439453, 'loss_3': -16.53261947631836, 'loss_4': -0.6731165647506714, 'epoch': 28.98}
{'loss': 0.0059, 'grad_norm': 4.171922206878662, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.002081609098240733, 'loss_2': 0.003795623779296875, 'loss_3': -16.53107261657715, 'loss_4': -0.24315789341926575, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 17:20:22,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:22,143 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:03:00<02:49,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 17:20:29,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011020717211067677, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008386683650314808, 'eval_loss_2': 0.0026340335607528687, 'eval_loss_3': -18.189594268798828, 'eval_loss_4': -0.27718597650527954, 'epoch': 28.98}
{'loss': 0.0162, 'grad_norm': 6.592474937438965, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.010860403999686241, 'loss_2': 0.0053863525390625, 'loss_3': -16.48898696899414, 'loss_4': -0.23143960535526276, 'epoch': 28.99}
{'loss': 0.0082, 'grad_norm': 4.6730828285217285, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.003006833838298917, 'loss_2': 0.00522613525390625, 'loss_3': -16.47210693359375, 'loss_4': -0.2080194652080536, 'epoch': 28.99}
{'loss': 0.0074, 'grad_norm': 6.345289707183838, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.00407144520431757, 'loss_2': 0.003292083740234375, 'loss_3': -16.80528450012207, 'loss_4': 0.31580811738967896, 'epoch': 29.0}
{'loss': 0.003, 'grad_norm': 4.574113368988037, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.00173541612457484, 'loss_2': 0.001224517822265625, 'loss_3': -16.528491973876953, 'loss_4': -0.24960458278656006, 'epoch': 29.01}
{'loss': 0.0035, 'grad_norm': 4.127493381500244, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.0024274608585983515, 'loss_2': 0.0011043548583984375, 'loss_3': -16.573486328125, 'loss_4': -0.3887034058570862, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 17:20:29,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:29,179 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:03:07<02:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:20:36,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011202503927052021, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.227, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008521348237991333, 'eval_loss_2': 0.0026811547577381134, 'eval_loss_3': -18.188430786132812, 'eval_loss_4': -0.2781396508216858, 'epoch': 29.01}
{'loss': 0.0192, 'grad_norm': 8.434510231018066, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.013105087913572788, 'loss_2': 0.0060882568359375, 'loss_3': -16.53401756286621, 'loss_4': -0.7392409443855286, 'epoch': 29.02}
{'loss': 0.0079, 'grad_norm': 4.854071617126465, 'learning_rate': 1e-06, 'loss_1': 0.003111155005171895, 'loss_2': 0.0048065185546875, 'loss_3': -16.560745239257812, 'loss_4': -0.06487853080034256, 'epoch': 29.02}
{'loss': 0.0046, 'grad_norm': 4.9535088539123535, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.0024321991950273514, 'loss_2': 0.002166748046875, 'loss_3': -16.557880401611328, 'loss_4': -0.06860994547605515, 'epoch': 29.03}
{'loss': 0.016, 'grad_norm': 6.444819450378418, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.007170801982283592, 'loss_2': 0.008819580078125, 'loss_3': -16.31801414489746, 'loss_4': -0.45581892132759094, 'epoch': 29.03}
{'loss': 0.0087, 'grad_norm': 4.693595886230469, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.0027133761905133724, 'loss_2': 0.0059661865234375, 'loss_3': -16.763103485107422, 'loss_4': -0.3890991806983948, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 17:20:36,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:36,537 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:03:14<02:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:43,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011495009064674377, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.99, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008582249283790588, 'eval_loss_2': 0.002912759780883789, 'eval_loss_3': -18.186561584472656, 'eval_loss_4': -0.28282424807548523, 'epoch': 29.04}
{'loss': 0.0066, 'grad_norm': 4.738528251647949, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.004787060897797346, 'loss_2': 0.001827239990234375, 'loss_3': -16.42825698852539, 'loss_4': -0.16885177791118622, 'epoch': 29.05}
{'loss': 0.0079, 'grad_norm': 5.2498459815979, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.004556520376354456, 'loss_2': 0.003326416015625, 'loss_3': -16.466960906982422, 'loss_4': -0.3924403786659241, 'epoch': 29.05}
{'loss': 0.0033, 'grad_norm': 5.334815502166748, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.003065207041800022, 'loss_2': 0.00027561187744140625, 'loss_3': -16.559961318969727, 'loss_4': -0.25153738260269165, 'epoch': 29.06}
{'loss': 0.008, 'grad_norm': 5.392381191253662, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.007149488665163517, 'loss_2': 0.0008769035339355469, 'loss_3': -16.551284790039062, 'loss_4': -0.32684704661369324, 'epoch': 29.06}
{'loss': 0.0081, 'grad_norm': 4.580053329467773, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0025073711294680834, 'loss_2': 0.00560760498046875, 'loss_3': -16.490930557250977, 'loss_4': -0.499917209148407, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 17:20:43,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:43,898 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:22<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:51,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011473845690488815, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.648, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.0084121348336339, 'eval_loss_2': 0.0030617117881774902, 'eval_loss_3': -18.186405181884766, 'eval_loss_4': -0.28222548961639404, 'epoch': 29.07}
{'loss': 0.0046, 'grad_norm': 4.763967990875244, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.00403224304318428, 'loss_2': 0.0005955696105957031, 'loss_3': -16.581573486328125, 'loss_4': -0.1062832772731781, 'epoch': 29.08}
{'loss': 0.0052, 'grad_norm': 6.984071254730225, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.005156747996807098, 'loss_2': 1.3709068298339844e-05, 'loss_3': -16.656824111938477, 'loss_4': -0.363844096660614, 'epoch': 29.08}
{'loss': 0.0079, 'grad_norm': 4.78533411026001, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.00287997187115252, 'loss_2': 0.004974365234375, 'loss_3': -16.6719970703125, 'loss_4': -0.16704773902893066, 'epoch': 29.09}
{'loss': 0.0666, 'grad_norm': 9.273104667663574, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.059889934957027435, 'loss_2': 0.0067596435546875, 'loss_3': -16.747220993041992, 'loss_4': -0.08831790089607239, 'epoch': 29.09}
{'loss': 0.003, 'grad_norm': 4.663731575012207, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.0015441537834703922, 'loss_2': 0.0014781951904296875, 'loss_3': -16.53577423095703, 'loss_4': -0.6654891967773438, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 17:20:51,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:51,247 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:29<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:58,598 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011324003338813782, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.778, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00829307734966278, 'eval_loss_2': 0.003030925989151001, 'eval_loss_3': -18.184619903564453, 'eval_loss_4': -0.2749451994895935, 'epoch': 29.1}
{'loss': 0.0052, 'grad_norm': 4.631887912750244, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.00283220992423594, 'loss_2': 0.002323150634765625, 'loss_3': -16.5281982421875, 'loss_4': -0.35438504815101624, 'epoch': 29.1}
{'loss': 0.0059, 'grad_norm': 4.4604363441467285, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.0028396390844136477, 'loss_2': 0.0030422210693359375, 'loss_3': -16.482391357421875, 'loss_4': -0.19955666363239288, 'epoch': 29.11}
{'loss': 0.01, 'grad_norm': 4.948974609375, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.004532055463641882, 'loss_2': 0.005462646484375, 'loss_3': -16.66434097290039, 'loss_4': -0.18814025819301605, 'epoch': 29.12}
{'loss': 0.0053, 'grad_norm': 4.655003547668457, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.003405708121135831, 'loss_2': 0.0018634796142578125, 'loss_3': -16.4801082611084, 'loss_4': -0.3675391674041748, 'epoch': 29.12}
{'loss': 0.0034, 'grad_norm': 4.519619941711426, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.0021859125699847937, 'loss_2': 0.0011959075927734375, 'loss_3': -16.604650497436523, 'loss_4': 0.004918478429317474, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 17:20:58,599 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:58,599 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:36<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:05,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011124027892947197, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.883, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008076800033450127, 'eval_loss_2': 0.0030472278594970703, 'eval_loss_3': -18.188175201416016, 'eval_loss_4': -0.2652954161167145, 'epoch': 29.13}
{'loss': 0.0052, 'grad_norm': 5.0453338623046875, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.004275243729352951, 'loss_2': 0.000888824462890625, 'loss_3': -16.468698501586914, 'loss_4': -0.03333321958780289, 'epoch': 29.13}
{'loss': 0.0034, 'grad_norm': 4.70297384262085, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.00240154517814517, 'loss_2': 0.0009741783142089844, 'loss_3': -16.54564666748047, 'loss_4': -0.11879090219736099, 'epoch': 29.14}
{'loss': 0.0074, 'grad_norm': 4.849894046783447, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.003628601785749197, 'loss_2': 0.003734588623046875, 'loss_3': -16.546369552612305, 'loss_4': 0.10149265080690384, 'epoch': 29.15}
{'loss': 0.0076, 'grad_norm': 5.731546878814697, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.004360280930995941, 'loss_2': 0.003192901611328125, 'loss_3': -16.543685913085938, 'loss_4': -0.49410733580589294, 'epoch': 29.15}
{'loss': 0.0074, 'grad_norm': 5.061753749847412, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0038489645812660456, 'loss_2': 0.00354766845703125, 'loss_3': -16.474563598632812, 'loss_4': -0.6136956214904785, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 17:21:05,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:05,941 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:44<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:13,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011063406243920326, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007988343015313148, 'eval_loss_2': 0.0030750632286071777, 'eval_loss_3': -18.19097137451172, 'eval_loss_4': -0.26511555910110474, 'epoch': 29.16}
{'loss': 0.0111, 'grad_norm': 4.794853687286377, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.0036967373453080654, 'loss_2': 0.007389068603515625, 'loss_3': -16.484472274780273, 'loss_4': -0.24821004271507263, 'epoch': 29.16}
{'loss': 0.0147, 'grad_norm': 8.864055633544922, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.011449046432971954, 'loss_2': 0.0032196044921875, 'loss_3': -16.55519676208496, 'loss_4': -0.15577587485313416, 'epoch': 29.17}
{'loss': 0.0135, 'grad_norm': 8.136921882629395, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.01327911764383316, 'loss_2': 0.00022602081298828125, 'loss_3': -16.42459487915039, 'loss_4': -0.31505224108695984, 'epoch': 29.17}
{'loss': 0.0092, 'grad_norm': 4.476010322570801, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.006604349240660667, 'loss_2': 0.00260162353515625, 'loss_3': -16.451824188232422, 'loss_4': -0.358632355928421, 'epoch': 29.18}
{'loss': 0.01, 'grad_norm': 4.8269877433776855, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.0038792400155216455, 'loss_2': 0.006092071533203125, 'loss_3': -16.336685180664062, 'loss_4': 0.06179538369178772, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 17:21:13,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:13,289 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:51<02:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:20,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011130888015031815, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008032310754060745, 'eval_loss_2': 0.0030985772609710693, 'eval_loss_3': -18.19292640686035, 'eval_loss_4': -0.25467973947525024, 'epoch': 29.19}
{'loss': 0.0107, 'grad_norm': 5.52287483215332, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.007736166473478079, 'loss_2': 0.00293731689453125, 'loss_3': -16.481929779052734, 'loss_4': 0.34250760078430176, 'epoch': 29.19}
{'loss': 0.0076, 'grad_norm': 4.561842918395996, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.0040682097896933556, 'loss_2': 0.00350189208984375, 'loss_3': -16.49039649963379, 'loss_4': 0.22242359817028046, 'epoch': 29.2}
{'loss': 0.0137, 'grad_norm': 15.741033554077148, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.011385833844542503, 'loss_2': 0.002346038818359375, 'loss_3': -16.441627502441406, 'loss_4': -0.35405999422073364, 'epoch': 29.2}
{'loss': 0.0066, 'grad_norm': 5.050283908843994, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.0043828729540109634, 'loss_2': 0.00217437744140625, 'loss_3': -16.58856201171875, 'loss_4': -0.16653306782245636, 'epoch': 29.21}
{'loss': 0.0071, 'grad_norm': 4.72182559967041, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.003659425536170602, 'loss_2': 0.003398895263671875, 'loss_3': -16.54314422607422, 'loss_4': -0.5463831424713135, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 17:21:20,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:20,651 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:58<02:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:28,000 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011106214486062527, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00802608486264944, 'eval_loss_2': 0.003080129623413086, 'eval_loss_3': -18.193437576293945, 'eval_loss_4': -0.24398519098758698, 'epoch': 29.22}
{'loss': 0.0035, 'grad_norm': 4.94138240814209, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.0029630050994455814, 'loss_2': 0.0005178451538085938, 'loss_3': -16.451080322265625, 'loss_4': -0.401297926902771, 'epoch': 29.22}
{'loss': 0.0074, 'grad_norm': 4.453121185302734, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.004957432392984629, 'loss_2': 0.00246429443359375, 'loss_3': -16.441390991210938, 'loss_4': -0.5972932577133179, 'epoch': 29.23}
{'loss': 0.0084, 'grad_norm': 4.903670310974121, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.0036786592099815607, 'loss_2': 0.0047607421875, 'loss_3': -16.621225357055664, 'loss_4': -0.37828490138053894, 'epoch': 29.23}
{'loss': 0.006, 'grad_norm': 4.957037448883057, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.003243750426918268, 'loss_2': 0.00276947021484375, 'loss_3': -16.316524505615234, 'loss_4': -0.18889696896076202, 'epoch': 29.24}
{'loss': 0.0029, 'grad_norm': 4.366311550140381, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.002779146656394005, 'loss_2': 0.0001277923583984375, 'loss_3': -16.583362579345703, 'loss_4': -0.4986407458782196, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 17:21:28,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:28,000 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:04:06<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:35,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011113106273114681, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00813370756804943, 'eval_loss_2': 0.0029793977737426758, 'eval_loss_3': -18.19228744506836, 'eval_loss_4': -0.23621836304664612, 'epoch': 29.24}
{'loss': 0.0114, 'grad_norm': 7.59751558303833, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.00948843639343977, 'loss_2': 0.001865386962890625, 'loss_3': -16.53611946105957, 'loss_4': -0.03035333752632141, 'epoch': 29.25}
{'loss': 0.0116, 'grad_norm': 7.2083258628845215, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.007518147584050894, 'loss_2': 0.004119873046875, 'loss_3': -16.766315460205078, 'loss_4': 0.06146521121263504, 'epoch': 29.26}
{'loss': 0.0742, 'grad_norm': 9.814805030822754, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.07071888446807861, 'loss_2': 0.0034942626953125, 'loss_3': -16.23280143737793, 'loss_4': -0.1266299933195114, 'epoch': 29.26}
{'loss': 0.0094, 'grad_norm': 4.6027092933654785, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.0028940618503838778, 'loss_2': 0.00652313232421875, 'loss_3': -16.50720977783203, 'loss_4': -0.5532845854759216, 'epoch': 29.27}
{'loss': 0.0127, 'grad_norm': 7.1141438484191895, 'learning_rate': 7.5e-07, 'loss_1': 0.007575807627290487, 'loss_2': 0.005130767822265625, 'loss_3': -16.513324737548828, 'loss_4': -0.5304296016693115, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 17:21:35,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:35,358 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:04:13<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:42,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010936669073998928, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.829, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008110485039651394, 'eval_loss_2': 0.002826184034347534, 'eval_loss_3': -18.191993713378906, 'eval_loss_4': -0.2379559576511383, 'epoch': 29.27}
{'loss': 0.0055, 'grad_norm': 4.297199249267578, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.003339396556839347, 'loss_2': 0.0021114349365234375, 'loss_3': -16.526657104492188, 'loss_4': -0.08634815365076065, 'epoch': 29.28}
{'loss': 0.0079, 'grad_norm': 4.895474910736084, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.005531749688088894, 'loss_2': 0.0023212432861328125, 'loss_3': -16.470983505249023, 'loss_4': -0.8639935255050659, 'epoch': 29.28}
{'loss': 0.0073, 'grad_norm': 5.204029560089111, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.0032163842115551233, 'loss_2': 0.004055023193359375, 'loss_3': -16.715068817138672, 'loss_4': 0.029749885201454163, 'epoch': 29.29}
{'loss': 0.0091, 'grad_norm': 4.800179481506348, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.004182123113423586, 'loss_2': 0.0048828125, 'loss_3': -16.4322509765625, 'loss_4': 0.010197464376688004, 'epoch': 29.3}
{'loss': 0.014, 'grad_norm': 6.513177871704102, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.008697482757270336, 'loss_2': 0.00531768798828125, 'loss_3': -16.56053924560547, 'loss_4': 0.37110668420791626, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 17:21:42,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:42,703 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:20<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:50,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010697569698095322, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.474, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007944609969854355, 'eval_loss_2': 0.002752959728240967, 'eval_loss_3': -18.192241668701172, 'eval_loss_4': -0.24154868721961975, 'epoch': 29.3}
{'loss': 0.0073, 'grad_norm': 4.45039176940918, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.0015036951517686248, 'loss_2': 0.005764007568359375, 'loss_3': -16.77545166015625, 'loss_4': -0.15184560418128967, 'epoch': 29.31}
{'loss': 0.0017, 'grad_norm': 4.296299457550049, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.0016692226054146886, 'loss_2': 1.0728836059570312e-05, 'loss_3': -16.581363677978516, 'loss_4': -0.13821515440940857, 'epoch': 29.31}
{'loss': 0.0145, 'grad_norm': 7.1269636154174805, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.013413926586508751, 'loss_2': 0.0010623931884765625, 'loss_3': -16.493072509765625, 'loss_4': -0.6383546590805054, 'epoch': 29.32}
{'loss': 0.0072, 'grad_norm': 4.679020881652832, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.0030105544719845057, 'loss_2': 0.00420379638671875, 'loss_3': -16.45423126220703, 'loss_4': -0.40489357709884644, 'epoch': 29.33}
{'loss': 0.0097, 'grad_norm': 5.251533508300781, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.005100002512335777, 'loss_2': 0.00461578369140625, 'loss_3': -16.523969650268555, 'loss_4': -0.3672844171524048, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 17:21:50,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:50,056 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:28<01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:57,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010636232793331146, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.444, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007880710065364838, 'eval_loss_2': 0.0027555227279663086, 'eval_loss_3': -18.193340301513672, 'eval_loss_4': -0.2421533614397049, 'epoch': 29.33}
{'loss': 0.0023, 'grad_norm': 4.570689678192139, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.0012486902996897697, 'loss_2': 0.00109100341796875, 'loss_3': -16.68414306640625, 'loss_4': -0.5608407258987427, 'epoch': 29.34}
{'loss': 0.0075, 'grad_norm': 5.244013786315918, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.0036653918214142323, 'loss_2': 0.003875732421875, 'loss_3': -16.569801330566406, 'loss_4': -0.7284443378448486, 'epoch': 29.34}
{'loss': 0.005, 'grad_norm': 4.869599342346191, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.0032651363871991634, 'loss_2': 0.0016956329345703125, 'loss_3': -16.524686813354492, 'loss_4': -0.3576003313064575, 'epoch': 29.35}
{'loss': 0.0256, 'grad_norm': 13.189424514770508, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.024086197838187218, 'loss_2': 0.0015420913696289062, 'loss_3': -16.40053939819336, 'loss_4': 0.20242929458618164, 'epoch': 29.35}
{'loss': 0.0082, 'grad_norm': 4.941917419433594, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.005168007221072912, 'loss_2': 0.003002166748046875, 'loss_3': -16.278564453125, 'loss_4': -0.37526360154151917, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 17:21:57,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:57,408 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:35<01:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:04,773 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010519578121602535, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.759, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007879002019762993, 'eval_loss_2': 0.0026405751705169678, 'eval_loss_3': -18.192222595214844, 'eval_loss_4': -0.2379155457019806, 'epoch': 29.36}
{'loss': 0.0064, 'grad_norm': 4.325120449066162, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.002989446045830846, 'loss_2': 0.00336456298828125, 'loss_3': -16.522066116333008, 'loss_4': -0.03457140922546387, 'epoch': 29.37}
{'loss': 0.0048, 'grad_norm': 4.973254203796387, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0028299849946051836, 'loss_2': 0.00196075439453125, 'loss_3': -16.49559783935547, 'loss_4': -0.07634396851062775, 'epoch': 29.37}
{'loss': 0.0104, 'grad_norm': 6.187399387359619, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.005851823836565018, 'loss_2': 0.004558563232421875, 'loss_3': -16.633190155029297, 'loss_4': -0.05840759351849556, 'epoch': 29.38}
{'loss': 0.0151, 'grad_norm': 8.903048515319824, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.01209719106554985, 'loss_2': 0.00299835205078125, 'loss_3': -16.51629638671875, 'loss_4': -0.5701661109924316, 'epoch': 29.38}
{'loss': 0.0122, 'grad_norm': 5.943583011627197, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.010804109275341034, 'loss_2': 0.001354217529296875, 'loss_3': -16.350723266601562, 'loss_4': -0.17029058933258057, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 17:22:04,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:04,774 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:42<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:12,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010487440042197704, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007924441248178482, 'eval_loss_2': 0.002562999725341797, 'eval_loss_3': -18.19133758544922, 'eval_loss_4': -0.23095270991325378, 'epoch': 29.39}
{'loss': 0.0041, 'grad_norm': 5.529680252075195, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.002989555709064007, 'loss_2': 0.0011501312255859375, 'loss_3': -16.563438415527344, 'loss_4': -0.43295609951019287, 'epoch': 29.4}
{'loss': 0.0069, 'grad_norm': 4.915070533752441, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.005273402202874422, 'loss_2': 0.0016565322875976562, 'loss_3': -16.566478729248047, 'loss_4': 0.07317107915878296, 'epoch': 29.4}
{'loss': 0.0072, 'grad_norm': 5.0885796546936035, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.005096816923469305, 'loss_2': 0.002094268798828125, 'loss_3': -16.569438934326172, 'loss_4': -0.23778550326824188, 'epoch': 29.41}
{'loss': 0.0047, 'grad_norm': 4.511622428894043, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.0029144117143005133, 'loss_2': 0.0018062591552734375, 'loss_3': -16.661598205566406, 'loss_4': 0.08087577670812607, 'epoch': 29.41}
{'loss': 0.0039, 'grad_norm': 4.685274124145508, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.002574689919129014, 'loss_2': 0.00135040283203125, 'loss_3': -16.658252716064453, 'loss_4': -0.3018336892127991, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 17:22:12,128 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:12,128 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:50<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:19,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010437693446874619, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.57, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.00797646027058363, 'eval_loss_2': 0.0024612322449684143, 'eval_loss_3': -18.190433502197266, 'eval_loss_4': -0.23044630885124207, 'epoch': 29.42}
{'loss': 0.0076, 'grad_norm': 4.32920503616333, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.0034592626616358757, 'loss_2': 0.00412750244140625, 'loss_3': -16.604516983032227, 'loss_4': -0.10614068806171417, 'epoch': 29.42}
{'loss': 0.0097, 'grad_norm': 5.177358150482178, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.002746696351096034, 'loss_2': 0.006969451904296875, 'loss_3': -16.36520004272461, 'loss_4': -0.22993795573711395, 'epoch': 29.43}
{'loss': 0.005, 'grad_norm': 4.957755088806152, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.004248548299074173, 'loss_2': 0.0007748603820800781, 'loss_3': -16.649520874023438, 'loss_4': 0.14322718977928162, 'epoch': 29.44}
{'loss': 0.0058, 'grad_norm': 5.343900203704834, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.002068925416097045, 'loss_2': 0.003719329833984375, 'loss_3': -16.473655700683594, 'loss_4': -0.4702652096748352, 'epoch': 29.44}
{'loss': 0.007, 'grad_norm': 5.746670722961426, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.006967339664697647, 'loss_2': 5.435943603515625e-05, 'loss_3': -16.507122039794922, 'loss_4': -0.09584704041481018, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 17:22:19,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:19,490 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:57<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:26,840 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010532169602811337, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008085033856332302, 'eval_loss_2': 0.0024471357464790344, 'eval_loss_3': -18.190290451049805, 'eval_loss_4': -0.2267744541168213, 'epoch': 29.45}
{'loss': 0.01, 'grad_norm': 4.679596424102783, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.00391843356192112, 'loss_2': 0.0061187744140625, 'loss_3': -16.768844604492188, 'loss_4': -0.12815572321414948, 'epoch': 29.45}
{'loss': 0.0099, 'grad_norm': 5.579652786254883, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.005565782077610493, 'loss_2': 0.00434112548828125, 'loss_3': -16.382762908935547, 'loss_4': -0.3121536374092102, 'epoch': 29.46}
{'loss': 0.0066, 'grad_norm': 5.14489221572876, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.0054877703078091145, 'loss_2': 0.00113677978515625, 'loss_3': -16.456771850585938, 'loss_4': 0.22471988201141357, 'epoch': 29.47}
{'loss': 0.0047, 'grad_norm': 4.249634742736816, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.0025221025571227074, 'loss_2': 0.002155303955078125, 'loss_3': -16.622352600097656, 'loss_4': -0.03344228118658066, 'epoch': 29.47}
{'loss': 0.0058, 'grad_norm': 5.050124645233154, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.005546157713979483, 'loss_2': 0.0002307891845703125, 'loss_3': -16.607358932495117, 'loss_4': -0.14361163973808289, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 17:22:26,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:26,840 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:05:05<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:34,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010606466792523861, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.737, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008106647059321404, 'eval_loss_2': 0.002499818801879883, 'eval_loss_3': -18.19029998779297, 'eval_loss_4': -0.2229156643152237, 'epoch': 29.48}
{'loss': 0.0101, 'grad_norm': 5.883309841156006, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.006693139206618071, 'loss_2': 0.003444671630859375, 'loss_3': -16.433815002441406, 'loss_4': -0.5989444851875305, 'epoch': 29.48}
{'loss': 0.0071, 'grad_norm': 5.191053867340088, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.0033489034976810217, 'loss_2': 0.003757476806640625, 'loss_3': -16.511192321777344, 'loss_4': -0.08680635690689087, 'epoch': 29.49}
{'loss': 0.0051, 'grad_norm': 5.083038806915283, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.003092115046456456, 'loss_2': 0.0020084381103515625, 'loss_3': -16.350614547729492, 'loss_4': -0.6409435272216797, 'epoch': 29.49}
{'loss': 0.0066, 'grad_norm': 6.460016250610352, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.006489758379757404, 'loss_2': 6.222724914550781e-05, 'loss_3': -16.53721046447754, 'loss_4': -0.36273911595344543, 'epoch': 29.5}
{'loss': 0.0074, 'grad_norm': 5.368990898132324, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.005294452887028456, 'loss_2': 0.0020656585693359375, 'loss_3': -16.61636734008789, 'loss_4': -0.5777537822723389, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 17:22:34,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:34,191 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:05:12<01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:41,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010600676760077477, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.287, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008114208467304707, 'eval_loss_2': 0.0024864673614501953, 'eval_loss_3': -18.18937873840332, 'eval_loss_4': -0.2237350046634674, 'epoch': 29.51}
{'loss': 0.0064, 'grad_norm': 4.876260757446289, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.003470231080427766, 'loss_2': 0.0028839111328125, 'loss_3': -16.357934951782227, 'loss_4': -0.06449677795171738, 'epoch': 29.51}
{'loss': 0.0069, 'grad_norm': 4.712876319885254, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.002636457560583949, 'loss_2': 0.004230499267578125, 'loss_3': -16.70148468017578, 'loss_4': -0.10530239343643188, 'epoch': 29.52}
{'loss': 0.0071, 'grad_norm': 4.946392059326172, 'learning_rate': 5e-07, 'loss_1': 0.0044256472028791904, 'loss_2': 0.0027027130126953125, 'loss_3': -16.411046981811523, 'loss_4': -0.128396138548851, 'epoch': 29.52}
{'loss': 0.0055, 'grad_norm': 4.641465187072754, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.001678320812061429, 'loss_2': 0.00385284423828125, 'loss_3': -16.540969848632812, 'loss_4': 0.24778786301612854, 'epoch': 29.53}
{'loss': 0.0078, 'grad_norm': 5.067748546600342, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.0022960063070058823, 'loss_2': 0.005550384521484375, 'loss_3': -16.728954315185547, 'loss_4': 0.24085813760757446, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 17:22:41,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:41,553 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:19<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:48,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010678615421056747, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.615, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008154395967721939, 'eval_loss_2': 0.0025242194533348083, 'eval_loss_3': -18.191558837890625, 'eval_loss_4': -0.21757765114307404, 'epoch': 29.53}
{'loss': 0.005, 'grad_norm': 4.861110210418701, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.003104835283011198, 'loss_2': 0.0018520355224609375, 'loss_3': -16.585865020751953, 'loss_4': 0.08829769492149353, 'epoch': 29.54}
{'loss': 0.0116, 'grad_norm': 6.037766933441162, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.007889242842793465, 'loss_2': 0.0037326812744140625, 'loss_3': -16.516071319580078, 'loss_4': -0.4483778476715088, 'epoch': 29.55}
{'loss': 0.0024, 'grad_norm': 4.819224834442139, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.0022603324614465237, 'loss_2': 0.0001506805419921875, 'loss_3': -16.647586822509766, 'loss_4': -0.45244184136390686, 'epoch': 29.55}
{'loss': 0.0048, 'grad_norm': 4.804051876068115, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.003612629370763898, 'loss_2': 0.001194000244140625, 'loss_3': -16.281198501586914, 'loss_4': -0.15738624334335327, 'epoch': 29.56}
{'loss': 0.0069, 'grad_norm': 4.442945957183838, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.0021811858750879765, 'loss_2': 0.004749298095703125, 'loss_3': -16.498498916625977, 'loss_4': -0.3906813859939575, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 17:22:48,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:48,902 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:27<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:56,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01075157430022955, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.684, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008195711299777031, 'eval_loss_2': 0.002555862069129944, 'eval_loss_3': -18.1912841796875, 'eval_loss_4': -0.2141551524400711, 'epoch': 29.56}
{'loss': 0.0026, 'grad_norm': 4.675226211547852, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.0018016359535977244, 'loss_2': 0.0007901191711425781, 'loss_3': -16.65802764892578, 'loss_4': -0.19023366272449493, 'epoch': 29.57}
{'loss': 0.0109, 'grad_norm': 4.693887710571289, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.00394833879545331, 'loss_2': 0.0069732666015625, 'loss_3': -16.364761352539062, 'loss_4': -0.51154625415802, 'epoch': 29.58}
{'loss': 0.0047, 'grad_norm': 5.404926300048828, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.0026095774956047535, 'loss_2': 0.002124786376953125, 'loss_3': -16.523582458496094, 'loss_4': -0.393075555562973, 'epoch': 29.58}
{'loss': 0.0251, 'grad_norm': 11.688446044921875, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.024458199739456177, 'loss_2': 0.0006608963012695312, 'loss_3': -16.462127685546875, 'loss_4': -0.3463450074195862, 'epoch': 29.59}
{'loss': 0.0045, 'grad_norm': 4.9624247550964355, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.002490913262590766, 'loss_2': 0.002025604248046875, 'loss_3': -16.51488494873047, 'loss_4': -0.19685061275959015, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 17:22:56,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:56,244 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:34<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:03,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01075655221939087, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008113204501569271, 'eval_loss_2': 0.0026433467864990234, 'eval_loss_3': -18.189517974853516, 'eval_loss_4': -0.2098226100206375, 'epoch': 29.59}
{'loss': 0.0076, 'grad_norm': 4.460702419281006, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.0030967765487730503, 'loss_2': 0.004474639892578125, 'loss_3': -16.498897552490234, 'loss_4': -0.26456451416015625, 'epoch': 29.6}
{'loss': 0.011, 'grad_norm': 6.537411212921143, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.007138477172702551, 'loss_2': 0.003875732421875, 'loss_3': -16.679553985595703, 'loss_4': -0.10077730566263199, 'epoch': 29.6}
{'loss': 0.0076, 'grad_norm': 4.1265716552734375, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.0019327020272612572, 'loss_2': 0.00566864013671875, 'loss_3': -16.42914581298828, 'loss_4': 0.005829021334648132, 'epoch': 29.61}
{'loss': 0.0057, 'grad_norm': 4.690179347991943, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.003305508056655526, 'loss_2': 0.002353668212890625, 'loss_3': -16.388267517089844, 'loss_4': -0.32705968618392944, 'epoch': 29.62}
{'loss': 0.0037, 'grad_norm': 4.651859283447266, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.002143912250176072, 'loss_2': 0.0016040802001953125, 'loss_3': -16.56170654296875, 'loss_4': -0.2621387839317322, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 17:23:03,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:03,590 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:41<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:10,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010873920284211636, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.86, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008129931055009365, 'eval_loss_2': 0.0027439892292022705, 'eval_loss_3': -18.18824005126953, 'eval_loss_4': -0.20301632583141327, 'epoch': 29.62}
{'loss': 0.0035, 'grad_norm': 4.934328079223633, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.0021580427419394255, 'loss_2': 0.0013027191162109375, 'loss_3': -16.51064682006836, 'loss_4': -0.36201420426368713, 'epoch': 29.63}
{'loss': 0.0069, 'grad_norm': 4.613582134246826, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.0034871981479227543, 'loss_2': 0.003459930419921875, 'loss_3': -16.364173889160156, 'loss_4': -0.31872326135635376, 'epoch': 29.63}
{'loss': 0.0099, 'grad_norm': 4.598086833953857, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.002404217841103673, 'loss_2': 0.0074920654296875, 'loss_3': -16.452377319335938, 'loss_4': -0.20046642422676086, 'epoch': 29.64}
{'loss': 0.0181, 'grad_norm': 14.539191246032715, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.012658246792852879, 'loss_2': 0.005401611328125, 'loss_3': -16.64454460144043, 'loss_4': 0.1274968534708023, 'epoch': 29.65}
{'loss': 0.0069, 'grad_norm': 5.314360618591309, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.0031810470391064882, 'loss_2': 0.00370025634765625, 'loss_3': -16.50557518005371, 'loss_4': -0.19073915481567383, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 17:23:10,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:10,929 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:49<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:18,290 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010921984910964966, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008124218322336674, 'eval_loss_2': 0.0027977675199508667, 'eval_loss_3': -18.186664581298828, 'eval_loss_4': -0.20101532340049744, 'epoch': 29.65}
{'loss': 0.0073, 'grad_norm': 4.653496265411377, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.004089339170604944, 'loss_2': 0.003231048583984375, 'loss_3': -16.53327751159668, 'loss_4': 0.139619380235672, 'epoch': 29.66}
{'loss': 0.0068, 'grad_norm': 4.540340423583984, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.004912791773676872, 'loss_2': 0.0018777847290039062, 'loss_3': -16.460025787353516, 'loss_4': -0.025763466954231262, 'epoch': 29.66}
{'loss': 0.0051, 'grad_norm': 4.635603904724121, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.002696423092857003, 'loss_2': 0.002407073974609375, 'loss_3': -16.53974151611328, 'loss_4': -0.4966874122619629, 'epoch': 29.67}
{'loss': 0.0102, 'grad_norm': 5.242319107055664, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.004790435545146465, 'loss_2': 0.00536346435546875, 'loss_3': -16.553552627563477, 'loss_4': -0.28970950841903687, 'epoch': 29.67}
{'loss': 0.0048, 'grad_norm': 4.662577152252197, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.0024728344287723303, 'loss_2': 0.002277374267578125, 'loss_3': -16.709110260009766, 'loss_4': -0.5168839693069458, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 17:23:18,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:18,290 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:56<00:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:25,652 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010973101481795311, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008171653375029564, 'eval_loss_2': 0.002801448106765747, 'eval_loss_3': -18.186527252197266, 'eval_loss_4': -0.1983284205198288, 'epoch': 29.68}
{'loss': 0.0112, 'grad_norm': 10.242962837219238, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.01020827330648899, 'loss_2': 0.0010204315185546875, 'loss_3': -16.567075729370117, 'loss_4': -0.2200949639081955, 'epoch': 29.69}
{'loss': 0.0114, 'grad_norm': 4.3932600021362305, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.003236780408769846, 'loss_2': 0.0081939697265625, 'loss_3': -16.532575607299805, 'loss_4': -0.23150785267353058, 'epoch': 29.69}
{'loss': 0.0102, 'grad_norm': 5.210849285125732, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.006306643132120371, 'loss_2': 0.0038604736328125, 'loss_3': -16.62220001220703, 'loss_4': -0.06836891174316406, 'epoch': 29.7}
{'loss': 0.0207, 'grad_norm': 10.697206497192383, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.013736882247030735, 'loss_2': 0.00698089599609375, 'loss_3': -16.508323669433594, 'loss_4': -0.10207314789295197, 'epoch': 29.7}
{'loss': 0.0125, 'grad_norm': 6.600289344787598, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.005647546146064997, 'loss_2': 0.00681304931640625, 'loss_3': -16.589168548583984, 'loss_4': -0.15378202497959137, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 17:23:25,652 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:25,652 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:06:03<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:32,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011008316650986671, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.56, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008227968588471413, 'eval_loss_2': 0.002780348062515259, 'eval_loss_3': -18.185802459716797, 'eval_loss_4': -0.197143092751503, 'epoch': 29.71}
{'loss': 0.0119, 'grad_norm': 5.876787185668945, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.00843820907175541, 'loss_2': 0.003452301025390625, 'loss_3': -16.348670959472656, 'loss_4': -0.3440486788749695, 'epoch': 29.72}
{'loss': 0.008, 'grad_norm': 4.466536521911621, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.003220429876819253, 'loss_2': 0.004734039306640625, 'loss_3': -16.50723648071289, 'loss_4': -0.3433730900287628, 'epoch': 29.72}
{'loss': 0.0073, 'grad_norm': 5.669832229614258, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.006073886062949896, 'loss_2': 0.0012359619140625, 'loss_3': -16.47057342529297, 'loss_4': 0.09519708901643753, 'epoch': 29.73}
{'loss': 0.0162, 'grad_norm': 8.907862663269043, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.0120076984167099, 'loss_2': 0.00415802001953125, 'loss_3': -16.37985610961914, 'loss_4': -0.02258666604757309, 'epoch': 29.73}
{'loss': 0.0061, 'grad_norm': 5.208817958831787, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.004886675626039505, 'loss_2': 0.0011968612670898438, 'loss_3': -16.50041961669922, 'loss_4': -0.06109130382537842, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 17:23:33,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:33,000 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:06:11<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:40,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0110267149284482, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.813, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008326534181833267, 'eval_loss_2': 0.0027001798152923584, 'eval_loss_3': -18.186080932617188, 'eval_loss_4': -0.1962517499923706, 'epoch': 29.74}
{'loss': 0.0112, 'grad_norm': 6.533716678619385, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.006024752743542194, 'loss_2': 0.00521087646484375, 'loss_3': -16.50425148010254, 'loss_4': -0.3289356827735901, 'epoch': 29.74}
{'loss': 0.0064, 'grad_norm': 4.886791229248047, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.0031161990482360125, 'loss_2': 0.0032367706298828125, 'loss_3': -16.530437469482422, 'loss_4': -0.21934328973293304, 'epoch': 29.75}
{'loss': 0.0074, 'grad_norm': 4.368780136108398, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.004745895974338055, 'loss_2': 0.00266265869140625, 'loss_3': -16.759227752685547, 'loss_4': 0.04284390062093735, 'epoch': 29.76}
{'loss': 0.0053, 'grad_norm': 5.079309940338135, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.003583574201911688, 'loss_2': 0.0017299652099609375, 'loss_3': -16.480247497558594, 'loss_4': 0.10001453012228012, 'epoch': 29.76}
{'loss': 0.0092, 'grad_norm': 4.707871913909912, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.0033718852791935205, 'loss_2': 0.005802154541015625, 'loss_3': -16.578895568847656, 'loss_4': 0.30587899684906006, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 17:23:40,343 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:40,343 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:06:18<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:47,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011001307517290115, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.821, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008357454091310501, 'eval_loss_2': 0.0026438534259796143, 'eval_loss_3': -18.18568229675293, 'eval_loss_4': -0.19548195600509644, 'epoch': 29.77}
{'loss': 0.0094, 'grad_norm': 7.1544013023376465, 'learning_rate': 2.5e-07, 'loss_1': 0.006357730366289616, 'loss_2': 0.003040313720703125, 'loss_3': -16.237525939941406, 'loss_4': -0.7327746152877808, 'epoch': 29.77}
{'loss': 0.0618, 'grad_norm': 14.868650436401367, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.05618121102452278, 'loss_2': 0.005626678466796875, 'loss_3': -16.655305862426758, 'loss_4': 0.07405262440443039, 'epoch': 29.78}
{'loss': 0.0044, 'grad_norm': 4.623270034790039, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.002050691284239292, 'loss_2': 0.00238800048828125, 'loss_3': -16.69012451171875, 'loss_4': -0.27993470430374146, 'epoch': 29.78}
{'loss': 0.0059, 'grad_norm': 4.969019412994385, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.003911813721060753, 'loss_2': 0.0019989013671875, 'loss_3': -16.57037925720215, 'loss_4': -0.10731557011604309, 'epoch': 29.79}
{'loss': 0.0151, 'grad_norm': 9.582742691040039, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.01400256622582674, 'loss_2': 0.0010538101196289062, 'loss_3': -16.434371948242188, 'loss_4': -0.7181172370910645, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 17:23:47,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:47,686 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:25<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:55,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010993972420692444, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008357114158570766, 'eval_loss_2': 0.002636857330799103, 'eval_loss_3': -18.185745239257812, 'eval_loss_4': -0.19613748788833618, 'epoch': 29.8}
{'loss': 0.0041, 'grad_norm': 4.587180137634277, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.0026634500827640295, 'loss_2': 0.001434326171875, 'loss_3': -16.48210906982422, 'loss_4': -0.2614384591579437, 'epoch': 29.8}
{'loss': 0.0112, 'grad_norm': 4.841681003570557, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.0036557051353156567, 'loss_2': 0.00754547119140625, 'loss_3': -16.39853286743164, 'loss_4': 0.019625291228294373, 'epoch': 29.81}
{'loss': 0.0062, 'grad_norm': 6.110185623168945, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.0037208423018455505, 'loss_2': 0.002445220947265625, 'loss_3': -16.479015350341797, 'loss_4': -0.791154682636261, 'epoch': 29.81}
{'loss': 0.0045, 'grad_norm': 4.921797275543213, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0016986825503408909, 'loss_2': 0.0028209686279296875, 'loss_3': -16.653059005737305, 'loss_4': -0.018854476511478424, 'epoch': 29.82}
{'loss': 0.0104, 'grad_norm': 6.639690399169922, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.009860732592642307, 'loss_2': 0.0005016326904296875, 'loss_3': -16.448318481445312, 'loss_4': -0.4377700686454773, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 17:23:55,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:55,043 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:33<00:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:02,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011017341166734695, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008362028747797012, 'eval_loss_2': 0.002655312418937683, 'eval_loss_3': -18.185396194458008, 'eval_loss_4': -0.19419533014297485, 'epoch': 29.83}
{'loss': 0.0041, 'grad_norm': 5.067166805267334, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.004004672169685364, 'loss_2': 6.556510925292969e-05, 'loss_3': -16.404624938964844, 'loss_4': -0.11423748731613159, 'epoch': 29.83}
{'loss': 0.005, 'grad_norm': 5.461239337921143, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.004365589469671249, 'loss_2': 0.0006022453308105469, 'loss_3': -16.647998809814453, 'loss_4': 0.0945327952504158, 'epoch': 29.84}
{'loss': 0.0119, 'grad_norm': 4.773960113525391, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.00293717160820961, 'loss_2': 0.00899505615234375, 'loss_3': -16.6368350982666, 'loss_4': -0.258098840713501, 'epoch': 29.84}
{'loss': 0.01, 'grad_norm': 5.251924514770508, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.004995393566787243, 'loss_2': 0.004970550537109375, 'loss_3': -16.604877471923828, 'loss_4': -0.3888569176197052, 'epoch': 29.85}
{'loss': 0.0026, 'grad_norm': 4.289992332458496, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.002384353429079056, 'loss_2': 0.0002524852752685547, 'loss_3': -16.62852668762207, 'loss_4': -0.20506557822227478, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 17:24:02,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:02,409 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:40<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:09,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011063111945986748, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.714, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008413574658334255, 'eval_loss_2': 0.002649538218975067, 'eval_loss_3': -18.184663772583008, 'eval_loss_4': -0.19105304777622223, 'epoch': 29.85}
{'loss': 0.0124, 'grad_norm': 4.809300422668457, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.00572931906208396, 'loss_2': 0.006683349609375, 'loss_3': -16.526729583740234, 'loss_4': -0.7620949745178223, 'epoch': 29.86}
{'loss': 0.0128, 'grad_norm': 5.640192031860352, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.00812381412833929, 'loss_2': 0.00472259521484375, 'loss_3': -16.691940307617188, 'loss_4': -0.415297269821167, 'epoch': 29.87}
{'loss': 0.0055, 'grad_norm': 5.306065082550049, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.005177944432944059, 'loss_2': 0.00030612945556640625, 'loss_3': -16.452869415283203, 'loss_4': -0.06268507987260818, 'epoch': 29.87}
{'loss': 0.0042, 'grad_norm': 4.950982093811035, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.003455868223682046, 'loss_2': 0.0007581710815429688, 'loss_3': -16.497127532958984, 'loss_4': -0.30480140447616577, 'epoch': 29.88}
{'loss': 0.0061, 'grad_norm': 4.973770618438721, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.0033188771922141314, 'loss_2': 0.0027313232421875, 'loss_3': -16.511428833007812, 'loss_4': -0.24437612295150757, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 17:24:09,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:09,754 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:47<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:17,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011104474775493145, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.863, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.00842111837118864, 'eval_loss_2': 0.0026833564043045044, 'eval_loss_3': -18.184478759765625, 'eval_loss_4': -0.18952128291130066, 'epoch': 29.88}
{'loss': 0.0059, 'grad_norm': 4.631258487701416, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.004549144767224789, 'loss_2': 0.0013113021850585938, 'loss_3': -16.35287094116211, 'loss_4': 0.041846323758363724, 'epoch': 29.89}
{'loss': 0.0343, 'grad_norm': 14.440590858459473, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.028512725606560707, 'loss_2': 0.00576019287109375, 'loss_3': -16.37342071533203, 'loss_4': 0.07136974483728409, 'epoch': 29.9}
{'loss': 0.0117, 'grad_norm': 5.961073875427246, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.009706946089863777, 'loss_2': 0.0019931793212890625, 'loss_3': -16.378665924072266, 'loss_4': -0.6078991889953613, 'epoch': 29.9}
{'loss': 0.0122, 'grad_norm': 4.622773170471191, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.006031841039657593, 'loss_2': 0.0061187744140625, 'loss_3': -16.387584686279297, 'loss_4': -0.2610448896884918, 'epoch': 29.91}
{'loss': 0.0094, 'grad_norm': 5.1621174812316895, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.0030051339417696, 'loss_2': 0.00638580322265625, 'loss_3': -16.37337303161621, 'loss_4': -0.5643036961555481, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 17:24:17,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:17,099 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:55<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:24,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011101216077804565, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.834, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008404740132391453, 'eval_loss_2': 0.0026964768767356873, 'eval_loss_3': -18.18451690673828, 'eval_loss_4': -0.18833453953266144, 'epoch': 29.91}
{'loss': 0.003, 'grad_norm': 4.58746337890625, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.001259572571143508, 'loss_2': 0.0017414093017578125, 'loss_3': -16.773128509521484, 'loss_4': -0.26809588074684143, 'epoch': 29.92}
{'loss': 0.0124, 'grad_norm': 5.820966720581055, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.010013305582106113, 'loss_2': 0.002391815185546875, 'loss_3': -16.580081939697266, 'loss_4': -0.45469003915786743, 'epoch': 29.92}
{'loss': 0.0044, 'grad_norm': 5.059916019439697, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.0032412426080554724, 'loss_2': 0.0011529922485351562, 'loss_3': -16.411319732666016, 'loss_4': -0.006067976355552673, 'epoch': 29.93}
{'loss': 0.0157, 'grad_norm': 5.26409387588501, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.005883491598069668, 'loss_2': 0.0098419189453125, 'loss_3': -16.294723510742188, 'loss_4': -0.18059563636779785, 'epoch': 29.94}
{'loss': 0.0124, 'grad_norm': 4.415572166442871, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.004650953691452742, 'loss_2': 0.0077056884765625, 'loss_3': -16.739391326904297, 'loss_4': -0.23296058177947998, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 17:24:24,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:24,445 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:07:02<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:31,794 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011163635179400444, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.81, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008445515297353268, 'eval_loss_2': 0.002718120813369751, 'eval_loss_3': -18.184343338012695, 'eval_loss_4': -0.18758393824100494, 'epoch': 29.94}
{'loss': 0.0149, 'grad_norm': 7.6107378005981445, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.011335022747516632, 'loss_2': 0.003528594970703125, 'loss_3': -16.601573944091797, 'loss_4': 0.06030450016260147, 'epoch': 29.95}
{'loss': 0.0121, 'grad_norm': 6.851709842681885, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.007499017287045717, 'loss_2': 0.004642486572265625, 'loss_3': -16.573701858520508, 'loss_4': -0.2373185157775879, 'epoch': 29.95}
{'loss': 0.0036, 'grad_norm': 4.37571382522583, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.0026977257803082466, 'loss_2': 0.0008912086486816406, 'loss_3': -16.649524688720703, 'loss_4': -0.44740521907806396, 'epoch': 29.96}
{'loss': 0.0047, 'grad_norm': 4.47974157333374, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.0038075956981629133, 'loss_2': 0.0009417533874511719, 'loss_3': -16.424026489257812, 'loss_4': -0.38934561610221863, 'epoch': 29.97}
{'loss': 0.0067, 'grad_norm': 5.199081897735596, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.004275238141417503, 'loss_2': 0.0024242401123046875, 'loss_3': -16.55501365661621, 'loss_4': -0.328755259513855, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 17:24:31,794 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:31,794 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:09<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 17:24:38,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011168677359819412, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.707, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008456725627183914, 'eval_loss_2': 0.002711951732635498, 'eval_loss_3': -18.184621810913086, 'eval_loss_4': -0.18724897503852844, 'epoch': 29.97}
{'loss': 0.0138, 'grad_norm': 10.97805404663086, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.011520224623382092, 'loss_2': 0.00225830078125, 'loss_3': -16.57440757751465, 'loss_4': 0.14056822657585144, 'epoch': 29.98}
{'loss': 0.012, 'grad_norm': 6.204044818878174, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.009638655930757523, 'loss_2': 0.002391815185546875, 'loss_3': -16.359619140625, 'loss_4': -0.43726837635040283, 'epoch': 29.98}
{'loss': 0.0051, 'grad_norm': 4.155797481536865, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.0033326218836009502, 'loss_2': 0.0017833709716796875, 'loss_3': -16.517574310302734, 'loss_4': 0.06288308650255203, 'epoch': 29.99}
{'loss': 0.0082, 'grad_norm': 4.55634069442749, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.0029679127037525177, 'loss_2': 0.0052337646484375, 'loss_3': -16.549591064453125, 'loss_4': -0.01882334053516388, 'epoch': 29.99}
{'loss': 0.0047, 'grad_norm': 6.005240440368652, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.003498001489788294, 'loss_2': 0.0011644363403320312, 'loss_3': -16.400829315185547, 'loss_4': -0.3369289040565491, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 17:24:38,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:38,818 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:13<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 17:24:42,784 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.011177069507539272, 'eval_runtime': 3.9658, 'eval_samples_per_second': 258.206, 'eval_steps_per_second': 4.034, 'eval_loss_1': 0.008452987298369408, 'eval_loss_2': 0.00272408127784729, 'eval_loss_3': -18.184642791748047, 'eval_loss_4': -0.1880570352077484, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 17:24:42,785 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/checkpoint-3055 (score: 0.006848055403679609).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:13<00:00,  1.48s/it]
{'train_runtime': 7634.6442, 'train_samples_per_second': 43.138, 'train_steps_per_second': 0.676, 'train_loss': 0.03756641583082215, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 17:24:42,880 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64
[INFO|configuration_utils.py:420] 2025-01-21 17:24:42,881 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 17:24:43,471 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 17:24:43,473 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 17:24:43,473 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg64/special_tokens_map.json
01/21/2025 17:24:43 - INFO - __main__ -   ***** Train results *****
01/21/2025 17:24:43 - INFO - __main__ -     epoch = 30.0
01/21/2025 17:24:43 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 17:24:43 - INFO - __main__ -     train_loss = 0.03756641583082215
01/21/2025 17:24:43 - INFO - __main__ -     train_runtime = 7634.6442
01/21/2025 17:24:43 - INFO - __main__ -     train_samples_per_second = 43.138
01/21/2025 17:24:43 - INFO - __main__ -     train_steps_per_second = 0.676
01/21/2025 17:24:43 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 17:24:43,741 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 17:24:43,741 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:43,741 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.48it/s]
01/21/2025 17:24:47 - INFO - __main__ -   ***** Eval results *****
01/21/2025 17:24:47 - INFO - __main__ -     epoch = 30.0
01/21/2025 17:24:47 - INFO - __main__ -     eval_loss = 0.006848055403679609
01/21/2025 17:24:47 - INFO - __main__ -     eval_loss_1 = 0.0042063104920089245
01/21/2025 17:24:47 - INFO - __main__ -     eval_loss_2 = 0.002641744911670685
01/21/2025 17:24:47 - INFO - __main__ -     eval_loss_3 = -18.243549346923828
01/21/2025 17:24:47 - INFO - __main__ -     eval_loss_4 = 0.9139963388442993
01/21/2025 17:24:47 - INFO - __main__ -     eval_runtime = 3.8708
01/21/2025 17:24:47 - INFO - __main__ -     eval_samples_per_second = 264.548
01/21/2025 17:24:47 - INFO - __main__ -     eval_steps_per_second = 4.134
