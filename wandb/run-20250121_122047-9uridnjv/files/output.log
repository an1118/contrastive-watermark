  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 12:20:48,037 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:06:08,  1.30it/s][INFO|trainer.py:4226] 2025-01-21 12:20:52,252 >>
{'loss': 3.8043, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.7275032997131348, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 4.1277, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 4.044373512268066, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 4.1075, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 4.038660526275635, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.6937, 'grad_norm': 134.0193328857422, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.6270411014556885, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 4.126, 'grad_norm': 118.02704620361328, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 4.052826404571533, 'loss_2': 0.07318115234375, 'loss_3': -13.596857070922852, 'loss_4': 9.473554611206055, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:52,252 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:52,252 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:08<1:06:08,  1.30it/s][INFO|trainer.py:3910] 2025-01-21 12:20:56,046 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 12:20:56,048 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-5/config.json                                                                               
{'eval_loss': 2.250128746032715, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.971, 'eval_steps_per_second': 4.218, 'eval_loss_1': 2.2050161361694336, 'eval_loss_2': 0.04511260986328125, 'eval_loss_3': -18.02210807800293, 'eval_loss_4': 8.568704605102539, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:56,532 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:56,534 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:56,534 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:33:47,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 12:21:00,853 >>
{'loss': 3.9062, 'grad_norm': 135.93687438964844, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.8559718132019043, 'loss_2': 0.05023193359375, 'loss_3': -14.089892387390137, 'loss_4': 9.41438102722168, 'epoch': 0.03}
{'loss': 3.486, 'grad_norm': 130.07284545898438, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 3.4509024620056152, 'loss_2': 0.035125732421875, 'loss_3': -14.53295612335205, 'loss_4': 7.853508949279785, 'epoch': 0.04}
{'loss': 3.3602, 'grad_norm': 119.20144653320312, 'learning_rate': 2.997093023255814e-05, 'loss_1': 3.3196423053741455, 'loss_2': 0.04058837890625, 'loss_3': -14.542590141296387, 'loss_4': 5.187591552734375, 'epoch': 0.05}
{'loss': 3.1217, 'grad_norm': 126.50193786621094, 'learning_rate': 2.996511627906977e-05, 'loss_1': 3.0714287757873535, 'loss_2': 0.05029296875, 'loss_3': -14.538009643554688, 'loss_4': 5.103977203369141, 'epoch': 0.05}
{'loss': 3.0525, 'grad_norm': 125.46253967285156, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.997957706451416, 'loss_2': 0.054534912109375, 'loss_3': -14.863136291503906, 'loss_4': 4.94490385055542, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:00,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:00,853 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:33:47,  1.09s/it][INFO|trainer.py:3910] 2025-01-21 12:21:04,655 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 12:21:04,657 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-10/config.json                                                                              
{'eval_loss': 1.6009161472320557, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 1.552541732788086, 'eval_loss_2': 0.048374176025390625, 'eval_loss_3': -17.814884185791016, 'eval_loss_4': 5.133103370666504, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:05,140 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:05,142 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:05,142 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:05,951 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:38:28,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:21:09,598 >>
{'loss': 2.4584, 'grad_norm': 111.20843505859375, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.4071197509765625, 'loss_2': 0.051239013671875, 'loss_3': -14.9982271194458, 'loss_4': 5.857595443725586, 'epoch': 0.06}
{'loss': 2.5849, 'grad_norm': 118.44728088378906, 'learning_rate': 2.994767441860465e-05, 'loss_1': 2.5224449634552, 'loss_2': 0.062469482421875, 'loss_3': -14.861841201782227, 'loss_4': 4.958071708679199, 'epoch': 0.07}
{'loss': 2.2493, 'grad_norm': 109.29707336425781, 'learning_rate': 2.994186046511628e-05, 'loss_1': 2.1891419887542725, 'loss_2': 0.0601806640625, 'loss_3': -15.088643074035645, 'loss_4': 6.336122989654541, 'epoch': 0.08}
{'loss': 2.1256, 'grad_norm': 112.26738739013672, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 2.0611653327941895, 'loss_2': 0.06439208984375, 'loss_3': -14.965625762939453, 'loss_4': 6.107460975646973, 'epoch': 0.08}
{'loss': 2.0103, 'grad_norm': 131.33233642578125, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.9451415538787842, 'loss_2': 0.065185546875, 'loss_3': -15.332377433776855, 'loss_4': 7.335936069488525, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:09,598 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:09,598 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:38:28,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:21:13,384 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 12:21:13,385 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-15/config.json                                                                              
{'eval_loss': 0.7415499687194824, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.575, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.6743292808532715, 'eval_loss_2': 0.06722068786621094, 'eval_loss_3': -18.07550621032715, 'eval_loss_4': 6.866998195648193, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:13,849 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:13,850 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:13,851 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:14,628 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:38:40,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:21:18,265 >>
{'loss': 2.012, 'grad_norm': 117.19474792480469, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.9352073669433594, 'loss_2': 0.0767822265625, 'loss_3': -15.220259666442871, 'loss_4': 7.316662788391113, 'epoch': 0.09}
{'loss': 1.9419, 'grad_norm': 102.17659759521484, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.8791289329528809, 'loss_2': 0.062744140625, 'loss_3': -15.158401489257812, 'loss_4': 7.131656646728516, 'epoch': 0.1}
{'loss': 1.5982, 'grad_norm': 129.5879364013672, 'learning_rate': 2.991279069767442e-05, 'loss_1': 1.524680733680725, 'loss_2': 0.073486328125, 'loss_3': -15.240254402160645, 'loss_4': 7.33442497253418, 'epoch': 0.1}
{'loss': 1.3794, 'grad_norm': 111.04059600830078, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 1.3339401483535767, 'loss_2': 0.04541015625, 'loss_3': -15.10045337677002, 'loss_4': 6.3434648513793945, 'epoch': 0.11}
{'loss': 1.0285, 'grad_norm': 103.61962127685547, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 0.9781001210212708, 'loss_2': 0.050445556640625, 'loss_3': -15.220621109008789, 'loss_4': 4.986568450927734, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:18,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:18,265 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:38:40,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:21:22,047 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 12:21:22,048 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-20/config.json                                                                              
{'eval_loss': 0.43193602561950684, 'eval_runtime': 3.7802, 'eval_samples_per_second': 270.886, 'eval_steps_per_second': 4.233, 'eval_loss_1': 0.4002320468425751, 'eval_loss_2': 0.031703948974609375, 'eval_loss_3': -17.69528579711914, 'eval_loss_4': 6.48728084564209, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:22,505 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:22,507 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:22,507 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:23,302 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:38<1:38:46,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:21:26,952 >>
{'loss': 1.1074, 'grad_norm': 107.1412124633789, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 1.0788846015930176, 'loss_2': 0.028533935546875, 'loss_3': -14.777685165405273, 'loss_4': 6.127293586730957, 'epoch': 0.12}
{'loss': 0.9717, 'grad_norm': 98.28734588623047, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.9424299001693726, 'loss_2': 0.029266357421875, 'loss_3': -14.620763778686523, 'loss_4': 6.471900939941406, 'epoch': 0.13}
{'loss': 0.5949, 'grad_norm': 77.072998046875, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.5783892869949341, 'loss_2': 0.0165557861328125, 'loss_3': -14.964664459228516, 'loss_4': 6.1648736000061035, 'epoch': 0.13}
{'loss': 0.826, 'grad_norm': 105.41539001464844, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.8170417547225952, 'loss_2': 0.0089569091796875, 'loss_3': -14.826103210449219, 'loss_4': 6.290770530700684, 'epoch': 0.14}
{'loss': 0.6675, 'grad_norm': 79.06739807128906, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.6627116203308105, 'loss_2': 0.004810333251953125, 'loss_3': -14.944731712341309, 'loss_4': 5.376385688781738, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:26,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:26,952 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:42<1:38:46,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:21:30,738 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 12:21:30,739 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-25/config.json                                                                              
{'eval_loss': 0.16352584958076477, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.579, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.1593477576971054, 'eval_loss_2': 0.004178106784820557, 'eval_loss_3': -17.905303955078125, 'eval_loss_4': 5.745938301086426, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:31,199 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:31,200 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:31,200 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:31,995 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:47<1:38:45,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:21:35,643 >>
{'loss': 0.5449, 'grad_norm': 66.07383728027344, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.5399219393730164, 'loss_2': 0.0049896240234375, 'loss_3': -15.140193939208984, 'loss_4': 5.658210754394531, 'epoch': 0.15}
{'loss': 0.7369, 'grad_norm': 80.81830596923828, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.7365305423736572, 'loss_2': 0.0003809928894042969, 'loss_3': -14.825567245483398, 'loss_4': 6.369053840637207, 'epoch': 0.16}
{'loss': 0.4723, 'grad_norm': 66.39337921142578, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.47076696157455444, 'loss_2': 0.001544952392578125, 'loss_3': -14.98862075805664, 'loss_4': 5.577969551086426, 'epoch': 0.16}
{'loss': 0.5254, 'grad_norm': 82.09306335449219, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.524584949016571, 'loss_2': 0.0008373260498046875, 'loss_3': -14.919055938720703, 'loss_4': 5.122225761413574, 'epoch': 0.17}
{'loss': 0.4222, 'grad_norm': 66.23247528076172, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.41428154706954956, 'loss_2': 0.0079345703125, 'loss_3': -14.895113945007324, 'loss_4': 6.26186466217041, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:35,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:35,643 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:51<1:38:45,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:21:39,433 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 12:21:39,434 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-30/config.json                                                                              
{'eval_loss': 0.11230422556400299, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.323, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.10854022204875946, 'eval_loss_2': 0.0037640035152435303, 'eval_loss_3': -17.953540802001953, 'eval_loss_4': 5.188990592956543, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:39,906 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:39,907 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:39,908 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:40,719 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:56<1:38:48,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:21:44,365 >>
{'loss': 0.5771, 'grad_norm': 70.29367065429688, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.5762656331062317, 'loss_2': 0.0008625984191894531, 'loss_3': -14.817292213439941, 'loss_4': 6.7500762939453125, 'epoch': 0.18}
{'loss': 0.4693, 'grad_norm': 60.81560516357422, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.4669401943683624, 'loss_2': 0.002330780029296875, 'loss_3': -14.738212585449219, 'loss_4': 4.56390905380249, 'epoch': 0.19}
{'loss': 0.4741, 'grad_norm': 65.3849105834961, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.4607630670070648, 'loss_2': 0.0133056640625, 'loss_3': -14.694948196411133, 'loss_4': 4.768351078033447, 'epoch': 0.19}
{'loss': 0.3603, 'grad_norm': 49.787086486816406, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.3462122082710266, 'loss_2': 0.01404571533203125, 'loss_3': -14.559301376342773, 'loss_4': 4.611519813537598, 'epoch': 0.2}
{'loss': 0.3737, 'grad_norm': 50.02509307861328, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.3694937825202942, 'loss_2': 0.00417327880859375, 'loss_3': -14.491070747375488, 'loss_4': 5.125795841217041, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:44,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:44,365 >>   Batch size = 64
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:03<1:30:15,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:21:51,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.1493988335132599, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.765, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.1390952169895172, 'eval_loss_2': 0.010303616523742676, 'eval_loss_3': -17.77513313293457, 'eval_loss_4': 4.536643028259277, 'epoch': 0.2}
{'loss': 0.4055, 'grad_norm': 60.25502395629883, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.3936135172843933, 'loss_2': 0.0118560791015625, 'loss_3': -14.650014877319336, 'loss_4': 4.684170722961426, 'epoch': 0.21}
{'loss': 0.3941, 'grad_norm': 51.89042663574219, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.37216201424598694, 'loss_2': 0.02197265625, 'loss_3': -14.538921356201172, 'loss_4': 4.431244850158691, 'epoch': 0.22}
{'loss': 0.4155, 'grad_norm': 67.70529174804688, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.40701737999916077, 'loss_2': 0.0084381103515625, 'loss_3': -14.462754249572754, 'loss_4': 4.499562740325928, 'epoch': 0.22}
{'loss': 0.2293, 'grad_norm': 45.90495681762695, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.217352956533432, 'loss_2': 0.0119171142578125, 'loss_3': -14.688886642456055, 'loss_4': 2.5660672187805176, 'epoch': 0.23}
{'loss': 0.4426, 'grad_norm': 56.194541931152344, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.41425517201423645, 'loss_2': 0.0283660888671875, 'loss_3': -14.557108879089355, 'loss_4': 3.314584255218506, 'epoch': 0.23}
[INFO|trainer.py:4228] 2025-01-21 12:21:51,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:51,709 >>   Batch size = 64
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:07<1:30:15,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:21:55,503 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-40
[INFO|configuration_utils.py:420] 2025-01-21 12:21:55,504 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-40/config.json                                                                              
{'eval_loss': 0.0996871367096901, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.012, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.08281425386667252, 'eval_loss_2': 0.016872882843017578, 'eval_loss_3': -17.78554916381836, 'eval_loss_4': 2.843329668045044, 'epoch': 0.23}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:55,990 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-40/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:55,992 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-40/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:55,992 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-40/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:56,789 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-30] due to args.save_total_limit
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:12<1:37:14,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:22:00,431 >>
{'loss': 0.2088, 'grad_norm': 50.78639221191406, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.2017064392566681, 'loss_2': 0.00711822509765625, 'loss_3': -14.570913314819336, 'loss_4': 2.431772470474243, 'epoch': 0.24}
{'loss': 0.1586, 'grad_norm': 31.566104888916016, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.14317220449447632, 'loss_2': 0.01541900634765625, 'loss_3': -14.41104793548584, 'loss_4': 1.5412688255310059, 'epoch': 0.24}
{'loss': 0.2361, 'grad_norm': 49.90567398071289, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.21851782500743866, 'loss_2': 0.017578125, 'loss_3': -14.70898151397705, 'loss_4': 2.201098918914795, 'epoch': 0.25}
{'loss': 0.3766, 'grad_norm': 50.43867111206055, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.36333590745925903, 'loss_2': 0.01328277587890625, 'loss_3': -14.548547744750977, 'loss_4': 2.970768690109253, 'epoch': 0.26}
{'loss': 0.2949, 'grad_norm': 49.90048599243164, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.280382364988327, 'loss_2': 0.0145263671875, 'loss_3': -14.457765579223633, 'loss_4': 2.9179162979125977, 'epoch': 0.26}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:00,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:00,432 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:16<1:37:14,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 12:22:04,223 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 12:22:04,224 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-45/config.json                                                                              
{'eval_loss': 0.06456218659877777, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.15, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.057613056153059006, 'eval_loss_2': 0.006949134171009064, 'eval_loss_3': -17.98978614807129, 'eval_loss_4': 2.047968626022339, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:04,706 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:04,707 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:04,707 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:05,508 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-40] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:21<1:38:15,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:22:09,151 >>
{'loss': 0.1224, 'grad_norm': 27.27991485595703, 'learning_rate': 2.975e-05, 'loss_1': 0.11729447543621063, 'loss_2': 0.00513458251953125, 'loss_3': -15.03510856628418, 'loss_4': 1.9769108295440674, 'epoch': 0.27}
{'loss': 0.1589, 'grad_norm': 32.42301559448242, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.15721125900745392, 'loss_2': 0.0017147064208984375, 'loss_3': -14.706033706665039, 'loss_4': 1.6523889303207397, 'epoch': 0.27}
{'loss': 0.3019, 'grad_norm': 50.016788482666016, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.29841095209121704, 'loss_2': 0.0034656524658203125, 'loss_3': -14.511570930480957, 'loss_4': 1.4366962909698486, 'epoch': 0.28}
{'loss': 0.2319, 'grad_norm': 41.138343811035156, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.22743196785449982, 'loss_2': 0.0045166015625, 'loss_3': -14.85783576965332, 'loss_4': 2.06685209274292, 'epoch': 0.28}
{'loss': 0.1904, 'grad_norm': 39.671287536621094, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.18565888702869415, 'loss_2': 0.0047149658203125, 'loss_3': -14.580339431762695, 'loss_4': 0.5346152186393738, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:09,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:09,152 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:28<1:29:53,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:22:16,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08174465596675873, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.937, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.06973980367183685, 'eval_loss_2': 0.012004852294921875, 'eval_loss_3': -17.94280433654785, 'eval_loss_4': 1.0751063823699951, 'epoch': 0.29}
{'loss': 0.249, 'grad_norm': 51.636863708496094, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.2401939332485199, 'loss_2': 0.0088043212890625, 'loss_3': -14.818232536315918, 'loss_4': 0.8532930612564087, 'epoch': 0.3}
{'loss': 0.1949, 'grad_norm': 46.19382095336914, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.17811648547649384, 'loss_2': 0.0167388916015625, 'loss_3': -14.796005249023438, 'loss_4': 1.5066643953323364, 'epoch': 0.3}
{'loss': 0.171, 'grad_norm': 28.26004409790039, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.15933167934417725, 'loss_2': 0.01169586181640625, 'loss_3': -14.885841369628906, 'loss_4': 0.969272255897522, 'epoch': 0.31}
{'loss': 0.2155, 'grad_norm': 37.888214111328125, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.210562065243721, 'loss_2': 0.004901885986328125, 'loss_3': -14.68740177154541, 'loss_4': 1.3007798194885254, 'epoch': 0.31}
{'loss': 0.2412, 'grad_norm': 41.49100875854492, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.22747895121574402, 'loss_2': 0.01373291015625, 'loss_3': -14.841768264770508, 'loss_4': 1.4122567176818848, 'epoch': 0.32}
[INFO|trainer.py:4228] 2025-01-21 12:22:16,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:16,491 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:35<1:28:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:22:23,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0662316232919693, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.106, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.05951802805066109, 'eval_loss_2': 0.006713598966598511, 'eval_loss_3': -18.06082534790039, 'eval_loss_4': 1.6972304582595825, 'epoch': 0.32}
{'loss': 0.1345, 'grad_norm': 32.17354965209961, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.1342383176088333, 'loss_2': 0.000232696533203125, 'loss_3': -15.049782752990723, 'loss_4': 1.353943109512329, 'epoch': 0.33}
{'loss': 0.2054, 'grad_norm': 39.15300369262695, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.20394185185432434, 'loss_2': 0.001415252685546875, 'loss_3': -15.150871276855469, 'loss_4': 2.2183890342712402, 'epoch': 0.33}
{'loss': 0.144, 'grad_norm': 29.58854866027832, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.14236363768577576, 'loss_2': 0.0016794204711914062, 'loss_3': -14.751858711242676, 'loss_4': 2.062652111053467, 'epoch': 0.34}
{'loss': 0.2243, 'grad_norm': 43.30567169189453, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.2230529934167862, 'loss_2': 0.001270294189453125, 'loss_3': -14.912681579589844, 'loss_4': 2.5125491619110107, 'epoch': 0.34}
{'loss': 0.1608, 'grad_norm': 45.83287811279297, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.15863962471485138, 'loss_2': 0.002124786376953125, 'loss_3': -14.812871932983398, 'loss_4': 2.175374746322632, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 12:22:23,835 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:23,835 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:39<1:28:32,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:22:27,637 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-60
[INFO|configuration_utils.py:420] 2025-01-21 12:22:27,639 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-60/config.json                                                                              
{'eval_loss': 0.0642426609992981, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.386, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.05421024188399315, 'eval_loss_2': 0.010032415390014648, 'eval_loss_3': -18.07834243774414, 'eval_loss_4': 2.6486315727233887, 'epoch': 0.35}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:28,132 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-60/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:28,133 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:28,134 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-60/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:28,914 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-45] due to args.save_total_limit
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:44<1:36:39,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:22:32,555 >>
{'loss': 0.2507, 'grad_norm': 36.050838470458984, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.2338864505290985, 'loss_2': 0.0167694091796875, 'loss_3': -14.848031997680664, 'loss_4': 2.3603973388671875, 'epoch': 0.35}
{'loss': 0.1849, 'grad_norm': 38.4930419921875, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.17103925347328186, 'loss_2': 0.0138397216796875, 'loss_3': -14.931864738464355, 'loss_4': 3.130197763442993, 'epoch': 0.36}
{'loss': 0.1232, 'grad_norm': 26.16222381591797, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.11271365731954575, 'loss_2': 0.01052093505859375, 'loss_3': -15.043249130249023, 'loss_4': 2.603187084197998, 'epoch': 0.37}
{'loss': 0.1902, 'grad_norm': 39.47121047973633, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.1823938637971878, 'loss_2': 0.0078277587890625, 'loss_3': -14.779587745666504, 'loss_4': 3.837268352508545, 'epoch': 0.37}
{'loss': 0.1749, 'grad_norm': 41.20644760131836, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.16766685247421265, 'loss_2': 0.007266998291015625, 'loss_3': -14.730862617492676, 'loss_4': 3.712878704071045, 'epoch': 0.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:32,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:32,555 >>   Batch size = 64
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:48<1:36:39,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 12:22:36,346 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-65
[INFO|configuration_utils.py:420] 2025-01-21 12:22:36,347 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-65/config.json                                                                              
{'eval_loss': 0.056428078562021255, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.197, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.05070830136537552, 'eval_loss_2': 0.005719780921936035, 'eval_loss_3': -18.128267288208008, 'eval_loss_4': 3.246251344680786, 'epoch': 0.38}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:36,847 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-65/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:36,848 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-65/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:36,849 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-65/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:37,661 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-60] due to args.save_total_limit
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:53<1:38:05,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:22:41,308 >>
{'loss': 0.1455, 'grad_norm': 28.232280731201172, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.13365770876407623, 'loss_2': 0.01181793212890625, 'loss_3': -15.076277732849121, 'loss_4': 2.8662962913513184, 'epoch': 0.38}
{'loss': 0.2468, 'grad_norm': 51.172462463378906, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.2441260814666748, 'loss_2': 0.00269317626953125, 'loss_3': -14.911815643310547, 'loss_4': 3.646975040435791, 'epoch': 0.39}
{'loss': 0.3481, 'grad_norm': 55.17232131958008, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.34247714281082153, 'loss_2': 0.005580902099609375, 'loss_3': -15.013986587524414, 'loss_4': 3.2578423023223877, 'epoch': 0.4}
{'loss': 0.1947, 'grad_norm': 41.49041748046875, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.18005716800689697, 'loss_2': 0.014678955078125, 'loss_3': -14.785876274108887, 'loss_4': 3.738874673843384, 'epoch': 0.4}
{'loss': 0.1753, 'grad_norm': 42.9735107421875, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.17229650914669037, 'loss_2': 0.0030364990234375, 'loss_3': -15.216177940368652, 'loss_4': 3.1536197662353516, 'epoch': 0.41}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:41,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:41,309 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:00<1:29:43,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:22:48,656 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05783556401729584, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.072, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.04889511317014694, 'eval_loss_2': 0.008940458297729492, 'eval_loss_3': -18.174171447753906, 'eval_loss_4': 3.0406064987182617, 'epoch': 0.41}
{'loss': 0.2407, 'grad_norm': 39.968048095703125, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.2337569296360016, 'loss_2': 0.006927490234375, 'loss_3': -15.086456298828125, 'loss_4': 3.289691686630249, 'epoch': 0.41}
{'loss': 0.2268, 'grad_norm': 37.15277862548828, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.20460884273052216, 'loss_2': 0.022216796875, 'loss_3': -14.878833770751953, 'loss_4': 3.0994081497192383, 'epoch': 0.42}
{'loss': 0.276, 'grad_norm': 45.87910842895508, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.2596302628517151, 'loss_2': 0.0163726806640625, 'loss_3': -15.018281936645508, 'loss_4': 3.4424519538879395, 'epoch': 0.42}
{'loss': 0.172, 'grad_norm': 27.595436096191406, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.16619952023029327, 'loss_2': 0.00576019287109375, 'loss_3': -14.997781753540039, 'loss_4': 2.7930333614349365, 'epoch': 0.43}
{'loss': 0.153, 'grad_norm': 31.531877517700195, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.15105772018432617, 'loss_2': 0.0019130706787109375, 'loss_3': -15.017412185668945, 'loss_4': 3.204582691192627, 'epoch': 0.44}
[INFO|trainer.py:4228] 2025-01-21 12:22:48,656 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:48,656 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:04<1:29:43,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:22:52,452 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-75
[INFO|configuration_utils.py:420] 2025-01-21 12:22:52,453 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-75/config.json                                                                              
{'eval_loss': 0.05120858550071716, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.889, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.047889240086078644, 'eval_loss_2': 0.0033193491399288177, 'eval_loss_3': -18.13018226623535, 'eval_loss_4': 3.2485737800598145, 'epoch': 0.44}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:52,928 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-75/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:52,929 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-75/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:52,930 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-75/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:53,721 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-65] due to args.save_total_limit
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:36:29,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:22:57,365 >>
{'loss': 0.1922, 'grad_norm': 38.54948043823242, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.18943719565868378, 'loss_2': 0.00279998779296875, 'loss_3': -15.078248977661133, 'loss_4': 3.5847718715667725, 'epoch': 0.44}
{'loss': 0.1689, 'grad_norm': 26.9092960357666, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.16323420405387878, 'loss_2': 0.0056304931640625, 'loss_3': -14.854512214660645, 'loss_4': 2.478327751159668, 'epoch': 0.45}
{'loss': 0.2203, 'grad_norm': 31.064208984375, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.20538939535617828, 'loss_2': 0.014923095703125, 'loss_3': -14.93687915802002, 'loss_4': 3.1883435249328613, 'epoch': 0.45}
{'loss': 0.2166, 'grad_norm': 37.263309478759766, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.21058200299739838, 'loss_2': 0.006038665771484375, 'loss_3': -15.096242904663086, 'loss_4': 3.710132122039795, 'epoch': 0.46}
{'loss': 0.2366, 'grad_norm': 52.43048858642578, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.22632166743278503, 'loss_2': 0.01031494140625, 'loss_3': -14.876214981079102, 'loss_4': 3.137669801712036, 'epoch': 0.47}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:57,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:57,365 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:16<1:29:21,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:23:04,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07890883088111877, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.684, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.06165733560919762, 'eval_loss_2': 0.01725149154663086, 'eval_loss_3': -17.97837257385254, 'eval_loss_4': 3.1207022666931152, 'epoch': 0.47}
{'loss': 0.1642, 'grad_norm': 30.523239135742188, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.14551985263824463, 'loss_2': 0.0186767578125, 'loss_3': -14.837743759155273, 'loss_4': 3.130462408065796, 'epoch': 0.47}
{'loss': 0.1794, 'grad_norm': 37.784908294677734, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.1604742556810379, 'loss_2': 0.0189208984375, 'loss_3': -14.645079612731934, 'loss_4': 2.4344873428344727, 'epoch': 0.48}
{'loss': 0.2046, 'grad_norm': 42.016056060791016, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.18940886855125427, 'loss_2': 0.01514434814453125, 'loss_3': -14.882465362548828, 'loss_4': 2.523120403289795, 'epoch': 0.48}
{'loss': 0.1761, 'grad_norm': 42.10242462158203, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.17101478576660156, 'loss_2': 0.00504302978515625, 'loss_3': -14.771440505981445, 'loss_4': 2.232971668243408, 'epoch': 0.49}
{'loss': 0.1826, 'grad_norm': 41.15009689331055, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.17538608610630035, 'loss_2': 0.007228851318359375, 'loss_3': -14.56332778930664, 'loss_4': 3.5407729148864746, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 12:23:04,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:04,716 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:20<1:29:21,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:23:08,508 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-85
[INFO|configuration_utils.py:420] 2025-01-21 12:23:08,509 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-85/config.json                                                                              
{'eval_loss': 0.047303587198257446, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.094, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.039947837591171265, 'eval_loss_2': 0.007355749607086182, 'eval_loss_3': -17.9628963470459, 'eval_loss_4': 2.5186173915863037, 'epoch': 0.49}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:09,034 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-85/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:09,035 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-85/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:09,036 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-85/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:09,817 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-75] due to args.save_total_limit
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:25<1:36:32,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:23:13,461 >>
{'loss': 0.1483, 'grad_norm': 34.23490905761719, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.13991563022136688, 'loss_2': 0.0084228515625, 'loss_3': -14.624136924743652, 'loss_4': 2.963949203491211, 'epoch': 0.5}
{'loss': 0.0813, 'grad_norm': 23.618337631225586, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.07998936623334885, 'loss_2': 0.0013065338134765625, 'loss_3': -14.679668426513672, 'loss_4': 2.67075777053833, 'epoch': 0.51}
{'loss': 0.1667, 'grad_norm': 38.90109634399414, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.1542419195175171, 'loss_2': 0.012481689453125, 'loss_3': -14.763019561767578, 'loss_4': 2.5342278480529785, 'epoch': 0.51}
{'loss': 0.1385, 'grad_norm': 27.94157600402832, 'learning_rate': 2.95e-05, 'loss_1': 0.13321931660175323, 'loss_2': 0.00531768798828125, 'loss_3': -14.814291000366211, 'loss_4': 2.922182559967041, 'epoch': 0.52}
{'loss': 0.1017, 'grad_norm': 23.997560501098633, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.09142360091209412, 'loss_2': 0.01031494140625, 'loss_3': -14.84432315826416, 'loss_4': 2.992417812347412, 'epoch': 0.52}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:13,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:13,462 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:29<1:36:32,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 12:23:17,254 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-90
[INFO|configuration_utils.py:420] 2025-01-21 12:23:17,256 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-90/config.json                                                                              
{'eval_loss': 0.042792197316884995, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.083, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.035547129809856415, 'eval_loss_2': 0.007245063781738281, 'eval_loss_3': -17.994705200195312, 'eval_loss_4': 2.201451301574707, 'epoch': 0.52}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:17,739 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-90/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:17,741 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-90/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:17,741 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-90/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:18,540 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-85] due to args.save_total_limit
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:34<1:37:34,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:23:22,195 >>
{'loss': 0.169, 'grad_norm': 49.981990814208984, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.15701940655708313, 'loss_2': 0.0119781494140625, 'loss_3': -14.647315979003906, 'loss_4': 3.191221237182617, 'epoch': 0.53}
{'loss': 0.0776, 'grad_norm': 16.528316497802734, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.06648780405521393, 'loss_2': 0.01108551025390625, 'loss_3': -14.952524185180664, 'loss_4': 2.7856884002685547, 'epoch': 0.53}
{'loss': 0.1662, 'grad_norm': 34.08406448364258, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.15027649700641632, 'loss_2': 0.015899658203125, 'loss_3': -14.934621810913086, 'loss_4': 3.187657594680786, 'epoch': 0.54}
{'loss': 0.2457, 'grad_norm': 37.47974395751953, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.24447737634181976, 'loss_2': 0.0012149810791015625, 'loss_3': -14.738234519958496, 'loss_4': 2.5916032791137695, 'epoch': 0.55}
{'loss': 0.2223, 'grad_norm': 43.66791534423828, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.22208312153816223, 'loss_2': 0.00018095970153808594, 'loss_3': -14.538431167602539, 'loss_4': 3.2990503311157227, 'epoch': 0.55}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:22,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:22,195 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:41<1:29:11,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:23:29,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04939693212509155, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.033, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.040321797132492065, 'eval_loss_2': 0.009075134992599487, 'eval_loss_3': -18.063631057739258, 'eval_loss_4': 1.981634497642517, 'epoch': 0.55}
{'loss': 0.2036, 'grad_norm': 43.19901657104492, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.19933120906352997, 'loss_2': 0.004241943359375, 'loss_3': -14.809444427490234, 'loss_4': 2.5648040771484375, 'epoch': 0.56}
{'loss': 0.1113, 'grad_norm': 25.35922622680664, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.09755489230155945, 'loss_2': 0.01371002197265625, 'loss_3': -14.642724990844727, 'loss_4': 2.0055243968963623, 'epoch': 0.56}
{'loss': 0.187, 'grad_norm': 34.21860885620117, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.1763371229171753, 'loss_2': 0.010650634765625, 'loss_3': -14.769043922424316, 'loss_4': 2.1791162490844727, 'epoch': 0.57}
{'loss': 0.2227, 'grad_norm': 47.28987503051758, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.2052728533744812, 'loss_2': 0.0174713134765625, 'loss_3': -14.724050521850586, 'loss_4': 2.079383373260498, 'epoch': 0.58}
{'loss': 0.1397, 'grad_norm': 33.64071273803711, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.12953758239746094, 'loss_2': 0.01019287109375, 'loss_3': -14.821913719177246, 'loss_4': 2.0813703536987305, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 12:23:29,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:29,536 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:48<1:27:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:36,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05217805504798889, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.855, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.033967647701501846, 'eval_loss_2': 0.018210411071777344, 'eval_loss_3': -18.020143508911133, 'eval_loss_4': 1.419494867324829, 'epoch': 0.58}
{'loss': 0.1403, 'grad_norm': 27.459335327148438, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.12938080728054047, 'loss_2': 0.01094818115234375, 'loss_3': -14.864190101623535, 'loss_4': 1.743988037109375, 'epoch': 0.59}
{'loss': 0.1109, 'grad_norm': 20.330368041992188, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.10438457876443863, 'loss_2': 0.00647735595703125, 'loss_3': -14.81208610534668, 'loss_4': 1.4694498777389526, 'epoch': 0.59}
{'loss': 0.1617, 'grad_norm': 37.9220085144043, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.15626969933509827, 'loss_2': 0.005382537841796875, 'loss_3': -14.773527145385742, 'loss_4': 2.4672677516937256, 'epoch': 0.6}
{'loss': 0.155, 'grad_norm': 29.879966735839844, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.15133772790431976, 'loss_2': 0.003681182861328125, 'loss_3': -15.102039337158203, 'loss_4': 1.6177133321762085, 'epoch': 0.6}
{'loss': 0.1895, 'grad_norm': 42.91944122314453, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.18819975852966309, 'loss_2': 0.0012722015380859375, 'loss_3': -14.910391807556152, 'loss_4': 1.9136804342269897, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 12:23:36,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:36,892 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:56<1:27:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:44,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06697758287191391, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.016, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0615064799785614, 'eval_loss_2': 0.0054711103439331055, 'eval_loss_3': -17.90755271911621, 'eval_loss_4': 1.2615058422088623, 'epoch': 0.61}
{'loss': 0.1086, 'grad_norm': 23.95836639404297, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.10686219483613968, 'loss_2': 0.0017871856689453125, 'loss_3': -14.918550491333008, 'loss_4': 1.5235891342163086, 'epoch': 0.62}
{'loss': 0.3568, 'grad_norm': 54.055076599121094, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.35188496112823486, 'loss_2': 0.00495147705078125, 'loss_3': -14.818928718566895, 'loss_4': 1.9993162155151367, 'epoch': 0.62}
{'loss': 0.1226, 'grad_norm': 31.386381149291992, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.12174195796251297, 'loss_2': 0.000881195068359375, 'loss_3': -14.927512168884277, 'loss_4': 1.3315030336380005, 'epoch': 0.63}
{'loss': 0.1349, 'grad_norm': 21.683805465698242, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.12541785836219788, 'loss_2': 0.00943756103515625, 'loss_3': -14.933969497680664, 'loss_4': 1.065688133239746, 'epoch': 0.63}
{'loss': 0.1156, 'grad_norm': 29.659311294555664, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.11392329633235931, 'loss_2': 0.0016384124755859375, 'loss_3': -14.976810455322266, 'loss_4': 1.3542646169662476, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 12:23:44,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:44,241 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [03:00<1:27:33,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:23:48,038 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-110
[INFO|configuration_utils.py:420] 2025-01-21 12:23:48,039 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-110/config.json                                                                             
{'eval_loss': 0.04160546511411667, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.789, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.03794994205236435, 'eval_loss_2': 0.0036555230617523193, 'eval_loss_3': -18.09360694885254, 'eval_loss_4': 0.6575688123703003, 'epoch': 0.64}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:48,522 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-110/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:48,523 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-110/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:48,523 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-110/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:49,350 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-90] due to args.save_total_limit
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:04<1:35:53,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:23:52,993 >>
{'loss': 0.3043, 'grad_norm': 43.93282699584961, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.29909321665763855, 'loss_2': 0.005237579345703125, 'loss_3': -15.081514358520508, 'loss_4': 1.7040609121322632, 'epoch': 0.65}
{'loss': 0.2322, 'grad_norm': 33.050899505615234, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.2295207381248474, 'loss_2': 0.00272369384765625, 'loss_3': -14.870362281799316, 'loss_4': 1.8599374294281006, 'epoch': 0.65}
{'loss': 0.1277, 'grad_norm': 25.622718811035156, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.1271558254957199, 'loss_2': 0.0005717277526855469, 'loss_3': -15.002859115600586, 'loss_4': 1.3084092140197754, 'epoch': 0.66}
{'loss': 0.1561, 'grad_norm': 32.15142822265625, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.14926810562610626, 'loss_2': 0.006839752197265625, 'loss_3': -14.989776611328125, 'loss_4': 1.0801588296890259, 'epoch': 0.66}
{'loss': 0.0865, 'grad_norm': 18.967815399169922, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.0844467431306839, 'loss_2': 0.0020885467529296875, 'loss_3': -15.020519256591797, 'loss_4': 1.0445826053619385, 'epoch': 0.67}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:52,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:52,994 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:08<1:35:53,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 12:23:56,790 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-115
[INFO|configuration_utils.py:420] 2025-01-21 12:23:56,791 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-115/config.json                                                                             
{'eval_loss': 0.0377507284283638, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.805, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.032298773527145386, 'eval_loss_2': 0.005451954901218414, 'eval_loss_3': -18.122329711914062, 'eval_loss_4': 0.6791898608207703, 'epoch': 0.67}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:57,270 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-115/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:57,272 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-115/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:57,272 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-115/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:58,068 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-110] due to args.save_total_limit
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:13<1:36:53,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:24:01,713 >>
{'loss': 0.1644, 'grad_norm': 36.42057800292969, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.16296540200710297, 'loss_2': 0.0014276504516601562, 'loss_3': -15.119574546813965, 'loss_4': 1.7490849494934082, 'epoch': 0.67}
{'loss': 0.093, 'grad_norm': 20.122037887573242, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.08743417263031006, 'loss_2': 0.005573272705078125, 'loss_3': -15.1185941696167, 'loss_4': 0.5079507231712341, 'epoch': 0.68}
{'loss': 0.1109, 'grad_norm': 31.89809799194336, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.10520834475755692, 'loss_2': 0.00571441650390625, 'loss_3': -14.775579452514648, 'loss_4': 1.2439520359039307, 'epoch': 0.69}
{'loss': 0.1195, 'grad_norm': 31.233522415161133, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.10875242948532104, 'loss_2': 0.0107879638671875, 'loss_3': -15.028191566467285, 'loss_4': 1.6896048784255981, 'epoch': 0.69}
{'loss': 0.0886, 'grad_norm': 20.213144302368164, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.0854024738073349, 'loss_2': 0.0032024383544921875, 'loss_3': -14.98391342163086, 'loss_4': 1.5103769302368164, 'epoch': 0.7}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:01,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:01,713 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:21<1:28:47,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:24:09,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06414730101823807, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.863, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.05892834812402725, 'eval_loss_2': 0.005218952894210815, 'eval_loss_3': -17.897043228149414, 'eval_loss_4': 1.355316162109375, 'epoch': 0.7}
{'loss': 0.0655, 'grad_norm': 20.045650482177734, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.06457419693470001, 'loss_2': 0.0009598731994628906, 'loss_3': -14.933998107910156, 'loss_4': 1.3563294410705566, 'epoch': 0.7}
{'loss': 0.1119, 'grad_norm': 26.53169059753418, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.10988402366638184, 'loss_2': 0.0019683837890625, 'loss_3': -14.753984451293945, 'loss_4': 2.3113131523132324, 'epoch': 0.71}
{'loss': 0.1544, 'grad_norm': 30.19076919555664, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.15195411443710327, 'loss_2': 0.002422332763671875, 'loss_3': -14.657838821411133, 'loss_4': 1.8994507789611816, 'epoch': 0.72}
{'loss': 0.0895, 'grad_norm': 21.966697692871094, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.0796353816986084, 'loss_2': 0.0098419189453125, 'loss_3': -15.226301193237305, 'loss_4': 1.5070619583129883, 'epoch': 0.72}
{'loss': 0.0805, 'grad_norm': 20.199766159057617, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.07704989612102509, 'loss_2': 0.0034389495849609375, 'loss_3': -14.851022720336914, 'loss_4': 1.71370267868042, 'epoch': 0.73}
[INFO|trainer.py:4228] 2025-01-21 12:24:09,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:09,060 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:28<1:27:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:16,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07286567240953445, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.031, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.07014991343021393, 'eval_loss_2': 0.002715766429901123, 'eval_loss_3': -17.876224517822266, 'eval_loss_4': 2.013721466064453, 'epoch': 0.73}
{'loss': 0.0736, 'grad_norm': 19.284868240356445, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.0698104053735733, 'loss_2': 0.00379180908203125, 'loss_3': -14.971660614013672, 'loss_4': 1.380842924118042, 'epoch': 0.73}
{'loss': 0.1297, 'grad_norm': 25.020967483520508, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.12939628958702087, 'loss_2': 0.00030493736267089844, 'loss_3': -14.871620178222656, 'loss_4': 2.0369696617126465, 'epoch': 0.74}
{'loss': 0.1235, 'grad_norm': 30.183258056640625, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.11792989820241928, 'loss_2': 0.005584716796875, 'loss_3': -14.767837524414062, 'loss_4': 1.8133540153503418, 'epoch': 0.74}
{'loss': 0.1535, 'grad_norm': 28.132768630981445, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.13990579545497894, 'loss_2': 0.0135955810546875, 'loss_3': -15.079075813293457, 'loss_4': 2.549792528152466, 'epoch': 0.75}
{'loss': 0.1054, 'grad_norm': 25.881696701049805, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.10390906780958176, 'loss_2': 0.00144195556640625, 'loss_3': -14.77151107788086, 'loss_4': 2.4780707359313965, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 12:24:16,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:16,404 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:35<1:27:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:23,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07453904300928116, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.741, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.06635258346796036, 'eval_loss_2': 0.0081864595413208, 'eval_loss_3': -17.941051483154297, 'eval_loss_4': 2.519965648651123, 'epoch': 0.76}
{'loss': 0.1923, 'grad_norm': 49.913108825683594, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.18255320191383362, 'loss_2': 0.009796142578125, 'loss_3': -14.935977935791016, 'loss_4': 2.6975913047790527, 'epoch': 0.76}
{'loss': 0.0919, 'grad_norm': 25.59870719909668, 'learning_rate': 2.925e-05, 'loss_1': 0.08833424001932144, 'loss_2': 0.00360870361328125, 'loss_3': -15.070795059204102, 'loss_4': 2.328334093093872, 'epoch': 0.77}
{'loss': 0.1525, 'grad_norm': 39.15266036987305, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.15180222690105438, 'loss_2': 0.00067138671875, 'loss_3': -15.02871322631836, 'loss_4': 2.4929463863372803, 'epoch': 0.77}
{'loss': 0.0826, 'grad_norm': 23.549772262573242, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.08190953731536865, 'loss_2': 0.0007390975952148438, 'loss_3': -15.106040954589844, 'loss_4': 2.5742509365081787, 'epoch': 0.78}
{'loss': 0.2049, 'grad_norm': 43.44506072998047, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.20246851444244385, 'loss_2': 0.0024261474609375, 'loss_3': -14.899669647216797, 'loss_4': 3.114182233810425, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 12:24:23,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:23,763 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:39<1:27:06,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:24:27,558 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-135
[INFO|configuration_utils.py:420] 2025-01-21 12:24:27,560 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-135/config.json                                                                             
{'eval_loss': 0.03448782488703728, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.933, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.03133043646812439, 'eval_loss_2': 0.003157384693622589, 'eval_loss_3': -18.12442398071289, 'eval_loss_4': 2.6111950874328613, 'epoch': 0.78}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:28,032 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-135/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:28,033 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-135/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:28,033 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-135/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:28,826 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-115] due to args.save_total_limit
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:44<1:35:04,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:24:32,466 >>
{'loss': 0.1435, 'grad_norm': 37.109500885009766, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.14144524931907654, 'loss_2': 0.002086639404296875, 'loss_3': -15.021910667419434, 'loss_4': 2.6828081607818604, 'epoch': 0.79}
{'loss': 0.1235, 'grad_norm': 30.84604263305664, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.12203331291675568, 'loss_2': 0.0014972686767578125, 'loss_3': -15.148382186889648, 'loss_4': 3.175717830657959, 'epoch': 0.8}
{'loss': 0.1029, 'grad_norm': 23.18990135192871, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.10213445872068405, 'loss_2': 0.0007266998291015625, 'loss_3': -15.098648071289062, 'loss_4': 3.45318341255188, 'epoch': 0.8}
{'loss': 0.0745, 'grad_norm': 16.573923110961914, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.07203661650419235, 'loss_2': 0.00246429443359375, 'loss_3': -15.244302749633789, 'loss_4': 2.971921920776367, 'epoch': 0.81}
{'loss': 0.0642, 'grad_norm': 16.106393814086914, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.06207505613565445, 'loss_2': 0.002086639404296875, 'loss_3': -15.264122009277344, 'loss_4': 2.938192844390869, 'epoch': 0.81}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:32,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:32,466 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:51<1:28:11,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:24:39,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04149630293250084, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.79, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.030461367219686508, 'eval_loss_2': 0.011034935712814331, 'eval_loss_3': -18.177583694458008, 'eval_loss_4': 2.5654783248901367, 'epoch': 0.81}
{'loss': 0.0722, 'grad_norm': 21.034141540527344, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.05906258523464203, 'loss_2': 0.013092041015625, 'loss_3': -14.946093559265137, 'loss_4': 2.210402250289917, 'epoch': 0.82}
{'loss': 0.0634, 'grad_norm': 13.357283592224121, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.054177820682525635, 'loss_2': 0.0092010498046875, 'loss_3': -15.07446575164795, 'loss_4': 3.093625783920288, 'epoch': 0.83}
{'loss': 0.0785, 'grad_norm': 17.462738037109375, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.06823409348726273, 'loss_2': 0.01029205322265625, 'loss_3': -14.9570894241333, 'loss_4': 2.5912880897521973, 'epoch': 0.83}
{'loss': 0.1552, 'grad_norm': 29.20557403564453, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.13218015432357788, 'loss_2': 0.022979736328125, 'loss_3': -15.148906707763672, 'loss_4': 2.6314659118652344, 'epoch': 0.84}
{'loss': 0.1227, 'grad_norm': 23.986478805541992, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.1080278754234314, 'loss_2': 0.01464080810546875, 'loss_3': -15.268709182739258, 'loss_4': 3.5452795028686523, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 12:24:39,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:39,815 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:59<1:26:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:47,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.043161336332559586, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.925, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.026501117274165154, 'eval_loss_2': 0.016660213470458984, 'eval_loss_3': -18.221786499023438, 'eval_loss_4': 2.089263439178467, 'epoch': 0.84}
{'loss': 0.172, 'grad_norm': 27.318811416625977, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.16030822694301605, 'loss_2': 0.0116729736328125, 'loss_3': -15.064725875854492, 'loss_4': 2.3494138717651367, 'epoch': 0.85}
{'loss': 0.1519, 'grad_norm': 30.499614715576172, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.14380961656570435, 'loss_2': 0.0080413818359375, 'loss_3': -15.206181526184082, 'loss_4': 3.0961458683013916, 'epoch': 0.85}
{'loss': 0.0914, 'grad_norm': 20.843769073486328, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.08187209069728851, 'loss_2': 0.00957489013671875, 'loss_3': -15.273176193237305, 'loss_4': 2.051215648651123, 'epoch': 0.86}
{'loss': 0.0947, 'grad_norm': 17.47812271118164, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.08313030004501343, 'loss_2': 0.01153564453125, 'loss_3': -15.03984260559082, 'loss_4': 2.1503138542175293, 'epoch': 0.87}
{'loss': 0.0737, 'grad_norm': 15.604220390319824, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.0691676214337349, 'loss_2': 0.0045318603515625, 'loss_3': -15.087949752807617, 'loss_4': 1.6427770853042603, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 12:24:47,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:47,159 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [04:02<1:26:54,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:24:50,954 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-150
[INFO|configuration_utils.py:420] 2025-01-21 12:24:50,955 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-150/config.json                                                                             
{'eval_loss': 0.031036771833896637, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.96, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02628847025334835, 'eval_loss_2': 0.004748299717903137, 'eval_loss_3': -18.201339721679688, 'eval_loss_4': 1.4303488731384277, 'epoch': 0.87}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:51,448 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-150/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:51,449 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:51,449 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-150/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:52,260 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-135] due to args.save_total_limit
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:07<1:35:01,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:24:55,902 >>
{'loss': 0.0976, 'grad_norm': 21.76350975036621, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.09228891134262085, 'loss_2': 0.0053253173828125, 'loss_3': -15.162789344787598, 'loss_4': 1.7829153537750244, 'epoch': 0.88}
{'loss': 0.123, 'grad_norm': 29.705352783203125, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.11707327514886856, 'loss_2': 0.00594329833984375, 'loss_3': -15.153559684753418, 'loss_4': 1.0775012969970703, 'epoch': 0.88}
{'loss': 0.164, 'grad_norm': 33.65090560913086, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.15741164982318878, 'loss_2': 0.006580352783203125, 'loss_3': -15.026697158813477, 'loss_4': 1.3390053510665894, 'epoch': 0.89}
{'loss': 0.187, 'grad_norm': 36.69879150390625, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.17604264616966248, 'loss_2': 0.0110015869140625, 'loss_3': -15.224191665649414, 'loss_4': 1.6205042600631714, 'epoch': 0.9}
{'loss': 0.12, 'grad_norm': 24.26283073425293, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.09632180631160736, 'loss_2': 0.0237274169921875, 'loss_3': -15.275655746459961, 'loss_4': 1.5138912200927734, 'epoch': 0.9}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:55,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:55,903 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:15<1:27:53,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:25:03,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04618161544203758, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.837, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0292848888784647, 'eval_loss_2': 0.016896724700927734, 'eval_loss_3': -18.135801315307617, 'eval_loss_4': 1.2134782075881958, 'epoch': 0.9}
{'loss': 0.0869, 'grad_norm': 15.15402603149414, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.06522117555141449, 'loss_2': 0.0216827392578125, 'loss_3': -15.119712829589844, 'loss_4': 0.6433927416801453, 'epoch': 0.91}
{'loss': 0.1354, 'grad_norm': 21.34916877746582, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.10261714458465576, 'loss_2': 0.03277587890625, 'loss_3': -15.233620643615723, 'loss_4': 1.4069416522979736, 'epoch': 0.91}
{'loss': 0.2318, 'grad_norm': 41.877601623535156, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.2199704647064209, 'loss_2': 0.011810302734375, 'loss_3': -15.286600112915039, 'loss_4': 1.4443377256393433, 'epoch': 0.92}
{'loss': 0.1059, 'grad_norm': 19.58875846862793, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.0844733938574791, 'loss_2': 0.0214080810546875, 'loss_3': -15.086248397827148, 'loss_4': 1.2569819688796997, 'epoch': 0.92}
{'loss': 0.0706, 'grad_norm': 19.145137786865234, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.05801716074347496, 'loss_2': 0.012542724609375, 'loss_3': -15.311338424682617, 'loss_4': 1.369887113571167, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 12:25:03,242 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:03,242 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:22<1:26:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:10,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04314250499010086, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.727, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.036518942564725876, 'eval_loss_2': 0.006623566150665283, 'eval_loss_3': -18.06053924560547, 'eval_loss_4': 1.2051814794540405, 'epoch': 0.93}
{'loss': 0.0887, 'grad_norm': 20.81572914123535, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.08156153559684753, 'loss_2': 0.00716400146484375, 'loss_3': -15.292516708374023, 'loss_4': 1.0357664823532104, 'epoch': 0.94}
{'loss': 0.0475, 'grad_norm': 11.855647087097168, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.03746866062283516, 'loss_2': 0.0100555419921875, 'loss_3': -15.185993194580078, 'loss_4': 1.0447636842727661, 'epoch': 0.94}
{'loss': 0.1404, 'grad_norm': 36.36830139160156, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.1391567885875702, 'loss_2': 0.001216888427734375, 'loss_3': -15.077841758728027, 'loss_4': 1.2906615734100342, 'epoch': 0.95}
{'loss': 0.0758, 'grad_norm': 20.413028717041016, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.06926126778125763, 'loss_2': 0.006500244140625, 'loss_3': -15.31588363647461, 'loss_4': 1.2771673202514648, 'epoch': 0.95}
{'loss': 0.1397, 'grad_norm': 24.80838966369629, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.12378250062465668, 'loss_2': 0.01593017578125, 'loss_3': -14.973013877868652, 'loss_4': 1.2227367162704468, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 12:25:10,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:10,592 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:29<1:26:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:17,947 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04744355380535126, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0361509770154953, 'eval_loss_2': 0.011292576789855957, 'eval_loss_3': -17.997234344482422, 'eval_loss_4': 1.315272569656372, 'epoch': 0.96}
{'loss': 0.1015, 'grad_norm': 23.98297119140625, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.08830206841230392, 'loss_2': 0.01324462890625, 'loss_3': -15.303091049194336, 'loss_4': 1.2900042533874512, 'epoch': 0.97}
{'loss': 0.0885, 'grad_norm': 19.009693145751953, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.08364760875701904, 'loss_2': 0.00482177734375, 'loss_3': -15.262055397033691, 'loss_4': 1.3895639181137085, 'epoch': 0.97}
{'loss': 0.0856, 'grad_norm': 29.321725845336914, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.07846561074256897, 'loss_2': 0.0071258544921875, 'loss_3': -15.028724670410156, 'loss_4': 1.4427895545959473, 'epoch': 0.98}
{'loss': 0.1714, 'grad_norm': 56.979286193847656, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.1631719321012497, 'loss_2': 0.00827789306640625, 'loss_3': -15.003532409667969, 'loss_4': 1.288431167602539, 'epoch': 0.98}
{'loss': 0.1304, 'grad_norm': 25.622766494750977, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.11593158543109894, 'loss_2': 0.014495849609375, 'loss_3': -15.389849662780762, 'loss_4': 1.9344656467437744, 'epoch': 0.99}
[INFO|trainer.py:4228] 2025-01-21 12:25:17,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:17,947 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:36<1:23:59,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 12:25:24,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04142823815345764, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.03189053758978844, 'eval_loss_2': 0.009537696838378906, 'eval_loss_3': -17.982723236083984, 'eval_loss_4': 1.745428204536438, 'epoch': 0.99}
{'loss': 0.0597, 'grad_norm': 13.958707809448242, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.05538054555654526, 'loss_2': 0.004364013671875, 'loss_3': -15.171271324157715, 'loss_4': 1.5699472427368164, 'epoch': 0.99}
{'loss': 0.0491, 'grad_norm': 23.711532592773438, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.044912248849868774, 'loss_2': 0.0042266845703125, 'loss_3': -15.053696632385254, 'loss_4': 2.269758462905884, 'epoch': 1.0}
{'loss': 0.0565, 'grad_norm': 16.048873901367188, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.05355972796678543, 'loss_2': 0.002956390380859375, 'loss_3': -15.234100341796875, 'loss_4': 2.1043505668640137, 'epoch': 1.01}
{'loss': 0.0706, 'grad_norm': 16.83724594116211, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.06901697814464569, 'loss_2': 0.00156402587890625, 'loss_3': -15.306563377380371, 'loss_4': 1.941267967224121, 'epoch': 1.01}
{'loss': 0.1234, 'grad_norm': 30.820358276367188, 'learning_rate': 2.9e-05, 'loss_1': 0.11940117925405502, 'loss_2': 0.0040435791015625, 'loss_3': -15.251936912536621, 'loss_4': 2.096346616744995, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 12:25:24,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:24,996 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:44<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:32,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03175610676407814, 'eval_runtime': 3.8227, 'eval_samples_per_second': 267.875, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.027397217229008675, 'eval_loss_2': 0.004358887672424316, 'eval_loss_3': -18.005535125732422, 'eval_loss_4': 1.8913670778274536, 'epoch': 1.02}
{'loss': 0.1724, 'grad_norm': 38.95416259765625, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.16971606016159058, 'loss_2': 0.002716064453125, 'loss_3': -15.145807266235352, 'loss_4': 2.4226460456848145, 'epoch': 1.02}
{'loss': 0.0763, 'grad_norm': 17.58906364440918, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.06705734878778458, 'loss_2': 0.009246826171875, 'loss_3': -14.967745780944824, 'loss_4': 2.100085496902466, 'epoch': 1.03}
{'loss': 0.0846, 'grad_norm': 22.707014083862305, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.08443049341440201, 'loss_2': 0.0001842975616455078, 'loss_3': -15.10324478149414, 'loss_4': 2.410428285598755, 'epoch': 1.03}
{'loss': 0.0866, 'grad_norm': 19.797086715698242, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.08563778549432755, 'loss_2': 0.0009403228759765625, 'loss_3': -15.091513633728027, 'loss_4': 2.6848573684692383, 'epoch': 1.04}
{'loss': 0.0945, 'grad_norm': 17.870603561401367, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.08905066549777985, 'loss_2': 0.005405426025390625, 'loss_3': -15.080470085144043, 'loss_4': 1.7278199195861816, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 12:25:32,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:32,376 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:48<1:26:03,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:25:36,180 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-180
[INFO|configuration_utils.py:420] 2025-01-21 12:25:36,182 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-180/config.json                                                                             
{'eval_loss': 0.028104783967137337, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.024521460756659508, 'eval_loss_2': 0.003583323210477829, 'eval_loss_3': -18.101333618164062, 'eval_loss_4': 2.463003635406494, 'epoch': 1.05}
[INFO|modeling_utils.py:2988] 2025-01-21 12:25:36,668 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-180/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:25:36,669 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-180/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:25:36,669 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-180/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:25:37,471 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-150] due to args.save_total_limit
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:53<1:34:21,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:25:41,108 >>
{'loss': 0.0853, 'grad_norm': 20.419309616088867, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.07941772043704987, 'loss_2': 0.005847930908203125, 'loss_3': -15.278350830078125, 'loss_4': 2.871307849884033, 'epoch': 1.05}
{'loss': 0.1127, 'grad_norm': 29.289979934692383, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.10974878072738647, 'loss_2': 0.0029621124267578125, 'loss_3': -15.345230102539062, 'loss_4': 2.7731709480285645, 'epoch': 1.06}
{'loss': 0.1696, 'grad_norm': 31.757701873779297, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.16931791603565216, 'loss_2': 0.00033020973205566406, 'loss_3': -15.276779174804688, 'loss_4': 2.816013813018799, 'epoch': 1.06}
{'loss': 0.0676, 'grad_norm': 14.120540618896484, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.06298715621232986, 'loss_2': 0.00461578369140625, 'loss_3': -15.074847221374512, 'loss_4': 2.493135929107666, 'epoch': 1.07}
{'loss': 0.0793, 'grad_norm': 17.35158348083496, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.07753992825746536, 'loss_2': 0.0017805099487304688, 'loss_3': -15.097007751464844, 'loss_4': 2.807760238647461, 'epoch': 1.08}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:25:41,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:41,109 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [05:00<1:27:31,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:25:48,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03054317831993103, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.027324676513671875, 'eval_loss_2': 0.0032185018062591553, 'eval_loss_3': -18.09349250793457, 'eval_loss_4': 2.429990768432617, 'epoch': 1.08}
{'loss': 0.1101, 'grad_norm': 33.98649215698242, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.1095779687166214, 'loss_2': 0.0005235671997070312, 'loss_3': -15.181772232055664, 'loss_4': 2.5064539909362793, 'epoch': 1.08}
{'loss': 0.0552, 'grad_norm': 17.2530574798584, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.04856300354003906, 'loss_2': 0.00666046142578125, 'loss_3': -15.10448169708252, 'loss_4': 2.351477861404419, 'epoch': 1.09}
{'loss': 0.1637, 'grad_norm': 36.248634338378906, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.1570725291967392, 'loss_2': 0.0066375732421875, 'loss_3': -14.977811813354492, 'loss_4': 2.2822625637054443, 'epoch': 1.09}
{'loss': 0.1515, 'grad_norm': 38.44388198852539, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.13924916088581085, 'loss_2': 0.0122833251953125, 'loss_3': -14.998371124267578, 'loss_4': 2.6261138916015625, 'epoch': 1.1}
{'loss': 0.0717, 'grad_norm': 16.600204467773438, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.07055727392435074, 'loss_2': 0.0011272430419921875, 'loss_3': -15.0458984375, 'loss_4': 2.448253631591797, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 12:25:48,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:48,466 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:07<1:26:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:55,823 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04453875496983528, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.03541208803653717, 'eval_loss_2': 0.009126663208007812, 'eval_loss_3': -18.072065353393555, 'eval_loss_4': 2.1056313514709473, 'epoch': 1.1}
{'loss': 0.0866, 'grad_norm': 19.965341567993164, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.0719861090183258, 'loss_2': 0.0146636962890625, 'loss_3': -15.147830963134766, 'loss_4': 2.1475701332092285, 'epoch': 1.11}
{'loss': 0.0579, 'grad_norm': 14.044246673583984, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.05213058367371559, 'loss_2': 0.0058135986328125, 'loss_3': -15.26069164276123, 'loss_4': 2.0929696559906006, 'epoch': 1.12}
{'loss': 0.0899, 'grad_norm': 25.25942611694336, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.08193225413560867, 'loss_2': 0.00797271728515625, 'loss_3': -15.220991134643555, 'loss_4': 1.9087021350860596, 'epoch': 1.12}
{'loss': 0.1056, 'grad_norm': 27.07364273071289, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.0963454470038414, 'loss_2': 0.0092315673828125, 'loss_3': -15.0301513671875, 'loss_4': 1.997002124786377, 'epoch': 1.13}
{'loss': 0.0694, 'grad_norm': 17.00077247619629, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.0609288290143013, 'loss_2': 0.0084228515625, 'loss_3': -15.156102180480957, 'loss_4': 1.7371256351470947, 'epoch': 1.13}
[INFO|trainer.py:4228] 2025-01-21 12:25:55,823 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:55,823 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:15<1:25:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:03,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05390527844429016, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.621, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.04889973625540733, 'eval_loss_2': 0.005005538463592529, 'eval_loss_3': -17.951663970947266, 'eval_loss_4': 1.9154751300811768, 'epoch': 1.13}
{'loss': 0.0439, 'grad_norm': 12.718851089477539, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.0386013500392437, 'loss_2': 0.00531768798828125, 'loss_3': -15.172431945800781, 'loss_4': 1.7995227575302124, 'epoch': 1.14}
{'loss': 0.0469, 'grad_norm': 18.227020263671875, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.04560217261314392, 'loss_2': 0.0013017654418945312, 'loss_3': -15.096633911132812, 'loss_4': 1.2179391384124756, 'epoch': 1.15}
{'loss': 0.1234, 'grad_norm': 26.070301055908203, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.11747799068689346, 'loss_2': 0.00591278076171875, 'loss_3': -14.806007385253906, 'loss_4': 1.551071286201477, 'epoch': 1.15}
{'loss': 0.0497, 'grad_norm': 11.166029930114746, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.0415765605866909, 'loss_2': 0.00814056396484375, 'loss_3': -14.989473342895508, 'loss_4': 1.8122241497039795, 'epoch': 1.16}
{'loss': 0.0578, 'grad_norm': 15.686304092407227, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.053449928760528564, 'loss_2': 0.0043182373046875, 'loss_3': -15.092767715454102, 'loss_4': 1.564040184020996, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 12:26:03,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:03,170 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:22<1:25:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:10,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03669528663158417, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.030309604480862617, 'eval_loss_2': 0.006385684013366699, 'eval_loss_3': -18.067428588867188, 'eval_loss_4': 1.3839508295059204, 'epoch': 1.16}
{'loss': 0.0635, 'grad_norm': 18.62447166442871, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.06334549188613892, 'loss_2': 0.00012803077697753906, 'loss_3': -14.77751350402832, 'loss_4': 1.6371029615402222, 'epoch': 1.17}
{'loss': 0.1239, 'grad_norm': 24.332509994506836, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.10894978046417236, 'loss_2': 0.01497650146484375, 'loss_3': -15.076603889465332, 'loss_4': 1.7234677076339722, 'epoch': 1.17}
{'loss': 0.0911, 'grad_norm': 25.689157485961914, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.0820576474070549, 'loss_2': 0.009063720703125, 'loss_3': -15.090476036071777, 'loss_4': 1.7645082473754883, 'epoch': 1.18}
{'loss': 0.1057, 'grad_norm': 24.85165023803711, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.10308647155761719, 'loss_2': 0.0026187896728515625, 'loss_3': -15.182220458984375, 'loss_4': 1.9883469343185425, 'epoch': 1.19}
{'loss': 0.0941, 'grad_norm': 25.17462921142578, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.08778665214776993, 'loss_2': 0.006359100341796875, 'loss_3': -15.027093887329102, 'loss_4': 1.761081337928772, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 12:26:10,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:10,524 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:26<1:25:49,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:26:14,328 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-205
[INFO|configuration_utils.py:420] 2025-01-21 12:26:14,329 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-205/config.json                                                                             
{'eval_loss': 0.024555301293730736, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.295, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.021759888157248497, 'eval_loss_2': 0.0027954131364822388, 'eval_loss_3': -18.20569610595703, 'eval_loss_4': 1.3594746589660645, 'epoch': 1.19}
[INFO|modeling_utils.py:2988] 2025-01-21 12:26:14,809 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-205/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:26:14,810 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-205/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:26:14,810 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-205/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:26:15,609 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-180] due to args.save_total_limit
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:31<1:33:53,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:26:19,248 >>
{'loss': 0.068, 'grad_norm': 22.042993545532227, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.06671326607465744, 'loss_2': 0.00130462646484375, 'loss_3': -15.006712913513184, 'loss_4': 2.002171754837036, 'epoch': 1.2}
{'loss': 0.2514, 'grad_norm': 60.84980010986328, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.24590712785720825, 'loss_2': 0.00545501708984375, 'loss_3': -15.0874605178833, 'loss_4': 2.306098461151123, 'epoch': 1.2}
{'loss': 0.1176, 'grad_norm': 27.403112411499023, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.11244823783636093, 'loss_2': 0.005157470703125, 'loss_3': -15.172203063964844, 'loss_4': 2.2120256423950195, 'epoch': 1.21}
{'loss': 0.1245, 'grad_norm': 35.24844741821289, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.12235656380653381, 'loss_2': 0.002094268798828125, 'loss_3': -15.238645553588867, 'loss_4': 1.5766420364379883, 'epoch': 1.22}
{'loss': 0.2506, 'grad_norm': 36.914222717285156, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.24047529697418213, 'loss_2': 0.01013946533203125, 'loss_3': -15.147828102111816, 'loss_4': 1.8833770751953125, 'epoch': 1.22}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:26:19,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:19,248 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:38<1:27:02,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:26:26,598 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024750802665948868, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.652, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02118740603327751, 'eval_loss_2': 0.003563396632671356, 'eval_loss_3': -18.16370391845703, 'eval_loss_4': 0.8944857716560364, 'epoch': 1.22}
{'loss': 0.0901, 'grad_norm': 20.582056045532227, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.0875566229224205, 'loss_2': 0.002521514892578125, 'loss_3': -15.233322143554688, 'loss_4': 1.0998293161392212, 'epoch': 1.23}
{'loss': 0.1357, 'grad_norm': 26.92630958557129, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.1311848759651184, 'loss_2': 0.004497528076171875, 'loss_3': -15.249076843261719, 'loss_4': 1.0894732475280762, 'epoch': 1.23}
{'loss': 0.0831, 'grad_norm': 16.827852249145508, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.07051628082990646, 'loss_2': 0.012603759765625, 'loss_3': -15.08426284790039, 'loss_4': 1.0841683149337769, 'epoch': 1.24}
{'loss': 0.0823, 'grad_norm': 21.88733673095703, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.07356763631105423, 'loss_2': 0.0087127685546875, 'loss_3': -15.237568855285645, 'loss_4': 0.3747691512107849, 'epoch': 1.24}
{'loss': 0.0555, 'grad_norm': 12.73049259185791, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.04671289771795273, 'loss_2': 0.008819580078125, 'loss_3': -15.109650611877441, 'loss_4': 0.8656355142593384, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 12:26:26,599 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:26,599 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:45<1:25:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:33,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03722788393497467, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.241, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.029888197779655457, 'eval_loss_2': 0.007339686155319214, 'eval_loss_3': -18.005613327026367, 'eval_loss_4': 1.086126446723938, 'epoch': 1.25}
{'loss': 0.084, 'grad_norm': 20.18174171447754, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.07920590043067932, 'loss_2': 0.0048370361328125, 'loss_3': -15.095130920410156, 'loss_4': 0.9279319047927856, 'epoch': 1.26}
{'loss': 0.0576, 'grad_norm': 16.76897430419922, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.05316484719514847, 'loss_2': 0.004421234130859375, 'loss_3': -15.247509002685547, 'loss_4': 1.7328317165374756, 'epoch': 1.26}
{'loss': 0.0641, 'grad_norm': 16.654523849487305, 'learning_rate': 2.875e-05, 'loss_1': 0.061679963022470474, 'loss_2': 0.002407073974609375, 'loss_3': -14.948891639709473, 'loss_4': 1.3767292499542236, 'epoch': 1.27}
{'loss': 0.0491, 'grad_norm': 16.84556770324707, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.04087073355913162, 'loss_2': 0.0082244873046875, 'loss_3': -15.18806266784668, 'loss_4': 1.959399938583374, 'epoch': 1.27}
{'loss': 0.046, 'grad_norm': 12.039788246154785, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.041589610278606415, 'loss_2': 0.004367828369140625, 'loss_3': -15.278550148010254, 'loss_4': 1.8589038848876953, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 12:26:33,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:33,956 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:53<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:41,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04364755004644394, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.469, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03971010446548462, 'eval_loss_2': 0.00393744558095932, 'eval_loss_3': -17.98308563232422, 'eval_loss_4': 2.066019058227539, 'epoch': 1.28}
{'loss': 0.069, 'grad_norm': 15.535933494567871, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.06863123923540115, 'loss_2': 0.0003266334533691406, 'loss_3': -15.18492603302002, 'loss_4': 1.7094612121582031, 'epoch': 1.28}
{'loss': 0.0638, 'grad_norm': 18.133140563964844, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.062002018094062805, 'loss_2': 0.0018310546875, 'loss_3': -15.071343421936035, 'loss_4': 2.481628656387329, 'epoch': 1.29}
{'loss': 0.0882, 'grad_norm': 21.639760971069336, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.07772885262966156, 'loss_2': 0.01043701171875, 'loss_3': -15.121542930603027, 'loss_4': 2.3902297019958496, 'epoch': 1.3}
{'loss': 0.0539, 'grad_norm': 13.929774284362793, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.042048145085573196, 'loss_2': 0.01187896728515625, 'loss_3': -15.253988265991211, 'loss_4': 2.1251962184906006, 'epoch': 1.3}
{'loss': 0.1065, 'grad_norm': 24.56570053100586, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.1051420196890831, 'loss_2': 0.001312255859375, 'loss_3': -15.069034576416016, 'loss_4': 2.2517096996307373, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 12:26:41,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:41,322 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [06:00<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:48,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03215213492512703, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.396, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.028575053438544273, 'eval_loss_2': 0.0035770833492279053, 'eval_loss_3': -18.06399917602539, 'eval_loss_4': 2.3817496299743652, 'epoch': 1.31}
{'loss': 0.0869, 'grad_norm': 23.562057495117188, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.08029843866825104, 'loss_2': 0.00662994384765625, 'loss_3': -15.244518280029297, 'loss_4': 2.583771228790283, 'epoch': 1.31}
{'loss': 0.0879, 'grad_norm': 21.23298454284668, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.08464968949556351, 'loss_2': 0.003276824951171875, 'loss_3': -15.310327529907227, 'loss_4': 2.595724105834961, 'epoch': 1.32}
{'loss': 0.0301, 'grad_norm': 7.174649238586426, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.02095773257315159, 'loss_2': 0.00914764404296875, 'loss_3': -15.28536605834961, 'loss_4': 1.5039252042770386, 'epoch': 1.33}
{'loss': 0.0604, 'grad_norm': 17.893150329589844, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.058351561427116394, 'loss_2': 0.00201416015625, 'loss_3': -15.330158233642578, 'loss_4': 3.014054775238037, 'epoch': 1.33}
{'loss': 0.0531, 'grad_norm': 15.052661895751953, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.05084498971700668, 'loss_2': 0.0022869110107421875, 'loss_3': -15.045747756958008, 'loss_4': 1.9372364282608032, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 12:26:48,706 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:48,706 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:08<1:25:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:56,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029131338000297546, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02147059142589569, 'eval_loss_2': 0.0076607465744018555, 'eval_loss_3': -18.127521514892578, 'eval_loss_4': 2.353569984436035, 'epoch': 1.34}
{'loss': 0.0437, 'grad_norm': 20.481246948242188, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.037658557295799255, 'loss_2': 0.0059967041015625, 'loss_3': -14.993108749389648, 'loss_4': 2.4844462871551514, 'epoch': 1.34}
{'loss': 0.1936, 'grad_norm': 33.37276077270508, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.17457669973373413, 'loss_2': 0.0190277099609375, 'loss_3': -15.0404052734375, 'loss_4': 2.027477264404297, 'epoch': 1.35}
{'loss': 0.1219, 'grad_norm': 29.77628517150879, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.110735222697258, 'loss_2': 0.011138916015625, 'loss_3': -14.898552894592285, 'loss_4': 2.3932719230651855, 'epoch': 1.35}
{'loss': 0.059, 'grad_norm': 14.984904289245605, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.03966599702835083, 'loss_2': 0.019317626953125, 'loss_3': -15.307676315307617, 'loss_4': 2.5297093391418457, 'epoch': 1.36}
{'loss': 0.1044, 'grad_norm': 38.255271911621094, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.09172073006629944, 'loss_2': 0.0127105712890625, 'loss_3': -15.251005172729492, 'loss_4': 2.6869900226593018, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 12:26:56,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:56,068 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:15<1:25:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:03,429 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032375089824199677, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.241, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.02132975123822689, 'eval_loss_2': 0.011045336723327637, 'eval_loss_3': -18.193803787231445, 'eval_loss_4': 1.8611857891082764, 'epoch': 1.37}
{'loss': 0.1, 'grad_norm': 25.980968475341797, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.08628832548856735, 'loss_2': 0.0137481689453125, 'loss_3': -14.894791603088379, 'loss_4': 2.0966739654541016, 'epoch': 1.37}
{'loss': 0.1188, 'grad_norm': 30.795047760009766, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.10358303785324097, 'loss_2': 0.01525115966796875, 'loss_3': -15.232674598693848, 'loss_4': 2.005919933319092, 'epoch': 1.38}
{'loss': 0.077, 'grad_norm': 22.162853240966797, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.07638850808143616, 'loss_2': 0.0006561279296875, 'loss_3': -15.284218788146973, 'loss_4': 2.172638416290283, 'epoch': 1.38}
{'loss': 0.0873, 'grad_norm': 30.628070831298828, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.0837254673242569, 'loss_2': 0.0035877227783203125, 'loss_3': -15.167481422424316, 'loss_4': 1.9765093326568604, 'epoch': 1.39}
{'loss': 0.0495, 'grad_norm': 15.986123085021973, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.04793672636151314, 'loss_2': 0.001529693603515625, 'loss_3': -15.334700584411621, 'loss_4': 1.9026477336883545, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 12:27:03,429 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:03,429 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:19<1:25:20,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:27:07,227 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-240
[INFO|configuration_utils.py:420] 2025-01-21 12:27:07,229 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-240/config.json                                                                             
{'eval_loss': 0.02312609553337097, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.681, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.019841430708765984, 'eval_loss_2': 0.003284662961959839, 'eval_loss_3': -18.221216201782227, 'eval_loss_4': 1.2803272008895874, 'epoch': 1.4}
[INFO|modeling_utils.py:2988] 2025-01-21 12:27:07,706 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-240/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:27:07,707 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-240/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:27:07,707 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-240/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:27:08,509 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-205] due to args.save_total_limit
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:24<1:33:13,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:27:12,152 >>
{'loss': 0.0605, 'grad_norm': 11.863750457763672, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.05469059571623802, 'loss_2': 0.00585174560546875, 'loss_3': -15.225240707397461, 'loss_4': 1.770176887512207, 'epoch': 1.4}
{'loss': 0.0446, 'grad_norm': 14.148041725158691, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.04259561374783516, 'loss_2': 0.0020351409912109375, 'loss_3': -15.504111289978027, 'loss_4': 0.801703929901123, 'epoch': 1.41}
{'loss': 0.0697, 'grad_norm': 19.760456085205078, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.0689154639840126, 'loss_2': 0.0008020401000976562, 'loss_3': -15.352160453796387, 'loss_4': 1.4437134265899658, 'epoch': 1.41}
{'loss': 0.0481, 'grad_norm': 14.149831771850586, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.04381904751062393, 'loss_2': 0.00424957275390625, 'loss_3': -15.51831340789795, 'loss_4': 1.0513033866882324, 'epoch': 1.42}
{'loss': 0.0466, 'grad_norm': 14.21092700958252, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.04318554699420929, 'loss_2': 0.003448486328125, 'loss_3': -15.28156566619873, 'loss_4': 0.427288293838501, 'epoch': 1.42}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:27:12,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:12,153 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:31<1:26:33,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:27:19,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.038198500871658325, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.058, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03113687038421631, 'eval_loss_2': 0.007061630487442017, 'eval_loss_3': -18.134069442749023, 'eval_loss_4': 0.6141635775566101, 'epoch': 1.42}
{'loss': 0.0784, 'grad_norm': 23.639488220214844, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.0702696442604065, 'loss_2': 0.008148193359375, 'loss_3': -15.469003677368164, 'loss_4': 0.8889407515525818, 'epoch': 1.43}
{'loss': 0.1586, 'grad_norm': 31.462574005126953, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.14663419127464294, 'loss_2': 0.0119781494140625, 'loss_3': -15.122085571289062, 'loss_4': 0.5596884489059448, 'epoch': 1.44}
{'loss': 0.0689, 'grad_norm': 23.10843276977539, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.06839577108621597, 'loss_2': 0.00046253204345703125, 'loss_3': -15.166455268859863, 'loss_4': 0.551645040512085, 'epoch': 1.44}
{'loss': 0.0744, 'grad_norm': 20.873144149780273, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.0681164488196373, 'loss_2': 0.00626373291015625, 'loss_3': -15.11153793334961, 'loss_4': 0.226036936044693, 'epoch': 1.45}
{'loss': 0.0375, 'grad_norm': 11.593369483947754, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.0365213043987751, 'loss_2': 0.0009984970092773438, 'loss_3': -15.578241348266602, 'loss_4': 0.6985199451446533, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 12:27:19,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:19,515 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:38<1:25:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:26,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07531031966209412, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.877, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.07117754966020584, 'eval_loss_2': 0.004132777452468872, 'eval_loss_3': -17.895336151123047, 'eval_loss_4': 0.8671854734420776, 'epoch': 1.45}
{'loss': 0.1007, 'grad_norm': 32.29603958129883, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.09691016376018524, 'loss_2': 0.00379180908203125, 'loss_3': -15.215587615966797, 'loss_4': 1.0719481706619263, 'epoch': 1.46}
{'loss': 0.0998, 'grad_norm': 26.181591033935547, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.0941414088010788, 'loss_2': 0.00565338134765625, 'loss_3': -15.206113815307617, 'loss_4': 0.6649635434150696, 'epoch': 1.47}
{'loss': 0.0826, 'grad_norm': 25.34113121032715, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.08046149462461472, 'loss_2': 0.0021266937255859375, 'loss_3': -15.180864334106445, 'loss_4': 1.0387202501296997, 'epoch': 1.47}
{'loss': 0.206, 'grad_norm': 41.853092193603516, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.19208143651485443, 'loss_2': 0.0139007568359375, 'loss_3': -15.186609268188477, 'loss_4': 1.7466092109680176, 'epoch': 1.48}
{'loss': 0.0633, 'grad_norm': 24.566816329956055, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.0610087588429451, 'loss_2': 0.0023345947265625, 'loss_3': -15.246206283569336, 'loss_4': 1.0319294929504395, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 12:27:26,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:26,868 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:46<1:24:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:34,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04536839574575424, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.639, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.03912138566374779, 'eval_loss_2': 0.006247013807296753, 'eval_loss_3': -18.046451568603516, 'eval_loss_4': 1.3553698062896729, 'epoch': 1.48}
{'loss': 0.065, 'grad_norm': 19.250028610229492, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.05674600973725319, 'loss_2': 0.00829315185546875, 'loss_3': -15.290459632873535, 'loss_4': 1.4346650838851929, 'epoch': 1.49}
{'loss': 0.1081, 'grad_norm': 32.71701431274414, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.1013399064540863, 'loss_2': 0.006771087646484375, 'loss_3': -15.477381706237793, 'loss_4': 1.6827433109283447, 'epoch': 1.49}
{'loss': 0.0589, 'grad_norm': 16.841588973999023, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.043408915400505066, 'loss_2': 0.015472412109375, 'loss_3': -15.262228012084961, 'loss_4': 1.634210228919983, 'epoch': 1.5}
{'loss': 0.0978, 'grad_norm': 22.774478912353516, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.09502749890089035, 'loss_2': 0.00276947021484375, 'loss_3': -15.122967720031738, 'loss_4': 1.9937279224395752, 'epoch': 1.51}
{'loss': 0.0684, 'grad_norm': 22.18047523498535, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.06715396046638489, 'loss_2': 0.0012388229370117188, 'loss_3': -15.436577796936035, 'loss_4': 2.1437652111053467, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 12:27:34,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:34,216 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:50<1:24:51,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:27:38,012 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-260
[INFO|configuration_utils.py:420] 2025-01-21 12:27:38,013 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-260/config.json                                                                             
{'eval_loss': 0.02242855541408062, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014993233606219292, 'eval_loss_2': 0.007435321807861328, 'eval_loss_3': -18.260343551635742, 'eval_loss_4': 2.1938071250915527, 'epoch': 1.51}
[INFO|modeling_utils.py:2988] 2025-01-21 12:27:38,490 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-260/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:27:38,491 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-260/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:27:38,492 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-260/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:27:39,283 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-240] due to args.save_total_limit
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:54<1:32:35,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 12:27:42,907 >>
{'loss': 0.0879, 'grad_norm': 30.51767921447754, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.08606775850057602, 'loss_2': 0.0018100738525390625, 'loss_3': -15.422737121582031, 'loss_4': 2.8836851119995117, 'epoch': 1.52}
{'loss': 0.0786, 'grad_norm': 20.109066009521484, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.06680949777364731, 'loss_2': 0.01180267333984375, 'loss_3': -15.372068405151367, 'loss_4': 2.4936065673828125, 'epoch': 1.52}
{'loss': 0.1428, 'grad_norm': 33.302860260009766, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.12509384751319885, 'loss_2': 0.0176849365234375, 'loss_3': -15.352777481079102, 'loss_4': 2.5233874320983887, 'epoch': 1.53}
{'loss': 0.0729, 'grad_norm': 28.666810989379883, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.06094791740179062, 'loss_2': 0.011993408203125, 'loss_3': -15.103336334228516, 'loss_4': 2.3092494010925293, 'epoch': 1.53}
{'loss': 0.0492, 'grad_norm': 11.201769828796387, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.03970688581466675, 'loss_2': 0.009490966796875, 'loss_3': -15.483015060424805, 'loss_4': 2.6151766777038574, 'epoch': 1.54}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:27:42,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:42,907 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [07:02<1:25:58,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:27:50,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027592994272708893, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.286, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.015629151836037636, 'eval_loss_2': 0.011963844299316406, 'eval_loss_3': -18.333824157714844, 'eval_loss_4': 3.183509349822998, 'epoch': 1.54}
{'loss': 0.1285, 'grad_norm': 36.39173889160156, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.12084262073040009, 'loss_2': 0.007678985595703125, 'loss_3': -15.31572151184082, 'loss_4': 3.8553051948547363, 'epoch': 1.55}
{'loss': 0.0975, 'grad_norm': 22.591632843017578, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.08428486436605453, 'loss_2': 0.0132293701171875, 'loss_3': -15.343070983886719, 'loss_4': 3.7738547325134277, 'epoch': 1.55}
{'loss': 0.0857, 'grad_norm': 20.95448875427246, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.08098453283309937, 'loss_2': 0.004741668701171875, 'loss_3': -15.414398193359375, 'loss_4': 3.732530117034912, 'epoch': 1.56}
{'loss': 0.0881, 'grad_norm': 27.874706268310547, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.0865335762500763, 'loss_2': 0.0015850067138671875, 'loss_3': -15.62411117553711, 'loss_4': 3.706460952758789, 'epoch': 1.56}
{'loss': 0.0798, 'grad_norm': 20.412641525268555, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.07445862144231796, 'loss_2': 0.005340576171875, 'loss_3': -15.419862747192383, 'loss_4': 3.6172385215759277, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 12:27:50,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:50,246 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:09<1:24:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:57,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027541140094399452, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.611, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.019094211980700493, 'eval_loss_2': 0.008446931838989258, 'eval_loss_3': -18.3586368560791, 'eval_loss_4': 3.7994065284729004, 'epoch': 1.57}
{'loss': 0.0629, 'grad_norm': 12.137903213500977, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.04836802929639816, 'loss_2': 0.014556884765625, 'loss_3': -15.462928771972656, 'loss_4': 3.708554744720459, 'epoch': 1.58}
{'loss': 0.1098, 'grad_norm': 23.586254119873047, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.103315070271492, 'loss_2': 0.00647735595703125, 'loss_3': -15.42108154296875, 'loss_4': 3.357245683670044, 'epoch': 1.58}
{'loss': 0.1134, 'grad_norm': 31.267297744750977, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.09704052656888962, 'loss_2': 0.016357421875, 'loss_3': -15.603973388671875, 'loss_4': 3.7590479850769043, 'epoch': 1.59}
{'loss': 0.0937, 'grad_norm': 15.611343383789062, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.07301949709653854, 'loss_2': 0.020660400390625, 'loss_3': -15.588887214660645, 'loss_4': 3.703261137008667, 'epoch': 1.59}
{'loss': 0.1161, 'grad_norm': 29.585073471069336, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.09843272715806961, 'loss_2': 0.0176239013671875, 'loss_3': -15.178717613220215, 'loss_4': 2.767653226852417, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 12:27:57,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:57,608 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:16<1:24:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:04,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029806114733219147, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.034, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01907966285943985, 'eval_loss_2': 0.010726451873779297, 'eval_loss_3': -18.300418853759766, 'eval_loss_4': 2.9684531688690186, 'epoch': 1.6}
{'loss': 0.0849, 'grad_norm': 17.07396125793457, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.0718231350183487, 'loss_2': 0.013092041015625, 'loss_3': -15.493728637695312, 'loss_4': 2.943122148513794, 'epoch': 1.6}
{'loss': 0.1005, 'grad_norm': 20.120975494384766, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.09230756759643555, 'loss_2': 0.008148193359375, 'loss_3': -15.725915908813477, 'loss_4': 3.098245143890381, 'epoch': 1.61}
{'loss': 0.0737, 'grad_norm': 14.884191513061523, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.06790442764759064, 'loss_2': 0.005817413330078125, 'loss_3': -15.692886352539062, 'loss_4': 2.8936967849731445, 'epoch': 1.62}
{'loss': 0.0884, 'grad_norm': 31.067922592163086, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.08526298403739929, 'loss_2': 0.0030975341796875, 'loss_3': -15.62545108795166, 'loss_4': 2.767475128173828, 'epoch': 1.62}
{'loss': 0.0793, 'grad_norm': 14.739642143249512, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.06431228667497635, 'loss_2': 0.0149688720703125, 'loss_3': -15.710044860839844, 'loss_4': 2.3551530838012695, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 12:28:04,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:04,956 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:24<1:24:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:12,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029443347826600075, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.058, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01965966261923313, 'eval_loss_2': 0.009783685207366943, 'eval_loss_3': -18.345035552978516, 'eval_loss_4': 2.2813103199005127, 'epoch': 1.63}
{'loss': 0.0724, 'grad_norm': 15.202305793762207, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.06626405566930771, 'loss_2': 0.00616455078125, 'loss_3': -15.78111457824707, 'loss_4': 2.2020161151885986, 'epoch': 1.63}
{'loss': 0.0931, 'grad_norm': 20.107498168945312, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.07611924409866333, 'loss_2': 0.016937255859375, 'loss_3': -15.726112365722656, 'loss_4': 1.8797121047973633, 'epoch': 1.64}
{'loss': 0.114, 'grad_norm': 27.28795623779297, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.10148655623197556, 'loss_2': 0.0125274658203125, 'loss_3': -15.708641052246094, 'loss_4': 1.8834640979766846, 'epoch': 1.65}
{'loss': 0.114, 'grad_norm': 28.722394943237305, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.10267245769500732, 'loss_2': 0.0113525390625, 'loss_3': -15.624628067016602, 'loss_4': 2.9147017002105713, 'epoch': 1.65}
{'loss': 0.0971, 'grad_norm': 27.207897186279297, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.09693698585033417, 'loss_2': 0.00018322467803955078, 'loss_3': -15.744302749633789, 'loss_4': 2.407443046569824, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 12:28:12,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:12,296 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:31<1:25:14,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:28:19,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026670867577195168, 'eval_runtime': 3.971, 'eval_samples_per_second': 257.866, 'eval_steps_per_second': 4.029, 'eval_loss_1': 0.02036547102034092, 'eval_loss_2': 0.006305396556854248, 'eval_loss_3': -18.397781372070312, 'eval_loss_4': 2.17476487159729, 'epoch': 1.66}
{'loss': 0.0859, 'grad_norm': 16.087276458740234, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.07643943279981613, 'loss_2': 0.0095062255859375, 'loss_3': -15.574078559875488, 'loss_4': 2.8051950931549072, 'epoch': 1.66}
{'loss': 0.0959, 'grad_norm': 22.342897415161133, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.0944809764623642, 'loss_2': 0.0014438629150390625, 'loss_3': -15.725937843322754, 'loss_4': 2.2044906616210938, 'epoch': 1.67}
{'loss': 0.1161, 'grad_norm': 25.322021484375, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.11194144934415817, 'loss_2': 0.004180908203125, 'loss_3': -15.669957160949707, 'loss_4': 2.757772207260132, 'epoch': 1.67}
{'loss': 0.1063, 'grad_norm': 29.350574493408203, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.09235328435897827, 'loss_2': 0.01392364501953125, 'loss_3': -15.807046890258789, 'loss_4': 2.890137195587158, 'epoch': 1.68}
{'loss': 0.0705, 'grad_norm': 17.186357498168945, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.05496395751833916, 'loss_2': 0.01556396484375, 'loss_3': -15.670886039733887, 'loss_4': 2.5474765300750732, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 12:28:19,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:19,815 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:39<1:24:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:27,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028307393193244934, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.018201487138867378, 'eval_loss_2': 0.010105907917022705, 'eval_loss_3': -18.367454528808594, 'eval_loss_4': 2.138080596923828, 'epoch': 1.69}
{'loss': 0.0932, 'grad_norm': 19.64107894897461, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.07861944288015366, 'loss_2': 0.0146026611328125, 'loss_3': -15.661664009094238, 'loss_4': 2.5556607246398926, 'epoch': 1.69}
{'loss': 0.1248, 'grad_norm': 28.540494918823242, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.11150805652141571, 'loss_2': 0.013336181640625, 'loss_3': -15.632987976074219, 'loss_4': 2.2982394695281982, 'epoch': 1.7}
{'loss': 0.1486, 'grad_norm': 21.81604766845703, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.14752832055091858, 'loss_2': 0.0010738372802734375, 'loss_3': -15.51849365234375, 'loss_4': 2.3605685234069824, 'epoch': 1.7}
{'loss': 0.1219, 'grad_norm': 27.080223083496094, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.11271224915981293, 'loss_2': 0.0091400146484375, 'loss_3': -15.736973762512207, 'loss_4': 2.1725783348083496, 'epoch': 1.71}
{'loss': 0.1095, 'grad_norm': 30.37540054321289, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.10857024788856506, 'loss_2': 0.0009374618530273438, 'loss_3': -15.397684097290039, 'loss_4': 1.8950754404067993, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 12:28:27,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:27,156 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:46<1:24:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:34,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02309439703822136, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019162829965353012, 'eval_loss_2': 0.003931567072868347, 'eval_loss_3': -18.30247688293457, 'eval_loss_4': 2.003009557723999, 'epoch': 1.72}
{'loss': 0.0971, 'grad_norm': 21.444683074951172, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.09600689262151718, 'loss_2': 0.00107574462890625, 'loss_3': -15.40961742401123, 'loss_4': 2.0371015071868896, 'epoch': 1.72}
{'loss': 0.0823, 'grad_norm': 21.673437118530273, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.08008302748203278, 'loss_2': 0.0022430419921875, 'loss_3': -15.651860237121582, 'loss_4': 1.7956641912460327, 'epoch': 1.73}
{'loss': 0.043, 'grad_norm': 13.557879447937012, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.04216999560594559, 'loss_2': 0.00083160400390625, 'loss_3': -15.52568244934082, 'loss_4': 2.0350303649902344, 'epoch': 1.73}
{'loss': 0.1087, 'grad_norm': 17.662948608398438, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.09054036438465118, 'loss_2': 0.01812744140625, 'loss_3': -15.623051643371582, 'loss_4': 2.260003089904785, 'epoch': 1.74}
{'loss': 0.088, 'grad_norm': 15.987893104553223, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.06863701343536377, 'loss_2': 0.0193634033203125, 'loss_3': -15.51831340789795, 'loss_4': 1.3459248542785645, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 12:28:34,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:34,511 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:53<1:23:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:41,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.054183296859264374, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.064, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.031664181500673294, 'eval_loss_2': 0.02251911163330078, 'eval_loss_3': -18.146217346191406, 'eval_loss_4': 1.9798400402069092, 'epoch': 1.74}
{'loss': 0.0916, 'grad_norm': 20.134721755981445, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.07487989962100983, 'loss_2': 0.0166778564453125, 'loss_3': -15.478256225585938, 'loss_4': 1.9095064401626587, 'epoch': 1.75}
{'loss': 0.0996, 'grad_norm': 23.319442749023438, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.0727904736995697, 'loss_2': 0.02679443359375, 'loss_3': -15.397706985473633, 'loss_4': 1.8559812307357788, 'epoch': 1.76}
{'loss': 0.0585, 'grad_norm': 14.096960067749023, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.03625987842679024, 'loss_2': 0.022247314453125, 'loss_3': -15.544158935546875, 'loss_4': 1.8923739194869995, 'epoch': 1.76}
{'loss': 0.0688, 'grad_norm': 14.603202819824219, 'learning_rate': 2.825e-05, 'loss_1': 0.05078747868537903, 'loss_2': 0.0180511474609375, 'loss_3': -15.54654312133789, 'loss_4': 1.6327183246612549, 'epoch': 1.77}
{'loss': 0.0954, 'grad_norm': 19.642181396484375, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.07164016366004944, 'loss_2': 0.0237579345703125, 'loss_3': -15.489872932434082, 'loss_4': 2.1046247482299805, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 12:28:41,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:41,844 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:01<1:23:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:49,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06391093134880066, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.991, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.04959341511130333, 'eval_loss_2': 0.014317512512207031, 'eval_loss_3': -17.996116638183594, 'eval_loss_4': 2.1181678771972656, 'epoch': 1.77}
{'loss': 0.1595, 'grad_norm': 33.08595657348633, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.1479548215866089, 'loss_2': 0.01157379150390625, 'loss_3': -15.066906929016113, 'loss_4': 1.7690653800964355, 'epoch': 1.78}
{'loss': 0.0756, 'grad_norm': 20.48822593688965, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.06630950421094894, 'loss_2': 0.00926971435546875, 'loss_3': -15.329803466796875, 'loss_4': 2.01664400100708, 'epoch': 1.78}
{'loss': 0.1018, 'grad_norm': 19.527889251708984, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.09416359663009644, 'loss_2': 0.007598876953125, 'loss_3': -15.311233520507812, 'loss_4': 1.6797548532485962, 'epoch': 1.79}
{'loss': 0.0648, 'grad_norm': 23.11210060119629, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.06378713250160217, 'loss_2': 0.0010213851928710938, 'loss_3': -15.418184280395508, 'loss_4': 1.6382520198822021, 'epoch': 1.8}
{'loss': 0.0372, 'grad_norm': 10.853856086730957, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.03228418156504631, 'loss_2': 0.0048980712890625, 'loss_3': -15.289329528808594, 'loss_4': 1.1405500173568726, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 12:28:49,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:49,192 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:08<1:23:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:56,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0357714518904686, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.073, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.029104072600603104, 'eval_loss_2': 0.006667375564575195, 'eval_loss_3': -18.050437927246094, 'eval_loss_4': 1.8946021795272827, 'epoch': 1.8}
{'loss': 0.0648, 'grad_norm': 24.73293113708496, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.06134127825498581, 'loss_2': 0.00341033935546875, 'loss_3': -15.518569946289062, 'loss_4': 1.307283878326416, 'epoch': 1.81}
{'loss': 0.0571, 'grad_norm': 11.342254638671875, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.04170769080519676, 'loss_2': 0.015350341796875, 'loss_3': -15.374618530273438, 'loss_4': 1.4475535154342651, 'epoch': 1.81}
{'loss': 0.1142, 'grad_norm': 25.65528106689453, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.10221856832504272, 'loss_2': 0.0119781494140625, 'loss_3': -15.353057861328125, 'loss_4': 1.9225034713745117, 'epoch': 1.82}
{'loss': 0.0503, 'grad_norm': 9.33994197845459, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.02628590352833271, 'loss_2': 0.024017333984375, 'loss_3': -15.440801620483398, 'loss_4': 1.811631202697754, 'epoch': 1.83}
{'loss': 0.1182, 'grad_norm': 27.22148323059082, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.10617958009243011, 'loss_2': 0.011993408203125, 'loss_3': -15.495492935180664, 'loss_4': 2.3500144481658936, 'epoch': 1.83}
[INFO|trainer.py:4228] 2025-01-21 12:28:56,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:56,546 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:15<1:23:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:03,893 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028263207525014877, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.59, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.020393723621964455, 'eval_loss_2': 0.007869482040405273, 'eval_loss_3': -18.180564880371094, 'eval_loss_4': 2.045985460281372, 'epoch': 1.83}
{'loss': 0.0641, 'grad_norm': 13.391410827636719, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.04401959478855133, 'loss_2': 0.020050048828125, 'loss_3': -15.449392318725586, 'loss_4': 2.689359188079834, 'epoch': 1.84}
{'loss': 0.1043, 'grad_norm': 31.62906265258789, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.09689473360776901, 'loss_2': 0.007358551025390625, 'loss_3': -15.492914199829102, 'loss_4': 2.4035041332244873, 'epoch': 1.84}
{'loss': 0.0792, 'grad_norm': 22.544700622558594, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.07491385191679001, 'loss_2': 0.00431060791015625, 'loss_3': -15.34050178527832, 'loss_4': 2.5160584449768066, 'epoch': 1.85}
{'loss': 0.0712, 'grad_norm': 20.053117752075195, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.07048237323760986, 'loss_2': 0.000751495361328125, 'loss_3': -15.282806396484375, 'loss_4': 3.052483081817627, 'epoch': 1.85}
{'loss': 0.1143, 'grad_norm': 26.079795837402344, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.11108871549367905, 'loss_2': 0.003204345703125, 'loss_3': -15.289350509643555, 'loss_4': 3.176490306854248, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 12:29:03,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:03,894 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:23<1:23:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:11,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04039032384753227, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.111, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.025330375880002975, 'eval_loss_2': 0.015059947967529297, 'eval_loss_3': -18.245498657226562, 'eval_loss_4': 2.864250898361206, 'epoch': 1.86}
{'loss': 0.0533, 'grad_norm': 11.960859298706055, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.03714478760957718, 'loss_2': 0.016204833984375, 'loss_3': -15.338396072387695, 'loss_4': 2.750995635986328, 'epoch': 1.87}
{'loss': 0.0419, 'grad_norm': 9.612719535827637, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.031209737062454224, 'loss_2': 0.0107269287109375, 'loss_3': -15.660487174987793, 'loss_4': 3.022977113723755, 'epoch': 1.87}
{'loss': 0.0673, 'grad_norm': 24.32189178466797, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.06368006765842438, 'loss_2': 0.00360107421875, 'loss_3': -15.53048324584961, 'loss_4': 3.577550172805786, 'epoch': 1.88}
{'loss': 0.1753, 'grad_norm': 42.61241912841797, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.1679575890302658, 'loss_2': 0.00737762451171875, 'loss_3': -15.447052001953125, 'loss_4': 3.934969425201416, 'epoch': 1.88}
{'loss': 0.0527, 'grad_norm': 16.87726593017578, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.04268394410610199, 'loss_2': 0.0100250244140625, 'loss_3': -15.647302627563477, 'loss_4': 3.0298070907592773, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 12:29:11,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:11,237 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:30<1:23:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:18,590 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03390400856733322, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02941144071519375, 'eval_loss_2': 0.004492565989494324, 'eval_loss_3': -18.289165496826172, 'eval_loss_4': 2.8435256481170654, 'epoch': 1.89}
{'loss': 0.0533, 'grad_norm': 18.359844207763672, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.052230268716812134, 'loss_2': 0.0011014938354492188, 'loss_3': -15.531460762023926, 'loss_4': 3.53511381149292, 'epoch': 1.9}
{'loss': 0.0623, 'grad_norm': 26.309438705444336, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.06154868006706238, 'loss_2': 0.0007452964782714844, 'loss_3': -15.72998332977295, 'loss_4': 3.2179133892059326, 'epoch': 1.9}
{'loss': 0.0653, 'grad_norm': 20.106088638305664, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.058231137692928314, 'loss_2': 0.007110595703125, 'loss_3': -15.536447525024414, 'loss_4': 2.525390863418579, 'epoch': 1.91}
{'loss': 0.0305, 'grad_norm': 7.673480987548828, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.02804468385875225, 'loss_2': 0.002445220947265625, 'loss_3': -15.604351997375488, 'loss_4': 1.1613520383834839, 'epoch': 1.91}
{'loss': 0.0549, 'grad_norm': 11.976935386657715, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.045767780393362045, 'loss_2': 0.00913238525390625, 'loss_3': -15.685060501098633, 'loss_4': 1.3578802347183228, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 12:29:18,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:18,590 >>   Batch size = 64
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:37<1:23:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:25,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029257504269480705, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.020506111904978752, 'eval_loss_2': 0.008751392364501953, 'eval_loss_3': -18.244802474975586, 'eval_loss_4': 0.8418594002723694, 'epoch': 1.92}
{'loss': 0.0702, 'grad_norm': 20.710805892944336, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.05552154406905174, 'loss_2': 0.0146331787109375, 'loss_3': -15.477266311645508, 'loss_4': 1.2377982139587402, 'epoch': 1.92}
{'loss': 0.0555, 'grad_norm': 15.187112808227539, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.0482795275747776, 'loss_2': 0.00725555419921875, 'loss_3': -15.639993667602539, 'loss_4': 0.5616345405578613, 'epoch': 1.93}
{'loss': 0.0507, 'grad_norm': 8.874841690063477, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.039404064416885376, 'loss_2': 0.01131439208984375, 'loss_3': -15.600622177124023, 'loss_4': 0.34423375129699707, 'epoch': 1.94}
{'loss': 0.0426, 'grad_norm': 13.102892875671387, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.03780512139201164, 'loss_2': 0.00479888916015625, 'loss_3': -15.63210678100586, 'loss_4': 0.283752977848053, 'epoch': 1.94}
{'loss': 0.0421, 'grad_norm': 10.211576461791992, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.03461790084838867, 'loss_2': 0.00748443603515625, 'loss_3': -15.756797790527344, 'loss_4': 0.07476771622896194, 'epoch': 1.95}
[INFO|trainer.py:4228] 2025-01-21 12:29:25,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:25,928 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:45<1:23:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:33,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024081911891698837, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.234, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.02075481042265892, 'eval_loss_2': 0.003327101469039917, 'eval_loss_3': -18.110366821289062, 'eval_loss_4': 0.1679861694574356, 'epoch': 1.95}
{'loss': 0.0625, 'grad_norm': 16.296127319335938, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.055532440543174744, 'loss_2': 0.00696563720703125, 'loss_3': -15.612716674804688, 'loss_4': -0.38839319348335266, 'epoch': 1.95}
{'loss': 0.0632, 'grad_norm': 19.097841262817383, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.06086401268839836, 'loss_2': 0.0023708343505859375, 'loss_3': -15.652756690979004, 'loss_4': -0.28833016753196716, 'epoch': 1.96}
{'loss': 0.1121, 'grad_norm': 32.10466003417969, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.11119408160448074, 'loss_2': 0.0008783340454101562, 'loss_3': -15.351974487304688, 'loss_4': -0.16568472981452942, 'epoch': 1.97}
{'loss': 0.1117, 'grad_norm': 24.13022804260254, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.09510886669158936, 'loss_2': 0.016632080078125, 'loss_3': -15.4998140335083, 'loss_4': 0.10571719706058502, 'epoch': 1.97}
{'loss': 0.0346, 'grad_norm': 9.694231986999512, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.03364367410540581, 'loss_2': 0.0009093284606933594, 'loss_3': -15.506795883178711, 'loss_4': 0.22525092959403992, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 12:29:33,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:33,264 >>   Batch size = 64
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:52<1:18:19,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 12:29:40,290 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.053779590874910355, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.912, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.034137479960918427, 'eval_loss_2': 0.019642114639282227, 'eval_loss_3': -18.03807258605957, 'eval_loss_4': 0.04285723343491554, 'epoch': 1.98}
{'loss': 0.0573, 'grad_norm': 10.422121047973633, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.039858970791101456, 'loss_2': 0.0174102783203125, 'loss_3': -15.61156177520752, 'loss_4': -0.20719650387763977, 'epoch': 1.98}
{'loss': 0.0524, 'grad_norm': 8.016637802124023, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.03184132277965546, 'loss_2': 0.02056884765625, 'loss_3': -15.68841552734375, 'loss_4': -0.41556456685066223, 'epoch': 1.99}
{'loss': 0.1232, 'grad_norm': 23.203088760375977, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.09207715839147568, 'loss_2': 0.0311279296875, 'loss_3': -15.867164611816406, 'loss_4': -0.22793760895729065, 'epoch': 1.99}
{'loss': 0.0448, 'grad_norm': 11.257905960083008, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.021942732855677605, 'loss_2': 0.0229034423828125, 'loss_3': -15.589095115661621, 'loss_4': 0.40470772981643677, 'epoch': 2.0}
{'loss': 0.0726, 'grad_norm': 11.625072479248047, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.050309307873249054, 'loss_2': 0.022247314453125, 'loss_3': -15.47525405883789, 'loss_4': -0.528627872467041, 'epoch': 2.01}
[INFO|trainer.py:4228] 2025-01-21 12:29:40,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:40,290 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [08:59<1:22:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:29:47,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.041261911392211914, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.942, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.028388528153300285, 'eval_loss_2': 0.01287338137626648, 'eval_loss_3': -18.137802124023438, 'eval_loss_4': -0.01088952086865902, 'epoch': 2.01}
{'loss': 0.0662, 'grad_norm': 15.133679389953613, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.05145988240838051, 'loss_2': 0.0147247314453125, 'loss_3': -15.641572952270508, 'loss_4': -0.3779209852218628, 'epoch': 2.01}
{'loss': 0.103, 'grad_norm': 20.146242141723633, 'learning_rate': 2.8e-05, 'loss_1': 0.10067085176706314, 'loss_2': 0.00229644775390625, 'loss_3': -15.728214263916016, 'loss_4': -0.20461656153202057, 'epoch': 2.02}
{'loss': 0.0328, 'grad_norm': 10.73206615447998, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.02955181524157524, 'loss_2': 0.00324249267578125, 'loss_3': -15.448204040527344, 'loss_4': -0.38944607973098755, 'epoch': 2.02}
{'loss': 0.0267, 'grad_norm': 9.108640670776367, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.025272151455283165, 'loss_2': 0.0014629364013671875, 'loss_3': -15.698600769042969, 'loss_4': -0.9225677251815796, 'epoch': 2.03}
{'loss': 0.0488, 'grad_norm': 11.633814811706543, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.04068656265735626, 'loss_2': 0.008148193359375, 'loss_3': -15.568049430847168, 'loss_4': -0.0616673082113266, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 12:29:47,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:47,628 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:06<1:22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:54,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03679220750927925, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.96, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.022226739674806595, 'eval_loss_2': 0.014565467834472656, 'eval_loss_3': -18.188997268676758, 'eval_loss_4': 0.23843568563461304, 'epoch': 2.03}
{'loss': 0.061, 'grad_norm': 14.715506553649902, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.05069010704755783, 'loss_2': 0.01027679443359375, 'loss_3': -15.540191650390625, 'loss_4': 0.3887304365634918, 'epoch': 2.04}
{'loss': 0.0846, 'grad_norm': 14.725422859191895, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.05579034984111786, 'loss_2': 0.028778076171875, 'loss_3': -15.570843696594238, 'loss_4': 0.676947832107544, 'epoch': 2.05}
{'loss': 0.0559, 'grad_norm': 11.786458969116211, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.030184723436832428, 'loss_2': 0.0257568359375, 'loss_3': -15.63417911529541, 'loss_4': 0.2887727916240692, 'epoch': 2.05}
{'loss': 0.0652, 'grad_norm': 17.00250816345215, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.052869975566864014, 'loss_2': 0.0122833251953125, 'loss_3': -15.602858543395996, 'loss_4': 1.227980613708496, 'epoch': 2.06}
{'loss': 0.0402, 'grad_norm': 8.675622940063477, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.03300032392144203, 'loss_2': 0.0072174072265625, 'loss_3': -15.688940048217773, 'loss_4': 1.2094647884368896, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 12:29:54,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:54,964 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:14<1:23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:02,312 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023027298972010612, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.019343912601470947, 'eval_loss_2': 0.0036833882331848145, 'eval_loss_3': -18.270950317382812, 'eval_loss_4': 0.96626877784729, 'epoch': 2.06}
{'loss': 0.0496, 'grad_norm': 13.982514381408691, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.04688910394906998, 'loss_2': 0.002712249755859375, 'loss_3': -15.550439834594727, 'loss_4': 1.1470928192138672, 'epoch': 2.07}
{'loss': 0.0715, 'grad_norm': 17.18124008178711, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.0536499060690403, 'loss_2': 0.0178070068359375, 'loss_3': -15.587425231933594, 'loss_4': 1.0434229373931885, 'epoch': 2.08}
{'loss': 0.0231, 'grad_norm': 7.902846336364746, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.018021078780293465, 'loss_2': 0.00510406494140625, 'loss_3': -15.718389511108398, 'loss_4': 1.448591947555542, 'epoch': 2.08}
{'loss': 0.055, 'grad_norm': 12.133996963500977, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.042854659259319305, 'loss_2': 0.012115478515625, 'loss_3': -15.621435165405273, 'loss_4': 1.840489387512207, 'epoch': 2.09}
{'loss': 0.0385, 'grad_norm': 16.75189208984375, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.037045422941446304, 'loss_2': 0.0014591217041015625, 'loss_3': -15.521690368652344, 'loss_4': 1.618713617324829, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 12:30:02,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:02,313 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:21<1:23:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:09,657 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03160040080547333, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.804, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019619865342974663, 'eval_loss_2': 0.011980533599853516, 'eval_loss_3': -18.28940200805664, 'eval_loss_4': 1.3001394271850586, 'epoch': 2.09}
{'loss': 0.0658, 'grad_norm': 16.65125274658203, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.057024821639060974, 'loss_2': 0.00872802734375, 'loss_3': -15.638139724731445, 'loss_4': 1.780820608139038, 'epoch': 2.1}
{'loss': 0.0276, 'grad_norm': 6.306177616119385, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.01755470037460327, 'loss_2': 0.01009368896484375, 'loss_3': -15.771169662475586, 'loss_4': 1.3716214895248413, 'epoch': 2.1}
{'loss': 0.0579, 'grad_norm': 16.210159301757812, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.04860733076930046, 'loss_2': 0.0092620849609375, 'loss_3': -15.580268859863281, 'loss_4': 1.366981029510498, 'epoch': 2.11}
{'loss': 0.0426, 'grad_norm': 10.838237762451172, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.03342151641845703, 'loss_2': 0.00922393798828125, 'loss_3': -15.698622703552246, 'loss_4': 1.5204517841339111, 'epoch': 2.12}
{'loss': 0.0568, 'grad_norm': 15.792664527893066, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.05667576566338539, 'loss_2': 0.00012159347534179688, 'loss_3': -15.415807723999023, 'loss_4': 1.4606690406799316, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 12:30:09,657 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:09,657 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:28<1:22:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:16,998 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0267581045627594, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.898, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01845434308052063, 'eval_loss_2': 0.00830376148223877, 'eval_loss_3': -18.276947021484375, 'eval_loss_4': 1.5366233587265015, 'epoch': 2.12}
{'loss': 0.0526, 'grad_norm': 13.306583404541016, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.045277535915374756, 'loss_2': 0.007366180419921875, 'loss_3': -15.48167896270752, 'loss_4': 1.2969545125961304, 'epoch': 2.13}
{'loss': 0.0688, 'grad_norm': 17.184301376342773, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.05190690606832504, 'loss_2': 0.01690673828125, 'loss_3': -15.773098945617676, 'loss_4': 1.862720251083374, 'epoch': 2.13}
{'loss': 0.0652, 'grad_norm': 14.776110649108887, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.05894031375646591, 'loss_2': 0.006256103515625, 'loss_3': -15.661649703979492, 'loss_4': 2.025144100189209, 'epoch': 2.14}
{'loss': 0.0441, 'grad_norm': 8.593791007995605, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.030917152762413025, 'loss_2': 0.013153076171875, 'loss_3': -15.422389030456543, 'loss_4': 1.9829423427581787, 'epoch': 2.15}
{'loss': 0.058, 'grad_norm': 11.040534019470215, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.04171086475253105, 'loss_2': 0.0162811279296875, 'loss_3': -15.490471839904785, 'loss_4': 1.9921388626098633, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 12:30:16,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:16,998 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:36<1:22:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:24,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02549806982278824, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.992, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.017569994553923607, 'eval_loss_2': 0.007928073406219482, 'eval_loss_3': -18.251638412475586, 'eval_loss_4': 1.7723093032836914, 'epoch': 2.15}
{'loss': 0.0337, 'grad_norm': 7.719708442687988, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.022721627727150917, 'loss_2': 0.01102447509765625, 'loss_3': -15.650028228759766, 'loss_4': 1.5998339653015137, 'epoch': 2.16}
{'loss': 0.1492, 'grad_norm': 24.278350830078125, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.14382511377334595, 'loss_2': 0.0053863525390625, 'loss_3': -15.431471824645996, 'loss_4': 1.2455253601074219, 'epoch': 2.16}
{'loss': 0.0703, 'grad_norm': 23.778066635131836, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.06770298629999161, 'loss_2': 0.002613067626953125, 'loss_3': -15.537199020385742, 'loss_4': 1.7316533327102661, 'epoch': 2.17}
{'loss': 0.0316, 'grad_norm': 8.343835830688477, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.02324504964053631, 'loss_2': 0.00838470458984375, 'loss_3': -15.57458782196045, 'loss_4': 1.9331518411636353, 'epoch': 2.17}
{'loss': 0.0517, 'grad_norm': 14.360103607177734, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.038952700793743134, 'loss_2': 0.01275634765625, 'loss_3': -15.430914878845215, 'loss_4': 1.4176913499832153, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 12:30:24,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:24,336 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:43<1:22:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:31,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03121885471045971, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.939, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018436281010508537, 'eval_loss_2': 0.012782573699951172, 'eval_loss_3': -18.245676040649414, 'eval_loss_4': 1.824245810508728, 'epoch': 2.18}
{'loss': 0.0647, 'grad_norm': 24.750333786010742, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.05253445357084274, 'loss_2': 0.01214599609375, 'loss_3': -15.444351196289062, 'loss_4': 2.1027894020080566, 'epoch': 2.19}
{'loss': 0.0454, 'grad_norm': 9.205150604248047, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.031213829293847084, 'loss_2': 0.01422119140625, 'loss_3': -15.699514389038086, 'loss_4': 1.684740424156189, 'epoch': 2.19}
{'loss': 0.062, 'grad_norm': 12.744498252868652, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.051882799714803696, 'loss_2': 0.01009368896484375, 'loss_3': -15.559612274169922, 'loss_4': 1.526151418685913, 'epoch': 2.2}
{'loss': 0.0892, 'grad_norm': 17.374778747558594, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.08720754832029343, 'loss_2': 0.001956939697265625, 'loss_3': -15.58941650390625, 'loss_4': 1.3723690509796143, 'epoch': 2.2}
{'loss': 0.0373, 'grad_norm': 14.495626449584961, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.034996677190065384, 'loss_2': 0.00229644775390625, 'loss_3': -15.695390701293945, 'loss_4': 1.3450467586517334, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 12:30:31,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:31,679 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:51<1:22:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:39,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025470945984125137, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.511, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01895836368203163, 'eval_loss_2': 0.006512582302093506, 'eval_loss_3': -18.2412109375, 'eval_loss_4': 1.0490092039108276, 'epoch': 2.21}
{'loss': 0.0873, 'grad_norm': 21.25575828552246, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.0812222957611084, 'loss_2': 0.00603485107421875, 'loss_3': -15.838102340698242, 'loss_4': 1.398465871810913, 'epoch': 2.22}
{'loss': 0.0383, 'grad_norm': 10.003639221191406, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.03469174727797508, 'loss_2': 0.00356292724609375, 'loss_3': -15.714414596557617, 'loss_4': 0.6181682348251343, 'epoch': 2.22}
{'loss': 0.092, 'grad_norm': 23.29149627685547, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.08141250908374786, 'loss_2': 0.0105743408203125, 'loss_3': -15.490175247192383, 'loss_4': 0.7030495405197144, 'epoch': 2.23}
{'loss': 0.0415, 'grad_norm': 12.238017082214355, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.038589466363191605, 'loss_2': 0.002918243408203125, 'loss_3': -15.689884185791016, 'loss_4': 0.4969981610774994, 'epoch': 2.23}
{'loss': 0.0412, 'grad_norm': 17.317153930664062, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.04097800701856613, 'loss_2': 0.00018644332885742188, 'loss_3': -15.664892196655273, 'loss_4': 0.17616954445838928, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 12:30:39,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:39,025 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [09:58<1:22:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:46,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026147879660129547, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.027, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.02205822616815567, 'eval_loss_2': 0.004089653491973877, 'eval_loss_3': -18.181562423706055, 'eval_loss_4': 0.13918399810791016, 'epoch': 2.24}
{'loss': 0.0317, 'grad_norm': 9.732926368713379, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.025756433606147766, 'loss_2': 0.00589752197265625, 'loss_3': -15.519333839416504, 'loss_4': -0.4932235777378082, 'epoch': 2.24}
{'loss': 0.0837, 'grad_norm': 27.250722885131836, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.08237124979496002, 'loss_2': 0.001369476318359375, 'loss_3': -15.790946006774902, 'loss_4': 0.28096580505371094, 'epoch': 2.25}
{'loss': 0.0764, 'grad_norm': 21.598691940307617, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.07176453620195389, 'loss_2': 0.00460052490234375, 'loss_3': -15.55985164642334, 'loss_4': 0.44656842947006226, 'epoch': 2.26}
{'loss': 0.0465, 'grad_norm': 15.04943561553955, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.03456135466694832, 'loss_2': 0.0119171142578125, 'loss_3': -15.85254192352295, 'loss_4': -0.015632376074790955, 'epoch': 2.26}
{'loss': 0.0416, 'grad_norm': 12.440052032470703, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.035313982516527176, 'loss_2': 0.00629425048828125, 'loss_3': -15.761194229125977, 'loss_4': -0.06507977843284607, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 12:30:46,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:46,373 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:05<1:22:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:53,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03559595346450806, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.802, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.02897147461771965, 'eval_loss_2': 0.006624475121498108, 'eval_loss_3': -18.11353874206543, 'eval_loss_4': -0.062451548874378204, 'epoch': 2.27}
{'loss': 0.0702, 'grad_norm': 18.721498489379883, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.05942533165216446, 'loss_2': 0.010772705078125, 'loss_3': -15.676896095275879, 'loss_4': -0.5282407402992249, 'epoch': 2.27}
{'loss': 0.0456, 'grad_norm': 10.97275447845459, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.03364067152142525, 'loss_2': 0.0119171142578125, 'loss_3': -15.80236530303955, 'loss_4': 0.022642605006694794, 'epoch': 2.28}
{'loss': 0.0302, 'grad_norm': 9.278608322143555, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.020644139498472214, 'loss_2': 0.0095062255859375, 'loss_3': -15.797928810119629, 'loss_4': -0.35509243607521057, 'epoch': 2.28}
{'loss': 0.0658, 'grad_norm': 19.435745239257812, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.05829037353396416, 'loss_2': 0.007503509521484375, 'loss_3': -15.648770332336426, 'loss_4': -0.03866196423768997, 'epoch': 2.29}
{'loss': 0.0463, 'grad_norm': 12.29053783416748, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.0382968969643116, 'loss_2': 0.00800323486328125, 'loss_3': -15.740226745605469, 'loss_4': -0.17469574511051178, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 12:30:53,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:53,716 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:13<1:22:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:01,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03140147775411606, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.023489562794566154, 'eval_loss_2': 0.007911920547485352, 'eval_loss_3': -18.14342498779297, 'eval_loss_4': 0.00849107000976801, 'epoch': 2.3}
{'loss': 0.0674, 'grad_norm': 17.419654846191406, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.06205998733639717, 'loss_2': 0.00533294677734375, 'loss_3': -15.691139221191406, 'loss_4': 0.17218419909477234, 'epoch': 2.3}
{'loss': 0.0319, 'grad_norm': 11.713634490966797, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.028480516746640205, 'loss_2': 0.003406524658203125, 'loss_3': -15.859052658081055, 'loss_4': 0.1481105089187622, 'epoch': 2.31}
{'loss': 0.0384, 'grad_norm': 16.609209060668945, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.03655807301402092, 'loss_2': 0.0018262863159179688, 'loss_3': -15.834956169128418, 'loss_4': 0.3064984381198883, 'epoch': 2.31}
{'loss': 0.1176, 'grad_norm': 22.38355827331543, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.11686259508132935, 'loss_2': 0.0007123947143554688, 'loss_3': -15.519128799438477, 'loss_4': 0.6729204058647156, 'epoch': 2.32}
{'loss': 0.0989, 'grad_norm': 15.03734302520752, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.09572360664606094, 'loss_2': 0.0032196044921875, 'loss_3': -15.71800422668457, 'loss_4': 0.5822027325630188, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 12:31:01,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:01,054 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:20<1:22:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:08,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02742263861000538, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.875, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.023621298372745514, 'eval_loss_2': 0.0038013383746147156, 'eval_loss_3': -18.158592224121094, 'eval_loss_4': 0.444507896900177, 'epoch': 2.33}
{'loss': 0.0417, 'grad_norm': 9.342655181884766, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.029337028041481972, 'loss_2': 0.0123291015625, 'loss_3': -15.862590789794922, 'loss_4': 0.5569729208946228, 'epoch': 2.33}
{'loss': 0.0423, 'grad_norm': 16.149282455444336, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.03839831054210663, 'loss_2': 0.00392913818359375, 'loss_3': -15.73560905456543, 'loss_4': 0.46826881170272827, 'epoch': 2.34}
{'loss': 0.0406, 'grad_norm': 9.528706550598145, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.02990603633224964, 'loss_2': 0.0107269287109375, 'loss_3': -15.840230941772461, 'loss_4': 0.33399754762649536, 'epoch': 2.34}
{'loss': 0.0306, 'grad_norm': 8.238892555236816, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.02430078759789467, 'loss_2': 0.00627899169921875, 'loss_3': -15.71794319152832, 'loss_4': 0.503420352935791, 'epoch': 2.35}
{'loss': 0.0533, 'grad_norm': 12.33298110961914, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.049226172268390656, 'loss_2': 0.00408172607421875, 'loss_3': -15.663064956665039, 'loss_4': 0.8416211605072021, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 12:31:08,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:08,399 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:27<1:22:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:15,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03342412784695625, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.513, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.029495973140001297, 'eval_loss_2': 0.003928154706954956, 'eval_loss_3': -18.12759017944336, 'eval_loss_4': 0.6368716955184937, 'epoch': 2.35}
{'loss': 0.0473, 'grad_norm': 14.826993942260742, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.04263611137866974, 'loss_2': 0.0046234130859375, 'loss_3': -15.613618850708008, 'loss_4': 1.0756957530975342, 'epoch': 2.36}
{'loss': 0.0424, 'grad_norm': 10.695011138916016, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.0345129631459713, 'loss_2': 0.00791168212890625, 'loss_3': -15.619009017944336, 'loss_4': 0.28511881828308105, 'epoch': 2.37}
{'loss': 0.0457, 'grad_norm': 13.834541320800781, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.04232145845890045, 'loss_2': 0.0033721923828125, 'loss_3': -15.517369270324707, 'loss_4': 0.5264195203781128, 'epoch': 2.37}
{'loss': 0.0227, 'grad_norm': 9.654504776000977, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.020475655794143677, 'loss_2': 0.0022144317626953125, 'loss_3': -15.682955741882324, 'loss_4': 0.3819727897644043, 'epoch': 2.38}
{'loss': 0.0285, 'grad_norm': 9.041786193847656, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.025866631418466568, 'loss_2': 0.0026683807373046875, 'loss_3': -15.674138069152832, 'loss_4': 0.7703108787536621, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 12:31:15,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:15,739 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:35<1:21:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:23,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02703755721449852, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.48, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02390911988914013, 'eval_loss_2': 0.00312843918800354, 'eval_loss_3': -18.134613037109375, 'eval_loss_4': 0.4263475835323334, 'epoch': 2.38}
{'loss': 0.0431, 'grad_norm': 13.259323120117188, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.041776251047849655, 'loss_2': 0.001293182373046875, 'loss_3': -15.617522239685059, 'loss_4': 0.737002968788147, 'epoch': 2.39}
{'loss': 0.098, 'grad_norm': 25.963871002197266, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.09022779762744904, 'loss_2': 0.00774383544921875, 'loss_3': -15.55367660522461, 'loss_4': 0.5222745537757874, 'epoch': 2.4}
{'loss': 0.0443, 'grad_norm': 10.767326354980469, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.03320733830332756, 'loss_2': 0.0110931396484375, 'loss_3': -15.586938858032227, 'loss_4': 0.15913251042366028, 'epoch': 2.4}
{'loss': 0.037, 'grad_norm': 13.170981407165527, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.02595173753798008, 'loss_2': 0.01107025146484375, 'loss_3': -15.756168365478516, 'loss_4': 0.17659714818000793, 'epoch': 2.41}
{'loss': 0.0344, 'grad_norm': 10.24620246887207, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.03052479773759842, 'loss_2': 0.0038604736328125, 'loss_3': -15.78652572631836, 'loss_4': 0.19839522242546082, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 12:31:23,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:23,079 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:42<1:22:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:30,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026122495532035828, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.131, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.0219726525247097, 'eval_loss_2': 0.004149839282035828, 'eval_loss_3': -18.146080017089844, 'eval_loss_4': 0.3315419852733612, 'epoch': 2.41}
{'loss': 0.0269, 'grad_norm': 8.40347671508789, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.022175097838044167, 'loss_2': 0.00469970703125, 'loss_3': -15.522326469421387, 'loss_4': 0.32949355244636536, 'epoch': 2.42}
{'loss': 0.0627, 'grad_norm': 13.537297248840332, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.04580201208591461, 'loss_2': 0.0168914794921875, 'loss_3': -15.680213928222656, 'loss_4': 0.742114245891571, 'epoch': 2.42}
{'loss': 0.0305, 'grad_norm': 7.363919258117676, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.024104131385684013, 'loss_2': 0.006378173828125, 'loss_3': -15.782875061035156, 'loss_4': 0.8923500776290894, 'epoch': 2.43}
{'loss': 0.0307, 'grad_norm': 10.398942947387695, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.02523215301334858, 'loss_2': 0.00543212890625, 'loss_3': -15.863543510437012, 'loss_4': 0.8793405890464783, 'epoch': 2.44}
{'loss': 0.0536, 'grad_norm': 17.251943588256836, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.05305776000022888, 'loss_2': 0.000507354736328125, 'loss_3': -15.92561149597168, 'loss_4': 0.484732985496521, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 12:31:30,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:30,426 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:49<1:21:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:37,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031019067391753197, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.262, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01974186673760414, 'eval_loss_2': 0.011277198791503906, 'eval_loss_3': -18.17163848876953, 'eval_loss_4': 0.2502121329307556, 'epoch': 2.44}
{'loss': 0.0696, 'grad_norm': 27.475936889648438, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.06600028276443481, 'loss_2': 0.00360107421875, 'loss_3': -15.634695053100586, 'loss_4': 0.5435034036636353, 'epoch': 2.45}
{'loss': 0.0387, 'grad_norm': 9.85739803314209, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.02682608924806118, 'loss_2': 0.0118865966796875, 'loss_3': -15.669677734375, 'loss_4': 0.39211857318878174, 'epoch': 2.45}
{'loss': 0.0369, 'grad_norm': 8.271696090698242, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.025425218045711517, 'loss_2': 0.0114288330078125, 'loss_3': -15.907827377319336, 'loss_4': 0.41721683740615845, 'epoch': 2.46}
{'loss': 0.1065, 'grad_norm': 28.487903594970703, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.09962639212608337, 'loss_2': 0.00682830810546875, 'loss_3': -15.882316589355469, 'loss_4': 0.9329895973205566, 'epoch': 2.47}
{'loss': 0.0649, 'grad_norm': 16.65341567993164, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.0556102953851223, 'loss_2': 0.009246826171875, 'loss_3': -15.510476112365723, 'loss_4': 1.0770907402038574, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 12:31:37,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:37,760 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [10:57<1:21:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:45,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02951652556657791, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.206, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01935965195298195, 'eval_loss_2': 0.010156869888305664, 'eval_loss_3': -18.167797088623047, 'eval_loss_4': 0.07292574644088745, 'epoch': 2.47}
{'loss': 0.064, 'grad_norm': 15.559494972229004, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.048145413398742676, 'loss_2': 0.01580810546875, 'loss_3': -15.799213409423828, 'loss_4': 0.03825443238019943, 'epoch': 2.48}
{'loss': 0.0658, 'grad_norm': 15.556411743164062, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.053893525153398514, 'loss_2': 0.0118865966796875, 'loss_3': -15.769407272338867, 'loss_4': 0.4782044589519501, 'epoch': 2.48}
{'loss': 0.0749, 'grad_norm': 16.145343780517578, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.06550399959087372, 'loss_2': 0.0093994140625, 'loss_3': -15.569549560546875, 'loss_4': -0.3328634798526764, 'epoch': 2.49}
{'loss': 0.0316, 'grad_norm': 7.582927703857422, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.028227532282471657, 'loss_2': 0.003345489501953125, 'loss_3': -15.809460639953613, 'loss_4': -0.05706973373889923, 'epoch': 2.49}
{'loss': 0.099, 'grad_norm': 23.306777954101562, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.09726016223430634, 'loss_2': 0.0017518997192382812, 'loss_3': -15.825180053710938, 'loss_4': 0.2545948326587677, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 12:31:45,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:45,086 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:04<1:21:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:52,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028668353334069252, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.043, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.02017713524401188, 'eval_loss_2': 0.008491218090057373, 'eval_loss_3': -18.118759155273438, 'eval_loss_4': -0.21568036079406738, 'epoch': 2.5}
{'loss': 0.0701, 'grad_norm': 16.077394485473633, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.05877186357975006, 'loss_2': 0.0113067626953125, 'loss_3': -15.90969467163086, 'loss_4': 0.6976588368415833, 'epoch': 2.51}
{'loss': 0.0752, 'grad_norm': 21.76245880126953, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.06167987734079361, 'loss_2': 0.0135498046875, 'loss_3': -15.633824348449707, 'loss_4': 0.5474417209625244, 'epoch': 2.51}
{'loss': 0.0637, 'grad_norm': 13.181262016296387, 'learning_rate': 2.75e-05, 'loss_1': 0.060708656907081604, 'loss_2': 0.00295257568359375, 'loss_3': -15.74445915222168, 'loss_4': 0.06809850037097931, 'epoch': 2.52}
{'loss': 0.2133, 'grad_norm': 39.341880798339844, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.19886575639247894, 'loss_2': 0.014404296875, 'loss_3': -15.585649490356445, 'loss_4': 0.8100686073303223, 'epoch': 2.52}
{'loss': 0.0469, 'grad_norm': 11.349719047546387, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.036212850362062454, 'loss_2': 0.0106658935546875, 'loss_3': -15.814523696899414, 'loss_4': -0.4010545015335083, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 12:31:52,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:52,425 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:11<1:21:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:59,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029240122064948082, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.279, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.021632423624396324, 'eval_loss_2': 0.007607698440551758, 'eval_loss_3': -18.156326293945312, 'eval_loss_4': -0.1571517288684845, 'epoch': 2.53}
{'loss': 0.0943, 'grad_norm': 23.866552352905273, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.08813877403736115, 'loss_2': 0.006195068359375, 'loss_3': -15.897982597351074, 'loss_4': 0.3864139914512634, 'epoch': 2.53}
{'loss': 0.0816, 'grad_norm': 18.396940231323242, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.07204568386077881, 'loss_2': 0.00958251953125, 'loss_3': -15.978754043579102, 'loss_4': 0.7332998514175415, 'epoch': 2.54}
{'loss': 0.0881, 'grad_norm': 17.349586486816406, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.08491435647010803, 'loss_2': 0.00322723388671875, 'loss_3': -15.756853103637695, 'loss_4': 0.1824280023574829, 'epoch': 2.55}
{'loss': 0.088, 'grad_norm': 18.94898223876953, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.0854148119688034, 'loss_2': 0.002620697021484375, 'loss_3': -15.86436939239502, 'loss_4': 0.5135701894760132, 'epoch': 2.55}
{'loss': 0.04, 'grad_norm': 14.478208541870117, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.036645930260419846, 'loss_2': 0.0033969879150390625, 'loss_3': -15.876893997192383, 'loss_4': 0.4305728077888489, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 12:31:59,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:59,780 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:19<1:21:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:07,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02711414359509945, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.094, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0212323609739542, 'eval_loss_2': 0.005881786346435547, 'eval_loss_3': -18.21933937072754, 'eval_loss_4': -0.0907244086265564, 'epoch': 2.56}
{'loss': 0.0537, 'grad_norm': 14.647330284118652, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.04561610892415047, 'loss_2': 0.0080718994140625, 'loss_3': -15.798643112182617, 'loss_4': 0.27629005908966064, 'epoch': 2.56}
{'loss': 0.0733, 'grad_norm': 29.642610549926758, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.057472825050354004, 'loss_2': 0.0158538818359375, 'loss_3': -15.940662384033203, 'loss_4': 0.18978671729564667, 'epoch': 2.57}
{'loss': 0.0929, 'grad_norm': 23.690568923950195, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.08277066797018051, 'loss_2': 0.0101318359375, 'loss_3': -15.943672180175781, 'loss_4': 0.4441470801830292, 'epoch': 2.58}
{'loss': 0.0957, 'grad_norm': 25.75783920288086, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.09175409376621246, 'loss_2': 0.00390625, 'loss_3': -15.87550163269043, 'loss_4': 1.244857668876648, 'epoch': 2.58}
{'loss': 0.0976, 'grad_norm': 33.00487518310547, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.09662460535764694, 'loss_2': 0.00098419189453125, 'loss_3': -15.820380210876465, 'loss_4': 0.06790130585432053, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 12:32:07,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:07,117 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:26<1:21:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:14,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029358722269535065, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.951, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02086958847939968, 'eval_loss_2': 0.008489131927490234, 'eval_loss_3': -18.209211349487305, 'eval_loss_4': 0.23758478462696075, 'epoch': 2.59}
{'loss': 0.0749, 'grad_norm': 15.971686363220215, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.06151551380753517, 'loss_2': 0.01336669921875, 'loss_3': -15.761570930480957, 'loss_4': 0.407267689704895, 'epoch': 2.59}
{'loss': 0.0537, 'grad_norm': 13.097184181213379, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.05020441859960556, 'loss_2': 0.00350189208984375, 'loss_3': -15.819670677185059, 'loss_4': 0.5248389840126038, 'epoch': 2.6}
{'loss': 0.0499, 'grad_norm': 13.420595169067383, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.044754508882761, 'loss_2': 0.0051727294921875, 'loss_3': -15.958386421203613, 'loss_4': 0.9920864105224609, 'epoch': 2.6}
{'loss': 0.0514, 'grad_norm': 17.849227905273438, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.04848971962928772, 'loss_2': 0.00290679931640625, 'loss_3': -15.943181037902832, 'loss_4': 0.6713491678237915, 'epoch': 2.61}
{'loss': 0.0749, 'grad_norm': 16.527685165405273, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.07328011095523834, 'loss_2': 0.0015735626220703125, 'loss_3': -15.879968643188477, 'loss_4': 1.2449181079864502, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 12:32:14,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:14,462 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:30<1:21:30,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:32:18,253 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-450
[INFO|configuration_utils.py:420] 2025-01-21 12:32:18,255 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-450/config.json                                                                             
{'eval_loss': 0.022069914266467094, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01946171373128891, 'eval_loss_2': 0.0026081986725330353, 'eval_loss_3': -18.18183708190918, 'eval_loss_4': 0.8177471160888672, 'epoch': 2.62}
[INFO|modeling_utils.py:2988] 2025-01-21 12:32:18,735 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-450/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:32:18,736 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:32:18,736 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-450/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:32:19,541 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-260] due to args.save_total_limit
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:35<1:29:10,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:32:23,192 >>
{'loss': 0.0631, 'grad_norm': 16.323272705078125, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.06213740259408951, 'loss_2': 0.0009546279907226562, 'loss_3': -15.809616088867188, 'loss_4': 0.9483882188796997, 'epoch': 2.62}
{'loss': 0.0723, 'grad_norm': 21.688152313232422, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.07114358991384506, 'loss_2': 0.0011768341064453125, 'loss_3': -16.073530197143555, 'loss_4': 1.1584901809692383, 'epoch': 2.63}
{'loss': 0.0663, 'grad_norm': 18.561548233032227, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.06096754968166351, 'loss_2': 0.005340576171875, 'loss_3': -15.721231460571289, 'loss_4': 1.2363321781158447, 'epoch': 2.63}
{'loss': 0.0839, 'grad_norm': 23.09178924560547, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.07878927886486053, 'loss_2': 0.0051116943359375, 'loss_3': -15.747479438781738, 'loss_4': 1.9302339553833008, 'epoch': 2.64}
{'loss': 0.037, 'grad_norm': 13.06279468536377, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.034804508090019226, 'loss_2': 0.0022258758544921875, 'loss_3': -15.807677268981934, 'loss_4': 1.4973230361938477, 'epoch': 2.65}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:32:23,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:23,192 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:42<1:22:33,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:32:30,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02741255611181259, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.382, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02202429622411728, 'eval_loss_2': 0.0053882598876953125, 'eval_loss_3': -18.140859603881836, 'eval_loss_4': 1.2903364896774292, 'epoch': 2.65}
{'loss': 0.0482, 'grad_norm': 11.419586181640625, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.04025615006685257, 'loss_2': 0.0079498291015625, 'loss_3': -15.74349594116211, 'loss_4': 1.393796682357788, 'epoch': 2.65}
{'loss': 0.0317, 'grad_norm': 9.415908813476562, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.031340815126895905, 'loss_2': 0.0004038810729980469, 'loss_3': -15.885058403015137, 'loss_4': 1.6130567789077759, 'epoch': 2.66}
{'loss': 0.0275, 'grad_norm': 10.183618545532227, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.026445820927619934, 'loss_2': 0.001026153564453125, 'loss_3': -15.59277629852295, 'loss_4': 1.69606614112854, 'epoch': 2.66}
{'loss': 0.0441, 'grad_norm': 8.063421249389648, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.030724508687853813, 'loss_2': 0.01337432861328125, 'loss_3': -15.78870964050293, 'loss_4': 2.0382187366485596, 'epoch': 2.67}
{'loss': 0.155, 'grad_norm': 28.90894317626953, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.14949451386928558, 'loss_2': 0.005535125732421875, 'loss_3': -15.690824508666992, 'loss_4': 1.8852975368499756, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 12:32:30,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:30,527 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:49<1:21:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:37,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029348891228437424, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.1, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.02488384023308754, 'eval_loss_2': 0.004465050995349884, 'eval_loss_3': -18.10797119140625, 'eval_loss_4': 1.6810038089752197, 'epoch': 2.67}
{'loss': 0.0371, 'grad_norm': 7.548059940338135, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.027225416153669357, 'loss_2': 0.0098419189453125, 'loss_3': -15.722752571105957, 'loss_4': 1.5236637592315674, 'epoch': 2.68}
{'loss': 0.0496, 'grad_norm': 13.893653869628906, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.04268529266119003, 'loss_2': 0.006893157958984375, 'loss_3': -15.657639503479004, 'loss_4': 2.182126522064209, 'epoch': 2.69}
{'loss': 0.0462, 'grad_norm': 15.434192657470703, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.04024261236190796, 'loss_2': 0.006000518798828125, 'loss_3': -15.596075057983398, 'loss_4': 1.558266043663025, 'epoch': 2.69}
{'loss': 0.0573, 'grad_norm': 13.556681632995605, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.040235843509435654, 'loss_2': 0.0170440673828125, 'loss_3': -15.395517349243164, 'loss_4': 1.9274437427520752, 'epoch': 2.7}
{'loss': 0.0535, 'grad_norm': 16.55443000793457, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.05111930891871452, 'loss_2': 0.002361297607421875, 'loss_3': -15.617523193359375, 'loss_4': 1.7257059812545776, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 12:32:37,870 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:37,870 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [11:57<1:21:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:45,208 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02549615502357483, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.978, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02233979105949402, 'eval_loss_2': 0.0031563639640808105, 'eval_loss_3': -18.108964920043945, 'eval_loss_4': 1.6572058200836182, 'epoch': 2.7}
{'loss': 0.0351, 'grad_norm': 7.827998161315918, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.0284865852445364, 'loss_2': 0.006622314453125, 'loss_3': -15.66818618774414, 'loss_4': 1.7351254224777222, 'epoch': 2.71}
{'loss': 0.0427, 'grad_norm': 14.621258735656738, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.042155832052230835, 'loss_2': 0.0005197525024414062, 'loss_3': -15.568610191345215, 'loss_4': 1.4222506284713745, 'epoch': 2.72}
{'loss': 0.0455, 'grad_norm': 15.139876365661621, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.03744281828403473, 'loss_2': 0.00807952880859375, 'loss_3': -15.675804138183594, 'loss_4': 1.2297186851501465, 'epoch': 2.72}
{'loss': 0.0734, 'grad_norm': 24.866003036499023, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.058114197105169296, 'loss_2': 0.0152587890625, 'loss_3': -15.545567512512207, 'loss_4': 1.3335936069488525, 'epoch': 2.73}
{'loss': 0.0558, 'grad_norm': 14.895098686218262, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.041868340224027634, 'loss_2': 0.0139617919921875, 'loss_3': -15.683845520019531, 'loss_4': 1.541528344154358, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 12:32:45,208 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:45,208 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:04<1:20:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:52,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0383959598839283, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.221, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.021188335493206978, 'eval_loss_2': 0.017207622528076172, 'eval_loss_3': -18.130367279052734, 'eval_loss_4': 1.482192039489746, 'epoch': 2.73}
{'loss': 0.1226, 'grad_norm': 34.21492004394531, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.10633701831102371, 'loss_2': 0.0163116455078125, 'loss_3': -15.456075668334961, 'loss_4': 1.9559868574142456, 'epoch': 2.74}
{'loss': 0.0655, 'grad_norm': 23.02028465270996, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.05366161838173866, 'loss_2': 0.0118408203125, 'loss_3': -15.516899108886719, 'loss_4': 1.8194903135299683, 'epoch': 2.74}
{'loss': 0.0664, 'grad_norm': 23.285526275634766, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.047040633857250214, 'loss_2': 0.019317626953125, 'loss_3': -15.609058380126953, 'loss_4': 1.7299000024795532, 'epoch': 2.75}
{'loss': 0.0623, 'grad_norm': 14.206015586853027, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.048574019223451614, 'loss_2': 0.01377105712890625, 'loss_3': -15.541215896606445, 'loss_4': 0.8377474546432495, 'epoch': 2.76}
{'loss': 0.0647, 'grad_norm': 16.650049209594727, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.051039986312389374, 'loss_2': 0.01366424560546875, 'loss_3': -15.601380348205566, 'loss_4': 1.6379692554473877, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 12:32:52,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:52,541 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:11<1:20:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:59,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04325813800096512, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.228, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.03142685070633888, 'eval_loss_2': 0.011831283569335938, 'eval_loss_3': -18.100034713745117, 'eval_loss_4': 1.4075651168823242, 'epoch': 2.76}
{'loss': 0.0811, 'grad_norm': 18.30263328552246, 'learning_rate': 2.725e-05, 'loss_1': 0.07227064669132233, 'loss_2': 0.0088348388671875, 'loss_3': -15.650871276855469, 'loss_4': 1.6067577600479126, 'epoch': 2.77}
{'loss': 0.0474, 'grad_norm': 13.400949478149414, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.04406267777085304, 'loss_2': 0.0033473968505859375, 'loss_3': -15.627300262451172, 'loss_4': 1.8296921253204346, 'epoch': 2.77}
{'loss': 0.0805, 'grad_norm': 18.780698776245117, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.0705212727189064, 'loss_2': 0.00997161865234375, 'loss_3': -15.663631439208984, 'loss_4': 1.6165387630462646, 'epoch': 2.78}
{'loss': 0.0564, 'grad_norm': 16.25684356689453, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.05589135363698006, 'loss_2': 0.0005044937133789062, 'loss_3': -15.459365844726562, 'loss_4': 1.3937761783599854, 'epoch': 2.78}
{'loss': 0.0431, 'grad_norm': 16.85486602783203, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.04060060530900955, 'loss_2': 0.002532958984375, 'loss_3': -15.505244255065918, 'loss_4': 0.924775242805481, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 12:32:59,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:59,883 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:19<1:20:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:07,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05171991512179375, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.272, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.045260198414325714, 'eval_loss_2': 0.006459712982177734, 'eval_loss_3': -18.032411575317383, 'eval_loss_4': 1.070417881011963, 'epoch': 2.79}
{'loss': 0.0568, 'grad_norm': 17.80149269104004, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.050615932792425156, 'loss_2': 0.00616455078125, 'loss_3': -15.481996536254883, 'loss_4': 1.2784907817840576, 'epoch': 2.8}
{'loss': 0.0527, 'grad_norm': 17.11199188232422, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.04560455307364464, 'loss_2': 0.00713348388671875, 'loss_3': -15.604789733886719, 'loss_4': 1.3007628917694092, 'epoch': 2.8}
{'loss': 0.0234, 'grad_norm': 7.440064430236816, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.021179113537073135, 'loss_2': 0.0022029876708984375, 'loss_3': -15.766910552978516, 'loss_4': 0.7609053254127502, 'epoch': 2.81}
{'loss': 0.1271, 'grad_norm': 46.44568634033203, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.12344111502170563, 'loss_2': 0.003612518310546875, 'loss_3': -15.529354095458984, 'loss_4': 1.169614315032959, 'epoch': 2.81}
{'loss': 0.0491, 'grad_norm': 18.139793395996094, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.04887128621339798, 'loss_2': 0.00025010108947753906, 'loss_3': -15.707035064697266, 'loss_4': 0.9051798582077026, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 12:33:07,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:07,211 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:26<1:20:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:14,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030222248286008835, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.356, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.025192223489284515, 'eval_loss_2': 0.005030021071434021, 'eval_loss_3': -18.147750854492188, 'eval_loss_4': 0.619937539100647, 'epoch': 2.82}
{'loss': 0.0721, 'grad_norm': 19.65867042541504, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.07085993885993958, 'loss_2': 0.0012416839599609375, 'loss_3': -15.554512023925781, 'loss_4': 1.0569357872009277, 'epoch': 2.83}
{'loss': 0.0615, 'grad_norm': 16.116073608398438, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.04505641758441925, 'loss_2': 0.0164794921875, 'loss_3': -15.625219345092773, 'loss_4': 0.6402422785758972, 'epoch': 2.83}
{'loss': 0.024, 'grad_norm': 8.743951797485352, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.021449413150548935, 'loss_2': 0.002559661865234375, 'loss_3': -15.806976318359375, 'loss_4': 0.5692343711853027, 'epoch': 2.84}
{'loss': 0.0517, 'grad_norm': 12.215374946594238, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.0388743095099926, 'loss_2': 0.01280975341796875, 'loss_3': -15.826448440551758, 'loss_4': 0.6534901261329651, 'epoch': 2.84}
{'loss': 0.0327, 'grad_norm': 8.663509368896484, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.02216155454516411, 'loss_2': 0.0105133056640625, 'loss_3': -15.779618263244629, 'loss_4': 0.8944922089576721, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 12:33:14,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:14,543 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:33<1:20:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:21,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024198949337005615, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.544, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01882588490843773, 'eval_loss_2': 0.005373060703277588, 'eval_loss_3': -18.240638732910156, 'eval_loss_4': 0.9038891792297363, 'epoch': 2.85}
{'loss': 0.0714, 'grad_norm': 24.63941764831543, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.0689559131860733, 'loss_2': 0.0024776458740234375, 'loss_3': -15.613630294799805, 'loss_4': 1.0940769910812378, 'epoch': 2.85}
{'loss': 0.0339, 'grad_norm': 9.486483573913574, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.030949804931879044, 'loss_2': 0.0029621124267578125, 'loss_3': -15.518211364746094, 'loss_4': 1.1756633520126343, 'epoch': 2.86}
{'loss': 0.1482, 'grad_norm': 36.16722106933594, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.1343763768672943, 'loss_2': 0.013824462890625, 'loss_3': -15.710333824157715, 'loss_4': 2.276338577270508, 'epoch': 2.87}
{'loss': 0.0683, 'grad_norm': 20.444597244262695, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.06110524386167526, 'loss_2': 0.007221221923828125, 'loss_3': -15.712751388549805, 'loss_4': 1.3710222244262695, 'epoch': 2.87}
{'loss': 0.0437, 'grad_norm': 13.618423461914062, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.04221566021442413, 'loss_2': 0.001438140869140625, 'loss_3': -15.494344711303711, 'loss_4': 1.8798370361328125, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 12:33:21,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:21,885 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:41<1:20:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:29,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028091194108128548, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.567, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018809257075190544, 'eval_loss_2': 0.009281933307647705, 'eval_loss_3': -18.235265731811523, 'eval_loss_4': 1.3881266117095947, 'epoch': 2.88}
{'loss': 0.0557, 'grad_norm': 13.781820297241211, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.04688215255737305, 'loss_2': 0.00885772705078125, 'loss_3': -15.77557373046875, 'loss_4': 1.815765619277954, 'epoch': 2.88}
{'loss': 0.0692, 'grad_norm': 17.30451774597168, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.05795056372880936, 'loss_2': 0.01123046875, 'loss_3': -15.653383255004883, 'loss_4': 2.453580141067505, 'epoch': 2.89}
{'loss': 0.045, 'grad_norm': 8.928189277648926, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.03167303279042244, 'loss_2': 0.01332855224609375, 'loss_3': -15.38892650604248, 'loss_4': 1.9249931573867798, 'epoch': 2.9}
{'loss': 0.025, 'grad_norm': 6.905555725097656, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.01730162650346756, 'loss_2': 0.0077362060546875, 'loss_3': -15.618036270141602, 'loss_4': 1.321732997894287, 'epoch': 2.9}
{'loss': 0.0734, 'grad_norm': 18.99884033203125, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.06309033185243607, 'loss_2': 0.01031494140625, 'loss_3': -15.79755973815918, 'loss_4': 1.4853596687316895, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 12:33:29,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:29,241 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:48<1:20:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:36,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028782285749912262, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.024815088137984276, 'eval_loss_2': 0.003967195749282837, 'eval_loss_3': -18.12075424194336, 'eval_loss_4': 1.5030429363250732, 'epoch': 2.91}
{'loss': 0.0253, 'grad_norm': 8.848405838012695, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.02447953075170517, 'loss_2': 0.0008172988891601562, 'loss_3': -15.427545547485352, 'loss_4': 2.031970977783203, 'epoch': 2.91}
{'loss': 0.0624, 'grad_norm': 13.404793739318848, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.042530618607997894, 'loss_2': 0.019866943359375, 'loss_3': -15.334013938903809, 'loss_4': 1.5244090557098389, 'epoch': 2.92}
{'loss': 0.0804, 'grad_norm': 27.1594181060791, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.06640452891588211, 'loss_2': 0.0140228271484375, 'loss_3': -15.488075256347656, 'loss_4': 1.3450303077697754, 'epoch': 2.92}
{'loss': 0.0728, 'grad_norm': 20.421884536743164, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.05611483380198479, 'loss_2': 0.01666259765625, 'loss_3': -15.40906047821045, 'loss_4': 0.800204873085022, 'epoch': 2.93}
{'loss': 0.0425, 'grad_norm': 8.413056373596191, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.02482595294713974, 'loss_2': 0.0176544189453125, 'loss_3': -15.476606369018555, 'loss_4': 1.4444308280944824, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 12:33:36,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:36,592 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [12:55<1:20:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:43,941 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.053727105259895325, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.886, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.03765149042010307, 'eval_loss_2': 0.016075611114501953, 'eval_loss_3': -18.053600311279297, 'eval_loss_4': 1.5529811382293701, 'epoch': 2.94}
{'loss': 0.0617, 'grad_norm': 19.18760871887207, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.05183887481689453, 'loss_2': 0.0098876953125, 'loss_3': -15.362653732299805, 'loss_4': 1.7668280601501465, 'epoch': 2.94}
{'loss': 0.0941, 'grad_norm': 21.24741554260254, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.07919484376907349, 'loss_2': 0.014862060546875, 'loss_3': -15.55440616607666, 'loss_4': 1.577660083770752, 'epoch': 2.95}
{'loss': 0.0867, 'grad_norm': 17.454618453979492, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.07023143768310547, 'loss_2': 0.0164337158203125, 'loss_3': -15.788941383361816, 'loss_4': 1.9070532321929932, 'epoch': 2.95}
{'loss': 0.053, 'grad_norm': 19.01003074645996, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.044767286628484726, 'loss_2': 0.00823974609375, 'loss_3': -15.563777923583984, 'loss_4': 1.6503204107284546, 'epoch': 2.96}
{'loss': 0.1411, 'grad_norm': 27.920053482055664, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.1364249289035797, 'loss_2': 0.004627227783203125, 'loss_3': -15.414046287536621, 'loss_4': 2.502091407775879, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 12:33:43,941 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:43,941 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:03<1:19:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:33:51,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07526662200689316, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.867, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.07164162397384644, 'eval_loss_2': 0.0036249980330467224, 'eval_loss_3': -17.9627742767334, 'eval_loss_4': 2.387296676635742, 'epoch': 2.97}
{'loss': 0.0797, 'grad_norm': 19.061506271362305, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.07906197756528854, 'loss_2': 0.0006856918334960938, 'loss_3': -15.5661039352417, 'loss_4': 2.298715114593506, 'epoch': 2.97}
{'loss': 0.0495, 'grad_norm': 10.844054222106934, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.03909120708703995, 'loss_2': 0.01036834716796875, 'loss_3': -15.595157623291016, 'loss_4': 2.3344435691833496, 'epoch': 2.98}
{'loss': 0.1293, 'grad_norm': 25.362506866455078, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.12590523064136505, 'loss_2': 0.003387451171875, 'loss_3': -15.50189208984375, 'loss_4': 2.9551310539245605, 'epoch': 2.98}
{'loss': 0.2067, 'grad_norm': 34.105506896972656, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.1991795301437378, 'loss_2': 0.0075531005859375, 'loss_3': -15.373272895812988, 'loss_4': 2.9060792922973633, 'epoch': 2.99}
{'loss': 0.0926, 'grad_norm': 23.078561782836914, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.07983625680208206, 'loss_2': 0.0127410888671875, 'loss_3': -15.78738021850586, 'loss_4': 2.3543143272399902, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 12:33:51,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:51,271 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:10<1:18:45,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:33:58,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06929751485586166, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.642, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.06227297708392143, 'eval_loss_2': 0.007024526596069336, 'eval_loss_3': -17.979246139526367, 'eval_loss_4': 2.678677797317505, 'epoch': 2.99}
{'loss': 0.1402, 'grad_norm': 28.653018951416016, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.14006276428699493, 'loss_2': 0.00013136863708496094, 'loss_3': -15.66420841217041, 'loss_4': 2.3080193996429443, 'epoch': 3.0}
{'loss': 0.0699, 'grad_norm': 16.61538314819336, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.06677675992250443, 'loss_2': 0.003124237060546875, 'loss_3': -15.623551368713379, 'loss_4': 2.8244595527648926, 'epoch': 3.01}
{'loss': 0.087, 'grad_norm': 32.40961837768555, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.07724224776029587, 'loss_2': 0.0097808837890625, 'loss_3': -15.657188415527344, 'loss_4': 2.4105920791625977, 'epoch': 3.01}
{'loss': 0.1283, 'grad_norm': 30.495405197143555, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.1254437267780304, 'loss_2': 0.002819061279296875, 'loss_3': -15.951620101928711, 'loss_4': 1.979237675666809, 'epoch': 3.02}
{'loss': 0.0705, 'grad_norm': 18.14889907836914, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.06846658140420914, 'loss_2': 0.002079010009765625, 'loss_3': -15.744630813598633, 'loss_4': 2.846066951751709, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 12:33:58,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:58,330 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:17<1:19:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:34:05,664 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025204811245203018, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.411, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.019352467730641365, 'eval_loss_2': 0.005852341651916504, 'eval_loss_3': -18.18370246887207, 'eval_loss_4': 2.3941245079040527, 'epoch': 3.02}
{'loss': 0.0563, 'grad_norm': 12.686323165893555, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.0488152876496315, 'loss_2': 0.00746917724609375, 'loss_3': -15.517072677612305, 'loss_4': 2.2221310138702393, 'epoch': 3.03}
{'loss': 0.0618, 'grad_norm': 13.50457763671875, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.058066073805093765, 'loss_2': 0.00371551513671875, 'loss_3': -15.524434089660645, 'loss_4': 2.8835361003875732, 'epoch': 3.03}
{'loss': 0.0475, 'grad_norm': 12.11809253692627, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.04183294624090195, 'loss_2': 0.00569915771484375, 'loss_3': -15.7542724609375, 'loss_4': 3.348332166671753, 'epoch': 3.04}
{'loss': 0.0478, 'grad_norm': 15.710968017578125, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.042838919907808304, 'loss_2': 0.00496673583984375, 'loss_3': -15.735416412353516, 'loss_4': 3.3348772525787354, 'epoch': 3.05}
{'loss': 0.0681, 'grad_norm': 19.948284149169922, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.06444643437862396, 'loss_2': 0.003688812255859375, 'loss_3': -15.600678443908691, 'loss_4': 2.365485429763794, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 12:34:05,664 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:05,664 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:25<1:20:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:13,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02439568191766739, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.97, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02015451341867447, 'eval_loss_2': 0.00424116849899292, 'eval_loss_3': -18.240018844604492, 'eval_loss_4': 2.4502742290496826, 'epoch': 3.05}
{'loss': 0.0984, 'grad_norm': 28.22411346435547, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.09652719646692276, 'loss_2': 0.0019216537475585938, 'loss_3': -15.743002891540527, 'loss_4': 3.127300262451172, 'epoch': 3.06}
{'loss': 0.0472, 'grad_norm': 11.929800987243652, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.03953611105680466, 'loss_2': 0.007686614990234375, 'loss_3': -15.823859214782715, 'loss_4': 3.2517337799072266, 'epoch': 3.06}
{'loss': 0.1473, 'grad_norm': 36.73397445678711, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.1436803638935089, 'loss_2': 0.003612518310546875, 'loss_3': -15.76997184753418, 'loss_4': 2.992393970489502, 'epoch': 3.07}
{'loss': 0.0384, 'grad_norm': 14.349130630493164, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.037634361535310745, 'loss_2': 0.000751495361328125, 'loss_3': -15.7498197555542, 'loss_4': 2.6481666564941406, 'epoch': 3.08}
{'loss': 0.048, 'grad_norm': 12.419671058654785, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.04735827445983887, 'loss_2': 0.0006132125854492188, 'loss_3': -15.858996391296387, 'loss_4': 2.6329283714294434, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 12:34:13,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:13,011 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:28<1:20:07,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:34:16,805 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-530
[INFO|configuration_utils.py:420] 2025-01-21 12:34:16,807 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-530/config.json                                                                             
{'eval_loss': 0.0220506489276886, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.994, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.017323577776551247, 'eval_loss_2': 0.004727073013782501, 'eval_loss_3': -18.216957092285156, 'eval_loss_4': 1.2945829629898071, 'epoch': 3.08}
[INFO|modeling_utils.py:2988] 2025-01-21 12:34:17,267 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-530/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:34:17,269 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-530/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:34:17,269 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-530/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:34:18,060 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-450] due to args.save_total_limit
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:33<1:27:13,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 12:34:21,677 >>
{'loss': 0.1179, 'grad_norm': 34.78238296508789, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.11405305564403534, 'loss_2': 0.0038051605224609375, 'loss_3': -15.91763973236084, 'loss_4': 2.0176873207092285, 'epoch': 3.09}
{'loss': 0.0346, 'grad_norm': 11.49704647064209, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.029500212520360947, 'loss_2': 0.0050506591796875, 'loss_3': -15.648027420043945, 'loss_4': 1.494316577911377, 'epoch': 3.09}
{'loss': 0.042, 'grad_norm': 15.589905738830566, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.03772333264350891, 'loss_2': 0.0042572021484375, 'loss_3': -15.822827339172363, 'loss_4': 0.9044067859649658, 'epoch': 3.1}
{'loss': 0.0305, 'grad_norm': 9.261085510253906, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.02360481210052967, 'loss_2': 0.00690460205078125, 'loss_3': -15.858071327209473, 'loss_4': 0.766861617565155, 'epoch': 3.1}
{'loss': 0.0572, 'grad_norm': 17.454233169555664, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.05036946013569832, 'loss_2': 0.00678253173828125, 'loss_3': -15.827695846557617, 'loss_4': 0.6389708518981934, 'epoch': 3.11}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:34:21,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:21,677 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:41<1:21:09,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:34:29,026 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022599870339035988, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.018775472417473793, 'eval_loss_2': 0.003824397921562195, 'eval_loss_3': -18.152854919433594, 'eval_loss_4': 0.3618878424167633, 'epoch': 3.11}
{'loss': 0.0592, 'grad_norm': 26.009235382080078, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.058654021471738815, 'loss_2': 0.0005445480346679688, 'loss_3': -15.732609748840332, 'loss_4': 0.43187418580055237, 'epoch': 3.12}
{'loss': 0.0306, 'grad_norm': 13.328594207763672, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.026997247710824013, 'loss_2': 0.003597259521484375, 'loss_3': -15.645098686218262, 'loss_4': 0.17999887466430664, 'epoch': 3.12}
{'loss': 0.0484, 'grad_norm': 14.635104179382324, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.04756006598472595, 'loss_2': 0.0008854866027832031, 'loss_3': -15.669078826904297, 'loss_4': 0.701694667339325, 'epoch': 3.13}
{'loss': 0.0361, 'grad_norm': 9.70322322845459, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.031579941511154175, 'loss_2': 0.004558563232421875, 'loss_3': -15.771295547485352, 'loss_4': 0.16140595078468323, 'epoch': 3.13}
{'loss': 0.016, 'grad_norm': 5.619114875793457, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.011558123864233494, 'loss_2': 0.00443267822265625, 'loss_3': -15.954782485961914, 'loss_4': 0.3411572575569153, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 12:34:29,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:29,026 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:48<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:36,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0325314924120903, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.295, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.029169132933020592, 'eval_loss_2': 0.0033623576164245605, 'eval_loss_3': -18.081005096435547, 'eval_loss_4': 0.044195834547281265, 'epoch': 3.14}
{'loss': 0.0203, 'grad_norm': 6.126102924346924, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.015871386975049973, 'loss_2': 0.00443267822265625, 'loss_3': -15.688422203063965, 'loss_4': -0.07552964240312576, 'epoch': 3.15}
{'loss': 0.0866, 'grad_norm': 34.77532958984375, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.0817718505859375, 'loss_2': 0.004795074462890625, 'loss_3': -15.61336898803711, 'loss_4': 0.04247862100601196, 'epoch': 3.15}
{'loss': 0.1038, 'grad_norm': 30.336904525756836, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.09328549355268478, 'loss_2': 0.010467529296875, 'loss_3': -15.96036148071289, 'loss_4': 0.64943528175354, 'epoch': 3.16}
{'loss': 0.041, 'grad_norm': 9.697307586669922, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.03666369989514351, 'loss_2': 0.00437164306640625, 'loss_3': -15.890848159790039, 'loss_4': -0.1251411885023117, 'epoch': 3.16}
{'loss': 0.0238, 'grad_norm': 7.1896586418151855, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.023186497390270233, 'loss_2': 0.0005655288696289062, 'loss_3': -15.774969100952148, 'loss_4': 0.14388428628444672, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 12:34:36,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:36,358 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [13:55<1:19:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:43,697 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0221151951700449, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.967, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.019210871309041977, 'eval_loss_2': 0.0029043257236480713, 'eval_loss_3': -18.182998657226562, 'eval_loss_4': 0.028097176924347878, 'epoch': 3.17}
{'loss': 0.0458, 'grad_norm': 15.88162612915039, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.042218174785375595, 'loss_2': 0.003631591796875, 'loss_3': -15.684043884277344, 'loss_4': -0.028625667095184326, 'epoch': 3.17}
{'loss': 0.0375, 'grad_norm': 9.15149974822998, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.03033500351011753, 'loss_2': 0.007171630859375, 'loss_3': -15.844661712646484, 'loss_4': 0.1278846710920334, 'epoch': 3.18}
{'loss': 0.0317, 'grad_norm': 9.646746635437012, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.029431423172354698, 'loss_2': 0.002223968505859375, 'loss_3': -15.746294021606445, 'loss_4': -0.2107279747724533, 'epoch': 3.19}
{'loss': 0.0359, 'grad_norm': 11.212552070617676, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.03414168953895569, 'loss_2': 0.0017118453979492188, 'loss_3': -15.7806978225708, 'loss_4': 0.08090749382972717, 'epoch': 3.19}
{'loss': 0.0379, 'grad_norm': 13.159798622131348, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.037846341729164124, 'loss_2': 1.1444091796875e-05, 'loss_3': -15.764265060424805, 'loss_4': 0.36943867802619934, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 12:34:43,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:43,697 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:03<1:19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:51,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022371217608451843, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.452, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014902845025062561, 'eval_loss_2': 0.007468372583389282, 'eval_loss_3': -18.188034057617188, 'eval_loss_4': 0.10253328830003738, 'epoch': 3.2}
{'loss': 0.043, 'grad_norm': 8.503625869750977, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.028034958988428116, 'loss_2': 0.0149383544921875, 'loss_3': -16.025888442993164, 'loss_4': 0.8604044914245605, 'epoch': 3.2}
{'loss': 0.0241, 'grad_norm': 7.008605480194092, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.014405016787350178, 'loss_2': 0.00970458984375, 'loss_3': -15.916587829589844, 'loss_4': 0.6844482421875, 'epoch': 3.21}
{'loss': 0.0345, 'grad_norm': 12.55429458618164, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.03015359491109848, 'loss_2': 0.00434112548828125, 'loss_3': -15.782214164733887, 'loss_4': 0.5138136148452759, 'epoch': 3.22}
{'loss': 0.0307, 'grad_norm': 11.71971321105957, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.02733744867146015, 'loss_2': 0.003406524658203125, 'loss_3': -15.841381072998047, 'loss_4': 0.6074645519256592, 'epoch': 3.22}
{'loss': 0.043, 'grad_norm': 16.65018653869629, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.04169111326336861, 'loss_2': 0.0013275146484375, 'loss_3': -15.824153900146484, 'loss_4': 0.563944399356842, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 12:34:51,030 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:51,030 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:06<1:19:35,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:34:54,822 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-555
[INFO|configuration_utils.py:420] 2025-01-21 12:34:54,823 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-555/config.json                                                                             
{'eval_loss': 0.01922421157360077, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.131, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014353513717651367, 'eval_loss_2': 0.004870697855949402, 'eval_loss_3': -18.22211456298828, 'eval_loss_4': 0.38554859161376953, 'epoch': 3.23}
[INFO|modeling_utils.py:2988] 2025-01-21 12:34:55,290 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-555/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:34:55,291 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-555/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:34:55,291 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-555/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:34:56,090 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-530] due to args.save_total_limit
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:11<1:26:59,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 12:34:59,725 >>
{'loss': 0.0451, 'grad_norm': 11.358471870422363, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.04263832047581673, 'loss_2': 0.002490997314453125, 'loss_3': -15.812259674072266, 'loss_4': 1.2872498035430908, 'epoch': 3.23}
{'loss': 0.0382, 'grad_norm': 10.967995643615723, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.03279361128807068, 'loss_2': 0.00543975830078125, 'loss_3': -15.903875350952148, 'loss_4': 0.8843464851379395, 'epoch': 3.24}
{'loss': 0.0415, 'grad_norm': 12.854588508605957, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.034708354622125626, 'loss_2': 0.006748199462890625, 'loss_3': -15.750446319580078, 'loss_4': 0.9102759957313538, 'epoch': 3.24}
{'loss': 0.0581, 'grad_norm': 13.09152603149414, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.04975688457489014, 'loss_2': 0.008392333984375, 'loss_3': -15.771754264831543, 'loss_4': 0.88889479637146, 'epoch': 3.25}
{'loss': 0.0284, 'grad_norm': 7.592825889587402, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.02638128586113453, 'loss_2': 0.0019702911376953125, 'loss_3': -15.827289581298828, 'loss_4': 0.8566316962242126, 'epoch': 3.26}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:34:59,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:59,725 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:19<1:20:41,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:35:07,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02101438120007515, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.849, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015787038952112198, 'eval_loss_2': 0.005227342247962952, 'eval_loss_3': -18.205547332763672, 'eval_loss_4': 0.46384677290916443, 'epoch': 3.26}
{'loss': 0.0417, 'grad_norm': 10.089823722839355, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.03754088282585144, 'loss_2': 0.00420379638671875, 'loss_3': -15.719053268432617, 'loss_4': 1.060147762298584, 'epoch': 3.26}
{'loss': 0.0232, 'grad_norm': 6.959726333618164, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.01812087930738926, 'loss_2': 0.005035400390625, 'loss_3': -15.801229476928711, 'loss_4': 0.5100077390670776, 'epoch': 3.27}
{'loss': 0.0693, 'grad_norm': 14.40422534942627, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.054218441247940063, 'loss_2': 0.0150604248046875, 'loss_3': -15.90041446685791, 'loss_4': 0.7679492831230164, 'epoch': 3.27}
{'loss': 0.0289, 'grad_norm': 8.672396659851074, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.026916341856122017, 'loss_2': 0.0020046234130859375, 'loss_3': -15.853096008300781, 'loss_4': 1.1046335697174072, 'epoch': 3.28}
{'loss': 0.0541, 'grad_norm': 13.461823463439941, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.05143792927265167, 'loss_2': 0.00270843505859375, 'loss_3': -15.730539321899414, 'loss_4': 0.35759711265563965, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 12:35:07,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:07,062 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:22<1:20:41,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 12:35:10,850 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-565
[INFO|configuration_utils.py:420] 2025-01-21 12:35:10,851 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-565/config.json                                                                             
{'eval_loss': 0.018032170832157135, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.436, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014150239527225494, 'eval_loss_2': 0.0038819313049316406, 'eval_loss_3': -18.272422790527344, 'eval_loss_4': 0.3850317597389221, 'epoch': 3.28}
[INFO|modeling_utils.py:2988] 2025-01-21 12:35:11,317 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-565/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:35:11,318 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-565/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:35:11,318 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-565/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:35:12,112 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-555] due to args.save_total_limit
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:27<1:26:46,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 12:35:15,726 >>
{'loss': 0.0375, 'grad_norm': 8.842096328735352, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.032824501395225525, 'loss_2': 0.00469970703125, 'loss_3': -15.933602333068848, 'loss_4': 0.5638570785522461, 'epoch': 3.29}
{'loss': 0.0473, 'grad_norm': 16.768516540527344, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.04589901491999626, 'loss_2': 0.00144195556640625, 'loss_3': -15.763956069946289, 'loss_4': 0.5271590948104858, 'epoch': 3.3}
{'loss': 0.0563, 'grad_norm': 22.592287063598633, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.055970966815948486, 'loss_2': 0.0003399848937988281, 'loss_3': -15.789285659790039, 'loss_4': 1.107140302658081, 'epoch': 3.3}
{'loss': 0.057, 'grad_norm': 16.5438175201416, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.053677719086408615, 'loss_2': 0.00330352783203125, 'loss_3': -15.935543060302734, 'loss_4': 0.5414673089981079, 'epoch': 3.31}
{'loss': 0.0677, 'grad_norm': 15.377532958984375, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.05626111477613449, 'loss_2': 0.011444091796875, 'loss_3': -15.893022537231445, 'loss_4': 0.5504242181777954, 'epoch': 3.31}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:35:15,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:15,726 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:35<1:20:25,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:35:23,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021090419963002205, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.257, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.015247509814798832, 'eval_loss_2': 0.005842909216880798, 'eval_loss_3': -18.246265411376953, 'eval_loss_4': -0.01385763380676508, 'epoch': 3.31}
{'loss': 0.0686, 'grad_norm': 20.139577865600586, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.06315221637487411, 'loss_2': 0.00543212890625, 'loss_3': -15.920740127563477, 'loss_4': 0.8562549352645874, 'epoch': 3.32}
{'loss': 0.028, 'grad_norm': 6.88752555847168, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.02183705009520054, 'loss_2': 0.00612640380859375, 'loss_3': -15.810281753540039, 'loss_4': -0.06472654640674591, 'epoch': 3.33}
{'loss': 0.0373, 'grad_norm': 9.787252426147461, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.0314192958176136, 'loss_2': 0.00589752197265625, 'loss_3': -15.878921508789062, 'loss_4': -0.36014509201049805, 'epoch': 3.33}
{'loss': 0.1163, 'grad_norm': 15.88485336303711, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.112552709877491, 'loss_2': 0.003753662109375, 'loss_3': -15.938467025756836, 'loss_4': -0.02160733938217163, 'epoch': 3.34}
{'loss': 0.1215, 'grad_norm': 25.26073455810547, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.11697109043598175, 'loss_2': 0.004489898681640625, 'loss_3': -15.940995216369629, 'loss_4': -0.08818943798542023, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 12:35:23,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:23,063 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:42<1:19:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:30,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024517357349395752, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.366, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.020817486569285393, 'eval_loss_2': 0.00369986891746521, 'eval_loss_3': -18.187850952148438, 'eval_loss_4': -0.4026182293891907, 'epoch': 3.34}
{'loss': 0.051, 'grad_norm': 14.635750770568848, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.04755858704447746, 'loss_2': 0.00348663330078125, 'loss_3': -15.930728912353516, 'loss_4': -0.2869500517845154, 'epoch': 3.35}
{'loss': 0.0467, 'grad_norm': 12.071102142333984, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.04240942373871803, 'loss_2': 0.00433349609375, 'loss_3': -15.901960372924805, 'loss_4': -0.8624719381332397, 'epoch': 3.35}
{'loss': 0.0387, 'grad_norm': 10.522664070129395, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.037441685795784, 'loss_2': 0.0012979507446289062, 'loss_3': -15.933971405029297, 'loss_4': -0.5839333534240723, 'epoch': 3.36}
{'loss': 0.0642, 'grad_norm': 17.09795379638672, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.05417415127158165, 'loss_2': 0.010040283203125, 'loss_3': -15.722803115844727, 'loss_4': 0.13797348737716675, 'epoch': 3.37}
{'loss': 0.0823, 'grad_norm': 16.42207145690918, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.07840035855770111, 'loss_2': 0.003856658935546875, 'loss_3': -15.539111137390137, 'loss_4': 0.18402478098869324, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 12:35:30,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:30,391 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:49<1:19:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:37,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03254159539937973, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.092, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.029625730589032173, 'eval_loss_2': 0.0029158666729927063, 'eval_loss_3': -18.148038864135742, 'eval_loss_4': -0.2408401370048523, 'epoch': 3.37}
{'loss': 0.0658, 'grad_norm': 16.660680770874023, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.06091391295194626, 'loss_2': 0.00492095947265625, 'loss_3': -15.812366485595703, 'loss_4': -0.40157413482666016, 'epoch': 3.38}
{'loss': 0.0766, 'grad_norm': 23.501127243041992, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.06916996091604233, 'loss_2': 0.00745391845703125, 'loss_3': -15.934683799743652, 'loss_4': 0.05033577233552933, 'epoch': 3.38}
{'loss': 0.0504, 'grad_norm': 11.324111938476562, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.03954426199197769, 'loss_2': 0.01084136962890625, 'loss_3': -15.761920928955078, 'loss_4': 0.24744479358196259, 'epoch': 3.39}
{'loss': 0.032, 'grad_norm': 10.628528594970703, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.03145924210548401, 'loss_2': 0.0005674362182617188, 'loss_3': -15.892294883728027, 'loss_4': 0.14659383893013, 'epoch': 3.4}
{'loss': 0.0619, 'grad_norm': 17.722929000854492, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.0604439452290535, 'loss_2': 0.001499176025390625, 'loss_3': -15.674383163452148, 'loss_4': 0.26124829053878784, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 12:35:37,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:37,732 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:57<1:18:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:45,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.039102546870708466, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.261, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.03176126629114151, 'eval_loss_2': 0.007341280579566956, 'eval_loss_3': -18.12706756591797, 'eval_loss_4': 0.31954994797706604, 'epoch': 3.4}
{'loss': 0.0336, 'grad_norm': 7.701915740966797, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.022068142890930176, 'loss_2': 0.011505126953125, 'loss_3': -15.837034225463867, 'loss_4': 0.2813872694969177, 'epoch': 3.41}
{'loss': 0.0541, 'grad_norm': 12.992500305175781, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.040468327701091766, 'loss_2': 0.01367950439453125, 'loss_3': -16.146812438964844, 'loss_4': 0.6629219055175781, 'epoch': 3.41}
{'loss': 0.0525, 'grad_norm': 14.755301475524902, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.040218908339738846, 'loss_2': 0.012298583984375, 'loss_3': -16.036867141723633, 'loss_4': 0.23896563053131104, 'epoch': 3.42}
{'loss': 0.1305, 'grad_norm': 21.96751594543457, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.12542526423931122, 'loss_2': 0.005100250244140625, 'loss_3': -15.759078979492188, 'loss_4': 0.3870701193809509, 'epoch': 3.42}
{'loss': 0.0529, 'grad_norm': 12.939958572387695, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.052709028124809265, 'loss_2': 0.00014257431030273438, 'loss_3': -15.823628425598145, 'loss_4': 0.7093912363052368, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 12:35:45,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:45,062 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:04<1:18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:52,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.062231093645095825, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.945, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.057514552026987076, 'eval_loss_2': 0.004716545343399048, 'eval_loss_3': -17.991134643554688, 'eval_loss_4': 0.7566399574279785, 'epoch': 3.43}
{'loss': 0.0623, 'grad_norm': 17.012426376342773, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.06119144335389137, 'loss_2': 0.001132965087890625, 'loss_3': -15.876304626464844, 'loss_4': 1.1515963077545166, 'epoch': 3.44}
{'loss': 0.0529, 'grad_norm': 16.057390213012695, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.052438486367464066, 'loss_2': 0.00045561790466308594, 'loss_3': -15.609673500061035, 'loss_4': 0.8158915042877197, 'epoch': 3.44}
{'loss': 0.0317, 'grad_norm': 7.583496570587158, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.02534693293273449, 'loss_2': 0.00638580322265625, 'loss_3': -15.818216323852539, 'loss_4': 1.3190109729766846, 'epoch': 3.45}
{'loss': 0.0588, 'grad_norm': 15.415523529052734, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.05156630277633667, 'loss_2': 0.00725555419921875, 'loss_3': -15.384880065917969, 'loss_4': 0.9789319038391113, 'epoch': 3.45}
{'loss': 0.0443, 'grad_norm': 16.230634689331055, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.035674359649419785, 'loss_2': 0.008636474609375, 'loss_3': -15.831497192382812, 'loss_4': 1.2270219326019287, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 12:35:52,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:52,407 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:11<1:18:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:59,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06320662051439285, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.821, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.053931668400764465, 'eval_loss_2': 0.009274959564208984, 'eval_loss_3': -18.04808235168457, 'eval_loss_4': 1.146239995956421, 'epoch': 3.46}
{'loss': 0.034, 'grad_norm': 8.352157592773438, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.028341930359601974, 'loss_2': 0.005680084228515625, 'loss_3': -15.889710426330566, 'loss_4': 0.451616108417511, 'epoch': 3.47}
{'loss': 0.0359, 'grad_norm': 10.464250564575195, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.031434230506420135, 'loss_2': 0.004505157470703125, 'loss_3': -15.848431587219238, 'loss_4': 1.0962834358215332, 'epoch': 3.47}
{'loss': 0.0782, 'grad_norm': 21.216184616088867, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.06812003999948502, 'loss_2': 0.010040283203125, 'loss_3': -15.840421676635742, 'loss_4': 1.81907320022583, 'epoch': 3.48}
{'loss': 0.0637, 'grad_norm': 10.256811141967773, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.04491296783089638, 'loss_2': 0.0187530517578125, 'loss_3': -15.92647933959961, 'loss_4': 0.7681354284286499, 'epoch': 3.48}
{'loss': 0.0354, 'grad_norm': 9.881582260131836, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.022789178416132927, 'loss_2': 0.0125885009765625, 'loss_3': -15.939523696899414, 'loss_4': 1.218327283859253, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 12:35:59,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:59,751 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:19<1:18:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:07,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023237664252519608, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.843, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018181761726737022, 'eval_loss_2': 0.005055904388427734, 'eval_loss_3': -18.303075790405273, 'eval_loss_4': 1.157655954360962, 'epoch': 3.49}
{'loss': 0.0312, 'grad_norm': 13.033601760864258, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.02575961872935295, 'loss_2': 0.005401611328125, 'loss_3': -16.022306442260742, 'loss_4': 1.2982244491577148, 'epoch': 3.49}
{'loss': 0.0497, 'grad_norm': 16.816770553588867, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.048492491245269775, 'loss_2': 0.0012083053588867188, 'loss_3': -15.99441909790039, 'loss_4': 1.893604040145874, 'epoch': 3.5}
{'loss': 0.0772, 'grad_norm': 23.107507705688477, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.07554250955581665, 'loss_2': 0.0016508102416992188, 'loss_3': -15.901185989379883, 'loss_4': 0.6857515573501587, 'epoch': 3.51}
{'loss': 0.0229, 'grad_norm': 8.456957817077637, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.021602977067232132, 'loss_2': 0.0013322830200195312, 'loss_3': -15.914835929870605, 'loss_4': 1.2242846488952637, 'epoch': 3.51}
{'loss': 0.0229, 'grad_norm': 7.67987585067749, 'learning_rate': 2.65e-05, 'loss_1': 0.021886395290493965, 'loss_2': 0.0010385513305664062, 'loss_3': -15.958511352539062, 'loss_4': 1.7746529579162598, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 12:36:07,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:07,095 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:26<1:18:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:14,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02149348147213459, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.028, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.017498688772320747, 'eval_loss_2': 0.003994792699813843, 'eval_loss_3': -18.335834503173828, 'eval_loss_4': 1.324358582496643, 'epoch': 3.52}
{'loss': 0.0464, 'grad_norm': 10.890571594238281, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.04264547675848007, 'loss_2': 0.00371551513671875, 'loss_3': -15.850221633911133, 'loss_4': 1.3451826572418213, 'epoch': 3.52}
{'loss': 0.0628, 'grad_norm': 19.081588745117188, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.059112031012773514, 'loss_2': 0.00366973876953125, 'loss_3': -15.999601364135742, 'loss_4': 1.3887159824371338, 'epoch': 3.53}
{'loss': 0.0305, 'grad_norm': 10.557570457458496, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.027991827577352524, 'loss_2': 0.00252532958984375, 'loss_3': -15.933833122253418, 'loss_4': 1.1921886205673218, 'epoch': 3.53}
{'loss': 0.0489, 'grad_norm': 15.780157089233398, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.04334276169538498, 'loss_2': 0.00554656982421875, 'loss_3': -15.799203872680664, 'loss_4': 1.749660611152649, 'epoch': 3.54}
{'loss': 0.0892, 'grad_norm': 26.780000686645508, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.08288227021694183, 'loss_2': 0.00628662109375, 'loss_3': -16.04840660095215, 'loss_4': 0.9778604507446289, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 12:36:14,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:14,431 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:33<1:18:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:21,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020287424325942993, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.939, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016595136374235153, 'eval_loss_2': 0.00369228795170784, 'eval_loss_3': -18.322702407836914, 'eval_loss_4': 1.057551383972168, 'epoch': 3.55}
{'loss': 0.0313, 'grad_norm': 11.24765682220459, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.031145676970481873, 'loss_2': 0.00011813640594482422, 'loss_3': -15.896955490112305, 'loss_4': 1.2626490592956543, 'epoch': 3.55}
{'loss': 0.0414, 'grad_norm': 15.00248908996582, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.04103337600827217, 'loss_2': 0.00040030479431152344, 'loss_3': -15.860467910766602, 'loss_4': 1.697284460067749, 'epoch': 3.56}
{'loss': 0.0344, 'grad_norm': 16.598979949951172, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.03406351059675217, 'loss_2': 0.0003771781921386719, 'loss_3': -15.796283721923828, 'loss_4': 0.7825192213058472, 'epoch': 3.56}
{'loss': 0.0331, 'grad_norm': 12.302166938781738, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.030416034162044525, 'loss_2': 0.0026702880859375, 'loss_3': -15.810937881469727, 'loss_4': 0.8660538792610168, 'epoch': 3.57}
{'loss': 0.0421, 'grad_norm': 10.295681953430176, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.027982627972960472, 'loss_2': 0.0141143798828125, 'loss_3': -15.749704360961914, 'loss_4': 0.8489046096801758, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 12:36:21,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:21,769 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:41<1:18:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:29,116 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031503915786743164, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.716, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.025682775303721428, 'eval_loss_2': 0.005821138620376587, 'eval_loss_3': -18.231847763061523, 'eval_loss_4': 1.0384498834609985, 'epoch': 3.58}
{'loss': 0.0598, 'grad_norm': 14.5758056640625, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.05334480106830597, 'loss_2': 0.006439208984375, 'loss_3': -15.844379425048828, 'loss_4': 0.8459348678588867, 'epoch': 3.58}
{'loss': 0.0516, 'grad_norm': 15.09459114074707, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.04433061182498932, 'loss_2': 0.007305145263671875, 'loss_3': -15.778970718383789, 'loss_4': 1.00443696975708, 'epoch': 3.59}
{'loss': 0.0421, 'grad_norm': 10.79210376739502, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.036600030958652496, 'loss_2': 0.005523681640625, 'loss_3': -15.893914222717285, 'loss_4': 1.3782052993774414, 'epoch': 3.59}
{'loss': 0.0456, 'grad_norm': 13.94461727142334, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.035486213862895966, 'loss_2': 0.01007080078125, 'loss_3': -15.712435722351074, 'loss_4': 1.210889220237732, 'epoch': 3.6}
{'loss': 0.0191, 'grad_norm': 7.740815162658691, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.013553104363381863, 'loss_2': 0.00550079345703125, 'loss_3': -15.796378135681152, 'loss_4': 1.2738639116287231, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 12:36:29,116 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:29,116 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:48<1:22:54,  1.10s/it][INFO|trainer.py:4226] 2025-01-21 12:36:36,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04735706001520157, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.85, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.04344751685857773, 'eval_loss_2': 0.00390954315662384, 'eval_loss_3': -18.154159545898438, 'eval_loss_4': 1.3468773365020752, 'epoch': 3.6}
{'loss': 0.0432, 'grad_norm': 11.609016418457031, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.03298206627368927, 'loss_2': 0.01021575927734375, 'loss_3': -15.641191482543945, 'loss_4': 1.2619116306304932, 'epoch': 3.61}
{'loss': 0.0455, 'grad_norm': 14.734764099121094, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.045097462832927704, 'loss_2': 0.0003643035888671875, 'loss_3': -15.855463027954102, 'loss_4': 1.6527081727981567, 'epoch': 3.62}
{'loss': 0.0249, 'grad_norm': 6.462369918823242, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.01639261655509472, 'loss_2': 0.0084991455078125, 'loss_3': -15.78188705444336, 'loss_4': 1.5827555656433105, 'epoch': 3.62}
{'loss': 0.0592, 'grad_norm': 16.218677520751953, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.04399440065026283, 'loss_2': 0.01519012451171875, 'loss_3': -15.872821807861328, 'loss_4': 0.8278432488441467, 'epoch': 3.63}
{'loss': 0.0595, 'grad_norm': 14.836230278015137, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.05028203874826431, 'loss_2': 0.00917816162109375, 'loss_3': -15.661300659179688, 'loss_4': 1.0636978149414062, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 12:36:36,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:36,658 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:55<1:19:11,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:36:44,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07356134057044983, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.53, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.06397184729576111, 'eval_loss_2': 0.00958949327468872, 'eval_loss_3': -18.085811614990234, 'eval_loss_4': 1.5006961822509766, 'epoch': 3.63}
{'loss': 0.0595, 'grad_norm': 12.432584762573242, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.04387315735220909, 'loss_2': 0.015655517578125, 'loss_3': -15.794629096984863, 'loss_4': 1.1373953819274902, 'epoch': 3.64}
{'loss': 0.0207, 'grad_norm': 7.825259685516357, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.019168797880411148, 'loss_2': 0.0015583038330078125, 'loss_3': -15.813712120056152, 'loss_4': 1.6162426471710205, 'epoch': 3.65}
{'loss': 0.0777, 'grad_norm': 23.754915237426758, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.0684608668088913, 'loss_2': 0.00920867919921875, 'loss_3': -15.759355545043945, 'loss_4': 1.8549511432647705, 'epoch': 3.65}
{'loss': 0.0736, 'grad_norm': 23.237016677856445, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.06965631991624832, 'loss_2': 0.0039825439453125, 'loss_3': -15.943792343139648, 'loss_4': 1.631879448890686, 'epoch': 3.66}
{'loss': 0.1299, 'grad_norm': 21.339815139770508, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.12410803884267807, 'loss_2': 0.00574493408203125, 'loss_3': -15.648813247680664, 'loss_4': 2.0336806774139404, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 12:36:44,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:44,009 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [16:03<1:18:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:51,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04797714576125145, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.04317288100719452, 'eval_loss_2': 0.0048042647540569305, 'eval_loss_3': -18.130229949951172, 'eval_loss_4': 1.8349751234054565, 'epoch': 3.66}
{'loss': 0.0822, 'grad_norm': 25.088817596435547, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.08094419538974762, 'loss_2': 0.0012359619140625, 'loss_3': -15.604430198669434, 'loss_4': 1.7167479991912842, 'epoch': 3.67}
{'loss': 0.0315, 'grad_norm': 9.882821083068848, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.02887057326734066, 'loss_2': 0.002658843994140625, 'loss_3': -15.89370346069336, 'loss_4': 1.6875284910202026, 'epoch': 3.67}
{'loss': 0.0841, 'grad_norm': 23.940343856811523, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.07814954966306686, 'loss_2': 0.005950927734375, 'loss_3': -15.485926628112793, 'loss_4': 1.776639699935913, 'epoch': 3.68}
{'loss': 0.0352, 'grad_norm': 16.423078536987305, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.02955177240073681, 'loss_2': 0.005641937255859375, 'loss_3': -15.989583969116211, 'loss_4': 1.5854573249816895, 'epoch': 3.69}
{'loss': 0.0298, 'grad_norm': 9.200583457946777, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.0235839132219553, 'loss_2': 0.006244659423828125, 'loss_3': -16.109102249145508, 'loss_4': 2.593568801879883, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 12:36:51,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:51,361 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:10<1:18:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:58,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02053852379322052, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014819287694990635, 'eval_loss_2': 0.00571923702955246, 'eval_loss_3': -18.25812339782715, 'eval_loss_4': 2.121654510498047, 'epoch': 3.69}
{'loss': 0.0284, 'grad_norm': 6.398584842681885, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.015526694245636463, 'loss_2': 0.0128936767578125, 'loss_3': -15.74856948852539, 'loss_4': 2.0399770736694336, 'epoch': 3.7}
{'loss': 0.0225, 'grad_norm': 9.098711967468262, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.02089111879467964, 'loss_2': 0.0016155242919921875, 'loss_3': -15.82833194732666, 'loss_4': 2.45430588722229, 'epoch': 3.7}
{'loss': 0.1478, 'grad_norm': 35.052207946777344, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.1399695873260498, 'loss_2': 0.00786590576171875, 'loss_3': -15.648248672485352, 'loss_4': 2.8045430183410645, 'epoch': 3.71}
{'loss': 0.0497, 'grad_norm': 14.046846389770508, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.04120268672704697, 'loss_2': 0.008453369140625, 'loss_3': -15.733736038208008, 'loss_4': 2.4478468894958496, 'epoch': 3.72}
{'loss': 0.0627, 'grad_norm': 18.89443588256836, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.05556097999215126, 'loss_2': 0.007183074951171875, 'loss_3': -15.746749877929688, 'loss_4': 2.8103296756744385, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 12:36:58,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:58,713 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:18<1:18:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:06,074 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02771405316889286, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.549, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014854230917990208, 'eval_loss_2': 0.012859821319580078, 'eval_loss_3': -18.286415100097656, 'eval_loss_4': 2.096658229827881, 'epoch': 3.72}
{'loss': 0.068, 'grad_norm': 17.20285987854004, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.048516083508729935, 'loss_2': 0.01947021484375, 'loss_3': -15.866564750671387, 'loss_4': 2.5403432846069336, 'epoch': 3.73}
{'loss': 0.0543, 'grad_norm': 14.38376235961914, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.03580375760793686, 'loss_2': 0.0185089111328125, 'loss_3': -15.940682411193848, 'loss_4': 3.0615310668945312, 'epoch': 3.73}
{'loss': 0.0919, 'grad_norm': 30.934844970703125, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.06889674067497253, 'loss_2': 0.0229949951171875, 'loss_3': -15.926474571228027, 'loss_4': 2.84163761138916, 'epoch': 3.74}
{'loss': 0.0386, 'grad_norm': 6.685020446777344, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.020770220085978508, 'loss_2': 0.017822265625, 'loss_3': -15.850410461425781, 'loss_4': 1.7059005498886108, 'epoch': 3.74}
{'loss': 0.0446, 'grad_norm': 15.551875114440918, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.03462745249271393, 'loss_2': 0.0099334716796875, 'loss_3': -15.904677391052246, 'loss_4': 2.845400094985962, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 12:37:06,074 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:06,074 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:25<1:18:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:13,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02234315127134323, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015441113151609898, 'eval_loss_2': 0.006902039051055908, 'eval_loss_3': -18.29157066345215, 'eval_loss_4': 1.8687615394592285, 'epoch': 3.75}
{'loss': 0.0408, 'grad_norm': 10.827414512634277, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.03183618187904358, 'loss_2': 0.00897216796875, 'loss_3': -15.911235809326172, 'loss_4': 2.5460128784179688, 'epoch': 3.76}
{'loss': 0.0171, 'grad_norm': 6.968046188354492, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.017070088535547256, 'loss_2': 3.3855438232421875e-05, 'loss_3': -16.03750991821289, 'loss_4': 1.9945924282073975, 'epoch': 3.76}
{'loss': 0.0411, 'grad_norm': 14.138360023498535, 'learning_rate': 2.625e-05, 'loss_1': 0.03746350109577179, 'loss_2': 0.00360107421875, 'loss_3': -15.787364959716797, 'loss_4': 1.1513140201568604, 'epoch': 3.77}
{'loss': 0.0618, 'grad_norm': 16.009174346923828, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.05378814414143562, 'loss_2': 0.00797271728515625, 'loss_3': -15.88953971862793, 'loss_4': 1.8111646175384521, 'epoch': 3.77}
{'loss': 0.0405, 'grad_norm': 10.133246421813965, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.03306979686021805, 'loss_2': 0.00738525390625, 'loss_3': -16.058935165405273, 'loss_4': 1.603560447692871, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 12:37:13,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:13,426 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:32<1:17:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:20,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028336793184280396, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.423, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013865502551198006, 'eval_loss_2': 0.014471292495727539, 'eval_loss_3': -18.28655242919922, 'eval_loss_4': 1.1932191848754883, 'epoch': 3.78}
{'loss': 0.0439, 'grad_norm': 11.6767578125, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.0315115712583065, 'loss_2': 0.01239013671875, 'loss_3': -16.075319290161133, 'loss_4': 1.4840459823608398, 'epoch': 3.78}
{'loss': 0.0642, 'grad_norm': 15.243690490722656, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.04861893132328987, 'loss_2': 0.015533447265625, 'loss_3': -15.785743713378906, 'loss_4': 1.1737723350524902, 'epoch': 3.79}
{'loss': 0.1552, 'grad_norm': 13.809423446655273, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.14208580553531647, 'loss_2': 0.01309967041015625, 'loss_3': -15.810659408569336, 'loss_4': 1.5796818733215332, 'epoch': 3.8}
{'loss': 0.0418, 'grad_norm': 7.402867317199707, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.02816913090646267, 'loss_2': 0.0136260986328125, 'loss_3': -15.884859085083008, 'loss_4': 0.7947591543197632, 'epoch': 3.8}
{'loss': 0.0444, 'grad_norm': 7.670473098754883, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.025656070560216904, 'loss_2': 0.01873779296875, 'loss_3': -15.918267250061035, 'loss_4': 0.4715220332145691, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 12:37:20,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:20,779 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:40<1:17:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:28,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02470014989376068, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014063820242881775, 'eval_loss_2': 0.010636329650878906, 'eval_loss_3': -18.292224884033203, 'eval_loss_4': 0.3919485807418823, 'epoch': 3.81}
{'loss': 0.0392, 'grad_norm': 6.90313720703125, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.025694696232676506, 'loss_2': 0.0134735107421875, 'loss_3': -16.015235900878906, 'loss_4': 0.4040423333644867, 'epoch': 3.81}
{'loss': 0.0429, 'grad_norm': 13.104601860046387, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.03327823057770729, 'loss_2': 0.0096435546875, 'loss_3': -15.895920753479004, 'loss_4': 0.5034120082855225, 'epoch': 3.82}
{'loss': 0.0564, 'grad_norm': 12.087259292602539, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.05249495804309845, 'loss_2': 0.00392913818359375, 'loss_3': -15.807489395141602, 'loss_4': 0.1562899500131607, 'epoch': 3.83}
{'loss': 0.0333, 'grad_norm': 8.86469841003418, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.028412461280822754, 'loss_2': 0.004924774169921875, 'loss_3': -15.938966751098633, 'loss_4': 0.2283753752708435, 'epoch': 3.83}
{'loss': 0.0593, 'grad_norm': 22.221071243286133, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.05002405494451523, 'loss_2': 0.0092926025390625, 'loss_3': -15.854923248291016, 'loss_4': -0.030456632375717163, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 12:37:28,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:28,134 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:47<1:17:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:35,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02554181031882763, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.565, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01311209425330162, 'eval_loss_2': 0.01242971420288086, 'eval_loss_3': -18.289445877075195, 'eval_loss_4': -0.1504974514245987, 'epoch': 3.84}
{'loss': 0.0512, 'grad_norm': 8.859980583190918, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.03488757088780403, 'loss_2': 0.0162811279296875, 'loss_3': -15.927513122558594, 'loss_4': 0.02959682047367096, 'epoch': 3.84}
{'loss': 0.0657, 'grad_norm': 15.378925323486328, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.05676534026861191, 'loss_2': 0.00891876220703125, 'loss_3': -15.892768859863281, 'loss_4': 0.07328520715236664, 'epoch': 3.85}
{'loss': 0.033, 'grad_norm': 6.017479419708252, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.021938392892479897, 'loss_2': 0.011016845703125, 'loss_3': -15.975205421447754, 'loss_4': -0.10817790031433105, 'epoch': 3.85}
{'loss': 0.0603, 'grad_norm': 13.130831718444824, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.0452129989862442, 'loss_2': 0.01511383056640625, 'loss_3': -16.056669235229492, 'loss_4': -0.3250874876976013, 'epoch': 3.86}
{'loss': 0.0564, 'grad_norm': 9.17751407623291, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.04927603527903557, 'loss_2': 0.0070953369140625, 'loss_3': -15.899415969848633, 'loss_4': -0.19353599846363068, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 12:37:35,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:35,488 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:54<1:17:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:42,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020185384899377823, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.253, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01342467125505209, 'eval_loss_2': 0.006760716438293457, 'eval_loss_3': -18.248226165771484, 'eval_loss_4': -0.23058569431304932, 'epoch': 3.87}
{'loss': 0.0273, 'grad_norm': 7.318294048309326, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.018812116235494614, 'loss_2': 0.00848388671875, 'loss_3': -16.072200775146484, 'loss_4': 0.190931037068367, 'epoch': 3.87}
{'loss': 0.0489, 'grad_norm': 22.875654220581055, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.04866023361682892, 'loss_2': 0.00024509429931640625, 'loss_3': -15.781078338623047, 'loss_4': 0.1315738558769226, 'epoch': 3.88}
{'loss': 0.0555, 'grad_norm': 15.959436416625977, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.052576418966054916, 'loss_2': 0.002925872802734375, 'loss_3': -16.059459686279297, 'loss_4': 0.05410601943731308, 'epoch': 3.88}
{'loss': 0.0273, 'grad_norm': 9.395808219909668, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.0245527271181345, 'loss_2': 0.0027027130126953125, 'loss_3': -16.054536819458008, 'loss_4': -0.0692741796374321, 'epoch': 3.89}
{'loss': 0.0408, 'grad_norm': 11.638070106506348, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.040332209318876266, 'loss_2': 0.0005035400390625, 'loss_3': -15.93427848815918, 'loss_4': -0.09479214251041412, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 12:37:42,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:42,843 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:02<1:17:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:50,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026270579546689987, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.749, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.018569866195321083, 'eval_loss_2': 0.007700711488723755, 'eval_loss_3': -18.214231491088867, 'eval_loss_4': -0.11521470546722412, 'epoch': 3.9}
{'loss': 0.0401, 'grad_norm': 18.121124267578125, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.03875867649912834, 'loss_2': 0.001377105712890625, 'loss_3': -15.871973037719727, 'loss_4': 0.12680649757385254, 'epoch': 3.9}
{'loss': 0.0604, 'grad_norm': 22.468219757080078, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.05371991917490959, 'loss_2': 0.006671905517578125, 'loss_3': -15.8021879196167, 'loss_4': -0.40095192193984985, 'epoch': 3.91}
{'loss': 0.0315, 'grad_norm': 9.123666763305664, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.026530921459197998, 'loss_2': 0.004924774169921875, 'loss_3': -16.006872177124023, 'loss_4': -0.7098008394241333, 'epoch': 3.91}
{'loss': 0.0297, 'grad_norm': 8.775533676147461, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.021801592782139778, 'loss_2': 0.00787353515625, 'loss_3': -16.12771987915039, 'loss_4': -0.040449678897857666, 'epoch': 3.92}
{'loss': 0.0653, 'grad_norm': 22.231534957885742, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.0599246472120285, 'loss_2': 0.005352020263671875, 'loss_3': -15.785137176513672, 'loss_4': -0.2684212327003479, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 12:37:50,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:50,192 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:09<1:17:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:57,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03328098729252815, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.571, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03039214201271534, 'eval_loss_2': 0.0028888434171676636, 'eval_loss_3': -18.107929229736328, 'eval_loss_4': -0.22422853112220764, 'epoch': 3.92}
{'loss': 0.0452, 'grad_norm': 18.70528221130371, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.037135183811187744, 'loss_2': 0.008087158203125, 'loss_3': -15.928543090820312, 'loss_4': 0.004816301167011261, 'epoch': 3.93}
{'loss': 0.0475, 'grad_norm': 14.035452842712402, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.039626408368349075, 'loss_2': 0.007843017578125, 'loss_3': -15.931159019470215, 'loss_4': -0.21362701058387756, 'epoch': 3.94}
{'loss': 0.0342, 'grad_norm': 11.335955619812012, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.027997275814414024, 'loss_2': 0.006252288818359375, 'loss_3': -16.016910552978516, 'loss_4': -0.2261286824941635, 'epoch': 3.94}
{'loss': 0.0336, 'grad_norm': 8.685423851013184, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.028192196041345596, 'loss_2': 0.00540924072265625, 'loss_3': -15.824735641479492, 'loss_4': -0.03819694370031357, 'epoch': 3.95}
{'loss': 0.0354, 'grad_norm': 16.417278289794922, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.03022877499461174, 'loss_2': 0.005218505859375, 'loss_3': -16.04412269592285, 'loss_4': 0.7863479852676392, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 12:37:57,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:57,548 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:16<1:17:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:04,914 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04081512615084648, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03723670169711113, 'eval_loss_2': 0.0035784244537353516, 'eval_loss_3': -18.043926239013672, 'eval_loss_4': 0.34626075625419617, 'epoch': 3.95}
{'loss': 0.0487, 'grad_norm': 15.962708473205566, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.04557451233267784, 'loss_2': 0.00315093994140625, 'loss_3': -15.897279739379883, 'loss_4': 0.3827049136161804, 'epoch': 3.96}
{'loss': 0.1373, 'grad_norm': 20.156213760375977, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.1243383139371872, 'loss_2': 0.01291656494140625, 'loss_3': -15.755447387695312, 'loss_4': 0.8445802330970764, 'epoch': 3.97}
{'loss': 0.0264, 'grad_norm': 8.321338653564453, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.020279323682188988, 'loss_2': 0.006107330322265625, 'loss_3': -15.799232482910156, 'loss_4': 0.11384725570678711, 'epoch': 3.97}
{'loss': 0.0459, 'grad_norm': 11.807239532470703, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.034330449998378754, 'loss_2': 0.01152801513671875, 'loss_3': -15.959268569946289, 'loss_4': 1.0304009914398193, 'epoch': 3.98}
{'loss': 0.0528, 'grad_norm': 12.917069435119629, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.04281364008784294, 'loss_2': 0.010009765625, 'loss_3': -15.927458763122559, 'loss_4': 0.7293300032615662, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 12:38:04,914 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:04,915 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:23<1:14:18,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 12:38:11,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06083524599671364, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.05447448045015335, 'eval_loss_2': 0.006360769271850586, 'eval_loss_3': -17.955657958984375, 'eval_loss_4': 0.9755716323852539, 'epoch': 3.98}
{'loss': 0.0477, 'grad_norm': 11.65120792388916, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.03556588292121887, 'loss_2': 0.012176513671875, 'loss_3': -15.797957420349121, 'loss_4': 0.804539680480957, 'epoch': 3.99}
{'loss': 0.0476, 'grad_norm': 13.479135513305664, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.040363628417253494, 'loss_2': 0.00727081298828125, 'loss_3': -15.840503692626953, 'loss_4': 1.5661543607711792, 'epoch': 3.99}
{'loss': 0.3102, 'grad_norm': 47.86281204223633, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.2979932129383087, 'loss_2': 0.01220703125, 'loss_3': -15.121732711791992, 'loss_4': 1.8629958629608154, 'epoch': 4.0}
{'loss': 0.0407, 'grad_norm': 12.195815086364746, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.028315071016550064, 'loss_2': 0.012359619140625, 'loss_3': -15.974508285522461, 'loss_4': 0.4695509970188141, 'epoch': 4.01}
{'loss': 0.0452, 'grad_norm': 13.4140043258667, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.031608253717422485, 'loss_2': 0.01355743408203125, 'loss_3': -15.725902557373047, 'loss_4': 0.9604112505912781, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 12:38:11,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:11,955 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:31<1:16:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:38:19,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030423499643802643, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.023693183436989784, 'eval_loss_2': 0.006730318069458008, 'eval_loss_3': -18.084077835083008, 'eval_loss_4': 0.882312536239624, 'epoch': 4.01}
{'loss': 0.1367, 'grad_norm': 11.605670928955078, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.12906774878501892, 'loss_2': 0.0076141357421875, 'loss_3': -15.881869316101074, 'loss_4': 1.099306583404541, 'epoch': 4.02}
{'loss': 0.0318, 'grad_norm': 9.575846672058105, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.02521715871989727, 'loss_2': 0.006591796875, 'loss_3': -15.932757377624512, 'loss_4': 0.7081997990608215, 'epoch': 4.02}
{'loss': 0.0322, 'grad_norm': 14.20669937133789, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.02830199897289276, 'loss_2': 0.003864288330078125, 'loss_3': -15.688350677490234, 'loss_4': 0.6181964874267578, 'epoch': 4.03}
{'loss': 0.0637, 'grad_norm': 15.063358306884766, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.05955565720796585, 'loss_2': 0.0041046142578125, 'loss_3': -15.943344116210938, 'loss_4': 1.629117727279663, 'epoch': 4.03}
{'loss': 0.0256, 'grad_norm': 7.966107368469238, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.022354694083333015, 'loss_2': 0.00327301025390625, 'loss_3': -15.902704238891602, 'loss_4': 0.827649712562561, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 12:38:19,316 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:19,316 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:38<1:17:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:26,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01853279396891594, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.879, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01540778111666441, 'eval_loss_2': 0.003125011920928955, 'eval_loss_3': -18.105648040771484, 'eval_loss_4': 0.9762007594108582, 'epoch': 4.04}
{'loss': 0.0313, 'grad_norm': 15.862204551696777, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.02951579913496971, 'loss_2': 0.0017442703247070312, 'loss_3': -15.841320037841797, 'loss_4': 1.2905466556549072, 'epoch': 4.05}
{'loss': 0.0548, 'grad_norm': 19.096805572509766, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.04737907648086548, 'loss_2': 0.00739288330078125, 'loss_3': -15.894208908081055, 'loss_4': 1.6371817588806152, 'epoch': 4.05}
{'loss': 0.0291, 'grad_norm': 9.848896026611328, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.023342469707131386, 'loss_2': 0.0057220458984375, 'loss_3': -15.850478172302246, 'loss_4': 0.789525032043457, 'epoch': 4.06}
{'loss': 0.034, 'grad_norm': 9.379289627075195, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.03078361041843891, 'loss_2': 0.003200531005859375, 'loss_3': -15.766840934753418, 'loss_4': 1.4791581630706787, 'epoch': 4.06}
{'loss': 0.0291, 'grad_norm': 8.115395545959473, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.021645717322826385, 'loss_2': 0.0074920654296875, 'loss_3': -15.61889362335205, 'loss_4': 1.2717477083206177, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 12:38:26,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:26,661 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:42<1:17:07,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:38:30,459 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-700
[INFO|configuration_utils.py:420] 2025-01-21 12:38:30,460 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-700/config.json                                                                             
{'eval_loss': 0.015305855311453342, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.696, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012800315394997597, 'eval_loss_2': 0.0025055408477783203, 'eval_loss_3': -18.158924102783203, 'eval_loss_4': 1.1970348358154297, 'epoch': 4.07}
[INFO|modeling_utils.py:2988] 2025-01-21 12:38:30,933 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-700/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:38:30,934 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:38:30,935 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-700/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:38:31,737 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-565] due to args.save_total_limit
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:47<1:24:21,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:38:35,368 >>
{'loss': 0.0218, 'grad_norm': 6.856008529663086, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.019939973950386047, 'loss_2': 0.001903533935546875, 'loss_3': -15.866308212280273, 'loss_4': 1.4677839279174805, 'epoch': 4.08}
{'loss': 0.0177, 'grad_norm': 7.685099124908447, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.017177503556013107, 'loss_2': 0.0005311965942382812, 'loss_3': -15.672924995422363, 'loss_4': 1.2282761335372925, 'epoch': 4.08}
{'loss': 0.0393, 'grad_norm': 8.533003807067871, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.026632579043507576, 'loss_2': 0.0126495361328125, 'loss_3': -15.701496124267578, 'loss_4': 1.7017300128936768, 'epoch': 4.09}
{'loss': 0.036, 'grad_norm': 12.778797149658203, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.03187863156199455, 'loss_2': 0.004093170166015625, 'loss_3': -15.686660766601562, 'loss_4': 1.8066596984863281, 'epoch': 4.09}
{'loss': 0.0268, 'grad_norm': 20.79231834411621, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.024142514914274216, 'loss_2': 0.00262451171875, 'loss_3': -15.696366310119629, 'loss_4': 1.2064217329025269, 'epoch': 4.1}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:38:35,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:35,368 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:54<1:18:12,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:38:42,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020865771919488907, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.507, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014622863382101059, 'eval_loss_2': 0.006242908537387848, 'eval_loss_3': -18.196468353271484, 'eval_loss_4': 1.4170914888381958, 'epoch': 4.1}
{'loss': 0.0276, 'grad_norm': 9.850621223449707, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.01971898227930069, 'loss_2': 0.0078582763671875, 'loss_3': -15.674558639526367, 'loss_4': 1.3128032684326172, 'epoch': 4.1}
{'loss': 0.0255, 'grad_norm': 8.757100105285645, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.01998215727508068, 'loss_2': 0.005519866943359375, 'loss_3': -15.896087646484375, 'loss_4': 1.8973171710968018, 'epoch': 4.11}
{'loss': 0.0334, 'grad_norm': 8.983515739440918, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.026422230526804924, 'loss_2': 0.00699615478515625, 'loss_3': -15.71381950378418, 'loss_4': 2.4444026947021484, 'epoch': 4.12}
{'loss': 0.0204, 'grad_norm': 6.301845550537109, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.017768751829862595, 'loss_2': 0.002658843994140625, 'loss_3': -15.942286491394043, 'loss_4': 1.4472498893737793, 'epoch': 4.12}
{'loss': 0.0714, 'grad_norm': 33.5870475769043, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.062091223895549774, 'loss_2': 0.0093231201171875, 'loss_3': -15.876285552978516, 'loss_4': 2.2334389686584473, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 12:38:42,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:42,714 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [18:02<1:17:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:50,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027406055480241776, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.798, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.016784269362688065, 'eval_loss_2': 0.010621786117553711, 'eval_loss_3': -18.214025497436523, 'eval_loss_4': 1.2097755670547485, 'epoch': 4.13}
{'loss': 0.0338, 'grad_norm': 12.520936965942383, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.02321617677807808, 'loss_2': 0.010589599609375, 'loss_3': -15.980990409851074, 'loss_4': 1.2297255992889404, 'epoch': 4.13}
{'loss': 0.1172, 'grad_norm': 23.3961124420166, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.10090436041355133, 'loss_2': 0.01629638671875, 'loss_3': -15.99057674407959, 'loss_4': 1.6627155542373657, 'epoch': 4.14}
{'loss': 0.03, 'grad_norm': 13.051180839538574, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.027919188141822815, 'loss_2': 0.002033233642578125, 'loss_3': -15.98611831665039, 'loss_4': 2.045989513397217, 'epoch': 4.15}
{'loss': 0.0273, 'grad_norm': 7.747432231903076, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.020361782982945442, 'loss_2': 0.0069427490234375, 'loss_3': -15.74083423614502, 'loss_4': 1.7909958362579346, 'epoch': 4.15}
{'loss': 0.0793, 'grad_norm': 10.96436882019043, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.0607730895280838, 'loss_2': 0.0185699462890625, 'loss_3': -16.165489196777344, 'loss_4': 1.3274834156036377, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 12:38:50,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:50,057 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:09<1:16:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:57,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030518947169184685, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.058, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.017230449244379997, 'eval_loss_2': 0.013288497924804688, 'eval_loss_3': -18.205280303955078, 'eval_loss_4': 1.218465805053711, 'epoch': 4.16}
{'loss': 0.0317, 'grad_norm': 9.311522483825684, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.02168784663081169, 'loss_2': 0.010009765625, 'loss_3': -15.798828125, 'loss_4': 1.5481387376785278, 'epoch': 4.16}
{'loss': 0.0319, 'grad_norm': 8.61922836303711, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.018225980922579765, 'loss_2': 0.013702392578125, 'loss_3': -15.965466499328613, 'loss_4': 1.256554365158081, 'epoch': 4.17}
{'loss': 0.0363, 'grad_norm': 11.431473731994629, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.02828921377658844, 'loss_2': 0.0080413818359375, 'loss_3': -15.853343963623047, 'loss_4': 1.3134725093841553, 'epoch': 4.17}
{'loss': 0.0199, 'grad_norm': 9.569904327392578, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.01964564248919487, 'loss_2': 0.00023293495178222656, 'loss_3': -15.919086456298828, 'loss_4': 1.2213670015335083, 'epoch': 4.18}
{'loss': 0.0246, 'grad_norm': 5.288064479827881, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.013814550824463367, 'loss_2': 0.010772705078125, 'loss_3': -16.186603546142578, 'loss_4': 1.4416998624801636, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 12:38:57,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:57,393 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:16<1:16:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:04,735 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023545270785689354, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.284, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.016335373744368553, 'eval_loss_2': 0.007209897041320801, 'eval_loss_3': -18.168087005615234, 'eval_loss_4': 1.3509072065353394, 'epoch': 4.19}
{'loss': 0.0536, 'grad_norm': 11.218449592590332, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.04338102787733078, 'loss_2': 0.01021575927734375, 'loss_3': -15.658452987670898, 'loss_4': 1.4042623043060303, 'epoch': 4.19}
{'loss': 0.0265, 'grad_norm': 6.381746292114258, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.014442909508943558, 'loss_2': 0.0120697021484375, 'loss_3': -15.791125297546387, 'loss_4': 1.0398789644241333, 'epoch': 4.2}
{'loss': 0.0549, 'grad_norm': 14.543070793151855, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.04512149840593338, 'loss_2': 0.0097808837890625, 'loss_3': -15.957326889038086, 'loss_4': 1.431248664855957, 'epoch': 4.2}
{'loss': 0.0733, 'grad_norm': 14.149721145629883, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.05545497685670853, 'loss_2': 0.0178375244140625, 'loss_3': -16.08071517944336, 'loss_4': 2.12437105178833, 'epoch': 4.21}
{'loss': 0.0399, 'grad_norm': 16.4299259185791, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.033747777342796326, 'loss_2': 0.006103515625, 'loss_3': -16.00473976135254, 'loss_4': 1.5704749822616577, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 12:39:04,735 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:04,735 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:24<1:16:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:12,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025438427925109863, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.018679842352867126, 'eval_loss_2': 0.006758585572242737, 'eval_loss_3': -18.101961135864258, 'eval_loss_4': 1.7181036472320557, 'epoch': 4.22}
{'loss': 0.0388, 'grad_norm': 9.450007438659668, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.028625858947634697, 'loss_2': 0.0101776123046875, 'loss_3': -15.812219619750977, 'loss_4': 1.7081034183502197, 'epoch': 4.22}
{'loss': 0.0355, 'grad_norm': 19.34564781188965, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.030918309465050697, 'loss_2': 0.00460052490234375, 'loss_3': -15.905704498291016, 'loss_4': 1.6226906776428223, 'epoch': 4.23}
{'loss': 0.0453, 'grad_norm': 14.256682395935059, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.03774287924170494, 'loss_2': 0.007537841796875, 'loss_3': -15.681121826171875, 'loss_4': 1.7354552745819092, 'epoch': 4.23}
{'loss': 0.026, 'grad_norm': 6.436960697174072, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.017114626243710518, 'loss_2': 0.00891876220703125, 'loss_3': -15.783256530761719, 'loss_4': 1.9470700025558472, 'epoch': 4.24}
{'loss': 0.0514, 'grad_norm': 14.515286445617676, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.04793069139122963, 'loss_2': 0.0034503936767578125, 'loss_3': -15.811766624450684, 'loss_4': 2.0889899730682373, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 12:39:12,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:12,082 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:31<1:16:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:19,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025923728942871094, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.347, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.019929049536585808, 'eval_loss_2': 0.005994677543640137, 'eval_loss_3': -18.09124755859375, 'eval_loss_4': 1.8357815742492676, 'epoch': 4.24}
{'loss': 0.0805, 'grad_norm': 25.85767936706543, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.07300331443548203, 'loss_2': 0.00753021240234375, 'loss_3': -15.779351234436035, 'loss_4': 2.105980396270752, 'epoch': 4.25}
{'loss': 0.0294, 'grad_norm': 12.046014785766602, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.027003232389688492, 'loss_2': 0.002368927001953125, 'loss_3': -15.72652816772461, 'loss_4': 2.110255479812622, 'epoch': 4.26}
{'loss': 0.0358, 'grad_norm': 11.309404373168945, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.032486241310834885, 'loss_2': 0.003326416015625, 'loss_3': -15.844958305358887, 'loss_4': 1.829474687576294, 'epoch': 4.26}
{'loss': 0.0576, 'grad_norm': 15.025660514831543, 'learning_rate': 2.575e-05, 'loss_1': 0.054886702448129654, 'loss_2': 0.002681732177734375, 'loss_3': -15.82016372680664, 'loss_4': 2.1415340900421143, 'epoch': 4.27}
{'loss': 0.0204, 'grad_norm': 7.488305568695068, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.019849387928843498, 'loss_2': 0.0005497932434082031, 'loss_3': -15.705713272094727, 'loss_4': 1.862632155418396, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 12:39:19,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:19,434 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:38<1:16:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:26,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021837864071130753, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.547, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018683839589357376, 'eval_loss_2': 0.0031540244817733765, 'eval_loss_3': -18.09217071533203, 'eval_loss_4': 1.946880578994751, 'epoch': 4.27}
{'loss': 0.0359, 'grad_norm': 10.864653587341309, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.03488367423415184, 'loss_2': 0.0010328292846679688, 'loss_3': -15.936532974243164, 'loss_4': 2.1168758869171143, 'epoch': 4.28}
{'loss': 0.0516, 'grad_norm': 16.81081771850586, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.04536185786128044, 'loss_2': 0.006206512451171875, 'loss_3': -15.872525215148926, 'loss_4': 1.6480419635772705, 'epoch': 4.28}
{'loss': 0.0309, 'grad_norm': 22.926799774169922, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.029431575909256935, 'loss_2': 0.0014772415161132812, 'loss_3': -15.681011199951172, 'loss_4': 1.6638360023498535, 'epoch': 4.29}
{'loss': 0.026, 'grad_norm': 8.32327651977539, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.022128842771053314, 'loss_2': 0.0038394927978515625, 'loss_3': -15.798964500427246, 'loss_4': 1.7695653438568115, 'epoch': 4.3}
{'loss': 0.0216, 'grad_norm': 8.151082038879395, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.015962349250912666, 'loss_2': 0.005649566650390625, 'loss_3': -16.089000701904297, 'loss_4': 1.5025334358215332, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 12:39:26,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:26,780 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:46<1:16:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:34,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021856166422367096, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.103, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.017866233363747597, 'eval_loss_2': 0.0039899349212646484, 'eval_loss_3': -18.135231018066406, 'eval_loss_4': 1.7167528867721558, 'epoch': 4.3}
{'loss': 0.0343, 'grad_norm': 16.862783432006836, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.03154789283871651, 'loss_2': 0.0027923583984375, 'loss_3': -16.05372428894043, 'loss_4': 1.8996604681015015, 'epoch': 4.31}
{'loss': 0.0368, 'grad_norm': 10.570103645324707, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.029142653569579124, 'loss_2': 0.0076446533203125, 'loss_3': -15.814064979553223, 'loss_4': 1.728562355041504, 'epoch': 4.31}
{'loss': 0.031, 'grad_norm': 11.06602954864502, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.03014097921550274, 'loss_2': 0.0008215904235839844, 'loss_3': -15.546706199645996, 'loss_4': 1.5279427766799927, 'epoch': 4.32}
{'loss': 0.0934, 'grad_norm': 19.31387710571289, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.09194879233837128, 'loss_2': 0.0014705657958984375, 'loss_3': -15.900829315185547, 'loss_4': 1.5204296112060547, 'epoch': 4.33}
{'loss': 0.0193, 'grad_norm': 7.5165557861328125, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.014460922218859196, 'loss_2': 0.00485992431640625, 'loss_3': -15.614358901977539, 'loss_4': 1.110719084739685, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 12:39:34,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:34,107 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:53<1:16:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:41,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019582873210310936, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.102, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01609756052494049, 'eval_loss_2': 0.0034853145480155945, 'eval_loss_3': -18.1390380859375, 'eval_loss_4': 1.3896983861923218, 'epoch': 4.33}
{'loss': 0.0145, 'grad_norm': 5.563597679138184, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.010737111791968346, 'loss_2': 0.003734588623046875, 'loss_3': -16.009876251220703, 'loss_4': 1.159806489944458, 'epoch': 4.34}
{'loss': 0.0179, 'grad_norm': 8.214547157287598, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.016492454335093498, 'loss_2': 0.0013904571533203125, 'loss_3': -15.643704414367676, 'loss_4': 1.1782575845718384, 'epoch': 4.34}
{'loss': 0.0301, 'grad_norm': 9.837257385253906, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.029333041980862617, 'loss_2': 0.0008068084716796875, 'loss_3': -16.02440071105957, 'loss_4': 1.5957056283950806, 'epoch': 4.35}
{'loss': 0.0695, 'grad_norm': 18.733144760131836, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.06157051399350166, 'loss_2': 0.0079345703125, 'loss_3': -15.7181978225708, 'loss_4': 1.7567081451416016, 'epoch': 4.35}
{'loss': 0.0167, 'grad_norm': 6.2315144538879395, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.013565978035330772, 'loss_2': 0.003131866455078125, 'loss_3': -15.969310760498047, 'loss_4': 1.4140207767486572, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 12:39:41,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:41,444 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:00<1:16:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:48,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018419774249196053, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.173, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014612136408686638, 'eval_loss_2': 0.0038076378405094147, 'eval_loss_3': -18.19637107849121, 'eval_loss_4': 1.1735239028930664, 'epoch': 4.36}
{'loss': 0.0335, 'grad_norm': 8.060842514038086, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.025172799825668335, 'loss_2': 0.00827789306640625, 'loss_3': -16.14159393310547, 'loss_4': 1.6386899948120117, 'epoch': 4.37}
{'loss': 0.0296, 'grad_norm': 6.707503795623779, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.018623437732458115, 'loss_2': 0.011016845703125, 'loss_3': -15.813380241394043, 'loss_4': 0.8264002799987793, 'epoch': 4.37}
{'loss': 0.0245, 'grad_norm': 10.535067558288574, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.01786257140338421, 'loss_2': 0.006664276123046875, 'loss_3': -15.757190704345703, 'loss_4': 0.846899151802063, 'epoch': 4.38}
{'loss': 0.0167, 'grad_norm': 6.399723052978516, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.01474206056445837, 'loss_2': 0.001934051513671875, 'loss_3': -15.896852493286133, 'loss_4': 0.8499510288238525, 'epoch': 4.38}
{'loss': 0.0399, 'grad_norm': 9.820377349853516, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.03248549997806549, 'loss_2': 0.007373809814453125, 'loss_3': -15.968605041503906, 'loss_4': 0.4802398979663849, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 12:39:48,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:48,782 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:08<1:16:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:56,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01739717647433281, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.195, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013029809109866619, 'eval_loss_2': 0.004367366433143616, 'eval_loss_3': -18.207387924194336, 'eval_loss_4': 0.5456821918487549, 'epoch': 4.39}
{'loss': 0.0231, 'grad_norm': 7.356632232666016, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.017624028027057648, 'loss_2': 0.00545501708984375, 'loss_3': -15.923839569091797, 'loss_4': 0.27169179916381836, 'epoch': 4.4}
{'loss': 0.0603, 'grad_norm': 16.430585861206055, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.053450554609298706, 'loss_2': 0.0068511962890625, 'loss_3': -15.96690845489502, 'loss_4': 0.609984278678894, 'epoch': 4.4}
{'loss': 0.0167, 'grad_norm': 6.017978191375732, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.01225680485367775, 'loss_2': 0.004444122314453125, 'loss_3': -16.040529251098633, 'loss_4': 0.7134237885475159, 'epoch': 4.41}
{'loss': 0.0383, 'grad_norm': 11.840996742248535, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.03397226706147194, 'loss_2': 0.00431060791015625, 'loss_3': -15.810688972473145, 'loss_4': 0.3742302656173706, 'epoch': 4.41}
{'loss': 0.0264, 'grad_norm': 9.93440055847168, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.02356441132724285, 'loss_2': 0.00279998779296875, 'loss_3': -15.955577850341797, 'loss_4': 0.7475966215133667, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 12:39:56,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:56,121 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:15<1:16:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:03,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017651470378041267, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013084917329251766, 'eval_loss_2': 0.004566550254821777, 'eval_loss_3': -18.208404541015625, 'eval_loss_4': 0.42294174432754517, 'epoch': 4.42}
{'loss': 0.0231, 'grad_norm': 8.470916748046875, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.019910234957933426, 'loss_2': 0.003143310546875, 'loss_3': -16.015077590942383, 'loss_4': 0.1367603987455368, 'epoch': 4.42}
{'loss': 0.0292, 'grad_norm': 8.053522109985352, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.02421806938946247, 'loss_2': 0.00495147705078125, 'loss_3': -16.002412796020508, 'loss_4': 0.7559531927108765, 'epoch': 4.43}
{'loss': 0.0604, 'grad_norm': 13.7579927444458, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.05800487846136093, 'loss_2': 0.002414703369140625, 'loss_3': -15.944252967834473, 'loss_4': 0.7748005390167236, 'epoch': 4.44}
{'loss': 0.0635, 'grad_norm': 21.51199722290039, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.05521507188677788, 'loss_2': 0.00829315185546875, 'loss_3': -15.869876861572266, 'loss_4': 0.9375489950180054, 'epoch': 4.44}
{'loss': 0.0271, 'grad_norm': 6.919404983520508, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.01678207702934742, 'loss_2': 0.01033782958984375, 'loss_3': -16.05546760559082, 'loss_4': 1.749211072921753, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 12:40:03,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:03,471 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:22<1:15:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:10,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01975565403699875, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013695769011974335, 'eval_loss_2': 0.006059885025024414, 'eval_loss_3': -18.16559410095215, 'eval_loss_4': 0.6565989851951599, 'epoch': 4.45}
{'loss': 0.0785, 'grad_norm': 22.699838638305664, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.06744719296693802, 'loss_2': 0.011016845703125, 'loss_3': -15.834753036499023, 'loss_4': 1.2347712516784668, 'epoch': 4.45}
{'loss': 0.0673, 'grad_norm': 12.816393852233887, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.05810600891709328, 'loss_2': 0.00919342041015625, 'loss_3': -15.95637321472168, 'loss_4': 0.9134434461593628, 'epoch': 4.46}
{'loss': 0.0282, 'grad_norm': 7.327780246734619, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.025236960500478745, 'loss_2': 0.0029296875, 'loss_3': -15.916036605834961, 'loss_4': 0.8435086607933044, 'epoch': 4.47}
{'loss': 0.0331, 'grad_norm': 10.697712898254395, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.022070016711950302, 'loss_2': 0.010986328125, 'loss_3': -15.890040397644043, 'loss_4': 0.5524784326553345, 'epoch': 4.47}
{'loss': 0.0289, 'grad_norm': 10.12601375579834, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.028698481619358063, 'loss_2': 0.00017571449279785156, 'loss_3': -15.958039283752441, 'loss_4': 1.4618051052093506, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 12:40:10,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:10,816 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:30<1:15:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:18,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019626900553703308, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.219, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.015513583086431026, 'eval_loss_2': 0.004113316535949707, 'eval_loss_3': -18.148666381835938, 'eval_loss_4': 1.044326663017273, 'epoch': 4.48}
{'loss': 0.0211, 'grad_norm': 7.9314284324646, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.020517850294709206, 'loss_2': 0.0005435943603515625, 'loss_3': -15.857644081115723, 'loss_4': 0.9040126204490662, 'epoch': 4.48}
{'loss': 0.0191, 'grad_norm': 6.939887046813965, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.018325474113225937, 'loss_2': 0.0008106231689453125, 'loss_3': -15.891406059265137, 'loss_4': 1.1841484308242798, 'epoch': 4.49}
{'loss': 0.0526, 'grad_norm': 20.805179595947266, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.051048099994659424, 'loss_2': 0.0015401840209960938, 'loss_3': -15.88564682006836, 'loss_4': 1.406209945678711, 'epoch': 4.49}
{'loss': 0.0234, 'grad_norm': 7.020575523376465, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.021165544167160988, 'loss_2': 0.00222015380859375, 'loss_3': -15.78023910522461, 'loss_4': 1.1175825595855713, 'epoch': 4.5}
{'loss': 0.0153, 'grad_norm': 5.6830573081970215, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.014437883161008358, 'loss_2': 0.0009050369262695312, 'loss_3': -15.952584266662598, 'loss_4': 1.3601117134094238, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 12:40:18,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:18,147 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:37<1:15:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:25,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027119480073451996, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.74, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.023504206910729408, 'eval_loss_2': 0.003615275025367737, 'eval_loss_3': -18.092029571533203, 'eval_loss_4': 1.3625452518463135, 'epoch': 4.51}
{'loss': 0.0742, 'grad_norm': 18.591413497924805, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.06773621588945389, 'loss_2': 0.00650787353515625, 'loss_3': -15.986672401428223, 'loss_4': 1.6073298454284668, 'epoch': 4.51}
{'loss': 0.0296, 'grad_norm': 7.959313869476318, 'learning_rate': 2.55e-05, 'loss_1': 0.022657359018921852, 'loss_2': 0.00698089599609375, 'loss_3': -15.882999420166016, 'loss_4': 1.6092256307601929, 'epoch': 4.52}
{'loss': 0.0218, 'grad_norm': 7.667766094207764, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.020820491015911102, 'loss_2': 0.001018524169921875, 'loss_3': -15.604496955871582, 'loss_4': 1.5521020889282227, 'epoch': 4.52}
{'loss': 0.0669, 'grad_norm': 22.810462951660156, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.06660595536231995, 'loss_2': 0.0002651214599609375, 'loss_3': -15.480392456054688, 'loss_4': 1.2357827425003052, 'epoch': 4.53}
{'loss': 0.0347, 'grad_norm': 8.358463287353516, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.024594474583864212, 'loss_2': 0.01006317138671875, 'loss_3': -15.826549530029297, 'loss_4': 1.1321518421173096, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 12:40:25,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:25,487 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:44<1:15:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:32,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03445801883935928, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.04, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.0221694465726614, 'eval_loss_2': 0.012288570404052734, 'eval_loss_3': -18.11711883544922, 'eval_loss_4': 1.4366790056228638, 'epoch': 4.53}
{'loss': 0.0323, 'grad_norm': 10.02197551727295, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.02154657617211342, 'loss_2': 0.0107421875, 'loss_3': -15.846067428588867, 'loss_4': 1.3045355081558228, 'epoch': 4.54}
{'loss': 0.0649, 'grad_norm': 14.247438430786133, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.042970214039087296, 'loss_2': 0.02191162109375, 'loss_3': -15.629657745361328, 'loss_4': 1.324242115020752, 'epoch': 4.55}
{'loss': 0.0334, 'grad_norm': 9.042301177978516, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.019565138965845108, 'loss_2': 0.01381683349609375, 'loss_3': -15.814912796020508, 'loss_4': 1.1272187232971191, 'epoch': 4.55}
{'loss': 0.0534, 'grad_norm': 12.399713516235352, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.03152599558234215, 'loss_2': 0.02191162109375, 'loss_3': -15.855716705322266, 'loss_4': 1.7055108547210693, 'epoch': 4.56}
{'loss': 0.0319, 'grad_norm': 8.380306243896484, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.025256451219320297, 'loss_2': 0.00665283203125, 'loss_3': -15.648569107055664, 'loss_4': 1.368980884552002, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 12:40:32,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:32,827 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:52<1:15:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:40,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022143391892313957, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.961, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.017414476722478867, 'eval_loss_2': 0.004728913307189941, 'eval_loss_3': -18.153425216674805, 'eval_loss_4': 1.6299694776535034, 'epoch': 4.56}
{'loss': 0.0279, 'grad_norm': 8.938654899597168, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.019944004714488983, 'loss_2': 0.00799560546875, 'loss_3': -15.77863597869873, 'loss_4': 1.4592585563659668, 'epoch': 4.57}
{'loss': 0.0192, 'grad_norm': 7.1520161628723145, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.018504390493035316, 'loss_2': 0.0006508827209472656, 'loss_3': -16.015514373779297, 'loss_4': 1.5063118934631348, 'epoch': 4.58}
{'loss': 0.0318, 'grad_norm': 7.216825485229492, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.021470442414283752, 'loss_2': 0.01030731201171875, 'loss_3': -15.908706665039062, 'loss_4': 1.5489821434020996, 'epoch': 4.58}
{'loss': 0.0545, 'grad_norm': 8.320494651794434, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.032720085233449936, 'loss_2': 0.021759033203125, 'loss_3': -15.737913131713867, 'loss_4': 1.760439157485962, 'epoch': 4.59}
{'loss': 0.074, 'grad_norm': 26.398359298706055, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.05591009184718132, 'loss_2': 0.0180816650390625, 'loss_3': -15.752610206604004, 'loss_4': 1.5085718631744385, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 12:40:40,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:40,168 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [19:59<1:15:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:47,519 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026821177452802658, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.469, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016409676522016525, 'eval_loss_2': 0.010411500930786133, 'eval_loss_3': -18.171342849731445, 'eval_loss_4': 2.0243868827819824, 'epoch': 4.59}
{'loss': 0.0391, 'grad_norm': 15.637442588806152, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.02625243552029133, 'loss_2': 0.0128173828125, 'loss_3': -15.893095016479492, 'loss_4': 2.5394864082336426, 'epoch': 4.6}
{'loss': 0.0348, 'grad_norm': 6.212270259857178, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.01766553707420826, 'loss_2': 0.017120361328125, 'loss_3': -15.968883514404297, 'loss_4': 2.2237155437469482, 'epoch': 4.6}
{'loss': 0.0473, 'grad_norm': 14.004642486572266, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.03869358450174332, 'loss_2': 0.00860595703125, 'loss_3': -16.028507232666016, 'loss_4': 2.3234622478485107, 'epoch': 4.61}
{'loss': 0.022, 'grad_norm': 5.901274681091309, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.01681237854063511, 'loss_2': 0.0052032470703125, 'loss_3': -15.957140922546387, 'loss_4': 2.2317075729370117, 'epoch': 4.62}
{'loss': 0.0207, 'grad_norm': 6.240598678588867, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.015131689608097076, 'loss_2': 0.005527496337890625, 'loss_3': -15.864423751831055, 'loss_4': 2.543991804122925, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 12:40:47,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:47,519 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:06<1:15:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:54,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01974775269627571, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.671, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.016013149172067642, 'eval_loss_2': 0.003734603524208069, 'eval_loss_3': -18.228273391723633, 'eval_loss_4': 2.2705202102661133, 'epoch': 4.62}
{'loss': 0.0507, 'grad_norm': 16.681045532226562, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.0474337674677372, 'loss_2': 0.0032806396484375, 'loss_3': -15.98341178894043, 'loss_4': 2.392399311065674, 'epoch': 4.63}
{'loss': 0.0497, 'grad_norm': 16.433422088623047, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.04733796417713165, 'loss_2': 0.0023956298828125, 'loss_3': -15.869701385498047, 'loss_4': 2.3442485332489014, 'epoch': 4.63}
{'loss': 0.0537, 'grad_norm': 15.416817665100098, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.042296942323446274, 'loss_2': 0.011383056640625, 'loss_3': -16.063880920410156, 'loss_4': 2.5412960052490234, 'epoch': 4.64}
{'loss': 0.0547, 'grad_norm': 9.64608383178711, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.036438725888729095, 'loss_2': 0.018218994140625, 'loss_3': -15.959137916564941, 'loss_4': 2.741412878036499, 'epoch': 4.65}
{'loss': 0.0716, 'grad_norm': 14.017255783081055, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.049307797104120255, 'loss_2': 0.0222930908203125, 'loss_3': -16.098834991455078, 'loss_4': 2.357414722442627, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 12:40:54,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:54,864 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:14<1:15:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:02,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03546600416302681, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.833, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019093796610832214, 'eval_loss_2': 0.016372203826904297, 'eval_loss_3': -18.26470947265625, 'eval_loss_4': 2.547379970550537, 'epoch': 4.65}
{'loss': 0.066, 'grad_norm': 12.823404312133789, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.04846120998263359, 'loss_2': 0.0175628662109375, 'loss_3': -16.144203186035156, 'loss_4': 2.50648832321167, 'epoch': 4.66}
{'loss': 0.0619, 'grad_norm': 10.860282897949219, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.042069997638463974, 'loss_2': 0.0197906494140625, 'loss_3': -15.991348266601562, 'loss_4': 2.618630886077881, 'epoch': 4.66}
{'loss': 0.0563, 'grad_norm': 13.656286239624023, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.045361269265413284, 'loss_2': 0.0109405517578125, 'loss_3': -15.91036319732666, 'loss_4': 2.6103832721710205, 'epoch': 4.67}
{'loss': 0.0499, 'grad_norm': 11.648738861083984, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.04305299371480942, 'loss_2': 0.00688934326171875, 'loss_3': -15.920768737792969, 'loss_4': 2.11606764793396, 'epoch': 4.67}
{'loss': 0.1192, 'grad_norm': 28.203590393066406, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.11598681658506393, 'loss_2': 0.00318145751953125, 'loss_3': -15.7142972946167, 'loss_4': 1.9019134044647217, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 12:41:02,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:02,215 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:21<1:15:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:09,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020376527681946754, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.986, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.015713518485426903, 'eval_loss_2': 0.004663005471229553, 'eval_loss_3': -18.216833114624023, 'eval_loss_4': 1.9607017040252686, 'epoch': 4.68}
{'loss': 0.0562, 'grad_norm': 23.919225692749023, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.052968185395002365, 'loss_2': 0.003215789794921875, 'loss_3': -15.734013557434082, 'loss_4': 2.189936637878418, 'epoch': 4.69}
{'loss': 0.0408, 'grad_norm': 14.324575424194336, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.03956296667456627, 'loss_2': 0.0012493133544921875, 'loss_3': -15.82243537902832, 'loss_4': 2.231750965118408, 'epoch': 4.69}
{'loss': 0.0267, 'grad_norm': 10.230084419250488, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.025903798639774323, 'loss_2': 0.0008220672607421875, 'loss_3': -16.171354293823242, 'loss_4': 1.2613866329193115, 'epoch': 4.7}
{'loss': 0.0482, 'grad_norm': 16.67365837097168, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.04276548698544502, 'loss_2': 0.005474090576171875, 'loss_3': -15.743830680847168, 'loss_4': 1.1969513893127441, 'epoch': 4.7}
{'loss': 0.0221, 'grad_norm': 12.47697925567627, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.017777999863028526, 'loss_2': 0.004299163818359375, 'loss_3': -16.00755500793457, 'loss_4': 1.6891368627548218, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 12:41:09,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:09,557 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:28<1:15:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:16,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01839149184525013, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.945, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.014376223087310791, 'eval_loss_2': 0.0040152668952941895, 'eval_loss_3': -18.21168327331543, 'eval_loss_4': 1.1969525814056396, 'epoch': 4.71}
{'loss': 0.0138, 'grad_norm': 6.090773105621338, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.013153460808098316, 'loss_2': 0.0006709098815917969, 'loss_3': -15.973939895629883, 'loss_4': 1.1513317823410034, 'epoch': 4.72}
{'loss': 0.0304, 'grad_norm': 9.994906425476074, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.02811715565621853, 'loss_2': 0.00226593017578125, 'loss_3': -15.729532241821289, 'loss_4': 1.1048325300216675, 'epoch': 4.72}
{'loss': 0.0291, 'grad_norm': 6.474331378936768, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.018448980525135994, 'loss_2': 0.0106658935546875, 'loss_3': -15.82081413269043, 'loss_4': 1.4951499700546265, 'epoch': 4.73}
{'loss': 0.0415, 'grad_norm': 14.810100555419922, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.03795820102095604, 'loss_2': 0.0035247802734375, 'loss_3': -16.03984260559082, 'loss_4': 0.8670896291732788, 'epoch': 4.73}
{'loss': 0.0225, 'grad_norm': 6.810689449310303, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.021249784156680107, 'loss_2': 0.0012264251708984375, 'loss_3': -15.960403442382812, 'loss_4': 1.1014912128448486, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 12:41:16,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:16,897 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:36<1:15:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:24,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021312864497303963, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.901, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014889865182340145, 'eval_loss_2': 0.006422996520996094, 'eval_loss_3': -18.224952697753906, 'eval_loss_4': 0.8788019418716431, 'epoch': 4.74}
{'loss': 0.0255, 'grad_norm': 8.535093307495117, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.018997667357325554, 'loss_2': 0.0064544677734375, 'loss_3': -15.993236541748047, 'loss_4': 0.9331680536270142, 'epoch': 4.74}
{'loss': 0.0416, 'grad_norm': 13.878217697143555, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.032911114394664764, 'loss_2': 0.00868988037109375, 'loss_3': -15.969512939453125, 'loss_4': 1.149250864982605, 'epoch': 4.75}
{'loss': 0.0376, 'grad_norm': 7.725581645965576, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.025722794234752655, 'loss_2': 0.0119171142578125, 'loss_3': -15.792083740234375, 'loss_4': 1.3850159645080566, 'epoch': 4.76}
{'loss': 0.0496, 'grad_norm': 9.738698959350586, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.043822288513183594, 'loss_2': 0.005764007568359375, 'loss_3': -15.89751148223877, 'loss_4': 0.9993022680282593, 'epoch': 4.76}
{'loss': 0.0317, 'grad_norm': 9.495281219482422, 'learning_rate': 2.525e-05, 'loss_1': 0.030219601467251778, 'loss_2': 0.001476287841796875, 'loss_3': -15.947356224060059, 'loss_4': 1.141395092010498, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 12:41:24,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:24,241 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:40<1:15:04,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:41:28,039 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-820
[INFO|configuration_utils.py:420] 2025-01-21 12:41:28,040 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-820/config.json                                                                             
{'eval_loss': 0.014374722726643085, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.754, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011890009976923466, 'eval_loss_2': 0.0024847127497196198, 'eval_loss_3': -18.23110580444336, 'eval_loss_4': 0.7189269661903381, 'epoch': 4.77}
[INFO|modeling_utils.py:2988] 2025-01-21 12:41:28,504 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-820/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:41:28,505 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-820/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:41:28,505 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-820/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:41:29,316 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-700] due to args.save_total_limit
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:44<1:22:02,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:41:32,950 >>
{'loss': 0.0285, 'grad_norm': 7.278834342956543, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.0281975194811821, 'loss_2': 0.0002803802490234375, 'loss_3': -15.851651191711426, 'loss_4': 0.5169280171394348, 'epoch': 4.77}
{'loss': 0.0161, 'grad_norm': 7.819861888885498, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.015507577918469906, 'loss_2': 0.0005726814270019531, 'loss_3': -16.101177215576172, 'loss_4': 0.6810283660888672, 'epoch': 4.78}
{'loss': 0.098, 'grad_norm': 12.18474006652832, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.09364921599626541, 'loss_2': 0.00437164306640625, 'loss_3': -16.035123825073242, 'loss_4': 1.7078583240509033, 'epoch': 4.78}
{'loss': 0.0187, 'grad_norm': 7.465044021606445, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.018425162881612778, 'loss_2': 0.0002925395965576172, 'loss_3': -15.993685722351074, 'loss_4': 0.6254059076309204, 'epoch': 4.79}
{'loss': 0.0646, 'grad_norm': 16.43782615661621, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.055104997009038925, 'loss_2': 0.0094757080078125, 'loss_3': -16.030141830444336, 'loss_4': 1.5273640155792236, 'epoch': 4.8}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:41:32,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:32,950 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:52<1:15:53,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:41:40,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014749918133020401, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.441, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.011343870311975479, 'eval_loss_2': 0.003406047821044922, 'eval_loss_3': -18.23487663269043, 'eval_loss_4': 1.1939003467559814, 'epoch': 4.8}
{'loss': 0.0286, 'grad_norm': 8.136362075805664, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.022121408954262733, 'loss_2': 0.006488800048828125, 'loss_3': -15.87674331665039, 'loss_4': 0.9467630386352539, 'epoch': 4.8}
{'loss': 0.0431, 'grad_norm': 13.177566528320312, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.04058264195919037, 'loss_2': 0.002490997314453125, 'loss_3': -15.835819244384766, 'loss_4': 1.1323612928390503, 'epoch': 4.81}
{'loss': 0.0534, 'grad_norm': 13.563789367675781, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.047056276351213455, 'loss_2': 0.00630950927734375, 'loss_3': -15.88822078704834, 'loss_4': 1.7310773134231567, 'epoch': 4.81}
{'loss': 0.0412, 'grad_norm': 21.57576560974121, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.03749488294124603, 'loss_2': 0.0037364959716796875, 'loss_3': -15.898468971252441, 'loss_4': 1.482040524482727, 'epoch': 4.82}
{'loss': 0.0354, 'grad_norm': 10.968179702758789, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.027209728956222534, 'loss_2': 0.0082244873046875, 'loss_3': -16.01513671875, 'loss_4': 1.529531717300415, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 12:41:40,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:40,273 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [20:59<1:14:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:47,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016633441671729088, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.353, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.010987658984959126, 'eval_loss_2': 0.005645781755447388, 'eval_loss_3': -18.239789962768555, 'eval_loss_4': 1.7276440858840942, 'epoch': 4.83}
{'loss': 0.0255, 'grad_norm': 9.605905532836914, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.024316558614373207, 'loss_2': 0.0011425018310546875, 'loss_3': -15.882665634155273, 'loss_4': 1.6024534702301025, 'epoch': 4.83}
{'loss': 0.0504, 'grad_norm': 17.536344528198242, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.04760820046067238, 'loss_2': 0.002819061279296875, 'loss_3': -15.867118835449219, 'loss_4': 1.830893635749817, 'epoch': 4.84}
{'loss': 0.039, 'grad_norm': 12.605319023132324, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.030099255964159966, 'loss_2': 0.0089263916015625, 'loss_3': -15.895523071289062, 'loss_4': 1.8917734622955322, 'epoch': 4.84}
{'loss': 0.035, 'grad_norm': 9.006464958190918, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.034777842462062836, 'loss_2': 0.00026607513427734375, 'loss_3': -16.10247039794922, 'loss_4': 2.131040334701538, 'epoch': 4.85}
{'loss': 0.0581, 'grad_norm': 19.142047882080078, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.056820858269929886, 'loss_2': 0.0012531280517578125, 'loss_3': -16.104049682617188, 'loss_4': 2.477735996246338, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 12:41:47,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:47,604 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:06<1:14:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:54,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01638074778020382, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.236, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013098097406327724, 'eval_loss_2': 0.0032826513051986694, 'eval_loss_3': -18.269683837890625, 'eval_loss_4': 2.025625228881836, 'epoch': 4.85}
{'loss': 0.0419, 'grad_norm': 10.669692993164062, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.038653649389743805, 'loss_2': 0.003223419189453125, 'loss_3': -16.021961212158203, 'loss_4': 2.1715188026428223, 'epoch': 4.86}
{'loss': 0.0426, 'grad_norm': 13.519603729248047, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.040255725383758545, 'loss_2': 0.0023288726806640625, 'loss_3': -15.843620300292969, 'loss_4': 2.8778603076934814, 'epoch': 4.87}
{'loss': 0.1306, 'grad_norm': 28.97580909729004, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.1302003413438797, 'loss_2': 0.0004029273986816406, 'loss_3': -15.582923889160156, 'loss_4': 2.569481611251831, 'epoch': 4.87}
{'loss': 0.061, 'grad_norm': 14.125411987304688, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.05667894706130028, 'loss_2': 0.00432586669921875, 'loss_3': -16.122806549072266, 'loss_4': 2.4935197830200195, 'epoch': 4.88}
{'loss': 0.0325, 'grad_norm': 12.875985145568848, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.03183544799685478, 'loss_2': 0.0006604194641113281, 'loss_3': -15.962677955627441, 'loss_4': 1.4436078071594238, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 12:41:54,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:54,934 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:14<1:14:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:02,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019719360396265984, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.188, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012499925680458546, 'eval_loss_2': 0.007219433784484863, 'eval_loss_3': -18.29477310180664, 'eval_loss_4': 1.8195267915725708, 'epoch': 4.88}
{'loss': 0.0351, 'grad_norm': 19.7007999420166, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.033725690096616745, 'loss_2': 0.0014057159423828125, 'loss_3': -16.00131607055664, 'loss_4': 2.477720260620117, 'epoch': 4.89}
{'loss': 0.0264, 'grad_norm': 10.19072151184082, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.026282811537384987, 'loss_2': 7.87973403930664e-05, 'loss_3': -16.13332748413086, 'loss_4': 1.9695897102355957, 'epoch': 4.9}
{'loss': 0.0365, 'grad_norm': 8.339664459228516, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.022995630279183388, 'loss_2': 0.0135345458984375, 'loss_3': -16.10309410095215, 'loss_4': 2.056602954864502, 'epoch': 4.9}
{'loss': 0.0278, 'grad_norm': 8.462143898010254, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.02026486210525036, 'loss_2': 0.00750732421875, 'loss_3': -16.06394386291504, 'loss_4': 1.8333053588867188, 'epoch': 4.91}
{'loss': 0.0487, 'grad_norm': 16.36570167541504, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.03868381679058075, 'loss_2': 0.010009765625, 'loss_3': -15.992379188537598, 'loss_4': 1.7545862197875977, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 12:42:02,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:02,270 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:21<1:14:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:09,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022280625998973846, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.012491068802773952, 'eval_loss_2': 0.00978955626487732, 'eval_loss_3': -18.26422882080078, 'eval_loss_4': 1.3395124673843384, 'epoch': 4.91}
{'loss': 0.0547, 'grad_norm': 12.783695220947266, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.04409630969166756, 'loss_2': 0.0106048583984375, 'loss_3': -15.90670394897461, 'loss_4': 1.09619140625, 'epoch': 4.92}
{'loss': 0.0773, 'grad_norm': 14.78110408782959, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.06477807462215424, 'loss_2': 0.01256561279296875, 'loss_3': -15.879477500915527, 'loss_4': 1.6399214267730713, 'epoch': 4.92}
{'loss': 0.0321, 'grad_norm': 12.983495712280273, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.031090257689356804, 'loss_2': 0.0010118484497070312, 'loss_3': -16.00520896911621, 'loss_4': 1.742678165435791, 'epoch': 4.93}
{'loss': 0.0309, 'grad_norm': 10.001533508300781, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.025452306494116783, 'loss_2': 0.0054931640625, 'loss_3': -16.08770179748535, 'loss_4': 1.3415812253952026, 'epoch': 4.94}
{'loss': 0.0554, 'grad_norm': 10.098456382751465, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.046695273369550705, 'loss_2': 0.00875091552734375, 'loss_3': -15.590614318847656, 'loss_4': 0.9674025177955627, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 12:42:09,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:09,613 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:28<1:14:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:16,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01662975363433361, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.285, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.011598046869039536, 'eval_loss_2': 0.005031704902648926, 'eval_loss_3': -18.242671966552734, 'eval_loss_4': 1.0005083084106445, 'epoch': 4.94}
{'loss': 0.0315, 'grad_norm': 11.920201301574707, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.028915157541632652, 'loss_2': 0.002574920654296875, 'loss_3': -16.004589080810547, 'loss_4': 1.207300066947937, 'epoch': 4.95}
{'loss': 0.0209, 'grad_norm': 6.318173885345459, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.018514633178710938, 'loss_2': 0.002414703369140625, 'loss_3': -15.974071502685547, 'loss_4': 0.7781472206115723, 'epoch': 4.95}
{'loss': 0.0176, 'grad_norm': 6.228955268859863, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.01748843491077423, 'loss_2': 0.0001323223114013672, 'loss_3': -15.985628128051758, 'loss_4': 1.329740285873413, 'epoch': 4.96}
{'loss': 0.0245, 'grad_norm': 8.034269332885742, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.021214116364717484, 'loss_2': 0.0032367706298828125, 'loss_3': -15.777015686035156, 'loss_4': 1.2545063495635986, 'epoch': 4.97}
{'loss': 0.0212, 'grad_norm': 6.454098701477051, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.016172243282198906, 'loss_2': 0.0050506591796875, 'loss_3': -16.028888702392578, 'loss_4': 1.2218282222747803, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 12:42:16,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:16,940 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:35<1:06:48,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 12:42:23,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016271233558654785, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.175, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012756967917084694, 'eval_loss_2': 0.0035142675042152405, 'eval_loss_3': -18.2476749420166, 'eval_loss_4': 1.087884545326233, 'epoch': 4.97}
{'loss': 0.0195, 'grad_norm': 7.119899749755859, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.017942652106285095, 'loss_2': 0.0015201568603515625, 'loss_3': -16.003849029541016, 'loss_4': 0.8317268490791321, 'epoch': 4.98}
{'loss': 0.0622, 'grad_norm': 17.407888412475586, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.05487579479813576, 'loss_2': 0.0073699951171875, 'loss_3': -16.019733428955078, 'loss_4': 1.7308716773986816, 'epoch': 4.98}
{'loss': 0.0259, 'grad_norm': 6.565994739532471, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.01886739209294319, 'loss_2': 0.006999969482421875, 'loss_3': -16.082883834838867, 'loss_4': 1.5664749145507812, 'epoch': 4.99}
{'loss': 0.0371, 'grad_norm': 8.444128036499023, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.025053156539797783, 'loss_2': 0.01200103759765625, 'loss_3': -15.919419288635254, 'loss_4': 1.54412043094635, 'epoch': 4.99}
{'loss': 0.0257, 'grad_norm': 7.494159698486328, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.013857663609087467, 'loss_2': 0.011871337890625, 'loss_3': -16.207740783691406, 'loss_4': 1.989552617073059, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 12:42:23,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:23,920 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:43<1:13:07,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:42:31,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019821975380182266, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.985, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014409545809030533, 'eval_loss_2': 0.005412429571151733, 'eval_loss_3': -18.23311996459961, 'eval_loss_4': 1.1795482635498047, 'epoch': 5.0}
{'loss': 0.0376, 'grad_norm': 7.995686054229736, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.027963781729340553, 'loss_2': 0.00965118408203125, 'loss_3': -15.773873329162598, 'loss_4': 1.3323760032653809, 'epoch': 5.01}
{'loss': 0.034, 'grad_norm': 12.551997184753418, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.03135433420538902, 'loss_2': 0.002666473388671875, 'loss_3': -16.105182647705078, 'loss_4': 1.583730697631836, 'epoch': 5.01}
{'loss': 0.0374, 'grad_norm': 10.915487289428711, 'learning_rate': 2.5e-05, 'loss_1': 0.03317030891776085, 'loss_2': 0.0042572021484375, 'loss_3': -16.003826141357422, 'loss_4': 1.5526182651519775, 'epoch': 5.02}
{'loss': 0.0229, 'grad_norm': 7.2898149490356445, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.021231429651379585, 'loss_2': 0.0016574859619140625, 'loss_3': -15.843608856201172, 'loss_4': 0.9295659065246582, 'epoch': 5.02}
{'loss': 0.0223, 'grad_norm': 8.475661277770996, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.021178508177399635, 'loss_2': 0.0011310577392578125, 'loss_3': -15.843246459960938, 'loss_4': 1.109945297241211, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 12:42:31,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:31,295 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:50<1:13:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:42:38,622 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019146792590618134, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.384, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.014031046070158482, 'eval_loss_2': 0.0051157474517822266, 'eval_loss_3': -18.19642448425293, 'eval_loss_4': 1.0639739036560059, 'epoch': 5.03}
{'loss': 0.0279, 'grad_norm': 7.328938961029053, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.022467292845249176, 'loss_2': 0.0054779052734375, 'loss_3': -16.05944061279297, 'loss_4': 1.323386788368225, 'epoch': 5.03}
{'loss': 0.0344, 'grad_norm': 9.791767120361328, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.026920124888420105, 'loss_2': 0.00748443603515625, 'loss_3': -15.872901916503906, 'loss_4': 0.9343360662460327, 'epoch': 5.04}
{'loss': 0.0343, 'grad_norm': 7.067798614501953, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.02244240790605545, 'loss_2': 0.0118560791015625, 'loss_3': -15.855546951293945, 'loss_4': 1.0278397798538208, 'epoch': 5.05}
{'loss': 0.0238, 'grad_norm': 9.87917709350586, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.022975046187639236, 'loss_2': 0.0008664131164550781, 'loss_3': -15.975349426269531, 'loss_4': 1.757094144821167, 'epoch': 5.05}
{'loss': 0.0309, 'grad_norm': 7.954799175262451, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.022622687742114067, 'loss_2': 0.0083160400390625, 'loss_3': -15.669480323791504, 'loss_4': 1.4036602973937988, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 12:42:38,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:38,623 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [21:57<1:14:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:45,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015477590262889862, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.052, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013203971087932587, 'eval_loss_2': 0.0022736191749572754, 'eval_loss_3': -18.178470611572266, 'eval_loss_4': 1.2171920537948608, 'epoch': 5.06}
{'loss': 0.0262, 'grad_norm': 9.123193740844727, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.022092493250966072, 'loss_2': 0.00411224365234375, 'loss_3': -16.060964584350586, 'loss_4': 1.2143468856811523, 'epoch': 5.06}
{'loss': 0.0419, 'grad_norm': 11.905220031738281, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.03959466889500618, 'loss_2': 0.002307891845703125, 'loss_3': -16.042804718017578, 'loss_4': 1.3831605911254883, 'epoch': 5.07}
{'loss': 0.0331, 'grad_norm': 10.02929401397705, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.028492193669080734, 'loss_2': 0.00458526611328125, 'loss_3': -15.93914794921875, 'loss_4': 0.5999450087547302, 'epoch': 5.08}
{'loss': 0.0408, 'grad_norm': 12.218573570251465, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.03851017728447914, 'loss_2': 0.002288818359375, 'loss_3': -15.984481811523438, 'loss_4': 0.7926794290542603, 'epoch': 5.08}
{'loss': 0.0293, 'grad_norm': 13.575016975402832, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.027365783229470253, 'loss_2': 0.0019321441650390625, 'loss_3': -15.761560440063477, 'loss_4': 0.8096269369125366, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 12:42:45,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:45,963 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [22:05<1:14:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:53,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01679406687617302, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01414109393954277, 'eval_loss_2': 0.002652972936630249, 'eval_loss_3': -18.176982879638672, 'eval_loss_4': 1.2717454433441162, 'epoch': 5.09}
{'loss': 0.0275, 'grad_norm': 10.313252449035645, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.02527879737317562, 'loss_2': 0.00220489501953125, 'loss_3': -15.85558795928955, 'loss_4': 0.9684759378433228, 'epoch': 5.09}
{'loss': 0.0112, 'grad_norm': 5.6240668296813965, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.008670785464346409, 'loss_2': 0.002483367919921875, 'loss_3': -16.033756256103516, 'loss_4': 1.0022245645523071, 'epoch': 5.1}
{'loss': 0.0548, 'grad_norm': 16.360017776489258, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.053512439131736755, 'loss_2': 0.0013036727905273438, 'loss_3': -15.674813270568848, 'loss_4': 0.927703857421875, 'epoch': 5.1}
{'loss': 0.0202, 'grad_norm': 6.081383228302002, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.019126640632748604, 'loss_2': 0.0011138916015625, 'loss_3': -16.048044204711914, 'loss_4': 1.7679978609085083, 'epoch': 5.11}
{'loss': 0.0209, 'grad_norm': 9.293591499328613, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.020402628928422928, 'loss_2': 0.0005435943603515625, 'loss_3': -15.828446388244629, 'loss_4': 1.3118864297866821, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 12:42:53,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:53,310 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:12<1:13:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:00,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020475372672080994, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.016520917415618896, 'eval_loss_2': 0.003954455256462097, 'eval_loss_3': -18.152101516723633, 'eval_loss_4': 1.5554078817367554, 'epoch': 5.12}
{'loss': 0.0284, 'grad_norm': 6.382122039794922, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.02509284019470215, 'loss_2': 0.003292083740234375, 'loss_3': -15.764715194702148, 'loss_4': 1.4319998025894165, 'epoch': 5.12}
{'loss': 0.0397, 'grad_norm': 15.387651443481445, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.038094718009233475, 'loss_2': 0.0016326904296875, 'loss_3': -15.733800888061523, 'loss_4': 1.2070565223693848, 'epoch': 5.13}
{'loss': 0.0247, 'grad_norm': 11.768996238708496, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.02318860962986946, 'loss_2': 0.0015153884887695312, 'loss_3': -15.906685829162598, 'loss_4': 1.7194032669067383, 'epoch': 5.13}
{'loss': 0.0963, 'grad_norm': 22.651498794555664, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.09445520490407944, 'loss_2': 0.001861572265625, 'loss_3': -15.952169418334961, 'loss_4': 1.9372938871383667, 'epoch': 5.14}
{'loss': 0.0184, 'grad_norm': 5.292119026184082, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.010369659401476383, 'loss_2': 0.0080718994140625, 'loss_3': -15.836690902709961, 'loss_4': 1.072824239730835, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 12:43:00,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:00,648 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:19<1:13:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:07,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022433122619986534, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.208, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019312161952257156, 'eval_loss_2': 0.0031209588050842285, 'eval_loss_3': -18.129470825195312, 'eval_loss_4': 1.604027509689331, 'epoch': 5.15}
{'loss': 0.0257, 'grad_norm': 6.815877437591553, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.01845959760248661, 'loss_2': 0.007266998291015625, 'loss_3': -15.912729263305664, 'loss_4': 1.4898297786712646, 'epoch': 5.15}
{'loss': 0.0468, 'grad_norm': 10.666379928588867, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.04046458750963211, 'loss_2': 0.006320953369140625, 'loss_3': -15.826991081237793, 'loss_4': 1.5193078517913818, 'epoch': 5.16}
{'loss': 0.015, 'grad_norm': 6.383988380432129, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.014034280553460121, 'loss_2': 0.0009660720825195312, 'loss_3': -15.702496528625488, 'loss_4': 1.7592554092407227, 'epoch': 5.16}
{'loss': 0.0375, 'grad_norm': 20.659833908081055, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.036059923470020294, 'loss_2': 0.001453399658203125, 'loss_3': -15.916370391845703, 'loss_4': 1.7721366882324219, 'epoch': 5.17}
{'loss': 0.0224, 'grad_norm': 7.8829193115234375, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.018656332045793533, 'loss_2': 0.0037822723388671875, 'loss_3': -15.659717559814453, 'loss_4': 1.3596633672714233, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 12:43:07,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:07,990 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:27<1:13:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:15,323 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024508589878678322, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.02, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.020500535145401955, 'eval_loss_2': 0.004008054733276367, 'eval_loss_3': -18.075641632080078, 'eval_loss_4': 1.5487213134765625, 'epoch': 5.17}
{'loss': 0.0189, 'grad_norm': 6.418628692626953, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.015589097514748573, 'loss_2': 0.0032749176025390625, 'loss_3': -15.795730590820312, 'loss_4': 1.489511251449585, 'epoch': 5.18}
{'loss': 0.0182, 'grad_norm': 6.394471645355225, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.014424880966544151, 'loss_2': 0.0037384033203125, 'loss_3': -15.784440994262695, 'loss_4': 1.6564275026321411, 'epoch': 5.19}
{'loss': 0.0261, 'grad_norm': 8.789694786071777, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.02254202961921692, 'loss_2': 0.00353240966796875, 'loss_3': -15.821016311645508, 'loss_4': 1.9266818761825562, 'epoch': 5.19}
{'loss': 0.0149, 'grad_norm': 5.329647064208984, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.008295307867228985, 'loss_2': 0.006591796875, 'loss_3': -15.778304100036621, 'loss_4': 1.6325721740722656, 'epoch': 5.2}
{'loss': 0.0229, 'grad_norm': 11.447735786437988, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.022449271753430367, 'loss_2': 0.0004334449768066406, 'loss_3': -15.722101211547852, 'loss_4': 1.5881097316741943, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 12:43:15,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:15,324 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:34<1:13:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:22,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03242264688014984, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.122, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.02587978169322014, 'eval_loss_2': 0.006542861461639404, 'eval_loss_3': -18.018814086914062, 'eval_loss_4': 1.603386402130127, 'epoch': 5.2}
{'loss': 0.0487, 'grad_norm': 14.103669166564941, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.040112148970365524, 'loss_2': 0.008575439453125, 'loss_3': -15.6066312789917, 'loss_4': 1.5609784126281738, 'epoch': 5.21}
{'loss': 0.1123, 'grad_norm': 28.169870376586914, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.10226085036993027, 'loss_2': 0.0100250244140625, 'loss_3': -15.759500503540039, 'loss_4': 1.9678592681884766, 'epoch': 5.22}
{'loss': 0.0218, 'grad_norm': 6.382497787475586, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.014087002724409103, 'loss_2': 0.0077056884765625, 'loss_3': -15.819271087646484, 'loss_4': 1.7784249782562256, 'epoch': 5.22}
{'loss': 0.1318, 'grad_norm': 28.14616584777832, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.11404328793287277, 'loss_2': 0.017730712890625, 'loss_3': -15.460264205932617, 'loss_4': 1.7986907958984375, 'epoch': 5.23}
{'loss': 0.0579, 'grad_norm': 15.908154487609863, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.053647659718990326, 'loss_2': 0.004245758056640625, 'loss_3': -15.817935943603516, 'loss_4': 1.3806726932525635, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 12:43:22,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:22,662 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:41<1:13:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:30,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028590332716703415, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.498, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.022419946268200874, 'eval_loss_2': 0.006170392036437988, 'eval_loss_3': -18.016712188720703, 'eval_loss_4': 1.7679086923599243, 'epoch': 5.23}
{'loss': 0.0253, 'grad_norm': 8.131147384643555, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.024075675755739212, 'loss_2': 0.001247406005859375, 'loss_3': -15.742364883422852, 'loss_4': 1.7339982986450195, 'epoch': 5.24}
{'loss': 0.0555, 'grad_norm': 22.608102798461914, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.05508560687303543, 'loss_2': 0.0004055500030517578, 'loss_3': -15.664186477661133, 'loss_4': 1.2014912366867065, 'epoch': 5.24}
{'loss': 0.0093, 'grad_norm': 5.565805435180664, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.008461665362119675, 'loss_2': 0.0008158683776855469, 'loss_3': -16.072948455810547, 'loss_4': 1.5468261241912842, 'epoch': 5.25}
{'loss': 0.1241, 'grad_norm': 34.03570556640625, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.12379154562950134, 'loss_2': 0.0003361701965332031, 'loss_3': -15.761215209960938, 'loss_4': 2.1256563663482666, 'epoch': 5.26}
{'loss': 0.0337, 'grad_norm': 11.032890319824219, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.028317507356405258, 'loss_2': 0.005401611328125, 'loss_3': -15.698409080505371, 'loss_4': 1.7493689060211182, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 12:43:30,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:30,009 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:49<1:13:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:37,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019589930772781372, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.914, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01054278016090393, 'eval_loss_2': 0.009047150611877441, 'eval_loss_3': -18.171445846557617, 'eval_loss_4': 1.6193667650222778, 'epoch': 5.26}
{'loss': 0.0269, 'grad_norm': 7.457147598266602, 'learning_rate': 2.475e-05, 'loss_1': 0.016244856640696526, 'loss_2': 0.010650634765625, 'loss_3': -15.63604736328125, 'loss_4': 1.1936309337615967, 'epoch': 5.27}
{'loss': 0.0422, 'grad_norm': 16.770313262939453, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.034410037100315094, 'loss_2': 0.007778167724609375, 'loss_3': -15.837343215942383, 'loss_4': 1.377016544342041, 'epoch': 5.27}
{'loss': 0.0183, 'grad_norm': 5.4947190284729, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.009530347771942616, 'loss_2': 0.0088043212890625, 'loss_3': -15.731412887573242, 'loss_4': 1.590680718421936, 'epoch': 5.28}
{'loss': 0.0179, 'grad_norm': 6.7572407722473145, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.017774997279047966, 'loss_2': 0.00016164779663085938, 'loss_3': -15.929351806640625, 'loss_4': 2.3177947998046875, 'epoch': 5.28}
{'loss': 0.0565, 'grad_norm': 23.166215896606445, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.05351761728525162, 'loss_2': 0.0029754638671875, 'loss_3': -15.687383651733398, 'loss_4': 2.7355732917785645, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 12:43:37,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:37,353 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [22:56<1:13:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:44,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01497291773557663, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01168451365083456, 'eval_loss_2': 0.0032884031534194946, 'eval_loss_3': -18.18994903564453, 'eval_loss_4': 1.9718819856643677, 'epoch': 5.29}
{'loss': 0.0539, 'grad_norm': 22.68722915649414, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.052874818444252014, 'loss_2': 0.0009937286376953125, 'loss_3': -15.855125427246094, 'loss_4': 2.5518722534179688, 'epoch': 5.3}
{'loss': 0.0367, 'grad_norm': 11.014376640319824, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.029172753915190697, 'loss_2': 0.00751495361328125, 'loss_3': -15.523734092712402, 'loss_4': 1.8618775606155396, 'epoch': 5.3}
{'loss': 0.0267, 'grad_norm': 7.510732650756836, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.01612824760377407, 'loss_2': 0.0105743408203125, 'loss_3': -15.864587783813477, 'loss_4': 2.3042473793029785, 'epoch': 5.31}
{'loss': 0.0338, 'grad_norm': 9.652754783630371, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.018839048221707344, 'loss_2': 0.01495361328125, 'loss_3': -15.876371383666992, 'loss_4': 2.0001440048217773, 'epoch': 5.31}
{'loss': 0.0534, 'grad_norm': 21.402700424194336, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.03617309033870697, 'loss_2': 0.01727294921875, 'loss_3': -16.001136779785156, 'loss_4': 1.9465748071670532, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 12:43:44,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:44,690 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:04<1:13:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:52,021 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02119886502623558, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.304, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0106655303388834, 'eval_loss_2': 0.010533332824707031, 'eval_loss_3': -18.158483505249023, 'eval_loss_4': 1.2175397872924805, 'epoch': 5.32}
{'loss': 0.0247, 'grad_norm': 7.109562397003174, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.012665952555835247, 'loss_2': 0.01206207275390625, 'loss_3': -15.914693832397461, 'loss_4': 0.9783816933631897, 'epoch': 5.33}
{'loss': 0.0152, 'grad_norm': 4.923107147216797, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.006563311442732811, 'loss_2': 0.0085906982421875, 'loss_3': -15.908512115478516, 'loss_4': 0.9703052043914795, 'epoch': 5.33}
{'loss': 0.0177, 'grad_norm': 6.83179235458374, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.01107572577893734, 'loss_2': 0.006626129150390625, 'loss_3': -15.855016708374023, 'loss_4': 1.2718515396118164, 'epoch': 5.34}
{'loss': 0.013, 'grad_norm': 4.603912830352783, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.006702750455588102, 'loss_2': 0.00628662109375, 'loss_3': -15.975775718688965, 'loss_4': 0.8502237200737, 'epoch': 5.34}
{'loss': 0.02, 'grad_norm': 5.604069709777832, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.013014509342610836, 'loss_2': 0.00698089599609375, 'loss_3': -15.835500717163086, 'loss_4': 0.7732183933258057, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 12:43:52,022 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:52,022 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:07<1:13:13,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:43:55,814 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-920
[INFO|configuration_utils.py:420] 2025-01-21 12:43:55,815 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-920/config.json                                                                             
{'eval_loss': 0.0142296701669693, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.115, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010641171596944332, 'eval_loss_2': 0.0035884976387023926, 'eval_loss_3': -18.142425537109375, 'eval_loss_4': 0.2770818769931793, 'epoch': 5.35}
[INFO|modeling_utils.py:2988] 2025-01-21 12:43:56,285 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-920/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:43:56,287 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-920/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:43:56,287 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-920/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:43:57,109 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-820] due to args.save_total_limit
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:12<1:20:11,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:44:00,741 >>
{'loss': 0.0109, 'grad_norm': 5.527557849884033, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.009230630472302437, 'loss_2': 0.0016679763793945312, 'loss_3': -16.125385284423828, 'loss_4': 0.5066749453544617, 'epoch': 5.35}
{'loss': 0.0395, 'grad_norm': 15.637856483459473, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.036428239196538925, 'loss_2': 0.00310516357421875, 'loss_3': -15.592988967895508, 'loss_4': 0.7028164863586426, 'epoch': 5.36}
{'loss': 0.0435, 'grad_norm': 14.343932151794434, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.027986466884613037, 'loss_2': 0.01554107666015625, 'loss_3': -15.822486877441406, 'loss_4': 0.38120973110198975, 'epoch': 5.37}
{'loss': 0.0461, 'grad_norm': 16.28631019592285, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.03289134055376053, 'loss_2': 0.0131988525390625, 'loss_3': -15.781723976135254, 'loss_4': -0.362311989068985, 'epoch': 5.37}
{'loss': 0.104, 'grad_norm': 18.371793746948242, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.09074828773736954, 'loss_2': 0.0132293701171875, 'loss_3': -15.8775634765625, 'loss_4': 0.017838329076766968, 'epoch': 5.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:44:00,741 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:00,741 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:20<1:14:13,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:44:08,074 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02686958760023117, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.076, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012306028045713902, 'eval_loss_2': 0.014563560485839844, 'eval_loss_3': -18.1153507232666, 'eval_loss_4': -0.49724191427230835, 'epoch': 5.38}
{'loss': 0.0429, 'grad_norm': 7.878587245941162, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.03307615965604782, 'loss_2': 0.0098419189453125, 'loss_3': -15.816712379455566, 'loss_4': -0.48179879784584045, 'epoch': 5.38}
{'loss': 0.0451, 'grad_norm': 12.628866195678711, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.026050245389342308, 'loss_2': 0.019012451171875, 'loss_3': -15.803278923034668, 'loss_4': -0.5245380997657776, 'epoch': 5.39}
{'loss': 0.0352, 'grad_norm': 9.842144966125488, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.028534065932035446, 'loss_2': 0.006633758544921875, 'loss_3': -16.00279998779297, 'loss_4': -0.6917608976364136, 'epoch': 5.4}
{'loss': 0.0235, 'grad_norm': 5.394766807556152, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.010259448550641537, 'loss_2': 0.01325225830078125, 'loss_3': -15.97183609008789, 'loss_4': -0.9394367933273315, 'epoch': 5.4}
{'loss': 0.0239, 'grad_norm': 12.03465461730957, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.01962132193148136, 'loss_2': 0.004306793212890625, 'loss_3': -15.97814655303955, 'loss_4': 0.4647058844566345, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 12:44:08,074 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:08,074 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:27<1:13:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:15,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01659153588116169, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.21, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012039321474730968, 'eval_loss_2': 0.004552215337753296, 'eval_loss_3': -18.0726261138916, 'eval_loss_4': -0.6110854148864746, 'epoch': 5.41}
{'loss': 0.024, 'grad_norm': 8.596531867980957, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.0229534562677145, 'loss_2': 0.001049041748046875, 'loss_3': -15.812882423400879, 'loss_4': -1.076798677444458, 'epoch': 5.41}
{'loss': 0.0339, 'grad_norm': 12.174788475036621, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.02923704870045185, 'loss_2': 0.00464630126953125, 'loss_3': -15.79537582397461, 'loss_4': -0.5502821207046509, 'epoch': 5.42}
{'loss': 0.0259, 'grad_norm': 11.401409149169922, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.020615965127944946, 'loss_2': 0.0053253173828125, 'loss_3': -15.975628852844238, 'loss_4': -0.625802755355835, 'epoch': 5.42}
{'loss': 0.0122, 'grad_norm': 6.23799467086792, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.012001547031104565, 'loss_2': 0.0001823902130126953, 'loss_3': -16.16645050048828, 'loss_4': -0.49980270862579346, 'epoch': 5.43}
{'loss': 0.0285, 'grad_norm': 6.525488376617432, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.01795153133571148, 'loss_2': 0.01053619384765625, 'loss_3': -15.89076042175293, 'loss_4': -0.4843031167984009, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 12:44:15,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:15,398 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:34<1:12:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:22,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02259320393204689, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.387, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013654416427016258, 'eval_loss_2': 0.008938789367675781, 'eval_loss_3': -18.095584869384766, 'eval_loss_4': -0.4297986626625061, 'epoch': 5.44}
{'loss': 0.0257, 'grad_norm': 9.753829002380371, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.0221551600843668, 'loss_2': 0.0035400390625, 'loss_3': -15.764833450317383, 'loss_4': -0.33373069763183594, 'epoch': 5.44}
{'loss': 0.0231, 'grad_norm': 7.482524871826172, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.016026310622692108, 'loss_2': 0.00704193115234375, 'loss_3': -16.270484924316406, 'loss_4': -0.1838018000125885, 'epoch': 5.45}
{'loss': 0.045, 'grad_norm': 11.837839126586914, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.031833477318286896, 'loss_2': 0.0131378173828125, 'loss_3': -15.853618621826172, 'loss_4': -0.5879552364349365, 'epoch': 5.45}
{'loss': 0.0441, 'grad_norm': 12.587410926818848, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.03485511243343353, 'loss_2': 0.00927734375, 'loss_3': -16.073007583618164, 'loss_4': 0.9906076192855835, 'epoch': 5.46}
{'loss': 0.0312, 'grad_norm': 8.255805015563965, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.020940985530614853, 'loss_2': 0.01025390625, 'loss_3': -16.026403427124023, 'loss_4': 0.4782290458679199, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 12:44:22,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:22,726 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:42<1:12:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:30,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01698971726000309, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.108, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014111503958702087, 'eval_loss_2': 0.0028782114386558533, 'eval_loss_3': -18.097728729248047, 'eval_loss_4': 0.06477589905261993, 'epoch': 5.47}
{'loss': 0.0309, 'grad_norm': 11.0855131149292, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.024359337985515594, 'loss_2': 0.00653076171875, 'loss_3': -16.01053237915039, 'loss_4': 0.5651254653930664, 'epoch': 5.47}
{'loss': 0.0167, 'grad_norm': 5.408559322357178, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.012283776886761189, 'loss_2': 0.004444122314453125, 'loss_3': -16.20378875732422, 'loss_4': 0.3301318883895874, 'epoch': 5.48}
{'loss': 0.0132, 'grad_norm': 5.8969221115112305, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.01237019058316946, 'loss_2': 0.0008177757263183594, 'loss_3': -15.996061325073242, 'loss_4': 0.2027432918548584, 'epoch': 5.48}
{'loss': 0.0431, 'grad_norm': 8.003998756408691, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.03008536994457245, 'loss_2': 0.012969970703125, 'loss_3': -15.946466445922852, 'loss_4': 0.724504828453064, 'epoch': 5.49}
{'loss': 0.0416, 'grad_norm': 11.436534881591797, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.036086224019527435, 'loss_2': 0.005474090576171875, 'loss_3': -16.165889739990234, 'loss_4': 0.31851130723953247, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 12:44:30,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:30,063 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:49<1:12:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:37,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02119242399930954, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.199, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.011457554996013641, 'eval_loss_2': 0.009734869003295898, 'eval_loss_3': -18.13156509399414, 'eval_loss_4': 0.15922309458255768, 'epoch': 5.49}
{'loss': 0.021, 'grad_norm': 5.968468189239502, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.014032105915248394, 'loss_2': 0.006954193115234375, 'loss_3': -16.16584014892578, 'loss_4': 0.7262066602706909, 'epoch': 5.5}
{'loss': 0.0247, 'grad_norm': 7.00690221786499, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.017354950308799744, 'loss_2': 0.00732421875, 'loss_3': -16.068195343017578, 'loss_4': 0.3624545931816101, 'epoch': 5.51}
{'loss': 0.03, 'grad_norm': 6.883884906768799, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.016554903239011765, 'loss_2': 0.01348876953125, 'loss_3': -16.148208618164062, 'loss_4': 0.13235953450202942, 'epoch': 5.51}
{'loss': 0.0418, 'grad_norm': 14.10948657989502, 'learning_rate': 2.45e-05, 'loss_1': 0.03923745080828667, 'loss_2': 0.0025920867919921875, 'loss_3': -15.947874069213867, 'loss_4': 0.3819701373577118, 'epoch': 5.52}
{'loss': 0.0654, 'grad_norm': 29.573322296142578, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.06511980295181274, 'loss_2': 0.0003247261047363281, 'loss_3': -15.861441612243652, 'loss_4': 0.4641929268836975, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 12:44:37,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:37,399 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [23:56<1:12:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:44,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015792712569236755, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.322, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012039296329021454, 'eval_loss_2': 0.0037534162402153015, 'eval_loss_3': -18.179880142211914, 'eval_loss_4': 0.24082688987255096, 'epoch': 5.52}
{'loss': 0.0503, 'grad_norm': 15.426288604736328, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.04640521481633186, 'loss_2': 0.00394439697265625, 'loss_3': -16.20252227783203, 'loss_4': 0.838670551776886, 'epoch': 5.53}
{'loss': 0.0358, 'grad_norm': 13.713436126708984, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.031642843037843704, 'loss_2': 0.004169464111328125, 'loss_3': -15.986960411071777, 'loss_4': 0.416253924369812, 'epoch': 5.53}
{'loss': 0.0218, 'grad_norm': 5.925078868865967, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.014494368806481361, 'loss_2': 0.00726318359375, 'loss_3': -16.123794555664062, 'loss_4': 0.5202493071556091, 'epoch': 5.54}
{'loss': 0.0403, 'grad_norm': 9.092522621154785, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.024637682363390923, 'loss_2': 0.0156707763671875, 'loss_3': -16.21210289001465, 'loss_4': 0.4419935345649719, 'epoch': 5.55}
{'loss': 0.0457, 'grad_norm': 8.115045547485352, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.03094886802136898, 'loss_2': 0.0147705078125, 'loss_3': -16.100555419921875, 'loss_4': 1.1162712574005127, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 12:44:44,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:44,729 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:04<1:12:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:52,068 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019984904676675797, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.719, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011696876958012581, 'eval_loss_2': 0.008288025856018066, 'eval_loss_3': -18.207843780517578, 'eval_loss_4': 0.2093103528022766, 'epoch': 5.55}
{'loss': 0.0168, 'grad_norm': 5.297392845153809, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.011382144875824451, 'loss_2': 0.005397796630859375, 'loss_3': -16.07291030883789, 'loss_4': 0.43742692470550537, 'epoch': 5.56}
{'loss': 0.0461, 'grad_norm': 14.550657272338867, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.03720635920763016, 'loss_2': 0.00887298583984375, 'loss_3': -16.304439544677734, 'loss_4': 0.5102058053016663, 'epoch': 5.56}
{'loss': 0.0581, 'grad_norm': 21.734848022460938, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.05322584509849548, 'loss_2': 0.00485992431640625, 'loss_3': -15.822649002075195, 'loss_4': 0.04081898182630539, 'epoch': 5.57}
{'loss': 0.0309, 'grad_norm': 7.5701375007629395, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.03044130653142929, 'loss_2': 0.0004901885986328125, 'loss_3': -15.913066864013672, 'loss_4': 0.1257656067609787, 'epoch': 5.58}
{'loss': 0.0403, 'grad_norm': 9.484886169433594, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.03351571038365364, 'loss_2': 0.006744384765625, 'loss_3': -16.03607940673828, 'loss_4': 0.11400625109672546, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 12:44:52,068 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:52,068 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:11<1:13:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:44:59,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01583053171634674, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.249, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012807557359337807, 'eval_loss_2': 0.0030229762196540833, 'eval_loss_3': -18.2159423828125, 'eval_loss_4': 0.020139794796705246, 'epoch': 5.58}
{'loss': 0.0637, 'grad_norm': 23.787982940673828, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.06354938447475433, 'loss_2': 0.0001804828643798828, 'loss_3': -16.246583938598633, 'loss_4': 0.11493410170078278, 'epoch': 5.59}
{'loss': 0.0201, 'grad_norm': 8.837766647338867, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.016917994245886803, 'loss_2': 0.00322723388671875, 'loss_3': -16.111652374267578, 'loss_4': 0.3055238723754883, 'epoch': 5.59}
{'loss': 0.03, 'grad_norm': 10.116403579711914, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.02867928333580494, 'loss_2': 0.0013103485107421875, 'loss_3': -16.14392852783203, 'loss_4': 0.24815525114536285, 'epoch': 5.6}
{'loss': 0.0199, 'grad_norm': 6.113632678985596, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.018379341810941696, 'loss_2': 0.0015163421630859375, 'loss_3': -16.245750427246094, 'loss_4': -0.12095026671886444, 'epoch': 5.6}
{'loss': 0.0378, 'grad_norm': 8.885364532470703, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.029924241825938225, 'loss_2': 0.0078582763671875, 'loss_3': -16.267601013183594, 'loss_4': -0.14193375408649445, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 12:44:59,578 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:59,578 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:18<1:12:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:06,906 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01643374375998974, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.973, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012182741425931454, 'eval_loss_2': 0.004251003265380859, 'eval_loss_3': -18.242969512939453, 'eval_loss_4': -0.04999387264251709, 'epoch': 5.61}
{'loss': 0.0231, 'grad_norm': 6.901556015014648, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.0206752996891737, 'loss_2': 0.002410888671875, 'loss_3': -16.188899993896484, 'loss_4': 0.2559179365634918, 'epoch': 5.62}
{'loss': 0.036, 'grad_norm': 13.3886079788208, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.0338418073952198, 'loss_2': 0.00218963623046875, 'loss_3': -16.215431213378906, 'loss_4': 0.5723982453346252, 'epoch': 5.62}
{'loss': 0.0344, 'grad_norm': 9.700838088989258, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.03308364748954773, 'loss_2': 0.0013294219970703125, 'loss_3': -16.032785415649414, 'loss_4': 0.1706070601940155, 'epoch': 5.63}
{'loss': 0.0133, 'grad_norm': 4.992046356201172, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.00958852469921112, 'loss_2': 0.0037479400634765625, 'loss_3': -16.108043670654297, 'loss_4': 0.5743928551673889, 'epoch': 5.63}
{'loss': 0.0207, 'grad_norm': 7.220790386199951, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.017328841611742973, 'loss_2': 0.003360748291015625, 'loss_3': -15.967674255371094, 'loss_4': 0.027489088475704193, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 12:45:06,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:06,906 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:26<1:12:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:14,237 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014375311322510242, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.184, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.010808270424604416, 'eval_loss_2': 0.003567039966583252, 'eval_loss_3': -18.218551635742188, 'eval_loss_4': 0.14991013705730438, 'epoch': 5.64}
{'loss': 0.0432, 'grad_norm': 18.311779022216797, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.03717760741710663, 'loss_2': 0.0060272216796875, 'loss_3': -15.873933792114258, 'loss_4': 0.27894890308380127, 'epoch': 5.65}
{'loss': 0.027, 'grad_norm': 12.58839225769043, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.02324596792459488, 'loss_2': 0.003753662109375, 'loss_3': -15.872661590576172, 'loss_4': 0.30458441376686096, 'epoch': 5.65}
{'loss': 0.0253, 'grad_norm': 8.539154052734375, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.020291320979595184, 'loss_2': 0.0050201416015625, 'loss_3': -16.18878173828125, 'loss_4': 0.3546539545059204, 'epoch': 5.66}
{'loss': 0.0146, 'grad_norm': 5.167536735534668, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.012023349292576313, 'loss_2': 0.002620697021484375, 'loss_3': -15.984793663024902, 'loss_4': 0.13563653826713562, 'epoch': 5.66}
{'loss': 0.0367, 'grad_norm': 11.421102523803711, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.03254218026995659, 'loss_2': 0.00417327880859375, 'loss_3': -16.005319595336914, 'loss_4': 0.6291807889938354, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 12:45:14,237 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:14,237 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:30<1:12:17,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:45:18,027 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-975
[INFO|configuration_utils.py:420] 2025-01-21 12:45:18,029 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-975/config.json                                                                             
{'eval_loss': 0.013402296230196953, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.239, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.010540365241467953, 'eval_loss_2': 0.0028619319200515747, 'eval_loss_3': -18.215499877929688, 'eval_loss_4': 0.18852703273296356, 'epoch': 5.67}
[INFO|modeling_utils.py:2988] 2025-01-21 12:45:18,497 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-975/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:45:18,499 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-975/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:45:18,499 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-975/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:45:19,323 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-920] due to args.save_total_limit
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:34<1:19:05,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:45:22,954 >>
{'loss': 0.0389, 'grad_norm': 13.78389835357666, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.035073548555374146, 'loss_2': 0.003826141357421875, 'loss_3': -16.073312759399414, 'loss_4': 0.015720784664154053, 'epoch': 5.67}
{'loss': 0.0169, 'grad_norm': 6.799778461456299, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.01348482072353363, 'loss_2': 0.003444671630859375, 'loss_3': -16.13982391357422, 'loss_4': 0.16373546421527863, 'epoch': 5.68}
{'loss': 0.0493, 'grad_norm': 15.259439468383789, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.04334510862827301, 'loss_2': 0.0059967041015625, 'loss_3': -16.063575744628906, 'loss_4': 0.4270677864551544, 'epoch': 5.69}
{'loss': 0.0277, 'grad_norm': 8.287999153137207, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.0208134688436985, 'loss_2': 0.006927490234375, 'loss_3': -16.136009216308594, 'loss_4': 0.654181957244873, 'epoch': 5.69}
{'loss': 0.0344, 'grad_norm': 6.404348850250244, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.011908799409866333, 'loss_2': 0.0225067138671875, 'loss_3': -16.100605010986328, 'loss_4': -0.0904221385717392, 'epoch': 5.7}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:45:22,955 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:22,955 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:42<1:13:18,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:45:30,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026540018618106842, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.922, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01350853405892849, 'eval_loss_2': 0.013031482696533203, 'eval_loss_3': -18.16189193725586, 'eval_loss_4': 0.28460198640823364, 'epoch': 5.7}
{'loss': 0.0311, 'grad_norm': 7.273396968841553, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.016220806166529655, 'loss_2': 0.0148468017578125, 'loss_3': -16.14548683166504, 'loss_4': 0.18311572074890137, 'epoch': 5.7}
{'loss': 0.0332, 'grad_norm': 9.157965660095215, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.022527821362018585, 'loss_2': 0.010711669921875, 'loss_3': -16.05158805847168, 'loss_4': 0.3307958245277405, 'epoch': 5.71}
{'loss': 0.0277, 'grad_norm': 9.306900024414062, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.016847796738147736, 'loss_2': 0.01087188720703125, 'loss_3': -15.895756721496582, 'loss_4': 0.20488759875297546, 'epoch': 5.72}
{'loss': 0.0226, 'grad_norm': 5.046931266784668, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.011535710655152798, 'loss_2': 0.0110321044921875, 'loss_3': -16.12502670288086, 'loss_4': 0.416477233171463, 'epoch': 5.72}
{'loss': 0.1069, 'grad_norm': 20.082210540771484, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.09437303990125656, 'loss_2': 0.01256561279296875, 'loss_3': -15.743945121765137, 'loss_4': 0.752178966999054, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 12:45:30,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:30,289 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:49<1:12:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:37,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018593601882457733, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.997, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01531761884689331, 'eval_loss_2': 0.0032759830355644226, 'eval_loss_3': -18.148168563842773, 'eval_loss_4': 0.7742946743965149, 'epoch': 5.73}
{'loss': 0.019, 'grad_norm': 8.24545669555664, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.018756652250885963, 'loss_2': 0.00026988983154296875, 'loss_3': -15.986146926879883, 'loss_4': 1.1754884719848633, 'epoch': 5.73}
{'loss': 0.0351, 'grad_norm': 12.033644676208496, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.03139980509877205, 'loss_2': 0.003650665283203125, 'loss_3': -15.781950950622559, 'loss_4': 0.8589649200439453, 'epoch': 5.74}
{'loss': 0.0123, 'grad_norm': 5.304239749908447, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.009804229252040386, 'loss_2': 0.002536773681640625, 'loss_3': -15.815747261047363, 'loss_4': 0.8321740627288818, 'epoch': 5.74}
{'loss': 0.0571, 'grad_norm': 16.861331939697266, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.050917237997055054, 'loss_2': 0.006168365478515625, 'loss_3': -15.78363037109375, 'loss_4': 1.2590365409851074, 'epoch': 5.75}
{'loss': 0.024, 'grad_norm': 8.249696731567383, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.02388305962085724, 'loss_2': 8.285045623779297e-05, 'loss_3': -16.098796844482422, 'loss_4': 1.1248786449432373, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 12:45:37,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:37,616 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [24:56<1:11:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:44,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021672485396265984, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.474, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014459013007581234, 'eval_loss_2': 0.007213473320007324, 'eval_loss_3': -18.144760131835938, 'eval_loss_4': 1.2188196182250977, 'epoch': 5.76}
{'loss': 0.0482, 'grad_norm': 9.767047882080078, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.032535478472709656, 'loss_2': 0.0156707763671875, 'loss_3': -16.073585510253906, 'loss_4': 1.6373631954193115, 'epoch': 5.76}
{'loss': 0.0334, 'grad_norm': 10.909883499145508, 'learning_rate': 2.425e-05, 'loss_1': 0.026583803817629814, 'loss_2': 0.00676727294921875, 'loss_3': -16.01909637451172, 'loss_4': 1.588914394378662, 'epoch': 5.77}
{'loss': 0.0215, 'grad_norm': 6.161340713500977, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.016536403447389603, 'loss_2': 0.004917144775390625, 'loss_3': -15.920816421508789, 'loss_4': 1.1011707782745361, 'epoch': 5.77}
{'loss': 0.0476, 'grad_norm': 17.183185577392578, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.03420041501522064, 'loss_2': 0.01343536376953125, 'loss_3': -15.945302963256836, 'loss_4': 1.8569973707199097, 'epoch': 5.78}
{'loss': 0.0154, 'grad_norm': 5.673973083496094, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.011532960459589958, 'loss_2': 0.003841400146484375, 'loss_3': -16.02016830444336, 'loss_4': 1.76334547996521, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 12:45:44,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:44,946 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [25:04<1:11:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:52,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01783241704106331, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.796, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014342086389660835, 'eval_loss_2': 0.0034903287887573242, 'eval_loss_3': -18.164188385009766, 'eval_loss_4': 1.4537523984909058, 'epoch': 5.78}
{'loss': 0.048, 'grad_norm': 13.768912315368652, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.04496762529015541, 'loss_2': 0.003040313720703125, 'loss_3': -16.124515533447266, 'loss_4': 1.7891775369644165, 'epoch': 5.79}
{'loss': 0.0334, 'grad_norm': 10.084010124206543, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.024533221498131752, 'loss_2': 0.00885009765625, 'loss_3': -15.897010803222656, 'loss_4': 1.5873489379882812, 'epoch': 5.8}
{'loss': 0.033, 'grad_norm': 9.200899124145508, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.02962644025683403, 'loss_2': 0.00336456298828125, 'loss_3': -15.81421947479248, 'loss_4': 2.072885036468506, 'epoch': 5.8}
{'loss': 0.0422, 'grad_norm': 12.458742141723633, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.03322437033057213, 'loss_2': 0.0089569091796875, 'loss_3': -16.044706344604492, 'loss_4': 1.1182448863983154, 'epoch': 5.81}
{'loss': 0.0405, 'grad_norm': 11.691740989685059, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.030954061076045036, 'loss_2': 0.009521484375, 'loss_3': -15.891576766967773, 'loss_4': 1.3990607261657715, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 12:45:52,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:52,290 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:11<1:11:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:59,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02481057494878769, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.991, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014750861562788486, 'eval_loss_2': 0.010059714317321777, 'eval_loss_3': -18.1492919921875, 'eval_loss_4': 1.1089587211608887, 'epoch': 5.81}
{'loss': 0.0591, 'grad_norm': 12.586292266845703, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.05017399415373802, 'loss_2': 0.0088958740234375, 'loss_3': -16.178974151611328, 'loss_4': 1.52601957321167, 'epoch': 5.82}
{'loss': 0.0683, 'grad_norm': 15.414756774902344, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.05950498208403587, 'loss_2': 0.0087738037109375, 'loss_3': -15.966419219970703, 'loss_4': 1.7664002180099487, 'epoch': 5.83}
{'loss': 0.0455, 'grad_norm': 11.519775390625, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.0344972126185894, 'loss_2': 0.011016845703125, 'loss_3': -15.981147766113281, 'loss_4': 0.8259937763214111, 'epoch': 5.83}
{'loss': 0.0325, 'grad_norm': 6.992710590362549, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.022743098437786102, 'loss_2': 0.0097198486328125, 'loss_3': -16.134262084960938, 'loss_4': 1.2732661962509155, 'epoch': 5.84}
{'loss': 0.0372, 'grad_norm': 15.908819198608398, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.036425426602363586, 'loss_2': 0.0007724761962890625, 'loss_3': -16.111352920532227, 'loss_4': 1.1127028465270996, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 12:45:59,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:59,628 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:18<1:11:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:06,953 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017672549933195114, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.077, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013749885372817516, 'eval_loss_2': 0.003922663629055023, 'eval_loss_3': -18.127952575683594, 'eval_loss_4': 0.8449080586433411, 'epoch': 5.84}
{'loss': 0.0411, 'grad_norm': 22.103477478027344, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.03989184647798538, 'loss_2': 0.001255035400390625, 'loss_3': -16.057147979736328, 'loss_4': 0.7314690351486206, 'epoch': 5.85}
{'loss': 0.0416, 'grad_norm': 13.655892372131348, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.04082737863063812, 'loss_2': 0.0007600784301757812, 'loss_3': -15.827020645141602, 'loss_4': 0.6938186883926392, 'epoch': 5.85}
{'loss': 0.0398, 'grad_norm': 10.759705543518066, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.03831527382135391, 'loss_2': 0.0015077590942382812, 'loss_3': -15.95291519165039, 'loss_4': 0.7330820560455322, 'epoch': 5.86}
{'loss': 0.0258, 'grad_norm': 8.758349418640137, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.021971913054585457, 'loss_2': 0.003818511962890625, 'loss_3': -16.197656631469727, 'loss_4': 1.0205180644989014, 'epoch': 5.87}
{'loss': 0.0465, 'grad_norm': 11.755402565002441, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.04436129704117775, 'loss_2': 0.002170562744140625, 'loss_3': -15.95530891418457, 'loss_4': 0.6901031732559204, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 12:46:06,953 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:06,953 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:26<1:11:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:14,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014278026297688484, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.727, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010785432532429695, 'eval_loss_2': 0.003492593765258789, 'eval_loss_3': -18.155963897705078, 'eval_loss_4': 0.4108060300350189, 'epoch': 5.87}
{'loss': 0.0286, 'grad_norm': 8.553502082824707, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.02274848148226738, 'loss_2': 0.005825042724609375, 'loss_3': -16.091957092285156, 'loss_4': 0.4071175456047058, 'epoch': 5.88}
{'loss': 0.0444, 'grad_norm': 9.457436561584473, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.033707648515701294, 'loss_2': 0.0107421875, 'loss_3': -15.835854530334473, 'loss_4': 0.3501929044723511, 'epoch': 5.88}
{'loss': 0.015, 'grad_norm': 5.266751766204834, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.012348031625151634, 'loss_2': 0.00267791748046875, 'loss_3': -15.991128921508789, 'loss_4': 0.5627469420433044, 'epoch': 5.89}
{'loss': 0.0268, 'grad_norm': 7.391329288482666, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.02276969887316227, 'loss_2': 0.0039825439453125, 'loss_3': -16.090702056884766, 'loss_4': 0.6129599809646606, 'epoch': 5.9}
{'loss': 0.0389, 'grad_norm': 10.880284309387207, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.03498147800564766, 'loss_2': 0.003936767578125, 'loss_3': -16.009380340576172, 'loss_4': 0.2687123715877533, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 12:46:14,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:14,299 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:33<1:11:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:21,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016691509634256363, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012781785801053047, 'eval_loss_2': 0.0039097219705581665, 'eval_loss_3': -18.16975212097168, 'eval_loss_4': 0.26599574089050293, 'epoch': 5.9}
{'loss': 0.0219, 'grad_norm': 6.4030537605285645, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.02029852569103241, 'loss_2': 0.001575469970703125, 'loss_3': -16.11750602722168, 'loss_4': 0.09019076824188232, 'epoch': 5.91}
{'loss': 0.1124, 'grad_norm': 33.59245681762695, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.1112309992313385, 'loss_2': 0.001148223876953125, 'loss_3': -15.864240646362305, 'loss_4': 0.5187941789627075, 'epoch': 5.91}
{'loss': 0.0252, 'grad_norm': 9.545059204101562, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.02158132754266262, 'loss_2': 0.003597259521484375, 'loss_3': -16.075210571289062, 'loss_4': 0.25854164361953735, 'epoch': 5.92}
{'loss': 0.0549, 'grad_norm': 16.250625610351562, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.04831220582127571, 'loss_2': 0.00656890869140625, 'loss_3': -16.299217224121094, 'loss_4': 0.3316763937473297, 'epoch': 5.92}
{'loss': 0.0567, 'grad_norm': 21.972490310668945, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.054716285318136215, 'loss_2': 0.002033233642578125, 'loss_3': -16.10595703125, 'loss_4': 1.195906162261963, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 12:46:21,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:21,646 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:40<1:11:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:28,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01735050044953823, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.123, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012103280052542686, 'eval_loss_2': 0.005247220396995544, 'eval_loss_3': -18.217666625976562, 'eval_loss_4': 0.5019081830978394, 'epoch': 5.93}
{'loss': 0.0664, 'grad_norm': 22.047550201416016, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.058800335973501205, 'loss_2': 0.007579803466796875, 'loss_3': -16.175132751464844, 'loss_4': 1.0050828456878662, 'epoch': 5.94}
{'loss': 0.0324, 'grad_norm': 7.701478004455566, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.024405157193541527, 'loss_2': 0.0079498291015625, 'loss_3': -16.204683303833008, 'loss_4': 1.122340202331543, 'epoch': 5.94}
{'loss': 0.0841, 'grad_norm': 30.060964584350586, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.08137483894824982, 'loss_2': 0.00272369384765625, 'loss_3': -16.006837844848633, 'loss_4': 0.6948933601379395, 'epoch': 5.95}
{'loss': 0.0151, 'grad_norm': 5.916106700897217, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.014798062853515148, 'loss_2': 0.0002608299255371094, 'loss_3': -15.942702293395996, 'loss_4': 1.2753790616989136, 'epoch': 5.95}
{'loss': 0.0272, 'grad_norm': 9.499994277954102, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.01910986751317978, 'loss_2': 0.008087158203125, 'loss_3': -16.102222442626953, 'loss_4': 1.1313718557357788, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 12:46:28,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:28,981 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:48<1:11:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:36,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016263358294963837, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.924, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01223837397992611, 'eval_loss_2': 0.004024982452392578, 'eval_loss_3': -18.216869354248047, 'eval_loss_4': 0.6391189098358154, 'epoch': 5.96}
{'loss': 0.0332, 'grad_norm': 14.583959579467773, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.029896818101406097, 'loss_2': 0.003261566162109375, 'loss_3': -16.132709503173828, 'loss_4': 1.1092989444732666, 'epoch': 5.97}
{'loss': 0.0374, 'grad_norm': 13.128447532653809, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.03269970417022705, 'loss_2': 0.00472259521484375, 'loss_3': -16.09889793395996, 'loss_4': 0.6687562465667725, 'epoch': 5.97}
{'loss': 0.0292, 'grad_norm': 7.372607231140137, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.01976805180311203, 'loss_2': 0.009429931640625, 'loss_3': -16.158491134643555, 'loss_4': 1.3054598569869995, 'epoch': 5.98}
{'loss': 0.0203, 'grad_norm': 10.770161628723145, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.020316729322075844, 'loss_2': 3.0100345611572266e-05, 'loss_3': -16.05782699584961, 'loss_4': 0.6818766593933105, 'epoch': 5.98}
{'loss': 0.0114, 'grad_norm': 5.099874973297119, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.008990348316729069, 'loss_2': 0.00238800048828125, 'loss_3': -16.01224136352539, 'loss_4': 0.8357178568840027, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 12:46:36,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:36,322 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:55<1:09:16,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 12:46:43,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014363451860845089, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01049165427684784, 'eval_loss_2': 0.0038717985153198242, 'eval_loss_3': -18.180200576782227, 'eval_loss_4': 0.6490025520324707, 'epoch': 5.99}
{'loss': 0.0179, 'grad_norm': 6.5053558349609375, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.014767052605748177, 'loss_2': 0.00313568115234375, 'loss_3': -16.106670379638672, 'loss_4': 0.8926262855529785, 'epoch': 5.99}
{'loss': 0.0136, 'grad_norm': 8.222603797912598, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.010899164713919163, 'loss_2': 0.00272369384765625, 'loss_3': -15.890203475952148, 'loss_4': 0.9513775110244751, 'epoch': 6.0}
{'loss': 0.0166, 'grad_norm': 6.025119304656982, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.015270291827619076, 'loss_2': 0.0013246536254882812, 'loss_3': -15.980269432067871, 'loss_4': 1.1670165061950684, 'epoch': 6.01}
{'loss': 0.0466, 'grad_norm': 14.848442077636719, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.03362145274877548, 'loss_2': 0.0129852294921875, 'loss_3': -16.109970092773438, 'loss_4': 1.618313193321228, 'epoch': 6.01}
{'loss': 0.0282, 'grad_norm': 8.368834495544434, 'learning_rate': 2.4e-05, 'loss_1': 0.023753127083182335, 'loss_2': 0.004451751708984375, 'loss_3': -16.06659507751465, 'loss_4': 1.2752166986465454, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 12:46:43,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:43,349 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [25:59<1:09:16,  1.01s/it][INFO|trainer.py:3910] 2025-01-21 12:46:47,148 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1035
[INFO|configuration_utils.py:420] 2025-01-21 12:46:47,149 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1035/config.json                                                                            
{'eval_loss': 0.013301357626914978, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010206952691078186, 'eval_loss_2': 0.003094404935836792, 'eval_loss_3': -18.15082550048828, 'eval_loss_4': 0.8670065999031067, 'epoch': 6.02}
[INFO|modeling_utils.py:2988] 2025-01-21 12:46:47,640 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1035/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:46:47,642 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1035/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:46:47,642 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1035/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:46:48,485 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-975] due to args.save_total_limit
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:04<1:17:54,  1.13s/it][INFO|trainer.py:4226] 2025-01-21 12:46:52,117 >>
{'loss': 0.0395, 'grad_norm': 12.573542594909668, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.03824053332209587, 'loss_2': 0.0012159347534179688, 'loss_3': -15.940929412841797, 'loss_4': 0.9731919765472412, 'epoch': 6.02}
{'loss': 0.0218, 'grad_norm': 5.526182174682617, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.013292817398905754, 'loss_2': 0.0084686279296875, 'loss_3': -15.978867530822754, 'loss_4': 1.043471336364746, 'epoch': 6.03}
{'loss': 0.0201, 'grad_norm': 10.838738441467285, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.01994478330016136, 'loss_2': 0.0001983642578125, 'loss_3': -16.028404235839844, 'loss_4': 1.2033536434173584, 'epoch': 6.03}
{'loss': 0.0317, 'grad_norm': 12.196988105773926, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.02800801396369934, 'loss_2': 0.0037326812744140625, 'loss_3': -16.092327117919922, 'loss_4': 0.9951039552688599, 'epoch': 6.04}
{'loss': 0.0196, 'grad_norm': 7.0090460777282715, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.014777770265936852, 'loss_2': 0.004856109619140625, 'loss_3': -16.03166961669922, 'loss_4': 0.8788595795631409, 'epoch': 6.05}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:46:52,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:52,118 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:11<1:12:12,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:46:59,451 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014367079362273216, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.803, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010273434221744537, 'eval_loss_2': 0.004093647003173828, 'eval_loss_3': -18.126705169677734, 'eval_loss_4': 0.9766531586647034, 'epoch': 6.05}
{'loss': 0.0326, 'grad_norm': 11.965474128723145, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.03071143850684166, 'loss_2': 0.0019168853759765625, 'loss_3': -15.711385726928711, 'loss_4': 0.8072805404663086, 'epoch': 6.05}
{'loss': 0.0371, 'grad_norm': 8.815472602844238, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.02779778651893139, 'loss_2': 0.009307861328125, 'loss_3': -16.066192626953125, 'loss_4': 1.5301510095596313, 'epoch': 6.06}
{'loss': 0.0246, 'grad_norm': 7.675900936126709, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.01964711956679821, 'loss_2': 0.0049591064453125, 'loss_3': -15.897419929504395, 'loss_4': 1.299743890762329, 'epoch': 6.06}
{'loss': 0.0276, 'grad_norm': 8.705998420715332, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.021587349474430084, 'loss_2': 0.006008148193359375, 'loss_3': -15.844039916992188, 'loss_4': 1.185338020324707, 'epoch': 6.07}
{'loss': 0.044, 'grad_norm': 16.727458953857422, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.04054640606045723, 'loss_2': 0.00344085693359375, 'loss_3': -16.009119033813477, 'loss_4': 1.5032873153686523, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 12:46:59,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:59,451 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:18<1:11:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:06,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015462545678019524, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.382, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012164710089564323, 'eval_loss_2': 0.0032978355884552, 'eval_loss_3': -18.109390258789062, 'eval_loss_4': 1.187730312347412, 'epoch': 6.08}
{'loss': 0.024, 'grad_norm': 8.338371276855469, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.017959963530302048, 'loss_2': 0.0060882568359375, 'loss_3': -15.782028198242188, 'loss_4': 1.338771104812622, 'epoch': 6.08}
{'loss': 0.0337, 'grad_norm': 10.02169418334961, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.03306426480412483, 'loss_2': 0.0006747245788574219, 'loss_3': -15.821166038513184, 'loss_4': 1.4920650720596313, 'epoch': 6.09}
{'loss': 0.0205, 'grad_norm': 6.592616081237793, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.016655398532748222, 'loss_2': 0.003803253173828125, 'loss_3': -15.967878341674805, 'loss_4': 1.2897802591323853, 'epoch': 6.09}
{'loss': 0.0157, 'grad_norm': 5.550630569458008, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.011846094392240047, 'loss_2': 0.003902435302734375, 'loss_3': -16.03696060180664, 'loss_4': 1.4041192531585693, 'epoch': 6.1}
{'loss': 0.0458, 'grad_norm': 25.34353256225586, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.04390017315745354, 'loss_2': 0.0018672943115234375, 'loss_3': -15.698262214660645, 'loss_4': 1.2083077430725098, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 12:47:06,781 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:06,781 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:26<1:10:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:14,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017858723178505898, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.453, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013692210428416729, 'eval_loss_2': 0.004166513681411743, 'eval_loss_3': -18.10052490234375, 'eval_loss_4': 0.9841980338096619, 'epoch': 6.1}
{'loss': 0.0207, 'grad_norm': 8.722984313964844, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.019840320572257042, 'loss_2': 0.000881195068359375, 'loss_3': -15.94127082824707, 'loss_4': 1.070412039756775, 'epoch': 6.11}
{'loss': 0.0212, 'grad_norm': 7.000729560852051, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.019550753757357597, 'loss_2': 0.0016698837280273438, 'loss_3': -15.892244338989258, 'loss_4': 0.9924131631851196, 'epoch': 6.12}
{'loss': 0.0138, 'grad_norm': 5.053258895874023, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.01019423920661211, 'loss_2': 0.003631591796875, 'loss_3': -15.98695182800293, 'loss_4': 1.0447850227355957, 'epoch': 6.12}
{'loss': 0.0322, 'grad_norm': 9.16522216796875, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.029776085168123245, 'loss_2': 0.0023956298828125, 'loss_3': -16.073171615600586, 'loss_4': 1.0105304718017578, 'epoch': 6.13}
{'loss': 0.0388, 'grad_norm': 13.066801071166992, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.03678128495812416, 'loss_2': 0.0020275115966796875, 'loss_3': -16.24297523498535, 'loss_4': 0.7814364433288574, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 12:47:14,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:14,108 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:33<1:10:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:21,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018807219341397285, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.235, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01425196509808302, 'eval_loss_2': 0.004555255174636841, 'eval_loss_3': -18.069448471069336, 'eval_loss_4': 0.5217351913452148, 'epoch': 6.13}
{'loss': 0.0184, 'grad_norm': 6.967006683349609, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.015890080481767654, 'loss_2': 0.0025157928466796875, 'loss_3': -16.132665634155273, 'loss_4': 0.6112185716629028, 'epoch': 6.14}
{'loss': 0.0206, 'grad_norm': 7.112756252288818, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.015454298816621304, 'loss_2': 0.00513458251953125, 'loss_3': -16.02912139892578, 'loss_4': 0.6107489466667175, 'epoch': 6.15}
{'loss': 0.0164, 'grad_norm': 5.439604759216309, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.013715690933167934, 'loss_2': 0.00267791748046875, 'loss_3': -16.356998443603516, 'loss_4': 0.48682302236557007, 'epoch': 6.15}
{'loss': 0.0188, 'grad_norm': 5.760439872741699, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.012584996409714222, 'loss_2': 0.00623321533203125, 'loss_3': -16.169403076171875, 'loss_4': 0.9331362843513489, 'epoch': 6.16}
{'loss': 0.0276, 'grad_norm': 7.566633224487305, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.01791481487452984, 'loss_2': 0.0097198486328125, 'loss_3': -16.07255744934082, 'loss_4': 0.5838466882705688, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 12:47:21,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:21,443 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:40<1:10:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:28,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02029142715036869, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01691049337387085, 'eval_loss_2': 0.0033809319138526917, 'eval_loss_3': -18.0433406829834, 'eval_loss_4': 0.4149506986141205, 'epoch': 6.16}
{'loss': 0.0286, 'grad_norm': 10.345881462097168, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.02785160019993782, 'loss_2': 0.0007801055908203125, 'loss_3': -15.963367462158203, 'loss_4': 0.7042679190635681, 'epoch': 6.17}
{'loss': 0.0256, 'grad_norm': 7.213104724884033, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.020654387772083282, 'loss_2': 0.0048980712890625, 'loss_3': -15.744691848754883, 'loss_4': 0.48813435435295105, 'epoch': 6.17}
{'loss': 0.0563, 'grad_norm': 16.709699630737305, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.055819008499383926, 'loss_2': 0.0005159378051757812, 'loss_3': -15.950319290161133, 'loss_4': 0.5432493686676025, 'epoch': 6.18}
{'loss': 0.031, 'grad_norm': 10.98641300201416, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.026677127927541733, 'loss_2': 0.004364013671875, 'loss_3': -15.91075325012207, 'loss_4': 0.8609033226966858, 'epoch': 6.19}
{'loss': 0.0139, 'grad_norm': 5.815732955932617, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.011021425947546959, 'loss_2': 0.002925872802734375, 'loss_3': -16.046287536621094, 'loss_4': 0.7127021551132202, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 12:47:28,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:28,775 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:48<1:10:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:36,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025381293147802353, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.79, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021525589749217033, 'eval_loss_2': 0.0038557052612304688, 'eval_loss_3': -18.00600242614746, 'eval_loss_4': 0.49845564365386963, 'epoch': 6.19}
{'loss': 0.0357, 'grad_norm': 9.871770858764648, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.030531061813235283, 'loss_2': 0.0051727294921875, 'loss_3': -15.823404312133789, 'loss_4': 0.449907511472702, 'epoch': 6.2}
{'loss': 0.019, 'grad_norm': 7.532203674316406, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.01759270578622818, 'loss_2': 0.0014324188232421875, 'loss_3': -16.10740852355957, 'loss_4': 0.7032967805862427, 'epoch': 6.2}
{'loss': 0.02, 'grad_norm': 7.199798107147217, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.018308080732822418, 'loss_2': 0.0016918182373046875, 'loss_3': -16.00202751159668, 'loss_4': 0.7957991361618042, 'epoch': 6.21}
{'loss': 0.0126, 'grad_norm': 5.107536792755127, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.009241682477295399, 'loss_2': 0.003330230712890625, 'loss_3': -16.034692764282227, 'loss_4': 0.5807231068611145, 'epoch': 6.22}
{'loss': 0.0179, 'grad_norm': 6.076246738433838, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.010709445923566818, 'loss_2': 0.007232666015625, 'loss_3': -16.246826171875, 'loss_4': 0.5622677803039551, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 12:47:36,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:36,118 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:55<1:10:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:43,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028911197558045387, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.179, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.024935834109783173, 'eval_loss_2': 0.003975361585617065, 'eval_loss_3': -18.00215721130371, 'eval_loss_4': 0.7874127626419067, 'epoch': 6.22}
{'loss': 0.0183, 'grad_norm': 5.9954304695129395, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.014002712443470955, 'loss_2': 0.004253387451171875, 'loss_3': -15.913562774658203, 'loss_4': 0.650173544883728, 'epoch': 6.23}
{'loss': 0.0229, 'grad_norm': 10.666626930236816, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.019905006512999535, 'loss_2': 0.003017425537109375, 'loss_3': -16.139606475830078, 'loss_4': 1.0514113903045654, 'epoch': 6.23}
{'loss': 0.051, 'grad_norm': 24.024206161499023, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.047698013484478, 'loss_2': 0.003292083740234375, 'loss_3': -15.880744934082031, 'loss_4': 0.8852521181106567, 'epoch': 6.24}
{'loss': 0.0372, 'grad_norm': 10.274770736694336, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.033451858907938004, 'loss_2': 0.0037975311279296875, 'loss_3': -15.96945571899414, 'loss_4': 0.765103816986084, 'epoch': 6.24}
{'loss': 0.0423, 'grad_norm': 13.071045875549316, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.03683437779545784, 'loss_2': 0.00548553466796875, 'loss_3': -16.168216705322266, 'loss_4': 1.0101901292800903, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 12:47:43,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:43,450 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [27:02<1:10:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:50,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04659078270196915, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.517, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.04008964076638222, 'eval_loss_2': 0.006501138210296631, 'eval_loss_3': -17.945072174072266, 'eval_loss_4': 0.9917068481445312, 'epoch': 6.25}
{'loss': 0.0518, 'grad_norm': 14.843884468078613, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.03695415332913399, 'loss_2': 0.014892578125, 'loss_3': -16.155330657958984, 'loss_4': 0.9557851552963257, 'epoch': 6.26}
{'loss': 0.0437, 'grad_norm': 11.167675971984863, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.034365106374025345, 'loss_2': 0.0093536376953125, 'loss_3': -15.866283416748047, 'loss_4': 1.0182185173034668, 'epoch': 6.26}
{'loss': 0.0333, 'grad_norm': 8.437612533569336, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.03233593702316284, 'loss_2': 0.0009655952453613281, 'loss_3': -16.008224487304688, 'loss_4': 1.2044310569763184, 'epoch': 6.27}
{'loss': 0.0558, 'grad_norm': 15.857633590698242, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.05478974059224129, 'loss_2': 0.0010280609130859375, 'loss_3': -16.212121963500977, 'loss_4': 1.450183391571045, 'epoch': 6.27}
{'loss': 0.0843, 'grad_norm': 14.821090698242188, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.08012856543064117, 'loss_2': 0.00418853759765625, 'loss_3': -15.954143524169922, 'loss_4': 0.8386363983154297, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 12:47:50,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:50,788 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:10<1:10:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:58,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06515660881996155, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.179, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.06178378313779831, 'eval_loss_2': 0.00337282195687294, 'eval_loss_3': -17.89143943786621, 'eval_loss_4': 1.009039044380188, 'epoch': 6.28}
{'loss': 0.0275, 'grad_norm': 7.222136497497559, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.023722687736153603, 'loss_2': 0.00379180908203125, 'loss_3': -16.35434341430664, 'loss_4': 1.1643130779266357, 'epoch': 6.28}
{'loss': 0.03, 'grad_norm': 16.673463821411133, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.028421781957149506, 'loss_2': 0.0016040802001953125, 'loss_3': -16.25823211669922, 'loss_4': 0.8966478705406189, 'epoch': 6.29}
{'loss': 0.0328, 'grad_norm': 8.942010879516602, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.024106116965413094, 'loss_2': 0.0086822509765625, 'loss_3': -15.9588623046875, 'loss_4': 0.9562748670578003, 'epoch': 6.3}
{'loss': 0.0397, 'grad_norm': 18.651058197021484, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.03879816457629204, 'loss_2': 0.000926971435546875, 'loss_3': -15.861791610717773, 'loss_4': 0.5946468114852905, 'epoch': 6.3}
{'loss': 0.0661, 'grad_norm': 15.671431541442871, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.049900542944669724, 'loss_2': 0.0162353515625, 'loss_3': -16.058055877685547, 'loss_4': 1.0298951864242554, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 12:47:58,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:58,118 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:17<1:10:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:05,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027619335800409317, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.395, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017577383667230606, 'eval_loss_2': 0.010041952133178711, 'eval_loss_3': -18.064245223999023, 'eval_loss_4': 0.8032630085945129, 'epoch': 6.31}
{'loss': 0.1094, 'grad_norm': 28.199199676513672, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.09907210618257523, 'loss_2': 0.010345458984375, 'loss_3': -16.113786697387695, 'loss_4': 1.175896167755127, 'epoch': 6.31}
{'loss': 0.0512, 'grad_norm': 19.35285758972168, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.042164020240306854, 'loss_2': 0.0090484619140625, 'loss_3': -15.967357635498047, 'loss_4': 1.5885056257247925, 'epoch': 6.32}
{'loss': 0.0266, 'grad_norm': 7.469784259796143, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.015431669540703297, 'loss_2': 0.0111236572265625, 'loss_3': -15.877323150634766, 'loss_4': 1.0871803760528564, 'epoch': 6.33}
{'loss': 0.0293, 'grad_norm': 9.232076644897461, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.02030174247920513, 'loss_2': 0.0090179443359375, 'loss_3': -15.964557647705078, 'loss_4': 0.9830179214477539, 'epoch': 6.33}
{'loss': 0.0372, 'grad_norm': 11.792001724243164, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.02735409140586853, 'loss_2': 0.00989532470703125, 'loss_3': -16.06523323059082, 'loss_4': 1.312964916229248, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 12:48:05,443 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:05,443 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:24<1:10:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:12,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01715194620192051, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.971, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012195693328976631, 'eval_loss_2': 0.004956252872943878, 'eval_loss_3': -18.167415618896484, 'eval_loss_4': 0.9043518900871277, 'epoch': 6.34}
{'loss': 0.0113, 'grad_norm': 5.453761100769043, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.010669196024537086, 'loss_2': 0.0006475448608398438, 'loss_3': -16.25467300415039, 'loss_4': 0.7031289935112, 'epoch': 6.34}
{'loss': 0.0101, 'grad_norm': 5.021057605743408, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.008916017599403858, 'loss_2': 0.001163482666015625, 'loss_3': -16.268911361694336, 'loss_4': 1.2847447395324707, 'epoch': 6.35}
{'loss': 0.0183, 'grad_norm': 6.481908798217773, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.01546869333833456, 'loss_2': 0.002788543701171875, 'loss_3': -16.047077178955078, 'loss_4': 1.1766016483306885, 'epoch': 6.35}
{'loss': 0.0232, 'grad_norm': 7.81033182144165, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.018527021631598473, 'loss_2': 0.00470733642578125, 'loss_3': -15.899261474609375, 'loss_4': 1.3797690868377686, 'epoch': 6.36}
{'loss': 0.0628, 'grad_norm': 30.739511489868164, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.06259050965309143, 'loss_2': 0.0001819133758544922, 'loss_3': -16.010669708251953, 'loss_4': 0.978792130947113, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 12:48:12,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:12,775 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:32<1:10:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:20,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01877521723508835, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.202, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012454412877559662, 'eval_loss_2': 0.0063208043575286865, 'eval_loss_3': -18.21673011779785, 'eval_loss_4': 1.1309192180633545, 'epoch': 6.37}
{'loss': 0.0851, 'grad_norm': 18.70313262939453, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.08356011658906937, 'loss_2': 0.001556396484375, 'loss_3': -16.048460006713867, 'loss_4': 1.312692403793335, 'epoch': 6.37}
{'loss': 0.0244, 'grad_norm': 13.012890815734863, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.018847526982426643, 'loss_2': 0.0055389404296875, 'loss_3': -16.06716537475586, 'loss_4': 0.9565036296844482, 'epoch': 6.38}
{'loss': 0.0286, 'grad_norm': 9.33754825592041, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.02136159874498844, 'loss_2': 0.00728607177734375, 'loss_3': -16.055959701538086, 'loss_4': 1.1925575733184814, 'epoch': 6.38}
{'loss': 0.0317, 'grad_norm': 6.337175369262695, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.02210063673555851, 'loss_2': 0.0096435546875, 'loss_3': -16.222322463989258, 'loss_4': 0.5969083905220032, 'epoch': 6.39}
{'loss': 0.0324, 'grad_norm': 10.416481018066406, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.026769233867526054, 'loss_2': 0.00562286376953125, 'loss_3': -16.18172836303711, 'loss_4': 0.9342583417892456, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 12:48:20,128 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:20,128 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:39<1:10:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:27,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022405192255973816, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.155, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013338996097445488, 'eval_loss_2': 0.009066194295883179, 'eval_loss_3': -18.212432861328125, 'eval_loss_4': 1.1855275630950928, 'epoch': 6.4}
{'loss': 0.0304, 'grad_norm': 5.772581100463867, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.01380094699561596, 'loss_2': 0.016632080078125, 'loss_3': -16.21563720703125, 'loss_4': 1.5309244394302368, 'epoch': 6.4}
{'loss': 0.0663, 'grad_norm': 22.89297866821289, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.05980489030480385, 'loss_2': 0.00650787353515625, 'loss_3': -16.31443214416504, 'loss_4': 1.362939715385437, 'epoch': 6.41}
{'loss': 0.0566, 'grad_norm': 13.338357925415039, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.03994100168347359, 'loss_2': 0.0166168212890625, 'loss_3': -16.118404388427734, 'loss_4': 1.3029956817626953, 'epoch': 6.41}
{'loss': 0.018, 'grad_norm': 6.566906929016113, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.015675842761993408, 'loss_2': 0.0023345947265625, 'loss_3': -16.290002822875977, 'loss_4': 1.7766743898391724, 'epoch': 6.42}
{'loss': 0.0642, 'grad_norm': 19.091228485107422, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.061207111924886703, 'loss_2': 0.0030364990234375, 'loss_3': -16.294105529785156, 'loss_4': 1.7317063808441162, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 12:48:27,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:27,468 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:46<1:10:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:34,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018026916310191154, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.132, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012933699414134026, 'eval_loss_2': 0.005093216896057129, 'eval_loss_3': -18.250045776367188, 'eval_loss_4': 1.2527354955673218, 'epoch': 6.42}
{'loss': 0.0364, 'grad_norm': 6.3816447257995605, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.021793747320771217, 'loss_2': 0.01462554931640625, 'loss_3': -16.118497848510742, 'loss_4': 1.5628161430358887, 'epoch': 6.43}
{'loss': 0.0177, 'grad_norm': 5.872552394866943, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.015789099037647247, 'loss_2': 0.0018939971923828125, 'loss_3': -16.193424224853516, 'loss_4': 1.3224235773086548, 'epoch': 6.44}
{'loss': 0.0311, 'grad_norm': 9.61988353729248, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.02260352484881878, 'loss_2': 0.008514404296875, 'loss_3': -16.314865112304688, 'loss_4': 0.9746030569076538, 'epoch': 6.44}
{'loss': 0.0267, 'grad_norm': 5.516681671142578, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.015458697453141212, 'loss_2': 0.0112152099609375, 'loss_3': -16.38232421875, 'loss_4': 1.0864908695220947, 'epoch': 6.45}
{'loss': 0.0319, 'grad_norm': 9.714171409606934, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.025454362854361534, 'loss_2': 0.00640106201171875, 'loss_3': -16.460960388183594, 'loss_4': 1.7043447494506836, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 12:48:34,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:34,807 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:54<1:09:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:42,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024304376915097237, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013579116202890873, 'eval_loss_2': 0.010725259780883789, 'eval_loss_3': -18.238628387451172, 'eval_loss_4': 1.0485858917236328, 'epoch': 6.45}
{'loss': 0.04, 'grad_norm': 15.080129623413086, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.03361482918262482, 'loss_2': 0.006412506103515625, 'loss_3': -16.46645164489746, 'loss_4': 1.218390941619873, 'epoch': 6.46}
{'loss': 0.0327, 'grad_norm': 7.271989822387695, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.017524782568216324, 'loss_2': 0.0151519775390625, 'loss_3': -16.23944854736328, 'loss_4': 1.0693706274032593, 'epoch': 6.47}
{'loss': 0.0228, 'grad_norm': 9.15587043762207, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.020827187225222588, 'loss_2': 0.002017974853515625, 'loss_3': -16.075374603271484, 'loss_4': 1.2649248838424683, 'epoch': 6.47}
{'loss': 0.0298, 'grad_norm': 8.779319763183594, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.02406422421336174, 'loss_2': 0.00576019287109375, 'loss_3': -16.370546340942383, 'loss_4': 1.4761137962341309, 'epoch': 6.48}
{'loss': 0.0413, 'grad_norm': 14.9171724319458, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.03797207400202751, 'loss_2': 0.00336456298828125, 'loss_3': -16.329566955566406, 'loss_4': 0.8826064467430115, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 12:48:42,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:42,141 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [28:01<1:09:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:49,473 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020092345774173737, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.301, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.015255187638103962, 'eval_loss_2': 0.004837155342102051, 'eval_loss_3': -18.209033966064453, 'eval_loss_4': 0.8112393617630005, 'epoch': 6.48}
{'loss': 0.0165, 'grad_norm': 5.660311698913574, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.01484487485140562, 'loss_2': 0.0016384124755859375, 'loss_3': -16.28208351135254, 'loss_4': 0.8570090532302856, 'epoch': 6.49}
{'loss': 0.0439, 'grad_norm': 11.250398635864258, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.03657463565468788, 'loss_2': 0.007343292236328125, 'loss_3': -16.30139923095703, 'loss_4': 1.021119475364685, 'epoch': 6.49}
{'loss': 0.0235, 'grad_norm': 13.075654983520508, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.02345503866672516, 'loss_2': 9.417533874511719e-05, 'loss_3': -16.26493263244629, 'loss_4': 1.13200044631958, 'epoch': 6.5}
{'loss': 0.0178, 'grad_norm': 5.496883392333984, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.013425519689917564, 'loss_2': 0.0043792724609375, 'loss_3': -16.298694610595703, 'loss_4': 0.9650114178657532, 'epoch': 6.51}
{'loss': 0.0763, 'grad_norm': 21.924379348754883, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.07286575436592102, 'loss_2': 0.0033931732177734375, 'loss_3': -16.228843688964844, 'loss_4': 0.5307168960571289, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 12:48:49,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:49,473 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:08<1:09:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:56,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024006813764572144, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.912, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01766367442905903, 'eval_loss_2': 0.006343141198158264, 'eval_loss_3': -18.179622650146484, 'eval_loss_4': 0.7145431041717529, 'epoch': 6.51}
{'loss': 0.0311, 'grad_norm': 12.931267738342285, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.029413575306534767, 'loss_2': 0.00170135498046875, 'loss_3': -16.389211654663086, 'loss_4': 1.246412754058838, 'epoch': 6.52}
{'loss': 0.0298, 'grad_norm': 10.179350852966309, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.028689205646514893, 'loss_2': 0.0010986328125, 'loss_3': -16.2637939453125, 'loss_4': 0.6441829800605774, 'epoch': 6.52}
{'loss': 0.0166, 'grad_norm': 6.938494682312012, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.014217703603208065, 'loss_2': 0.0023651123046875, 'loss_3': -16.250160217285156, 'loss_4': 0.5685848593711853, 'epoch': 6.53}
{'loss': 0.0319, 'grad_norm': 8.290712356567383, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.027297092601656914, 'loss_2': 0.0045928955078125, 'loss_3': -16.208431243896484, 'loss_4': 0.5416353344917297, 'epoch': 6.53}
{'loss': 0.0187, 'grad_norm': 6.755773067474365, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.01634388044476509, 'loss_2': 0.002307891845703125, 'loss_3': -16.228851318359375, 'loss_4': 0.5116153955459595, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 12:48:56,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:56,814 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:16<1:09:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:04,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023412249982357025, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.061, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.015831461176276207, 'eval_loss_2': 0.007580786943435669, 'eval_loss_3': -18.16750717163086, 'eval_loss_4': 0.6395043134689331, 'epoch': 6.54}
{'loss': 0.029, 'grad_norm': 8.999908447265625, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.020496757701039314, 'loss_2': 0.008453369140625, 'loss_3': -16.25223159790039, 'loss_4': 0.5851017832756042, 'epoch': 6.55}
{'loss': 0.0622, 'grad_norm': 15.639893531799316, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.04802395775914192, 'loss_2': 0.01416015625, 'loss_3': -16.106229782104492, 'loss_4': 1.1008414030075073, 'epoch': 6.55}
{'loss': 0.0423, 'grad_norm': 9.876129150390625, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.03087097965180874, 'loss_2': 0.011474609375, 'loss_3': -16.172340393066406, 'loss_4': 0.7508876323699951, 'epoch': 6.56}
{'loss': 0.0307, 'grad_norm': 10.395289421081543, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.021891891956329346, 'loss_2': 0.00885009765625, 'loss_3': -16.31636619567871, 'loss_4': 0.66876220703125, 'epoch': 6.56}
{'loss': 0.0574, 'grad_norm': 12.478408813476562, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.044253502041101456, 'loss_2': 0.0131378173828125, 'loss_3': -16.09160614013672, 'loss_4': 0.8322770595550537, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 12:49:04,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:04,147 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:23<1:09:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:11,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028684981167316437, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.2, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.016656525433063507, 'eval_loss_2': 0.01202845573425293, 'eval_loss_3': -18.150903701782227, 'eval_loss_4': 0.6468877792358398, 'epoch': 6.57}
{'loss': 0.0506, 'grad_norm': 8.937073707580566, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.03863956406712532, 'loss_2': 0.0119171142578125, 'loss_3': -16.123371124267578, 'loss_4': 0.5624366402626038, 'epoch': 6.58}
{'loss': 0.064, 'grad_norm': 14.159390449523926, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.05672371760010719, 'loss_2': 0.00726318359375, 'loss_3': -16.117042541503906, 'loss_4': 0.9145203232765198, 'epoch': 6.58}
{'loss': 0.0261, 'grad_norm': 4.935739517211914, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.011888167820870876, 'loss_2': 0.0142364501953125, 'loss_3': -16.327880859375, 'loss_4': 1.0149967670440674, 'epoch': 6.59}
{'loss': 0.0381, 'grad_norm': 14.176331520080566, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.032072070986032486, 'loss_2': 0.0059967041015625, 'loss_3': -16.136903762817383, 'loss_4': 0.6822370290756226, 'epoch': 6.59}
{'loss': 0.0524, 'grad_norm': 23.820161819458008, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.05171525105834007, 'loss_2': 0.0006575584411621094, 'loss_3': -16.173511505126953, 'loss_4': 1.1424325704574585, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 12:49:11,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:11,481 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:30<1:09:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:18,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020808063447475433, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.037, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.016641519963741302, 'eval_loss_2': 0.004166543483734131, 'eval_loss_3': -18.14483070373535, 'eval_loss_4': 0.9767025113105774, 'epoch': 6.6}
{'loss': 0.0631, 'grad_norm': 17.8967227935791, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.05665160343050957, 'loss_2': 0.00644683837890625, 'loss_3': -16.139156341552734, 'loss_4': 0.8662735223770142, 'epoch': 6.6}
{'loss': 0.0388, 'grad_norm': 8.829706192016602, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.030970236286520958, 'loss_2': 0.00785064697265625, 'loss_3': -16.125165939331055, 'loss_4': 1.062608242034912, 'epoch': 6.61}
{'loss': 0.0594, 'grad_norm': 16.758512496948242, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.05115415155887604, 'loss_2': 0.0082855224609375, 'loss_3': -16.30806541442871, 'loss_4': 1.4956055879592896, 'epoch': 6.62}
{'loss': 0.0292, 'grad_norm': 8.964820861816406, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.027957947924733162, 'loss_2': 0.001224517822265625, 'loss_3': -16.062746047973633, 'loss_4': 0.9139298796653748, 'epoch': 6.62}
{'loss': 0.0795, 'grad_norm': 24.05933380126953, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.07132593542337418, 'loss_2': 0.00817108154296875, 'loss_3': -16.09827995300293, 'loss_4': 1.2694363594055176, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 12:49:18,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:18,818 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:38<1:09:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:26,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027539044618606567, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.12, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.018841177225112915, 'eval_loss_2': 0.008697867393493652, 'eval_loss_3': -18.138063430786133, 'eval_loss_4': 1.3355557918548584, 'epoch': 6.63}
{'loss': 0.1025, 'grad_norm': 23.03339385986328, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.09507793933153152, 'loss_2': 0.0074310302734375, 'loss_3': -16.32587432861328, 'loss_4': 1.6868058443069458, 'epoch': 6.63}
{'loss': 0.0471, 'grad_norm': 10.145791053771973, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.034812744706869125, 'loss_2': 0.0122528076171875, 'loss_3': -16.119434356689453, 'loss_4': 1.6021326780319214, 'epoch': 6.64}
{'loss': 0.0357, 'grad_norm': 9.89242172241211, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.029890436679124832, 'loss_2': 0.0058135986328125, 'loss_3': -16.087631225585938, 'loss_4': 0.9104820489883423, 'epoch': 6.65}
{'loss': 0.0317, 'grad_norm': 8.35010051727295, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.024993201717734337, 'loss_2': 0.006755828857421875, 'loss_3': -15.970331192016602, 'loss_4': 1.034083366394043, 'epoch': 6.65}
{'loss': 0.0587, 'grad_norm': 26.369754791259766, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.05483347922563553, 'loss_2': 0.0038204193115234375, 'loss_3': -16.15214729309082, 'loss_4': 1.367679238319397, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 12:49:26,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:26,157 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:45<1:09:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:33,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02316252887248993, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.913, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.018825463950634003, 'eval_loss_2': 0.0043370649218559265, 'eval_loss_3': -18.095746994018555, 'eval_loss_4': 1.1727807521820068, 'epoch': 6.66}
{'loss': 0.0461, 'grad_norm': 15.538508415222168, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.043136466294527054, 'loss_2': 0.003009796142578125, 'loss_3': -16.086366653442383, 'loss_4': 1.3089927434921265, 'epoch': 6.66}
{'loss': 0.0475, 'grad_norm': 18.727462768554688, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.04673616960644722, 'loss_2': 0.0008106231689453125, 'loss_3': -16.198219299316406, 'loss_4': 1.0985629558563232, 'epoch': 6.67}
{'loss': 0.0388, 'grad_norm': 13.9185791015625, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.03762492164969444, 'loss_2': 0.0011997222900390625, 'loss_3': -16.30348014831543, 'loss_4': 1.4081370830535889, 'epoch': 6.67}
{'loss': 0.0324, 'grad_norm': 8.89217758178711, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.028897007927298546, 'loss_2': 0.003509521484375, 'loss_3': -15.954000473022461, 'loss_4': 1.5664277076721191, 'epoch': 6.68}
{'loss': 0.0248, 'grad_norm': 7.65769624710083, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.02357397973537445, 'loss_2': 0.0011920928955078125, 'loss_3': -16.20941162109375, 'loss_4': 1.1841812133789062, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 12:49:33,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:33,493 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:52<1:09:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:40,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027958452701568604, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01914215087890625, 'eval_loss_2': 0.008816301822662354, 'eval_loss_3': -18.057933807373047, 'eval_loss_4': 0.8150122761726379, 'epoch': 6.69}
{'loss': 0.0394, 'grad_norm': 9.323726654052734, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.03341623395681381, 'loss_2': 0.006023406982421875, 'loss_3': -16.203184127807617, 'loss_4': 1.2377893924713135, 'epoch': 6.69}
{'loss': 0.0508, 'grad_norm': 13.204635620117188, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.04067853093147278, 'loss_2': 0.010101318359375, 'loss_3': -16.01160430908203, 'loss_4': 1.1953829526901245, 'epoch': 6.7}
{'loss': 0.0307, 'grad_norm': 6.343971252441406, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.013886700384318829, 'loss_2': 0.0167694091796875, 'loss_3': -16.120750427246094, 'loss_4': 0.8697497844696045, 'epoch': 6.7}
{'loss': 0.0263, 'grad_norm': 6.620139122009277, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.014872446656227112, 'loss_2': 0.011444091796875, 'loss_3': -16.04216957092285, 'loss_4': 0.8923196792602539, 'epoch': 6.71}
{'loss': 0.0349, 'grad_norm': 8.371679306030273, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.024255502969026566, 'loss_2': 0.0106048583984375, 'loss_3': -16.17920684814453, 'loss_4': 0.9295049905776978, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 12:49:40,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:40,837 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [29:00<1:09:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:48,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02384660765528679, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.272, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.017578985542058945, 'eval_loss_2': 0.006267622113227844, 'eval_loss_3': -18.034793853759766, 'eval_loss_4': 0.714573085308075, 'epoch': 6.72}
{'loss': 0.0167, 'grad_norm': 6.019008636474609, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.014193423092365265, 'loss_2': 0.0024700164794921875, 'loss_3': -16.24011993408203, 'loss_4': 0.627781093120575, 'epoch': 6.72}
{'loss': 0.0099, 'grad_norm': 5.3824782371521, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.009533882141113281, 'loss_2': 0.00037860870361328125, 'loss_3': -16.059925079345703, 'loss_4': 0.48798394203186035, 'epoch': 6.73}
{'loss': 0.0712, 'grad_norm': 22.015647888183594, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.07088195532560349, 'loss_2': 0.0003142356872558594, 'loss_3': -15.975849151611328, 'loss_4': 1.1961219310760498, 'epoch': 6.73}
{'loss': 0.1412, 'grad_norm': 29.944406509399414, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.13599766790866852, 'loss_2': 0.005218505859375, 'loss_3': -15.952893257141113, 'loss_4': 1.5037891864776611, 'epoch': 6.74}
{'loss': 0.0358, 'grad_norm': 11.729260444641113, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.027006028220057487, 'loss_2': 0.00881195068359375, 'loss_3': -16.041545867919922, 'loss_4': 0.7294445037841797, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 12:49:48,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:48,164 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [29:07<1:08:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:55,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027537692338228226, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.043, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.017408955842256546, 'eval_loss_2': 0.01012873649597168, 'eval_loss_3': -18.06777000427246, 'eval_loss_4': 0.7976621389389038, 'epoch': 6.74}
{'loss': 0.0428, 'grad_norm': 9.897096633911133, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.027608852833509445, 'loss_2': 0.0152130126953125, 'loss_3': -16.062978744506836, 'loss_4': 0.9227056503295898, 'epoch': 6.75}
{'loss': 0.0304, 'grad_norm': 7.209733963012695, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.019385984167456627, 'loss_2': 0.0110321044921875, 'loss_3': -16.066118240356445, 'loss_4': 0.6169909238815308, 'epoch': 6.76}
{'loss': 0.0267, 'grad_norm': 5.677382946014404, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.014655102975666523, 'loss_2': 0.01209259033203125, 'loss_3': -16.12371253967285, 'loss_4': 0.9125922322273254, 'epoch': 6.76}
{'loss': 0.0293, 'grad_norm': 6.08970832824707, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.014940962195396423, 'loss_2': 0.0143585205078125, 'loss_3': -15.677874565124512, 'loss_4': 0.5462354421615601, 'epoch': 6.77}
{'loss': 0.0418, 'grad_norm': 17.497257232666016, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.03392195329070091, 'loss_2': 0.00787353515625, 'loss_3': -16.191959381103516, 'loss_4': 1.31095290184021, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 12:49:55,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:55,492 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:14<1:08:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:02,822 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026987986639142036, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.285, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.018200024962425232, 'eval_loss_2': 0.008787959814071655, 'eval_loss_3': -18.068286895751953, 'eval_loss_4': 1.0051161050796509, 'epoch': 6.77}
{'loss': 0.0251, 'grad_norm': 6.714760780334473, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.018190186470746994, 'loss_2': 0.0069427490234375, 'loss_3': -16.05245590209961, 'loss_4': 0.9611457586288452, 'epoch': 6.78}
{'loss': 0.014, 'grad_norm': 5.565085411071777, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.008782481774687767, 'loss_2': 0.0052337646484375, 'loss_3': -16.04732894897461, 'loss_4': 0.9695168137550354, 'epoch': 6.78}
{'loss': 0.0154, 'grad_norm': 9.029525756835938, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.014642305672168732, 'loss_2': 0.0007457733154296875, 'loss_3': -16.152437210083008, 'loss_4': 1.31929612159729, 'epoch': 6.79}
{'loss': 0.0333, 'grad_norm': 17.493146896362305, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.032347165048122406, 'loss_2': 0.0009045600891113281, 'loss_3': -15.912397384643555, 'loss_4': 0.6274303793907166, 'epoch': 6.8}
{'loss': 0.0161, 'grad_norm': 6.10666036605835, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.011189079843461514, 'loss_2': 0.00489044189453125, 'loss_3': -15.853312492370605, 'loss_4': 1.1168999671936035, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 12:50:02,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:02,822 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:22<1:08:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:10,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020657680928707123, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.213, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01702829636633396, 'eval_loss_2': 0.0036293864250183105, 'eval_loss_3': -18.07857894897461, 'eval_loss_4': 1.0133426189422607, 'epoch': 6.8}
{'loss': 0.0216, 'grad_norm': 11.034961700439453, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.018719865009188652, 'loss_2': 0.0029296875, 'loss_3': -16.047271728515625, 'loss_4': 1.1230976581573486, 'epoch': 6.81}
{'loss': 0.0265, 'grad_norm': 8.704630851745605, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.02401808276772499, 'loss_2': 0.00250244140625, 'loss_3': -16.031692504882812, 'loss_4': 0.5000905990600586, 'epoch': 6.81}
{'loss': 0.0101, 'grad_norm': 4.942829608917236, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.00878233090043068, 'loss_2': 0.00131988525390625, 'loss_3': -16.032285690307617, 'loss_4': 1.161314606666565, 'epoch': 6.82}
{'loss': 0.0224, 'grad_norm': 6.846879005432129, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.02173488773405552, 'loss_2': 0.0006189346313476562, 'loss_3': -16.027734756469727, 'loss_4': 0.942819356918335, 'epoch': 6.83}
{'loss': 0.0277, 'grad_norm': 9.572758674621582, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.018575521185994148, 'loss_2': 0.0091552734375, 'loss_3': -16.205406188964844, 'loss_4': 0.5615787506103516, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 12:50:10,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:10,161 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:29<1:08:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:17,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021869542077183723, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014447691850364208, 'eval_loss_2': 0.00742185115814209, 'eval_loss_3': -18.090261459350586, 'eval_loss_4': 0.7602470517158508, 'epoch': 6.83}
{'loss': 0.0294, 'grad_norm': 10.111978530883789, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.027323899790644646, 'loss_2': 0.002048492431640625, 'loss_3': -16.073328018188477, 'loss_4': 0.6587647199630737, 'epoch': 6.84}
{'loss': 0.0216, 'grad_norm': 5.766003608703613, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.014535675756633282, 'loss_2': 0.00710296630859375, 'loss_3': -16.020912170410156, 'loss_4': 0.8382464051246643, 'epoch': 6.84}
{'loss': 0.0213, 'grad_norm': 6.058785915374756, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.011517396196722984, 'loss_2': 0.0097503662109375, 'loss_3': -16.150657653808594, 'loss_4': 0.5975163578987122, 'epoch': 6.85}
{'loss': 0.0574, 'grad_norm': 17.114940643310547, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.04654107987880707, 'loss_2': 0.01081085205078125, 'loss_3': -15.92886734008789, 'loss_4': 0.7490110993385315, 'epoch': 6.85}
{'loss': 0.0204, 'grad_norm': 6.390894889831543, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.014988015405833721, 'loss_2': 0.005367279052734375, 'loss_3': -16.168453216552734, 'loss_4': 0.8595430850982666, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 12:50:17,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:17,512 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:36<1:08:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:24,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0178738534450531, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014422503300011158, 'eval_loss_2': 0.0034513473510742188, 'eval_loss_3': -18.177871704101562, 'eval_loss_4': 0.4465181231498718, 'epoch': 6.86}
{'loss': 0.0212, 'grad_norm': 8.081789016723633, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.018996478989720345, 'loss_2': 0.0021820068359375, 'loss_3': -16.18337631225586, 'loss_4': 0.9724214673042297, 'epoch': 6.87}
{'loss': 0.068, 'grad_norm': 17.44447898864746, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.06523920595645905, 'loss_2': 0.0027904510498046875, 'loss_3': -15.956131935119629, 'loss_4': 0.8658461570739746, 'epoch': 6.87}
{'loss': 0.0206, 'grad_norm': 7.536073684692383, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.015858545899391174, 'loss_2': 0.004791259765625, 'loss_3': -16.20254898071289, 'loss_4': 0.31388866901397705, 'epoch': 6.88}
{'loss': 0.0297, 'grad_norm': 11.874272346496582, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.029679689556360245, 'loss_2': 3.5703182220458984e-05, 'loss_3': -16.15666961669922, 'loss_4': 0.2660540044307709, 'epoch': 6.88}
{'loss': 0.0309, 'grad_norm': 7.8278985023498535, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.024041958153247833, 'loss_2': 0.006877899169921875, 'loss_3': -16.208494186401367, 'loss_4': -0.12028956413269043, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 12:50:24,863 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:24,863 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:44<1:08:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:32,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020969871431589127, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016106965020298958, 'eval_loss_2': 0.0048629045486450195, 'eval_loss_3': -18.17502212524414, 'eval_loss_4': 0.10481038689613342, 'epoch': 6.89}
{'loss': 0.0295, 'grad_norm': 10.733750343322754, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.026806339621543884, 'loss_2': 0.002651214599609375, 'loss_3': -16.369728088378906, 'loss_4': 0.24011321365833282, 'epoch': 6.9}
{'loss': 0.0159, 'grad_norm': 6.884356498718262, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.015253790654242039, 'loss_2': 0.0006017684936523438, 'loss_3': -15.953014373779297, 'loss_4': 0.10262909531593323, 'epoch': 6.9}
{'loss': 0.0326, 'grad_norm': 10.761678695678711, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.02928343042731285, 'loss_2': 0.003345489501953125, 'loss_3': -16.140884399414062, 'loss_4': 0.10498644411563873, 'epoch': 6.91}
{'loss': 0.0259, 'grad_norm': 8.307455062866211, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.023307833820581436, 'loss_2': 0.002559661865234375, 'loss_3': -16.101558685302734, 'loss_4': -0.08565965294837952, 'epoch': 6.91}
{'loss': 0.0243, 'grad_norm': 8.067995071411133, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.015958484262228012, 'loss_2': 0.00830078125, 'loss_3': -16.192058563232422, 'loss_4': 0.18474885821342468, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 12:50:32,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:32,209 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:51<1:08:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:39,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01858038827776909, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.822, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014938575215637684, 'eval_loss_2': 0.0036418139934539795, 'eval_loss_3': -18.199871063232422, 'eval_loss_4': 0.002280108630657196, 'epoch': 6.92}
{'loss': 0.0265, 'grad_norm': 9.217531204223633, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.02188391238451004, 'loss_2': 0.00457000732421875, 'loss_3': -16.015846252441406, 'loss_4': -0.21693971753120422, 'epoch': 6.92}
{'loss': 0.0384, 'grad_norm': 11.149619102478027, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.027045242488384247, 'loss_2': 0.01134490966796875, 'loss_3': -16.007247924804688, 'loss_4': -0.2363029420375824, 'epoch': 6.93}
{'loss': 0.0167, 'grad_norm': 6.072376728057861, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.010213738307356834, 'loss_2': 0.0064544677734375, 'loss_3': -16.10137939453125, 'loss_4': -0.07204754650592804, 'epoch': 6.94}
{'loss': 0.0288, 'grad_norm': 8.934959411621094, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.027033012360334396, 'loss_2': 0.0017385482788085938, 'loss_3': -16.25674819946289, 'loss_4': -0.8011443614959717, 'epoch': 6.94}
{'loss': 0.031, 'grad_norm': 10.601893424987793, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.0221684779971838, 'loss_2': 0.00885009765625, 'loss_3': -16.125293731689453, 'loss_4': 0.2747349441051483, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 12:50:39,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:39,550 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [29:58<1:08:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:50:46,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02418106608092785, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.073, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.015278590843081474, 'eval_loss_2': 0.008902475237846375, 'eval_loss_3': -18.20893669128418, 'eval_loss_4': -0.12004521489143372, 'epoch': 6.95}
{'loss': 0.0195, 'grad_norm': 5.753495216369629, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.009076980873942375, 'loss_2': 0.0104522705078125, 'loss_3': -16.1839542388916, 'loss_4': 0.05609780550003052, 'epoch': 6.95}
{'loss': 0.0357, 'grad_norm': 8.12285041809082, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.024294676259160042, 'loss_2': 0.0113983154296875, 'loss_3': -16.216510772705078, 'loss_4': -0.29657143354415894, 'epoch': 6.96}
{'loss': 0.0308, 'grad_norm': 6.986607074737549, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.023167554289102554, 'loss_2': 0.007598876953125, 'loss_3': -16.1302547454834, 'loss_4': 0.21603895723819733, 'epoch': 6.97}
{'loss': 0.0205, 'grad_norm': 8.225993156433105, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.01876855455338955, 'loss_2': 0.001720428466796875, 'loss_3': -16.010032653808594, 'loss_4': 0.24919170141220093, 'epoch': 6.97}
{'loss': 0.0266, 'grad_norm': 7.176908016204834, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.015604261308908463, 'loss_2': 0.01102447509765625, 'loss_3': -16.111446380615234, 'loss_4': 0.0304199680685997, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 12:50:46,876 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:46,876 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [30:05<1:04:23,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 12:50:53,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017353635281324387, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.774, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014813092537224293, 'eval_loss_2': 0.0025405436754226685, 'eval_loss_3': -18.2014217376709, 'eval_loss_4': -0.25462645292282104, 'epoch': 6.98}
{'loss': 0.0179, 'grad_norm': 5.389113426208496, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.01560141984373331, 'loss_2': 0.00232696533203125, 'loss_3': -16.073455810546875, 'loss_4': -0.31933432817459106, 'epoch': 6.98}
{'loss': 0.0249, 'grad_norm': 8.320225715637207, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.021500926464796066, 'loss_2': 0.00341033935546875, 'loss_3': -15.894479751586914, 'loss_4': 0.1382608711719513, 'epoch': 6.99}
{'loss': 0.0302, 'grad_norm': 6.5555620193481445, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.021512791514396667, 'loss_2': 0.0086517333984375, 'loss_3': -16.20412254333496, 'loss_4': 0.3392115533351898, 'epoch': 6.99}
{'loss': 0.0121, 'grad_norm': 8.663762092590332, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.005606494843959808, 'loss_2': 0.0064849853515625, 'loss_3': -16.177932739257812, 'loss_4': 0.09537828713655472, 'epoch': 7.0}
{'loss': 0.0332, 'grad_norm': 12.23591423034668, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.024546444416046143, 'loss_2': 0.00864410400390625, 'loss_3': -16.025108337402344, 'loss_4': -0.15586918592453003, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 12:50:53,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:53,904 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:13<1:07:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:51:01,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01924711838364601, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013750557787716389, 'eval_loss_2': 0.005496561527252197, 'eval_loss_3': -18.17813491821289, 'eval_loss_4': -0.21004989743232727, 'epoch': 7.01}
{'loss': 0.0352, 'grad_norm': 10.516173362731934, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.02522902376949787, 'loss_2': 0.0099639892578125, 'loss_3': -16.016738891601562, 'loss_4': 0.12479357421398163, 'epoch': 7.01}
{'loss': 0.0324, 'grad_norm': 9.822524070739746, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.02197321690618992, 'loss_2': 0.01041412353515625, 'loss_3': -15.94075870513916, 'loss_4': 0.11973369121551514, 'epoch': 7.02}
{'loss': 0.0246, 'grad_norm': 10.301562309265137, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.017993146553635597, 'loss_2': 0.006622314453125, 'loss_3': -16.05047607421875, 'loss_4': -0.39654749631881714, 'epoch': 7.02}
{'loss': 0.0219, 'grad_norm': 6.30391788482666, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.013554409146308899, 'loss_2': 0.00836944580078125, 'loss_3': -15.917268753051758, 'loss_4': 0.16312122344970703, 'epoch': 7.03}
{'loss': 0.0168, 'grad_norm': 8.258540153503418, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.01617008075118065, 'loss_2': 0.0006437301635742188, 'loss_3': -16.019519805908203, 'loss_4': -0.26120805740356445, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 12:51:01,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:01,249 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:20<1:08:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:08,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020442049950361252, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.993, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01499895378947258, 'eval_loss_2': 0.005443096160888672, 'eval_loss_3': -18.146198272705078, 'eval_loss_4': -0.00880160927772522, 'epoch': 7.03}
{'loss': 0.0189, 'grad_norm': 6.278313159942627, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.014254948124289513, 'loss_2': 0.004634857177734375, 'loss_3': -16.109661102294922, 'loss_4': 0.40585994720458984, 'epoch': 7.04}
{'loss': 0.0208, 'grad_norm': 7.66191291809082, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.018810342997312546, 'loss_2': 0.00202178955078125, 'loss_3': -16.223224639892578, 'loss_4': 0.3042478561401367, 'epoch': 7.05}
{'loss': 0.0346, 'grad_norm': 18.010913848876953, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.031667180359363556, 'loss_2': 0.00290679931640625, 'loss_3': -16.15676498413086, 'loss_4': 0.5654236674308777, 'epoch': 7.05}
{'loss': 0.0292, 'grad_norm': 8.033133506774902, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.020881522446870804, 'loss_2': 0.00832366943359375, 'loss_3': -15.982715606689453, 'loss_4': 0.17081724107265472, 'epoch': 7.06}
{'loss': 0.0236, 'grad_norm': 8.855477333068848, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.02031225711107254, 'loss_2': 0.0032825469970703125, 'loss_3': -15.85948657989502, 'loss_4': 0.46378278732299805, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 12:51:08,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:08,590 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:27<1:08:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:15,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01769941672682762, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.618, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014638121239840984, 'eval_loss_2': 0.0030612945556640625, 'eval_loss_3': -18.10378646850586, 'eval_loss_4': 0.2524268925189972, 'epoch': 7.06}
{'loss': 0.0238, 'grad_norm': 8.003019332885742, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.01920205168426037, 'loss_2': 0.00457763671875, 'loss_3': -16.217554092407227, 'loss_4': 0.43038231134414673, 'epoch': 7.07}
{'loss': 0.0256, 'grad_norm': 8.433809280395508, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.021581051871180534, 'loss_2': 0.003986358642578125, 'loss_3': -15.990645408630371, 'loss_4': 0.3187476396560669, 'epoch': 7.08}
{'loss': 0.0182, 'grad_norm': 5.490698337554932, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.008732132613658905, 'loss_2': 0.0094451904296875, 'loss_3': -16.157012939453125, 'loss_4': -0.0003492385149002075, 'epoch': 7.08}
{'loss': 0.0187, 'grad_norm': 6.157519340515137, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.010924465022981167, 'loss_2': 0.0077667236328125, 'loss_3': -16.145565032958984, 'loss_4': -0.033219918608665466, 'epoch': 7.09}
{'loss': 0.0222, 'grad_norm': 8.087268829345703, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.018908077850937843, 'loss_2': 0.003246307373046875, 'loss_3': -15.964505195617676, 'loss_4': 0.591485321521759, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 12:51:15,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:15,926 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:35<1:08:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:23,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02005901001393795, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.016735482960939407, 'eval_loss_2': 0.0033235251903533936, 'eval_loss_3': -18.062849044799805, 'eval_loss_4': 0.4923149049282074, 'epoch': 7.09}
{'loss': 0.0203, 'grad_norm': 7.200750827789307, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.015372795052826405, 'loss_2': 0.00496673583984375, 'loss_3': -16.163644790649414, 'loss_4': 0.6066356301307678, 'epoch': 7.1}
{'loss': 0.0366, 'grad_norm': 16.021793365478516, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.03463955968618393, 'loss_2': 0.00197601318359375, 'loss_3': -16.180282592773438, 'loss_4': 0.45281630754470825, 'epoch': 7.1}
{'loss': 0.0135, 'grad_norm': 7.077692985534668, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.010164164006710052, 'loss_2': 0.0033416748046875, 'loss_3': -15.73245620727539, 'loss_4': 0.21141886711120605, 'epoch': 7.11}
{'loss': 0.0165, 'grad_norm': 5.933154106140137, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.014994100667536259, 'loss_2': 0.0015316009521484375, 'loss_3': -15.852575302124023, 'loss_4': 1.0569846630096436, 'epoch': 7.12}
{'loss': 0.041, 'grad_norm': 28.68829345703125, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.03938566893339157, 'loss_2': 0.00165557861328125, 'loss_3': -15.906091690063477, 'loss_4': 0.8232144117355347, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 12:51:23,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:23,268 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:42<1:07:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:30,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03154425323009491, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.232, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.02411334030330181, 'eval_loss_2': 0.007430911064147949, 'eval_loss_3': -17.971561431884766, 'eval_loss_4': 0.7526624798774719, 'epoch': 7.12}
{'loss': 0.0394, 'grad_norm': 8.84554386138916, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.031838517636060715, 'loss_2': 0.00759124755859375, 'loss_3': -15.80029296875, 'loss_4': 0.2953571081161499, 'epoch': 7.13}
{'loss': 0.0242, 'grad_norm': 7.688351631164551, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.015265282243490219, 'loss_2': 0.0088958740234375, 'loss_3': -16.134437561035156, 'loss_4': 0.9198145866394043, 'epoch': 7.13}
{'loss': 0.0498, 'grad_norm': 10.10258674621582, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.03332905471324921, 'loss_2': 0.0164947509765625, 'loss_3': -16.121004104614258, 'loss_4': 0.6112325191497803, 'epoch': 7.14}
{'loss': 0.0192, 'grad_norm': 5.463075637817383, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.010948369279503822, 'loss_2': 0.0082550048828125, 'loss_3': -16.12647819519043, 'loss_4': 1.187414526939392, 'epoch': 7.15}
{'loss': 0.031, 'grad_norm': 7.8554277420043945, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.02058463916182518, 'loss_2': 0.0103759765625, 'loss_3': -15.71015739440918, 'loss_4': 0.5559255480766296, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 12:51:30,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:30,602 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:49<1:07:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:37,948 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028841279447078705, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.021358393132686615, 'eval_loss_2': 0.00748288631439209, 'eval_loss_3': -18.006837844848633, 'eval_loss_4': 0.9001555442810059, 'epoch': 7.15}
{'loss': 0.0261, 'grad_norm': 9.202866554260254, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.02287612110376358, 'loss_2': 0.003231048583984375, 'loss_3': -15.889633178710938, 'loss_4': 0.5531237125396729, 'epoch': 7.16}
{'loss': 0.0274, 'grad_norm': 8.388482093811035, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.024439996108412743, 'loss_2': 0.002918243408203125, 'loss_3': -15.876367568969727, 'loss_4': 1.1192516088485718, 'epoch': 7.16}
{'loss': 0.0431, 'grad_norm': 11.362244606018066, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.03402840718626976, 'loss_2': 0.0090484619140625, 'loss_3': -15.943090438842773, 'loss_4': 0.7995527982711792, 'epoch': 7.17}
{'loss': 0.037, 'grad_norm': 17.95945930480957, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.032622624188661575, 'loss_2': 0.004364013671875, 'loss_3': -15.815906524658203, 'loss_4': 0.5234077572822571, 'epoch': 7.17}
{'loss': 0.0179, 'grad_norm': 6.125755310058594, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.014057240448892117, 'loss_2': 0.003887176513671875, 'loss_3': -15.766057014465332, 'loss_4': 0.6424596309661865, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 12:51:37,948 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:37,949 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [30:57<1:07:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:45,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021650992333889008, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015775375068187714, 'eval_loss_2': 0.005875617265701294, 'eval_loss_3': -18.037940979003906, 'eval_loss_4': 0.7775321006774902, 'epoch': 7.18}
{'loss': 0.0246, 'grad_norm': 7.994884967803955, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.016178004443645477, 'loss_2': 0.008392333984375, 'loss_3': -15.98231029510498, 'loss_4': 0.16509807109832764, 'epoch': 7.19}
{'loss': 0.0244, 'grad_norm': 8.131085395812988, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.021537281572818756, 'loss_2': 0.00286865234375, 'loss_3': -15.987077713012695, 'loss_4': 0.29160642623901367, 'epoch': 7.19}
{'loss': 0.024, 'grad_norm': 7.17220401763916, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.021967953070998192, 'loss_2': 0.002071380615234375, 'loss_3': -16.358089447021484, 'loss_4': 0.9098579287528992, 'epoch': 7.2}
{'loss': 0.0278, 'grad_norm': 7.212043285369873, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.019142117351293564, 'loss_2': 0.00870513916015625, 'loss_3': -15.95674991607666, 'loss_4': 0.8657312989234924, 'epoch': 7.2}
{'loss': 0.0278, 'grad_norm': 6.400003910064697, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.016283400356769562, 'loss_2': 0.011474609375, 'loss_3': -15.94377326965332, 'loss_4': 0.6801832318305969, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 12:51:45,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:45,294 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [31:04<1:07:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:52,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014165678061544895, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.872, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011431589722633362, 'eval_loss_2': 0.0027340874075889587, 'eval_loss_3': -18.116416931152344, 'eval_loss_4': 0.641563892364502, 'epoch': 7.21}
{'loss': 0.0413, 'grad_norm': 8.858366966247559, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.03548211231827736, 'loss_2': 0.00582122802734375, 'loss_3': -15.985950469970703, 'loss_4': 0.916959822177887, 'epoch': 7.22}
{'loss': 0.0416, 'grad_norm': 12.475251197814941, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.03918421268463135, 'loss_2': 0.002410888671875, 'loss_3': -16.31678009033203, 'loss_4': 0.9420315027236938, 'epoch': 7.22}
{'loss': 0.0288, 'grad_norm': 8.782548904418945, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.026657216250896454, 'loss_2': 0.0021228790283203125, 'loss_3': -15.869383811950684, 'loss_4': 0.8797358870506287, 'epoch': 7.23}
{'loss': 0.0438, 'grad_norm': 13.612305641174316, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.037286464124917984, 'loss_2': 0.006481170654296875, 'loss_3': -16.15367317199707, 'loss_4': 0.3147716522216797, 'epoch': 7.23}
{'loss': 0.032, 'grad_norm': 9.897780418395996, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.03014109469950199, 'loss_2': 0.0018281936645507812, 'loss_3': -16.312286376953125, 'loss_4': 0.20777249336242676, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 12:51:52,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:52,631 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:11<1:07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:59,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015816111117601395, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.714, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00986071489751339, 'eval_loss_2': 0.005955398082733154, 'eval_loss_3': -18.13693618774414, 'eval_loss_4': 0.34628352522850037, 'epoch': 7.24}
{'loss': 0.0276, 'grad_norm': 12.475484848022461, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.02556547336280346, 'loss_2': 0.00208282470703125, 'loss_3': -16.23549461364746, 'loss_4': 0.41981780529022217, 'epoch': 7.24}
{'loss': 0.0248, 'grad_norm': 9.721172332763672, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.02151227742433548, 'loss_2': 0.0032958984375, 'loss_3': -16.090110778808594, 'loss_4': 0.7914062738418579, 'epoch': 7.25}
{'loss': 0.0369, 'grad_norm': 14.8154878616333, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.030963405966758728, 'loss_2': 0.0059661865234375, 'loss_3': -16.13262939453125, 'loss_4': 0.18184953927993774, 'epoch': 7.26}
{'loss': 0.0116, 'grad_norm': 5.141817569732666, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.008848176337778568, 'loss_2': 0.002712249755859375, 'loss_3': -16.218860626220703, 'loss_4': -0.030382752418518066, 'epoch': 7.26}
{'loss': 0.0174, 'grad_norm': 6.181183815002441, 'learning_rate': 2.275e-05, 'loss_1': 0.011429117061197758, 'loss_2': 0.00600433349609375, 'loss_3': -16.136093139648438, 'loss_4': 0.18321654200553894, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 12:51:59,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:59,972 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:19<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:07,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01614651270210743, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.863, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013230355456471443, 'eval_loss_2': 0.0029161572456359863, 'eval_loss_3': -18.123533248901367, 'eval_loss_4': -0.047574274241924286, 'epoch': 7.27}
{'loss': 0.0373, 'grad_norm': 19.579233169555664, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.036201901733875275, 'loss_2': 0.001132965087890625, 'loss_3': -16.166563034057617, 'loss_4': 0.617539644241333, 'epoch': 7.27}
{'loss': 0.0185, 'grad_norm': 5.48421573638916, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.012820028699934483, 'loss_2': 0.00567626953125, 'loss_3': -16.279212951660156, 'loss_4': 0.1737479269504547, 'epoch': 7.28}
{'loss': 0.0299, 'grad_norm': 10.972818374633789, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.029029149562120438, 'loss_2': 0.0008263587951660156, 'loss_3': -16.13500213623047, 'loss_4': -0.11436056345701218, 'epoch': 7.28}
{'loss': 0.1132, 'grad_norm': 29.026811599731445, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.11278527975082397, 'loss_2': 0.0004215240478515625, 'loss_3': -15.807698249816895, 'loss_4': -0.35001569986343384, 'epoch': 7.29}
{'loss': 0.0354, 'grad_norm': 9.853781700134277, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.03365982696413994, 'loss_2': 0.0017681121826171875, 'loss_3': -16.279075622558594, 'loss_4': 0.0209798663854599, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 12:52:07,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:07,309 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:26<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:14,656 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015950089320540428, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012753298506140709, 'eval_loss_2': 0.0031967908143997192, 'eval_loss_3': -18.13251304626465, 'eval_loss_4': -0.4600061774253845, 'epoch': 7.3}
{'loss': 0.0388, 'grad_norm': 10.86301326751709, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.038534872233867645, 'loss_2': 0.0002841949462890625, 'loss_3': -16.18523406982422, 'loss_4': -0.1294603943824768, 'epoch': 7.3}
{'loss': 0.0513, 'grad_norm': 14.36816120147705, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.050000790506601334, 'loss_2': 0.001312255859375, 'loss_3': -15.94001293182373, 'loss_4': -0.5386531949043274, 'epoch': 7.31}
{'loss': 0.1049, 'grad_norm': 24.430940628051758, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.10406307876110077, 'loss_2': 0.0008258819580078125, 'loss_3': -16.060760498046875, 'loss_4': -0.38645780086517334, 'epoch': 7.31}
{'loss': 0.0313, 'grad_norm': 13.745245933532715, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.02616717293858528, 'loss_2': 0.00511932373046875, 'loss_3': -16.173063278198242, 'loss_4': -0.28503158688545227, 'epoch': 7.32}
{'loss': 0.0388, 'grad_norm': 8.658441543579102, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.034644898027181625, 'loss_2': 0.0041961669921875, 'loss_3': -16.346067428588867, 'loss_4': -0.31913992762565613, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 12:52:14,656 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:14,656 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:33<1:07:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:22,005 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017467651516199112, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.4, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01395433023571968, 'eval_loss_2': 0.003513321280479431, 'eval_loss_3': -18.140138626098633, 'eval_loss_4': -0.6534367203712463, 'epoch': 7.33}
{'loss': 0.0607, 'grad_norm': 14.896470069885254, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.05515360087156296, 'loss_2': 0.00553131103515625, 'loss_3': -16.230628967285156, 'loss_4': 0.14913301169872284, 'epoch': 7.33}
{'loss': 0.1043, 'grad_norm': 25.966726303100586, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.10167093575000763, 'loss_2': 0.002651214599609375, 'loss_3': -16.19344139099121, 'loss_4': -1.117873191833496, 'epoch': 7.34}
{'loss': 0.0445, 'grad_norm': 9.956002235412598, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.0376293808221817, 'loss_2': 0.006862640380859375, 'loss_3': -16.076032638549805, 'loss_4': -1.0883914232254028, 'epoch': 7.34}
{'loss': 0.0292, 'grad_norm': 6.560358047485352, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.020346185192465782, 'loss_2': 0.0088043212890625, 'loss_3': -16.377849578857422, 'loss_4': -0.7304078340530396, 'epoch': 7.35}
{'loss': 0.0452, 'grad_norm': 13.48448657989502, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.040160875767469406, 'loss_2': 0.005084991455078125, 'loss_3': -16.005970001220703, 'loss_4': 0.01003219187259674, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 12:52:22,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:22,005 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:41<1:07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:29,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015067512169480324, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.768, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011258536018431187, 'eval_loss_2': 0.0038089752197265625, 'eval_loss_3': -18.123497009277344, 'eval_loss_4': -0.6189085245132446, 'epoch': 7.35}
{'loss': 0.049, 'grad_norm': 12.958060264587402, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.046962905675172806, 'loss_2': 0.002063751220703125, 'loss_3': -16.185102462768555, 'loss_4': -0.18116077780723572, 'epoch': 7.36}
{'loss': 0.0223, 'grad_norm': 6.734094142913818, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.018989238888025284, 'loss_2': 0.003337860107421875, 'loss_3': -16.133163452148438, 'loss_4': -0.17773084342479706, 'epoch': 7.37}
{'loss': 0.0362, 'grad_norm': 10.156355857849121, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.031588587909936905, 'loss_2': 0.004638671875, 'loss_3': -16.050987243652344, 'loss_4': -0.8363948464393616, 'epoch': 7.37}
{'loss': 0.0183, 'grad_norm': 6.907256603240967, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.01769416034221649, 'loss_2': 0.0005741119384765625, 'loss_3': -16.19931983947754, 'loss_4': -0.4180527329444885, 'epoch': 7.38}
{'loss': 0.0252, 'grad_norm': 8.408434867858887, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.024984057992696762, 'loss_2': 0.00019741058349609375, 'loss_3': -16.128353118896484, 'loss_4': -0.5434087514877319, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 12:52:29,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:29,339 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:48<1:06:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:52:36,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01369934156537056, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.026, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010125418193638325, 'eval_loss_2': 0.0035739243030548096, 'eval_loss_3': -18.118289947509766, 'eval_loss_4': -0.6473954319953918, 'epoch': 7.38}
{'loss': 0.0133, 'grad_norm': 5.05367374420166, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.011526739224791527, 'loss_2': 0.0017604827880859375, 'loss_3': -16.23633575439453, 'loss_4': -0.7544068098068237, 'epoch': 7.39}
{'loss': 0.0379, 'grad_norm': 8.713644981384277, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.031084025278687477, 'loss_2': 0.00685882568359375, 'loss_3': -16.259227752685547, 'loss_4': -0.6862091422080994, 'epoch': 7.4}
{'loss': 0.0152, 'grad_norm': 6.052605628967285, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.011166758835315704, 'loss_2': 0.0040740966796875, 'loss_3': -16.341102600097656, 'loss_4': -0.9995201230049133, 'epoch': 7.4}
{'loss': 0.0416, 'grad_norm': 17.721689224243164, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.038134537637233734, 'loss_2': 0.003429412841796875, 'loss_3': -16.12679100036621, 'loss_4': -0.7196260690689087, 'epoch': 7.41}
{'loss': 0.0191, 'grad_norm': 6.832173824310303, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.01533518172800541, 'loss_2': 0.00377655029296875, 'loss_3': -16.135385513305664, 'loss_4': -0.5893787145614624, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 12:52:36,665 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:36,665 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:52<1:06:59,  1.03s/it][INFO|trainer.py:3910] 2025-01-21 12:52:40,460 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1275
[INFO|configuration_utils.py:420] 2025-01-21 12:52:40,461 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1275/config.json                                                                            
{'eval_loss': 0.013240266591310501, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.932, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008620788343250751, 'eval_loss_2': 0.004619479179382324, 'eval_loss_3': -18.108678817749023, 'eval_loss_4': -0.8570148944854736, 'epoch': 7.41}
[INFO|modeling_utils.py:2988] 2025-01-21 12:52:40,944 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1275/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:52:40,945 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1275/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:52:40,946 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1275/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:52:41,799 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1035] due to args.save_total_limit
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [31:57<1:13:34,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:52:45,419 >>
{'loss': 0.0505, 'grad_norm': 15.263998985290527, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.04588417708873749, 'loss_2': 0.00458526611328125, 'loss_3': -16.024831771850586, 'loss_4': -0.7872369289398193, 'epoch': 7.42}
{'loss': 0.0272, 'grad_norm': 10.901540756225586, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.023837951943278313, 'loss_2': 0.0033416748046875, 'loss_3': -16.278587341308594, 'loss_4': -0.9039785861968994, 'epoch': 7.42}
{'loss': 0.0139, 'grad_norm': 6.391727924346924, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.01180912833660841, 'loss_2': 0.00208282470703125, 'loss_3': -15.98399543762207, 'loss_4': -0.46189242601394653, 'epoch': 7.43}
{'loss': 0.0222, 'grad_norm': 8.794194221496582, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.015675000846385956, 'loss_2': 0.006500244140625, 'loss_3': -15.986235618591309, 'loss_4': -0.6355224847793579, 'epoch': 7.44}
{'loss': 0.0429, 'grad_norm': 19.64124870300293, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.037784550338983536, 'loss_2': 0.00510406494140625, 'loss_3': -16.085281372070312, 'loss_4': -0.43276989459991455, 'epoch': 7.44}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:52:45,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:45,420 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [32:01<1:13:34,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 12:52:49,212 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1280
[INFO|configuration_utils.py:420] 2025-01-21 12:52:49,213 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1280/config.json                                                                            
{'eval_loss': 0.01300514955073595, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.107, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.00911519955843687, 'eval_loss_2': 0.0038899481296539307, 'eval_loss_3': -18.132301330566406, 'eval_loss_4': -0.9305641651153564, 'epoch': 7.44}
[INFO|modeling_utils.py:2988] 2025-01-21 12:52:49,730 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1280/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:52:49,731 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1280/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:52:49,731 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1280/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:52:50,727 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1275] due to args.save_total_limit
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:06<1:15:24,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:52:54,357 >>
{'loss': 0.0258, 'grad_norm': 8.726141929626465, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.02569848857820034, 'loss_2': 0.00010824203491210938, 'loss_3': -16.006229400634766, 'loss_4': -0.7040430307388306, 'epoch': 7.45}
{'loss': 0.0326, 'grad_norm': 14.092211723327637, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.032126132398843765, 'loss_2': 0.0004773139953613281, 'loss_3': -16.059711456298828, 'loss_4': -0.4156641960144043, 'epoch': 7.45}
{'loss': 0.016, 'grad_norm': 10.264690399169922, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.013462794944643974, 'loss_2': 0.00249481201171875, 'loss_3': -16.256988525390625, 'loss_4': -0.41682136058807373, 'epoch': 7.46}
{'loss': 0.0178, 'grad_norm': 6.828214168548584, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.017760436981916428, 'loss_2': 6.395578384399414e-05, 'loss_3': -16.31795883178711, 'loss_4': -0.7163374423980713, 'epoch': 7.47}
{'loss': 0.0379, 'grad_norm': 12.17536735534668, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.031781408935785294, 'loss_2': 0.0061187744140625, 'loss_3': -16.104021072387695, 'loss_4': -0.6625625491142273, 'epoch': 7.47}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:52:54,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:54,358 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:10<1:15:24,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:52:58,153 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1285
[INFO|configuration_utils.py:420] 2025-01-21 12:52:58,154 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1285/config.json                                                                            
{'eval_loss': 0.012890963815152645, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.916, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009213238023221493, 'eval_loss_2': 0.0036777257919311523, 'eval_loss_3': -18.193105697631836, 'eval_loss_4': -0.7622772455215454, 'epoch': 7.47}
[INFO|modeling_utils.py:2988] 2025-01-21 12:52:58,681 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1285/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:52:58,682 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1285/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:52:58,683 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1285/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:52:59,526 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1280] due to args.save_total_limit
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:15<1:15:06,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:53:03,169 >>
{'loss': 0.0247, 'grad_norm': 7.090236663818359, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.022188816219568253, 'loss_2': 0.00255584716796875, 'loss_3': -16.03814697265625, 'loss_4': -0.538623571395874, 'epoch': 7.48}
{'loss': 0.0223, 'grad_norm': 6.232075214385986, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.01926087774336338, 'loss_2': 0.00302886962890625, 'loss_3': -16.203773498535156, 'loss_4': -0.12188738584518433, 'epoch': 7.48}
{'loss': 0.0216, 'grad_norm': 7.029849529266357, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.017788920551538467, 'loss_2': 0.003833770751953125, 'loss_3': -16.28221893310547, 'loss_4': -0.3053775429725647, 'epoch': 7.49}
{'loss': 0.0154, 'grad_norm': 5.058690547943115, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.00794924795627594, 'loss_2': 0.0074462890625, 'loss_3': -16.201234817504883, 'loss_4': -0.2986292243003845, 'epoch': 7.49}
{'loss': 0.0414, 'grad_norm': 11.809160232543945, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.040335532277822495, 'loss_2': 0.0010967254638671875, 'loss_3': -16.027477264404297, 'loss_4': 0.027444988489151, 'epoch': 7.5}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:53:03,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:03,169 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:18<1:15:06,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:53:06,953 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1290
[INFO|configuration_utils.py:420] 2025-01-21 12:53:06,954 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1290/config.json                                                                            
{'eval_loss': 0.012118601240217686, 'eval_runtime': 3.7829, 'eval_samples_per_second': 270.695, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.009130322374403477, 'eval_loss_2': 0.002988278865814209, 'eval_loss_3': -18.21860694885254, 'eval_loss_4': -0.05786741152405739, 'epoch': 7.5}
[INFO|modeling_utils.py:2988] 2025-01-21 12:53:07,442 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1290/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:53:07,443 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1290/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:53:07,443 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1290/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:53:08,299 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1285] due to args.save_total_limit
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:23<1:14:47,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:53:11,933 >>
{'loss': 0.0191, 'grad_norm': 7.666325569152832, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.011929475702345371, 'loss_2': 0.007198333740234375, 'loss_3': -16.376873016357422, 'loss_4': -0.30146604776382446, 'epoch': 7.51}
{'loss': 0.012, 'grad_norm': 5.311706066131592, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.008816845715045929, 'loss_2': 0.0031890869140625, 'loss_3': -16.145402908325195, 'loss_4': 0.3794565796852112, 'epoch': 7.51}
{'loss': 0.0373, 'grad_norm': 9.6129732131958, 'learning_rate': 2.25e-05, 'loss_1': 0.03035387396812439, 'loss_2': 0.006977081298828125, 'loss_3': -16.105012893676758, 'loss_4': 0.10282779484987259, 'epoch': 7.52}
{'loss': 0.0298, 'grad_norm': 6.568045616149902, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.021007047966122627, 'loss_2': 0.0087738037109375, 'loss_3': -16.149812698364258, 'loss_4': 0.4355407655239105, 'epoch': 7.52}
{'loss': 0.0208, 'grad_norm': 6.155498504638672, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.015947513282299042, 'loss_2': 0.00489044189453125, 'loss_3': -15.959413528442383, 'loss_4': 1.0925302505493164, 'epoch': 7.53}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:53:11,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:11,933 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:31<1:08:00,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:53:19,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0133124440908432, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.355, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.009580157697200775, 'eval_loss_2': 0.0037322863936424255, 'eval_loss_3': -18.216379165649414, 'eval_loss_4': 0.35006964206695557, 'epoch': 7.53}
{'loss': 0.0177, 'grad_norm': 5.639367580413818, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.012402624823153019, 'loss_2': 0.005283355712890625, 'loss_3': -16.27730369567871, 'loss_4': 0.4273208975791931, 'epoch': 7.53}
{'loss': 0.0324, 'grad_norm': 8.264979362487793, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.029733827337622643, 'loss_2': 0.002712249755859375, 'loss_3': -16.141611099243164, 'loss_4': 0.6814420223236084, 'epoch': 7.54}
{'loss': 0.1059, 'grad_norm': 23.36748695373535, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.10481011867523193, 'loss_2': 0.0011186599731445312, 'loss_3': -16.17036247253418, 'loss_4': 1.544816493988037, 'epoch': 7.55}
{'loss': 0.0378, 'grad_norm': 10.732422828674316, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.033527374267578125, 'loss_2': 0.004230499267578125, 'loss_3': -16.169538497924805, 'loss_4': 1.0482743978500366, 'epoch': 7.55}
{'loss': 0.0531, 'grad_norm': 18.25018310546875, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.04731373116374016, 'loss_2': 0.0057373046875, 'loss_3': -16.16156005859375, 'loss_4': 0.6780300140380859, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 12:53:19,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:19,264 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:38<1:06:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:26,587 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013040035031735897, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.244, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00957527756690979, 'eval_loss_2': 0.0034647583961486816, 'eval_loss_3': -18.166536331176758, 'eval_loss_4': 0.4577857255935669, 'epoch': 7.56}
{'loss': 0.0423, 'grad_norm': 13.143998146057129, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.03774312138557434, 'loss_2': 0.00457000732421875, 'loss_3': -16.10230255126953, 'loss_4': 0.6198058724403381, 'epoch': 7.56}
{'loss': 0.023, 'grad_norm': 10.945377349853516, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.02225881814956665, 'loss_2': 0.0007152557373046875, 'loss_3': -16.204448699951172, 'loss_4': 0.42916548252105713, 'epoch': 7.57}
{'loss': 0.015, 'grad_norm': 6.190183639526367, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.014391760341823101, 'loss_2': 0.0006031990051269531, 'loss_3': -16.070207595825195, 'loss_4': 0.37154510617256165, 'epoch': 7.58}
{'loss': 0.0146, 'grad_norm': 6.0973310470581055, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.01257170271128416, 'loss_2': 0.00200653076171875, 'loss_3': -16.218847274780273, 'loss_4': -0.3778851628303528, 'epoch': 7.58}
{'loss': 0.019, 'grad_norm': 5.384370803833008, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.011461426503956318, 'loss_2': 0.0074920654296875, 'loss_3': -16.162086486816406, 'loss_4': -0.08567333221435547, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 12:53:26,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:26,587 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:46<1:07:22,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:53:34,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03134666383266449, 'eval_runtime': 3.9729, 'eval_samples_per_second': 257.749, 'eval_steps_per_second': 4.027, 'eval_loss_1': 0.02825455740094185, 'eval_loss_2': 0.0030921027064323425, 'eval_loss_3': -18.03473663330078, 'eval_loss_4': 0.6813114881515503, 'epoch': 7.59}
{'loss': 0.0145, 'grad_norm': 7.591489791870117, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.012450484558939934, 'loss_2': 0.002002716064453125, 'loss_3': -15.985182762145996, 'loss_4': 0.2747422456741333, 'epoch': 7.59}
{'loss': 0.02, 'grad_norm': 7.289614677429199, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.01690700463950634, 'loss_2': 0.0030612945556640625, 'loss_3': -15.966334342956543, 'loss_4': 0.6376768946647644, 'epoch': 7.6}
{'loss': 0.0321, 'grad_norm': 11.533981323242188, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.03034626506268978, 'loss_2': 0.00171661376953125, 'loss_3': -16.059009552001953, 'loss_4': 0.4197899103164673, 'epoch': 7.6}
{'loss': 0.0158, 'grad_norm': 7.237269878387451, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.011649941094219685, 'loss_2': 0.0041046142578125, 'loss_3': -16.048221588134766, 'loss_4': 0.2360999435186386, 'epoch': 7.61}
{'loss': 0.031, 'grad_norm': 12.99545955657959, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.020107826218008995, 'loss_2': 0.0109405517578125, 'loss_3': -15.946389198303223, 'loss_4': 0.41842806339263916, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 12:53:34,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:34,099 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:53<1:06:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:41,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.121037557721138, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.089, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.11618264019489288, 'eval_loss_2': 0.004854917526245117, 'eval_loss_3': -17.84648323059082, 'eval_loss_4': 0.821057140827179, 'epoch': 7.62}
{'loss': 0.0257, 'grad_norm': 8.208986282348633, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.024571411311626434, 'loss_2': 0.001171112060546875, 'loss_3': -15.774439811706543, 'loss_4': 1.0554137229919434, 'epoch': 7.62}
{'loss': 0.0148, 'grad_norm': 5.689911365509033, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.01351457741111517, 'loss_2': 0.001239776611328125, 'loss_3': -16.14981460571289, 'loss_4': 0.8405704498291016, 'epoch': 7.63}
{'loss': 0.0184, 'grad_norm': 5.540066242218018, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.009508122690021992, 'loss_2': 0.00888824462890625, 'loss_3': -15.972978591918945, 'loss_4': -0.12902967631816864, 'epoch': 7.63}
{'loss': 0.0189, 'grad_norm': 5.516070365905762, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.013242567889392376, 'loss_2': 0.00562286376953125, 'loss_3': -15.887645721435547, 'loss_4': 0.5998713374137878, 'epoch': 7.64}
{'loss': 0.0433, 'grad_norm': 12.33957576751709, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.03621390834450722, 'loss_2': 0.0070648193359375, 'loss_3': -15.761637687683105, 'loss_4': 0.4281662404537201, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 12:53:41,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:41,435 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [33:00<1:06:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:48,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.1584542691707611, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.108, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.1503947377204895, 'eval_loss_2': 0.008059561252593994, 'eval_loss_3': -17.767196655273438, 'eval_loss_4': 0.7864999175071716, 'epoch': 7.65}
{'loss': 0.087, 'grad_norm': 11.101481437683105, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.0773148238658905, 'loss_2': 0.0096435546875, 'loss_3': -15.739058494567871, 'loss_4': 0.684825599193573, 'epoch': 7.65}
{'loss': 0.0206, 'grad_norm': 5.735954761505127, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.008940069936215878, 'loss_2': 0.0117034912109375, 'loss_3': -15.964118957519531, 'loss_4': 0.18830828368663788, 'epoch': 7.66}
{'loss': 0.0135, 'grad_norm': 5.3933258056640625, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.008402915671467781, 'loss_2': 0.005096435546875, 'loss_3': -15.946564674377441, 'loss_4': 0.15420860052108765, 'epoch': 7.66}
{'loss': 0.0295, 'grad_norm': 14.137227058410645, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.021510526537895203, 'loss_2': 0.00799560546875, 'loss_3': -16.079679489135742, 'loss_4': 0.5656659603118896, 'epoch': 7.67}
{'loss': 0.017, 'grad_norm': 7.9589033126831055, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.009774735197424889, 'loss_2': 0.00727081298828125, 'loss_3': -16.145387649536133, 'loss_4': 0.5765925645828247, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 12:53:48,777 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:48,777 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [33:08<1:06:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:56,106 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04039628803730011, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.217, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.03677639365196228, 'eval_loss_2': 0.0036198943853378296, 'eval_loss_3': -18.003982543945312, 'eval_loss_4': 0.4486471712589264, 'epoch': 7.67}
{'loss': 0.0184, 'grad_norm': 6.224504470825195, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.014173267409205437, 'loss_2': 0.004184722900390625, 'loss_3': -16.059059143066406, 'loss_4': 0.4505789279937744, 'epoch': 7.68}
{'loss': 0.0276, 'grad_norm': 7.9993791580200195, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.02669786475598812, 'loss_2': 0.0008563995361328125, 'loss_3': -15.900083541870117, 'loss_4': 0.32141169905662537, 'epoch': 7.69}
{'loss': 0.0186, 'grad_norm': 6.744009494781494, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.016804775223135948, 'loss_2': 0.0017938613891601562, 'loss_3': -15.984085083007812, 'loss_4': 0.20824290812015533, 'epoch': 7.69}
{'loss': 0.041, 'grad_norm': 10.10667896270752, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.02740602381527424, 'loss_2': 0.013641357421875, 'loss_3': -16.095081329345703, 'loss_4': 0.7648642063140869, 'epoch': 7.7}
{'loss': 0.0635, 'grad_norm': 21.155376434326172, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.052389200776815414, 'loss_2': 0.011138916015625, 'loss_3': -15.931413650512695, 'loss_4': 0.7211002111434937, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 12:53:56,106 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:56,106 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:15<1:06:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:03,451 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01513088308274746, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.986, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.00967821292579174, 'eval_loss_2': 0.005452670156955719, 'eval_loss_3': -18.14961814880371, 'eval_loss_4': 0.7193804979324341, 'epoch': 7.7}
{'loss': 0.0289, 'grad_norm': 7.91666841506958, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.02015882357954979, 'loss_2': 0.00872802734375, 'loss_3': -16.13346290588379, 'loss_4': 0.9583487510681152, 'epoch': 7.71}
{'loss': 0.0208, 'grad_norm': 10.225361824035645, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.01763518713414669, 'loss_2': 0.0031833648681640625, 'loss_3': -15.915393829345703, 'loss_4': 0.8163094520568848, 'epoch': 7.72}
{'loss': 0.0148, 'grad_norm': 8.40158748626709, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.014439157210290432, 'loss_2': 0.0003161430358886719, 'loss_3': -16.150100708007812, 'loss_4': 0.9857523441314697, 'epoch': 7.72}
{'loss': 0.0313, 'grad_norm': 13.79169750213623, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.029803751036524773, 'loss_2': 0.00148773193359375, 'loss_3': -15.893409729003906, 'loss_4': 1.2691221237182617, 'epoch': 7.73}
{'loss': 0.0117, 'grad_norm': 6.132101535797119, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.011266568675637245, 'loss_2': 0.00038552284240722656, 'loss_3': -16.252124786376953, 'loss_4': 0.9767199754714966, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 12:54:03,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:03,451 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:22<1:06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:10,785 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015863019973039627, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.174, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010369022376835346, 'eval_loss_2': 0.0054939985275268555, 'eval_loss_3': -18.210506439208984, 'eval_loss_4': 0.9747443795204163, 'epoch': 7.73}
{'loss': 0.0705, 'grad_norm': 12.486123085021973, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.06279373914003372, 'loss_2': 0.007659912109375, 'loss_3': -15.987282752990723, 'loss_4': 0.7725057601928711, 'epoch': 7.74}
{'loss': 0.0328, 'grad_norm': 13.286314964294434, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.02572714537382126, 'loss_2': 0.0070953369140625, 'loss_3': -16.227705001831055, 'loss_4': 1.160497784614563, 'epoch': 7.74}
{'loss': 0.0272, 'grad_norm': 9.267598152160645, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.023656532168388367, 'loss_2': 0.0035190582275390625, 'loss_3': -16.094331741333008, 'loss_4': 1.3655922412872314, 'epoch': 7.75}
{'loss': 0.0149, 'grad_norm': 5.735645294189453, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.011289174668490887, 'loss_2': 0.003570556640625, 'loss_3': -16.075571060180664, 'loss_4': 1.032496452331543, 'epoch': 7.76}
{'loss': 0.0325, 'grad_norm': 10.992326736450195, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.024601513519883156, 'loss_2': 0.00788116455078125, 'loss_3': -16.04990005493164, 'loss_4': 1.741353988647461, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 12:54:10,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:10,785 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:30<1:06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:18,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01645876094698906, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.832, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012988579459488392, 'eval_loss_2': 0.003470182418823242, 'eval_loss_3': -18.206438064575195, 'eval_loss_4': 1.0530911684036255, 'epoch': 7.76}
{'loss': 0.0302, 'grad_norm': 9.8701753616333, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.024052299559116364, 'loss_2': 0.00618743896484375, 'loss_3': -16.01441764831543, 'loss_4': 0.8729363679885864, 'epoch': 7.77}
{'loss': 0.0196, 'grad_norm': 6.752452373504639, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.014801234938204288, 'loss_2': 0.004810333251953125, 'loss_3': -16.015703201293945, 'loss_4': 0.973993718624115, 'epoch': 7.77}
{'loss': 0.0209, 'grad_norm': 8.7634859085083, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.017001917585730553, 'loss_2': 0.00385284423828125, 'loss_3': -15.893818855285645, 'loss_4': 0.8529095649719238, 'epoch': 7.78}
{'loss': 0.0226, 'grad_norm': 9.203741073608398, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.018919669091701508, 'loss_2': 0.0036773681640625, 'loss_3': -15.993127822875977, 'loss_4': 0.9362553358078003, 'epoch': 7.78}
{'loss': 0.0123, 'grad_norm': 6.170229911804199, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.012232567183673382, 'loss_2': 5.805492401123047e-05, 'loss_3': -16.192577362060547, 'loss_4': 0.9985731840133667, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 12:54:18,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:18,125 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:37<1:06:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:25,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013095785863697529, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.281, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009732131846249104, 'eval_loss_2': 0.0033636540174484253, 'eval_loss_3': -18.201549530029297, 'eval_loss_4': 0.6946481466293335, 'epoch': 7.79}
{'loss': 0.0248, 'grad_norm': 10.531515121459961, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.02398844249546528, 'loss_2': 0.000858306884765625, 'loss_3': -16.09856414794922, 'loss_4': 0.9179491996765137, 'epoch': 7.8}
{'loss': 0.0413, 'grad_norm': 22.894210815429688, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.04056302085518837, 'loss_2': 0.000782012939453125, 'loss_3': -16.151336669921875, 'loss_4': 0.6547132730484009, 'epoch': 7.8}
{'loss': 0.0317, 'grad_norm': 9.536985397338867, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.025306202471256256, 'loss_2': 0.0063629150390625, 'loss_3': -15.976054191589355, 'loss_4': 0.5308864712715149, 'epoch': 7.81}
{'loss': 0.0135, 'grad_norm': 5.402243614196777, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.007868465036153793, 'loss_2': 0.0056304931640625, 'loss_3': -16.166912078857422, 'loss_4': 0.5776777267456055, 'epoch': 7.81}
{'loss': 0.0198, 'grad_norm': 7.374595642089844, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.013468393124639988, 'loss_2': 0.006317138671875, 'loss_3': -16.448440551757812, 'loss_4': 0.4573557376861572, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 12:54:25,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:25,477 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:41<1:06:02,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:54:29,271 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1345
[INFO|configuration_utils.py:420] 2025-01-21 12:54:29,272 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1345/config.json                                                                            
{'eval_loss': 0.011734645813703537, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.974, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.007904747501015663, 'eval_loss_2': 0.0038298964500427246, 'eval_loss_3': -18.196945190429688, 'eval_loss_4': 0.21010558307170868, 'epoch': 7.82}
[INFO|modeling_utils.py:2988] 2025-01-21 12:54:29,746 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1345/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:54:29,747 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1345/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:54:29,747 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1345/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:54:30,581 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1290] due to args.save_total_limit
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:46<1:12:13,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:54:34,209 >>
{'loss': 0.0391, 'grad_norm': 12.159311294555664, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.03674202412366867, 'loss_2': 0.0023345947265625, 'loss_3': -16.017032623291016, 'loss_4': 0.028747081756591797, 'epoch': 7.83}
{'loss': 0.0247, 'grad_norm': 5.846115589141846, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.016486864537000656, 'loss_2': 0.00824737548828125, 'loss_3': -16.063854217529297, 'loss_4': 0.2729014754295349, 'epoch': 7.83}
{'loss': 0.0276, 'grad_norm': 9.98498821258545, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.024818163365125656, 'loss_2': 0.002735137939453125, 'loss_3': -16.288644790649414, 'loss_4': -0.055714309215545654, 'epoch': 7.84}
{'loss': 0.0225, 'grad_norm': 7.531787872314453, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.017291028052568436, 'loss_2': 0.00524139404296875, 'loss_3': -16.366117477416992, 'loss_4': -0.14404961466789246, 'epoch': 7.84}
{'loss': 0.0206, 'grad_norm': 7.274676322937012, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.019042419269680977, 'loss_2': 0.0015230178833007812, 'loss_3': -15.979594230651855, 'loss_4': 0.1508447229862213, 'epoch': 7.85}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:54:34,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:34,209 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:53<1:06:47,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:54:41,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012349129654467106, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.964, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008848736062645912, 'eval_loss_2': 0.0035003945231437683, 'eval_loss_3': -18.232982635498047, 'eval_loss_4': 0.13504692912101746, 'epoch': 7.85}
{'loss': 0.0146, 'grad_norm': 5.706822872161865, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.009059096686542034, 'loss_2': 0.0055084228515625, 'loss_3': -16.451017379760742, 'loss_4': -0.12667012214660645, 'epoch': 7.85}
{'loss': 0.0259, 'grad_norm': 7.82411003112793, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.018792053684592247, 'loss_2': 0.00714874267578125, 'loss_3': -16.239782333374023, 'loss_4': 0.2538038492202759, 'epoch': 7.86}
{'loss': 0.0226, 'grad_norm': 6.302478790283203, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.011106757447123528, 'loss_2': 0.0114593505859375, 'loss_3': -16.216808319091797, 'loss_4': 0.2687793970108032, 'epoch': 7.87}
{'loss': 0.0593, 'grad_norm': 27.862768173217773, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.04966830834746361, 'loss_2': 0.00960540771484375, 'loss_3': -16.369508743286133, 'loss_4': 0.5561150312423706, 'epoch': 7.87}
{'loss': 0.03, 'grad_norm': 9.76708698272705, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.018564630299806595, 'loss_2': 0.011474609375, 'loss_3': -16.295425415039062, 'loss_4': 0.3702890872955322, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 12:54:41,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:41,541 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:57<1:06:47,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 12:54:45,330 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1355
[INFO|configuration_utils.py:420] 2025-01-21 12:54:45,331 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1355/config.json                                                                            
{'eval_loss': 0.011702654883265495, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.381, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.00898426491767168, 'eval_loss_2': 0.0027183890342712402, 'eval_loss_3': -18.229068756103516, 'eval_loss_4': 0.4921705424785614, 'epoch': 7.88}
[INFO|modeling_utils.py:2988] 2025-01-21 12:54:45,817 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1355/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:54:45,818 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1355/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:54:45,818 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1355/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:54:46,666 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1345] due to args.save_total_limit
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [34:02<1:12:17,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:54:50,297 >>
{'loss': 0.0198, 'grad_norm': 8.843683242797852, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.01865905523300171, 'loss_2': 0.0010967254638671875, 'loss_3': -16.21734619140625, 'loss_4': 0.46595633029937744, 'epoch': 7.88}
{'loss': 0.0124, 'grad_norm': 5.465285778045654, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.009479288943111897, 'loss_2': 0.0028934478759765625, 'loss_3': -16.298532485961914, 'loss_4': 0.622344434261322, 'epoch': 7.89}
{'loss': 0.0191, 'grad_norm': 6.591822147369385, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.014756877906620502, 'loss_2': 0.004314422607421875, 'loss_3': -16.102468490600586, 'loss_4': 0.7450221180915833, 'epoch': 7.9}
{'loss': 0.0204, 'grad_norm': 5.766686916351318, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.01360712107270956, 'loss_2': 0.006793975830078125, 'loss_3': -16.274547576904297, 'loss_4': 0.7724523544311523, 'epoch': 7.9}
{'loss': 0.0165, 'grad_norm': 7.436338901519775, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.013314872980117798, 'loss_2': 0.003223419189453125, 'loss_3': -16.35350799560547, 'loss_4': 0.5280165672302246, 'epoch': 7.91}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:54:50,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:50,298 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [34:09<1:06:39,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:54:57,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011888718232512474, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.472, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.008640981279313564, 'eval_loss_2': 0.0032477378845214844, 'eval_loss_3': -18.22406005859375, 'eval_loss_4': 0.5765562057495117, 'epoch': 7.91}
{'loss': 0.015, 'grad_norm': 6.447325229644775, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.013983084820210934, 'loss_2': 0.0010318756103515625, 'loss_3': -16.09470558166504, 'loss_4': 0.8321303129196167, 'epoch': 7.91}
{'loss': 0.0399, 'grad_norm': 14.392271995544434, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.037624578922986984, 'loss_2': 0.0023040771484375, 'loss_3': -16.219562530517578, 'loss_4': 0.9486521482467651, 'epoch': 7.92}
{'loss': 0.0377, 'grad_norm': 12.37592887878418, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.027631405740976334, 'loss_2': 0.01007080078125, 'loss_3': -16.127147674560547, 'loss_4': 0.2651463747024536, 'epoch': 7.92}
{'loss': 0.0175, 'grad_norm': 5.992018699645996, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.010284549556672573, 'loss_2': 0.0072174072265625, 'loss_3': -16.283931732177734, 'loss_4': 0.9066973924636841, 'epoch': 7.93}
{'loss': 0.0277, 'grad_norm': 6.879204273223877, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.015562230721116066, 'loss_2': 0.01215362548828125, 'loss_3': -16.124496459960938, 'loss_4': 0.5067477226257324, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 12:54:57,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:57,628 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [34:13<1:06:39,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 12:55:01,445 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1365
[INFO|configuration_utils.py:420] 2025-01-21 12:55:01,447 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1365/config.json                                                                            
{'eval_loss': 0.011386265978217125, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.313, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008815070614218712, 'eval_loss_2': 0.002571195363998413, 'eval_loss_3': -18.18085479736328, 'eval_loss_4': 0.47396647930145264, 'epoch': 7.94}
[INFO|modeling_utils.py:2988] 2025-01-21 12:55:01,933 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1365/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:55:01,934 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1365/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:55:01,934 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1365/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:55:02,767 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1355] due to args.save_total_limit
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:18<1:12:08,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 12:55:06,391 >>
{'loss': 0.0123, 'grad_norm': 6.211463928222656, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.011072409339249134, 'loss_2': 0.0011777877807617188, 'loss_3': -16.084453582763672, 'loss_4': 0.8797327280044556, 'epoch': 7.94}
{'loss': 0.028, 'grad_norm': 15.396568298339844, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.022693416103720665, 'loss_2': 0.0053253173828125, 'loss_3': -16.072677612304688, 'loss_4': 0.1780490279197693, 'epoch': 7.95}
{'loss': 0.0259, 'grad_norm': 13.439008712768555, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.02480595000088215, 'loss_2': 0.00110626220703125, 'loss_3': -16.527992248535156, 'loss_4': 0.2968084216117859, 'epoch': 7.95}
{'loss': 0.0334, 'grad_norm': 10.597369194030762, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.024238429963588715, 'loss_2': 0.009124755859375, 'loss_3': -16.015214920043945, 'loss_4': 0.28576022386550903, 'epoch': 7.96}
{'loss': 0.0234, 'grad_norm': 8.363462448120117, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.02325497753918171, 'loss_2': 0.00016641616821289062, 'loss_3': -16.229001998901367, 'loss_4': 0.23921366035938263, 'epoch': 7.97}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:55:06,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:06,391 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:22<1:12:08,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 12:55:10,181 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1370
[INFO|configuration_utils.py:420] 2025-01-21 12:55:10,182 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1370/config.json                                                                            
{'eval_loss': 0.009650643914937973, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.381, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.007178634870797396, 'eval_loss_2': 0.0024720095098018646, 'eval_loss_3': -18.169984817504883, 'eval_loss_4': 0.11806853860616684, 'epoch': 7.97}
[INFO|modeling_utils.py:2988] 2025-01-21 12:55:10,669 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1370/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:55:10,670 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1370/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:55:10,670 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1370/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:55:11,513 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1365] due to args.save_total_limit
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:27<1:12:35,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:55:15,129 >>
{'loss': 0.0173, 'grad_norm': 6.51793098449707, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.01150088757276535, 'loss_2': 0.005767822265625, 'loss_3': -16.168752670288086, 'loss_4': -0.29463255405426025, 'epoch': 7.97}
{'loss': 0.0142, 'grad_norm': 6.2205376625061035, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.012058313004672527, 'loss_2': 0.00212860107421875, 'loss_3': -16.240894317626953, 'loss_4': 0.07651352882385254, 'epoch': 7.98}
{'loss': 0.0194, 'grad_norm': 9.279718399047852, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.01878075674176216, 'loss_2': 0.0006079673767089844, 'loss_3': -16.276805877685547, 'loss_4': 0.04152749478816986, 'epoch': 7.98}
{'loss': 0.0235, 'grad_norm': 9.166178703308105, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.018446501344442368, 'loss_2': 0.00502777099609375, 'loss_3': -15.974028587341309, 'loss_4': 0.5596907734870911, 'epoch': 7.99}
{'loss': 0.0247, 'grad_norm': 8.777763366699219, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.01883733458817005, 'loss_2': 0.00589752197265625, 'loss_3': -16.41222381591797, 'loss_4': -0.012121617794036865, 'epoch': 7.99}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:55:15,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:15,129 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:34<1:05:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:22,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011266915127635002, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.051, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0070086997002363205, 'eval_loss_2': 0.004258215427398682, 'eval_loss_3': -18.145313262939453, 'eval_loss_4': 0.10984674841165543, 'epoch': 7.99}
{'loss': 0.0187, 'grad_norm': 7.462347507476807, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.010126824490725994, 'loss_2': 0.0085601806640625, 'loss_3': -16.276737213134766, 'loss_4': -0.3837132751941681, 'epoch': 8.0}
{'loss': 0.0131, 'grad_norm': 5.384638786315918, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.006931483745574951, 'loss_2': 0.0061187744140625, 'loss_3': -16.338973999023438, 'loss_4': 0.260746031999588, 'epoch': 8.01}
{'loss': 0.0246, 'grad_norm': 10.604171752929688, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.021630635485053062, 'loss_2': 0.003002166748046875, 'loss_3': -16.268585205078125, 'loss_4': -0.0881146639585495, 'epoch': 8.01}
{'loss': 0.019, 'grad_norm': 7.937409400939941, 'learning_rate': 2.2e-05, 'loss_1': 0.012516462244093418, 'loss_2': 0.006500244140625, 'loss_3': -16.172386169433594, 'loss_4': 0.3042789697647095, 'epoch': 8.02}
{'loss': 0.0465, 'grad_norm': 16.443801879882812, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.03633404150605202, 'loss_2': 0.01013946533203125, 'loss_3': -16.244586944580078, 'loss_4': 0.1990225911140442, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 12:55:22,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:22,168 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:41<1:05:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:29,494 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013266850262880325, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.455, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.007606077939271927, 'eval_loss_2': 0.0056607723236083984, 'eval_loss_3': -18.155227661132812, 'eval_loss_4': 0.06499974429607391, 'epoch': 8.02}
{'loss': 0.0178, 'grad_norm': 5.224637508392334, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.00952609907835722, 'loss_2': 0.00830078125, 'loss_3': -15.96342658996582, 'loss_4': -0.284390926361084, 'epoch': 8.03}
{'loss': 0.028, 'grad_norm': 7.838140964508057, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.013743839226663113, 'loss_2': 0.0142822265625, 'loss_3': -15.979722023010254, 'loss_4': -0.03256203234195709, 'epoch': 8.03}
{'loss': 0.0188, 'grad_norm': 9.101465225219727, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.018428543582558632, 'loss_2': 0.0004100799560546875, 'loss_3': -16.122360229492188, 'loss_4': 0.23944410681724548, 'epoch': 8.04}
{'loss': 0.0156, 'grad_norm': 6.478224277496338, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.013079021126031876, 'loss_2': 0.002483367919921875, 'loss_3': -16.326683044433594, 'loss_4': 0.42334461212158203, 'epoch': 8.05}
{'loss': 0.0158, 'grad_norm': 5.875340461730957, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.014911599457263947, 'loss_2': 0.0009355545043945312, 'loss_3': -16.297941207885742, 'loss_4': 0.053876396268606186, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 12:55:29,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:29,495 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:48<1:05:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:36,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010889610275626183, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.305, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.007948234677314758, 'eval_loss_2': 0.0029413774609565735, 'eval_loss_3': -18.190845489501953, 'eval_loss_4': 0.047246430069208145, 'epoch': 8.05}
{'loss': 0.0216, 'grad_norm': 7.064731121063232, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.016123486682772636, 'loss_2': 0.00550079345703125, 'loss_3': -16.129053115844727, 'loss_4': -0.40010973811149597, 'epoch': 8.06}
{'loss': 0.0121, 'grad_norm': 5.081803798675537, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.008881160989403725, 'loss_2': 0.0032329559326171875, 'loss_3': -16.14027976989746, 'loss_4': -0.08935534954071045, 'epoch': 8.06}
{'loss': 0.0258, 'grad_norm': 17.861589431762695, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.02360018528997898, 'loss_2': 0.002178192138671875, 'loss_3': -16.300134658813477, 'loss_4': 0.25664690136909485, 'epoch': 8.07}
{'loss': 0.0118, 'grad_norm': 5.779435157775879, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.009531847201287746, 'loss_2': 0.002239227294921875, 'loss_3': -16.293743133544922, 'loss_4': 0.38437706232070923, 'epoch': 8.08}
{'loss': 0.0087, 'grad_norm': 5.646777153015137, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.00801176019012928, 'loss_2': 0.0007042884826660156, 'loss_3': -16.423858642578125, 'loss_4': -0.11334560066461563, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 12:55:36,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:36,821 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:56<1:05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:44,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010411316528916359, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.672, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007291177287697792, 'eval_loss_2': 0.003120139241218567, 'eval_loss_3': -18.232229232788086, 'eval_loss_4': 0.09448809176683426, 'epoch': 8.08}
{'loss': 0.0313, 'grad_norm': 16.716976165771484, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.030742844566702843, 'loss_2': 0.000514984130859375, 'loss_3': -16.261642456054688, 'loss_4': -0.04508703574538231, 'epoch': 8.09}
{'loss': 0.0185, 'grad_norm': 9.557157516479492, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.014708139933645725, 'loss_2': 0.0037994384765625, 'loss_3': -16.21224594116211, 'loss_4': -0.24028241634368896, 'epoch': 8.09}
{'loss': 0.0128, 'grad_norm': 5.784134864807129, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.010473636910319328, 'loss_2': 0.002307891845703125, 'loss_3': -16.312713623046875, 'loss_4': 0.4121849834918976, 'epoch': 8.1}
{'loss': 0.0136, 'grad_norm': 5.513024806976318, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.009887752123177052, 'loss_2': 0.0037136077880859375, 'loss_3': -16.188888549804688, 'loss_4': 0.0718352347612381, 'epoch': 8.1}
{'loss': 0.0231, 'grad_norm': 11.695640563964844, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.021860534325242043, 'loss_2': 0.001201629638671875, 'loss_3': -16.105403900146484, 'loss_4': -0.2984945774078369, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 12:55:44,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:44,174 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [35:03<1:04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:51,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012176621705293655, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.245, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.007848795503377914, 'eval_loss_2': 0.004327826201915741, 'eval_loss_3': -18.279788970947266, 'eval_loss_4': 0.08086418360471725, 'epoch': 8.11}
{'loss': 0.0275, 'grad_norm': 6.854971408843994, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.019646985456347466, 'loss_2': 0.007843017578125, 'loss_3': -16.338586807250977, 'loss_4': 0.2680787444114685, 'epoch': 8.12}
{'loss': 0.0181, 'grad_norm': 5.3860039710998535, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.010736936703324318, 'loss_2': 0.00733184814453125, 'loss_3': -16.172517776489258, 'loss_4': 0.1164865642786026, 'epoch': 8.12}
{'loss': 0.0156, 'grad_norm': 6.39863395690918, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.013654458336532116, 'loss_2': 0.00196075439453125, 'loss_3': -16.280902862548828, 'loss_4': -0.007209591567516327, 'epoch': 8.13}
{'loss': 0.0211, 'grad_norm': 9.280618667602539, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.017746174708008766, 'loss_2': 0.003326416015625, 'loss_3': -16.256298065185547, 'loss_4': 0.1968032717704773, 'epoch': 8.13}
{'loss': 0.0144, 'grad_norm': 5.06746244430542, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.009518653154373169, 'loss_2': 0.00490570068359375, 'loss_3': -16.433740615844727, 'loss_4': 0.3159326910972595, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 12:55:51,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:51,507 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [35:10<1:04:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:58,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013199657201766968, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.196, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.008678704500198364, 'eval_loss_2': 0.0045209527015686035, 'eval_loss_3': -18.289566040039062, 'eval_loss_4': 0.08351944386959076, 'epoch': 8.14}
{'loss': 0.0279, 'grad_norm': 10.428524017333984, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.01805632747709751, 'loss_2': 0.0098724365234375, 'loss_3': -16.209842681884766, 'loss_4': -0.05086423084139824, 'epoch': 8.15}
{'loss': 0.0106, 'grad_norm': 6.098992824554443, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.0101518789306283, 'loss_2': 0.00041604042053222656, 'loss_3': -16.250457763671875, 'loss_4': 0.4285428822040558, 'epoch': 8.15}
{'loss': 0.0341, 'grad_norm': 12.027139663696289, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.026463404297828674, 'loss_2': 0.007625579833984375, 'loss_3': -16.422008514404297, 'loss_4': -0.15649548172950745, 'epoch': 8.16}
{'loss': 0.0113, 'grad_norm': 4.972439289093018, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.005572822410613298, 'loss_2': 0.005702972412109375, 'loss_3': -16.2808895111084, 'loss_4': 0.004456333816051483, 'epoch': 8.16}
{'loss': 0.0212, 'grad_norm': 6.167243957519531, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.01217871718108654, 'loss_2': 0.00902557373046875, 'loss_3': -16.446121215820312, 'loss_4': -0.4877204895019531, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 12:55:58,840 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:58,840 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [35:18<1:04:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:06,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01678735576570034, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.153, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.009100326336920261, 'eval_loss_2': 0.007687032222747803, 'eval_loss_3': -18.27581787109375, 'eval_loss_4': 0.0040275235660374165, 'epoch': 8.17}
{'loss': 0.0124, 'grad_norm': 5.108789920806885, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.007609949912875891, 'loss_2': 0.00479888916015625, 'loss_3': -16.212318420410156, 'loss_4': -0.30631959438323975, 'epoch': 8.17}
{'loss': 0.0194, 'grad_norm': 9.811591148376465, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.01885807514190674, 'loss_2': 0.000545501708984375, 'loss_3': -16.184715270996094, 'loss_4': 0.034503862261772156, 'epoch': 8.18}
{'loss': 0.0222, 'grad_norm': 5.526317596435547, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.00991438515484333, 'loss_2': 0.01224517822265625, 'loss_3': -16.501447677612305, 'loss_4': 0.19359378516674042, 'epoch': 8.19}
{'loss': 0.0165, 'grad_norm': 5.309953689575195, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.013123693875968456, 'loss_2': 0.0033626556396484375, 'loss_3': -16.41143035888672, 'loss_4': -0.18453729152679443, 'epoch': 8.19}
{'loss': 0.023, 'grad_norm': 7.217150688171387, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.018443914130330086, 'loss_2': 0.00457763671875, 'loss_3': -16.204036712646484, 'loss_4': 0.21753907203674316, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 12:56:06,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:06,169 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:25<1:04:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:13,510 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016106348484754562, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.774, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007844069972634315, 'eval_loss_2': 0.008262276649475098, 'eval_loss_3': -18.26746368408203, 'eval_loss_4': -0.029434990137815475, 'epoch': 8.2}
{'loss': 0.0206, 'grad_norm': 6.316845417022705, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.012547971680760384, 'loss_2': 0.008056640625, 'loss_3': -16.310604095458984, 'loss_4': -0.14993542432785034, 'epoch': 8.2}
{'loss': 0.0196, 'grad_norm': 7.546221733093262, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.014227381907403469, 'loss_2': 0.005344390869140625, 'loss_3': -16.120336532592773, 'loss_4': -0.10784904658794403, 'epoch': 8.21}
{'loss': 0.0307, 'grad_norm': 11.386147499084473, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.02307307906448841, 'loss_2': 0.00762939453125, 'loss_3': -16.146217346191406, 'loss_4': -0.12417765706777573, 'epoch': 8.22}
{'loss': 0.0216, 'grad_norm': 7.0264081954956055, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.010359907522797585, 'loss_2': 0.0112762451171875, 'loss_3': -16.348783493041992, 'loss_4': -0.12716272473335266, 'epoch': 8.22}
{'loss': 0.0195, 'grad_norm': 5.552832126617432, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.010769565589725971, 'loss_2': 0.0087127685546875, 'loss_3': -16.36456298828125, 'loss_4': 0.07404780387878418, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 12:56:13,510 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:13,510 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:32<1:04:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:20,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015473795123398304, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00886685959994793, 'eval_loss_2': 0.006606936454772949, 'eval_loss_3': -18.21294403076172, 'eval_loss_4': 0.08805418014526367, 'epoch': 8.23}
{'loss': 0.0296, 'grad_norm': 9.372016906738281, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.02153843268752098, 'loss_2': 0.00806427001953125, 'loss_3': -16.125946044921875, 'loss_4': -0.18708306550979614, 'epoch': 8.23}
{'loss': 0.0291, 'grad_norm': 12.611745834350586, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.024943450465798378, 'loss_2': 0.0041656494140625, 'loss_3': -16.208175659179688, 'loss_4': 0.5390899181365967, 'epoch': 8.24}
{'loss': 0.0118, 'grad_norm': 5.995879173278809, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.007879991084337234, 'loss_2': 0.0039520263671875, 'loss_3': -16.320030212402344, 'loss_4': 0.008539851754903793, 'epoch': 8.24}
{'loss': 0.0135, 'grad_norm': 6.141133785247803, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.012432328425347805, 'loss_2': 0.0010662078857421875, 'loss_3': -16.211305618286133, 'loss_4': 0.0444527342915535, 'epoch': 8.25}
{'loss': 0.0283, 'grad_norm': 7.36081600189209, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.021307937800884247, 'loss_2': 0.00696563720703125, 'loss_3': -16.183475494384766, 'loss_4': 0.0768609344959259, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 12:56:20,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:20,858 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:40<1:04:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:28,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016889693215489388, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009908320382237434, 'eval_loss_2': 0.006981372833251953, 'eval_loss_3': -18.16970443725586, 'eval_loss_4': 0.3488423526287079, 'epoch': 8.26}
{'loss': 0.0534, 'grad_norm': 18.778305053710938, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.043319981545209885, 'loss_2': 0.01007843017578125, 'loss_3': -16.120853424072266, 'loss_4': -0.07886701822280884, 'epoch': 8.26}
{'loss': 0.0473, 'grad_norm': 15.850760459899902, 'learning_rate': 2.175e-05, 'loss_1': 0.042433962225914, 'loss_2': 0.0048675537109375, 'loss_3': -16.39069366455078, 'loss_4': 0.43364858627319336, 'epoch': 8.27}
{'loss': 0.0541, 'grad_norm': 18.047340393066406, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.041628964245319366, 'loss_2': 0.0124359130859375, 'loss_3': -16.237306594848633, 'loss_4': 0.8798564672470093, 'epoch': 8.27}
{'loss': 0.0292, 'grad_norm': 5.588046550750732, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.015432048588991165, 'loss_2': 0.0137786865234375, 'loss_3': -16.364147186279297, 'loss_4': 0.5752668976783752, 'epoch': 8.28}
{'loss': 0.0134, 'grad_norm': 4.826249122619629, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.0081283925101161, 'loss_2': 0.00530242919921875, 'loss_3': -16.21973991394043, 'loss_4': 0.23503652215003967, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 12:56:28,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:28,206 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:47<1:04:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:35,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017704926431179047, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.176, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011038845404982567, 'eval_loss_2': 0.006666079163551331, 'eval_loss_3': -18.169761657714844, 'eval_loss_4': 0.45932406187057495, 'epoch': 8.28}
{'loss': 0.0455, 'grad_norm': 12.433099746704102, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.029835060238838196, 'loss_2': 0.0156402587890625, 'loss_3': -16.194385528564453, 'loss_4': 0.3868386149406433, 'epoch': 8.29}
{'loss': 0.0229, 'grad_norm': 9.1087007522583, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.01803087629377842, 'loss_2': 0.00490570068359375, 'loss_3': -16.195430755615234, 'loss_4': 0.42297786474227905, 'epoch': 8.3}
{'loss': 0.0191, 'grad_norm': 6.235165596008301, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.015978224575519562, 'loss_2': 0.0030803680419921875, 'loss_3': -16.19226837158203, 'loss_4': 0.42187929153442383, 'epoch': 8.3}
{'loss': 0.0476, 'grad_norm': 19.986000061035156, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.03883040323853493, 'loss_2': 0.0088043212890625, 'loss_3': -16.241710662841797, 'loss_4': 1.0835233926773071, 'epoch': 8.31}
{'loss': 0.0118, 'grad_norm': 5.392831325531006, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.00833678524941206, 'loss_2': 0.0034694671630859375, 'loss_3': -16.215164184570312, 'loss_4': 0.2878933548927307, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 12:56:35,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:35,553 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:54<1:04:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:42,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015060734003782272, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011099923402071, 'eval_loss_2': 0.003960810601711273, 'eval_loss_3': -18.158611297607422, 'eval_loss_4': 0.6134378910064697, 'epoch': 8.31}
{'loss': 0.0201, 'grad_norm': 6.924890518188477, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.01390884444117546, 'loss_2': 0.006195068359375, 'loss_3': -16.27118682861328, 'loss_4': 0.48977726697921753, 'epoch': 8.32}
{'loss': 0.0423, 'grad_norm': 20.492050170898438, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.030061066150665283, 'loss_2': 0.01226043701171875, 'loss_3': -16.0798282623291, 'loss_4': 0.4817323684692383, 'epoch': 8.33}
{'loss': 0.0118, 'grad_norm': 5.380930423736572, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.011515547521412373, 'loss_2': 0.0002663135528564453, 'loss_3': -16.03589630126953, 'loss_4': 0.5460733771324158, 'epoch': 8.33}
{'loss': 0.0242, 'grad_norm': 6.750398635864258, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.01428982149809599, 'loss_2': 0.00992584228515625, 'loss_3': -16.000415802001953, 'loss_4': 0.42637985944747925, 'epoch': 8.34}
{'loss': 0.0308, 'grad_norm': 11.60382080078125, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.029490375891327858, 'loss_2': 0.0013103485107421875, 'loss_3': -16.228055953979492, 'loss_4': 0.4240149259567261, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 12:56:42,894 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:42,894 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [36:02<1:04:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:50,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01485077291727066, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.884, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010630800388753414, 'eval_loss_2': 0.004219971597194672, 'eval_loss_3': -18.145444869995117, 'eval_loss_4': 0.7415726184844971, 'epoch': 8.34}
{'loss': 0.0249, 'grad_norm': 10.179224014282227, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.020618608221411705, 'loss_2': 0.00423431396484375, 'loss_3': -16.119609832763672, 'loss_4': 0.5926070213317871, 'epoch': 8.35}
{'loss': 0.0173, 'grad_norm': 5.23296594619751, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.007988759316504002, 'loss_2': 0.00928497314453125, 'loss_3': -16.293434143066406, 'loss_4': 0.39512020349502563, 'epoch': 8.35}
{'loss': 0.0342, 'grad_norm': 15.707623481750488, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.034079764038324356, 'loss_2': 0.00014662742614746094, 'loss_3': -15.867071151733398, 'loss_4': 0.39288628101348877, 'epoch': 8.36}
{'loss': 0.016, 'grad_norm': 6.56096887588501, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.015305092558264732, 'loss_2': 0.0006513595581054688, 'loss_3': -16.14551544189453, 'loss_4': 1.0338236093521118, 'epoch': 8.37}
{'loss': 0.0164, 'grad_norm': 5.938793659210205, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.015630019828677177, 'loss_2': 0.0007257461547851562, 'loss_3': -16.313899993896484, 'loss_4': 0.6348042488098145, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 12:56:50,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:50,229 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [36:09<1:04:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:57,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016547245904803276, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.998, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011535098776221275, 'eval_loss_2': 0.005012147128582001, 'eval_loss_3': -18.16090202331543, 'eval_loss_4': 0.5137437582015991, 'epoch': 8.37}
{'loss': 0.0249, 'grad_norm': 7.701752662658691, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.02046114020049572, 'loss_2': 0.004425048828125, 'loss_3': -16.15715217590332, 'loss_4': 0.16714897751808167, 'epoch': 8.38}
{'loss': 0.0129, 'grad_norm': 5.691559791564941, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.011611645109951496, 'loss_2': 0.0012502670288085938, 'loss_3': -16.12868881225586, 'loss_4': 0.24246519804000854, 'epoch': 8.38}
{'loss': 0.0146, 'grad_norm': 5.582948684692383, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.01121074054390192, 'loss_2': 0.0033893585205078125, 'loss_3': -16.080989837646484, 'loss_4': 0.33331143856048584, 'epoch': 8.39}
{'loss': 0.0334, 'grad_norm': 11.01887035369873, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.026089094579219818, 'loss_2': 0.0073394775390625, 'loss_3': -16.113170623779297, 'loss_4': 0.14536899328231812, 'epoch': 8.4}
{'loss': 0.0141, 'grad_norm': 4.841053009033203, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.008713103830814362, 'loss_2': 0.005359649658203125, 'loss_3': -16.366682052612305, 'loss_4': -0.5230298638343811, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 12:56:57,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:57,560 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:16<1:04:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:04,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014013005420565605, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.172, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0107907485216856, 'eval_loss_2': 0.003222256898880005, 'eval_loss_3': -18.193340301513672, 'eval_loss_4': 0.048059042543172836, 'epoch': 8.4}
{'loss': 0.0269, 'grad_norm': 9.803244590759277, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.02343607321381569, 'loss_2': 0.0034332275390625, 'loss_3': -16.10437774658203, 'loss_4': 0.06739696860313416, 'epoch': 8.41}
{'loss': 0.0233, 'grad_norm': 8.863129615783691, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.018215304240584373, 'loss_2': 0.005046844482421875, 'loss_3': -16.21207046508789, 'loss_4': -0.1743212193250656, 'epoch': 8.41}
{'loss': 0.0214, 'grad_norm': 6.204639434814453, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.012939284555613995, 'loss_2': 0.0084686279296875, 'loss_3': -16.075469970703125, 'loss_4': 0.010050803422927856, 'epoch': 8.42}
{'loss': 0.0284, 'grad_norm': 11.304045677185059, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.022163718938827515, 'loss_2': 0.006275177001953125, 'loss_3': -16.130664825439453, 'loss_4': -0.2991645336151123, 'epoch': 8.42}
{'loss': 0.0191, 'grad_norm': 7.186278343200684, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.016972115263342857, 'loss_2': 0.0020809173583984375, 'loss_3': -16.27845001220703, 'loss_4': -0.020706504583358765, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 12:57:04,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:04,903 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:24<1:03:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:12,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014802437275648117, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.876, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010895295068621635, 'eval_loss_2': 0.003907144069671631, 'eval_loss_3': -18.212656021118164, 'eval_loss_4': -0.43249210715293884, 'epoch': 8.43}
{'loss': 0.0236, 'grad_norm': 6.77063512802124, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.014217435382306576, 'loss_2': 0.0093841552734375, 'loss_3': -16.2961483001709, 'loss_4': -0.24712629616260529, 'epoch': 8.44}
{'loss': 0.021, 'grad_norm': 7.255812168121338, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.01843523234128952, 'loss_2': 0.002593994140625, 'loss_3': -16.055774688720703, 'loss_4': -0.7399547100067139, 'epoch': 8.44}
{'loss': 0.0236, 'grad_norm': 7.239021301269531, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.016469575464725494, 'loss_2': 0.007171630859375, 'loss_3': -16.18878936767578, 'loss_4': -0.75830078125, 'epoch': 8.45}
{'loss': 0.016, 'grad_norm': 5.08626651763916, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.01045182254165411, 'loss_2': 0.005584716796875, 'loss_3': -16.298946380615234, 'loss_4': -0.7419083714485168, 'epoch': 8.45}
{'loss': 0.018, 'grad_norm': 5.075901985168457, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.009111062623560429, 'loss_2': 0.0088653564453125, 'loss_3': -16.16588592529297, 'loss_4': -0.9547384977340698, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 12:57:12,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:12,235 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:31<1:03:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:19,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014405792579054832, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.925, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010445929132401943, 'eval_loss_2': 0.003959864377975464, 'eval_loss_3': -18.22203826904297, 'eval_loss_4': -0.7706006169319153, 'epoch': 8.46}
{'loss': 0.0222, 'grad_norm': 7.0209455490112305, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.019317321479320526, 'loss_2': 0.00286102294921875, 'loss_3': -16.186954498291016, 'loss_4': -0.8110105991363525, 'epoch': 8.47}
{'loss': 0.0328, 'grad_norm': 8.686127662658691, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.027359046041965485, 'loss_2': 0.0054168701171875, 'loss_3': -15.9344482421875, 'loss_4': -0.7456443309783936, 'epoch': 8.47}
{'loss': 0.0193, 'grad_norm': 5.676732063293457, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.011424868367612362, 'loss_2': 0.0079193115234375, 'loss_3': -16.28276824951172, 'loss_4': -0.9687004089355469, 'epoch': 8.48}
{'loss': 0.0157, 'grad_norm': 7.382652759552002, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.012703667394816875, 'loss_2': 0.0030059814453125, 'loss_3': -16.325902938842773, 'loss_4': -0.8171577453613281, 'epoch': 8.48}
{'loss': 0.0286, 'grad_norm': 6.528664588928223, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.018737059086561203, 'loss_2': 0.0098724365234375, 'loss_3': -16.182239532470703, 'loss_4': -0.9858908653259277, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 12:57:19,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:19,574 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:38<1:03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:26,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01739056594669819, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.051, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.008848982863128185, 'eval_loss_2': 0.008541584014892578, 'eval_loss_3': -18.243812561035156, 'eval_loss_4': -0.8872986435890198, 'epoch': 8.49}
{'loss': 0.0315, 'grad_norm': 7.113457679748535, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.015400249511003494, 'loss_2': 0.016082763671875, 'loss_3': -16.075599670410156, 'loss_4': -1.1916372776031494, 'epoch': 8.49}
{'loss': 0.0365, 'grad_norm': 9.952534675598145, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.03178247809410095, 'loss_2': 0.0046844482421875, 'loss_3': -15.931775093078613, 'loss_4': -0.7419421672821045, 'epoch': 8.5}
{'loss': 0.0133, 'grad_norm': 5.386730194091797, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.007729126140475273, 'loss_2': 0.0055999755859375, 'loss_3': -16.22149658203125, 'loss_4': -1.0512328147888184, 'epoch': 8.51}
{'loss': 0.0371, 'grad_norm': 13.676176071166992, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.0337112620472908, 'loss_2': 0.00337982177734375, 'loss_3': -16.182594299316406, 'loss_4': -0.8361709117889404, 'epoch': 8.51}
{'loss': 0.0341, 'grad_norm': 9.91537094116211, 'learning_rate': 2.15e-05, 'loss_1': 0.0254823025316, 'loss_2': 0.00864410400390625, 'loss_3': -16.434864044189453, 'loss_4': -0.8127298951148987, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 12:57:26,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:26,907 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:46<1:03:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:34,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012287524528801441, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.82, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009047148749232292, 'eval_loss_2': 0.0032403767108917236, 'eval_loss_3': -18.248859405517578, 'eval_loss_4': -0.8325353860855103, 'epoch': 8.52}
{'loss': 0.034, 'grad_norm': 12.398575782775879, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.02622813731431961, 'loss_2': 0.00774383544921875, 'loss_3': -16.31412124633789, 'loss_4': -0.38345155119895935, 'epoch': 8.52}
{'loss': 0.0222, 'grad_norm': 6.039628982543945, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.011843699961900711, 'loss_2': 0.010345458984375, 'loss_3': -16.19208526611328, 'loss_4': -0.34107986092567444, 'epoch': 8.53}
{'loss': 0.0192, 'grad_norm': 6.133183002471924, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.00899195484817028, 'loss_2': 0.010223388671875, 'loss_3': -16.248764038085938, 'loss_4': -0.5819135904312134, 'epoch': 8.53}
{'loss': 0.0286, 'grad_norm': 8.97919750213623, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.01850130781531334, 'loss_2': 0.0101470947265625, 'loss_3': -16.34837532043457, 'loss_4': -0.5976367592811584, 'epoch': 8.54}
{'loss': 0.0181, 'grad_norm': 6.854794502258301, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.010880053043365479, 'loss_2': 0.00720977783203125, 'loss_3': -16.34958267211914, 'loss_4': -1.2252922058105469, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 12:57:34,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:34,240 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:53<1:03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:41,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012484925799071789, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.889, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008372086100280285, 'eval_loss_2': 0.004112839698791504, 'eval_loss_3': -18.23720932006836, 'eval_loss_4': -0.6038944721221924, 'epoch': 8.55}
{'loss': 0.0187, 'grad_norm': 8.134563446044922, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.013094332069158554, 'loss_2': 0.005573272705078125, 'loss_3': -16.01620101928711, 'loss_4': -0.42523685097694397, 'epoch': 8.55}
{'loss': 0.0354, 'grad_norm': 10.917797088623047, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.033053208142519, 'loss_2': 0.002361297607421875, 'loss_3': -15.93581771850586, 'loss_4': -0.3084944188594818, 'epoch': 8.56}
{'loss': 0.0249, 'grad_norm': 9.336603164672852, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.021121958270668983, 'loss_2': 0.0037746429443359375, 'loss_3': -15.9442720413208, 'loss_4': -0.6152359247207642, 'epoch': 8.56}
{'loss': 0.0116, 'grad_norm': 5.413722515106201, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.006053137592971325, 'loss_2': 0.0055084228515625, 'loss_3': -16.398357391357422, 'loss_4': -0.2917262315750122, 'epoch': 8.57}
{'loss': 0.0617, 'grad_norm': 26.151321411132812, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.05444330722093582, 'loss_2': 0.00726318359375, 'loss_3': -15.92408275604248, 'loss_4': 0.16047655045986176, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 12:57:41,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:41,572 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [37:00<1:03:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:48,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014873422682285309, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.813, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.00905082281678915, 'eval_loss_2': 0.005822598934173584, 'eval_loss_3': -18.202577590942383, 'eval_loss_4': -0.40180259943008423, 'epoch': 8.58}
{'loss': 0.032, 'grad_norm': 12.057641983032227, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.027156628668308258, 'loss_2': 0.00484466552734375, 'loss_3': -15.888192176818848, 'loss_4': -0.24583733081817627, 'epoch': 8.58}
{'loss': 0.0235, 'grad_norm': 10.16086196899414, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.017933018505573273, 'loss_2': 0.005523681640625, 'loss_3': -15.943126678466797, 'loss_4': -0.35562217235565186, 'epoch': 8.59}
{'loss': 0.0276, 'grad_norm': 9.611230850219727, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.02706754580140114, 'loss_2': 0.0005621910095214844, 'loss_3': -16.286108016967773, 'loss_4': -0.3095895051956177, 'epoch': 8.59}
{'loss': 0.0101, 'grad_norm': 5.148088455200195, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.008822950534522533, 'loss_2': 0.0012969970703125, 'loss_3': -16.14236068725586, 'loss_4': -0.04280869662761688, 'epoch': 8.6}
{'loss': 0.0196, 'grad_norm': 5.404770851135254, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.007448640652000904, 'loss_2': 0.012176513671875, 'loss_3': -16.09069061279297, 'loss_4': -0.36567893624305725, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 12:57:48,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:48,910 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [37:08<1:03:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:56,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016146481037139893, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.986, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011438845656812191, 'eval_loss_2': 0.004707634449005127, 'eval_loss_3': -18.19306755065918, 'eval_loss_4': -0.31370002031326294, 'epoch': 8.6}
{'loss': 0.0399, 'grad_norm': 19.89618682861328, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.03928465023636818, 'loss_2': 0.000576019287109375, 'loss_3': -15.903193473815918, 'loss_4': -0.4763123393058777, 'epoch': 8.61}
{'loss': 0.0094, 'grad_norm': 5.114480972290039, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.006659989710897207, 'loss_2': 0.00273895263671875, 'loss_3': -16.061019897460938, 'loss_4': -0.19668114185333252, 'epoch': 8.62}
{'loss': 0.0228, 'grad_norm': 10.60433292388916, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.020223423838615417, 'loss_2': 0.0026111602783203125, 'loss_3': -15.972816467285156, 'loss_4': -0.4463503062725067, 'epoch': 8.62}
{'loss': 0.0159, 'grad_norm': 6.885751724243164, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.012151157483458519, 'loss_2': 0.003765106201171875, 'loss_3': -16.186290740966797, 'loss_4': -0.4858098030090332, 'epoch': 8.63}
{'loss': 0.0261, 'grad_norm': 5.056686878204346, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.00911469291895628, 'loss_2': 0.016937255859375, 'loss_3': -16.028942108154297, 'loss_4': -0.5018515586853027, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 12:57:56,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:56,245 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:15<1:03:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:03,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023072104901075363, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.844, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014735324308276176, 'eval_loss_2': 0.008336782455444336, 'eval_loss_3': -18.174293518066406, 'eval_loss_4': -0.402822345495224, 'epoch': 8.63}
{'loss': 0.0207, 'grad_norm': 5.802099704742432, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.009871674701571465, 'loss_2': 0.01087188720703125, 'loss_3': -16.044357299804688, 'loss_4': -0.31601688265800476, 'epoch': 8.64}
{'loss': 0.0248, 'grad_norm': 11.00268268585205, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.011133400723338127, 'loss_2': 0.01363372802734375, 'loss_3': -16.097164154052734, 'loss_4': -0.1489446759223938, 'epoch': 8.65}
{'loss': 0.0252, 'grad_norm': 5.6409592628479, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.014538479968905449, 'loss_2': 0.0106201171875, 'loss_3': -16.147247314453125, 'loss_4': -0.29046839475631714, 'epoch': 8.65}
{'loss': 0.0196, 'grad_norm': 6.660634517669678, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.013280949555337429, 'loss_2': 0.00628662109375, 'loss_3': -16.15096092224121, 'loss_4': -0.5484340786933899, 'epoch': 8.66}
{'loss': 0.0641, 'grad_norm': 16.983694076538086, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.0631580725312233, 'loss_2': 0.0009641647338867188, 'loss_3': -16.070568084716797, 'loss_4': -0.26900792121887207, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 12:58:03,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:03,585 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:22<1:03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:10,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01998494379222393, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.959, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01206640899181366, 'eval_loss_2': 0.00791853666305542, 'eval_loss_3': -18.207223892211914, 'eval_loss_4': -0.2611675262451172, 'epoch': 8.66}
{'loss': 0.0306, 'grad_norm': 10.514256477355957, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.017192447558045387, 'loss_2': 0.01345062255859375, 'loss_3': -16.11739730834961, 'loss_4': -0.8004753589630127, 'epoch': 8.67}
{'loss': 0.0205, 'grad_norm': 5.477004528045654, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.00788431242108345, 'loss_2': 0.01264190673828125, 'loss_3': -16.217100143432617, 'loss_4': -0.40171030163764954, 'epoch': 8.67}
{'loss': 0.0208, 'grad_norm': 5.338262557983398, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.010011264123022556, 'loss_2': 0.01082611083984375, 'loss_3': -16.064023971557617, 'loss_4': -0.16525767743587494, 'epoch': 8.68}
{'loss': 0.0316, 'grad_norm': 7.185575485229492, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.02724897488951683, 'loss_2': 0.0043792724609375, 'loss_3': -15.984954833984375, 'loss_4': -0.05121001601219177, 'epoch': 8.69}
{'loss': 0.0191, 'grad_norm': 6.643016815185547, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.014134762808680534, 'loss_2': 0.0049896240234375, 'loss_3': -16.079761505126953, 'loss_4': -0.062333375215530396, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 12:58:10,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:10,920 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:30<1:03:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:18,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01732344552874565, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.837, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012526466511189938, 'eval_loss_2': 0.0047969818115234375, 'eval_loss_3': -18.226917266845703, 'eval_loss_4': -0.21036410331726074, 'epoch': 8.69}
{'loss': 0.0115, 'grad_norm': 5.0735578536987305, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.008816647343337536, 'loss_2': 0.0027313232421875, 'loss_3': -16.302722930908203, 'loss_4': -0.10457801818847656, 'epoch': 8.7}
{'loss': 0.0383, 'grad_norm': 8.926788330078125, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.025224434211850166, 'loss_2': 0.0130615234375, 'loss_3': -16.165660858154297, 'loss_4': -0.6897119283676147, 'epoch': 8.7}
{'loss': 0.0325, 'grad_norm': 10.738844871520996, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.02168685756623745, 'loss_2': 0.0107879638671875, 'loss_3': -16.0280818939209, 'loss_4': -0.13810308277606964, 'epoch': 8.71}
{'loss': 0.0282, 'grad_norm': 9.379387855529785, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.01870376616716385, 'loss_2': 0.0094757080078125, 'loss_3': -16.183513641357422, 'loss_4': -0.7498875856399536, 'epoch': 8.72}
{'loss': 0.035, 'grad_norm': 7.75962495803833, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.02749178744852543, 'loss_2': 0.0074920654296875, 'loss_3': -16.03917694091797, 'loss_4': 0.03831951320171356, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 12:58:18,263 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:18,264 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:37<1:03:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:25,598 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019982004538178444, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.425, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013471808284521103, 'eval_loss_2': 0.00651019811630249, 'eval_loss_3': -18.241193771362305, 'eval_loss_4': -0.13051582872867584, 'epoch': 8.72}
{'loss': 0.0191, 'grad_norm': 5.800478935241699, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.014158075675368309, 'loss_2': 0.004970550537109375, 'loss_3': -16.239788055419922, 'loss_4': -0.5841766595840454, 'epoch': 8.73}
{'loss': 0.0201, 'grad_norm': 9.578943252563477, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.016765965148806572, 'loss_2': 0.0033702850341796875, 'loss_3': -16.25381088256836, 'loss_4': 0.2493719607591629, 'epoch': 8.73}
{'loss': 0.0149, 'grad_norm': 5.609255790710449, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.014631649479269981, 'loss_2': 0.00030493736267089844, 'loss_3': -16.080890655517578, 'loss_4': -0.0704488605260849, 'epoch': 8.74}
{'loss': 0.0071, 'grad_norm': 5.158834457397461, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.005952054169028997, 'loss_2': 0.0011682510375976562, 'loss_3': -16.291399002075195, 'loss_4': -0.07864797115325928, 'epoch': 8.74}
{'loss': 0.0186, 'grad_norm': 6.8460516929626465, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.016398515552282333, 'loss_2': 0.0021839141845703125, 'loss_3': -15.977218627929688, 'loss_4': -0.15791037678718567, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 12:58:25,598 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:25,598 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:44<1:02:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:32,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01791134849190712, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.056, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013131472282111645, 'eval_loss_2': 0.0047798752784729, 'eval_loss_3': -18.242937088012695, 'eval_loss_4': -0.1904788762331009, 'epoch': 8.75}
{'loss': 0.0138, 'grad_norm': 5.364001750946045, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.009523059241473675, 'loss_2': 0.00423431396484375, 'loss_3': -15.939813613891602, 'loss_4': -0.6366572976112366, 'epoch': 8.76}
{'loss': 0.0155, 'grad_norm': 6.199418067932129, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.009098687209188938, 'loss_2': 0.0063629150390625, 'loss_3': -16.222034454345703, 'loss_4': 0.2888321876525879, 'epoch': 8.76}
{'loss': 0.0429, 'grad_norm': 23.049942016601562, 'learning_rate': 2.125e-05, 'loss_1': 0.032603949308395386, 'loss_2': 0.01031494140625, 'loss_3': -16.254688262939453, 'loss_4': 0.4336637258529663, 'epoch': 8.77}
{'loss': 0.0224, 'grad_norm': 8.291106224060059, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.022197704762220383, 'loss_2': 0.0002467632293701172, 'loss_3': -15.92947006225586, 'loss_4': -0.5143140554428101, 'epoch': 8.77}
{'loss': 0.0126, 'grad_norm': 6.721846580505371, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.01217743195593357, 'loss_2': 0.000392913818359375, 'loss_3': -16.24993133544922, 'loss_4': -0.5569435358047485, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 12:58:32,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:32,925 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:52<1:02:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:40,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02005825564265251, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.89, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.015620153397321701, 'eval_loss_2': 0.0044381022453308105, 'eval_loss_3': -18.215673446655273, 'eval_loss_4': -0.12333952635526657, 'epoch': 8.78}
{'loss': 0.0128, 'grad_norm': 5.033541679382324, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.009573422372341156, 'loss_2': 0.003177642822265625, 'loss_3': -16.14703369140625, 'loss_4': -0.2825581431388855, 'epoch': 8.78}
{'loss': 0.0101, 'grad_norm': 5.630999565124512, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.009998984634876251, 'loss_2': 8.296966552734375e-05, 'loss_3': -16.089683532714844, 'loss_4': -0.20095422863960266, 'epoch': 8.79}
{'loss': 0.0119, 'grad_norm': 4.69411039352417, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.008398299105465412, 'loss_2': 0.0035495758056640625, 'loss_3': -16.07771110534668, 'loss_4': 0.16579599678516388, 'epoch': 8.8}
{'loss': 0.0188, 'grad_norm': 5.809173107147217, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.01250168401747942, 'loss_2': 0.00628662109375, 'loss_3': -16.06118392944336, 'loss_4': -0.010158628225326538, 'epoch': 8.8}
{'loss': 0.0441, 'grad_norm': 12.346402168273926, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.042573362588882446, 'loss_2': 0.0015420913696289062, 'loss_3': -16.021100997924805, 'loss_4': 0.3439302444458008, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 12:58:40,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:40,258 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:59<1:02:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:47,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026254355907440186, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.859, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017615675926208496, 'eval_loss_2': 0.00863867998123169, 'eval_loss_3': -18.19171905517578, 'eval_loss_4': 0.11197436600923538, 'epoch': 8.81}
{'loss': 0.0489, 'grad_norm': 18.169504165649414, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.03815162554383278, 'loss_2': 0.01074981689453125, 'loss_3': -16.273883819580078, 'loss_4': 0.509734570980072, 'epoch': 8.81}
{'loss': 0.0223, 'grad_norm': 6.842936992645264, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.011443045921623707, 'loss_2': 0.0108642578125, 'loss_3': -16.111103057861328, 'loss_4': 0.014634102582931519, 'epoch': 8.82}
{'loss': 0.0218, 'grad_norm': 6.476655006408691, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.014017892070114613, 'loss_2': 0.0077362060546875, 'loss_3': -16.36077880859375, 'loss_4': -0.08222998678684235, 'epoch': 8.83}
{'loss': 0.0091, 'grad_norm': 5.959181308746338, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.008070231415331364, 'loss_2': 0.000988006591796875, 'loss_3': -16.163318634033203, 'loss_4': -0.05986534059047699, 'epoch': 8.83}
{'loss': 0.0158, 'grad_norm': 5.726649284362793, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.009143677540123463, 'loss_2': 0.00661468505859375, 'loss_3': -15.913267135620117, 'loss_4': 0.026960106566548347, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 12:58:47,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:47,592 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [38:06<1:02:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:54,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01982768438756466, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.684, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.016743129119277, 'eval_loss_2': 0.0030845552682876587, 'eval_loss_3': -18.187088012695312, 'eval_loss_4': 0.10890509933233261, 'epoch': 8.84}
{'loss': 0.005, 'grad_norm': 5.40140962600708, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.004941868595778942, 'loss_2': 7.927417755126953e-05, 'loss_3': -16.26396942138672, 'loss_4': 0.17154163122177124, 'epoch': 8.84}
{'loss': 0.0118, 'grad_norm': 5.7085089683532715, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.011172762140631676, 'loss_2': 0.0006122589111328125, 'loss_3': -16.40896224975586, 'loss_4': -0.4186144471168518, 'epoch': 8.85}
{'loss': 0.0693, 'grad_norm': 21.435977935791016, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.06206857040524483, 'loss_2': 0.007228851318359375, 'loss_3': -16.122920989990234, 'loss_4': 0.3309305012226105, 'epoch': 8.85}
{'loss': 0.0401, 'grad_norm': 8.768365859985352, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.02675689198076725, 'loss_2': 0.01337432861328125, 'loss_3': -16.215543746948242, 'loss_4': 0.0368211567401886, 'epoch': 8.86}
{'loss': 0.0505, 'grad_norm': 21.873262405395508, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.03385334089398384, 'loss_2': 0.0166778564453125, 'loss_3': -16.144184112548828, 'loss_4': 0.1740754246711731, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 12:58:54,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:54,930 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [38:14<1:02:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:02,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031663861125707626, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.472, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.018266405910253525, 'eval_loss_2': 0.013397455215454102, 'eval_loss_3': -18.193065643310547, 'eval_loss_4': 0.02429446578025818, 'epoch': 8.87}
{'loss': 0.026, 'grad_norm': 6.431931972503662, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.012272008694708347, 'loss_2': 0.01373291015625, 'loss_3': -16.393632888793945, 'loss_4': -0.01890341192483902, 'epoch': 8.87}
{'loss': 0.0282, 'grad_norm': 6.080952167510986, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.010107872076332569, 'loss_2': 0.01812744140625, 'loss_3': -16.4210147857666, 'loss_4': 0.006924659013748169, 'epoch': 8.88}
{'loss': 0.0898, 'grad_norm': 16.71851348876953, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.07512962818145752, 'loss_2': 0.01470947265625, 'loss_3': -16.359886169433594, 'loss_4': 0.11406922340393066, 'epoch': 8.88}
{'loss': 0.034, 'grad_norm': 8.010786056518555, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.01727321557700634, 'loss_2': 0.0167083740234375, 'loss_3': -16.16337776184082, 'loss_4': 0.19476962089538574, 'epoch': 8.89}
{'loss': 0.0257, 'grad_norm': 6.442381381988525, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.01662592403590679, 'loss_2': 0.0091094970703125, 'loss_3': -16.286623001098633, 'loss_4': -0.11736658960580826, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 12:59:02,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:02,275 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:21<1:02:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:09,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029066987335681915, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017844922840595245, 'eval_loss_2': 0.01122206449508667, 'eval_loss_3': -18.193592071533203, 'eval_loss_4': 0.12851737439632416, 'epoch': 8.9}
{'loss': 0.0315, 'grad_norm': 9.118257522583008, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.024531496688723564, 'loss_2': 0.00691986083984375, 'loss_3': -16.51605987548828, 'loss_4': 0.07411621510982513, 'epoch': 8.9}
{'loss': 0.0279, 'grad_norm': 9.03790283203125, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.01607438735663891, 'loss_2': 0.01177978515625, 'loss_3': -16.168201446533203, 'loss_4': -0.05647042393684387, 'epoch': 8.91}
{'loss': 0.0211, 'grad_norm': 5.685758590698242, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.015523232519626617, 'loss_2': 0.005565643310546875, 'loss_3': -16.452966690063477, 'loss_4': -0.05958542972803116, 'epoch': 8.91}
{'loss': 0.0272, 'grad_norm': 8.4861421585083, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.020287593826651573, 'loss_2': 0.006866455078125, 'loss_3': -16.36976432800293, 'loss_4': 0.5095750093460083, 'epoch': 8.92}
{'loss': 0.0191, 'grad_norm': 6.2331953048706055, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.01719752512872219, 'loss_2': 0.00188446044921875, 'loss_3': -16.10111427307129, 'loss_4': -0.1172449067234993, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 12:59:09,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:09,621 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:28<1:02:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:16,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022847849875688553, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.016, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01850013993680477, 'eval_loss_2': 0.004347711801528931, 'eval_loss_3': -18.231122970581055, 'eval_loss_4': 0.3387291431427002, 'epoch': 8.92}
{'loss': 0.0993, 'grad_norm': 29.320999145507812, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.0975627675652504, 'loss_2': 0.0017261505126953125, 'loss_3': -16.37938690185547, 'loss_4': 0.6138463020324707, 'epoch': 8.93}
{'loss': 0.01, 'grad_norm': 5.100215435028076, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.008917598985135555, 'loss_2': 0.0011119842529296875, 'loss_3': -16.29562759399414, 'loss_4': 0.28146126866340637, 'epoch': 8.94}
{'loss': 0.0648, 'grad_norm': 16.32946014404297, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.05096079781651497, 'loss_2': 0.0138092041015625, 'loss_3': -16.56081199645996, 'loss_4': 0.5758878588676453, 'epoch': 8.94}
{'loss': 0.0322, 'grad_norm': 10.193903923034668, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.022702235728502274, 'loss_2': 0.00946044921875, 'loss_3': -16.067962646484375, 'loss_4': 0.33897852897644043, 'epoch': 8.95}
{'loss': 0.0238, 'grad_norm': 10.824214935302734, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.020975010469555855, 'loss_2': 0.0028095245361328125, 'loss_3': -16.488344192504883, 'loss_4': 0.5130524039268494, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 12:59:16,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:16,956 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:36<1:02:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:24,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016759198158979416, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.778, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01002995390444994, 'eval_loss_2': 0.006729245185852051, 'eval_loss_3': -18.305381774902344, 'eval_loss_4': 0.6581441164016724, 'epoch': 8.95}
{'loss': 0.023, 'grad_norm': 5.789423942565918, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.012255613692104816, 'loss_2': 0.01070404052734375, 'loss_3': -16.390972137451172, 'loss_4': 1.0343300104141235, 'epoch': 8.96}
{'loss': 0.0546, 'grad_norm': 15.954217910766602, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.0495782233774662, 'loss_2': 0.005031585693359375, 'loss_3': -16.23016929626465, 'loss_4': 0.6190797090530396, 'epoch': 8.97}
{'loss': 0.0197, 'grad_norm': 6.619487762451172, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.01455027423799038, 'loss_2': 0.00514984130859375, 'loss_3': -16.19551658630371, 'loss_4': 0.4905535578727722, 'epoch': 8.97}
{'loss': 0.0257, 'grad_norm': 8.637758255004883, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.020448990166187286, 'loss_2': 0.005275726318359375, 'loss_3': -16.358549118041992, 'loss_4': 0.6862896680831909, 'epoch': 8.98}
{'loss': 0.0167, 'grad_norm': 6.588361740112305, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.01564895547926426, 'loss_2': 0.001033782958984375, 'loss_3': -16.496488571166992, 'loss_4': 0.2881113290786743, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 12:59:24,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:24,295 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:43<59:47,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 12:59:31,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013491695746779442, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.948, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009727257303893566, 'eval_loss_2': 0.003764435648918152, 'eval_loss_3': -18.29463005065918, 'eval_loss_4': 0.57973712682724, 'epoch': 8.98}
{'loss': 0.0342, 'grad_norm': 6.528783798217773, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.02241109125316143, 'loss_2': 0.0118255615234375, 'loss_3': -16.525218963623047, 'loss_4': 0.41956737637519836, 'epoch': 8.99}
{'loss': 0.0227, 'grad_norm': 7.492676734924316, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.021094761788845062, 'loss_2': 0.0016384124755859375, 'loss_3': -16.33460235595703, 'loss_4': 0.9478562474250793, 'epoch': 8.99}
{'loss': 0.0078, 'grad_norm': 6.990405559539795, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.007466332986950874, 'loss_2': 0.0003771781921386719, 'loss_3': -16.583356857299805, 'loss_4': 0.2963736653327942, 'epoch': 9.0}
{'loss': 0.0233, 'grad_norm': 6.241794109344482, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.022121939808130264, 'loss_2': 0.001194000244140625, 'loss_3': -16.299976348876953, 'loss_4': 0.19125042855739594, 'epoch': 9.01}
{'loss': 0.0472, 'grad_norm': 10.380797386169434, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.03986291587352753, 'loss_2': 0.007289886474609375, 'loss_3': -16.296419143676758, 'loss_4': 0.18420171737670898, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 12:59:31,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:31,315 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:50<1:01:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:59:38,652 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016084451228380203, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.213, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009746985509991646, 'eval_loss_2': 0.006337463855743408, 'eval_loss_3': -18.31069564819336, 'eval_loss_4': 0.33542123436927795, 'epoch': 9.01}
{'loss': 0.0778, 'grad_norm': 20.002824783325195, 'learning_rate': 2.1e-05, 'loss_1': 0.0711793377995491, 'loss_2': 0.006649017333984375, 'loss_3': -16.26736068725586, 'loss_4': 0.3180314898490906, 'epoch': 9.02}
{'loss': 0.032, 'grad_norm': 6.7406005859375, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.02291729673743248, 'loss_2': 0.0090484619140625, 'loss_3': -16.46401023864746, 'loss_4': 0.6776227355003357, 'epoch': 9.02}
{'loss': 0.0244, 'grad_norm': 7.026246070861816, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.021110668778419495, 'loss_2': 0.003337860107421875, 'loss_3': -16.626251220703125, 'loss_4': 0.15626418590545654, 'epoch': 9.03}
{'loss': 0.0556, 'grad_norm': 19.269773483276367, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.052137590944767, 'loss_2': 0.0034351348876953125, 'loss_3': -16.367450714111328, 'loss_4': 0.4014278054237366, 'epoch': 9.03}
{'loss': 0.093, 'grad_norm': 21.649351119995117, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.08511164784431458, 'loss_2': 0.007904052734375, 'loss_3': -16.161102294921875, 'loss_4': 0.5563461780548096, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 12:59:38,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:38,653 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:57<1:02:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:45,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014296328648924828, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.04, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009567580185830593, 'eval_loss_2': 0.004728749394416809, 'eval_loss_3': -18.284439086914062, 'eval_loss_4': 0.4064907133579254, 'epoch': 9.04}
{'loss': 0.0262, 'grad_norm': 8.033088684082031, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.02290239743888378, 'loss_2': 0.00331878662109375, 'loss_3': -16.29409408569336, 'loss_4': 0.4201222062110901, 'epoch': 9.05}
{'loss': 0.0147, 'grad_norm': 4.694568634033203, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.008419844321906567, 'loss_2': 0.0062713623046875, 'loss_3': -16.450191497802734, 'loss_4': 0.5926843881607056, 'epoch': 9.05}
{'loss': 0.0157, 'grad_norm': 5.687432765960693, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.013503503054380417, 'loss_2': 0.0021800994873046875, 'loss_3': -16.291831970214844, 'loss_4': 0.2844124436378479, 'epoch': 9.06}
{'loss': 0.0175, 'grad_norm': 6.094808578491211, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.01594322733581066, 'loss_2': 0.001537322998046875, 'loss_3': -16.307247161865234, 'loss_4': 0.39841848611831665, 'epoch': 9.06}
{'loss': 0.0298, 'grad_norm': 7.052706718444824, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.023795779794454575, 'loss_2': 0.00595855712890625, 'loss_3': -16.322078704833984, 'loss_4': 0.6427985429763794, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 12:59:45,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:45,993 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [39:05<1:02:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:53,333 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016531186178326607, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.913, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009498314931988716, 'eval_loss_2': 0.007032871246337891, 'eval_loss_3': -18.21813201904297, 'eval_loss_4': 0.44154003262519836, 'epoch': 9.07}
{'loss': 0.0294, 'grad_norm': 10.427631378173828, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.025728927925229073, 'loss_2': 0.0037078857421875, 'loss_3': -16.409915924072266, 'loss_4': 0.2895638346672058, 'epoch': 9.08}
{'loss': 0.024, 'grad_norm': 5.28827428817749, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.010730890557169914, 'loss_2': 0.0132904052734375, 'loss_3': -16.293760299682617, 'loss_4': 0.2579696774482727, 'epoch': 9.08}
{'loss': 0.0298, 'grad_norm': 7.918883800506592, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.022731129080057144, 'loss_2': 0.00702667236328125, 'loss_3': -16.39106559753418, 'loss_4': 0.1932867467403412, 'epoch': 9.09}
{'loss': 0.0155, 'grad_norm': 5.314678192138672, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.009279745630919933, 'loss_2': 0.006195068359375, 'loss_3': -16.404741287231445, 'loss_4': 0.5792542695999146, 'epoch': 9.09}
{'loss': 0.0262, 'grad_norm': 12.629100799560547, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.02213994413614273, 'loss_2': 0.0041046142578125, 'loss_3': -16.34640121459961, 'loss_4': 1.061797022819519, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 12:59:53,333 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:53,333 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [39:12<1:02:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:00,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015050025656819344, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01170630194246769, 'eval_loss_2': 0.003343723714351654, 'eval_loss_3': -18.18466567993164, 'eval_loss_4': 0.6346427202224731, 'epoch': 9.1}
{'loss': 0.0505, 'grad_norm': 16.164379119873047, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.04453221708536148, 'loss_2': 0.005931854248046875, 'loss_3': -16.17802619934082, 'loss_4': 0.3124159574508667, 'epoch': 9.1}
{'loss': 0.0274, 'grad_norm': 7.851175308227539, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.016115400940179825, 'loss_2': 0.011322021484375, 'loss_3': -16.447528839111328, 'loss_4': 0.32668694853782654, 'epoch': 9.11}
{'loss': 0.0244, 'grad_norm': 5.555944919586182, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.021155593916773796, 'loss_2': 0.0032558441162109375, 'loss_3': -16.376750946044922, 'loss_4': 0.753337025642395, 'epoch': 9.12}
{'loss': 0.0144, 'grad_norm': 8.301127433776855, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.013659777119755745, 'loss_2': 0.0007767677307128906, 'loss_3': -16.478273391723633, 'loss_4': 0.4910542666912079, 'epoch': 9.12}
{'loss': 0.0135, 'grad_norm': 6.270444393157959, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.010623236186802387, 'loss_2': 0.002864837646484375, 'loss_3': -16.351821899414062, 'loss_4': 0.18392908573150635, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 13:00:00,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:00,682 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:20<1:01:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:08,013 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02066827192902565, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.086, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014645223505795002, 'eval_loss_2': 0.006023049354553223, 'eval_loss_3': -18.14368438720703, 'eval_loss_4': 0.619976282119751, 'epoch': 9.13}
{'loss': 0.0398, 'grad_norm': 9.977988243103027, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.028541220352053642, 'loss_2': 0.01123046875, 'loss_3': -16.09217071533203, 'loss_4': 0.167872816324234, 'epoch': 9.13}
{'loss': 0.0144, 'grad_norm': 5.835940837860107, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.011064190417528152, 'loss_2': 0.003376007080078125, 'loss_3': -16.1833553314209, 'loss_4': 0.23965170979499817, 'epoch': 9.14}
{'loss': 0.0565, 'grad_norm': 28.94074821472168, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.0492594838142395, 'loss_2': 0.00725555419921875, 'loss_3': -16.206096649169922, 'loss_4': 0.675418496131897, 'epoch': 9.15}
{'loss': 0.0112, 'grad_norm': 4.974586009979248, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.009323259815573692, 'loss_2': 0.00186920166015625, 'loss_3': -16.35333824157715, 'loss_4': 0.6779344081878662, 'epoch': 9.15}
{'loss': 0.0421, 'grad_norm': 11.608917236328125, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.03410445526242256, 'loss_2': 0.0080108642578125, 'loss_3': -16.268199920654297, 'loss_4': 0.7869477272033691, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 13:00:08,013 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:08,013 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:27<1:01:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:15,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015893442556262016, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.263, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012880763038992882, 'eval_loss_2': 0.0030126795172691345, 'eval_loss_3': -18.16352653503418, 'eval_loss_4': 0.6715530753135681, 'epoch': 9.16}
{'loss': 0.0207, 'grad_norm': 9.749237060546875, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.017594486474990845, 'loss_2': 0.0031299591064453125, 'loss_3': -16.198320388793945, 'loss_4': 0.6598107218742371, 'epoch': 9.16}
{'loss': 0.0431, 'grad_norm': 13.476760864257812, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.03796001151204109, 'loss_2': 0.005096435546875, 'loss_3': -16.06736183166504, 'loss_4': 0.28382498025894165, 'epoch': 9.17}
{'loss': 0.0212, 'grad_norm': 7.82783842086792, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.016688669100403786, 'loss_2': 0.00449371337890625, 'loss_3': -16.35750389099121, 'loss_4': 0.41938501596450806, 'epoch': 9.17}
{'loss': 0.0237, 'grad_norm': 7.312252521514893, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.022800175473093987, 'loss_2': 0.0009202957153320312, 'loss_3': -16.18054962158203, 'loss_4': 1.0017437934875488, 'epoch': 9.18}
{'loss': 0.0933, 'grad_norm': 20.332624435424805, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.08801740407943726, 'loss_2': 0.00528717041015625, 'loss_3': -16.30860137939453, 'loss_4': 0.8056508302688599, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 13:00:15,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:15,347 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:34<1:01:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:22,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016082588583230972, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.893, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011772160418331623, 'eval_loss_2': 0.004310429096221924, 'eval_loss_3': -18.17482566833496, 'eval_loss_4': 0.7428242564201355, 'epoch': 9.19}
{'loss': 0.0306, 'grad_norm': 15.047221183776855, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.028980782255530357, 'loss_2': 0.0015850067138671875, 'loss_3': -16.081880569458008, 'loss_4': 1.1552470922470093, 'epoch': 9.19}
{'loss': 0.0172, 'grad_norm': 6.580469131469727, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.015770265832543373, 'loss_2': 0.001399993896484375, 'loss_3': -16.238784790039062, 'loss_4': 0.46324920654296875, 'epoch': 9.2}
{'loss': 0.0229, 'grad_norm': 7.8391194343566895, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.018746478483080864, 'loss_2': 0.004199981689453125, 'loss_3': -16.02560806274414, 'loss_4': 0.6792783737182617, 'epoch': 9.2}
{'loss': 0.0267, 'grad_norm': 8.945151329040527, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.02128295972943306, 'loss_2': 0.00537872314453125, 'loss_3': -16.25391387939453, 'loss_4': 0.49537622928619385, 'epoch': 9.21}
{'loss': 0.0177, 'grad_norm': 4.966570854187012, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.009969952516257763, 'loss_2': 0.007694244384765625, 'loss_3': -16.2586669921875, 'loss_4': 0.6643754839897156, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 13:00:22,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:22,678 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:42<1:01:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:30,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019506238400936127, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.585, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012838028371334076, 'eval_loss_2': 0.006668210029602051, 'eval_loss_3': -18.203392028808594, 'eval_loss_4': 0.7730317115783691, 'epoch': 9.22}
{'loss': 0.0408, 'grad_norm': 16.70111656188965, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.03497224301099777, 'loss_2': 0.005802154541015625, 'loss_3': -16.270755767822266, 'loss_4': 0.5297847390174866, 'epoch': 9.22}
{'loss': 0.0198, 'grad_norm': 6.374744892120361, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.01680396869778633, 'loss_2': 0.002986907958984375, 'loss_3': -16.365276336669922, 'loss_4': 1.0476799011230469, 'epoch': 9.23}
{'loss': 0.0299, 'grad_norm': 8.497382164001465, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.027899134904146194, 'loss_2': 0.001964569091796875, 'loss_3': -16.3194580078125, 'loss_4': 0.9606789350509644, 'epoch': 9.23}
{'loss': 0.0323, 'grad_norm': 6.751246452331543, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.016892170533537865, 'loss_2': 0.0154571533203125, 'loss_3': -16.411563873291016, 'loss_4': 1.192233920097351, 'epoch': 9.24}
{'loss': 0.0285, 'grad_norm': 10.538476943969727, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.02514321729540825, 'loss_2': 0.0033206939697265625, 'loss_3': -16.414875030517578, 'loss_4': 0.6875656843185425, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 13:00:30,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:30,019 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:49<1:01:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:37,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015674486756324768, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.966, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012178424745798111, 'eval_loss_2': 0.003496062010526657, 'eval_loss_3': -18.208112716674805, 'eval_loss_4': 0.8584133982658386, 'epoch': 9.24}
{'loss': 0.0417, 'grad_norm': 19.773733139038086, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.03542668744921684, 'loss_2': 0.00626373291015625, 'loss_3': -16.12887191772461, 'loss_4': 0.8848108053207397, 'epoch': 9.25}
{'loss': 0.0185, 'grad_norm': 7.752517223358154, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.016292667016386986, 'loss_2': 0.0021762847900390625, 'loss_3': -16.352991104125977, 'loss_4': 0.9098124504089355, 'epoch': 9.26}
{'loss': 0.017, 'grad_norm': 6.467782974243164, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.01475914940237999, 'loss_2': 0.00220489501953125, 'loss_3': -16.230743408203125, 'loss_4': 0.871330976486206, 'epoch': 9.26}
{'loss': 0.0264, 'grad_norm': 10.469258308410645, 'learning_rate': 2.075e-05, 'loss_1': 0.02324032597243786, 'loss_2': 0.0031375885009765625, 'loss_3': -16.00029754638672, 'loss_4': 0.7873783111572266, 'epoch': 9.27}
{'loss': 0.0267, 'grad_norm': 6.961407661437988, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.0162286888808012, 'loss_2': 0.0104522705078125, 'loss_3': -16.39601707458496, 'loss_4': 0.7540106773376465, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 13:00:37,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:37,357 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:56<1:01:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:44,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01951666921377182, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.853, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012771273031830788, 'eval_loss_2': 0.006745398044586182, 'eval_loss_3': -18.248870849609375, 'eval_loss_4': 0.8730849027633667, 'epoch': 9.27}
{'loss': 0.0281, 'grad_norm': 7.949104309082031, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.02449825406074524, 'loss_2': 0.0036144256591796875, 'loss_3': -16.12813377380371, 'loss_4': 0.878176212310791, 'epoch': 9.28}
{'loss': 0.0398, 'grad_norm': 12.014013290405273, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.03392399102449417, 'loss_2': 0.005908966064453125, 'loss_3': -16.381145477294922, 'loss_4': 0.9272054433822632, 'epoch': 9.28}
{'loss': 0.0498, 'grad_norm': 18.994169235229492, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.0457121878862381, 'loss_2': 0.004131317138671875, 'loss_3': -16.230527877807617, 'loss_4': 1.3824775218963623, 'epoch': 9.29}
{'loss': 0.0102, 'grad_norm': 5.905725479125977, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.00940464437007904, 'loss_2': 0.0007567405700683594, 'loss_3': -16.309213638305664, 'loss_4': 0.8513539433479309, 'epoch': 9.3}
{'loss': 0.016, 'grad_norm': 6.163790702819824, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.010549734346568584, 'loss_2': 0.00540924072265625, 'loss_3': -16.242055892944336, 'loss_4': 0.5317575335502625, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 13:00:44,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:44,695 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [40:04<1:01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:52,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014754312112927437, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.817, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011433782055974007, 'eval_loss_2': 0.00332053005695343, 'eval_loss_3': -18.24065399169922, 'eval_loss_4': 0.969016432762146, 'epoch': 9.3}
{'loss': 0.0351, 'grad_norm': 11.150256156921387, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.03463944047689438, 'loss_2': 0.0004582405090332031, 'loss_3': -16.18607521057129, 'loss_4': 1.1189045906066895, 'epoch': 9.31}
{'loss': 0.0326, 'grad_norm': 5.944308280944824, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.02091616950929165, 'loss_2': 0.01165771484375, 'loss_3': -16.283329010009766, 'loss_4': 0.8390339016914368, 'epoch': 9.31}
{'loss': 0.0228, 'grad_norm': 6.608394145965576, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.020474057644605637, 'loss_2': 0.002292633056640625, 'loss_3': -16.355937957763672, 'loss_4': 0.7762101292610168, 'epoch': 9.32}
{'loss': 0.0195, 'grad_norm': 5.665274143218994, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.012373285368084908, 'loss_2': 0.00710296630859375, 'loss_3': -16.36672592163086, 'loss_4': 1.2164620161056519, 'epoch': 9.33}
{'loss': 0.0179, 'grad_norm': 5.757643699645996, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.014756687916815281, 'loss_2': 0.003147125244140625, 'loss_3': -15.967370986938477, 'loss_4': 0.8214697241783142, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 13:00:52,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:52,038 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [40:11<1:01:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:59,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01585238426923752, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011924737133085728, 'eval_loss_2': 0.003927648067474365, 'eval_loss_3': -18.261688232421875, 'eval_loss_4': 0.9837265610694885, 'epoch': 9.33}
{'loss': 0.0103, 'grad_norm': 5.313210487365723, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.008796095848083496, 'loss_2': 0.001495361328125, 'loss_3': -16.258150100708008, 'loss_4': 0.7438787221908569, 'epoch': 9.34}
{'loss': 0.0265, 'grad_norm': 8.052635192871094, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.02234925888478756, 'loss_2': 0.00415802001953125, 'loss_3': -16.17305564880371, 'loss_4': 1.0492491722106934, 'epoch': 9.34}
{'loss': 0.0253, 'grad_norm': 9.691500663757324, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.02438395842909813, 'loss_2': 0.0009031295776367188, 'loss_3': -16.388734817504883, 'loss_4': 0.6347783207893372, 'epoch': 9.35}
{'loss': 0.0133, 'grad_norm': 6.083771705627441, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.012839141301810741, 'loss_2': 0.0005054473876953125, 'loss_3': -16.27101707458496, 'loss_4': 0.9300345182418823, 'epoch': 9.35}
{'loss': 0.0129, 'grad_norm': 5.087344646453857, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.010803496465086937, 'loss_2': 0.002086639404296875, 'loss_3': -16.326553344726562, 'loss_4': 0.9550265669822693, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 13:00:59,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:59,377 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:18<1:01:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:06,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015041057020425797, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.773, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011980477720499039, 'eval_loss_2': 0.003060579299926758, 'eval_loss_3': -18.262094497680664, 'eval_loss_4': 1.0891057252883911, 'epoch': 9.36}
{'loss': 0.0215, 'grad_norm': 9.606254577636719, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.021225864067673683, 'loss_2': 0.00023627281188964844, 'loss_3': -16.19460678100586, 'loss_4': 0.5742651224136353, 'epoch': 9.37}
{'loss': 0.0171, 'grad_norm': 7.0087995529174805, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.01578211970627308, 'loss_2': 0.0013532638549804688, 'loss_3': -16.377761840820312, 'loss_4': 0.6078090667724609, 'epoch': 9.37}
{'loss': 0.0455, 'grad_norm': 17.384925842285156, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.04282804951071739, 'loss_2': 0.0026378631591796875, 'loss_3': -16.430856704711914, 'loss_4': 1.1070401668548584, 'epoch': 9.38}
{'loss': 0.0316, 'grad_norm': 8.818068504333496, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.028321024030447006, 'loss_2': 0.0033111572265625, 'loss_3': -16.20629119873047, 'loss_4': 1.2069439888000488, 'epoch': 9.38}
{'loss': 0.0241, 'grad_norm': 10.49181079864502, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.016917450353503227, 'loss_2': 0.00713348388671875, 'loss_3': -16.105667114257812, 'loss_4': 0.9437091946601868, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 13:01:06,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:06,721 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:26<1:01:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:14,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019474714994430542, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.099, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014109344221651554, 'eval_loss_2': 0.0053653717041015625, 'eval_loss_3': -18.274879455566406, 'eval_loss_4': 1.1122478246688843, 'epoch': 9.39}
{'loss': 0.0488, 'grad_norm': 11.83038330078125, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.04111780598759651, 'loss_2': 0.00768280029296875, 'loss_3': -16.123987197875977, 'loss_4': 0.9436399936676025, 'epoch': 9.4}
{'loss': 0.0284, 'grad_norm': 9.76009464263916, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.027501940727233887, 'loss_2': 0.0008502006530761719, 'loss_3': -16.400861740112305, 'loss_4': 1.019568920135498, 'epoch': 9.4}
{'loss': 0.0297, 'grad_norm': 9.972309112548828, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.02007685787975788, 'loss_2': 0.00960540771484375, 'loss_3': -16.304950714111328, 'loss_4': 1.4746665954589844, 'epoch': 9.41}
{'loss': 0.0323, 'grad_norm': 14.706154823303223, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.027929317206144333, 'loss_2': 0.00435638427734375, 'loss_3': -16.33359146118164, 'loss_4': 1.0823479890823364, 'epoch': 9.41}
{'loss': 0.0191, 'grad_norm': 7.054187297821045, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.01744074933230877, 'loss_2': 0.001636505126953125, 'loss_3': -16.336400985717773, 'loss_4': 0.9348653554916382, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 13:01:14,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:14,055 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:33<1:01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:21,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018166404217481613, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015040764585137367, 'eval_loss_2': 0.0031256377696990967, 'eval_loss_3': -18.279888153076172, 'eval_loss_4': 1.2275824546813965, 'epoch': 9.42}
{'loss': 0.0183, 'grad_norm': 7.774903297424316, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.01759863644838333, 'loss_2': 0.0007228851318359375, 'loss_3': -16.20001220703125, 'loss_4': 0.7936420440673828, 'epoch': 9.42}
{'loss': 0.0215, 'grad_norm': 6.892249584197998, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.019407637417316437, 'loss_2': 0.002079010009765625, 'loss_3': -16.390439987182617, 'loss_4': 1.3015040159225464, 'epoch': 9.43}
{'loss': 0.0442, 'grad_norm': 9.833968162536621, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.036063581705093384, 'loss_2': 0.008148193359375, 'loss_3': -16.324609756469727, 'loss_4': 1.021721601486206, 'epoch': 9.44}
{'loss': 0.0188, 'grad_norm': 5.666862964630127, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.01499365083873272, 'loss_2': 0.00379180908203125, 'loss_3': -16.32525634765625, 'loss_4': 1.213407039642334, 'epoch': 9.44}
{'loss': 0.0242, 'grad_norm': 7.073685646057129, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.01489085704088211, 'loss_2': 0.00927734375, 'loss_3': -16.32986068725586, 'loss_4': 1.425523042678833, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 13:01:21,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:21,393 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:40<1:00:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:28,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021145135164260864, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.229, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013322859071195126, 'eval_loss_2': 0.007822275161743164, 'eval_loss_3': -18.262598037719727, 'eval_loss_4': 1.3601579666137695, 'epoch': 9.45}
{'loss': 0.022, 'grad_norm': 6.106726169586182, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.01105104573071003, 'loss_2': 0.010986328125, 'loss_3': -16.559228897094727, 'loss_4': 0.8848212957382202, 'epoch': 9.45}
{'loss': 0.0273, 'grad_norm': 8.000347137451172, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.020705409348011017, 'loss_2': 0.006641387939453125, 'loss_3': -16.19070053100586, 'loss_4': 1.1511813402175903, 'epoch': 9.46}
{'loss': 0.0254, 'grad_norm': 7.981264114379883, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.023152226582169533, 'loss_2': 0.002292633056640625, 'loss_3': -16.344913482666016, 'loss_4': 1.101111650466919, 'epoch': 9.47}
{'loss': 0.0149, 'grad_norm': 4.882957935333252, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.007323939353227615, 'loss_2': 0.0076141357421875, 'loss_3': -16.21738052368164, 'loss_4': 1.2442469596862793, 'epoch': 9.47}
{'loss': 0.0111, 'grad_norm': 5.1616058349609375, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.010539043694734573, 'loss_2': 0.0005245208740234375, 'loss_3': -16.35845375061035, 'loss_4': 1.2786188125610352, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 13:01:28,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:28,724 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:48<1:00:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:36,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015272015705704689, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.951, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012025879696011543, 'eval_loss_2': 0.0032461360096931458, 'eval_loss_3': -18.221881866455078, 'eval_loss_4': 1.4850915670394897, 'epoch': 9.48}
{'loss': 0.0432, 'grad_norm': 14.753971099853516, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.042528461664915085, 'loss_2': 0.0006856918334960938, 'loss_3': -16.214658737182617, 'loss_4': 1.3295903205871582, 'epoch': 9.48}
{'loss': 0.0179, 'grad_norm': 5.86354923248291, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.015467974357306957, 'loss_2': 0.002384185791015625, 'loss_3': -16.20327377319336, 'loss_4': 1.2933329343795776, 'epoch': 9.49}
{'loss': 0.0114, 'grad_norm': 6.07938814163208, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.011221691034734249, 'loss_2': 0.0001844167709350586, 'loss_3': -16.326446533203125, 'loss_4': 1.6863552331924438, 'epoch': 9.49}
{'loss': 0.0661, 'grad_norm': 28.54033088684082, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.06583160907030106, 'loss_2': 0.0002257823944091797, 'loss_3': -16.012248992919922, 'loss_4': 1.6651637554168701, 'epoch': 9.5}
{'loss': 0.0057, 'grad_norm': 4.379014492034912, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.005665661301463842, 'loss_2': 5.453824996948242e-05, 'loss_3': -16.401382446289062, 'loss_4': 1.5267624855041504, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 13:01:36,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:36,063 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:55<1:00:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:43,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015367584303021431, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.057, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012292953208088875, 'eval_loss_2': 0.003074631094932556, 'eval_loss_3': -18.193317413330078, 'eval_loss_4': 1.75434410572052, 'epoch': 9.51}
{'loss': 0.0179, 'grad_norm': 4.755710601806641, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.009457583539187908, 'loss_2': 0.0084381103515625, 'loss_3': -16.30286407470703, 'loss_4': 1.4758895635604858, 'epoch': 9.51}
{'loss': 0.019, 'grad_norm': 5.793787002563477, 'learning_rate': 2.05e-05, 'loss_1': 0.011907578445971012, 'loss_2': 0.007106781005859375, 'loss_3': -16.160690307617188, 'loss_4': 2.1287803649902344, 'epoch': 9.52}
{'loss': 0.0198, 'grad_norm': 7.353649139404297, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.014894222840666771, 'loss_2': 0.00494384765625, 'loss_3': -16.19526481628418, 'loss_4': 2.152212381362915, 'epoch': 9.52}
{'loss': 0.0173, 'grad_norm': 5.536088943481445, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.014648334123194218, 'loss_2': 0.002643585205078125, 'loss_3': -16.09326934814453, 'loss_4': 1.4903671741485596, 'epoch': 9.53}
{'loss': 0.0163, 'grad_norm': 5.609126091003418, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.011057896539568901, 'loss_2': 0.00527191162109375, 'loss_3': -15.83566665649414, 'loss_4': 1.8001031875610352, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 13:01:43,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:43,393 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [41:02<1:00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:50,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01842399686574936, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.996, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014869382604956627, 'eval_loss_2': 0.003554612398147583, 'eval_loss_3': -18.144718170166016, 'eval_loss_4': 1.941671371459961, 'epoch': 9.53}
{'loss': 0.1174, 'grad_norm': 26.874832153320312, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.11069683730602264, 'loss_2': 0.006687164306640625, 'loss_3': -16.001489639282227, 'loss_4': 2.000819444656372, 'epoch': 9.54}
{'loss': 0.0751, 'grad_norm': 22.19257926940918, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.07389018684625626, 'loss_2': 0.001216888427734375, 'loss_3': -16.22865867614746, 'loss_4': 2.008751392364502, 'epoch': 9.55}
{'loss': 0.0841, 'grad_norm': 17.544477462768555, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.08187257498502731, 'loss_2': 0.002197265625, 'loss_3': -16.115751266479492, 'loss_4': 2.0160155296325684, 'epoch': 9.55}
{'loss': 0.0189, 'grad_norm': 6.012152194976807, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.01501142792403698, 'loss_2': 0.0039215087890625, 'loss_3': -16.22760772705078, 'loss_4': 1.6337260007858276, 'epoch': 9.56}
{'loss': 0.0174, 'grad_norm': 5.630625247955322, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.01256009191274643, 'loss_2': 0.004840850830078125, 'loss_3': -16.256004333496094, 'loss_4': 1.669739007949829, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 13:01:50,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:50,735 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [41:10<1:01:32,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:01:58,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020004894584417343, 'eval_runtime': 3.9839, 'eval_samples_per_second': 257.037, 'eval_steps_per_second': 4.016, 'eval_loss_1': 0.01548159122467041, 'eval_loss_2': 0.0045233070850372314, 'eval_loss_3': -18.152103424072266, 'eval_loss_4': 1.9922466278076172, 'epoch': 9.56}
{'loss': 0.0394, 'grad_norm': 13.538928031921387, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.03229373320937157, 'loss_2': 0.0071258544921875, 'loss_3': -16.28184700012207, 'loss_4': 1.7686505317687988, 'epoch': 9.57}
{'loss': 0.013, 'grad_norm': 6.6294403076171875, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.012798020616173744, 'loss_2': 0.00023102760314941406, 'loss_3': -16.366962432861328, 'loss_4': 1.9909151792526245, 'epoch': 9.58}
{'loss': 0.0289, 'grad_norm': 8.387168884277344, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.02269311621785164, 'loss_2': 0.006195068359375, 'loss_3': -16.137039184570312, 'loss_4': 1.7589898109436035, 'epoch': 9.58}
{'loss': 0.0678, 'grad_norm': 16.0900936126709, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.06766903400421143, 'loss_2': 8.100271224975586e-05, 'loss_3': -16.075420379638672, 'loss_4': 2.2113189697265625, 'epoch': 9.59}
{'loss': 0.0203, 'grad_norm': 5.7593488693237305, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.01209922507405281, 'loss_2': 0.00823211669921875, 'loss_3': -16.267444610595703, 'loss_4': 1.9394922256469727, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 13:01:58,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:58,268 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:17<1:00:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:05,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.036541469395160675, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.06, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.031291715800762177, 'eval_loss_2': 0.0052497535943984985, 'eval_loss_3': -18.072294235229492, 'eval_loss_4': 2.037595510482788, 'epoch': 9.59}
{'loss': 0.0198, 'grad_norm': 5.335768222808838, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.007130261976271868, 'loss_2': 0.012664794921875, 'loss_3': -16.302654266357422, 'loss_4': 1.6550999879837036, 'epoch': 9.6}
{'loss': 0.0145, 'grad_norm': 5.114950656890869, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.00781994592398405, 'loss_2': 0.0066680908203125, 'loss_3': -16.230499267578125, 'loss_4': 2.209258556365967, 'epoch': 9.6}
{'loss': 0.0279, 'grad_norm': 9.04393482208252, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.023210782557725906, 'loss_2': 0.00467681884765625, 'loss_3': -15.920831680297852, 'loss_4': 1.9077556133270264, 'epoch': 9.61}
{'loss': 0.0159, 'grad_norm': 5.255920886993408, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.012991285882890224, 'loss_2': 0.002948760986328125, 'loss_3': -16.18910789489746, 'loss_4': 2.0981099605560303, 'epoch': 9.62}
{'loss': 0.0235, 'grad_norm': 17.351558685302734, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.023017827421426773, 'loss_2': 0.00049591064453125, 'loss_3': -16.083763122558594, 'loss_4': 1.8851325511932373, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 13:02:05,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:05,606 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:24<1:00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:12,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029822278767824173, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.308, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.026161139830946922, 'eval_loss_2': 0.0036611407995224, 'eval_loss_3': -18.098814010620117, 'eval_loss_4': 2.079193115234375, 'epoch': 9.62}
{'loss': 0.0196, 'grad_norm': 6.273390769958496, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.013325261883437634, 'loss_2': 0.00628662109375, 'loss_3': -16.282344818115234, 'loss_4': 1.53786301612854, 'epoch': 9.63}
{'loss': 0.0178, 'grad_norm': 5.960971832275391, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.009881564415991306, 'loss_2': 0.00791168212890625, 'loss_3': -16.174213409423828, 'loss_4': 2.020512342453003, 'epoch': 9.63}
{'loss': 0.0194, 'grad_norm': 6.451656818389893, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.014748776331543922, 'loss_2': 0.00464630126953125, 'loss_3': -16.129905700683594, 'loss_4': 1.9303950071334839, 'epoch': 9.64}
{'loss': 0.0165, 'grad_norm': 6.389444351196289, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.014579580165445805, 'loss_2': 0.0018911361694335938, 'loss_3': -16.114120483398438, 'loss_4': 1.3385204076766968, 'epoch': 9.65}
{'loss': 0.016, 'grad_norm': 4.906070232391357, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.010158191435039043, 'loss_2': 0.0058135986328125, 'loss_3': -16.379859924316406, 'loss_4': 2.163564682006836, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 13:02:12,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:12,932 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:32<1:00:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:20,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01136100199073553, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.952, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008015736937522888, 'eval_loss_2': 0.0033452659845352173, 'eval_loss_3': -18.216224670410156, 'eval_loss_4': 2.0430357456207275, 'epoch': 9.65}
{'loss': 0.0091, 'grad_norm': 5.370304107666016, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.008108495734632015, 'loss_2': 0.0009512901306152344, 'loss_3': -16.234102249145508, 'loss_4': 1.421050786972046, 'epoch': 9.66}
{'loss': 0.0216, 'grad_norm': 11.114526748657227, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.021175716072320938, 'loss_2': 0.00041484832763671875, 'loss_3': -16.16861343383789, 'loss_4': 1.9048793315887451, 'epoch': 9.66}
{'loss': 0.0182, 'grad_norm': 5.467344284057617, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.007762936409562826, 'loss_2': 0.010406494140625, 'loss_3': -16.096881866455078, 'loss_4': 1.7489190101623535, 'epoch': 9.67}
{'loss': 0.022, 'grad_norm': 5.77889347076416, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.014460508711636066, 'loss_2': 0.0075225830078125, 'loss_3': -16.042024612426758, 'loss_4': 2.2349770069122314, 'epoch': 9.67}
{'loss': 0.0428, 'grad_norm': 12.670804023742676, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.042482875287532806, 'loss_2': 0.0003197193145751953, 'loss_3': -16.08925437927246, 'loss_4': 2.148926258087158, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 13:02:20,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:20,276 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:39<1:00:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:27,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010982528328895569, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.513, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.007069379091262817, 'eval_loss_2': 0.0039131492376327515, 'eval_loss_3': -18.248329162597656, 'eval_loss_4': 2.1093907356262207, 'epoch': 9.68}
{'loss': 0.0117, 'grad_norm': 5.582564353942871, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.00876636803150177, 'loss_2': 0.002887725830078125, 'loss_3': -16.269424438476562, 'loss_4': 1.7056877613067627, 'epoch': 9.69}
{'loss': 0.0278, 'grad_norm': 13.362229347229004, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.021174555644392967, 'loss_2': 0.00661468505859375, 'loss_3': -15.904623985290527, 'loss_4': 2.1834049224853516, 'epoch': 9.69}
{'loss': 0.0188, 'grad_norm': 5.848540306091309, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.01015700213611126, 'loss_2': 0.00868988037109375, 'loss_3': -16.40554428100586, 'loss_4': 1.664978265762329, 'epoch': 9.7}
{'loss': 0.0269, 'grad_norm': 6.446591377258301, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.01568201556801796, 'loss_2': 0.01116943359375, 'loss_3': -16.241897583007812, 'loss_4': 1.5918104648590088, 'epoch': 9.7}
{'loss': 0.0232, 'grad_norm': 10.891048431396484, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.023070890456438065, 'loss_2': 0.00010716915130615234, 'loss_3': -16.17786407470703, 'loss_4': 2.099465847015381, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 13:02:27,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:27,623 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:46<1:00:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:34,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011077340692281723, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.902, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.006793047767132521, 'eval_loss_2': 0.004284292459487915, 'eval_loss_3': -18.23070526123047, 'eval_loss_4': 1.9540636539459229, 'epoch': 9.71}
{'loss': 0.0076, 'grad_norm': 5.37374210357666, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.005352690815925598, 'loss_2': 0.002269744873046875, 'loss_3': -16.330215454101562, 'loss_4': 1.8294711112976074, 'epoch': 9.72}
{'loss': 0.0321, 'grad_norm': 20.800268173217773, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.029482677578926086, 'loss_2': 0.00261688232421875, 'loss_3': -16.007173538208008, 'loss_4': 2.400026798248291, 'epoch': 9.72}
{'loss': 0.02, 'grad_norm': 5.603165149688721, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.017439117655158043, 'loss_2': 0.0025959014892578125, 'loss_3': -16.15162467956543, 'loss_4': 1.8739211559295654, 'epoch': 9.73}
{'loss': 0.0151, 'grad_norm': 5.90809440612793, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.011891110800206661, 'loss_2': 0.003185272216796875, 'loss_3': -16.197715759277344, 'loss_4': 2.128939628601074, 'epoch': 9.73}
{'loss': 0.0159, 'grad_norm': 6.7184576988220215, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.014204582199454308, 'loss_2': 0.0017366409301757812, 'loss_3': -16.322824478149414, 'loss_4': 2.15792179107666, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 13:02:34,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:34,960 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:54<1:00:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:42,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011520648375153542, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.06, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.0076304092071950436, 'eval_loss_2': 0.0038902387022972107, 'eval_loss_3': -18.242761611938477, 'eval_loss_4': 1.9122580289840698, 'epoch': 9.74}
{'loss': 0.0183, 'grad_norm': 6.4315924644470215, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.015764527022838593, 'loss_2': 0.0025043487548828125, 'loss_3': -16.30840492248535, 'loss_4': 1.620915412902832, 'epoch': 9.74}
{'loss': 0.0178, 'grad_norm': 5.082692623138428, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.00932429637759924, 'loss_2': 0.00850677490234375, 'loss_3': -16.131851196289062, 'loss_4': 1.6455976963043213, 'epoch': 9.75}
{'loss': 0.0216, 'grad_norm': 11.022040367126465, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.020348967984318733, 'loss_2': 0.0012416839599609375, 'loss_3': -16.238178253173828, 'loss_4': 1.9361026287078857, 'epoch': 9.76}
{'loss': 0.0277, 'grad_norm': 8.222145080566406, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.018220003694295883, 'loss_2': 0.00946044921875, 'loss_3': -16.083389282226562, 'loss_4': 1.7522169351577759, 'epoch': 9.76}
{'loss': 0.0108, 'grad_norm': 5.331332206726074, 'learning_rate': 2.025e-05, 'loss_1': 0.004819002002477646, 'loss_2': 0.005962371826171875, 'loss_3': -16.280166625976562, 'loss_4': 1.6773189306259155, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 13:02:42,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:42,295 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [42:01<1:00:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:49,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014349548146128654, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.918, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008369028568267822, 'eval_loss_2': 0.005980517715215683, 'eval_loss_3': -18.264785766601562, 'eval_loss_4': 1.5346307754516602, 'epoch': 9.77}
{'loss': 0.0235, 'grad_norm': 6.67017936706543, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.009213807061314583, 'loss_2': 0.0142669677734375, 'loss_3': -16.491252899169922, 'loss_4': 1.7662107944488525, 'epoch': 9.77}
{'loss': 0.0338, 'grad_norm': 8.150912284851074, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.01638653874397278, 'loss_2': 0.01739501953125, 'loss_3': -16.199317932128906, 'loss_4': 1.5525705814361572, 'epoch': 9.78}
{'loss': 0.0271, 'grad_norm': 7.835832118988037, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.023570382967591286, 'loss_2': 0.003498077392578125, 'loss_3': -16.21001625061035, 'loss_4': 0.5291319489479065, 'epoch': 9.78}
{'loss': 0.016, 'grad_norm': 6.823972702026367, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.012390817515552044, 'loss_2': 0.0035839080810546875, 'loss_3': -16.153736114501953, 'loss_4': 1.3823106288909912, 'epoch': 9.79}
{'loss': 0.0135, 'grad_norm': 5.353407382965088, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.010704400017857552, 'loss_2': 0.002758026123046875, 'loss_3': -16.307872772216797, 'loss_4': 1.3627625703811646, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 13:02:49,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:49,637 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1690/5160 [42:08<59:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:56,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01448914222419262, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.973, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010314969345927238, 'eval_loss_2': 0.004174172878265381, 'eval_loss_3': -18.244300842285156, 'eval_loss_4': 1.158908486366272, 'epoch': 9.8}
{'loss': 0.0102, 'grad_norm': 4.750678062438965, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.007544065825641155, 'loss_2': 0.002658843994140625, 'loss_3': -16.306739807128906, 'loss_4': 1.2300496101379395, 'epoch': 9.8}
{'loss': 0.021, 'grad_norm': 11.560436248779297, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.021007051691412926, 'loss_2': 3.337860107421875e-06, 'loss_3': -16.499858856201172, 'loss_4': 1.5269652605056763, 'epoch': 9.81}
{'loss': 0.0148, 'grad_norm': 5.416244983673096, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.012867043726146221, 'loss_2': 0.0019779205322265625, 'loss_3': -16.375656127929688, 'loss_4': 1.2854454517364502, 'epoch': 9.81}
{'loss': 0.01, 'grad_norm': 4.984505653381348, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.008148621767759323, 'loss_2': 0.0018186569213867188, 'loss_3': -16.398284912109375, 'loss_4': 1.1924887895584106, 'epoch': 9.82}
{'loss': 0.0114, 'grad_norm': 5.46577262878418, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.011166499927639961, 'loss_2': 0.0002734661102294922, 'loss_3': -16.291183471679688, 'loss_4': 1.0178210735321045, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 13:02:56,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:56,973 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [42:16<59:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:04,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016572177410125732, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.939, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012784241698682308, 'eval_loss_2': 0.0037879347801208496, 'eval_loss_3': -18.21299171447754, 'eval_loss_4': 1.073081612586975, 'epoch': 9.83}
{'loss': 0.0197, 'grad_norm': 6.387824535369873, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.014552946202456951, 'loss_2': 0.005157470703125, 'loss_3': -16.100017547607422, 'loss_4': 1.1319397687911987, 'epoch': 9.83}
{'loss': 0.0146, 'grad_norm': 5.405620098114014, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.012091537937521935, 'loss_2': 0.0024776458740234375, 'loss_3': -16.415050506591797, 'loss_4': 1.0319122076034546, 'epoch': 9.84}
{'loss': 0.0425, 'grad_norm': 8.478821754455566, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.030439788475632668, 'loss_2': 0.01201629638671875, 'loss_3': -16.130138397216797, 'loss_4': 0.8589192032814026, 'epoch': 9.84}
{'loss': 0.0207, 'grad_norm': 5.100508689880371, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.009458297863602638, 'loss_2': 0.01125335693359375, 'loss_3': -16.44061279296875, 'loss_4': 0.7228034734725952, 'epoch': 9.85}
{'loss': 0.0178, 'grad_norm': 5.6107354164123535, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.015309453010559082, 'loss_2': 0.0025157928466796875, 'loss_3': -16.268495559692383, 'loss_4': 0.7920602560043335, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 13:03:04,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:04,301 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:23<59:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:11,652 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025226648896932602, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.919, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01848524436354637, 'eval_loss_2': 0.0067414045333862305, 'eval_loss_3': -18.190282821655273, 'eval_loss_4': 0.6955496072769165, 'epoch': 9.85}
{'loss': 0.0311, 'grad_norm': 8.589530944824219, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.018300268799066544, 'loss_2': 0.01275634765625, 'loss_3': -16.28279685974121, 'loss_4': 0.5952565670013428, 'epoch': 9.86}
{'loss': 0.0304, 'grad_norm': 27.956403732299805, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.025572113692760468, 'loss_2': 0.00478363037109375, 'loss_3': -16.23245620727539, 'loss_4': 0.7999915480613708, 'epoch': 9.87}
{'loss': 0.0167, 'grad_norm': 5.769122123718262, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.01043463684618473, 'loss_2': 0.0062713623046875, 'loss_3': -16.27098846435547, 'loss_4': 0.797819972038269, 'epoch': 9.87}
{'loss': 0.0174, 'grad_norm': 5.113464832305908, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.012429464608430862, 'loss_2': 0.0050048828125, 'loss_3': -16.144306182861328, 'loss_4': 0.3466731607913971, 'epoch': 9.88}
{'loss': 0.0181, 'grad_norm': 8.907865524291992, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.017370877787470818, 'loss_2': 0.0006875991821289062, 'loss_3': -16.41754150390625, 'loss_4': 0.4536115527153015, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 13:03:11,652 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:11,652 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:30<59:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:18,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016699034720659256, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.09, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012270945124328136, 'eval_loss_2': 0.004428088665008545, 'eval_loss_3': -18.256549835205078, 'eval_loss_4': 0.5572554469108582, 'epoch': 9.88}
{'loss': 0.0159, 'grad_norm': 7.676778316497803, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.012910247780382633, 'loss_2': 0.002941131591796875, 'loss_3': -16.34571075439453, 'loss_4': 0.7563080787658691, 'epoch': 9.89}
{'loss': 0.02, 'grad_norm': 6.284045696258545, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.014356924220919609, 'loss_2': 0.00568389892578125, 'loss_3': -16.380468368530273, 'loss_4': 0.5972540378570557, 'epoch': 9.9}
{'loss': 0.0284, 'grad_norm': 5.824172019958496, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.01850850321352482, 'loss_2': 0.0098724365234375, 'loss_3': -16.408336639404297, 'loss_4': 0.4168723225593567, 'epoch': 9.9}
{'loss': 0.0408, 'grad_norm': 12.345756530761719, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.032308146357536316, 'loss_2': 0.008453369140625, 'loss_3': -16.276670455932617, 'loss_4': 1.069624900817871, 'epoch': 9.91}
{'loss': 0.0233, 'grad_norm': 6.971729755401611, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.020672013983130455, 'loss_2': 0.002666473388671875, 'loss_3': -16.500957489013672, 'loss_4': 0.5926365256309509, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 13:03:18,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:18,982 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:38<59:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:26,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015098330564796925, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.297, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0106146689504385, 'eval_loss_2': 0.004483662545681, 'eval_loss_3': -18.26764678955078, 'eval_loss_4': 0.5515929460525513, 'epoch': 9.91}
{'loss': 0.0121, 'grad_norm': 5.210777282714844, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.009425707161426544, 'loss_2': 0.002651214599609375, 'loss_3': -16.201608657836914, 'loss_4': 0.5396783351898193, 'epoch': 9.92}
{'loss': 0.0681, 'grad_norm': 16.03091049194336, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.05059599131345749, 'loss_2': 0.0174560546875, 'loss_3': -16.2861328125, 'loss_4': 0.2839196026325226, 'epoch': 9.92}
{'loss': 0.0313, 'grad_norm': 8.68984603881836, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.02133895829319954, 'loss_2': 0.0099334716796875, 'loss_3': -16.283889770507812, 'loss_4': 0.15030056238174438, 'epoch': 9.93}
{'loss': 0.1082, 'grad_norm': 22.50580596923828, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.09399427473545074, 'loss_2': 0.01416778564453125, 'loss_3': -16.34688377380371, 'loss_4': 0.8979984521865845, 'epoch': 9.94}
{'loss': 0.053, 'grad_norm': 14.010510444641113, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.03594093397259712, 'loss_2': 0.017059326171875, 'loss_3': -16.26073455810547, 'loss_4': 0.46450111269950867, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 13:03:26,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:26,307 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:45<59:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:33,640 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017478838562965393, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.106, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010675385594367981, 'eval_loss_2': 0.006803452968597412, 'eval_loss_3': -18.24298095703125, 'eval_loss_4': 0.6253414154052734, 'epoch': 9.94}
{'loss': 0.0238, 'grad_norm': 5.255392074584961, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.009708517231047153, 'loss_2': 0.0141143798828125, 'loss_3': -16.45756721496582, 'loss_4': 0.8754317760467529, 'epoch': 9.95}
{'loss': 0.027, 'grad_norm': 7.722661018371582, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.021642936393618584, 'loss_2': 0.005352020263671875, 'loss_3': -16.32596778869629, 'loss_4': 0.7673685550689697, 'epoch': 9.95}
{'loss': 0.0225, 'grad_norm': 6.750608444213867, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.01659005880355835, 'loss_2': 0.00595855712890625, 'loss_3': -16.151809692382812, 'loss_4': 0.733315646648407, 'epoch': 9.96}
{'loss': 0.0296, 'grad_norm': 9.422415733337402, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.02954457700252533, 'loss_2': 4.398822784423828e-05, 'loss_3': -16.365814208984375, 'loss_4': 0.24392177164554596, 'epoch': 9.97}
{'loss': 0.0197, 'grad_norm': 5.766877174377441, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.01522659882903099, 'loss_2': 0.00443267822265625, 'loss_3': -16.35390281677246, 'loss_4': 0.9976481795310974, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 13:03:33,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:33,640 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:52<53:26,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:03:40,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014142322354018688, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.994, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011643520556390285, 'eval_loss_2': 0.0024988017976284027, 'eval_loss_3': -18.2274227142334, 'eval_loss_4': 0.665378212928772, 'epoch': 9.97}
{'loss': 0.0195, 'grad_norm': 5.704403400421143, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.01511840708553791, 'loss_2': 0.00437164306640625, 'loss_3': -16.573246002197266, 'loss_4': 0.4659791588783264, 'epoch': 9.98}
{'loss': 0.0125, 'grad_norm': 5.788447856903076, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.01011090911924839, 'loss_2': 0.0023479461669921875, 'loss_3': -16.31650161743164, 'loss_4': 0.6261780261993408, 'epoch': 9.98}
{'loss': 0.0114, 'grad_norm': 5.718367576599121, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.008872168138623238, 'loss_2': 0.0024871826171875, 'loss_3': -16.511266708374023, 'loss_4': 0.6186326742172241, 'epoch': 9.99}
{'loss': 0.0292, 'grad_norm': 7.174086570739746, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.02037220448255539, 'loss_2': 0.00878143310546875, 'loss_3': -16.378215789794922, 'loss_4': 0.4018503427505493, 'epoch': 9.99}
{'loss': 0.0058, 'grad_norm': 6.106969833374023, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.0015587672824040055, 'loss_2': 0.0042572021484375, 'loss_3': -16.333293914794922, 'loss_4': 0.6541128754615784, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 13:03:40,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:40,625 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [43:00<58:33,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:03:48,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013953134417533875, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.438, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011116579174995422, 'eval_loss_2': 0.002836555242538452, 'eval_loss_3': -18.19866371154785, 'eval_loss_4': 0.7509442567825317, 'epoch': 10.0}
{'loss': 0.0164, 'grad_norm': 5.086742877960205, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.010985554195940495, 'loss_2': 0.0054473876953125, 'loss_3': -16.453384399414062, 'loss_4': 0.7995585203170776, 'epoch': 10.01}
{'loss': 0.0169, 'grad_norm': 7.4574456214904785, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.01513072568923235, 'loss_2': 0.0017490386962890625, 'loss_3': -16.380460739135742, 'loss_4': 0.5845009684562683, 'epoch': 10.01}
{'loss': 0.0349, 'grad_norm': 14.69014835357666, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.03072173334658146, 'loss_2': 0.004184722900390625, 'loss_3': -16.452350616455078, 'loss_4': 0.7858158946037292, 'epoch': 10.02}
{'loss': 0.0202, 'grad_norm': 8.503687858581543, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.018463626503944397, 'loss_2': 0.0017337799072265625, 'loss_3': -16.36886978149414, 'loss_4': 0.741425633430481, 'epoch': 10.02}
{'loss': 0.0087, 'grad_norm': 5.204483985900879, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.007909264415502548, 'loss_2': 0.0007476806640625, 'loss_3': -16.337329864501953, 'loss_4': 0.8035989999771118, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 13:03:48,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:48,011 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [43:07<59:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:03:55,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014617917127907276, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.994, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01082282979041338, 'eval_loss_2': 0.0037950873374938965, 'eval_loss_3': -18.227733612060547, 'eval_loss_4': 0.705848753452301, 'epoch': 10.03}
{'loss': 0.0166, 'grad_norm': 6.006000518798828, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.011932425200939178, 'loss_2': 0.00469970703125, 'loss_3': -16.465927124023438, 'loss_4': 0.6399044990539551, 'epoch': 10.03}
{'loss': 0.0481, 'grad_norm': 9.714676856994629, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.044942356646060944, 'loss_2': 0.003108978271484375, 'loss_3': -16.37546730041504, 'loss_4': 0.6752232313156128, 'epoch': 10.04}
{'loss': 0.0212, 'grad_norm': 8.077390670776367, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.01853642426431179, 'loss_2': 0.002712249755859375, 'loss_3': -16.403709411621094, 'loss_4': 1.0008292198181152, 'epoch': 10.05}
{'loss': 0.0156, 'grad_norm': 6.335194110870361, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.015423542819917202, 'loss_2': 0.00016033649444580078, 'loss_3': -16.503955841064453, 'loss_4': 0.8436261415481567, 'epoch': 10.05}
{'loss': 0.031, 'grad_norm': 7.899471282958984, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.020326146855950356, 'loss_2': 0.010711669921875, 'loss_3': -16.300512313842773, 'loss_4': 0.8436105251312256, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 13:03:55,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:55,345 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [43:14<59:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:02,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014109432697296143, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.005, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011269517242908478, 'eval_loss_2': 0.002839915454387665, 'eval_loss_3': -18.236927032470703, 'eval_loss_4': 0.6852927803993225, 'epoch': 10.06}
{'loss': 0.0151, 'grad_norm': 4.969815731048584, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.0076151457615196705, 'loss_2': 0.00745391845703125, 'loss_3': -16.567699432373047, 'loss_4': 0.5580481290817261, 'epoch': 10.06}
{'loss': 0.0503, 'grad_norm': 18.146224975585938, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.04807222634553909, 'loss_2': 0.002231597900390625, 'loss_3': -16.491981506347656, 'loss_4': 0.4737544655799866, 'epoch': 10.07}
{'loss': 0.032, 'grad_norm': 10.471181869506836, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.03169521316885948, 'loss_2': 0.0002589225769042969, 'loss_3': -16.479774475097656, 'loss_4': 1.2119675874710083, 'epoch': 10.08}
{'loss': 0.0267, 'grad_norm': 5.528800964355469, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.02150331251323223, 'loss_2': 0.00521087646484375, 'loss_3': -16.4080810546875, 'loss_4': 1.207340955734253, 'epoch': 10.08}
{'loss': 0.0249, 'grad_norm': 7.662431240081787, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.018966175615787506, 'loss_2': 0.00597381591796875, 'loss_3': -16.435733795166016, 'loss_4': 0.35395896434783936, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 13:04:02,683 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:02,683 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:22<59:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:10,021 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016172729432582855, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.134, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01150514930486679, 'eval_loss_2': 0.0046675801277160645, 'eval_loss_3': -18.223182678222656, 'eval_loss_4': 0.6910458207130432, 'epoch': 10.09}
{'loss': 0.0178, 'grad_norm': 6.41718053817749, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.014138750731945038, 'loss_2': 0.003704071044921875, 'loss_3': -16.2867374420166, 'loss_4': 0.5914450883865356, 'epoch': 10.09}
{'loss': 0.0174, 'grad_norm': 5.791258335113525, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.014661780558526516, 'loss_2': 0.0027179718017578125, 'loss_3': -16.445297241210938, 'loss_4': 0.9325128793716431, 'epoch': 10.1}
{'loss': 0.0131, 'grad_norm': 5.320952892303467, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.012277035973966122, 'loss_2': 0.000782012939453125, 'loss_3': -16.33942222595215, 'loss_4': 0.5424137711524963, 'epoch': 10.1}
{'loss': 0.0437, 'grad_norm': 15.57892894744873, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.0433395653963089, 'loss_2': 0.00038242340087890625, 'loss_3': -16.28436279296875, 'loss_4': 0.5399032831192017, 'epoch': 10.11}
{'loss': 0.0151, 'grad_norm': 6.061130523681641, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.013059761375188828, 'loss_2': 0.0019969940185546875, 'loss_3': -16.258838653564453, 'loss_4': 0.5496799349784851, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 13:04:10,021 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:10,021 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:29<58:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:17,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019214095547795296, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.196, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.014423348940908909, 'eval_loss_2': 0.004790745675563812, 'eval_loss_3': -18.185741424560547, 'eval_loss_4': 0.4348175823688507, 'epoch': 10.12}
{'loss': 0.0118, 'grad_norm': 5.0344953536987305, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.009267223067581654, 'loss_2': 0.0025634765625, 'loss_3': -16.471120834350586, 'loss_4': 0.5193536281585693, 'epoch': 10.12}
{'loss': 0.0216, 'grad_norm': 7.52240514755249, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.02085699327290058, 'loss_2': 0.0007381439208984375, 'loss_3': -16.34561538696289, 'loss_4': 0.6942800879478455, 'epoch': 10.13}
{'loss': 0.0278, 'grad_norm': 7.011205673217773, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.014526433311402798, 'loss_2': 0.01331329345703125, 'loss_3': -16.355308532714844, 'loss_4': 0.3033215403556824, 'epoch': 10.13}
{'loss': 0.0186, 'grad_norm': 4.885053634643555, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.008211249485611916, 'loss_2': 0.0103759765625, 'loss_3': -16.533466339111328, 'loss_4': 0.39976102113723755, 'epoch': 10.14}
{'loss': 0.0259, 'grad_norm': 5.124329090118408, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.012241866439580917, 'loss_2': 0.013702392578125, 'loss_3': -16.203290939331055, 'loss_4': 0.5736990571022034, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 13:04:17,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:17,347 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:36<58:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:24,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023959873244166374, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.41, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.017635013908147812, 'eval_loss_2': 0.006324857473373413, 'eval_loss_3': -18.149932861328125, 'eval_loss_4': 0.15171581506729126, 'epoch': 10.15}
{'loss': 0.0217, 'grad_norm': 6.351764678955078, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.017017338424921036, 'loss_2': 0.00464630126953125, 'loss_3': -16.232973098754883, 'loss_4': 0.09186501801013947, 'epoch': 10.15}
{'loss': 0.0144, 'grad_norm': 5.0806884765625, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.009252093732357025, 'loss_2': 0.005157470703125, 'loss_3': -16.406414031982422, 'loss_4': 0.094622902572155, 'epoch': 10.16}
{'loss': 0.0318, 'grad_norm': 8.771044731140137, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.025119878351688385, 'loss_2': 0.006683349609375, 'loss_3': -16.446428298950195, 'loss_4': -0.0033202767372131348, 'epoch': 10.16}
{'loss': 0.0156, 'grad_norm': 5.780791282653809, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.011400172486901283, 'loss_2': 0.00423431396484375, 'loss_3': -15.98128890991211, 'loss_4': 0.09059050679206848, 'epoch': 10.17}
{'loss': 0.0576, 'grad_norm': 19.15196418762207, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.053078543394804, 'loss_2': 0.00455474853515625, 'loss_3': -16.318496704101562, 'loss_4': 0.7211759090423584, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 13:04:24,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:24,695 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:44<58:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:32,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021405145525932312, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.698, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01655118353664875, 'eval_loss_2': 0.004853963851928711, 'eval_loss_3': -18.121402740478516, 'eval_loss_4': 0.35436367988586426, 'epoch': 10.17}
{'loss': 0.0186, 'grad_norm': 7.634771823883057, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.01786653883755207, 'loss_2': 0.0006947517395019531, 'loss_3': -16.406536102294922, 'loss_4': 0.45835524797439575, 'epoch': 10.18}
{'loss': 0.016, 'grad_norm': 7.4206976890563965, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.015560219064354897, 'loss_2': 0.0004069805145263672, 'loss_3': -16.367050170898438, 'loss_4': 0.32374244928359985, 'epoch': 10.19}
{'loss': 0.0199, 'grad_norm': 7.565107345581055, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.014598947949707508, 'loss_2': 0.005268096923828125, 'loss_3': -16.339893341064453, 'loss_4': 0.434551864862442, 'epoch': 10.19}
{'loss': 0.0271, 'grad_norm': 6.8948822021484375, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.019176563248038292, 'loss_2': 0.0079345703125, 'loss_3': -16.175357818603516, 'loss_4': 0.5667732954025269, 'epoch': 10.2}
{'loss': 0.0276, 'grad_norm': 8.63094711303711, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.025926994159817696, 'loss_2': 0.0017080307006835938, 'loss_3': -16.252246856689453, 'loss_4': 0.7795071005821228, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 13:04:32,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:32,033 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:51<58:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:39,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02404545620083809, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.96, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.015301765874028206, 'eval_loss_2': 0.008743688464164734, 'eval_loss_3': -18.14162254333496, 'eval_loss_4': 0.5202849507331848, 'epoch': 10.2}
{'loss': 0.0344, 'grad_norm': 11.632439613342285, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.02571847103536129, 'loss_2': 0.008697509765625, 'loss_3': -16.127267837524414, 'loss_4': 0.43716317415237427, 'epoch': 10.21}
{'loss': 0.0288, 'grad_norm': 9.023340225219727, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.020601017400622368, 'loss_2': 0.0081787109375, 'loss_3': -16.20905876159668, 'loss_4': 0.5824366211891174, 'epoch': 10.22}
{'loss': 0.0168, 'grad_norm': 8.959574699401855, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.014211046509444714, 'loss_2': 0.002620697021484375, 'loss_3': -16.199371337890625, 'loss_4': 0.7434018850326538, 'epoch': 10.22}
{'loss': 0.0436, 'grad_norm': 15.056346893310547, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.03720523416996002, 'loss_2': 0.00640869140625, 'loss_3': -16.252578735351562, 'loss_4': 0.6889604926109314, 'epoch': 10.23}
{'loss': 0.0325, 'grad_norm': 7.837893486022949, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.02327106148004532, 'loss_2': 0.009246826171875, 'loss_3': -16.38014793395996, 'loss_4': 0.5082040429115295, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 13:04:39,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:39,362 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:58<58:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:46,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019922565668821335, 'eval_runtime': 3.789, 'eval_samples_per_second': 270.259, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.016341399401426315, 'eval_loss_2': 0.0035811662673950195, 'eval_loss_3': -18.17953872680664, 'eval_loss_4': 0.4229881763458252, 'epoch': 10.23}
{'loss': 0.0177, 'grad_norm': 8.67565631866455, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.014821246266365051, 'loss_2': 0.002925872802734375, 'loss_3': -16.449777603149414, 'loss_4': 0.43253737688064575, 'epoch': 10.24}
{'loss': 0.0151, 'grad_norm': 8.195527076721191, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.013270121067762375, 'loss_2': 0.0018491744995117188, 'loss_3': -16.454553604125977, 'loss_4': 0.09123679250478745, 'epoch': 10.24}
{'loss': 0.0226, 'grad_norm': 7.662535667419434, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.021063702180981636, 'loss_2': 0.0014934539794921875, 'loss_3': -16.375545501708984, 'loss_4': 0.5235267877578735, 'epoch': 10.25}
{'loss': 0.023, 'grad_norm': 8.293303489685059, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.02098899334669113, 'loss_2': 0.0020427703857421875, 'loss_3': -16.265365600585938, 'loss_4': 0.3679402470588684, 'epoch': 10.26}
{'loss': 0.0358, 'grad_norm': 15.798530578613281, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.030648602172732353, 'loss_2': 0.00518035888671875, 'loss_3': -16.490806579589844, 'loss_4': 0.5577651262283325, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 13:04:46,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:46,689 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [44:06<58:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:54,021 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019438959658145905, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.152, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016529515385627747, 'eval_loss_2': 0.002909444272518158, 'eval_loss_3': -18.174501419067383, 'eval_loss_4': 0.3245578706264496, 'epoch': 10.26}
{'loss': 0.0277, 'grad_norm': 9.071331024169922, 'learning_rate': 1.975e-05, 'loss_1': 0.020897841081023216, 'loss_2': 0.00676727294921875, 'loss_3': -16.481342315673828, 'loss_4': 0.38102784752845764, 'epoch': 10.27}
{'loss': 0.0162, 'grad_norm': 6.345747470855713, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.015880824998021126, 'loss_2': 0.0003457069396972656, 'loss_3': -16.56380271911621, 'loss_4': 0.5958751440048218, 'epoch': 10.27}
{'loss': 0.0255, 'grad_norm': 10.042885780334473, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.023922422900795937, 'loss_2': 0.001617431640625, 'loss_3': -16.537433624267578, 'loss_4': 0.416100412607193, 'epoch': 10.28}
{'loss': 0.0183, 'grad_norm': 6.715388298034668, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.015608616173267365, 'loss_2': 0.00272369384765625, 'loss_3': -16.19124984741211, 'loss_4': 0.6934775114059448, 'epoch': 10.28}
{'loss': 0.018, 'grad_norm': 6.613300323486328, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.015344789251685143, 'loss_2': 0.0026912689208984375, 'loss_3': -16.3261775970459, 'loss_4': 0.8274248838424683, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 13:04:54,021 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:54,021 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [44:13<58:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:01,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02319171093404293, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.315, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01867746375501156, 'eval_loss_2': 0.004514247179031372, 'eval_loss_3': -18.175554275512695, 'eval_loss_4': 0.3910524547100067, 'epoch': 10.29}
{'loss': 0.0205, 'grad_norm': 6.618829250335693, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.014643503352999687, 'loss_2': 0.005855560302734375, 'loss_3': -16.176971435546875, 'loss_4': -0.06463449448347092, 'epoch': 10.3}
{'loss': 0.0233, 'grad_norm': 8.956254005432129, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.016590947285294533, 'loss_2': 0.006694793701171875, 'loss_3': -16.499303817749023, 'loss_4': 0.7899119853973389, 'epoch': 10.3}
{'loss': 0.033, 'grad_norm': 16.584890365600586, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.029014963656663895, 'loss_2': 0.003993988037109375, 'loss_3': -16.296791076660156, 'loss_4': 0.4964178800582886, 'epoch': 10.31}
{'loss': 0.017, 'grad_norm': 6.335353374481201, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.016244370490312576, 'loss_2': 0.0007524490356445312, 'loss_3': -16.30194854736328, 'loss_4': 0.5716519355773926, 'epoch': 10.31}
{'loss': 0.0223, 'grad_norm': 8.887146949768066, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.021872013807296753, 'loss_2': 0.00046443939208984375, 'loss_3': -16.27862548828125, 'loss_4': 0.2359556257724762, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 13:05:01,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:01,349 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:20<58:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:08,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024341706186532974, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.542, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.020602768287062645, 'eval_loss_2': 0.0037389397621154785, 'eval_loss_3': -18.174936294555664, 'eval_loss_4': 0.29312196373939514, 'epoch': 10.32}
{'loss': 0.0151, 'grad_norm': 4.925108432769775, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.010904194787144661, 'loss_2': 0.00417327880859375, 'loss_3': -16.344623565673828, 'loss_4': 0.3667318820953369, 'epoch': 10.33}
{'loss': 0.0207, 'grad_norm': 6.830760955810547, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.015156290493905544, 'loss_2': 0.0055084228515625, 'loss_3': -16.236984252929688, 'loss_4': 0.10559776425361633, 'epoch': 10.33}
{'loss': 0.0169, 'grad_norm': 5.164373874664307, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.007348639890551567, 'loss_2': 0.009552001953125, 'loss_3': -16.299673080444336, 'loss_4': -0.016732409596443176, 'epoch': 10.34}
{'loss': 0.0159, 'grad_norm': 5.00922966003418, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.008862568996846676, 'loss_2': 0.007068634033203125, 'loss_3': -16.271289825439453, 'loss_4': 0.7054096460342407, 'epoch': 10.34}
{'loss': 0.0412, 'grad_norm': 8.123786926269531, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.029434390366077423, 'loss_2': 0.01174163818359375, 'loss_3': -16.322450637817383, 'loss_4': 0.48233547806739807, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 13:05:08,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:08,686 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:28<58:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:16,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032671306282281876, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.737, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02722536399960518, 'eval_loss_2': 0.005445942282676697, 'eval_loss_3': -18.138046264648438, 'eval_loss_4': 0.20476195216178894, 'epoch': 10.35}
{'loss': 0.0188, 'grad_norm': 4.805243492126465, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.01260431855916977, 'loss_2': 0.0061492919921875, 'loss_3': -16.432029724121094, 'loss_4': 0.34297797083854675, 'epoch': 10.35}
{'loss': 0.0182, 'grad_norm': 6.438124179840088, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.017755506560206413, 'loss_2': 0.0004172325134277344, 'loss_3': -16.399776458740234, 'loss_4': 0.06974447518587112, 'epoch': 10.36}
{'loss': 0.0141, 'grad_norm': 5.136632919311523, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.011551246047019958, 'loss_2': 0.00252532958984375, 'loss_3': -16.28295135498047, 'loss_4': 0.33816468715667725, 'epoch': 10.37}
{'loss': 0.0182, 'grad_norm': 7.788506507873535, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.016943825408816338, 'loss_2': 0.0012912750244140625, 'loss_3': -16.331947326660156, 'loss_4': 0.08378524333238602, 'epoch': 10.37}
{'loss': 0.0262, 'grad_norm': 7.968112468719482, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.01894204504787922, 'loss_2': 0.0072174072265625, 'loss_3': -16.222427368164062, 'loss_4': 0.09652101993560791, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 13:05:16,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:16,025 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:35<58:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:23,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032333847135305405, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.030503688380122185, 'eval_loss_2': 0.0018301606178283691, 'eval_loss_3': -18.135574340820312, 'eval_loss_4': 0.060377299785614014, 'epoch': 10.38}
{'loss': 0.0417, 'grad_norm': 13.727323532104492, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.038310468196868896, 'loss_2': 0.0034084320068359375, 'loss_3': -16.30012321472168, 'loss_4': 0.4953010082244873, 'epoch': 10.38}
{'loss': 0.0169, 'grad_norm': 5.196409225463867, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.013293075375258923, 'loss_2': 0.00362396240234375, 'loss_3': -16.491744995117188, 'loss_4': 0.1396723985671997, 'epoch': 10.39}
{'loss': 0.0127, 'grad_norm': 5.3369574546813965, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.008006704039871693, 'loss_2': 0.0046844482421875, 'loss_3': -16.34256362915039, 'loss_4': 0.2775004506111145, 'epoch': 10.4}
{'loss': 0.0132, 'grad_norm': 5.545267105102539, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.010965277440845966, 'loss_2': 0.0022182464599609375, 'loss_3': -16.3195858001709, 'loss_4': -0.00965750589966774, 'epoch': 10.4}
{'loss': 0.0194, 'grad_norm': 6.484506130218506, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.01789465919137001, 'loss_2': 0.0015163421630859375, 'loss_3': -16.28391456604004, 'loss_4': 0.2898995876312256, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 13:05:23,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:23,370 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:42<58:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:30,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01980869099497795, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.824, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01730148121714592, 'eval_loss_2': 0.0025072097778320312, 'eval_loss_3': -18.186168670654297, 'eval_loss_4': 0.02684241533279419, 'epoch': 10.41}
{'loss': 0.0174, 'grad_norm': 5.852306365966797, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.011672302149236202, 'loss_2': 0.005680084228515625, 'loss_3': -16.58328628540039, 'loss_4': 0.038718245923519135, 'epoch': 10.41}
{'loss': 0.012, 'grad_norm': 4.477937698364258, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.0066221910528838634, 'loss_2': 0.00537872314453125, 'loss_3': -16.371078491210938, 'loss_4': -0.04299478605389595, 'epoch': 10.42}
{'loss': 0.0232, 'grad_norm': 10.132548332214355, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.015825971961021423, 'loss_2': 0.00740814208984375, 'loss_3': -16.431968688964844, 'loss_4': 0.3192094564437866, 'epoch': 10.42}
{'loss': 0.0243, 'grad_norm': 8.086094856262207, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.01900343969464302, 'loss_2': 0.005279541015625, 'loss_3': -16.408733367919922, 'loss_4': 0.0718143880367279, 'epoch': 10.43}
{'loss': 0.0233, 'grad_norm': 8.701330184936523, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.021929262205958366, 'loss_2': 0.001415252685546875, 'loss_3': -16.38544273376465, 'loss_4': 0.4126177430152893, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 13:05:30,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:30,709 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:50<58:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:38,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017756031826138496, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.085, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014042485505342484, 'eval_loss_2': 0.003713548183441162, 'eval_loss_3': -18.201263427734375, 'eval_loss_4': 0.021353688091039658, 'epoch': 10.44}
{'loss': 0.0365, 'grad_norm': 8.997175216674805, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.034915741533041, 'loss_2': 0.0016155242919921875, 'loss_3': -16.520856857299805, 'loss_4': -0.21868979930877686, 'epoch': 10.44}
{'loss': 0.0136, 'grad_norm': 5.83766508102417, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.013412965461611748, 'loss_2': 0.0001850128173828125, 'loss_3': -16.429359436035156, 'loss_4': -0.02777111530303955, 'epoch': 10.45}
{'loss': 0.0244, 'grad_norm': 7.088766574859619, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.018897758796811104, 'loss_2': 0.005512237548828125, 'loss_3': -16.54079246520996, 'loss_4': 0.17743198573589325, 'epoch': 10.45}
{'loss': 0.0243, 'grad_norm': 11.511165618896484, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.0174267515540123, 'loss_2': 0.0068359375, 'loss_3': -16.33826446533203, 'loss_4': -0.11735141277313232, 'epoch': 10.46}
{'loss': 0.0466, 'grad_norm': 11.810174942016602, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.03977096825838089, 'loss_2': 0.00684356689453125, 'loss_3': -16.52699851989746, 'loss_4': 0.8728411197662354, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 13:05:38,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:38,038 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:57<57:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:45,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01316436193883419, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.241, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00937668140977621, 'eval_loss_2': 0.003787681460380554, 'eval_loss_3': -18.24564552307129, 'eval_loss_4': 0.021608998998999596, 'epoch': 10.47}
{'loss': 0.0172, 'grad_norm': 6.00003719329834, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.015529995784163475, 'loss_2': 0.0016202926635742188, 'loss_3': -16.47613525390625, 'loss_4': -0.21791335940361023, 'epoch': 10.47}
{'loss': 0.0247, 'grad_norm': 7.400513648986816, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.018672047182917595, 'loss_2': 0.005992889404296875, 'loss_3': -16.44392967224121, 'loss_4': 0.43900519609451294, 'epoch': 10.48}
{'loss': 0.0267, 'grad_norm': 6.396158218383789, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.019630067050457, 'loss_2': 0.00704193115234375, 'loss_3': -16.411375045776367, 'loss_4': 0.017538681626319885, 'epoch': 10.48}
{'loss': 0.0192, 'grad_norm': 7.995453834533691, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.017571084201335907, 'loss_2': 0.0016536712646484375, 'loss_3': -16.47501564025879, 'loss_4': 0.15135544538497925, 'epoch': 10.49}
{'loss': 0.0144, 'grad_norm': 5.377870082855225, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.010496304370462894, 'loss_2': 0.003936767578125, 'loss_3': -16.333581924438477, 'loss_4': 0.5280967950820923, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 13:05:45,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:45,370 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [45:04<57:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:52,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01216798834502697, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.771, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00884493999183178, 'eval_loss_2': 0.0033230483531951904, 'eval_loss_3': -18.306955337524414, 'eval_loss_4': 0.015864742919802666, 'epoch': 10.49}
{'loss': 0.0197, 'grad_norm': 8.20975112915039, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.018839556723833084, 'loss_2': 0.000904083251953125, 'loss_3': -16.436355590820312, 'loss_4': 0.5847454071044922, 'epoch': 10.5}
{'loss': 0.0141, 'grad_norm': 4.8202409744262695, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.009756207466125488, 'loss_2': 0.0043792724609375, 'loss_3': -16.571306228637695, 'loss_4': 0.3359586000442505, 'epoch': 10.51}
{'loss': 0.0301, 'grad_norm': 10.140973091125488, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.024155128747224808, 'loss_2': 0.005916595458984375, 'loss_3': -16.34061050415039, 'loss_4': 0.4677317440509796, 'epoch': 10.51}
{'loss': 0.0172, 'grad_norm': 6.419676780700684, 'learning_rate': 1.95e-05, 'loss_1': 0.011147357523441315, 'loss_2': 0.006072998046875, 'loss_3': -16.641620635986328, 'loss_4': -0.14665676653385162, 'epoch': 10.52}
{'loss': 0.0186, 'grad_norm': 5.460836410522461, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.010743065737187862, 'loss_2': 0.007843017578125, 'loss_3': -16.622188568115234, 'loss_4': 0.7033122777938843, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 13:05:52,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:52,714 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [45:12<57:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:00,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012202173471450806, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.052, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009061158634722233, 'eval_loss_2': 0.0031410157680511475, 'eval_loss_3': -18.357765197753906, 'eval_loss_4': -0.19101326167583466, 'epoch': 10.52}
{'loss': 0.0209, 'grad_norm': 6.845339298248291, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.017214177176356316, 'loss_2': 0.00371551513671875, 'loss_3': -16.377365112304688, 'loss_4': -0.09068837761878967, 'epoch': 10.53}
{'loss': 0.0471, 'grad_norm': 10.513944625854492, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.0423000231385231, 'loss_2': 0.004756927490234375, 'loss_3': -16.53097152709961, 'loss_4': 0.07679283618927002, 'epoch': 10.53}
{'loss': 0.0411, 'grad_norm': 9.724767684936523, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.03282931074500084, 'loss_2': 0.0083160400390625, 'loss_3': -16.395946502685547, 'loss_4': 0.35558199882507324, 'epoch': 10.54}
{'loss': 0.0375, 'grad_norm': 11.92076301574707, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.03503662347793579, 'loss_2': 0.0024509429931640625, 'loss_3': -16.598567962646484, 'loss_4': -0.12237820029258728, 'epoch': 10.55}
{'loss': 0.0109, 'grad_norm': 5.175435543060303, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.008624075911939144, 'loss_2': 0.002269744873046875, 'loss_3': -16.384782791137695, 'loss_4': -0.4160653352737427, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 13:06:00,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:00,042 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:19<57:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:07,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011360520496964455, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008877481333911419, 'eval_loss_2': 0.0024830400943756104, 'eval_loss_3': -18.347179412841797, 'eval_loss_4': -0.4876417815685272, 'epoch': 10.55}
{'loss': 0.0535, 'grad_norm': 17.247785568237305, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.04787399619817734, 'loss_2': 0.00559234619140625, 'loss_3': -16.537200927734375, 'loss_4': 0.6276484131813049, 'epoch': 10.56}
{'loss': 0.0278, 'grad_norm': 9.195502281188965, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.02777901664376259, 'loss_2': 4.029273986816406e-05, 'loss_3': -16.601377487182617, 'loss_4': -0.027357041835784912, 'epoch': 10.56}
{'loss': 0.0188, 'grad_norm': 10.521076202392578, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.01655491814017296, 'loss_2': 0.00226593017578125, 'loss_3': -16.578357696533203, 'loss_4': -0.193273663520813, 'epoch': 10.57}
{'loss': 0.0225, 'grad_norm': 8.530281066894531, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.017339328303933144, 'loss_2': 0.00516510009765625, 'loss_3': -16.64894676208496, 'loss_4': -0.47905728220939636, 'epoch': 10.58}
{'loss': 0.0277, 'grad_norm': 7.668639183044434, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.01874503120779991, 'loss_2': 0.00897979736328125, 'loss_3': -16.59376335144043, 'loss_4': -0.19850870966911316, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 13:06:07,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:07,375 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:26<57:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:14,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016179846599698067, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.969, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009896325878798962, 'eval_loss_2': 0.00628352165222168, 'eval_loss_3': -18.366756439208984, 'eval_loss_4': -0.7382885217666626, 'epoch': 10.58}
{'loss': 0.0283, 'grad_norm': 11.82059097290039, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.0212942473590374, 'loss_2': 0.00701904296875, 'loss_3': -16.587844848632812, 'loss_4': -0.6720303297042847, 'epoch': 10.59}
{'loss': 0.0397, 'grad_norm': 9.593033790588379, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.03127383440732956, 'loss_2': 0.008453369140625, 'loss_3': -16.71771240234375, 'loss_4': -0.3336542546749115, 'epoch': 10.59}
{'loss': 0.0245, 'grad_norm': 6.036546230316162, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.013489997014403343, 'loss_2': 0.0109710693359375, 'loss_3': -16.407432556152344, 'loss_4': -0.5972787141799927, 'epoch': 10.6}
{'loss': 0.0424, 'grad_norm': 11.292757034301758, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.03680255264043808, 'loss_2': 0.00560760498046875, 'loss_3': -16.67235565185547, 'loss_4': -0.2730978727340698, 'epoch': 10.6}
{'loss': 0.0286, 'grad_norm': 7.425401210784912, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.025086693465709686, 'loss_2': 0.00347137451171875, 'loss_3': -16.342655181884766, 'loss_4': -0.8004055023193359, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 13:06:14,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:14,712 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:34<57:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:22,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01600777730345726, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.906, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013172429986298084, 'eval_loss_2': 0.0028353482484817505, 'eval_loss_3': -18.30451011657715, 'eval_loss_4': -0.5813405513763428, 'epoch': 10.61}
{'loss': 0.0225, 'grad_norm': 6.53562593460083, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.01724862866103649, 'loss_2': 0.00524139404296875, 'loss_3': -16.545387268066406, 'loss_4': -0.08475211262702942, 'epoch': 10.62}
{'loss': 0.0206, 'grad_norm': 6.255853176116943, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.012180231511592865, 'loss_2': 0.00838470458984375, 'loss_3': -16.44122314453125, 'loss_4': -0.39450106024742126, 'epoch': 10.62}
{'loss': 0.0212, 'grad_norm': 9.46214771270752, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.018618274480104446, 'loss_2': 0.002628326416015625, 'loss_3': -16.544775009155273, 'loss_4': -0.24129608273506165, 'epoch': 10.63}
{'loss': 0.0257, 'grad_norm': 8.943272590637207, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.0185104813426733, 'loss_2': 0.0072021484375, 'loss_3': -16.59777069091797, 'loss_4': -0.38286399841308594, 'epoch': 10.63}
{'loss': 0.0218, 'grad_norm': 9.458642959594727, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.016017843037843704, 'loss_2': 0.00579833984375, 'loss_3': -16.42448616027832, 'loss_4': 0.13262057304382324, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 13:06:22,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:22,043 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:41<57:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:29,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01716690883040428, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.754, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014208589680492878, 'eval_loss_2': 0.0029583200812339783, 'eval_loss_3': -18.283628463745117, 'eval_loss_4': -0.5271191000938416, 'epoch': 10.64}
{'loss': 0.043, 'grad_norm': 12.865278244018555, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.039068836718797684, 'loss_2': 0.00395965576171875, 'loss_3': -16.5030460357666, 'loss_4': -0.19372299313545227, 'epoch': 10.65}
{'loss': 0.0158, 'grad_norm': 6.167990207672119, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.011887974105775356, 'loss_2': 0.00390625, 'loss_3': -16.67223358154297, 'loss_4': -0.24566517770290375, 'epoch': 10.65}
{'loss': 0.1119, 'grad_norm': 26.82394790649414, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.10984503477811813, 'loss_2': 0.00200653076171875, 'loss_3': -16.339012145996094, 'loss_4': -0.21531079709529877, 'epoch': 10.66}
{'loss': 0.0205, 'grad_norm': 10.300357818603516, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.017696641385555267, 'loss_2': 0.0027637481689453125, 'loss_3': -16.55491828918457, 'loss_4': -0.4230044186115265, 'epoch': 10.66}
{'loss': 0.0111, 'grad_norm': 5.311892032623291, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.00866363663226366, 'loss_2': 0.002483367919921875, 'loss_3': -16.606470108032227, 'loss_4': -0.4493725895881653, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 13:06:29,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:29,376 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:48<57:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:36,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017179591581225395, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.014592809602618217, 'eval_loss_2': 0.0025867819786071777, 'eval_loss_3': -18.256385803222656, 'eval_loss_4': -0.40334460139274597, 'epoch': 10.67}
{'loss': 0.0245, 'grad_norm': 12.143957138061523, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.017466921359300613, 'loss_2': 0.00699615478515625, 'loss_3': -16.458057403564453, 'loss_4': -0.38117843866348267, 'epoch': 10.67}
{'loss': 0.031, 'grad_norm': 8.040242195129395, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.025019032880663872, 'loss_2': 0.0059967041015625, 'loss_3': -16.437353134155273, 'loss_4': -0.29176008701324463, 'epoch': 10.68}
{'loss': 0.0126, 'grad_norm': 5.504014015197754, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.009526172652840614, 'loss_2': 0.00311279296875, 'loss_3': -16.58513832092285, 'loss_4': 0.08970387279987335, 'epoch': 10.69}
{'loss': 0.0177, 'grad_norm': 5.942596435546875, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.012805301696062088, 'loss_2': 0.00485992431640625, 'loss_3': -16.466733932495117, 'loss_4': -0.30343097448349, 'epoch': 10.69}
{'loss': 0.016, 'grad_norm': 7.8088788986206055, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.014641324989497662, 'loss_2': 0.00138092041015625, 'loss_3': -16.50971794128418, 'loss_4': -0.11377915740013123, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 13:06:36,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:36,710 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:56<57:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:44,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018490150570869446, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.963, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01601150631904602, 'eval_loss_2': 0.0024786442518234253, 'eval_loss_3': -18.224763870239258, 'eval_loss_4': -0.25171390175819397, 'epoch': 10.7}
{'loss': 0.01, 'grad_norm': 5.91338586807251, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.009885689243674278, 'loss_2': 0.0001270771026611328, 'loss_3': -16.424560546875, 'loss_4': -0.1978524923324585, 'epoch': 10.7}
{'loss': 0.0194, 'grad_norm': 7.977611064910889, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.017844965681433678, 'loss_2': 0.0015277862548828125, 'loss_3': -16.374666213989258, 'loss_4': -0.15824635326862335, 'epoch': 10.71}
{'loss': 0.0097, 'grad_norm': 4.649238109588623, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.006568574346601963, 'loss_2': 0.003086090087890625, 'loss_3': -16.683246612548828, 'loss_4': -0.41462451219558716, 'epoch': 10.72}
{'loss': 0.0139, 'grad_norm': 5.9019670486450195, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.012983984313905239, 'loss_2': 0.0009331703186035156, 'loss_3': -16.440444946289062, 'loss_4': -0.5545274019241333, 'epoch': 10.72}
{'loss': 0.0134, 'grad_norm': 4.76956844329834, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.009521624073386192, 'loss_2': 0.003902435302734375, 'loss_3': -16.544872283935547, 'loss_4': -0.3778441548347473, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 13:06:44,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:44,042 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [46:03<57:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:51,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023608600720763206, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.065, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.02039370685815811, 'eval_loss_2': 0.003214895725250244, 'eval_loss_3': -18.200448989868164, 'eval_loss_4': -0.3973483145236969, 'epoch': 10.73}
{'loss': 0.0239, 'grad_norm': 7.805696487426758, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.021837852895259857, 'loss_2': 0.00205230712890625, 'loss_3': -16.178686141967773, 'loss_4': -0.0409075953066349, 'epoch': 10.73}
{'loss': 0.0183, 'grad_norm': 7.056018829345703, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.012830064631998539, 'loss_2': 0.00543212890625, 'loss_3': -16.48627471923828, 'loss_4': -0.12335085868835449, 'epoch': 10.74}
{'loss': 0.0201, 'grad_norm': 9.06005859375, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.01911543682217598, 'loss_2': 0.0009412765502929688, 'loss_3': -16.335796356201172, 'loss_4': -0.4245980381965637, 'epoch': 10.74}
{'loss': 0.0189, 'grad_norm': 7.304406642913818, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.015088541433215141, 'loss_2': 0.003818511962890625, 'loss_3': -16.48411750793457, 'loss_4': 0.11702825129032135, 'epoch': 10.75}
{'loss': 0.0255, 'grad_norm': 8.200948715209961, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.022601516917347908, 'loss_2': 0.0028934478759765625, 'loss_3': -16.393260955810547, 'loss_4': -0.2892358899116516, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 13:06:51,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:51,369 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [46:10<57:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:06:58,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0314289852976799, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.183, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.026132697239518166, 'eval_loss_2': 0.005296289920806885, 'eval_loss_3': -18.19668960571289, 'eval_loss_4': -0.663986086845398, 'epoch': 10.76}
{'loss': 0.0139, 'grad_norm': 4.294161319732666, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.006694050505757332, 'loss_2': 0.007228851318359375, 'loss_3': -16.374706268310547, 'loss_4': -0.6857444047927856, 'epoch': 10.76}
{'loss': 0.016, 'grad_norm': 5.38381814956665, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.009878130629658699, 'loss_2': 0.0060882568359375, 'loss_3': -16.549301147460938, 'loss_4': -0.7385755181312561, 'epoch': 10.77}
{'loss': 0.021, 'grad_norm': 8.332587242126465, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.017911722883582115, 'loss_2': 0.0030670166015625, 'loss_3': -16.41769790649414, 'loss_4': -0.8225225210189819, 'epoch': 10.77}
{'loss': 0.0103, 'grad_norm': 4.9245429039001465, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.006410831119865179, 'loss_2': 0.00390625, 'loss_3': -16.427505493164062, 'loss_4': -0.7425936460494995, 'epoch': 10.78}
{'loss': 0.0381, 'grad_norm': 19.522607803344727, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.03270088881254196, 'loss_2': 0.00536346435546875, 'loss_3': -16.583223342895508, 'loss_4': -0.6484380960464478, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 13:06:58,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:58,693 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:18<56:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:06,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037690676748752594, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.246, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.034319858998060226, 'eval_loss_2': 0.003370821475982666, 'eval_loss_3': -18.165016174316406, 'eval_loss_4': -0.8216527700424194, 'epoch': 10.78}
{'loss': 0.0098, 'grad_norm': 4.329489707946777, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.006428826134651899, 'loss_2': 0.0033435821533203125, 'loss_3': -16.36264419555664, 'loss_4': -0.6777647733688354, 'epoch': 10.79}
{'loss': 0.0172, 'grad_norm': 5.404862403869629, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.009104099124670029, 'loss_2': 0.0080718994140625, 'loss_3': -16.458324432373047, 'loss_4': -1.0532276630401611, 'epoch': 10.8}
{'loss': 0.0105, 'grad_norm': 5.012149333953857, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.007783391512930393, 'loss_2': 0.00269317626953125, 'loss_3': -16.44216537475586, 'loss_4': -0.8344516158103943, 'epoch': 10.8}
{'loss': 0.0208, 'grad_norm': 7.017200946807861, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.0181109718978405, 'loss_2': 0.00272369384765625, 'loss_3': -16.232948303222656, 'loss_4': -0.782447338104248, 'epoch': 10.81}
{'loss': 0.0271, 'grad_norm': 6.918766975402832, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.014068118296563625, 'loss_2': 0.0130767822265625, 'loss_3': -16.478614807128906, 'loss_4': -1.0119043588638306, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 13:07:06,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:06,025 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:25<56:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:13,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04268622398376465, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.584, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03646504506468773, 'eval_loss_2': 0.006221175193786621, 'eval_loss_3': -18.15689468383789, 'eval_loss_4': -0.8056144714355469, 'epoch': 10.81}
{'loss': 0.0276, 'grad_norm': 12.75320816040039, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.023408403620123863, 'loss_2': 0.00415802001953125, 'loss_3': -16.26821517944336, 'loss_4': -0.5044984221458435, 'epoch': 10.82}
{'loss': 0.0176, 'grad_norm': 5.794536590576172, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.009191839024424553, 'loss_2': 0.00841522216796875, 'loss_3': -16.659780502319336, 'loss_4': -0.5164389610290527, 'epoch': 10.83}
{'loss': 0.0194, 'grad_norm': 6.168481826782227, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.013495995663106441, 'loss_2': 0.005939483642578125, 'loss_3': -16.35446548461914, 'loss_4': -0.955287516117096, 'epoch': 10.83}
{'loss': 0.0095, 'grad_norm': 5.660312652587891, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.009020630270242691, 'loss_2': 0.00048470497131347656, 'loss_3': -16.315431594848633, 'loss_4': -0.4410296678543091, 'epoch': 10.84}
{'loss': 0.0129, 'grad_norm': 6.324977397918701, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.010414578951895237, 'loss_2': 0.002460479736328125, 'loss_3': -16.5952205657959, 'loss_4': -0.9863402843475342, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 13:07:13,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:13,370 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:32<56:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:07:20,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027913611382246017, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.025645073503255844, 'eval_loss_2': 0.0022685378789901733, 'eval_loss_3': -18.176584243774414, 'eval_loss_4': -0.651273787021637, 'epoch': 10.84}
{'loss': 0.0137, 'grad_norm': 4.5783610343933105, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.005871663335710764, 'loss_2': 0.0078277587890625, 'loss_3': -16.31765365600586, 'loss_4': -0.8645806312561035, 'epoch': 10.85}
{'loss': 0.0137, 'grad_norm': 5.653200149536133, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.008272522129118443, 'loss_2': 0.005462646484375, 'loss_3': -16.569387435913086, 'loss_4': -0.5002490878105164, 'epoch': 10.85}
{'loss': 0.018, 'grad_norm': 11.624671936035156, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.011159584857523441, 'loss_2': 0.00685882568359375, 'loss_3': -16.25310707092285, 'loss_4': -0.8512384295463562, 'epoch': 10.86}
{'loss': 0.0092, 'grad_norm': 5.252377986907959, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.00831659696996212, 'loss_2': 0.000896453857421875, 'loss_3': -16.509864807128906, 'loss_4': 0.04219396039843559, 'epoch': 10.87}
{'loss': 0.0148, 'grad_norm': 4.91502571105957, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.012314226478338242, 'loss_2': 0.002475738525390625, 'loss_3': -16.347137451171875, 'loss_4': -0.0611361563205719, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 13:07:20,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:20,691 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:40<56:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:28,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013562127016484737, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.214, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.010979428887367249, 'eval_loss_2': 0.0025826990604400635, 'eval_loss_3': -18.29851531982422, 'eval_loss_4': -0.36132457852363586, 'epoch': 10.87}
{'loss': 0.0073, 'grad_norm': 4.925935745239258, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.006873649079352617, 'loss_2': 0.0004596710205078125, 'loss_3': -16.370437622070312, 'loss_4': -0.30427759885787964, 'epoch': 10.88}
{'loss': 0.0255, 'grad_norm': 10.115300178527832, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.025211531668901443, 'loss_2': 0.0002732276916503906, 'loss_3': -16.407337188720703, 'loss_4': -0.1630440503358841, 'epoch': 10.88}
{'loss': 0.0278, 'grad_norm': 9.509177207946777, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.0268204715102911, 'loss_2': 0.0009508132934570312, 'loss_3': -16.477455139160156, 'loss_4': 0.4954891800880432, 'epoch': 10.89}
{'loss': 0.0098, 'grad_norm': 4.949452877044678, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.009196095168590546, 'loss_2': 0.0006237030029296875, 'loss_3': -16.38555145263672, 'loss_4': 0.10776989161968231, 'epoch': 10.9}
{'loss': 0.0259, 'grad_norm': 6.665695667266846, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.0200238898396492, 'loss_2': 0.005840301513671875, 'loss_3': -16.455873489379883, 'loss_4': 0.5081536769866943, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 13:07:28,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:28,023 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:47<56:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:35,350 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01361529715359211, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.125, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.008362340740859509, 'eval_loss_2': 0.005252957344055176, 'eval_loss_3': -18.34201431274414, 'eval_loss_4': -0.057285647839307785, 'epoch': 10.9}
{'loss': 0.0301, 'grad_norm': 8.71177864074707, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.025494307279586792, 'loss_2': 0.0045928955078125, 'loss_3': -16.283794403076172, 'loss_4': -0.17654408514499664, 'epoch': 10.91}
{'loss': 0.0195, 'grad_norm': 5.781052589416504, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.014386054128408432, 'loss_2': 0.00508880615234375, 'loss_3': -16.428560256958008, 'loss_4': 0.09375178813934326, 'epoch': 10.91}
{'loss': 0.0216, 'grad_norm': 5.126986026763916, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.010621998459100723, 'loss_2': 0.010986328125, 'loss_3': -16.483898162841797, 'loss_4': 0.34981438517570496, 'epoch': 10.92}
{'loss': 0.0184, 'grad_norm': 5.060827732086182, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.014032114297151566, 'loss_2': 0.00441741943359375, 'loss_3': -16.503734588623047, 'loss_4': 0.7656656503677368, 'epoch': 10.92}
{'loss': 0.0301, 'grad_norm': 8.8740873336792, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.024967430159449577, 'loss_2': 0.00510406494140625, 'loss_3': -16.398597717285156, 'loss_4': -0.11287736147642136, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 13:07:35,350 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:35,350 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:54<56:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:42,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011615265160799026, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.005, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008128572255373001, 'eval_loss_2': 0.0034866929054260254, 'eval_loss_3': -18.32966423034668, 'eval_loss_4': 0.10802384465932846, 'epoch': 10.93}
{'loss': 0.0182, 'grad_norm': 9.588302612304688, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.014996514655649662, 'loss_2': 0.0032176971435546875, 'loss_3': -16.30199432373047, 'loss_4': 0.17954343557357788, 'epoch': 10.94}
{'loss': 0.0969, 'grad_norm': 12.391757011413574, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.0962430015206337, 'loss_2': 0.0006647109985351562, 'loss_3': -16.255218505859375, 'loss_4': 0.43789005279541016, 'epoch': 10.94}
{'loss': 0.0402, 'grad_norm': 11.967726707458496, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.0325322300195694, 'loss_2': 0.007640838623046875, 'loss_3': -16.307565689086914, 'loss_4': 0.48334747552871704, 'epoch': 10.95}
{'loss': 0.0118, 'grad_norm': 5.099081039428711, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.011590763926506042, 'loss_2': 0.0002105236053466797, 'loss_3': -16.306346893310547, 'loss_4': 0.2524901032447815, 'epoch': 10.95}
{'loss': 0.0204, 'grad_norm': 8.0186128616333, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.016145572066307068, 'loss_2': 0.00424957275390625, 'loss_3': -16.527603149414062, 'loss_4': 0.5258033275604248, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 13:07:42,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:42,684 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [47:02<56:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:50,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01059233583509922, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.792, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.007411623373627663, 'eval_loss_2': 0.0031807124614715576, 'eval_loss_3': -18.32716941833496, 'eval_loss_4': 0.2036457061767578, 'epoch': 10.96}
{'loss': 0.0239, 'grad_norm': 7.692910194396973, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.022859033197164536, 'loss_2': 0.0010814666748046875, 'loss_3': -16.13190269470215, 'loss_4': 0.4316715598106384, 'epoch': 10.97}
{'loss': 0.0149, 'grad_norm': 6.015815258026123, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.010708615183830261, 'loss_2': 0.00421905517578125, 'loss_3': -16.58358383178711, 'loss_4': 0.6152384877204895, 'epoch': 10.97}
{'loss': 0.0569, 'grad_norm': 11.568428039550781, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.05573008209466934, 'loss_2': 0.0011281967163085938, 'loss_3': -16.40904426574707, 'loss_4': 0.839889407157898, 'epoch': 10.98}
{'loss': 0.2285, 'grad_norm': 40.5345458984375, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.22647283971309662, 'loss_2': 0.001979827880859375, 'loss_3': -16.16407012939453, 'loss_4': 0.22849822044372559, 'epoch': 10.98}
{'loss': 0.0221, 'grad_norm': 11.86528491973877, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.0219441968947649, 'loss_2': 0.000152587890625, 'loss_3': -16.163021087646484, 'loss_4': 0.5746511816978455, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 13:07:50,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:50,025 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [47:09<54:43,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:07:57,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010620107874274254, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.878, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.007125367876142263, 'eval_loss_2': 0.003494739532470703, 'eval_loss_3': -18.29823112487793, 'eval_loss_4': 0.45411619544029236, 'epoch': 10.99}
{'loss': 0.0215, 'grad_norm': 8.34286880493164, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.01953374408185482, 'loss_2': 0.001922607421875, 'loss_3': -16.361621856689453, 'loss_4': 0.7520338892936707, 'epoch': 10.99}
{'loss': 0.0073, 'grad_norm': 5.765650272369385, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.0032006509136408567, 'loss_2': 0.00414276123046875, 'loss_3': -16.416889190673828, 'loss_4': 1.0241438150405884, 'epoch': 11.0}
{'loss': 0.0295, 'grad_norm': 10.909932136535645, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.025029592216014862, 'loss_2': 0.004425048828125, 'loss_3': -16.38450813293457, 'loss_4': 0.877790629863739, 'epoch': 11.01}
{'loss': 0.0301, 'grad_norm': 9.725492477416992, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.02523217909038067, 'loss_2': 0.00484466552734375, 'loss_3': -16.428115844726562, 'loss_4': 1.3109675645828247, 'epoch': 11.01}
{'loss': 0.0155, 'grad_norm': 5.432125091552734, 'learning_rate': 1.9e-05, 'loss_1': 0.012587964534759521, 'loss_2': 0.0029392242431640625, 'loss_3': -16.32899284362793, 'loss_4': 0.6002976894378662, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 13:07:57,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:57,042 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:16<56:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:08:04,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013539083302021027, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.213, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.007907888852059841, 'eval_loss_2': 0.005631193518638611, 'eval_loss_3': -18.306074142456055, 'eval_loss_4': 0.753282904624939, 'epoch': 11.02}
{'loss': 0.0174, 'grad_norm': 4.7317657470703125, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.007946529425680637, 'loss_2': 0.00940704345703125, 'loss_3': -16.156824111938477, 'loss_4': 0.7733970880508423, 'epoch': 11.02}
{'loss': 0.0245, 'grad_norm': 5.433457374572754, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.015478178858757019, 'loss_2': 0.0090179443359375, 'loss_3': -16.305702209472656, 'loss_4': 0.5167925357818604, 'epoch': 11.03}
{'loss': 0.0484, 'grad_norm': 11.738028526306152, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.042589765042066574, 'loss_2': 0.0057830810546875, 'loss_3': -16.186927795410156, 'loss_4': 0.8013741970062256, 'epoch': 11.03}
{'loss': 0.0265, 'grad_norm': 10.003439903259277, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.01867528259754181, 'loss_2': 0.0078582763671875, 'loss_3': -16.34696388244629, 'loss_4': 0.8179770708084106, 'epoch': 11.04}
{'loss': 0.0187, 'grad_norm': 5.809123516082764, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.010797486640512943, 'loss_2': 0.00792694091796875, 'loss_3': -16.469234466552734, 'loss_4': 1.1327054500579834, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 13:08:04,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:04,371 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:23<56:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:11,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0124127846211195, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.165, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.00783631019294262, 'eval_loss_2': 0.00457647442817688, 'eval_loss_3': -18.267803192138672, 'eval_loss_4': 0.7062532901763916, 'epoch': 11.05}
{'loss': 0.0147, 'grad_norm': 6.351415634155273, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.01445676852017641, 'loss_2': 0.00020205974578857422, 'loss_3': -16.633939743041992, 'loss_4': 0.9895453453063965, 'epoch': 11.05}
{'loss': 0.0214, 'grad_norm': 7.154404640197754, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.017636464908719063, 'loss_2': 0.00379180908203125, 'loss_3': -16.494159698486328, 'loss_4': 1.1329237222671509, 'epoch': 11.06}
{'loss': 0.014, 'grad_norm': 6.070912837982178, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.013612438924610615, 'loss_2': 0.00034356117248535156, 'loss_3': -16.423229217529297, 'loss_4': 0.9327812790870667, 'epoch': 11.06}
{'loss': 0.0282, 'grad_norm': 11.071076393127441, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.027157999575138092, 'loss_2': 0.000995635986328125, 'loss_3': -16.442020416259766, 'loss_4': 0.8693386912345886, 'epoch': 11.07}
{'loss': 0.0237, 'grad_norm': 9.593340873718262, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.02125510573387146, 'loss_2': 0.00243377685546875, 'loss_3': -16.589765548706055, 'loss_4': 0.6913304328918457, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 13:08:11,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:11,701 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:31<56:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:19,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01445063203573227, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00901617668569088, 'eval_loss_2': 0.00543445348739624, 'eval_loss_3': -18.264644622802734, 'eval_loss_4': 0.6604699492454529, 'epoch': 11.08}
{'loss': 0.015, 'grad_norm': 5.992615699768066, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.013646342791616917, 'loss_2': 0.0013580322265625, 'loss_3': -16.490352630615234, 'loss_4': 0.8614422082901001, 'epoch': 11.08}
{'loss': 0.0174, 'grad_norm': 5.620325565338135, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.01138524990528822, 'loss_2': 0.006008148193359375, 'loss_3': -16.366500854492188, 'loss_4': 1.0074542760849, 'epoch': 11.09}
{'loss': 0.029, 'grad_norm': 8.911924362182617, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.017002787441015244, 'loss_2': 0.01200103759765625, 'loss_3': -16.38630485534668, 'loss_4': 0.7611924409866333, 'epoch': 11.09}
{'loss': 0.0537, 'grad_norm': 17.11815643310547, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.0469324104487896, 'loss_2': 0.00675201416015625, 'loss_3': -16.442522048950195, 'loss_4': 0.7106311321258545, 'epoch': 11.1}
{'loss': 0.072, 'grad_norm': 19.53399085998535, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.06928443163633347, 'loss_2': 0.00275421142578125, 'loss_3': -16.330263137817383, 'loss_4': 0.74448561668396, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 13:08:19,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:19,035 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:38<56:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:26,363 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02154282107949257, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.18, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012384925037622452, 'eval_loss_2': 0.009157896041870117, 'eval_loss_3': -18.234272003173828, 'eval_loss_4': 0.7747131586074829, 'epoch': 11.1}
{'loss': 0.0189, 'grad_norm': 5.654168605804443, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.010786057449877262, 'loss_2': 0.0080718994140625, 'loss_3': -16.386144638061523, 'loss_4': 0.8566646575927734, 'epoch': 11.11}
{'loss': 0.0148, 'grad_norm': 5.595805644989014, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.013418979942798615, 'loss_2': 0.0013952255249023438, 'loss_3': -16.226224899291992, 'loss_4': 0.5975573062896729, 'epoch': 11.12}
{'loss': 0.0223, 'grad_norm': 9.911824226379395, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.018318239599466324, 'loss_2': 0.00399017333984375, 'loss_3': -16.311153411865234, 'loss_4': 1.0137590169906616, 'epoch': 11.12}
{'loss': 0.0488, 'grad_norm': 10.886039733886719, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.03924507275223732, 'loss_2': 0.00958251953125, 'loss_3': -16.42477798461914, 'loss_4': 1.0088059902191162, 'epoch': 11.13}
{'loss': 0.0548, 'grad_norm': 16.676843643188477, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.051456693559885025, 'loss_2': 0.003314971923828125, 'loss_3': -16.263858795166016, 'loss_4': 0.8411308526992798, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 13:08:26,363 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:26,364 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:45<55:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:33,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015115020796656609, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.845, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011229065246880054, 'eval_loss_2': 0.0038859546184539795, 'eval_loss_3': -18.2381534576416, 'eval_loss_4': 0.8344760537147522, 'epoch': 11.13}
{'loss': 0.0204, 'grad_norm': 6.544394016265869, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.01611517369747162, 'loss_2': 0.0042877197265625, 'loss_3': -16.32220458984375, 'loss_4': 0.8708044290542603, 'epoch': 11.14}
{'loss': 0.0471, 'grad_norm': 20.25119400024414, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.036408163607120514, 'loss_2': 0.01068115234375, 'loss_3': -16.488174438476562, 'loss_4': 0.9659852981567383, 'epoch': 11.15}
{'loss': 0.013, 'grad_norm': 6.350176811218262, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.010328056290745735, 'loss_2': 0.002658843994140625, 'loss_3': -16.30194091796875, 'loss_4': 0.9127421379089355, 'epoch': 11.15}
{'loss': 0.0239, 'grad_norm': 6.778207778930664, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.014162774197757244, 'loss_2': 0.0097503662109375, 'loss_3': -16.38409996032715, 'loss_4': 1.1233820915222168, 'epoch': 11.16}
{'loss': 0.0131, 'grad_norm': 5.742303848266602, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.012300019152462482, 'loss_2': 0.00075531005859375, 'loss_3': -16.365596771240234, 'loss_4': 1.0544180870056152, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 13:08:33,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:33,702 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:53<55:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:41,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01637093536555767, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.086, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009393980726599693, 'eval_loss_2': 0.006976954638957977, 'eval_loss_3': -18.285797119140625, 'eval_loss_4': 0.9724851846694946, 'epoch': 11.16}
{'loss': 0.0163, 'grad_norm': 4.554400444030762, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.006802011746913195, 'loss_2': 0.0095367431640625, 'loss_3': -16.634456634521484, 'loss_4': 0.9819787740707397, 'epoch': 11.17}
{'loss': 0.0422, 'grad_norm': 13.208703994750977, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.029394684359431267, 'loss_2': 0.01280975341796875, 'loss_3': -16.31268310546875, 'loss_4': 0.9533252716064453, 'epoch': 11.17}
{'loss': 0.0092, 'grad_norm': 5.224668979644775, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.004077389370650053, 'loss_2': 0.00514984130859375, 'loss_3': -16.490406036376953, 'loss_4': 1.1633398532867432, 'epoch': 11.18}
{'loss': 0.0235, 'grad_norm': 5.686246395111084, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.013604767620563507, 'loss_2': 0.0098876953125, 'loss_3': -16.238239288330078, 'loss_4': 0.9400221705436707, 'epoch': 11.19}
{'loss': 0.0169, 'grad_norm': 6.191851615905762, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.012648506090044975, 'loss_2': 0.00428009033203125, 'loss_3': -16.37645721435547, 'loss_4': 1.3926911354064941, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 13:08:41,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:41,038 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [48:00<55:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:48,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016928113996982574, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.104, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010396159254014492, 'eval_loss_2': 0.006531953811645508, 'eval_loss_3': -18.322452545166016, 'eval_loss_4': 1.1810060739517212, 'epoch': 11.19}
{'loss': 0.0416, 'grad_norm': 16.509326934814453, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.03508799895644188, 'loss_2': 0.00652313232421875, 'loss_3': -16.48133087158203, 'loss_4': 1.0014457702636719, 'epoch': 11.2}
{'loss': 0.0211, 'grad_norm': 5.581077575683594, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.008538978174328804, 'loss_2': 0.012603759765625, 'loss_3': -16.45783233642578, 'loss_4': 1.2902135848999023, 'epoch': 11.2}
{'loss': 0.0239, 'grad_norm': 6.665709972381592, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.015707025304436684, 'loss_2': 0.00815582275390625, 'loss_3': -16.405820846557617, 'loss_4': 1.7382853031158447, 'epoch': 11.21}
{'loss': 0.0119, 'grad_norm': 5.079176902770996, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.005484233610332012, 'loss_2': 0.006458282470703125, 'loss_3': -16.49098014831543, 'loss_4': 1.2450981140136719, 'epoch': 11.22}
{'loss': 0.0133, 'grad_norm': 5.792729377746582, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.012640425935387611, 'loss_2': 0.00063323974609375, 'loss_3': -16.579517364501953, 'loss_4': 1.4392979145050049, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 13:08:48,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:48,371 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [48:07<55:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:55,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013778803870081902, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.985, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009412168525159359, 'eval_loss_2': 0.004366636276245117, 'eval_loss_3': -18.324234008789062, 'eval_loss_4': 1.375591516494751, 'epoch': 11.22}
{'loss': 0.025, 'grad_norm': 9.887238502502441, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.01866414211690426, 'loss_2': 0.006328582763671875, 'loss_3': -16.433712005615234, 'loss_4': 1.7657098770141602, 'epoch': 11.23}
{'loss': 0.0282, 'grad_norm': 8.907472610473633, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.022248968482017517, 'loss_2': 0.00591278076171875, 'loss_3': -16.528961181640625, 'loss_4': 1.729116439819336, 'epoch': 11.23}
{'loss': 0.0537, 'grad_norm': 18.082168579101562, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.04147195443511009, 'loss_2': 0.012237548828125, 'loss_3': -16.640972137451172, 'loss_4': 1.496457576751709, 'epoch': 11.24}
{'loss': 0.0095, 'grad_norm': 4.7144012451171875, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.006700961384922266, 'loss_2': 0.002838134765625, 'loss_3': -16.381492614746094, 'loss_4': 1.4562218189239502, 'epoch': 11.24}
{'loss': 0.0157, 'grad_norm': 5.272741794586182, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.009648162871599197, 'loss_2': 0.006072998046875, 'loss_3': -16.363853454589844, 'loss_4': 1.4885506629943848, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 13:08:55,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:55,708 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [48:15<55:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:03,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013568577356636524, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.032, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.008464780636131763, 'eval_loss_2': 0.005103796720504761, 'eval_loss_3': -18.322860717773438, 'eval_loss_4': 1.1562578678131104, 'epoch': 11.25}
{'loss': 0.0234, 'grad_norm': 6.533005237579346, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.01664384827017784, 'loss_2': 0.00676727294921875, 'loss_3': -16.500518798828125, 'loss_4': 1.131608009338379, 'epoch': 11.26}
{'loss': 0.0155, 'grad_norm': 6.80650520324707, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.011618300341069698, 'loss_2': 0.003887176513671875, 'loss_3': -16.42559051513672, 'loss_4': 1.415741205215454, 'epoch': 11.26}
{'loss': 0.0097, 'grad_norm': 6.792690277099609, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.009107696823775768, 'loss_2': 0.0005817413330078125, 'loss_3': -16.209796905517578, 'loss_4': 1.0365097522735596, 'epoch': 11.27}
{'loss': 0.0204, 'grad_norm': 5.977424621582031, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.017077220603823662, 'loss_2': 0.003368377685546875, 'loss_3': -16.309947967529297, 'loss_4': 1.4009218215942383, 'epoch': 11.27}
{'loss': 0.0116, 'grad_norm': 5.244711875915527, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.00891909096390009, 'loss_2': 0.0027256011962890625, 'loss_3': -16.347476959228516, 'loss_4': 1.005252480506897, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 13:09:03,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:03,040 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:22<55:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:10,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01157769188284874, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.979, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008580800145864487, 'eval_loss_2': 0.002996891736984253, 'eval_loss_3': -18.308637619018555, 'eval_loss_4': 0.9723141193389893, 'epoch': 11.28}
{'loss': 0.0135, 'grad_norm': 7.819828033447266, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.013135640881955624, 'loss_2': 0.00038433074951171875, 'loss_3': -16.488550186157227, 'loss_4': 0.5311422944068909, 'epoch': 11.28}
{'loss': 0.0274, 'grad_norm': 9.017215728759766, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.02395855262875557, 'loss_2': 0.00344085693359375, 'loss_3': -16.395915985107422, 'loss_4': 0.8837555646896362, 'epoch': 11.29}
{'loss': 0.0397, 'grad_norm': 12.914179801940918, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.03712671622633934, 'loss_2': 0.0025787353515625, 'loss_3': -16.202404022216797, 'loss_4': 1.0662422180175781, 'epoch': 11.3}
{'loss': 0.0204, 'grad_norm': 5.67354679107666, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.010782811790704727, 'loss_2': 0.0096282958984375, 'loss_3': -16.232528686523438, 'loss_4': 0.6430689096450806, 'epoch': 11.3}
{'loss': 0.0258, 'grad_norm': 9.40962028503418, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.018614575266838074, 'loss_2': 0.007144927978515625, 'loss_3': -16.36583709716797, 'loss_4': 0.9538518786430359, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 13:09:10,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:10,375 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:29<55:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:17,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010708045214414597, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007757198065519333, 'eval_loss_2': 0.0029508471488952637, 'eval_loss_3': -18.296785354614258, 'eval_loss_4': 0.9876261949539185, 'epoch': 11.31}
{'loss': 0.0876, 'grad_norm': 23.568038940429688, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.08620689809322357, 'loss_2': 0.00140380859375, 'loss_3': -16.35093116760254, 'loss_4': 0.886232852935791, 'epoch': 11.31}
{'loss': 0.0249, 'grad_norm': 6.039523124694824, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.014997165650129318, 'loss_2': 0.009857177734375, 'loss_3': -16.33143424987793, 'loss_4': 0.9764866232872009, 'epoch': 11.32}
{'loss': 0.0115, 'grad_norm': 5.385733604431152, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.010815007612109184, 'loss_2': 0.000644683837890625, 'loss_3': -16.2103214263916, 'loss_4': 1.4218671321868896, 'epoch': 11.33}
{'loss': 0.0318, 'grad_norm': 16.404632568359375, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.02989225462079048, 'loss_2': 0.00194549560546875, 'loss_3': -16.38042640686035, 'loss_4': 0.6118661165237427, 'epoch': 11.33}
{'loss': 0.0106, 'grad_norm': 5.047183990478516, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.005521866027265787, 'loss_2': 0.005069732666015625, 'loss_3': -16.51053237915039, 'loss_4': 0.973497211933136, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 13:09:17,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:17,718 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:37<55:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:25,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015334546566009521, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.007620276417583227, 'eval_loss_2': 0.007714271545410156, 'eval_loss_3': -18.282241821289062, 'eval_loss_4': 1.075260043144226, 'epoch': 11.34}
{'loss': 0.1033, 'grad_norm': 21.503137588500977, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.09247895330190659, 'loss_2': 0.01079559326171875, 'loss_3': -16.218416213989258, 'loss_4': 1.1576210260391235, 'epoch': 11.34}
{'loss': 0.0301, 'grad_norm': 7.206765174865723, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.017237624153494835, 'loss_2': 0.01285552978515625, 'loss_3': -16.286962509155273, 'loss_4': 1.0775212049484253, 'epoch': 11.35}
{'loss': 0.0124, 'grad_norm': 5.2708659172058105, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.008598651736974716, 'loss_2': 0.003818511962890625, 'loss_3': -16.31570816040039, 'loss_4': 0.8731727004051208, 'epoch': 11.35}
{'loss': 0.033, 'grad_norm': 8.861737251281738, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.02327672392129898, 'loss_2': 0.00970458984375, 'loss_3': -16.383819580078125, 'loss_4': 1.4808168411254883, 'epoch': 11.36}
{'loss': 0.0106, 'grad_norm': 4.903076171875, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.0078058200888335705, 'loss_2': 0.002834320068359375, 'loss_3': -16.461410522460938, 'loss_4': 1.7748643159866333, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 13:09:25,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:25,054 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:44<55:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:32,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015160109847784042, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.943, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.008916465565562248, 'eval_loss_2': 0.006243646144866943, 'eval_loss_3': -18.261760711669922, 'eval_loss_4': 1.161710500717163, 'epoch': 11.37}
{'loss': 0.0122, 'grad_norm': 5.849564075469971, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.012045102193951607, 'loss_2': 0.00010573863983154297, 'loss_3': -16.366962432861328, 'loss_4': 1.414640188217163, 'epoch': 11.37}
{'loss': 0.0221, 'grad_norm': 6.652345657348633, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.012796123512089252, 'loss_2': 0.00933074951171875, 'loss_3': -16.279220581054688, 'loss_4': 1.4241173267364502, 'epoch': 11.38}
{'loss': 0.0247, 'grad_norm': 8.82730484008789, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.02279878593981266, 'loss_2': 0.0019054412841796875, 'loss_3': -16.425621032714844, 'loss_4': 1.1892249584197998, 'epoch': 11.38}
{'loss': 0.0186, 'grad_norm': 7.072272777557373, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.01848756894469261, 'loss_2': 0.00015747547149658203, 'loss_3': -16.320707321166992, 'loss_4': 1.1458215713500977, 'epoch': 11.39}
{'loss': 0.015, 'grad_norm': 5.761841773986816, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.010538500733673573, 'loss_2': 0.004428863525390625, 'loss_3': -16.27047348022461, 'loss_4': 1.2301561832427979, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 13:09:32,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:32,384 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:51<55:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:39,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015196545049548149, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.246, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.010762088932096958, 'eval_loss_2': 0.004434455186128616, 'eval_loss_3': -18.249114990234375, 'eval_loss_4': 1.039823293685913, 'epoch': 11.4}
{'loss': 0.0229, 'grad_norm': 5.9308695793151855, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.013478685170412064, 'loss_2': 0.00946044921875, 'loss_3': -16.525291442871094, 'loss_4': 1.3311388492584229, 'epoch': 11.4}
{'loss': 0.0411, 'grad_norm': 11.668108940124512, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.03287294879555702, 'loss_2': 0.0081939697265625, 'loss_3': -16.296653747558594, 'loss_4': 1.5775868892669678, 'epoch': 11.41}
{'loss': 0.0346, 'grad_norm': 7.608914852142334, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.024480590596795082, 'loss_2': 0.0101470947265625, 'loss_3': -16.409751892089844, 'loss_4': 1.48256254196167, 'epoch': 11.41}
{'loss': 0.0234, 'grad_norm': 6.726235866546631, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.014218661934137344, 'loss_2': 0.00920867919921875, 'loss_3': -16.425121307373047, 'loss_4': 0.8850404024124146, 'epoch': 11.42}
{'loss': 0.0165, 'grad_norm': 4.766956806182861, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.012959349900484085, 'loss_2': 0.003570556640625, 'loss_3': -16.160457611083984, 'loss_4': 0.7913438677787781, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 13:09:39,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:39,723 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:59<55:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:47,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023850422352552414, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.869, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.019369732588529587, 'eval_loss_2': 0.004480689764022827, 'eval_loss_3': -18.195241928100586, 'eval_loss_4': 0.9837560057640076, 'epoch': 11.42}
{'loss': 0.0322, 'grad_norm': 8.761816024780273, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.03138331323862076, 'loss_2': 0.000774383544921875, 'loss_3': -16.457202911376953, 'loss_4': 1.0845708847045898, 'epoch': 11.43}
{'loss': 0.0189, 'grad_norm': 6.131221771240234, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.013584859669208527, 'loss_2': 0.00531005859375, 'loss_3': -16.4322566986084, 'loss_4': 0.9475400447845459, 'epoch': 11.44}
{'loss': 0.0217, 'grad_norm': 7.4151530265808105, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.019347814843058586, 'loss_2': 0.002323150634765625, 'loss_3': -16.338258743286133, 'loss_4': 0.7112029194831848, 'epoch': 11.44}
{'loss': 0.022, 'grad_norm': 7.995201587677002, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.01879888027906418, 'loss_2': 0.0031585693359375, 'loss_3': -16.27286720275879, 'loss_4': 1.0033290386199951, 'epoch': 11.45}
{'loss': 0.0255, 'grad_norm': 8.077129364013672, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.020373312756419182, 'loss_2': 0.00516510009765625, 'loss_3': -16.304168701171875, 'loss_4': 0.9628855586051941, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 13:09:47,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:47,064 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [49:06<55:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:54,408 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.058295805007219315, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.115, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.05595400929450989, 'eval_loss_2': 0.0023417919874191284, 'eval_loss_3': -18.02149772644043, 'eval_loss_4': 1.1820182800292969, 'epoch': 11.45}
{'loss': 0.0546, 'grad_norm': 21.373449325561523, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.05363837257027626, 'loss_2': 0.0010013580322265625, 'loss_3': -16.2877140045166, 'loss_4': 0.98145592212677, 'epoch': 11.46}
{'loss': 0.0243, 'grad_norm': 13.112398147583008, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.023123573511838913, 'loss_2': 0.0011548995971679688, 'loss_3': -16.336444854736328, 'loss_4': 0.9988111853599548, 'epoch': 11.47}
{'loss': 0.0324, 'grad_norm': 7.6138386726379395, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.028083479031920433, 'loss_2': 0.0043182373046875, 'loss_3': -15.771669387817383, 'loss_4': 0.7242282629013062, 'epoch': 11.47}
{'loss': 0.0193, 'grad_norm': 5.881555557250977, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.016412338241934776, 'loss_2': 0.0028533935546875, 'loss_3': -16.388324737548828, 'loss_4': 1.46701979637146, 'epoch': 11.48}
{'loss': 0.0446, 'grad_norm': 11.64383602142334, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.035106200724840164, 'loss_2': 0.009490966796875, 'loss_3': -16.2237548828125, 'loss_4': 1.1906191110610962, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 13:09:54,408 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:54,408 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [49:13<55:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:01,751 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.16359233856201172, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.171, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.15921254456043243, 'eval_loss_2': 0.004379801452159882, 'eval_loss_3': -17.846162796020508, 'eval_loss_4': 1.5843641757965088, 'epoch': 11.48}
{'loss': 0.0221, 'grad_norm': 8.629094123840332, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.020034216344356537, 'loss_2': 0.002079010009765625, 'loss_3': -16.352542877197266, 'loss_4': 1.1569594144821167, 'epoch': 11.49}
{'loss': 0.0325, 'grad_norm': 8.963144302368164, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.03006449155509472, 'loss_2': 0.00247955322265625, 'loss_3': -16.02774429321289, 'loss_4': 1.3968877792358398, 'epoch': 11.49}
{'loss': 0.0536, 'grad_norm': 19.900793075561523, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.050068870186805725, 'loss_2': 0.003490447998046875, 'loss_3': -15.87042236328125, 'loss_4': 1.2651160955429077, 'epoch': 11.5}
{'loss': 0.3054, 'grad_norm': 46.6565055847168, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.2995526194572449, 'loss_2': 0.005847930908203125, 'loss_3': -15.791643142700195, 'loss_4': 1.9148693084716797, 'epoch': 11.51}
{'loss': 0.3272, 'grad_norm': 46.526615142822266, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.3188525140285492, 'loss_2': 0.00832366943359375, 'loss_3': -15.895634651184082, 'loss_4': 1.3162126541137695, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 13:10:01,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:01,751 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:21<54:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:09,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.32028728723526, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.198, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.3142146170139313, 'eval_loss_2': 0.006072640419006348, 'eval_loss_3': -17.619243621826172, 'eval_loss_4': 2.124624013900757, 'epoch': 11.51}
{'loss': 0.1102, 'grad_norm': 18.159265518188477, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.10054373741149902, 'loss_2': 0.009674072265625, 'loss_3': -16.093948364257812, 'loss_4': 1.8807001113891602, 'epoch': 11.52}
{'loss': 0.04, 'grad_norm': 11.272089958190918, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.03523541986942291, 'loss_2': 0.004741668701171875, 'loss_3': -15.952935218811035, 'loss_4': 1.4880013465881348, 'epoch': 11.52}
{'loss': 0.1899, 'grad_norm': 38.40052032470703, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.18290561437606812, 'loss_2': 0.00699615478515625, 'loss_3': -15.864731788635254, 'loss_4': 1.9010876417160034, 'epoch': 11.53}
{'loss': 0.1281, 'grad_norm': 56.1638069152832, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.127663716673851, 'loss_2': 0.0004248619079589844, 'loss_3': -15.972208023071289, 'loss_4': 2.205627202987671, 'epoch': 11.53}
{'loss': 0.0366, 'grad_norm': 13.87982177734375, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.03243006765842438, 'loss_2': 0.00415802001953125, 'loss_3': -16.185449600219727, 'loss_4': 1.7112698554992676, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 13:10:09,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:09,088 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:28<54:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:16,422 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0711534172296524, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.507, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.06781359016895294, 'eval_loss_2': 0.003339819610118866, 'eval_loss_3': -18.02519416809082, 'eval_loss_4': 1.9071204662322998, 'epoch': 11.54}
{'loss': 0.0154, 'grad_norm': 5.391334056854248, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.010813730768859386, 'loss_2': 0.00460052490234375, 'loss_3': -16.327838897705078, 'loss_4': 1.5281938314437866, 'epoch': 11.55}
{'loss': 0.0085, 'grad_norm': 5.250829696655273, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.007579214405268431, 'loss_2': 0.0009441375732421875, 'loss_3': -16.297809600830078, 'loss_4': 1.6822625398635864, 'epoch': 11.55}
{'loss': 0.0138, 'grad_norm': 5.173811435699463, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.011281564831733704, 'loss_2': 0.002552032470703125, 'loss_3': -16.500085830688477, 'loss_4': 1.7449662685394287, 'epoch': 11.56}
{'loss': 0.027, 'grad_norm': 7.54565954208374, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.017921995371580124, 'loss_2': 0.0091094970703125, 'loss_3': -16.311555862426758, 'loss_4': 2.061037540435791, 'epoch': 11.56}
{'loss': 0.0167, 'grad_norm': 5.286431312561035, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.010266927070915699, 'loss_2': 0.00646209716796875, 'loss_3': -16.20916748046875, 'loss_4': 1.9496134519577026, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 13:10:16,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:16,423 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:35<54:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:23,764 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016906622797250748, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009932282380759716, 'eval_loss_2': 0.006974339485168457, 'eval_loss_3': -18.27876091003418, 'eval_loss_4': 2.2573397159576416, 'epoch': 11.57}
{'loss': 0.0294, 'grad_norm': 7.482238292694092, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.019406044855713844, 'loss_2': 0.0099945068359375, 'loss_3': -16.264659881591797, 'loss_4': 2.470905303955078, 'epoch': 11.58}
{'loss': 0.0294, 'grad_norm': 7.192042350769043, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.014511141926050186, 'loss_2': 0.0149078369140625, 'loss_3': -16.325477600097656, 'loss_4': 2.279918670654297, 'epoch': 11.58}
{'loss': 0.0315, 'grad_norm': 8.15832805633545, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.019844278693199158, 'loss_2': 0.0116424560546875, 'loss_3': -16.208438873291016, 'loss_4': 2.0600192546844482, 'epoch': 11.59}
{'loss': 0.0254, 'grad_norm': 6.756579399108887, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.02073024958372116, 'loss_2': 0.0047149658203125, 'loss_3': -16.19528579711914, 'loss_4': 2.2697181701660156, 'epoch': 11.59}
{'loss': 0.02, 'grad_norm': 5.695163726806641, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.00942529458552599, 'loss_2': 0.010528564453125, 'loss_3': -16.209226608276367, 'loss_4': 2.744229316711426, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 13:10:23,764 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:23,764 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:43<55:26,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:10:31,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014071747660636902, 'eval_runtime': 3.9884, 'eval_samples_per_second': 256.744, 'eval_steps_per_second': 4.012, 'eval_loss_1': 0.010471388697624207, 'eval_loss_2': 0.0036003589630126953, 'eval_loss_3': -18.32903480529785, 'eval_loss_4': 2.9035227298736572, 'epoch': 11.6}
{'loss': 0.0224, 'grad_norm': 7.561244010925293, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.01960601657629013, 'loss_2': 0.00275421142578125, 'loss_3': -16.159170150756836, 'loss_4': 2.7733733654022217, 'epoch': 11.6}
{'loss': 0.0191, 'grad_norm': 8.218056678771973, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.016422459855675697, 'loss_2': 0.002628326416015625, 'loss_3': -16.379343032836914, 'loss_4': 2.9090633392333984, 'epoch': 11.61}
{'loss': 0.034, 'grad_norm': 12.640772819519043, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.03079378791153431, 'loss_2': 0.003170013427734375, 'loss_3': -16.42892074584961, 'loss_4': 3.217824935913086, 'epoch': 11.62}
{'loss': 0.0419, 'grad_norm': 15.146248817443848, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.04111846908926964, 'loss_2': 0.00079345703125, 'loss_3': -16.318599700927734, 'loss_4': 3.423168182373047, 'epoch': 11.62}
{'loss': 0.0193, 'grad_norm': 6.791088104248047, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.018316788598895073, 'loss_2': 0.0009593963623046875, 'loss_3': -16.358070373535156, 'loss_4': 3.931694984436035, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 13:10:31,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:31,303 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:50<54:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:38,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015105215832591057, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.041, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011403350159525871, 'eval_loss_2': 0.0037018656730651855, 'eval_loss_3': -18.33803939819336, 'eval_loss_4': 3.1874473094940186, 'epoch': 11.63}
{'loss': 0.0393, 'grad_norm': 15.377281188964844, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.03240448608994484, 'loss_2': 0.0069427490234375, 'loss_3': -16.085819244384766, 'loss_4': 3.1517090797424316, 'epoch': 11.63}
{'loss': 0.0273, 'grad_norm': 11.468220710754395, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.025051839649677277, 'loss_2': 0.002254486083984375, 'loss_3': -16.32009506225586, 'loss_4': 3.492671251296997, 'epoch': 11.64}
{'loss': 0.012, 'grad_norm': 4.6639018058776855, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.008523862808942795, 'loss_2': 0.003509521484375, 'loss_3': -16.28401756286621, 'loss_4': 2.854213237762451, 'epoch': 11.65}
{'loss': 0.0304, 'grad_norm': 11.737308502197266, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.02140098810195923, 'loss_2': 0.0089874267578125, 'loss_3': -16.033245086669922, 'loss_4': 2.410244941711426, 'epoch': 11.65}
{'loss': 0.0234, 'grad_norm': 7.111034870147705, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.016927845776081085, 'loss_2': 0.0065155029296875, 'loss_3': -16.367692947387695, 'loss_4': 2.0853734016418457, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 13:10:38,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:38,647 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:57<54:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:45,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014363422989845276, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.168, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010702678002417088, 'eval_loss_2': 0.003660745918750763, 'eval_loss_3': -18.335063934326172, 'eval_loss_4': 2.3939433097839355, 'epoch': 11.66}
{'loss': 0.0317, 'grad_norm': 5.903953552246094, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.018541745841503143, 'loss_2': 0.01316070556640625, 'loss_3': -16.527618408203125, 'loss_4': 2.3056962490081787, 'epoch': 11.66}
{'loss': 0.0126, 'grad_norm': 6.097840785980225, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.012399168685078621, 'loss_2': 0.0002410411834716797, 'loss_3': -16.33771324157715, 'loss_4': 2.74507212638855, 'epoch': 11.67}
{'loss': 0.0189, 'grad_norm': 7.382171630859375, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.01866716332733631, 'loss_2': 0.00019288063049316406, 'loss_3': -16.49666976928711, 'loss_4': 2.4277830123901367, 'epoch': 11.67}
{'loss': 0.0239, 'grad_norm': 8.468602180480957, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.020946597680449486, 'loss_2': 0.002910614013671875, 'loss_3': -16.298274993896484, 'loss_4': 2.471912384033203, 'epoch': 11.68}
{'loss': 0.0179, 'grad_norm': 6.551578044891357, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.017033345997333527, 'loss_2': 0.0008664131164550781, 'loss_3': -16.282987594604492, 'loss_4': 2.1176626682281494, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 13:10:45,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:45,985 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [50:05<54:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:53,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02034299448132515, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.797, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01453237421810627, 'eval_loss_2': 0.0058106184005737305, 'eval_loss_3': -18.309490203857422, 'eval_loss_4': 1.9930635690689087, 'epoch': 11.69}
{'loss': 0.0298, 'grad_norm': 6.647454738616943, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.020683806389570236, 'loss_2': 0.00908660888671875, 'loss_3': -16.137603759765625, 'loss_4': 2.1363158226013184, 'epoch': 11.69}
{'loss': 0.019, 'grad_norm': 7.645188808441162, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.012620914727449417, 'loss_2': 0.00634002685546875, 'loss_3': -16.156055450439453, 'loss_4': 2.0870201587677, 'epoch': 11.7}
{'loss': 0.0247, 'grad_norm': 8.103593826293945, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.018161727115511894, 'loss_2': 0.006500244140625, 'loss_3': -16.240062713623047, 'loss_4': 1.9624818563461304, 'epoch': 11.7}
{'loss': 0.0165, 'grad_norm': 5.96702241897583, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.015180066227912903, 'loss_2': 0.0013484954833984375, 'loss_3': -16.2365779876709, 'loss_4': 1.5827339887619019, 'epoch': 11.71}
{'loss': 0.028, 'grad_norm': 12.502848625183105, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.018619034439325333, 'loss_2': 0.00940704345703125, 'loss_3': -16.346717834472656, 'loss_4': 1.6058874130249023, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 13:10:53,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:53,330 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [50:12<54:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:00,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02131021022796631, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.174, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.018094927072525024, 'eval_loss_2': 0.003215283155441284, 'eval_loss_3': -18.25701141357422, 'eval_loss_4': 1.4993590116500854, 'epoch': 11.72}
{'loss': 0.0131, 'grad_norm': 5.436275482177734, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.010122275911271572, 'loss_2': 0.0030231475830078125, 'loss_3': -16.010026931762695, 'loss_4': 2.023292064666748, 'epoch': 11.72}
{'loss': 0.0163, 'grad_norm': 6.96513032913208, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.013746538199484348, 'loss_2': 0.002536773681640625, 'loss_3': -16.350284576416016, 'loss_4': 0.9596594572067261, 'epoch': 11.73}
{'loss': 0.0225, 'grad_norm': 7.359436988830566, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.020893514156341553, 'loss_2': 0.0016536712646484375, 'loss_3': -16.30390167236328, 'loss_4': 1.3648955821990967, 'epoch': 11.73}
{'loss': 0.0096, 'grad_norm': 5.735785007476807, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.00868339091539383, 'loss_2': 0.0009031295776367188, 'loss_3': -16.44975471496582, 'loss_4': 1.0705387592315674, 'epoch': 11.74}
{'loss': 0.0155, 'grad_norm': 5.746732234954834, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.013038688339293003, 'loss_2': 0.002498626708984375, 'loss_3': -16.383682250976562, 'loss_4': 1.3531711101531982, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 13:11:00,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:00,667 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:19<54:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:08,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02024698629975319, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.09, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01704426296055317, 'eval_loss_2': 0.003202725201845169, 'eval_loss_3': -18.26299285888672, 'eval_loss_4': 1.1022417545318604, 'epoch': 11.74}
{'loss': 0.0322, 'grad_norm': 8.382253646850586, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.020058024674654007, 'loss_2': 0.01214599609375, 'loss_3': -16.384916305541992, 'loss_4': 1.5594260692596436, 'epoch': 11.75}
{'loss': 0.0098, 'grad_norm': 5.428440093994141, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.008572553284466267, 'loss_2': 0.0012578964233398438, 'loss_3': -16.332443237304688, 'loss_4': 0.6791620254516602, 'epoch': 11.76}
{'loss': 0.0142, 'grad_norm': 5.54509973526001, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.008151357993483543, 'loss_2': 0.00601959228515625, 'loss_3': -16.446332931518555, 'loss_4': 1.2022082805633545, 'epoch': 11.76}
{'loss': 0.0204, 'grad_norm': 8.165046691894531, 'learning_rate': 1.825e-05, 'loss_1': 0.013900679536163807, 'loss_2': 0.00652313232421875, 'loss_3': -16.41143798828125, 'loss_4': 0.6110203862190247, 'epoch': 11.77}
{'loss': 0.0146, 'grad_norm': 7.059089183807373, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.013323517516255379, 'loss_2': 0.0012712478637695312, 'loss_3': -16.28105354309082, 'loss_4': 1.0213478803634644, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 13:11:08,008 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:08,008 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:27<54:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:15,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019134175032377243, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016485583037137985, 'eval_loss_2': 0.002648591995239258, 'eval_loss_3': -18.249683380126953, 'eval_loss_4': 0.7120720148086548, 'epoch': 11.77}
{'loss': 0.0316, 'grad_norm': 17.365825653076172, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.0298371110111475, 'loss_2': 0.001811981201171875, 'loss_3': -16.501615524291992, 'loss_4': 0.6901043653488159, 'epoch': 11.78}
{'loss': 0.0147, 'grad_norm': 6.7580952644348145, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.014068026095628738, 'loss_2': 0.00061798095703125, 'loss_3': -16.23833465576172, 'loss_4': 0.9607782363891602, 'epoch': 11.78}
{'loss': 0.0114, 'grad_norm': 4.772726058959961, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.008493960835039616, 'loss_2': 0.002895355224609375, 'loss_3': -16.44330596923828, 'loss_4': 0.8995101451873779, 'epoch': 11.79}
{'loss': 0.0321, 'grad_norm': 10.601927757263184, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.025385867804288864, 'loss_2': 0.0067291259765625, 'loss_3': -16.249420166015625, 'loss_4': 0.4256475269794464, 'epoch': 11.8}
{'loss': 0.0197, 'grad_norm': 5.125131130218506, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.011313349939882755, 'loss_2': 0.0084075927734375, 'loss_3': -16.326290130615234, 'loss_4': 0.8995134830474854, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 13:11:15,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:15,361 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:34<54:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:22,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017603900283575058, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.701, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014118516817688942, 'eval_loss_2': 0.003485381603240967, 'eval_loss_3': -18.256000518798828, 'eval_loss_4': 0.4989882707595825, 'epoch': 11.8}
{'loss': 0.0086, 'grad_norm': 5.196063995361328, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.008231278508901596, 'loss_2': 0.0003943443298339844, 'loss_3': -16.135040283203125, 'loss_4': 0.3393140435218811, 'epoch': 11.81}
{'loss': 0.0217, 'grad_norm': 6.489584445953369, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.01429334469139576, 'loss_2': 0.0073699951171875, 'loss_3': -16.265106201171875, 'loss_4': 1.1849770545959473, 'epoch': 11.81}
{'loss': 0.0749, 'grad_norm': 19.97134017944336, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.06767047196626663, 'loss_2': 0.007236480712890625, 'loss_3': -16.241775512695312, 'loss_4': 0.8357293605804443, 'epoch': 11.82}
{'loss': 0.0256, 'grad_norm': 10.30960750579834, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.022362632676959038, 'loss_2': 0.003269195556640625, 'loss_3': -16.38905143737793, 'loss_4': 0.4304639995098114, 'epoch': 11.83}
{'loss': 0.0107, 'grad_norm': 5.0120744705200195, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.007191498298197985, 'loss_2': 0.0035247802734375, 'loss_3': -16.193222045898438, 'loss_4': 0.5278645157814026, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 13:11:22,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:22,703 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:42<53:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:30,034 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01614256389439106, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.034, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013411791995167732, 'eval_loss_2': 0.0027307718992233276, 'eval_loss_3': -18.29230308532715, 'eval_loss_4': 0.41487330198287964, 'epoch': 11.83}
{'loss': 0.0289, 'grad_norm': 10.147566795349121, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.02418386936187744, 'loss_2': 0.00475311279296875, 'loss_3': -16.288408279418945, 'loss_4': 0.8073365688323975, 'epoch': 11.84}
{'loss': 0.0237, 'grad_norm': 6.501674652099609, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.020290156826376915, 'loss_2': 0.0034465789794921875, 'loss_3': -16.267597198486328, 'loss_4': 0.9251366257667542, 'epoch': 11.84}
{'loss': 0.0077, 'grad_norm': 4.975705146789551, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.0051283990032970905, 'loss_2': 0.00257110595703125, 'loss_3': -16.48938751220703, 'loss_4': 0.4689531922340393, 'epoch': 11.85}
{'loss': 0.0762, 'grad_norm': 29.71195411682129, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.07470692694187164, 'loss_2': 0.0014524459838867188, 'loss_3': -16.253074645996094, 'loss_4': 0.6741980910301208, 'epoch': 11.85}
{'loss': 0.0161, 'grad_norm': 5.40992546081543, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.010333877056837082, 'loss_2': 0.00579071044921875, 'loss_3': -16.626953125, 'loss_4': 0.526764988899231, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 13:11:30,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:30,034 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:49<53:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:37,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019046256318688393, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.806, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015295836143195629, 'eval_loss_2': 0.003750421106815338, 'eval_loss_3': -18.290721893310547, 'eval_loss_4': 0.18646115064620972, 'epoch': 11.86}
{'loss': 0.0095, 'grad_norm': 6.850119590759277, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.008940648287534714, 'loss_2': 0.0005793571472167969, 'loss_3': -16.477935791015625, 'loss_4': 0.19371941685676575, 'epoch': 11.87}
{'loss': 0.0201, 'grad_norm': 7.508044719696045, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.014507382176816463, 'loss_2': 0.0055694580078125, 'loss_3': -16.46672821044922, 'loss_4': 0.6972915530204773, 'epoch': 11.87}
{'loss': 0.0103, 'grad_norm': 4.893429756164551, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.0069643668830394745, 'loss_2': 0.00333404541015625, 'loss_3': -16.453529357910156, 'loss_4': -0.056237444281578064, 'epoch': 11.88}
{'loss': 0.0152, 'grad_norm': 5.737995624542236, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.011296379379928112, 'loss_2': 0.003879547119140625, 'loss_3': -16.377771377563477, 'loss_4': 0.06358398497104645, 'epoch': 11.88}
{'loss': 0.0552, 'grad_norm': 22.95680809020996, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.05464893579483032, 'loss_2': 0.0005788803100585938, 'loss_3': -16.2225341796875, 'loss_4': 0.2909349799156189, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 13:11:37,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:37,375 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:56<53:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:44,708 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020688001066446304, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.113, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.018234649673104286, 'eval_loss_2': 0.002453349530696869, 'eval_loss_3': -18.27577781677246, 'eval_loss_4': -0.01301463134586811, 'epoch': 11.89}
{'loss': 0.0124, 'grad_norm': 5.034789562225342, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.007191383745521307, 'loss_2': 0.00516510009765625, 'loss_3': -16.308568954467773, 'loss_4': 0.06572191417217255, 'epoch': 11.9}
{'loss': 0.034, 'grad_norm': 8.897729873657227, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.030780337750911713, 'loss_2': 0.003208160400390625, 'loss_3': -16.330900192260742, 'loss_4': -0.06412408500909805, 'epoch': 11.9}
{'loss': 0.0063, 'grad_norm': 4.62405252456665, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.005967568140476942, 'loss_2': 0.0003399848937988281, 'loss_3': -16.441009521484375, 'loss_4': -0.08259957283735275, 'epoch': 11.91}
{'loss': 0.0205, 'grad_norm': 7.0115532875061035, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.01378256268799305, 'loss_2': 0.006732940673828125, 'loss_3': -16.40203094482422, 'loss_4': -0.31925153732299805, 'epoch': 11.91}
{'loss': 0.0246, 'grad_norm': 9.87242317199707, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.02270784042775631, 'loss_2': 0.001865386962890625, 'loss_3': -16.50333023071289, 'loss_4': 0.0772876888513565, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 13:11:44,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:44,708 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [51:04<53:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:52,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022966770455241203, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.908, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.018794862553477287, 'eval_loss_2': 0.004171907901763916, 'eval_loss_3': -18.29930877685547, 'eval_loss_4': -0.15505416691303253, 'epoch': 11.92}
{'loss': 0.0216, 'grad_norm': 7.591344833374023, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.01263668853789568, 'loss_2': 0.00891876220703125, 'loss_3': -16.4072265625, 'loss_4': 0.16138027608394623, 'epoch': 11.92}
{'loss': 0.0093, 'grad_norm': 5.367772579193115, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.008578862063586712, 'loss_2': 0.0007085800170898438, 'loss_3': -16.305349349975586, 'loss_4': -0.455135703086853, 'epoch': 11.93}
{'loss': 0.0184, 'grad_norm': 5.5991926193237305, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.010556673631072044, 'loss_2': 0.007843017578125, 'loss_3': -16.4948787689209, 'loss_4': -0.5090028047561646, 'epoch': 11.94}
{'loss': 0.0167, 'grad_norm': 11.40926456451416, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.012995230965316296, 'loss_2': 0.0037078857421875, 'loss_3': -16.436626434326172, 'loss_4': 0.3282439112663269, 'epoch': 11.94}
{'loss': 0.0171, 'grad_norm': 6.825148105621338, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.011596121825277805, 'loss_2': 0.00545501708984375, 'loss_3': -16.382001876831055, 'loss_4': -0.4487799108028412, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 13:11:52,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:52,048 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [51:11<53:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:59,390 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02287617325782776, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.578, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0191228985786438, 'eval_loss_2': 0.00375327467918396, 'eval_loss_3': -18.292028427124023, 'eval_loss_4': -0.11011186987161636, 'epoch': 11.95}
{'loss': 0.0116, 'grad_norm': 5.3971943855285645, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.009113393723964691, 'loss_2': 0.002521514892578125, 'loss_3': -16.556869506835938, 'loss_4': 0.10333605110645294, 'epoch': 11.95}
{'loss': 0.0051, 'grad_norm': 4.84205961227417, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.004215146414935589, 'loss_2': 0.0008511543273925781, 'loss_3': -16.301982879638672, 'loss_4': 0.10219351947307587, 'epoch': 11.96}
{'loss': 0.0137, 'grad_norm': 5.62038516998291, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.012497853487730026, 'loss_2': 0.0011997222900390625, 'loss_3': -16.412994384765625, 'loss_4': 0.10682882368564606, 'epoch': 11.97}
{'loss': 0.0121, 'grad_norm': 5.956735134124756, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.008209635503590107, 'loss_2': 0.0039043426513671875, 'loss_3': -16.469961166381836, 'loss_4': -0.07618197798728943, 'epoch': 11.97}
{'loss': 0.0134, 'grad_norm': 5.225276470184326, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.00953246932476759, 'loss_2': 0.0038471221923828125, 'loss_3': -16.362272262573242, 'loss_4': -0.053288500756025314, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 13:11:59,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:59,390 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:18<50:20,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 13:12:06,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028068028390407562, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.936, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.022814709693193436, 'eval_loss_2': 0.005253314971923828, 'eval_loss_3': -18.257221221923828, 'eval_loss_4': 0.15318790078163147, 'epoch': 11.98}
{'loss': 0.0452, 'grad_norm': 13.661971092224121, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.03971782326698303, 'loss_2': 0.005435943603515625, 'loss_3': -16.200523376464844, 'loss_4': 0.49434494972229004, 'epoch': 11.98}
{'loss': 0.0395, 'grad_norm': 8.59248161315918, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.02297276258468628, 'loss_2': 0.0164794921875, 'loss_3': -16.240074157714844, 'loss_4': -0.22195786237716675, 'epoch': 11.99}
{'loss': 0.018, 'grad_norm': 5.971604824066162, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.011996994726359844, 'loss_2': 0.00597381591796875, 'loss_3': -16.455821990966797, 'loss_4': 0.4136185348033905, 'epoch': 11.99}
{'loss': 0.0108, 'grad_norm': 12.39307975769043, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.008883407339453697, 'loss_2': 0.001941680908203125, 'loss_3': -16.13926887512207, 'loss_4': 0.39337968826293945, 'epoch': 12.0}
{'loss': 0.0789, 'grad_norm': 25.96578598022461, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.07583009451627731, 'loss_2': 0.0030841827392578125, 'loss_3': -16.285602569580078, 'loss_4': 0.8934849500656128, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 13:12:06,415 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:06,415 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:25<52:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:12:13,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03418336436152458, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.917, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.030612464994192123, 'eval_loss_2': 0.0035708993673324585, 'eval_loss_3': -18.23554801940918, 'eval_loss_4': 0.31747299432754517, 'epoch': 12.01}
{'loss': 0.0165, 'grad_norm': 6.054695129394531, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.012784630060195923, 'loss_2': 0.003673553466796875, 'loss_3': -16.396442413330078, 'loss_4': 0.44641217589378357, 'epoch': 12.01}
{'loss': 0.0098, 'grad_norm': 5.05061149597168, 'learning_rate': 1.8e-05, 'loss_1': 0.006336095742881298, 'loss_2': 0.003437042236328125, 'loss_3': -16.416481018066406, 'loss_4': 0.3685725927352905, 'epoch': 12.02}
{'loss': 0.0177, 'grad_norm': 6.521688461303711, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.012904188595712185, 'loss_2': 0.004791259765625, 'loss_3': -16.20965576171875, 'loss_4': 0.41009336709976196, 'epoch': 12.02}
{'loss': 0.0213, 'grad_norm': 7.207144737243652, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.01624440588057041, 'loss_2': 0.00506591796875, 'loss_3': -16.413494110107422, 'loss_4': -0.3559889793395996, 'epoch': 12.03}
{'loss': 0.0253, 'grad_norm': 12.794136047363281, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.022561799734830856, 'loss_2': 0.0027370452880859375, 'loss_3': -16.312265396118164, 'loss_4': -0.038879573345184326, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 13:12:13,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:13,748 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:33<53:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:21,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04391420632600784, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.16, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.03881356492638588, 'eval_loss_2': 0.005100637674331665, 'eval_loss_3': -18.230180740356445, 'eval_loss_4': 0.310617059469223, 'epoch': 12.03}
{'loss': 0.0265, 'grad_norm': 7.734940052032471, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.020297227427363396, 'loss_2': 0.00615692138671875, 'loss_3': -16.49628448486328, 'loss_4': 0.2741631269454956, 'epoch': 12.04}
{'loss': 0.0114, 'grad_norm': 5.523143291473389, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.011314751580357552, 'loss_2': 0.0001112222671508789, 'loss_3': -16.47997283935547, 'loss_4': 0.08738194406032562, 'epoch': 12.05}
{'loss': 0.0351, 'grad_norm': 14.565038681030273, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.035048358142375946, 'loss_2': 3.743171691894531e-05, 'loss_3': -16.374881744384766, 'loss_4': 0.6673418283462524, 'epoch': 12.05}
{'loss': 0.0275, 'grad_norm': 7.526674747467041, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.01591053046286106, 'loss_2': 0.01161956787109375, 'loss_3': -16.37527847290039, 'loss_4': 0.6130088567733765, 'epoch': 12.06}
{'loss': 0.0219, 'grad_norm': 7.670603275299072, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.01544394064694643, 'loss_2': 0.0064239501953125, 'loss_3': -16.308116912841797, 'loss_4': 0.4324445426464081, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 13:12:21,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:21,088 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:40<53:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:28,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042225636541843414, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.117, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.039229318499565125, 'eval_loss_2': 0.00299631804227829, 'eval_loss_3': -18.205615997314453, 'eval_loss_4': 0.47393882274627686, 'epoch': 12.06}
{'loss': 0.0157, 'grad_norm': 6.665171146392822, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.01410758588463068, 'loss_2': 0.0015459060668945312, 'loss_3': -16.343231201171875, 'loss_4': 0.5277302265167236, 'epoch': 12.07}
{'loss': 0.0159, 'grad_norm': 5.8129777908325195, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.013845177367329597, 'loss_2': 0.00205230712890625, 'loss_3': -16.361648559570312, 'loss_4': 0.6160887479782104, 'epoch': 12.08}
{'loss': 0.0252, 'grad_norm': 9.363568305969238, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.023666003718972206, 'loss_2': 0.0015745162963867188, 'loss_3': -16.248273849487305, 'loss_4': 0.548075795173645, 'epoch': 12.08}
{'loss': 0.0435, 'grad_norm': 13.24018383026123, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.03792284429073334, 'loss_2': 0.005565643310546875, 'loss_3': -16.087318420410156, 'loss_4': 0.20403453707695007, 'epoch': 12.09}
{'loss': 0.0306, 'grad_norm': 8.8475980758667, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.026325823739171028, 'loss_2': 0.004302978515625, 'loss_3': -16.129276275634766, 'loss_4': 0.6062716841697693, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 13:12:28,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:28,424 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:47<53:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:35,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05231315270066261, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.841, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.048294246196746826, 'eval_loss_2': 0.004018902778625488, 'eval_loss_3': -18.171709060668945, 'eval_loss_4': 0.7346488237380981, 'epoch': 12.09}
{'loss': 0.0262, 'grad_norm': 8.471364974975586, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.016917090862989426, 'loss_2': 0.0092926025390625, 'loss_3': -16.410812377929688, 'loss_4': 0.589699387550354, 'epoch': 12.1}
{'loss': 0.0631, 'grad_norm': 22.301340103149414, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.05905350670218468, 'loss_2': 0.004085540771484375, 'loss_3': -16.342166900634766, 'loss_4': 0.6338974833488464, 'epoch': 12.1}
{'loss': 0.0125, 'grad_norm': 5.986443996429443, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.012492881156504154, 'loss_2': 3.3974647521972656e-06, 'loss_3': -16.287765502929688, 'loss_4': 0.4892500340938568, 'epoch': 12.11}
{'loss': 0.015, 'grad_norm': 5.08574914932251, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.0098014110699296, 'loss_2': 0.00522613525390625, 'loss_3': -16.413185119628906, 'loss_4': 1.2249988317489624, 'epoch': 12.12}
{'loss': 0.0206, 'grad_norm': 6.5305681228637695, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.012418988160789013, 'loss_2': 0.0081634521484375, 'loss_3': -16.31437110900879, 'loss_4': 1.2530109882354736, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 13:12:35,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:35,766 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:55<53:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:43,097 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05275636911392212, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.279, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.05098087713122368, 'eval_loss_2': 0.001775495707988739, 'eval_loss_3': -18.166593551635742, 'eval_loss_4': 0.8505797386169434, 'epoch': 12.12}
{'loss': 0.0128, 'grad_norm': 6.865123748779297, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.011225711554288864, 'loss_2': 0.0015544891357421875, 'loss_3': -16.491531372070312, 'loss_4': 0.6877350807189941, 'epoch': 12.13}
{'loss': 0.0248, 'grad_norm': 8.538797378540039, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.018895450979471207, 'loss_2': 0.00592803955078125, 'loss_3': -16.189931869506836, 'loss_4': 0.6196980476379395, 'epoch': 12.13}
{'loss': 0.0135, 'grad_norm': 8.258795738220215, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.012706602923572063, 'loss_2': 0.000820159912109375, 'loss_3': -16.206707000732422, 'loss_4': 0.8065516948699951, 'epoch': 12.14}
{'loss': 0.0224, 'grad_norm': 7.696065425872803, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.01926179602742195, 'loss_2': 0.0031070709228515625, 'loss_3': -16.068952560424805, 'loss_4': 0.7982417345046997, 'epoch': 12.15}
{'loss': 0.0356, 'grad_norm': 9.84460735321045, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.021586809307336807, 'loss_2': 0.0140533447265625, 'loss_3': -15.975400924682617, 'loss_4': 0.4156714379787445, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 13:12:43,097 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:43,097 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [52:02<52:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:50,428 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03725551813840866, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.436, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.033852752298116684, 'eval_loss_2': 0.0034027695655822754, 'eval_loss_3': -18.20840072631836, 'eval_loss_4': 0.7941510677337646, 'epoch': 12.15}
{'loss': 0.0317, 'grad_norm': 8.93726634979248, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.023107510060071945, 'loss_2': 0.00860595703125, 'loss_3': -16.3485050201416, 'loss_4': 0.9942574501037598, 'epoch': 12.16}
{'loss': 0.0184, 'grad_norm': 5.908270359039307, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.01500706933438778, 'loss_2': 0.00334930419921875, 'loss_3': -16.06087303161621, 'loss_4': 1.0538647174835205, 'epoch': 12.16}
{'loss': 0.0207, 'grad_norm': 6.075231552124023, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.014537000097334385, 'loss_2': 0.00616455078125, 'loss_3': -16.397672653198242, 'loss_4': 0.6022685170173645, 'epoch': 12.17}
{'loss': 0.0193, 'grad_norm': 8.00879192352295, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.016802849248051643, 'loss_2': 0.002460479736328125, 'loss_3': -16.275951385498047, 'loss_4': 0.8653632998466492, 'epoch': 12.17}
{'loss': 0.0157, 'grad_norm': 6.404836654663086, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.01210334524512291, 'loss_2': 0.003551483154296875, 'loss_3': -16.196916580200195, 'loss_4': 0.95335853099823, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 13:12:50,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:50,428 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [52:09<52:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:57,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019035816192626953, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.175, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016248345375061035, 'eval_loss_2': 0.002787470817565918, 'eval_loss_3': -18.255247116088867, 'eval_loss_4': 0.7835821509361267, 'epoch': 12.18}
{'loss': 0.0261, 'grad_norm': 9.105289459228516, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.024518290534615517, 'loss_2': 0.0015668869018554688, 'loss_3': -16.429006576538086, 'loss_4': 1.5004730224609375, 'epoch': 12.19}
{'loss': 0.0237, 'grad_norm': 7.606925964355469, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.014154018834233284, 'loss_2': 0.0095367431640625, 'loss_3': -16.13174819946289, 'loss_4': 0.7362403869628906, 'epoch': 12.19}
{'loss': 0.0125, 'grad_norm': 5.278104305267334, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.010969645343720913, 'loss_2': 0.0015697479248046875, 'loss_3': -16.282947540283203, 'loss_4': 0.3235909938812256, 'epoch': 12.2}
{'loss': 0.0222, 'grad_norm': 6.463395118713379, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.01818816177546978, 'loss_2': 0.0040435791015625, 'loss_3': -16.369136810302734, 'loss_4': 0.7508808374404907, 'epoch': 12.2}
{'loss': 0.0145, 'grad_norm': 5.8315348625183105, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.013581769540905952, 'loss_2': 0.00095367431640625, 'loss_3': -15.975305557250977, 'loss_4': 0.3740254044532776, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 13:12:57,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:57,760 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:17<52:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:05,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014696314930915833, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.537, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01194226834923029, 'eval_loss_2': 0.0027540475130081177, 'eval_loss_3': -18.285526275634766, 'eval_loss_4': 0.5396460294723511, 'epoch': 12.21}
{'loss': 0.0252, 'grad_norm': 7.940284252166748, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.014565996825695038, 'loss_2': 0.010650634765625, 'loss_3': -16.27532196044922, 'loss_4': 0.88009113073349, 'epoch': 12.22}
{'loss': 0.0106, 'grad_norm': 4.9107666015625, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.007485410664230585, 'loss_2': 0.0031566619873046875, 'loss_3': -16.288835525512695, 'loss_4': 0.6376950740814209, 'epoch': 12.22}
{'loss': 0.007, 'grad_norm': 4.827455997467041, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.005041728727519512, 'loss_2': 0.0019197463989257812, 'loss_3': -16.372989654541016, 'loss_4': 0.5332223176956177, 'epoch': 12.23}
{'loss': 0.0199, 'grad_norm': 7.376363277435303, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.01740826666355133, 'loss_2': 0.0024871826171875, 'loss_3': -16.224382400512695, 'loss_4': 0.5913829207420349, 'epoch': 12.23}
{'loss': 0.0214, 'grad_norm': 7.472274303436279, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.01778555102646351, 'loss_2': 0.003612518310546875, 'loss_3': -16.122766494750977, 'loss_4': 0.709904670715332, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 13:13:05,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:05,089 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:24<52:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:12,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01341853104531765, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.852, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010888400487601757, 'eval_loss_2': 0.0025301314890384674, 'eval_loss_3': -18.282371520996094, 'eval_loss_4': 0.49623429775238037, 'epoch': 12.24}
{'loss': 0.0163, 'grad_norm': 5.959689617156982, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.015703244134783745, 'loss_2': 0.000606536865234375, 'loss_3': -16.209674835205078, 'loss_4': 0.6306304931640625, 'epoch': 12.24}
{'loss': 0.0177, 'grad_norm': 6.194028377532959, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.009721623733639717, 'loss_2': 0.00795745849609375, 'loss_3': -16.293115615844727, 'loss_4': 1.123245358467102, 'epoch': 12.25}
{'loss': 0.0257, 'grad_norm': 7.718903064727783, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.017575521022081375, 'loss_2': 0.0081329345703125, 'loss_3': -16.21625518798828, 'loss_4': 1.0215585231781006, 'epoch': 12.26}
{'loss': 0.0396, 'grad_norm': 21.31819725036621, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.03941353037953377, 'loss_2': 0.00014495849609375, 'loss_3': -16.31238555908203, 'loss_4': 1.2357003688812256, 'epoch': 12.26}
{'loss': 0.0379, 'grad_norm': 22.115503311157227, 'learning_rate': 1.775e-05, 'loss_1': 0.035770952701568604, 'loss_2': 0.00212860107421875, 'loss_3': -16.00831413269043, 'loss_4': 1.3108372688293457, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 13:13:12,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:12,437 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:31<52:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:19,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013169881887733936, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.031, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010362446308135986, 'eval_loss_2': 0.002807438373565674, 'eval_loss_3': -18.25396728515625, 'eval_loss_4': 0.46698683500289917, 'epoch': 12.27}
{'loss': 0.0232, 'grad_norm': 7.9796271324157715, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.01698312535881996, 'loss_2': 0.006237030029296875, 'loss_3': -16.144996643066406, 'loss_4': 0.8758189678192139, 'epoch': 12.27}
{'loss': 0.0127, 'grad_norm': 5.350991725921631, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.012124999426305294, 'loss_2': 0.0005474090576171875, 'loss_3': -16.225500106811523, 'loss_4': 0.333098828792572, 'epoch': 12.28}
{'loss': 0.0264, 'grad_norm': 5.9032793045043945, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.016019504517316818, 'loss_2': 0.0103912353515625, 'loss_3': -16.30849838256836, 'loss_4': 1.2327908277511597, 'epoch': 12.28}
{'loss': 0.0174, 'grad_norm': 7.6580352783203125, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.013646259903907776, 'loss_2': 0.0038013458251953125, 'loss_3': -16.420652389526367, 'loss_4': 0.8489187955856323, 'epoch': 12.29}
{'loss': 0.0209, 'grad_norm': 7.8542160987854, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.010708404704928398, 'loss_2': 0.01019287109375, 'loss_3': -16.269744873046875, 'loss_4': 0.7258228063583374, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 13:13:19,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:19,774 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:39<52:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:27,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013366984203457832, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.333, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.010682717896997929, 'eval_loss_2': 0.002684265375137329, 'eval_loss_3': -18.252525329589844, 'eval_loss_4': 0.3230364918708801, 'epoch': 12.3}
{'loss': 0.0168, 'grad_norm': 6.83540678024292, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.01276998408138752, 'loss_2': 0.004058837890625, 'loss_3': -16.230384826660156, 'loss_4': 0.5247406959533691, 'epoch': 12.3}
{'loss': 0.0158, 'grad_norm': 7.088825702667236, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.010919253341853619, 'loss_2': 0.004833221435546875, 'loss_3': -16.231563568115234, 'loss_4': 0.6811932921409607, 'epoch': 12.31}
{'loss': 0.0144, 'grad_norm': 5.077615261077881, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.009075440466403961, 'loss_2': 0.00533294677734375, 'loss_3': -16.189983367919922, 'loss_4': 0.39972424507141113, 'epoch': 12.31}
{'loss': 0.0289, 'grad_norm': 8.34122085571289, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.019341595470905304, 'loss_2': 0.00960540771484375, 'loss_3': -16.240108489990234, 'loss_4': 0.6222524642944336, 'epoch': 12.32}
{'loss': 0.0249, 'grad_norm': 8.357587814331055, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.017401836812496185, 'loss_2': 0.007541656494140625, 'loss_3': -16.222213745117188, 'loss_4': 0.6325613260269165, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 13:13:27,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:27,110 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:46<52:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:34,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017444293946027756, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.169, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013753434643149376, 'eval_loss_2': 0.003690861165523529, 'eval_loss_3': -18.250370025634766, 'eval_loss_4': 0.39298176765441895, 'epoch': 12.33}
{'loss': 0.0201, 'grad_norm': 6.222072601318359, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.013533380813896656, 'loss_2': 0.00656890869140625, 'loss_3': -16.182239532470703, 'loss_4': 1.5391170978546143, 'epoch': 12.33}
{'loss': 0.0165, 'grad_norm': 7.557623386383057, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.013663548976182938, 'loss_2': 0.00286102294921875, 'loss_3': -16.412994384765625, 'loss_4': 0.6372988224029541, 'epoch': 12.34}
{'loss': 0.0214, 'grad_norm': 6.062621593475342, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.01456375140696764, 'loss_2': 0.00679779052734375, 'loss_3': -16.244016647338867, 'loss_4': 0.017114728689193726, 'epoch': 12.34}
{'loss': 0.0475, 'grad_norm': 16.12436866760254, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.04084087908267975, 'loss_2': 0.00661468505859375, 'loss_3': -16.296810150146484, 'loss_4': 0.6149579286575317, 'epoch': 12.35}
{'loss': 0.0129, 'grad_norm': 4.939871788024902, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.010134615935385227, 'loss_2': 0.0027923583984375, 'loss_3': -16.311677932739258, 'loss_4': 0.9074578285217285, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 13:13:34,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:34,450 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:53<52:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:41,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015336712822318077, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.347, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013094778172671795, 'eval_loss_2': 0.002241935580968857, 'eval_loss_3': -18.22593879699707, 'eval_loss_4': 0.3891197144985199, 'epoch': 12.35}
{'loss': 0.0155, 'grad_norm': 7.316728591918945, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.015370415523648262, 'loss_2': 0.0001747608184814453, 'loss_3': -16.321331024169922, 'loss_4': 0.8919482827186584, 'epoch': 12.36}
{'loss': 0.0229, 'grad_norm': 9.543638229370117, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.020791107788681984, 'loss_2': 0.00213623046875, 'loss_3': -16.18208122253418, 'loss_4': 0.7803006172180176, 'epoch': 12.37}
{'loss': 0.0085, 'grad_norm': 5.292212009429932, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.005116268526762724, 'loss_2': 0.003391265869140625, 'loss_3': -16.403079986572266, 'loss_4': 0.2429565191268921, 'epoch': 12.37}
{'loss': 0.009, 'grad_norm': 5.133481979370117, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.007391436956822872, 'loss_2': 0.0016498565673828125, 'loss_3': -16.437679290771484, 'loss_4': 0.36852675676345825, 'epoch': 12.38}
{'loss': 0.0148, 'grad_norm': 5.168363571166992, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.005071072373539209, 'loss_2': 0.009735107421875, 'loss_3': -16.145977020263672, 'loss_4': 0.4641532003879547, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 13:13:41,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:41,788 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [53:01<52:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:49,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020433790981769562, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.398, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013915784657001495, 'eval_loss_2': 0.006518006324768066, 'eval_loss_3': -18.209083557128906, 'eval_loss_4': 0.2509085536003113, 'epoch': 12.38}
{'loss': 0.0125, 'grad_norm': 5.179263114929199, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.004196117632091045, 'loss_2': 0.008270263671875, 'loss_3': -16.47489356994629, 'loss_4': 0.13049916923046112, 'epoch': 12.39}
{'loss': 0.0123, 'grad_norm': 5.032660961151123, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.008126497268676758, 'loss_2': 0.004150390625, 'loss_3': -16.333831787109375, 'loss_4': 0.33897846937179565, 'epoch': 12.4}
{'loss': 0.0112, 'grad_norm': 5.91217565536499, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.009072396904230118, 'loss_2': 0.00215911865234375, 'loss_3': -16.261505126953125, 'loss_4': 0.23859268426895142, 'epoch': 12.4}
{'loss': 0.0382, 'grad_norm': 12.410388946533203, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.0326550267636776, 'loss_2': 0.00557708740234375, 'loss_3': -16.412113189697266, 'loss_4': 0.4082857668399811, 'epoch': 12.41}
{'loss': 0.015, 'grad_norm': 7.61277437210083, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.011063111945986748, 'loss_2': 0.00391387939453125, 'loss_3': -16.38612174987793, 'loss_4': -0.06571430712938309, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 13:13:49,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:49,123 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [53:08<52:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:56,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02030414342880249, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017083555459976196, 'eval_loss_2': 0.003220587968826294, 'eval_loss_3': -18.183338165283203, 'eval_loss_4': 0.11372853815555573, 'epoch': 12.41}
{'loss': 0.0171, 'grad_norm': 7.2101874351501465, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.01257726177573204, 'loss_2': 0.0045623779296875, 'loss_3': -16.100788116455078, 'loss_4': 0.370993435382843, 'epoch': 12.42}
{'loss': 0.0155, 'grad_norm': 8.5660400390625, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.01285554002970457, 'loss_2': 0.002658843994140625, 'loss_3': -16.213525772094727, 'loss_4': -0.09564182162284851, 'epoch': 12.42}
{'loss': 0.0407, 'grad_norm': 17.623458862304688, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.026220615953207016, 'loss_2': 0.01445770263671875, 'loss_3': -16.500219345092773, 'loss_4': 0.681096613407135, 'epoch': 12.43}
{'loss': 0.0097, 'grad_norm': 5.066641330718994, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.0093453424051404, 'loss_2': 0.0003376007080078125, 'loss_3': -16.16048812866211, 'loss_4': -0.09687333554029465, 'epoch': 12.44}
{'loss': 0.0133, 'grad_norm': 4.983283996582031, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.005917517002671957, 'loss_2': 0.007427215576171875, 'loss_3': -16.30748748779297, 'loss_4': -0.20880486071109772, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 13:13:56,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:56,462 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:15<52:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:03,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026090940460562706, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.866, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0175491776317358, 'eval_loss_2': 0.008541762828826904, 'eval_loss_3': -18.172779083251953, 'eval_loss_4': 0.12206365168094635, 'epoch': 12.44}
{'loss': 0.0415, 'grad_norm': 12.902297973632812, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.02948199398815632, 'loss_2': 0.01202392578125, 'loss_3': -16.324085235595703, 'loss_4': 0.1350124031305313, 'epoch': 12.45}
{'loss': 0.0159, 'grad_norm': 4.865456581115723, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.005112430080771446, 'loss_2': 0.01080322265625, 'loss_3': -16.441390991210938, 'loss_4': 0.4013228416442871, 'epoch': 12.45}
{'loss': 0.0267, 'grad_norm': 6.983394622802734, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.012773402035236359, 'loss_2': 0.0139007568359375, 'loss_3': -16.07465362548828, 'loss_4': 0.24015897512435913, 'epoch': 12.46}
{'loss': 0.0155, 'grad_norm': 5.611520290374756, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.010686691850423813, 'loss_2': 0.004856109619140625, 'loss_3': -16.41469955444336, 'loss_4': -0.06892724335193634, 'epoch': 12.47}
{'loss': 0.0195, 'grad_norm': 5.962165355682373, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.009407986886799335, 'loss_2': 0.0100555419921875, 'loss_3': -16.45973777770996, 'loss_4': 0.2402111142873764, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 13:14:03,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:03,798 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:23<51:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:11,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024899426847696304, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.188, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.018977826461195946, 'eval_loss_2': 0.005921602249145508, 'eval_loss_3': -18.152286529541016, 'eval_loss_4': 0.1587798297405243, 'epoch': 12.47}
{'loss': 0.0158, 'grad_norm': 4.599133491516113, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.010073339566588402, 'loss_2': 0.005741119384765625, 'loss_3': -16.463512420654297, 'loss_4': 0.014919161796569824, 'epoch': 12.48}
{'loss': 0.0242, 'grad_norm': 8.419391632080078, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.014258679933845997, 'loss_2': 0.009979248046875, 'loss_3': -16.198989868164062, 'loss_4': 0.02019408345222473, 'epoch': 12.48}
{'loss': 0.0094, 'grad_norm': 4.75913667678833, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.007038461044430733, 'loss_2': 0.00235748291015625, 'loss_3': -16.26824188232422, 'loss_4': -0.1276351511478424, 'epoch': 12.49}
{'loss': 0.0166, 'grad_norm': 6.856626987457275, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.014245337806642056, 'loss_2': 0.0023193359375, 'loss_3': -16.08831214904785, 'loss_4': -0.13962358236312866, 'epoch': 12.49}
{'loss': 0.0098, 'grad_norm': 5.149204254150391, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.008608322590589523, 'loss_2': 0.00121307373046875, 'loss_3': -15.955793380737305, 'loss_4': -0.0911945179104805, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 13:14:11,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:11,132 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:30<51:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:18,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026038799434900284, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.94, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.021669764071702957, 'eval_loss_2': 0.004369035363197327, 'eval_loss_3': -18.1336669921875, 'eval_loss_4': -0.022471584379673004, 'epoch': 12.5}
{'loss': 0.0105, 'grad_norm': 5.105424404144287, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.006404930725693703, 'loss_2': 0.00408172607421875, 'loss_3': -16.371496200561523, 'loss_4': 0.2466256022453308, 'epoch': 12.51}
{'loss': 0.0188, 'grad_norm': 7.5628509521484375, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.018168732523918152, 'loss_2': 0.0006775856018066406, 'loss_3': -16.343048095703125, 'loss_4': 0.2655460238456726, 'epoch': 12.51}
{'loss': 0.0217, 'grad_norm': 10.4358491897583, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.019133783876895905, 'loss_2': 0.0025482177734375, 'loss_3': -16.44803810119629, 'loss_4': -0.30505624413490295, 'epoch': 12.52}
{'loss': 0.0133, 'grad_norm': 5.021471977233887, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.008716906420886517, 'loss_2': 0.00458526611328125, 'loss_3': -16.258737564086914, 'loss_4': -0.40770792961120605, 'epoch': 12.52}
{'loss': 0.0282, 'grad_norm': 8.442814826965332, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.018996842205524445, 'loss_2': 0.0091705322265625, 'loss_3': -16.10659408569336, 'loss_4': -0.36355525255203247, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 13:14:18,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:18,469 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:37<51:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:25,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026692863553762436, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.322, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.02209758386015892, 'eval_loss_2': 0.004595279693603516, 'eval_loss_3': -18.150924682617188, 'eval_loss_4': -0.21619707345962524, 'epoch': 12.53}
{'loss': 0.0175, 'grad_norm': 5.375953674316406, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.010399270802736282, 'loss_2': 0.0070953369140625, 'loss_3': -16.03271484375, 'loss_4': -0.09864254295825958, 'epoch': 12.53}
{'loss': 0.0178, 'grad_norm': 5.7978010177612305, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.009721009992063046, 'loss_2': 0.00811767578125, 'loss_3': -16.337509155273438, 'loss_4': -0.12190116196870804, 'epoch': 12.54}
{'loss': 0.0128, 'grad_norm': 4.983462810516357, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.004769796505570412, 'loss_2': 0.00807952880859375, 'loss_3': -16.24463653564453, 'loss_4': -0.40228235721588135, 'epoch': 12.55}
{'loss': 0.0123, 'grad_norm': 5.500664234161377, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.010507158003747463, 'loss_2': 0.0017490386962890625, 'loss_3': -16.28530502319336, 'loss_4': -0.7551538348197937, 'epoch': 12.55}
{'loss': 0.0119, 'grad_norm': 5.408554553985596, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.010211862623691559, 'loss_2': 0.001678466796875, 'loss_3': -16.132875442504883, 'loss_4': -0.06829267740249634, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 13:14:25,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:25,802 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:45<51:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:33,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028839319944381714, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.025139929726719856, 'eval_loss_2': 0.003699392080307007, 'eval_loss_3': -18.14248275756836, 'eval_loss_4': -0.20560207962989807, 'epoch': 12.56}
{'loss': 0.0232, 'grad_norm': 10.5770263671875, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.022420592606067657, 'loss_2': 0.0008091926574707031, 'loss_3': -16.300819396972656, 'loss_4': -0.5239059925079346, 'epoch': 12.56}
{'loss': 0.0306, 'grad_norm': 8.811172485351562, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.018122080713510513, 'loss_2': 0.0124359130859375, 'loss_3': -16.143356323242188, 'loss_4': -0.21788741648197174, 'epoch': 12.57}
{'loss': 0.011, 'grad_norm': 6.1463470458984375, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.010652894154191017, 'loss_2': 0.00032901763916015625, 'loss_3': -16.288013458251953, 'loss_4': -0.1594533622264862, 'epoch': 12.58}
{'loss': 0.0201, 'grad_norm': 5.136324405670166, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.014803577214479446, 'loss_2': 0.00528717041015625, 'loss_3': -16.43553352355957, 'loss_4': 0.1822897046804428, 'epoch': 12.58}
{'loss': 0.0847, 'grad_norm': 12.814881324768066, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.07878502458333969, 'loss_2': 0.0059356689453125, 'loss_3': -16.344383239746094, 'loss_4': 0.14452296495437622, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 13:14:33,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:33,152 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:52<51:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:40,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031421445310115814, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.443, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.025026746094226837, 'eval_loss_2': 0.006394699215888977, 'eval_loss_3': -18.127365112304688, 'eval_loss_4': 0.008911538869142532, 'epoch': 12.59}
{'loss': 0.0835, 'grad_norm': 19.996524810791016, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.0739729180932045, 'loss_2': 0.0095672607421875, 'loss_3': -16.257701873779297, 'loss_4': 0.5333414077758789, 'epoch': 12.59}
{'loss': 0.011, 'grad_norm': 5.54908561706543, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.010943367145955563, 'loss_2': 6.479024887084961e-05, 'loss_3': -16.362777709960938, 'loss_4': 0.5059256553649902, 'epoch': 12.6}
{'loss': 0.0155, 'grad_norm': 5.0316972732543945, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.006206882651895285, 'loss_2': 0.00931549072265625, 'loss_3': -16.417163848876953, 'loss_4': 0.3434087634086609, 'epoch': 12.6}
{'loss': 0.0203, 'grad_norm': 6.823534965515137, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.020244471728801727, 'loss_2': 9.149312973022461e-05, 'loss_3': -16.187671661376953, 'loss_4': -0.029474109411239624, 'epoch': 12.61}
{'loss': 0.0264, 'grad_norm': 8.738374710083008, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.0256004948168993, 'loss_2': 0.0008225440979003906, 'loss_3': -16.447765350341797, 'loss_4': 0.15460489690303802, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 13:14:40,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:40,483 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [53:59<51:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:47,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029196936637163162, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.106, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.021835582330822945, 'eval_loss_2': 0.007361352443695068, 'eval_loss_3': -18.10334587097168, 'eval_loss_4': 0.17765557765960693, 'epoch': 12.62}
{'loss': 0.0286, 'grad_norm': 5.411848068237305, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.012033200822770596, 'loss_2': 0.016571044921875, 'loss_3': -16.375154495239258, 'loss_4': 0.4682212173938751, 'epoch': 12.62}
{'loss': 0.0317, 'grad_norm': 22.199968338012695, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.022256750613451004, 'loss_2': 0.0094146728515625, 'loss_3': -16.27176284790039, 'loss_4': 0.7558640241622925, 'epoch': 12.63}
{'loss': 0.0338, 'grad_norm': 11.191910743713379, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.02729473076760769, 'loss_2': 0.006549835205078125, 'loss_3': -16.36599349975586, 'loss_4': 0.20421713590621948, 'epoch': 12.63}
{'loss': 0.0204, 'grad_norm': 6.979886531829834, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.014357473701238632, 'loss_2': 0.0059967041015625, 'loss_3': -16.12994384765625, 'loss_4': 0.2643571197986603, 'epoch': 12.64}
{'loss': 0.0117, 'grad_norm': 5.205438137054443, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.006515206769108772, 'loss_2': 0.00518798828125, 'loss_3': -16.23276710510254, 'loss_4': 0.3754265606403351, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 13:14:47,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:47,820 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [54:07<51:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:55,148 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02630571648478508, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.061, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.020245175808668137, 'eval_loss_2': 0.006060540676116943, 'eval_loss_3': -18.144264221191406, 'eval_loss_4': 0.013903115876019001, 'epoch': 12.65}
{'loss': 0.0204, 'grad_norm': 6.758616924285889, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.01733192428946495, 'loss_2': 0.0030231475830078125, 'loss_3': -16.36542510986328, 'loss_4': -0.053643740713596344, 'epoch': 12.65}
{'loss': 0.0122, 'grad_norm': 5.303619861602783, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.009727578610181808, 'loss_2': 0.002521514892578125, 'loss_3': -16.382278442382812, 'loss_4': 0.06179479509592056, 'epoch': 12.66}
{'loss': 0.0206, 'grad_norm': 10.2074613571167, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.014419945888221264, 'loss_2': 0.006168365478515625, 'loss_3': -16.1383113861084, 'loss_4': -0.0045909583568573, 'epoch': 12.66}
{'loss': 0.0402, 'grad_norm': 14.54833698272705, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.035489778965711594, 'loss_2': 0.004718780517578125, 'loss_3': -16.375751495361328, 'loss_4': -0.3061312437057495, 'epoch': 12.67}
{'loss': 0.0081, 'grad_norm': 4.964539527893066, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.00751557806506753, 'loss_2': 0.0005502700805664062, 'loss_3': -16.45334815979004, 'loss_4': -0.27523306012153625, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 13:14:55,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:55,148 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [54:14<51:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:02,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02119637094438076, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.943, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.017473643645644188, 'eval_loss_2': 0.0037227272987365723, 'eval_loss_3': -18.156545639038086, 'eval_loss_4': -0.0857871025800705, 'epoch': 12.67}
{'loss': 0.0125, 'grad_norm': 4.363683700561523, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.004850077908486128, 'loss_2': 0.00762939453125, 'loss_3': -16.219764709472656, 'loss_4': -0.007889464497566223, 'epoch': 12.68}
{'loss': 0.0244, 'grad_norm': 7.166501998901367, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.015578009188175201, 'loss_2': 0.0088348388671875, 'loss_3': -16.114459991455078, 'loss_4': -0.3475949168205261, 'epoch': 12.69}
{'loss': 0.0184, 'grad_norm': 7.754791259765625, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.014182830229401588, 'loss_2': 0.0042266845703125, 'loss_3': -16.231502532958984, 'loss_4': -0.04827000945806503, 'epoch': 12.69}
{'loss': 0.0086, 'grad_norm': 5.363513946533203, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.0070759616792202, 'loss_2': 0.0014848709106445312, 'loss_3': -16.364356994628906, 'loss_4': 0.1542259007692337, 'epoch': 12.7}
{'loss': 0.027, 'grad_norm': 8.139995574951172, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.023894134908914566, 'loss_2': 0.00315093994140625, 'loss_3': -16.170921325683594, 'loss_4': -0.1627470850944519, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 13:15:02,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:02,480 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:21<51:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:09,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02090081200003624, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.906, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.017692741006612778, 'eval_loss_2': 0.003208070993423462, 'eval_loss_3': -18.142152786254883, 'eval_loss_4': -0.076261967420578, 'epoch': 12.7}
{'loss': 0.0154, 'grad_norm': 9.742035865783691, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.013869751244783401, 'loss_2': 0.0014810562133789062, 'loss_3': -16.256582260131836, 'loss_4': -0.127397358417511, 'epoch': 12.71}
{'loss': 0.0186, 'grad_norm': 8.760746955871582, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.018254302442073822, 'loss_2': 0.0003142356872558594, 'loss_3': -16.359453201293945, 'loss_4': 0.17137494683265686, 'epoch': 12.72}
{'loss': 0.013, 'grad_norm': 6.197285175323486, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.012450311332941055, 'loss_2': 0.0005350112915039062, 'loss_3': -16.385839462280273, 'loss_4': -0.2792944312095642, 'epoch': 12.72}
{'loss': 0.0088, 'grad_norm': 4.840398788452148, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.008040976710617542, 'loss_2': 0.0007128715515136719, 'loss_3': -16.50019073486328, 'loss_4': 0.09103146195411682, 'epoch': 12.73}
{'loss': 0.0136, 'grad_norm': 4.703224182128906, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.007477142848074436, 'loss_2': 0.00612640380859375, 'loss_3': -16.317886352539062, 'loss_4': 0.09075602889060974, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 13:15:09,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:09,815 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:29<51:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:17,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021984022110700607, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01850990764796734, 'eval_loss_2': 0.003474116325378418, 'eval_loss_3': -18.121179580688477, 'eval_loss_4': -0.17888399958610535, 'epoch': 12.73}
{'loss': 0.0663, 'grad_norm': 10.193227767944336, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.06124270334839821, 'loss_2': 0.00504302978515625, 'loss_3': -16.400197982788086, 'loss_4': 0.4373726546764374, 'epoch': 12.74}
{'loss': 0.0374, 'grad_norm': 14.557609558105469, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.03213563188910484, 'loss_2': 0.00527191162109375, 'loss_3': -16.09442901611328, 'loss_4': 0.2996024787425995, 'epoch': 12.74}
{'loss': 0.0093, 'grad_norm': 4.586516857147217, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.006485539022833109, 'loss_2': 0.002826690673828125, 'loss_3': -16.29543685913086, 'loss_4': 0.03646364063024521, 'epoch': 12.75}
{'loss': 0.0101, 'grad_norm': 4.462952613830566, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.007575896102935076, 'loss_2': 0.0025157928466796875, 'loss_3': -16.334922790527344, 'loss_4': -0.06863696128129959, 'epoch': 12.76}
{'loss': 0.0095, 'grad_norm': 5.248582363128662, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.009184345602989197, 'loss_2': 0.0002808570861816406, 'loss_3': -16.34027862548828, 'loss_4': 0.16448655724525452, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 13:15:17,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:17,148 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:36<51:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:24,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02249078080058098, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.079, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.016521193087100983, 'eval_loss_2': 0.005969583988189697, 'eval_loss_3': -18.152063369750977, 'eval_loss_4': -0.22631831467151642, 'epoch': 12.76}
{'loss': 0.01, 'grad_norm': 4.314377307891846, 'learning_rate': 1.725e-05, 'loss_1': 0.005038194824010134, 'loss_2': 0.004974365234375, 'loss_3': -16.218181610107422, 'loss_4': -0.12057111412286758, 'epoch': 12.77}
{'loss': 0.0131, 'grad_norm': 5.917203903198242, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.008828610181808472, 'loss_2': 0.004283905029296875, 'loss_3': -16.135053634643555, 'loss_4': 0.02198142558336258, 'epoch': 12.77}
{'loss': 0.0242, 'grad_norm': 6.219705104827881, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.012357912957668304, 'loss_2': 0.011871337890625, 'loss_3': -16.41812515258789, 'loss_4': 0.37045225501060486, 'epoch': 12.78}
{'loss': 0.0663, 'grad_norm': 23.253257751464844, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.06336363404989243, 'loss_2': 0.00293731689453125, 'loss_3': -16.35727882385254, 'loss_4': 0.16644322872161865, 'epoch': 12.78}
{'loss': 0.0104, 'grad_norm': 6.938887119293213, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.007232832256704569, 'loss_2': 0.003143310546875, 'loss_3': -16.507137298583984, 'loss_4': -0.40021640062332153, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 13:15:24,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:24,483 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:43<51:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:31,826 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018033724278211594, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.823, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01423417404294014, 'eval_loss_2': 0.003799550235271454, 'eval_loss_3': -18.186166763305664, 'eval_loss_4': -0.28142818808555603, 'epoch': 12.79}
{'loss': 0.011, 'grad_norm': 5.657491683959961, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.007599107455462217, 'loss_2': 0.00339508056640625, 'loss_3': -16.264873504638672, 'loss_4': -0.17814844846725464, 'epoch': 12.8}
{'loss': 0.0292, 'grad_norm': 9.893757820129395, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.024451980367302895, 'loss_2': 0.00478363037109375, 'loss_3': -16.37659454345703, 'loss_4': 0.2458256483078003, 'epoch': 12.8}
{'loss': 0.0155, 'grad_norm': 6.0659708976745605, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.013971377164125443, 'loss_2': 0.0014858245849609375, 'loss_3': -16.21637535095215, 'loss_4': 0.06513980031013489, 'epoch': 12.81}
{'loss': 0.012, 'grad_norm': 6.154021263122559, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.011889765039086342, 'loss_2': 9.953975677490234e-05, 'loss_3': -16.402681350708008, 'loss_4': -0.2904481291770935, 'epoch': 12.81}
{'loss': 0.0084, 'grad_norm': 4.715812683105469, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.006891051772981882, 'loss_2': 0.001499176025390625, 'loss_3': -16.280075073242188, 'loss_4': -0.011637844145298004, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 13:15:31,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:31,826 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:51<50:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:39,159 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017883911728858948, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.138, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01417640782892704, 'eval_loss_2': 0.003707505762577057, 'eval_loss_3': -18.1976261138916, 'eval_loss_4': -0.36957165598869324, 'epoch': 12.82}
{'loss': 0.014, 'grad_norm': 6.466165542602539, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.010400146245956421, 'loss_2': 0.00356292724609375, 'loss_3': -16.070680618286133, 'loss_4': -0.1630566418170929, 'epoch': 12.83}
{'loss': 0.0161, 'grad_norm': 5.379873275756836, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.010983705520629883, 'loss_2': 0.0050811767578125, 'loss_3': -16.26740837097168, 'loss_4': -0.12037064135074615, 'epoch': 12.83}
{'loss': 0.0261, 'grad_norm': 7.282339096069336, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.01597561128437519, 'loss_2': 0.0101165771484375, 'loss_3': -16.378650665283203, 'loss_4': -0.5499069690704346, 'epoch': 12.84}
{'loss': 0.0096, 'grad_norm': 5.499176502227783, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.008712262846529484, 'loss_2': 0.0009336471557617188, 'loss_3': -16.355051040649414, 'loss_4': 0.020761415362358093, 'epoch': 12.84}
{'loss': 0.0179, 'grad_norm': 6.934304714202881, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.011754799634218216, 'loss_2': 0.00617218017578125, 'loss_3': -16.35904312133789, 'loss_4': 0.035035744309425354, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 13:15:39,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:39,159 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [54:58<50:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:46,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01568390242755413, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.031, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01229230035096407, 'eval_loss_2': 0.0033916011452674866, 'eval_loss_3': -18.230052947998047, 'eval_loss_4': -0.41591519117355347, 'epoch': 12.85}
{'loss': 0.0189, 'grad_norm': 5.145640850067139, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.01270593423396349, 'loss_2': 0.006229400634765625, 'loss_3': -16.396610260009766, 'loss_4': -0.6902145743370056, 'epoch': 12.85}
{'loss': 0.0195, 'grad_norm': 9.120027542114258, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.018097462132573128, 'loss_2': 0.0013980865478515625, 'loss_3': -16.270709991455078, 'loss_4': -0.11063427478075027, 'epoch': 12.86}
{'loss': 0.0139, 'grad_norm': 7.5283098220825195, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.013903465121984482, 'loss_2': 1.3053417205810547e-05, 'loss_3': -16.28497314453125, 'loss_4': -0.036572445183992386, 'epoch': 12.87}
{'loss': 0.0106, 'grad_norm': 4.722698211669922, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.007097398396581411, 'loss_2': 0.003498077392578125, 'loss_3': -16.434738159179688, 'loss_4': -0.05563244968652725, 'epoch': 12.87}
{'loss': 0.0156, 'grad_norm': 7.335689067840576, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.015550252050161362, 'loss_2': 6.341934204101562e-05, 'loss_3': -16.20079231262207, 'loss_4': -0.13831771910190582, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 13:15:46,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:46,499 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [55:05<50:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:53,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015760114416480064, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.646, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011835119687020779, 'eval_loss_2': 0.00392499566078186, 'eval_loss_3': -18.198957443237305, 'eval_loss_4': -0.263725221157074, 'epoch': 12.88}
{'loss': 0.0203, 'grad_norm': 8.400959014892578, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.016281230375170708, 'loss_2': 0.0040130615234375, 'loss_3': -16.374038696289062, 'loss_4': -0.379022479057312, 'epoch': 12.88}
{'loss': 0.0572, 'grad_norm': 27.58343505859375, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.05653540790081024, 'loss_2': 0.0006718635559082031, 'loss_3': -16.207408905029297, 'loss_4': -0.2693009078502655, 'epoch': 12.89}
{'loss': 0.0138, 'grad_norm': 5.327233791351318, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.010621984489262104, 'loss_2': 0.00315093994140625, 'loss_3': -16.318994522094727, 'loss_4': -0.10532661527395248, 'epoch': 12.9}
{'loss': 0.013, 'grad_norm': 5.245719909667969, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.007255087606608868, 'loss_2': 0.0057525634765625, 'loss_3': -16.125011444091797, 'loss_4': -0.06180068850517273, 'epoch': 12.9}
{'loss': 0.0208, 'grad_norm': 7.496291637420654, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.011800135485827923, 'loss_2': 0.0090179443359375, 'loss_3': -16.190773010253906, 'loss_4': 0.25191861391067505, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 13:15:53,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:53,851 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [55:13<50:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:01,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01704513095319271, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.843, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012210746295750141, 'eval_loss_2': 0.004834383726119995, 'eval_loss_3': -18.1811580657959, 'eval_loss_4': -0.16239427030086517, 'epoch': 12.91}
{'loss': 0.0137, 'grad_norm': 4.416854381561279, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.0090708639472723, 'loss_2': 0.00464630126953125, 'loss_3': -16.35173797607422, 'loss_4': 0.21566589176654816, 'epoch': 12.91}
{'loss': 0.0116, 'grad_norm': 4.839687824249268, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.005955327767878771, 'loss_2': 0.005672454833984375, 'loss_3': -16.339767456054688, 'loss_4': -0.27619749307632446, 'epoch': 12.92}
{'loss': 0.0138, 'grad_norm': 5.082307815551758, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.006362754851579666, 'loss_2': 0.007472991943359375, 'loss_3': -16.412567138671875, 'loss_4': -0.09191150963306427, 'epoch': 12.92}
{'loss': 0.0161, 'grad_norm': 7.202890872955322, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.013137249276041985, 'loss_2': 0.0030059814453125, 'loss_3': -16.26458168029785, 'loss_4': -0.11273093521595001, 'epoch': 12.93}
{'loss': 0.009, 'grad_norm': 4.478055000305176, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.007130557671189308, 'loss_2': 0.0018739700317382812, 'loss_3': -16.25864601135254, 'loss_4': 0.3315010368824005, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 13:16:01,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:01,190 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:20<50:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:08,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013910746201872826, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.877, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011161847971379757, 'eval_loss_2': 0.0027488991618156433, 'eval_loss_3': -18.195045471191406, 'eval_loss_4': -0.02585097961127758, 'epoch': 12.94}
{'loss': 0.0552, 'grad_norm': 19.76213264465332, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.051565952599048615, 'loss_2': 0.0036792755126953125, 'loss_3': -16.241044998168945, 'loss_4': -0.1416832059621811, 'epoch': 12.94}
{'loss': 0.0237, 'grad_norm': 8.194984436035156, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.014021063223481178, 'loss_2': 0.0096893310546875, 'loss_3': -16.060428619384766, 'loss_4': -0.40467411279678345, 'epoch': 12.95}
{'loss': 0.033, 'grad_norm': 8.849555969238281, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.03221723064780235, 'loss_2': 0.0008029937744140625, 'loss_3': -16.24834442138672, 'loss_4': 0.44177180528640747, 'epoch': 12.95}
{'loss': 0.0341, 'grad_norm': 9.83273696899414, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.025185102596879005, 'loss_2': 0.0089263916015625, 'loss_3': -16.18854522705078, 'loss_4': -0.012980721890926361, 'epoch': 12.96}
{'loss': 0.0275, 'grad_norm': 7.289866924285889, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.016156494617462158, 'loss_2': 0.0113372802734375, 'loss_3': -16.546981811523438, 'loss_4': 0.5595513582229614, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 13:16:08,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:08,526 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:27<50:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:16:15,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02031242474913597, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.303, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012599346227943897, 'eval_loss_2': 0.0077130794525146484, 'eval_loss_3': -18.209606170654297, 'eval_loss_4': 0.038173675537109375, 'epoch': 12.97}
{'loss': 0.0321, 'grad_norm': 18.427711486816406, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.030087582767009735, 'loss_2': 0.0019989013671875, 'loss_3': -16.315277099609375, 'loss_4': 0.06747397780418396, 'epoch': 12.97}
{'loss': 0.0508, 'grad_norm': 16.79485511779785, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.03479607775807381, 'loss_2': 0.015960693359375, 'loss_3': -16.148191452026367, 'loss_4': 0.4721536636352539, 'epoch': 12.98}
{'loss': 0.0133, 'grad_norm': 5.231343746185303, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.008892025798559189, 'loss_2': 0.00445556640625, 'loss_3': -16.14583969116211, 'loss_4': 0.5657361149787903, 'epoch': 12.98}
{'loss': 0.0202, 'grad_norm': 7.146725177764893, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.019237026572227478, 'loss_2': 0.0009241104125976562, 'loss_3': -16.31438446044922, 'loss_4': 0.22567437589168549, 'epoch': 12.99}
{'loss': 0.0274, 'grad_norm': 7.51436710357666, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.014055224135518074, 'loss_2': 0.01336669921875, 'loss_3': -16.11556053161621, 'loss_4': 0.18708185851573944, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 13:16:15,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:15,833 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:34<49:30,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:16:22,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018930599093437195, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.164, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013962791301310062, 'eval_loss_2': 0.004967808723449707, 'eval_loss_3': -18.200210571289062, 'eval_loss_4': -0.1885802298784256, 'epoch': 12.99}
{'loss': 0.0172, 'grad_norm': 7.198412895202637, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.006485681049525738, 'loss_2': 0.0106658935546875, 'loss_3': -16.446439743041992, 'loss_4': -0.40702661871910095, 'epoch': 13.0}
{'loss': 0.0124, 'grad_norm': 5.736802577972412, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.01050141453742981, 'loss_2': 0.00194549560546875, 'loss_3': -16.314563751220703, 'loss_4': 0.23010167479515076, 'epoch': 13.01}
{'loss': 0.0196, 'grad_norm': 7.673293590545654, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.019045865163207054, 'loss_2': 0.0005769729614257812, 'loss_3': -16.281618118286133, 'loss_4': 0.4061911702156067, 'epoch': 13.01}
{'loss': 0.0121, 'grad_norm': 5.0872111320495605, 'learning_rate': 1.7e-05, 'loss_1': 0.009129476733505726, 'loss_2': 0.003002166748046875, 'loss_3': -16.390865325927734, 'loss_4': -0.38362956047058105, 'epoch': 13.02}
{'loss': 0.0237, 'grad_norm': 7.425447463989258, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.018113335594534874, 'loss_2': 0.005588531494140625, 'loss_3': -16.38422966003418, 'loss_4': -0.15135176479816437, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 13:16:22,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:22,890 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:42<50:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:16:30,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01714499481022358, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.517, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01502841804176569, 'eval_loss_2': 0.002116575837135315, 'eval_loss_3': -18.191370010375977, 'eval_loss_4': -0.2342384308576584, 'epoch': 13.02}
{'loss': 0.0179, 'grad_norm': 6.140313625335693, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.014814267866313457, 'loss_2': 0.003101348876953125, 'loss_3': -16.39004898071289, 'loss_4': 0.05751880258321762, 'epoch': 13.03}
{'loss': 0.0253, 'grad_norm': 8.57300090789795, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.02360091544687748, 'loss_2': 0.00174713134765625, 'loss_3': -16.132858276367188, 'loss_4': -0.17936284840106964, 'epoch': 13.03}
{'loss': 0.0199, 'grad_norm': 12.232633590698242, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.018427889794111252, 'loss_2': 0.0014629364013671875, 'loss_3': -16.473289489746094, 'loss_4': 0.1310350000858307, 'epoch': 13.04}
{'loss': 0.0212, 'grad_norm': 7.072935581207275, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.016097504645586014, 'loss_2': 0.00507354736328125, 'loss_3': -16.393463134765625, 'loss_4': -0.0007689893245697021, 'epoch': 13.05}
{'loss': 0.0183, 'grad_norm': 5.431026935577393, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.01045715156942606, 'loss_2': 0.00787353515625, 'loss_3': -16.226497650146484, 'loss_4': 0.09382472932338715, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 13:16:30,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:30,235 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:49<50:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:16:37,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017349641770124435, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.88, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014984008856117725, 'eval_loss_2': 0.0023656338453292847, 'eval_loss_3': -18.175758361816406, 'eval_loss_4': -0.3854072391986847, 'epoch': 13.05}
{'loss': 0.0083, 'grad_norm': 4.946283340454102, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.007453369442373514, 'loss_2': 0.0008091926574707031, 'loss_3': -16.30124282836914, 'loss_4': -0.6050482988357544, 'epoch': 13.06}
{'loss': 0.0236, 'grad_norm': 10.619799613952637, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.01883840188384056, 'loss_2': 0.004791259765625, 'loss_3': -16.089916229248047, 'loss_4': -0.7087128162384033, 'epoch': 13.06}
{'loss': 0.0166, 'grad_norm': 5.662596225738525, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.008759344927966595, 'loss_2': 0.00788116455078125, 'loss_3': -16.16469383239746, 'loss_4': -0.2337428629398346, 'epoch': 13.07}
{'loss': 0.0149, 'grad_norm': 6.058696269989014, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.013151316903531551, 'loss_2': 0.0017070770263671875, 'loss_3': -16.361879348754883, 'loss_4': -0.23837929964065552, 'epoch': 13.08}
{'loss': 0.0133, 'grad_norm': 6.053368091583252, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.012496230192482471, 'loss_2': 0.0008449554443359375, 'loss_3': -16.231582641601562, 'loss_4': -0.3116188049316406, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 13:16:37,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:37,560 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:56<50:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:44,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020933454856276512, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.321, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015188165009021759, 'eval_loss_2': 0.005745291709899902, 'eval_loss_3': -18.181337356567383, 'eval_loss_4': -0.4780902564525604, 'epoch': 13.08}
{'loss': 0.0186, 'grad_norm': 5.7788519859313965, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.010344495996832848, 'loss_2': 0.008270263671875, 'loss_3': -16.171337127685547, 'loss_4': -0.3352339565753937, 'epoch': 13.09}
{'loss': 0.0256, 'grad_norm': 12.364009857177734, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.01778927631676197, 'loss_2': 0.00778961181640625, 'loss_3': -16.39837646484375, 'loss_4': -0.10887891799211502, 'epoch': 13.09}
{'loss': 0.02, 'grad_norm': 8.87662124633789, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.014870206825435162, 'loss_2': 0.005157470703125, 'loss_3': -16.364124298095703, 'loss_4': -0.28347423672676086, 'epoch': 13.1}
{'loss': 0.0181, 'grad_norm': 6.96116828918457, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.013712258078157902, 'loss_2': 0.0043487548828125, 'loss_3': -16.35276222229004, 'loss_4': -0.4296238124370575, 'epoch': 13.1}
{'loss': 0.0201, 'grad_norm': 5.023434638977051, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.009407141245901585, 'loss_2': 0.01065826416015625, 'loss_3': -16.181114196777344, 'loss_4': -0.25919702649116516, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 13:16:44,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:44,886 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [56:04<50:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:52,218 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018613867461681366, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.386, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015476634725928307, 'eval_loss_2': 0.00313723087310791, 'eval_loss_3': -18.197023391723633, 'eval_loss_4': -0.21583230793476105, 'epoch': 13.11}
{'loss': 0.0145, 'grad_norm': 5.166683673858643, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.00930181983858347, 'loss_2': 0.0052337646484375, 'loss_3': -16.425363540649414, 'loss_4': 0.6229127049446106, 'epoch': 13.12}
{'loss': 0.0178, 'grad_norm': 6.478211879730225, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.016584519296884537, 'loss_2': 0.00119781494140625, 'loss_3': -16.357206344604492, 'loss_4': -0.4238976836204529, 'epoch': 13.12}
{'loss': 0.0993, 'grad_norm': 14.818378448486328, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.09069681167602539, 'loss_2': 0.00856781005859375, 'loss_3': -16.111745834350586, 'loss_4': -0.1864657700061798, 'epoch': 13.13}
{'loss': 0.0283, 'grad_norm': 10.236108779907227, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.019436439499258995, 'loss_2': 0.00885009765625, 'loss_3': -16.155847549438477, 'loss_4': 0.07398514449596405, 'epoch': 13.13}
{'loss': 0.0219, 'grad_norm': 5.373300552368164, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.010487494990229607, 'loss_2': 0.0113983154296875, 'loss_3': -16.43732452392578, 'loss_4': 0.09663505852222443, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 13:16:52,218 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:52,218 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [56:11<50:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:59,549 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024223648011684418, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.438, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.017756544053554535, 'eval_loss_2': 0.006467103958129883, 'eval_loss_3': -18.192790985107422, 'eval_loss_4': 0.1623571366071701, 'epoch': 13.14}
{'loss': 0.0247, 'grad_norm': 7.416849136352539, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.01581767573952675, 'loss_2': 0.00885772705078125, 'loss_3': -16.272850036621094, 'loss_4': -0.41522517800331116, 'epoch': 13.15}
{'loss': 0.0298, 'grad_norm': 11.413451194763184, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.023257246240973473, 'loss_2': 0.006511688232421875, 'loss_3': -16.251115798950195, 'loss_4': 0.8657165169715881, 'epoch': 13.15}
{'loss': 0.0211, 'grad_norm': 10.858505249023438, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.01865258999168873, 'loss_2': 0.0024356842041015625, 'loss_3': -16.294084548950195, 'loss_4': 0.8037312030792236, 'epoch': 13.16}
{'loss': 0.0145, 'grad_norm': 5.071843147277832, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.011376891285181046, 'loss_2': 0.003116607666015625, 'loss_3': -16.16799545288086, 'loss_4': 0.10975632071495056, 'epoch': 13.16}
{'loss': 0.0187, 'grad_norm': 5.473364353179932, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.007848871871829033, 'loss_2': 0.01084136962890625, 'loss_3': -16.43609619140625, 'loss_4': 0.44844886660575867, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 13:16:59,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:59,549 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:18<49:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:06,878 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023358874022960663, 'eval_runtime': 3.7833, 'eval_samples_per_second': 270.661, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.019511636346578598, 'eval_loss_2': 0.0038472414016723633, 'eval_loss_3': -18.184423446655273, 'eval_loss_4': 0.4761882722377777, 'epoch': 13.17}
{'loss': 0.0383, 'grad_norm': 12.038750648498535, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.03588423132896423, 'loss_2': 0.0024013519287109375, 'loss_3': -16.152124404907227, 'loss_4': 0.36621391773223877, 'epoch': 13.17}
{'loss': 0.0108, 'grad_norm': 5.181328296661377, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.0053460728377103806, 'loss_2': 0.00550079345703125, 'loss_3': -16.281200408935547, 'loss_4': 0.7474637627601624, 'epoch': 13.18}
{'loss': 0.0279, 'grad_norm': 8.496756553649902, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.026119057089090347, 'loss_2': 0.0017614364624023438, 'loss_3': -16.247791290283203, 'loss_4': 1.357198715209961, 'epoch': 13.19}
{'loss': 0.0136, 'grad_norm': 5.422300815582275, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.009640015661716461, 'loss_2': 0.00395965576171875, 'loss_3': -16.355884552001953, 'loss_4': 0.49056169390678406, 'epoch': 13.19}
{'loss': 0.0441, 'grad_norm': 15.569718360900879, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.04022698849439621, 'loss_2': 0.003917694091796875, 'loss_3': -16.190135955810547, 'loss_4': 1.022162675857544, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 13:17:06,878 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:06,878 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:26<49:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:14,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02614101767539978, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.005, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.023441461846232414, 'eval_loss_2': 0.002699553966522217, 'eval_loss_3': -18.1571102142334, 'eval_loss_4': 0.8549466133117676, 'epoch': 13.2}
{'loss': 0.0217, 'grad_norm': 7.6117143630981445, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.019447151571512222, 'loss_2': 0.0022907257080078125, 'loss_3': -16.212522506713867, 'loss_4': 0.9842888116836548, 'epoch': 13.2}
{'loss': 0.0161, 'grad_norm': 8.239714622497559, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.015560821630060673, 'loss_2': 0.0005216598510742188, 'loss_3': -16.22806167602539, 'loss_4': 0.8421688079833984, 'epoch': 13.21}
{'loss': 0.007, 'grad_norm': 5.856342792510986, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.006900161039084196, 'loss_2': 7.95125961303711e-05, 'loss_3': -16.244972229003906, 'loss_4': 0.8734351396560669, 'epoch': 13.22}
{'loss': 0.0286, 'grad_norm': 20.223066329956055, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.026788927614688873, 'loss_2': 0.0018205642700195312, 'loss_3': -16.088058471679688, 'loss_4': 1.2823126316070557, 'epoch': 13.22}
{'loss': 0.0196, 'grad_norm': 5.500809192657471, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.011095044203102589, 'loss_2': 0.008544921875, 'loss_3': -16.394733428955078, 'loss_4': 1.311191439628601, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 13:17:14,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:14,221 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:33<49:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:21,561 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031667426228523254, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.419, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.025546863675117493, 'eval_loss_2': 0.006120562553405762, 'eval_loss_3': -18.167034149169922, 'eval_loss_4': 1.2358949184417725, 'epoch': 13.23}
{'loss': 0.0288, 'grad_norm': 8.343293190002441, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.022706277668476105, 'loss_2': 0.006103515625, 'loss_3': -16.40380859375, 'loss_4': 0.5659841895103455, 'epoch': 13.23}
{'loss': 0.0153, 'grad_norm': 5.329426288604736, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.012241099961102009, 'loss_2': 0.003025054931640625, 'loss_3': -16.321857452392578, 'loss_4': 1.1562364101409912, 'epoch': 13.24}
{'loss': 0.0211, 'grad_norm': 9.492676734924316, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.01606496050953865, 'loss_2': 0.00505828857421875, 'loss_3': -16.146381378173828, 'loss_4': 1.0039172172546387, 'epoch': 13.24}
{'loss': 0.0157, 'grad_norm': 6.251221656799316, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.010128175839781761, 'loss_2': 0.005542755126953125, 'loss_3': -16.312480926513672, 'loss_4': 1.1129289865493774, 'epoch': 13.25}
{'loss': 0.0186, 'grad_norm': 6.076521396636963, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.010253790766000748, 'loss_2': 0.00830078125, 'loss_3': -16.07942008972168, 'loss_4': 1.4151337146759033, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 13:17:21,561 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:21,561 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:40<49:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:28,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020864104852080345, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.207, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01772007904946804, 'eval_loss_2': 0.0031440258026123047, 'eval_loss_3': -18.264856338500977, 'eval_loss_4': 1.441677212715149, 'epoch': 13.26}
{'loss': 0.022, 'grad_norm': 5.774709701538086, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.0143643943592906, 'loss_2': 0.00762176513671875, 'loss_3': -16.289846420288086, 'loss_4': 1.3857386112213135, 'epoch': 13.26}
{'loss': 0.0147, 'grad_norm': 5.210109710693359, 'learning_rate': 1.675e-05, 'loss_1': 0.009631730616092682, 'loss_2': 0.0050811767578125, 'loss_3': -16.317367553710938, 'loss_4': 1.096125841140747, 'epoch': 13.27}
{'loss': 0.0468, 'grad_norm': 12.476628303527832, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.03945530578494072, 'loss_2': 0.007320404052734375, 'loss_3': -16.38633918762207, 'loss_4': 1.5322177410125732, 'epoch': 13.27}
{'loss': 0.0267, 'grad_norm': 10.414249420166016, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.020564965903759003, 'loss_2': 0.006103515625, 'loss_3': -16.36333465576172, 'loss_4': 1.0089664459228516, 'epoch': 13.28}
{'loss': 0.0679, 'grad_norm': 16.009239196777344, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.06180664151906967, 'loss_2': 0.006114959716796875, 'loss_3': -16.243953704833984, 'loss_4': 1.6801501512527466, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 13:17:28,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:28,890 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:48<49:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:36,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024646025151014328, 'eval_runtime': 3.7798, 'eval_samples_per_second': 270.913, 'eval_steps_per_second': 4.233, 'eval_loss_1': 0.015835266560316086, 'eval_loss_2': 0.008810758590698242, 'eval_loss_3': -18.30004119873047, 'eval_loss_4': 1.3617786169052124, 'epoch': 13.28}
{'loss': 0.0271, 'grad_norm': 8.348448753356934, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.017364270985126495, 'loss_2': 0.009765625, 'loss_3': -16.46564483642578, 'loss_4': 1.3063843250274658, 'epoch': 13.29}
{'loss': 0.0272, 'grad_norm': 6.133055686950684, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.015880808234214783, 'loss_2': 0.01129150390625, 'loss_3': -16.485122680664062, 'loss_4': 1.221733570098877, 'epoch': 13.3}
{'loss': 0.0643, 'grad_norm': 20.63062286376953, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.046905338764190674, 'loss_2': 0.0173492431640625, 'loss_3': -16.207210540771484, 'loss_4': 1.1146659851074219, 'epoch': 13.3}
{'loss': 0.0291, 'grad_norm': 5.614331245422363, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.016611769795417786, 'loss_2': 0.01251220703125, 'loss_3': -16.346282958984375, 'loss_4': 1.0338078737258911, 'epoch': 13.31}
{'loss': 0.0311, 'grad_norm': 10.278562545776367, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.026743780821561813, 'loss_2': 0.00440216064453125, 'loss_3': -16.321378707885742, 'loss_4': 1.41267728805542, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 13:17:36,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:36,215 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:55<49:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:43,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02578062377870083, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.444, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01782084070146084, 'eval_loss_2': 0.00795978307723999, 'eval_loss_3': -18.33360481262207, 'eval_loss_4': 1.0169613361358643, 'epoch': 13.31}
{'loss': 0.0285, 'grad_norm': 11.558914184570312, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.021521417424082756, 'loss_2': 0.0069732666015625, 'loss_3': -16.461322784423828, 'loss_4': 0.865179717540741, 'epoch': 13.32}
{'loss': 0.0172, 'grad_norm': 6.715255260467529, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.013045763596892357, 'loss_2': 0.00420379638671875, 'loss_3': -16.24946403503418, 'loss_4': 0.7842142581939697, 'epoch': 13.33}
{'loss': 0.0275, 'grad_norm': 12.058664321899414, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.023366501554846764, 'loss_2': 0.004093170166015625, 'loss_3': -16.28365707397461, 'loss_4': 0.9565550684928894, 'epoch': 13.33}
{'loss': 0.0265, 'grad_norm': 8.202094078063965, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.014887833967804909, 'loss_2': 0.011566162109375, 'loss_3': -16.427593231201172, 'loss_4': 1.0698939561843872, 'epoch': 13.34}
{'loss': 0.0141, 'grad_norm': 6.673699855804443, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.011567039415240288, 'loss_2': 0.0025787353515625, 'loss_3': -16.386138916015625, 'loss_4': 0.677365243434906, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 13:17:43,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:43,546 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [57:02<49:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:50,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01852678693830967, 'eval_runtime': 3.7836, 'eval_samples_per_second': 270.644, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01623358763754368, 'eval_loss_2': 0.002293199300765991, 'eval_loss_3': -18.317026138305664, 'eval_loss_4': 0.8762516975402832, 'epoch': 13.34}
{'loss': 0.0153, 'grad_norm': 5.385808944702148, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.012856739573180676, 'loss_2': 0.002490997314453125, 'loss_3': -16.359670639038086, 'loss_4': 0.3787558972835541, 'epoch': 13.35}
{'loss': 0.0204, 'grad_norm': 7.399441719055176, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.018243443220853806, 'loss_2': 0.00211334228515625, 'loss_3': -16.427310943603516, 'loss_4': 0.6558811068534851, 'epoch': 13.35}
{'loss': 0.0165, 'grad_norm': 7.100302219390869, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.0123672503978014, 'loss_2': 0.0041351318359375, 'loss_3': -16.422256469726562, 'loss_4': 1.1916850805282593, 'epoch': 13.36}
{'loss': 0.0144, 'grad_norm': 5.2633957862854, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.010273929685354233, 'loss_2': 0.004119873046875, 'loss_3': -16.31669044494629, 'loss_4': 0.4607498049736023, 'epoch': 13.37}
{'loss': 0.0188, 'grad_norm': 7.7233805656433105, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.0180721003562212, 'loss_2': 0.0007572174072265625, 'loss_3': -16.560537338256836, 'loss_4': 0.521619439125061, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 13:17:50,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:50,872 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [57:10<49:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:58,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01809009350836277, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.847, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01423568744212389, 'eval_loss_2': 0.003854408860206604, 'eval_loss_3': -18.300430297851562, 'eval_loss_4': 0.7251242995262146, 'epoch': 13.37}
{'loss': 0.0093, 'grad_norm': 5.413987636566162, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.007250756956636906, 'loss_2': 0.002048492431640625, 'loss_3': -16.341833114624023, 'loss_4': 0.6022371053695679, 'epoch': 13.38}
{'loss': 0.0347, 'grad_norm': 10.125288963317871, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.027826441451907158, 'loss_2': 0.00682830810546875, 'loss_3': -16.231426239013672, 'loss_4': 1.0823781490325928, 'epoch': 13.38}
{'loss': 0.0153, 'grad_norm': 5.531974792480469, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.010249343700706959, 'loss_2': 0.005100250244140625, 'loss_3': -16.333206176757812, 'loss_4': 0.94962477684021, 'epoch': 13.39}
{'loss': 0.019, 'grad_norm': 6.010031223297119, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.014885377138853073, 'loss_2': 0.0040740966796875, 'loss_3': -16.293777465820312, 'loss_4': 0.6493935585021973, 'epoch': 13.4}
{'loss': 0.0081, 'grad_norm': 4.603850364685059, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.006244214717298746, 'loss_2': 0.0018377304077148438, 'loss_3': -16.42251968383789, 'loss_4': 0.39106953144073486, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 13:17:58,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:58,209 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:17<49:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:05,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015752490609884262, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.526, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.013490485027432442, 'eval_loss_2': 0.002262003719806671, 'eval_loss_3': -18.281431198120117, 'eval_loss_4': 0.5455642938613892, 'epoch': 13.4}
{'loss': 0.0122, 'grad_norm': 6.006862640380859, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.010764328762888908, 'loss_2': 0.0014667510986328125, 'loss_3': -16.342758178710938, 'loss_4': 1.0611019134521484, 'epoch': 13.41}
{'loss': 0.0177, 'grad_norm': 4.8231401443481445, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.00503210723400116, 'loss_2': 0.01263427734375, 'loss_3': -16.22947120666504, 'loss_4': 0.6077179312705994, 'epoch': 13.41}
{'loss': 0.0195, 'grad_norm': 6.560282230377197, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.014143044129014015, 'loss_2': 0.0053863525390625, 'loss_3': -16.414836883544922, 'loss_4': 0.4857862591743469, 'epoch': 13.42}
{'loss': 0.0187, 'grad_norm': 9.348660469055176, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.015489009208977222, 'loss_2': 0.0032558441162109375, 'loss_3': -16.299348831176758, 'loss_4': 0.2755705714225769, 'epoch': 13.42}
{'loss': 0.0182, 'grad_norm': 7.661009788513184, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.014039570465683937, 'loss_2': 0.00418853759765625, 'loss_3': -16.210289001464844, 'loss_4': 0.9138224124908447, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 13:18:05,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:05,536 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:24<49:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:12,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01859801635146141, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.441, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014296825043857098, 'eval_loss_2': 0.004301190376281738, 'eval_loss_3': -18.259906768798828, 'eval_loss_4': 0.280676931142807, 'epoch': 13.43}
{'loss': 0.0136, 'grad_norm': 5.909912109375, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.010637559927999973, 'loss_2': 0.003002166748046875, 'loss_3': -16.29572868347168, 'loss_4': 0.5593442320823669, 'epoch': 13.44}
{'loss': 0.0098, 'grad_norm': 5.382635116577148, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.008970513008534908, 'loss_2': 0.000835418701171875, 'loss_3': -16.423097610473633, 'loss_4': 0.6015284061431885, 'epoch': 13.44}
{'loss': 0.0131, 'grad_norm': 5.455201148986816, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.010229936800897121, 'loss_2': 0.002899169921875, 'loss_3': -16.440786361694336, 'loss_4': 0.08026565611362457, 'epoch': 13.45}
{'loss': 0.0874, 'grad_norm': 22.582422256469727, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.08599573373794556, 'loss_2': 0.0013866424560546875, 'loss_3': -16.14185333251953, 'loss_4': 0.261689156293869, 'epoch': 13.45}
{'loss': 0.0091, 'grad_norm': 4.82729959487915, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.0067497785203158855, 'loss_2': 0.0023899078369140625, 'loss_3': -16.249961853027344, 'loss_4': -0.5162507891654968, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 13:18:12,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:12,859 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:32<48:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:18:20,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017993826419115067, 'eval_runtime': 3.7842, 'eval_samples_per_second': 270.596, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.015289263799786568, 'eval_loss_2': 0.0027045607566833496, 'eval_loss_3': -18.219120025634766, 'eval_loss_4': -0.19256597757339478, 'epoch': 13.46}
{'loss': 0.0129, 'grad_norm': 6.207372188568115, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.00976290088146925, 'loss_2': 0.003177642822265625, 'loss_3': -16.380992889404297, 'loss_4': 0.27384430170059204, 'epoch': 13.47}
{'loss': 0.0146, 'grad_norm': 5.931183815002441, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.012075009755790234, 'loss_2': 0.0025386810302734375, 'loss_3': -16.38150405883789, 'loss_4': 0.2394213080406189, 'epoch': 13.47}
{'loss': 0.01, 'grad_norm': 4.8834733963012695, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.006905968300998211, 'loss_2': 0.003086090087890625, 'loss_3': -16.381929397583008, 'loss_4': -0.6023014783859253, 'epoch': 13.48}
{'loss': 0.0241, 'grad_norm': 10.696410179138184, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.018873149529099464, 'loss_2': 0.0052490234375, 'loss_3': -16.534866333007812, 'loss_4': -0.9203760623931885, 'epoch': 13.48}
{'loss': 0.0219, 'grad_norm': 9.770615577697754, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.019936492666602135, 'loss_2': 0.001987457275390625, 'loss_3': -16.39598274230957, 'loss_4': -0.4633964002132416, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 13:18:20,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:20,180 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:39<48:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:18:27,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022403009235858917, 'eval_runtime': 3.785, 'eval_samples_per_second': 270.54, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01984003745019436, 'eval_loss_2': 0.002562969923019409, 'eval_loss_3': -18.18462371826172, 'eval_loss_4': -0.5023446679115295, 'epoch': 13.49}
{'loss': 0.0147, 'grad_norm': 8.371718406677246, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.012525306083261967, 'loss_2': 0.0022068023681640625, 'loss_3': -16.195392608642578, 'loss_4': -0.5773807764053345, 'epoch': 13.49}
{'loss': 0.0171, 'grad_norm': 5.980856418609619, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.013650232926011086, 'loss_2': 0.00348663330078125, 'loss_3': -16.411558151245117, 'loss_4': -0.7171075344085693, 'epoch': 13.5}
{'loss': 0.0101, 'grad_norm': 6.473583698272705, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.00904098805040121, 'loss_2': 0.0010404586791992188, 'loss_3': -16.33256721496582, 'loss_4': -0.9191261529922485, 'epoch': 13.51}
{'loss': 0.0136, 'grad_norm': 5.17822265625, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.011254347860813141, 'loss_2': 0.0023193359375, 'loss_3': -16.372325897216797, 'loss_4': -0.592397928237915, 'epoch': 13.51}
{'loss': 0.0138, 'grad_norm': 5.23470401763916, 'learning_rate': 1.65e-05, 'loss_1': 0.009025657549500465, 'loss_2': 0.004787445068359375, 'loss_3': -16.261493682861328, 'loss_4': -0.6803733110427856, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 13:18:27,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:27,496 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:46<48:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:34,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027053505182266235, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.024180863052606583, 'eval_loss_2': 0.002872645854949951, 'eval_loss_3': -18.141582489013672, 'eval_loss_4': -0.7269291877746582, 'epoch': 13.52}
{'loss': 0.0185, 'grad_norm': 8.015932083129883, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.015572721138596535, 'loss_2': 0.0029315948486328125, 'loss_3': -16.168737411499023, 'loss_4': -0.5813537836074829, 'epoch': 13.52}
{'loss': 0.0651, 'grad_norm': 16.69432258605957, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.06400899589061737, 'loss_2': 0.001125335693359375, 'loss_3': -16.060462951660156, 'loss_4': -0.5636287927627563, 'epoch': 13.53}
{'loss': 0.0111, 'grad_norm': 8.461584091186523, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.010675405152142048, 'loss_2': 0.0003972053527832031, 'loss_3': -16.472631454467773, 'loss_4': -1.0592377185821533, 'epoch': 13.53}
{'loss': 0.0229, 'grad_norm': 6.457930564880371, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.019129259511828423, 'loss_2': 0.0037403106689453125, 'loss_3': -16.307828903198242, 'loss_4': -1.0750648975372314, 'epoch': 13.54}
{'loss': 0.0079, 'grad_norm': 4.74814510345459, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.007041859906166792, 'loss_2': 0.0008411407470703125, 'loss_3': -16.43639373779297, 'loss_4': -0.6107672452926636, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 13:18:34,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:34,833 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:54<48:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:42,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03550615906715393, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.212, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.029030829668045044, 'eval_loss_2': 0.006475329399108887, 'eval_loss_3': -18.081453323364258, 'eval_loss_4': -0.8415883779525757, 'epoch': 13.55}
{'loss': 0.0207, 'grad_norm': 6.938167095184326, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.012277239002287388, 'loss_2': 0.00844573974609375, 'loss_3': -16.265850067138672, 'loss_4': -0.6716628074645996, 'epoch': 13.55}
{'loss': 0.0206, 'grad_norm': 5.854729652404785, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.009963720105588436, 'loss_2': 0.01064300537109375, 'loss_3': -16.241161346435547, 'loss_4': -1.0351052284240723, 'epoch': 13.56}
{'loss': 0.0125, 'grad_norm': 6.22106409072876, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.00948878563940525, 'loss_2': 0.0030155181884765625, 'loss_3': -16.473331451416016, 'loss_4': -1.1955931186676025, 'epoch': 13.56}
{'loss': 0.0269, 'grad_norm': 8.530354499816895, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.018262188881635666, 'loss_2': 0.0085906982421875, 'loss_3': -16.437868118286133, 'loss_4': -0.4789641499519348, 'epoch': 13.57}
{'loss': 0.0188, 'grad_norm': 6.398508548736572, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.010980352759361267, 'loss_2': 0.007843017578125, 'loss_3': -16.32453155517578, 'loss_4': -0.9012166857719421, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 13:18:42,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:42,160 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [58:01<48:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:49,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04553593695163727, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.413, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.040254488587379456, 'eval_loss_2': 0.0052814483642578125, 'eval_loss_3': -18.058351516723633, 'eval_loss_4': -0.749672532081604, 'epoch': 13.58}
{'loss': 0.0214, 'grad_norm': 7.920603275299072, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.013437422923743725, 'loss_2': 0.0080108642578125, 'loss_3': -16.211942672729492, 'loss_4': -0.8984655141830444, 'epoch': 13.58}
{'loss': 0.0154, 'grad_norm': 5.177292346954346, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.00918416865170002, 'loss_2': 0.00617218017578125, 'loss_3': -16.130577087402344, 'loss_4': -1.0424524545669556, 'epoch': 13.59}
{'loss': 0.0185, 'grad_norm': 5.690890789031982, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.0115513252094388, 'loss_2': 0.0069580078125, 'loss_3': -16.334802627563477, 'loss_4': -1.2904088497161865, 'epoch': 13.59}
{'loss': 0.0124, 'grad_norm': 5.4584503173828125, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.01151655800640583, 'loss_2': 0.00090789794921875, 'loss_3': -16.21876335144043, 'loss_4': -0.8040923476219177, 'epoch': 13.6}
{'loss': 0.0208, 'grad_norm': 7.998109340667725, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.012868165969848633, 'loss_2': 0.0079345703125, 'loss_3': -16.515472412109375, 'loss_4': -0.6701897382736206, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 13:18:49,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:49,484 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [58:08<48:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:18:56,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05739201605319977, 'eval_runtime': 3.7828, 'eval_samples_per_second': 270.702, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.05224462226033211, 'eval_loss_2': 0.005147397518157959, 'eval_loss_3': -18.014135360717773, 'eval_loss_4': -0.7738862037658691, 'epoch': 13.6}
{'loss': 0.0157, 'grad_norm': 5.529139995574951, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.00932280346751213, 'loss_2': 0.006366729736328125, 'loss_3': -15.860654830932617, 'loss_4': -0.8354653120040894, 'epoch': 13.61}
{'loss': 0.017, 'grad_norm': 6.451254844665527, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.012752453796565533, 'loss_2': 0.00424957275390625, 'loss_3': -16.280078887939453, 'loss_4': -0.639272153377533, 'epoch': 13.62}
{'loss': 0.0182, 'grad_norm': 6.071550369262695, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.01154373213648796, 'loss_2': 0.006626129150390625, 'loss_3': -16.03985595703125, 'loss_4': -0.6692867875099182, 'epoch': 13.62}
{'loss': 0.0189, 'grad_norm': 5.850711822509766, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.012231932021677494, 'loss_2': 0.00670623779296875, 'loss_3': -16.337854385375977, 'loss_4': -1.1068620681762695, 'epoch': 13.63}
{'loss': 0.0273, 'grad_norm': 7.702757835388184, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.0206814706325531, 'loss_2': 0.006656646728515625, 'loss_3': -16.076671600341797, 'loss_4': -0.78098464012146, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 13:18:56,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:56,797 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:16<48:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:04,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06708991527557373, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.414, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0621415413916111, 'eval_loss_2': 0.00494837760925293, 'eval_loss_3': -18.00135612487793, 'eval_loss_4': -0.5441406965255737, 'epoch': 13.63}
{'loss': 0.0178, 'grad_norm': 6.182046890258789, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.010388053953647614, 'loss_2': 0.00738525390625, 'loss_3': -16.222700119018555, 'loss_4': -0.06567021459341049, 'epoch': 13.64}
{'loss': 0.0184, 'grad_norm': 5.385034084320068, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.013157588429749012, 'loss_2': 0.00528717041015625, 'loss_3': -16.285503387451172, 'loss_4': -0.27886247634887695, 'epoch': 13.65}
{'loss': 0.0306, 'grad_norm': 8.673996925354004, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.024979187175631523, 'loss_2': 0.00565338134765625, 'loss_3': -16.193437576293945, 'loss_4': -0.023285605013370514, 'epoch': 13.65}
{'loss': 0.0103, 'grad_norm': 5.157512664794922, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.008092956617474556, 'loss_2': 0.0022449493408203125, 'loss_3': -16.350584030151367, 'loss_4': -0.17923134565353394, 'epoch': 13.66}
{'loss': 0.0865, 'grad_norm': 16.183734893798828, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.08363528549671173, 'loss_2': 0.002902984619140625, 'loss_3': -16.325031280517578, 'loss_4': -0.2839590907096863, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 13:19:04,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:04,125 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:23<49:10,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:19:11,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07224620878696442, 'eval_runtime': 3.9855, 'eval_samples_per_second': 256.932, 'eval_steps_per_second': 4.015, 'eval_loss_1': 0.06781048327684402, 'eval_loss_2': 0.004435718059539795, 'eval_loss_3': -17.985130310058594, 'eval_loss_4': -0.17630772292613983, 'epoch': 13.66}
{'loss': 0.0066, 'grad_norm': 4.526630878448486, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.005218537990003824, 'loss_2': 0.0013570785522460938, 'loss_3': -16.209373474121094, 'loss_4': -0.2175253927707672, 'epoch': 13.67}
{'loss': 0.0143, 'grad_norm': 6.046121120452881, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.009808105416595936, 'loss_2': 0.004535675048828125, 'loss_3': -16.259796142578125, 'loss_4': -0.25860729813575745, 'epoch': 13.67}
{'loss': 0.0221, 'grad_norm': 6.651580810546875, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.014092584140598774, 'loss_2': 0.00801849365234375, 'loss_3': -16.153745651245117, 'loss_4': -0.09892812371253967, 'epoch': 13.68}
{'loss': 0.0136, 'grad_norm': 7.416504859924316, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.012942859902977943, 'loss_2': 0.0006885528564453125, 'loss_3': -16.219738006591797, 'loss_4': 0.26640549302101135, 'epoch': 13.69}
{'loss': 0.0383, 'grad_norm': 11.002212524414062, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.02815183810889721, 'loss_2': 0.01013946533203125, 'loss_3': -16.39311981201172, 'loss_4': 0.26166054606437683, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 13:19:11,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:11,660 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:31<48:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:19,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0816730484366417, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.07618962228298187, 'eval_loss_2': 0.0054834261536598206, 'eval_loss_3': -17.99391746520996, 'eval_loss_4': 0.24220342934131622, 'epoch': 13.69}
{'loss': 0.0155, 'grad_norm': 8.577513694763184, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.012726396322250366, 'loss_2': 0.002788543701171875, 'loss_3': -16.254619598388672, 'loss_4': 0.308247834444046, 'epoch': 13.7}
{'loss': 0.0168, 'grad_norm': 7.893918991088867, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.013101697899401188, 'loss_2': 0.0036773681640625, 'loss_3': -16.124507904052734, 'loss_4': 0.42366844415664673, 'epoch': 13.7}
{'loss': 0.0092, 'grad_norm': 5.614131450653076, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.008354270830750465, 'loss_2': 0.0008878707885742188, 'loss_3': -16.21345329284668, 'loss_4': -0.016607385128736496, 'epoch': 13.71}
{'loss': 0.0407, 'grad_norm': 15.687675476074219, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.033721648156642914, 'loss_2': 0.00702667236328125, 'loss_3': -16.22032356262207, 'loss_4': 0.6213026642799377, 'epoch': 13.72}
{'loss': 0.0112, 'grad_norm': 6.658261775970459, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.009780650958418846, 'loss_2': 0.0014400482177734375, 'loss_3': -16.53852081298828, 'loss_4': 0.19230890274047852, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 13:19:19,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:19,012 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:38<48:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:26,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03335908055305481, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.198, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.03012239746749401, 'eval_loss_2': 0.0032366812229156494, 'eval_loss_3': -18.086835861206055, 'eval_loss_4': 0.49181199073791504, 'epoch': 13.72}
{'loss': 0.0118, 'grad_norm': 6.744056701660156, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.00909879058599472, 'loss_2': 0.00269317626953125, 'loss_3': -16.176475524902344, 'loss_4': 0.42120978236198425, 'epoch': 13.73}
{'loss': 0.0116, 'grad_norm': 5.3869476318359375, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.006970416754484177, 'loss_2': 0.004638671875, 'loss_3': -16.157718658447266, 'loss_4': 0.927237868309021, 'epoch': 13.73}
{'loss': 0.017, 'grad_norm': 8.935990333557129, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.016839303076267242, 'loss_2': 0.0002002716064453125, 'loss_3': -16.14815902709961, 'loss_4': 0.15625940263271332, 'epoch': 13.74}
{'loss': 0.0155, 'grad_norm': 5.31046199798584, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.011608629487454891, 'loss_2': 0.00389862060546875, 'loss_3': -16.422285079956055, 'loss_4': 0.8062032461166382, 'epoch': 13.74}
{'loss': 0.0141, 'grad_norm': 4.809566020965576, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.0057701244950294495, 'loss_2': 0.0083770751953125, 'loss_3': -16.294273376464844, 'loss_4': 0.75569748878479, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 13:19:26,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:26,389 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:45<48:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:33,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03134164214134216, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.025567207485437393, 'eval_loss_2': 0.005774438381195068, 'eval_loss_3': -18.14654541015625, 'eval_loss_4': 0.8449715375900269, 'epoch': 13.75}
{'loss': 0.0195, 'grad_norm': 5.209761142730713, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.008716649375855923, 'loss_2': 0.01080322265625, 'loss_3': -16.296119689941406, 'loss_4': 0.9340822696685791, 'epoch': 13.76}
{'loss': 0.0231, 'grad_norm': 8.196282386779785, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.014495495706796646, 'loss_2': 0.0086212158203125, 'loss_3': -16.177936553955078, 'loss_4': 0.693017840385437, 'epoch': 13.76}
{'loss': 0.0115, 'grad_norm': 4.970283031463623, 'learning_rate': 1.625e-05, 'loss_1': 0.007601616904139519, 'loss_2': 0.00394439697265625, 'loss_3': -16.459400177001953, 'loss_4': 0.8031956553459167, 'epoch': 13.77}
{'loss': 0.0823, 'grad_norm': 16.76942253112793, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.07850976288318634, 'loss_2': 0.003810882568359375, 'loss_3': -16.365543365478516, 'loss_4': 1.29447340965271, 'epoch': 13.77}
{'loss': 0.0203, 'grad_norm': 10.768415451049805, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.015862636268138885, 'loss_2': 0.00441741943359375, 'loss_3': -16.470470428466797, 'loss_4': 1.1035246849060059, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 13:19:33,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:33,758 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:53<48:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:41,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02496650628745556, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.478, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.02065834403038025, 'eval_loss_2': 0.004308164119720459, 'eval_loss_3': -18.162944793701172, 'eval_loss_4': 1.0368678569793701, 'epoch': 13.78}
{'loss': 0.0198, 'grad_norm': 6.884289741516113, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.010899997316300869, 'loss_2': 0.0089263916015625, 'loss_3': -16.390316009521484, 'loss_4': 1.4183838367462158, 'epoch': 13.78}
{'loss': 0.0204, 'grad_norm': 6.377872943878174, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.013407965190708637, 'loss_2': 0.006946563720703125, 'loss_3': -16.371538162231445, 'loss_4': 1.6963539123535156, 'epoch': 13.79}
{'loss': 0.0118, 'grad_norm': 4.817235469818115, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.009111437946557999, 'loss_2': 0.002655029296875, 'loss_3': -16.276290893554688, 'loss_4': 1.089106559753418, 'epoch': 13.8}
{'loss': 0.0154, 'grad_norm': 4.925400257110596, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.006812873296439648, 'loss_2': 0.0085906982421875, 'loss_3': -16.370939254760742, 'loss_4': 1.6305515766143799, 'epoch': 13.8}
{'loss': 0.0116, 'grad_norm': 5.332211017608643, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.007887091487646103, 'loss_2': 0.0036716461181640625, 'loss_3': -16.413143157958984, 'loss_4': 1.0961740016937256, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 13:19:41,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:41,117 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [59:00<48:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:48,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02279122918844223, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.772, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017904825508594513, 'eval_loss_2': 0.004886403679847717, 'eval_loss_3': -18.184860229492188, 'eval_loss_4': 1.2240817546844482, 'epoch': 13.81}
{'loss': 0.0156, 'grad_norm': 8.42015552520752, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.012740083038806915, 'loss_2': 0.002819061279296875, 'loss_3': -16.22161102294922, 'loss_4': 1.2998499870300293, 'epoch': 13.81}
{'loss': 0.0166, 'grad_norm': 6.54686164855957, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.01631530374288559, 'loss_2': 0.00032782554626464844, 'loss_3': -16.41527557373047, 'loss_4': 1.4296919107437134, 'epoch': 13.82}
{'loss': 0.0234, 'grad_norm': 6.298227787017822, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.015293206088244915, 'loss_2': 0.00807952880859375, 'loss_3': -16.19567108154297, 'loss_4': 1.588390588760376, 'epoch': 13.83}
{'loss': 0.0095, 'grad_norm': 5.016911506652832, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.0072251781821250916, 'loss_2': 0.002254486083984375, 'loss_3': -16.209522247314453, 'loss_4': 1.4611293077468872, 'epoch': 13.83}
{'loss': 0.0208, 'grad_norm': 7.318943977355957, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.0188315249979496, 'loss_2': 0.0019474029541015625, 'loss_3': -16.159502029418945, 'loss_4': 1.5547728538513184, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 13:19:48,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:48,465 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [59:07<48:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:55,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027501525357365608, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.018516840413212776, 'eval_loss_2': 0.008984684944152832, 'eval_loss_3': -18.199003219604492, 'eval_loss_4': 1.3482298851013184, 'epoch': 13.84}
{'loss': 0.0223, 'grad_norm': 8.500252723693848, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.017487436532974243, 'loss_2': 0.00482940673828125, 'loss_3': -16.237592697143555, 'loss_4': 1.6298129558563232, 'epoch': 13.84}
{'loss': 0.016, 'grad_norm': 4.903212070465088, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.00931987538933754, 'loss_2': 0.0066680908203125, 'loss_3': -16.315185546875, 'loss_4': 1.3429334163665771, 'epoch': 13.85}
{'loss': 0.0301, 'grad_norm': 10.492622375488281, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.026587162166833878, 'loss_2': 0.003513336181640625, 'loss_3': -16.13936424255371, 'loss_4': 1.4217658042907715, 'epoch': 13.85}
{'loss': 0.0132, 'grad_norm': 6.746785640716553, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.010714483447372913, 'loss_2': 0.0024547576904296875, 'loss_3': -16.212535858154297, 'loss_4': 1.5734293460845947, 'epoch': 13.86}
{'loss': 0.0104, 'grad_norm': 5.759039878845215, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.009605059400200844, 'loss_2': 0.0008363723754882812, 'loss_3': -16.415861129760742, 'loss_4': 1.6304492950439453, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 13:19:55,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:55,813 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:15<47:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:03,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026293674483895302, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.019217591732740402, 'eval_loss_2': 0.007076084613800049, 'eval_loss_3': -18.218788146972656, 'eval_loss_4': 1.386871337890625, 'epoch': 13.87}
{'loss': 0.0263, 'grad_norm': 6.417684078216553, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.018559591844677925, 'loss_2': 0.0077667236328125, 'loss_3': -16.404293060302734, 'loss_4': 1.4038372039794922, 'epoch': 13.87}
{'loss': 0.0383, 'grad_norm': 15.924078941345215, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.028278451412916183, 'loss_2': 0.0099945068359375, 'loss_3': -16.128219604492188, 'loss_4': 1.497220516204834, 'epoch': 13.88}
{'loss': 0.0166, 'grad_norm': 7.620656490325928, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.014802907593548298, 'loss_2': 0.00176239013671875, 'loss_3': -16.264022827148438, 'loss_4': 1.2231717109680176, 'epoch': 13.88}
{'loss': 0.0174, 'grad_norm': 6.6191792488098145, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.015602326951920986, 'loss_2': 0.0018243789672851562, 'loss_3': -16.424339294433594, 'loss_4': 1.7862770557403564, 'epoch': 13.89}
{'loss': 0.0144, 'grad_norm': 4.899296283721924, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.006420199293643236, 'loss_2': 0.007965087890625, 'loss_3': -16.369857788085938, 'loss_4': 1.4098113775253296, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 13:20:03,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:03,159 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:22<47:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:10,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022291868925094604, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.932, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01921285130083561, 'eval_loss_2': 0.0030790194869041443, 'eval_loss_3': -18.241682052612305, 'eval_loss_4': 1.3377082347869873, 'epoch': 13.9}
{'loss': 0.0117, 'grad_norm': 5.876023769378662, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.011650333181023598, 'loss_2': 1.2636184692382812e-05, 'loss_3': -16.127490997314453, 'loss_4': 1.5143542289733887, 'epoch': 13.9}
{'loss': 0.0148, 'grad_norm': 7.5434184074401855, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.012218291871249676, 'loss_2': 0.002532958984375, 'loss_3': -16.487075805664062, 'loss_4': 1.3427484035491943, 'epoch': 13.91}
{'loss': 0.016, 'grad_norm': 5.813454627990723, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.011307846754789352, 'loss_2': 0.00466156005859375, 'loss_3': -16.1792049407959, 'loss_4': 0.9894379377365112, 'epoch': 13.91}
{'loss': 0.026, 'grad_norm': 5.453474044799805, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.01768087036907673, 'loss_2': 0.00827789306640625, 'loss_3': -16.128406524658203, 'loss_4': 1.2113507986068726, 'epoch': 13.92}
{'loss': 0.0502, 'grad_norm': 12.408632278442383, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.04571829363703728, 'loss_2': 0.0044708251953125, 'loss_3': -16.31475830078125, 'loss_4': 0.693234920501709, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 13:20:10,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:10,496 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:29<47:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:17,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02427002415060997, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.061, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.019046513363718987, 'eval_loss_2': 0.005223512649536133, 'eval_loss_3': -18.268024444580078, 'eval_loss_4': 1.1611924171447754, 'epoch': 13.92}
{'loss': 0.0128, 'grad_norm': 4.853048324584961, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.009331046603620052, 'loss_2': 0.0035037994384765625, 'loss_3': -16.167808532714844, 'loss_4': 0.7417836785316467, 'epoch': 13.93}
{'loss': 0.012, 'grad_norm': 5.787153244018555, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.011229360476136208, 'loss_2': 0.0007495880126953125, 'loss_3': -16.30473518371582, 'loss_4': 1.086698055267334, 'epoch': 13.94}
{'loss': 0.0154, 'grad_norm': 8.882702827453613, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.0150767145678401, 'loss_2': 0.00029850006103515625, 'loss_3': -16.280593872070312, 'loss_4': 1.1006054878234863, 'epoch': 13.94}
{'loss': 0.0151, 'grad_norm': 4.784532070159912, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.0063874064944684505, 'loss_2': 0.00872802734375, 'loss_3': -16.392202377319336, 'loss_4': 0.7584408521652222, 'epoch': 13.95}
{'loss': 0.0134, 'grad_norm': 5.321982383728027, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.009098721668124199, 'loss_2': 0.004299163818359375, 'loss_3': -16.399768829345703, 'loss_4': 1.0834941864013672, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 13:20:17,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:17,838 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:37<47:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:25,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02380666509270668, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.076, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.020499560981988907, 'eval_loss_2': 0.0033071041107177734, 'eval_loss_3': -18.25725555419922, 'eval_loss_4': 1.0619421005249023, 'epoch': 13.95}
{'loss': 0.011, 'grad_norm': 4.9517292976379395, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.010501003824174404, 'loss_2': 0.00054168701171875, 'loss_3': -16.17074203491211, 'loss_4': 1.410536766052246, 'epoch': 13.96}
{'loss': 0.0154, 'grad_norm': 5.883082866668701, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.008853384293615818, 'loss_2': 0.0065460205078125, 'loss_3': -16.406753540039062, 'loss_4': 1.40679132938385, 'epoch': 13.97}
{'loss': 0.014, 'grad_norm': 5.465663433074951, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.011256801895797253, 'loss_2': 0.002750396728515625, 'loss_3': -16.2674560546875, 'loss_4': 0.891626238822937, 'epoch': 13.97}
{'loss': 0.009, 'grad_norm': 4.799962520599365, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.007544153835624456, 'loss_2': 0.0014505386352539062, 'loss_3': -16.294330596923828, 'loss_4': 0.8820198774337769, 'epoch': 13.98}
{'loss': 0.0142, 'grad_norm': 6.970183849334717, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.012452686205506325, 'loss_2': 0.001758575439453125, 'loss_3': -16.359439849853516, 'loss_4': 0.6362616419792175, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 13:20:25,181 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:25,181 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:44<45:37,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 13:20:32,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02769014984369278, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.183, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.02187756448984146, 'eval_loss_2': 0.005812585353851318, 'eval_loss_3': -18.232921600341797, 'eval_loss_4': 1.1102228164672852, 'epoch': 13.98}
{'loss': 0.0241, 'grad_norm': 8.787038803100586, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.021586859598755836, 'loss_2': 0.002532958984375, 'loss_3': -16.127941131591797, 'loss_4': 1.2334610223770142, 'epoch': 13.99}
{'loss': 0.0175, 'grad_norm': 8.775602340698242, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.014892355538904667, 'loss_2': 0.0025634765625, 'loss_3': -16.370153427124023, 'loss_4': 0.8149983882904053, 'epoch': 13.99}
{'loss': 0.0173, 'grad_norm': 6.289261817932129, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.003975331783294678, 'loss_2': 0.0133209228515625, 'loss_3': -16.15331268310547, 'loss_4': 1.75387704372406, 'epoch': 14.0}
{'loss': 0.0354, 'grad_norm': 17.59870147705078, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.027660440653562546, 'loss_2': 0.007709503173828125, 'loss_3': -16.340824127197266, 'loss_4': 1.179648518562317, 'epoch': 14.01}
{'loss': 0.0189, 'grad_norm': 5.120229721069336, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.011097097769379616, 'loss_2': 0.00780487060546875, 'loss_3': -16.47603988647461, 'loss_4': 1.0808638334274292, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 13:20:32,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:32,209 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:51<47:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:20:39,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027176763862371445, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.827, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.02036025933921337, 'eval_loss_2': 0.006816506385803223, 'eval_loss_3': -18.206878662109375, 'eval_loss_4': 0.9705798625946045, 'epoch': 14.01}
{'loss': 0.0295, 'grad_norm': 5.630132675170898, 'learning_rate': 1.6e-05, 'loss_1': 0.012525920756161213, 'loss_2': 0.0169525146484375, 'loss_3': -16.24506950378418, 'loss_4': 0.7740868330001831, 'epoch': 14.02}
{'loss': 0.0278, 'grad_norm': 22.057889938354492, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.0235942043364048, 'loss_2': 0.0042266845703125, 'loss_3': -16.42824363708496, 'loss_4': 1.0996590852737427, 'epoch': 14.02}
{'loss': 0.0092, 'grad_norm': 5.076574802398682, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.0070799863897264, 'loss_2': 0.0020751953125, 'loss_3': -16.264156341552734, 'loss_4': 1.0911439657211304, 'epoch': 14.03}
{'loss': 0.0151, 'grad_norm': 7.008815288543701, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.012401075102388859, 'loss_2': 0.0026760101318359375, 'loss_3': -16.2148380279541, 'loss_4': 1.0372527837753296, 'epoch': 14.03}
{'loss': 0.0156, 'grad_norm': 10.768528938293457, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.01505463570356369, 'loss_2': 0.00058746337890625, 'loss_3': -16.219621658325195, 'loss_4': 1.1496825218200684, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 13:20:39,550 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:39,550 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                     | 2420/5160 [59:58<47:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:46,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017371319234371185, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.209, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013728072866797447, 'eval_loss_2': 0.003643244504928589, 'eval_loss_3': -18.26504898071289, 'eval_loss_4': 0.7226982712745667, 'epoch': 14.04}
{'loss': 0.0412, 'grad_norm': 21.1241512298584, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.03072969987988472, 'loss_2': 0.0104522705078125, 'loss_3': -16.26645851135254, 'loss_4': 0.6370889544487, 'epoch': 14.05}
{'loss': 0.0154, 'grad_norm': 4.843790531158447, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.010469186119735241, 'loss_2': 0.00490570068359375, 'loss_3': -16.3323974609375, 'loss_4': 0.9627981781959534, 'epoch': 14.05}
{'loss': 0.0218, 'grad_norm': 5.878091335296631, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.01223678421229124, 'loss_2': 0.009521484375, 'loss_3': -16.21600341796875, 'loss_4': 0.7964121103286743, 'epoch': 14.06}
{'loss': 0.0261, 'grad_norm': 5.751920223236084, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.010078689083456993, 'loss_2': 0.0159759521484375, 'loss_3': -16.319129943847656, 'loss_4': 0.4644096791744232, 'epoch': 14.06}
{'loss': 0.0252, 'grad_norm': 6.295042037963867, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.013116534799337387, 'loss_2': 0.01212310791015625, 'loss_3': -15.969998359680176, 'loss_4': 0.5378836393356323, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 13:20:46,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:46,883 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 2425/5160 [1:00:06<47:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:54,229 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01966492459177971, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.757, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01273779384791851, 'eval_loss_2': 0.006927132606506348, 'eval_loss_3': -18.267086029052734, 'eval_loss_4': 0.6026146411895752, 'epoch': 14.07}
{'loss': 0.0104, 'grad_norm': 4.829007148742676, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.006080660503357649, 'loss_2': 0.0043487548828125, 'loss_3': -16.30304718017578, 'loss_4': 0.308138370513916, 'epoch': 14.08}
{'loss': 0.0273, 'grad_norm': 12.6648588180542, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.0245220884680748, 'loss_2': 0.00281524658203125, 'loss_3': -16.27707290649414, 'loss_4': 0.8849425315856934, 'epoch': 14.08}
{'loss': 0.0156, 'grad_norm': 5.964555740356445, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.011488168500363827, 'loss_2': 0.004138946533203125, 'loss_3': -16.397361755371094, 'loss_4': 0.5955257415771484, 'epoch': 14.09}
{'loss': 0.0176, 'grad_norm': 6.6729888916015625, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.016337838023900986, 'loss_2': 0.0012578964233398438, 'loss_3': -16.375877380371094, 'loss_4': 0.7489337921142578, 'epoch': 14.09}
{'loss': 0.0128, 'grad_norm': 6.483641147613525, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.008086769841611385, 'loss_2': 0.004726409912109375, 'loss_3': -16.21567153930664, 'loss_4': 0.9535924792289734, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 13:20:54,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:54,229 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:13<47:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:01,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016299892216920853, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.141, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011889416724443436, 'eval_loss_2': 0.004410475492477417, 'eval_loss_3': -18.26808738708496, 'eval_loss_4': 0.5527441501617432, 'epoch': 14.1}
{'loss': 0.0703, 'grad_norm': 9.978616714477539, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.06623479723930359, 'loss_2': 0.00408935546875, 'loss_3': -16.265193939208984, 'loss_4': 0.38218843936920166, 'epoch': 14.1}
{'loss': 0.0256, 'grad_norm': 13.510405540466309, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.02501867711544037, 'loss_2': 0.0005998611450195312, 'loss_3': -16.36087417602539, 'loss_4': 0.29610514640808105, 'epoch': 14.11}
{'loss': 0.0196, 'grad_norm': 10.036338806152344, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.01801394484937191, 'loss_2': 0.0015411376953125, 'loss_3': -16.472187042236328, 'loss_4': 0.9811601638793945, 'epoch': 14.12}
{'loss': 0.0049, 'grad_norm': 4.228302478790283, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.004280067980289459, 'loss_2': 0.0006313323974609375, 'loss_3': -16.534934997558594, 'loss_4': 0.4266352951526642, 'epoch': 14.12}
{'loss': 0.007, 'grad_norm': 6.808970928192139, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.006674069911241531, 'loss_2': 0.0003161430358886719, 'loss_3': -16.388729095458984, 'loss_4': 0.5498822927474976, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 13:21:01,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:01,574 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:20<47:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:08,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017245564609766006, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.764, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012783054262399673, 'eval_loss_2': 0.004462510347366333, 'eval_loss_3': -18.26342010498047, 'eval_loss_4': 0.4988442063331604, 'epoch': 14.13}
{'loss': 0.0117, 'grad_norm': 5.888396739959717, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.006110206712037325, 'loss_2': 0.005596160888671875, 'loss_3': -16.348480224609375, 'loss_4': 0.6634070873260498, 'epoch': 14.13}
{'loss': 0.0301, 'grad_norm': 9.20061206817627, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.020102284848690033, 'loss_2': 0.00997161865234375, 'loss_3': -16.195022583007812, 'loss_4': 0.6631091833114624, 'epoch': 14.14}
{'loss': 0.0145, 'grad_norm': 5.2701416015625, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.011583560146391392, 'loss_2': 0.002910614013671875, 'loss_3': -16.314485549926758, 'loss_4': 0.6396028995513916, 'epoch': 14.15}
{'loss': 0.0175, 'grad_norm': 6.908417701721191, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.015059882774949074, 'loss_2': 0.0024242401123046875, 'loss_3': -16.259870529174805, 'loss_4': 1.050458312034607, 'epoch': 14.15}
{'loss': 0.0108, 'grad_norm': 5.219516277313232, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.007532475516200066, 'loss_2': 0.0032596588134765625, 'loss_3': -16.209257125854492, 'loss_4': 0.5189570188522339, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 13:21:08,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:08,910 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:28<47:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:16,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017252465710043907, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.031, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.012216559611260891, 'eval_loss_2': 0.005035907030105591, 'eval_loss_3': -18.245121002197266, 'eval_loss_4': 0.40754735469818115, 'epoch': 14.16}
{'loss': 0.0149, 'grad_norm': 5.559408664703369, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.011052301153540611, 'loss_2': 0.003810882568359375, 'loss_3': -16.266170501708984, 'loss_4': 0.5426934957504272, 'epoch': 14.16}
{'loss': 0.01, 'grad_norm': 5.574951648712158, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.007313053123652935, 'loss_2': 0.0026683807373046875, 'loss_3': -16.18600845336914, 'loss_4': 0.5323675870895386, 'epoch': 14.17}
{'loss': 0.0075, 'grad_norm': 4.710940361022949, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.007197473663836718, 'loss_2': 0.0002923011779785156, 'loss_3': -16.299726486206055, 'loss_4': 0.08137398958206177, 'epoch': 14.17}
{'loss': 0.0114, 'grad_norm': 5.601184844970703, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.007135025225579739, 'loss_2': 0.004306793212890625, 'loss_3': -16.195436477661133, 'loss_4': 0.5081164240837097, 'epoch': 14.18}
{'loss': 0.0272, 'grad_norm': 7.46870231628418, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.014269222505390644, 'loss_2': 0.01293182373046875, 'loss_3': -16.280357360839844, 'loss_4': 0.521084189414978, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 13:21:16,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:16,258 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:35<46:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:23,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021555589511990547, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.664, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012935805134475231, 'eval_loss_2': 0.00861978530883789, 'eval_loss_3': -18.2435302734375, 'eval_loss_4': 0.49644991755485535, 'epoch': 14.19}
{'loss': 0.0231, 'grad_norm': 5.869582176208496, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.01393337082117796, 'loss_2': 0.00919342041015625, 'loss_3': -16.369354248046875, 'loss_4': 0.9031574726104736, 'epoch': 14.19}
{'loss': 0.0207, 'grad_norm': 9.475419044494629, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.010024918243288994, 'loss_2': 0.0106658935546875, 'loss_3': -16.224409103393555, 'loss_4': 0.4107924997806549, 'epoch': 14.2}
{'loss': 0.0388, 'grad_norm': 15.975812911987305, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.028798066079616547, 'loss_2': 0.00995635986328125, 'loss_3': -16.318313598632812, 'loss_4': 0.6705502271652222, 'epoch': 14.2}
{'loss': 0.0141, 'grad_norm': 5.7695536613464355, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.009944788180291653, 'loss_2': 0.00417327880859375, 'loss_3': -16.23411750793457, 'loss_4': 0.45700588822364807, 'epoch': 14.21}
{'loss': 0.0393, 'grad_norm': 35.36501693725586, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.036555949598550797, 'loss_2': 0.002773284912109375, 'loss_3': -16.17444610595703, 'loss_4': 0.49375638365745544, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 13:21:23,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:23,604 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:42<46:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:30,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01874217391014099, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.589, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01331433653831482, 'eval_loss_2': 0.005427837371826172, 'eval_loss_3': -18.254714965820312, 'eval_loss_4': 0.5583577156066895, 'epoch': 14.22}
{'loss': 0.0149, 'grad_norm': 5.287395477294922, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.005957505665719509, 'loss_2': 0.00891876220703125, 'loss_3': -16.137523651123047, 'loss_4': 0.6410558223724365, 'epoch': 14.22}
{'loss': 0.0174, 'grad_norm': 4.444125652313232, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.006923382636159658, 'loss_2': 0.01044464111328125, 'loss_3': -16.199357986450195, 'loss_4': 0.34890735149383545, 'epoch': 14.23}
{'loss': 0.0139, 'grad_norm': 5.986403465270996, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.013643347658216953, 'loss_2': 0.0002307891845703125, 'loss_3': -16.178306579589844, 'loss_4': 0.47983676195144653, 'epoch': 14.23}
{'loss': 0.0539, 'grad_norm': 17.898866653442383, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.0494246631860733, 'loss_2': 0.00443267822265625, 'loss_3': -16.330175399780273, 'loss_4': 0.9976133108139038, 'epoch': 14.24}
{'loss': 0.0698, 'grad_norm': 28.263397216796875, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.0654081404209137, 'loss_2': 0.00443267822265625, 'loss_3': -16.348712921142578, 'loss_4': 1.4540116786956787, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 13:21:30,957 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:30,957 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:50<46:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:38,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017598088830709457, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.058, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01466606929898262, 'eval_loss_2': 0.002932019531726837, 'eval_loss_3': -18.235210418701172, 'eval_loss_4': 0.6978691220283508, 'epoch': 14.24}
{'loss': 0.0136, 'grad_norm': 5.021534442901611, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.007465363014489412, 'loss_2': 0.0061492919921875, 'loss_3': -16.274532318115234, 'loss_4': 1.146883249282837, 'epoch': 14.25}
{'loss': 0.0086, 'grad_norm': 4.926747798919678, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.008565586060285568, 'loss_2': 4.6372413635253906e-05, 'loss_3': -16.3100528717041, 'loss_4': 0.741985023021698, 'epoch': 14.26}
{'loss': 0.0188, 'grad_norm': 6.082917213439941, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.009934120811522007, 'loss_2': 0.008880615234375, 'loss_3': -15.994808197021484, 'loss_4': 0.8972612023353577, 'epoch': 14.26}
{'loss': 0.0079, 'grad_norm': 4.768821716308594, 'learning_rate': 1.575e-05, 'loss_1': 0.0067540425807237625, 'loss_2': 0.0011873245239257812, 'loss_3': -16.243972778320312, 'loss_4': 0.7659071087837219, 'epoch': 14.27}
{'loss': 0.0238, 'grad_norm': 6.048369884490967, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.010524160228669643, 'loss_2': 0.0132598876953125, 'loss_3': -16.172250747680664, 'loss_4': 1.110478401184082, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 13:21:38,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:38,301 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:00:57<46:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:45,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01603635400533676, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.014, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013153904117643833, 'eval_loss_2': 0.002882450819015503, 'eval_loss_3': -18.23126220703125, 'eval_loss_4': 0.8287384510040283, 'epoch': 14.27}
{'loss': 0.0107, 'grad_norm': 4.926908493041992, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.005337531212717295, 'loss_2': 0.005340576171875, 'loss_3': -16.214269638061523, 'loss_4': 1.1923762559890747, 'epoch': 14.28}
{'loss': 0.0247, 'grad_norm': 13.774249076843262, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.02304593101143837, 'loss_2': 0.00162506103515625, 'loss_3': -16.373117446899414, 'loss_4': 1.175641655921936, 'epoch': 14.28}
{'loss': 0.0082, 'grad_norm': 5.265753269195557, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.0073611438274383545, 'loss_2': 0.0008573532104492188, 'loss_3': -16.35394287109375, 'loss_4': 1.2487568855285645, 'epoch': 14.29}
{'loss': 0.0165, 'grad_norm': 7.221541881561279, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.014577408321201801, 'loss_2': 0.001964569091796875, 'loss_3': -16.152528762817383, 'loss_4': 0.907612681388855, 'epoch': 14.3}
{'loss': 0.0126, 'grad_norm': 5.925124168395996, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.0123826265335083, 'loss_2': 0.00024044513702392578, 'loss_3': -16.284637451171875, 'loss_4': 1.3958652019500732, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 13:21:45,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:45,647 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:01:04<46:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:52,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015728667378425598, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.03, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01303017232567072, 'eval_loss_2': 0.0026984959840774536, 'eval_loss_3': -18.225435256958008, 'eval_loss_4': 0.926425039768219, 'epoch': 14.3}
{'loss': 0.0271, 'grad_norm': 9.380395889282227, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.02289011888206005, 'loss_2': 0.0042266845703125, 'loss_3': -16.233768463134766, 'loss_4': 0.8722425699234009, 'epoch': 14.31}
{'loss': 0.0105, 'grad_norm': 5.877881050109863, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.009486899711191654, 'loss_2': 0.0010423660278320312, 'loss_3': -16.353561401367188, 'loss_4': 1.7151737213134766, 'epoch': 14.31}
{'loss': 0.0152, 'grad_norm': 5.944668292999268, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.01138914655894041, 'loss_2': 0.00376129150390625, 'loss_3': -16.296537399291992, 'loss_4': 1.426450490951538, 'epoch': 14.32}
{'loss': 0.0155, 'grad_norm': 5.882500171661377, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.012285473756492138, 'loss_2': 0.0032196044921875, 'loss_3': -16.17955780029297, 'loss_4': 1.0739609003067017, 'epoch': 14.33}
{'loss': 0.0337, 'grad_norm': 14.430937767028809, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.03273804485797882, 'loss_2': 0.0009617805480957031, 'loss_3': -16.300125122070312, 'loss_4': 1.353196620941162, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 13:21:52,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:52,987 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:01:12<46:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:00,342 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01617567241191864, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.742, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013141742907464504, 'eval_loss_2': 0.0030339285731315613, 'eval_loss_3': -18.228267669677734, 'eval_loss_4': 0.9246193170547485, 'epoch': 14.33}
{'loss': 0.0121, 'grad_norm': 5.904891490936279, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.009309863671660423, 'loss_2': 0.0028171539306640625, 'loss_3': -16.488155364990234, 'loss_4': 0.8798109292984009, 'epoch': 14.34}
{'loss': 0.0121, 'grad_norm': 5.665125370025635, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.010093026794493198, 'loss_2': 0.002056121826171875, 'loss_3': -16.378143310546875, 'loss_4': 1.372938871383667, 'epoch': 14.34}
{'loss': 0.0145, 'grad_norm': 5.336826801300049, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.010190993547439575, 'loss_2': 0.0042877197265625, 'loss_3': -16.388202667236328, 'loss_4': 0.9564299583435059, 'epoch': 14.35}
{'loss': 0.0233, 'grad_norm': 5.982813835144043, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.011057545430958271, 'loss_2': 0.01226806640625, 'loss_3': -16.191675186157227, 'loss_4': 0.9725883603096008, 'epoch': 14.35}
{'loss': 0.0192, 'grad_norm': 7.945397853851318, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.011756932362914085, 'loss_2': 0.0074920654296875, 'loss_3': -16.23972511291504, 'loss_4': 0.6316167116165161, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 13:22:00,342 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:00,342 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:19<46:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:07,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02257716655731201, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.699, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013430239632725716, 'eval_loss_2': 0.009146928787231445, 'eval_loss_3': -18.239482879638672, 'eval_loss_4': 0.8885070085525513, 'epoch': 14.36}
{'loss': 0.017, 'grad_norm': 5.655849456787109, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.010207525454461575, 'loss_2': 0.0067596435546875, 'loss_3': -16.277673721313477, 'loss_4': 0.7348030209541321, 'epoch': 14.37}
{'loss': 0.0209, 'grad_norm': 5.79408073425293, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.009963125921785831, 'loss_2': 0.010955810546875, 'loss_3': -16.275596618652344, 'loss_4': 1.3668259382247925, 'epoch': 14.37}
{'loss': 0.034, 'grad_norm': 20.73769187927246, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.026533599942922592, 'loss_2': 0.0074310302734375, 'loss_3': -16.312217712402344, 'loss_4': 0.9687552452087402, 'epoch': 14.38}
{'loss': 0.0133, 'grad_norm': 4.537176609039307, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.006060710176825523, 'loss_2': 0.007213592529296875, 'loss_3': -16.26934242248535, 'loss_4': 1.199739694595337, 'epoch': 14.38}
{'loss': 0.0181, 'grad_norm': 8.336243629455566, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.010334929451346397, 'loss_2': 0.0078125, 'loss_3': -16.38034439086914, 'loss_4': 0.6180765628814697, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 13:22:07,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:07,688 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:27<46:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:15,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017926722764968872, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.947, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012948178686201572, 'eval_loss_2': 0.004978545010089874, 'eval_loss_3': -18.257476806640625, 'eval_loss_4': 0.8132554888725281, 'epoch': 14.39}
{'loss': 0.0215, 'grad_norm': 10.241276741027832, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.018960682675242424, 'loss_2': 0.0025177001953125, 'loss_3': -16.282751083374023, 'loss_4': 1.246126413345337, 'epoch': 14.4}
{'loss': 0.0147, 'grad_norm': 5.30274772644043, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.009131054393947124, 'loss_2': 0.005611419677734375, 'loss_3': -16.30266571044922, 'loss_4': 0.7613123655319214, 'epoch': 14.4}
{'loss': 0.0159, 'grad_norm': 6.250162601470947, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.014053727500140667, 'loss_2': 0.001804351806640625, 'loss_3': -16.47740364074707, 'loss_4': 0.9603209495544434, 'epoch': 14.41}
{'loss': 0.0173, 'grad_norm': 10.422780990600586, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.01285705715417862, 'loss_2': 0.00446319580078125, 'loss_3': -16.309120178222656, 'loss_4': 1.264370322227478, 'epoch': 14.41}
{'loss': 0.0131, 'grad_norm': 4.660956859588623, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.007705335039645433, 'loss_2': 0.005352020263671875, 'loss_3': -16.19504165649414, 'loss_4': 0.6145647764205933, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 13:22:15,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:15,031 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:34<46:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:22,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01846269890666008, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.01, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.015612718649208546, 'eval_loss_2': 0.002849981188774109, 'eval_loss_3': -18.243741989135742, 'eval_loss_4': 0.6643351316452026, 'epoch': 14.42}
{'loss': 0.0377, 'grad_norm': 13.874488830566406, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.035716462880373, 'loss_2': 0.002010345458984375, 'loss_3': -16.406198501586914, 'loss_4': 0.9335759878158569, 'epoch': 14.42}
{'loss': 0.0222, 'grad_norm': 11.422637939453125, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.02197520062327385, 'loss_2': 0.0002231597900390625, 'loss_3': -16.370311737060547, 'loss_4': 0.7453982830047607, 'epoch': 14.43}
{'loss': 0.0128, 'grad_norm': 5.626687049865723, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.00823981873691082, 'loss_2': 0.004535675048828125, 'loss_3': -16.43291473388672, 'loss_4': 0.41814398765563965, 'epoch': 14.44}
{'loss': 0.0228, 'grad_norm': 7.987133026123047, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.019690975546836853, 'loss_2': 0.0030670166015625, 'loss_3': -16.274066925048828, 'loss_4': 0.17291006445884705, 'epoch': 14.44}
{'loss': 0.0122, 'grad_norm': 5.586060047149658, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.008539203554391861, 'loss_2': 0.003643035888671875, 'loss_3': -16.283769607543945, 'loss_4': 0.7799688577651978, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 13:22:22,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:22,372 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:41<46:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:29,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02124817669391632, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.59, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01876123435795307, 'eval_loss_2': 0.0024869441986083984, 'eval_loss_3': -18.245683670043945, 'eval_loss_4': 0.6439797282218933, 'epoch': 14.45}
{'loss': 0.0091, 'grad_norm': 5.028951644897461, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.004799781832844019, 'loss_2': 0.0042724609375, 'loss_3': -16.3836727142334, 'loss_4': 0.6985236406326294, 'epoch': 14.45}
{'loss': 0.0576, 'grad_norm': 15.60714340209961, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.05150274187326431, 'loss_2': 0.0060577392578125, 'loss_3': -16.346065521240234, 'loss_4': 0.8067244291305542, 'epoch': 14.46}
{'loss': 0.0109, 'grad_norm': 4.979668140411377, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.006954580545425415, 'loss_2': 0.003955841064453125, 'loss_3': -16.33416175842285, 'loss_4': 0.7652392387390137, 'epoch': 14.47}
{'loss': 0.0176, 'grad_norm': 6.326132297515869, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.009950390085577965, 'loss_2': 0.00762939453125, 'loss_3': -16.34619140625, 'loss_4': 0.6763365268707275, 'epoch': 14.47}
{'loss': 0.0109, 'grad_norm': 6.922987937927246, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.009911336936056614, 'loss_2': 0.001003265380859375, 'loss_3': -16.406017303466797, 'loss_4': 0.43975621461868286, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 13:22:29,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:29,721 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:49<46:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:37,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023333508521318436, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0201350636780262, 'eval_loss_2': 0.0031984448432922363, 'eval_loss_3': -18.24663543701172, 'eval_loss_4': 0.6173813343048096, 'epoch': 14.48}
{'loss': 0.0234, 'grad_norm': 5.776365280151367, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.013811148703098297, 'loss_2': 0.00963592529296875, 'loss_3': -16.2430362701416, 'loss_4': 0.4854778051376343, 'epoch': 14.48}
{'loss': 0.0369, 'grad_norm': 12.645751953125, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.02999122440814972, 'loss_2': 0.00691986083984375, 'loss_3': -16.53695297241211, 'loss_4': 0.6494507789611816, 'epoch': 14.49}
{'loss': 0.0185, 'grad_norm': 6.362821578979492, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.014329081401228905, 'loss_2': 0.00421142578125, 'loss_3': -16.195749282836914, 'loss_4': 0.20710787177085876, 'epoch': 14.49}
{'loss': 0.0187, 'grad_norm': 7.472564697265625, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.015012666583061218, 'loss_2': 0.00373077392578125, 'loss_3': -16.361610412597656, 'loss_4': 0.5153728723526001, 'epoch': 14.5}
{'loss': 0.0164, 'grad_norm': 9.294770240783691, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.013599485158920288, 'loss_2': 0.002819061279296875, 'loss_3': -16.352157592773438, 'loss_4': 0.6703848838806152, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 13:22:37,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:37,067 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:01:56<46:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:44,415 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02401011809706688, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.592, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.02057240717113018, 'eval_loss_2': 0.0034377090632915497, 'eval_loss_3': -18.23748016357422, 'eval_loss_4': 0.5577078461647034, 'epoch': 14.51}
{'loss': 0.0313, 'grad_norm': 10.581216812133789, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.028841935098171234, 'loss_2': 0.002475738525390625, 'loss_3': -16.21025848388672, 'loss_4': -0.1723257303237915, 'epoch': 14.51}
{'loss': 0.0194, 'grad_norm': 7.000981330871582, 'learning_rate': 1.55e-05, 'loss_1': 0.017047757282853127, 'loss_2': 0.0023365020751953125, 'loss_3': -16.262680053710938, 'loss_4': 0.7647814750671387, 'epoch': 14.52}
{'loss': 0.0181, 'grad_norm': 6.546502590179443, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.011727290228009224, 'loss_2': 0.006366729736328125, 'loss_3': -16.33399200439453, 'loss_4': 0.7026103138923645, 'epoch': 14.52}
{'loss': 0.02, 'grad_norm': 8.444074630737305, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.010345210321247578, 'loss_2': 0.009674072265625, 'loss_3': -16.359943389892578, 'loss_4': 0.8399170637130737, 'epoch': 14.53}
{'loss': 0.0219, 'grad_norm': 7.5595245361328125, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.020106658339500427, 'loss_2': 0.001819610595703125, 'loss_3': -16.301925659179688, 'loss_4': 0.760769248008728, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 13:22:44,415 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:44,415 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:02:03<45:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:51,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02605137601494789, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.885, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.020869214087724686, 'eval_loss_2': 0.005182161927223206, 'eval_loss_3': -18.2158260345459, 'eval_loss_4': 0.5095363855361938, 'epoch': 14.53}
{'loss': 0.0166, 'grad_norm': 6.759293556213379, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.014550927095115185, 'loss_2': 0.0020542144775390625, 'loss_3': -16.122756958007812, 'loss_4': 0.6862111687660217, 'epoch': 14.54}
{'loss': 0.0152, 'grad_norm': 4.991606712341309, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.0073919459246098995, 'loss_2': 0.00783538818359375, 'loss_3': -16.321945190429688, 'loss_4': 0.6243017315864563, 'epoch': 14.55}
{'loss': 0.0403, 'grad_norm': 6.872605800628662, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.03186052292585373, 'loss_2': 0.00846099853515625, 'loss_3': -16.290252685546875, 'loss_4': 1.0917177200317383, 'epoch': 14.55}
{'loss': 0.0164, 'grad_norm': 4.999527931213379, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.007064308971166611, 'loss_2': 0.00937652587890625, 'loss_3': -16.349525451660156, 'loss_4': 0.4579959213733673, 'epoch': 14.56}
{'loss': 0.013, 'grad_norm': 6.542269706726074, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.010041393339633942, 'loss_2': 0.002964019775390625, 'loss_3': -16.376174926757812, 'loss_4': 0.42816025018692017, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 13:22:51,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:51,756 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:02:11<45:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:59,094 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024540845304727554, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.124, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.02159782126545906, 'eval_loss_2': 0.0029430240392684937, 'eval_loss_3': -18.231189727783203, 'eval_loss_4': 0.591200053691864, 'epoch': 14.56}
{'loss': 0.007, 'grad_norm': 5.166903495788574, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.006927721668034792, 'loss_2': 4.9591064453125e-05, 'loss_3': -16.554729461669922, 'loss_4': 0.8459739685058594, 'epoch': 14.57}
{'loss': 0.011, 'grad_norm': 4.745411396026611, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.006151765119284391, 'loss_2': 0.00482940673828125, 'loss_3': -16.412708282470703, 'loss_4': 0.7900500297546387, 'epoch': 14.58}
{'loss': 0.017, 'grad_norm': 6.186203956604004, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.011638537049293518, 'loss_2': 0.00537109375, 'loss_3': -16.45067596435547, 'loss_4': 0.9287898540496826, 'epoch': 14.58}
{'loss': 0.0119, 'grad_norm': 5.071716785430908, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.009072153829038143, 'loss_2': 0.002811431884765625, 'loss_3': -16.31785011291504, 'loss_4': 0.7840061187744141, 'epoch': 14.59}
{'loss': 0.014, 'grad_norm': 5.8261284828186035, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.009729105979204178, 'loss_2': 0.004306793212890625, 'loss_3': -16.439159393310547, 'loss_4': 0.6138642430305481, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 13:22:59,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:59,095 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:18<45:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:06,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02946147508919239, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.023665042594075203, 'eval_loss_2': 0.0057964324951171875, 'eval_loss_3': -18.18117904663086, 'eval_loss_4': 0.7144938707351685, 'epoch': 14.59}
{'loss': 0.0111, 'grad_norm': 5.489377975463867, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.0104288961738348, 'loss_2': 0.000629425048828125, 'loss_3': -16.552282333374023, 'loss_4': 0.5834814310073853, 'epoch': 14.6}
{'loss': 0.0139, 'grad_norm': 5.717179298400879, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.00799266155809164, 'loss_2': 0.0058746337890625, 'loss_3': -16.23078727722168, 'loss_4': 0.48227477073669434, 'epoch': 14.6}
{'loss': 0.0382, 'grad_norm': 9.2461576461792, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.03009004518389702, 'loss_2': 0.00809478759765625, 'loss_3': -16.43898582458496, 'loss_4': 0.5663175582885742, 'epoch': 14.61}
{'loss': 0.0183, 'grad_norm': 6.5765156745910645, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.01180099043995142, 'loss_2': 0.00647735595703125, 'loss_3': -16.434173583984375, 'loss_4': 0.9731392860412598, 'epoch': 14.62}
{'loss': 0.0116, 'grad_norm': 5.5550031661987305, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.007974440231919289, 'loss_2': 0.003597259521484375, 'loss_3': -16.333606719970703, 'loss_4': 0.2958315908908844, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 13:23:06,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:06,435 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:25<45:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:13,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030763786286115646, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.996, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.025840261951088905, 'eval_loss_2': 0.004923522472381592, 'eval_loss_3': -18.147499084472656, 'eval_loss_4': 0.6965224742889404, 'epoch': 14.62}
{'loss': 0.0092, 'grad_norm': 5.424388885498047, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.008866752497851849, 'loss_2': 0.0003590583801269531, 'loss_3': -16.284482955932617, 'loss_4': 1.2573113441467285, 'epoch': 14.63}
{'loss': 0.0539, 'grad_norm': 16.885845184326172, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.05338782072067261, 'loss_2': 0.00051116943359375, 'loss_3': -16.28422737121582, 'loss_4': 1.226581335067749, 'epoch': 14.63}
{'loss': 0.0095, 'grad_norm': 5.249837398529053, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.008218406699597836, 'loss_2': 0.00128173828125, 'loss_3': -16.316452026367188, 'loss_4': 0.9781967997550964, 'epoch': 14.64}
{'loss': 0.0074, 'grad_norm': 5.153927326202393, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.005826327484101057, 'loss_2': 0.001552581787109375, 'loss_3': -16.22091293334961, 'loss_4': 0.1833702027797699, 'epoch': 14.65}
{'loss': 0.0263, 'grad_norm': 11.982208251953125, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.023983895778656006, 'loss_2': 0.002269744873046875, 'loss_3': -16.288423538208008, 'loss_4': 0.5363369584083557, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 13:23:13,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:13,779 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:33<45:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:21,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030336633324623108, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02702091634273529, 'eval_loss_2': 0.0033157169818878174, 'eval_loss_3': -18.136093139648438, 'eval_loss_4': 0.441823273897171, 'epoch': 14.65}
{'loss': 0.008, 'grad_norm': 4.466185569763184, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.0034049442037940025, 'loss_2': 0.0045928955078125, 'loss_3': -16.476364135742188, 'loss_4': 0.7787775993347168, 'epoch': 14.66}
{'loss': 0.0258, 'grad_norm': 9.587214469909668, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.020651962608098984, 'loss_2': 0.005138397216796875, 'loss_3': -16.30868148803711, 'loss_4': -0.08840960264205933, 'epoch': 14.66}
{'loss': 0.0216, 'grad_norm': 9.580246925354004, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.01964888721704483, 'loss_2': 0.0019893646240234375, 'loss_3': -16.389989852905273, 'loss_4': 0.6179039478302002, 'epoch': 14.67}
{'loss': 0.0099, 'grad_norm': 4.464008331298828, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.005175311584025621, 'loss_2': 0.004680633544921875, 'loss_3': -16.40826988220215, 'loss_4': 0.2684793174266815, 'epoch': 14.67}
{'loss': 0.0185, 'grad_norm': 4.948788166046143, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.008880611509084702, 'loss_2': 0.00962066650390625, 'loss_3': -16.215574264526367, 'loss_4': 0.052945688366889954, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 13:23:21,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:21,129 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:40<45:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:28,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02768980897963047, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.681, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.023592866957187653, 'eval_loss_2': 0.0040969401597976685, 'eval_loss_3': -18.16533660888672, 'eval_loss_4': 0.2249019294977188, 'epoch': 14.68}
{'loss': 0.0067, 'grad_norm': 6.337845802307129, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.0065908534452319145, 'loss_2': 0.00010991096496582031, 'loss_3': -16.466825485229492, 'loss_4': 0.5471503734588623, 'epoch': 14.69}
{'loss': 0.009, 'grad_norm': 4.737421035766602, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.005243185441941023, 'loss_2': 0.0037078857421875, 'loss_3': -16.355661392211914, 'loss_4': 0.3066212236881256, 'epoch': 14.69}
{'loss': 0.0106, 'grad_norm': 5.3202972412109375, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.007093559950590134, 'loss_2': 0.003490447998046875, 'loss_3': -16.06027603149414, 'loss_4': -0.05823680758476257, 'epoch': 14.7}
{'loss': 0.0273, 'grad_norm': 8.173659324645996, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.023808728903532028, 'loss_2': 0.003475189208984375, 'loss_3': -16.409378051757812, 'loss_4': 0.4532841145992279, 'epoch': 14.7}
{'loss': 0.0155, 'grad_norm': 6.8701252937316895, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.010655131191015244, 'loss_2': 0.00489044189453125, 'loss_3': -16.342418670654297, 'loss_4': 0.5841611623764038, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 13:23:28,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:28,477 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:47<45:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:35,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023455996066331863, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.79, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017891723662614822, 'eval_loss_2': 0.005564272403717041, 'eval_loss_3': -18.222187042236328, 'eval_loss_4': 0.2211657464504242, 'epoch': 14.71}
{'loss': 0.0138, 'grad_norm': 6.4158196449279785, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.012751217000186443, 'loss_2': 0.0010156631469726562, 'loss_3': -16.21339225769043, 'loss_4': 0.17708396911621094, 'epoch': 14.72}
{'loss': 0.0182, 'grad_norm': 6.221664905548096, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.011768098920583725, 'loss_2': 0.006435394287109375, 'loss_3': -16.416698455810547, 'loss_4': 0.4865352511405945, 'epoch': 14.72}
{'loss': 0.0168, 'grad_norm': 5.508330821990967, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.008809584192931652, 'loss_2': 0.00799560546875, 'loss_3': -16.246437072753906, 'loss_4': 0.04363970458507538, 'epoch': 14.73}
{'loss': 0.0182, 'grad_norm': 7.328558921813965, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.01567402109503746, 'loss_2': 0.0025424957275390625, 'loss_3': -16.452919006347656, 'loss_4': 0.3783140480518341, 'epoch': 14.73}
{'loss': 0.0221, 'grad_norm': 5.536922931671143, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.009953029453754425, 'loss_2': 0.01215362548828125, 'loss_3': -16.422527313232422, 'loss_4': -0.03319868445396423, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 13:23:35,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:35,821 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:02:55<45:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:43,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023003190755844116, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.019, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01817607320845127, 'eval_loss_2': 0.004827119410037994, 'eval_loss_3': -18.22909927368164, 'eval_loss_4': 0.3292165994644165, 'epoch': 14.74}
{'loss': 0.0156, 'grad_norm': 6.136796951293945, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.012609647586941719, 'loss_2': 0.0030059814453125, 'loss_3': -16.269264221191406, 'loss_4': 0.288667231798172, 'epoch': 14.74}
{'loss': 0.0116, 'grad_norm': 5.689085483551025, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.010292060673236847, 'loss_2': 0.0012950897216796875, 'loss_3': -16.45123291015625, 'loss_4': 0.7988987565040588, 'epoch': 14.75}
{'loss': 0.0243, 'grad_norm': 9.239605903625488, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.023340979591012, 'loss_2': 0.0009937286376953125, 'loss_3': -16.141216278076172, 'loss_4': 0.7647807598114014, 'epoch': 14.76}
{'loss': 0.0125, 'grad_norm': 5.693088531494141, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.008069406263530254, 'loss_2': 0.004436492919921875, 'loss_3': -16.19969940185547, 'loss_4': 0.6571164131164551, 'epoch': 14.76}
{'loss': 0.0082, 'grad_norm': 4.710327625274658, 'learning_rate': 1.525e-05, 'loss_1': 0.0054228645749390125, 'loss_2': 0.0027675628662109375, 'loss_3': -16.448623657226562, 'loss_4': 0.8328264951705933, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 13:23:43,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:43,158 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:03:02<45:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:50,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019848180934786797, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.137, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016154443845152855, 'eval_loss_2': 0.0036937370896339417, 'eval_loss_3': -18.222143173217773, 'eval_loss_4': 0.47739991545677185, 'epoch': 14.77}
{'loss': 0.0701, 'grad_norm': 16.569305419921875, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.06621705740690231, 'loss_2': 0.0038547515869140625, 'loss_3': -16.445938110351562, 'loss_4': 0.6848438382148743, 'epoch': 14.77}
{'loss': 0.0194, 'grad_norm': 7.000230312347412, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.016042979434132576, 'loss_2': 0.00333404541015625, 'loss_3': -16.26667594909668, 'loss_4': 0.7720984220504761, 'epoch': 14.78}
{'loss': 0.019, 'grad_norm': 5.818970203399658, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.010548734106123447, 'loss_2': 0.0084075927734375, 'loss_3': -16.44169807434082, 'loss_4': 0.6824524402618408, 'epoch': 14.78}
{'loss': 0.016, 'grad_norm': 8.692325592041016, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.014728797599673271, 'loss_2': 0.0012302398681640625, 'loss_3': -16.369312286376953, 'loss_4': 0.8164904117584229, 'epoch': 14.79}
{'loss': 0.0124, 'grad_norm': 6.453731060028076, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.009315303526818752, 'loss_2': 0.0030364990234375, 'loss_3': -16.235271453857422, 'loss_4': 0.8681895732879639, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 13:23:50,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:50,499 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:03:09<45:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:57,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01990380510687828, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015667764469981194, 'eval_loss_2': 0.004236042499542236, 'eval_loss_3': -18.22825813293457, 'eval_loss_4': 0.6140487194061279, 'epoch': 14.8}
{'loss': 0.0194, 'grad_norm': 7.195511341094971, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.013574308715760708, 'loss_2': 0.00579833984375, 'loss_3': -16.28289222717285, 'loss_4': 0.5566260814666748, 'epoch': 14.8}
{'loss': 0.0133, 'grad_norm': 5.441124439239502, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.008462171070277691, 'loss_2': 0.004817962646484375, 'loss_3': -16.275693893432617, 'loss_4': 0.658566951751709, 'epoch': 14.81}
{'loss': 0.0138, 'grad_norm': 5.304659843444824, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.00755690922960639, 'loss_2': 0.006256103515625, 'loss_3': -16.2357177734375, 'loss_4': 0.8785539269447327, 'epoch': 14.81}
{'loss': 0.0138, 'grad_norm': 5.384530067443848, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.011182105168700218, 'loss_2': 0.0025730133056640625, 'loss_3': -16.309215545654297, 'loss_4': 0.8096504807472229, 'epoch': 14.82}
{'loss': 0.0096, 'grad_norm': 4.504210472106934, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.004989477340131998, 'loss_2': 0.004573822021484375, 'loss_3': -16.260936737060547, 'loss_4': 0.7564601302146912, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 13:23:57,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:57,843 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:17<45:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:05,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018669934943318367, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.156, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014214438386261463, 'eval_loss_2': 0.004455499351024628, 'eval_loss_3': -18.257596969604492, 'eval_loss_4': 0.7396956086158752, 'epoch': 14.83}
{'loss': 0.0193, 'grad_norm': 9.905599594116211, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.01812293380498886, 'loss_2': 0.001224517822265625, 'loss_3': -16.371017456054688, 'loss_4': 1.6234571933746338, 'epoch': 14.83}
{'loss': 0.0382, 'grad_norm': 14.472436904907227, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.033063165843486786, 'loss_2': 0.00516510009765625, 'loss_3': -16.45885467529297, 'loss_4': 1.0393168926239014, 'epoch': 14.84}
{'loss': 0.0117, 'grad_norm': 4.676754474639893, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.00774430250748992, 'loss_2': 0.003910064697265625, 'loss_3': -16.402162551879883, 'loss_4': 0.5444918274879456, 'epoch': 14.84}
{'loss': 0.0109, 'grad_norm': 5.038471698760986, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.007653791457414627, 'loss_2': 0.003246307373046875, 'loss_3': -16.275066375732422, 'loss_4': 0.2685496211051941, 'epoch': 14.85}
{'loss': 0.011, 'grad_norm': 6.033324241638184, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.008235757239162922, 'loss_2': 0.0028076171875, 'loss_3': -16.27632713317871, 'loss_4': 0.2843289375305176, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 13:24:05,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:05,197 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:24<44:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:12,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01947620138525963, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01524129044264555, 'eval_loss_2': 0.004234910011291504, 'eval_loss_3': -18.261415481567383, 'eval_loss_4': 0.658598780632019, 'epoch': 14.85}
{'loss': 0.0428, 'grad_norm': 31.176570892333984, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.041649214923381805, 'loss_2': 0.0011930465698242188, 'loss_3': -16.374114990234375, 'loss_4': 0.5801947116851807, 'epoch': 14.86}
{'loss': 0.021, 'grad_norm': 6.569745063781738, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.015937989577651024, 'loss_2': 0.005069732666015625, 'loss_3': -16.330299377441406, 'loss_4': 0.8296464681625366, 'epoch': 14.87}
{'loss': 0.0084, 'grad_norm': 5.158522605895996, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.00543180713430047, 'loss_2': 0.003009796142578125, 'loss_3': -16.357776641845703, 'loss_4': 0.8452306389808655, 'epoch': 14.87}
{'loss': 0.0199, 'grad_norm': 5.305092811584473, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.01056796032935381, 'loss_2': 0.0092926025390625, 'loss_3': -16.2354736328125, 'loss_4': 0.39570218324661255, 'epoch': 14.88}
{'loss': 0.0068, 'grad_norm': 4.603828430175781, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.004489496815949678, 'loss_2': 0.0023345947265625, 'loss_3': -16.45805549621582, 'loss_4': 0.69191575050354, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 13:24:12,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:12,537 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:31<44:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:19,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020662369206547737, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.049, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01701587624847889, 'eval_loss_2': 0.0036464929580688477, 'eval_loss_3': -18.231966018676758, 'eval_loss_4': 0.5632228851318359, 'epoch': 14.88}
{'loss': 0.011, 'grad_norm': 5.5878705978393555, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.007318929303437471, 'loss_2': 0.003719329833984375, 'loss_3': -16.340341567993164, 'loss_4': 1.080826759338379, 'epoch': 14.89}
{'loss': 0.0082, 'grad_norm': 5.304332733154297, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.007844324223697186, 'loss_2': 0.0003192424774169922, 'loss_3': -16.241958618164062, 'loss_4': 0.39544641971588135, 'epoch': 14.9}
{'loss': 0.0436, 'grad_norm': 19.225582122802734, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.042628705501556396, 'loss_2': 0.0009546279907226562, 'loss_3': -16.296066284179688, 'loss_4': 1.2507903575897217, 'epoch': 14.9}
{'loss': 0.0213, 'grad_norm': 9.584280967712402, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.016980819404125214, 'loss_2': 0.0042877197265625, 'loss_3': -16.300373077392578, 'loss_4': 0.3782031834125519, 'epoch': 14.91}
{'loss': 0.0269, 'grad_norm': 13.583099365234375, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.024723593145608902, 'loss_2': 0.002216339111328125, 'loss_3': -16.47305679321289, 'loss_4': 0.3226722478866577, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 13:24:19,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:19,873 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:39<44:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:27,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022549673914909363, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.081, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01860177516937256, 'eval_loss_2': 0.003947898745536804, 'eval_loss_3': -18.241168975830078, 'eval_loss_4': 0.4663233458995819, 'epoch': 14.91}
{'loss': 0.0198, 'grad_norm': 9.09904670715332, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.017326144501566887, 'loss_2': 0.002498626708984375, 'loss_3': -16.518766403198242, 'loss_4': 0.4691653251647949, 'epoch': 14.92}
{'loss': 0.0231, 'grad_norm': 10.989839553833008, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.015320897102355957, 'loss_2': 0.0078277587890625, 'loss_3': -16.35146713256836, 'loss_4': 1.0921859741210938, 'epoch': 14.92}
{'loss': 0.0113, 'grad_norm': 5.366550445556641, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.007219832390546799, 'loss_2': 0.004047393798828125, 'loss_3': -16.569782257080078, 'loss_4': 0.48922979831695557, 'epoch': 14.93}
{'loss': 0.0113, 'grad_norm': 5.649957656860352, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.00990071427077055, 'loss_2': 0.00141143798828125, 'loss_3': -16.42509651184082, 'loss_4': 0.4574470818042755, 'epoch': 14.94}
{'loss': 0.0108, 'grad_norm': 5.099104404449463, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.008898424915969372, 'loss_2': 0.0019092559814453125, 'loss_3': -16.284595489501953, 'loss_4': 1.3002196550369263, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 13:24:27,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:27,206 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:46<44:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:34,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02354387566447258, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.151, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.019670886918902397, 'eval_loss_2': 0.003872990608215332, 'eval_loss_3': -18.24898910522461, 'eval_loss_4': 0.3925042748451233, 'epoch': 14.94}
{'loss': 0.0198, 'grad_norm': 9.063026428222656, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.01266711950302124, 'loss_2': 0.00711822509765625, 'loss_3': -16.259307861328125, 'loss_4': 0.3584502935409546, 'epoch': 14.95}
{'loss': 0.0172, 'grad_norm': 10.359367370605469, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.016354650259017944, 'loss_2': 0.0008077621459960938, 'loss_3': -16.32135009765625, 'loss_4': 0.8085082769393921, 'epoch': 14.95}
{'loss': 0.0138, 'grad_norm': 6.5891432762146, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.011507594026625156, 'loss_2': 0.0022792816162109375, 'loss_3': -16.13738441467285, 'loss_4': 0.4880678057670593, 'epoch': 14.96}
{'loss': 0.01, 'grad_norm': 4.8266448974609375, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.005588187370449305, 'loss_2': 0.00444793701171875, 'loss_3': -16.552982330322266, 'loss_4': 1.0280789136886597, 'epoch': 14.97}
{'loss': 0.0088, 'grad_norm': 4.952898025512695, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.00690004788339138, 'loss_2': 0.0019369125366210938, 'loss_3': -16.59059715270996, 'loss_4': 0.7226194143295288, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 13:24:34,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:34,538 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:53<40:09,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:24:41,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023478249087929726, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.051, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.019853612408041954, 'eval_loss_2': 0.003624632954597473, 'eval_loss_3': -18.22248077392578, 'eval_loss_4': 0.3741268515586853, 'epoch': 14.97}
{'loss': 0.0183, 'grad_norm': 12.460733413696289, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.016051243990659714, 'loss_2': 0.002292633056640625, 'loss_3': -16.395586013793945, 'loss_4': 0.7722675204277039, 'epoch': 14.98}
{'loss': 0.0287, 'grad_norm': 6.976659774780273, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.027443265542387962, 'loss_2': 0.0012464523315429688, 'loss_3': -16.462692260742188, 'loss_4': 0.3588728904724121, 'epoch': 14.98}
{'loss': 0.015, 'grad_norm': 5.825560569763184, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.00879480317234993, 'loss_2': 0.006237030029296875, 'loss_3': -16.299850463867188, 'loss_4': 0.41154104471206665, 'epoch': 14.99}
{'loss': 0.02, 'grad_norm': 7.5271100997924805, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.013629109598696232, 'loss_2': 0.00638580322265625, 'loss_3': -16.08357810974121, 'loss_4': 0.2199801206588745, 'epoch': 14.99}
{'loss': 0.0078, 'grad_norm': 6.2804059982299805, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.002749829087406397, 'loss_2': 0.0050201416015625, 'loss_3': -16.454776763916016, 'loss_4': -0.04382694512605667, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 13:24:41,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:41,539 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:04:00<43:54,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:24:48,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0255172997713089, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.032, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.020760703831911087, 'eval_loss_2': 0.00475659966468811, 'eval_loss_3': -18.200363159179688, 'eval_loss_4': 0.17265604436397552, 'epoch': 15.0}
{'loss': 0.0084, 'grad_norm': 4.810946464538574, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.006753060035407543, 'loss_2': 0.0016069412231445312, 'loss_3': -16.444690704345703, 'loss_4': -0.2640167474746704, 'epoch': 15.01}
{'loss': 0.0243, 'grad_norm': 8.292997360229492, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.015374314039945602, 'loss_2': 0.008880615234375, 'loss_3': -16.116943359375, 'loss_4': 0.146462082862854, 'epoch': 15.01}
{'loss': 0.0097, 'grad_norm': 5.036629676818848, 'learning_rate': 1.5e-05, 'loss_1': 0.008274960331618786, 'loss_2': 0.00140380859375, 'loss_3': -16.37591552734375, 'loss_4': 0.7498574256896973, 'epoch': 15.02}
{'loss': 0.0176, 'grad_norm': 5.685858249664307, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.009631144814193249, 'loss_2': 0.00798797607421875, 'loss_3': -16.211891174316406, 'loss_4': -0.03211948275566101, 'epoch': 15.02}
{'loss': 0.0089, 'grad_norm': 4.528583526611328, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.004533473867923021, 'loss_2': 0.00434112548828125, 'loss_3': -16.37205696105957, 'loss_4': 0.07241582870483398, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 13:24:48,921 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:48,921 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:04:08<44:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:24:56,254 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025624915957450867, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.021002935245633125, 'eval_loss_2': 0.004621982574462891, 'eval_loss_3': -18.2018985748291, 'eval_loss_4': -0.17043711245059967, 'epoch': 15.03}
{'loss': 0.0087, 'grad_norm': 4.2310051918029785, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.0028660381212830544, 'loss_2': 0.00586700439453125, 'loss_3': -16.411481857299805, 'loss_4': 0.0372379869222641, 'epoch': 15.03}
{'loss': 0.0088, 'grad_norm': 4.273333549499512, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.006402994971722364, 'loss_2': 0.002376556396484375, 'loss_3': -16.482025146484375, 'loss_4': -0.022012338042259216, 'epoch': 15.04}
{'loss': 0.0264, 'grad_norm': 17.469558715820312, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.018211832270026207, 'loss_2': 0.0082244873046875, 'loss_3': -16.220996856689453, 'loss_4': 0.5552219748497009, 'epoch': 15.05}
{'loss': 0.0065, 'grad_norm': 5.274474143981934, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.006210962776094675, 'loss_2': 0.00028705596923828125, 'loss_3': -16.430118560791016, 'loss_4': 0.30754411220550537, 'epoch': 15.05}
{'loss': 0.0147, 'grad_norm': 5.543817043304443, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.008720383048057556, 'loss_2': 0.0059661865234375, 'loss_3': -16.14215087890625, 'loss_4': 0.1822664439678192, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 13:24:56,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:56,254 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:15<44:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:03,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02636050432920456, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.137, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.021556008607149124, 'eval_loss_2': 0.004804491996765137, 'eval_loss_3': -18.206012725830078, 'eval_loss_4': -0.31400591135025024, 'epoch': 15.06}
{'loss': 0.008, 'grad_norm': 5.0369086265563965, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.0053222267888486385, 'loss_2': 0.002635955810546875, 'loss_3': -16.47372055053711, 'loss_4': -0.5048503875732422, 'epoch': 15.06}
{'loss': 0.0145, 'grad_norm': 8.055534362792969, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.011983029544353485, 'loss_2': 0.002552032470703125, 'loss_3': -16.362018585205078, 'loss_4': -0.3229770064353943, 'epoch': 15.07}
{'loss': 0.015, 'grad_norm': 5.707640171051025, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.006240735296159983, 'loss_2': 0.0087738037109375, 'loss_3': -16.577030181884766, 'loss_4': -0.28166428208351135, 'epoch': 15.08}
{'loss': 0.0119, 'grad_norm': 4.458917617797852, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.009536759927868843, 'loss_2': 0.0024127960205078125, 'loss_3': -16.467823028564453, 'loss_4': 0.025010965764522552, 'epoch': 15.08}
{'loss': 0.0168, 'grad_norm': 5.768409252166748, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.007422016002237797, 'loss_2': 0.00933074951171875, 'loss_3': -16.40582275390625, 'loss_4': -0.35874083638191223, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 13:25:03,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:03,591 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:22<44:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:10,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024590060114860535, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.0170509684830904, 'eval_loss_2': 0.007539093494415283, 'eval_loss_3': -18.245529174804688, 'eval_loss_4': -0.27826517820358276, 'epoch': 15.09}
{'loss': 0.0177, 'grad_norm': 13.415669441223145, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.013570311479270458, 'loss_2': 0.004123687744140625, 'loss_3': -16.415685653686523, 'loss_4': -0.18420308828353882, 'epoch': 15.09}
{'loss': 0.0123, 'grad_norm': 4.9392499923706055, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.005618253257125616, 'loss_2': 0.006702423095703125, 'loss_3': -16.254127502441406, 'loss_4': -0.2416953444480896, 'epoch': 15.1}
{'loss': 0.0123, 'grad_norm': 6.597838401794434, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.011764922179281712, 'loss_2': 0.0005431175231933594, 'loss_3': -16.319080352783203, 'loss_4': 0.27447283267974854, 'epoch': 15.1}
{'loss': 0.0156, 'grad_norm': 5.330942153930664, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.008148804306983948, 'loss_2': 0.00746917724609375, 'loss_3': -16.397459030151367, 'loss_4': 0.09085327386856079, 'epoch': 15.11}
{'loss': 0.0125, 'grad_norm': 5.073258399963379, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.007756869774311781, 'loss_2': 0.00470733642578125, 'loss_3': -16.431503295898438, 'loss_4': 0.10069155693054199, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 13:25:10,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:10,930 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:30<44:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:18,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017868753522634506, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.968, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.014632153324782848, 'eval_loss_2': 0.0032365992665290833, 'eval_loss_3': -18.25699234008789, 'eval_loss_4': -0.16813990473747253, 'epoch': 15.12}
{'loss': 0.017, 'grad_norm': 7.596085071563721, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.015486600808799267, 'loss_2': 0.00152587890625, 'loss_3': -16.322067260742188, 'loss_4': -0.023096591234207153, 'epoch': 15.12}
{'loss': 0.007, 'grad_norm': 4.393273830413818, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.005633423570543528, 'loss_2': 0.001331329345703125, 'loss_3': -16.35553550720215, 'loss_4': 0.3064912259578705, 'epoch': 15.13}
{'loss': 0.0164, 'grad_norm': 5.112682342529297, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.009827325120568275, 'loss_2': 0.006622314453125, 'loss_3': -16.44595718383789, 'loss_4': 0.7079002857208252, 'epoch': 15.13}
{'loss': 0.0107, 'grad_norm': 4.96711540222168, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.005391939543187618, 'loss_2': 0.00533294677734375, 'loss_3': -16.348411560058594, 'loss_4': -0.6295948028564453, 'epoch': 15.14}
{'loss': 0.0084, 'grad_norm': 4.623584747314453, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.005638922099024057, 'loss_2': 0.002773284912109375, 'loss_3': -16.313880920410156, 'loss_4': 0.47674867510795593, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 13:25:18,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:18,270 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:37<44:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:25,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01849943771958351, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.425, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014521701261401176, 'eval_loss_2': 0.003977734595537186, 'eval_loss_3': -18.25820541381836, 'eval_loss_4': -0.26471492648124695, 'epoch': 15.15}
{'loss': 0.014, 'grad_norm': 5.615474700927734, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.009471050463616848, 'loss_2': 0.00457000732421875, 'loss_3': -16.458683013916016, 'loss_4': 0.46055442094802856, 'epoch': 15.15}
{'loss': 0.0094, 'grad_norm': 5.270999908447266, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.00805601291358471, 'loss_2': 0.0013561248779296875, 'loss_3': -16.316925048828125, 'loss_4': -0.07561793923377991, 'epoch': 15.16}
{'loss': 0.0123, 'grad_norm': 5.0185675621032715, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.008141779340803623, 'loss_2': 0.004119873046875, 'loss_3': -16.183378219604492, 'loss_4': 0.26746755838394165, 'epoch': 15.16}
{'loss': 0.0753, 'grad_norm': 20.345849990844727, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.07498886436223984, 'loss_2': 0.0002808570861816406, 'loss_3': -16.498023986816406, 'loss_4': 0.07977309823036194, 'epoch': 15.17}
{'loss': 0.0113, 'grad_norm': 5.763959884643555, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.008773824200034142, 'loss_2': 0.002529144287109375, 'loss_3': -16.421131134033203, 'loss_4': -0.2194785177707672, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 13:25:25,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:25,619 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:44<44:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:32,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01785769872367382, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.041, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014964668080210686, 'eval_loss_2': 0.0028930306434631348, 'eval_loss_3': -18.254480361938477, 'eval_loss_4': -0.4150944948196411, 'epoch': 15.17}
{'loss': 0.0068, 'grad_norm': 4.808847427368164, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.006614156533032656, 'loss_2': 0.00021457672119140625, 'loss_3': -16.344776153564453, 'loss_4': -0.46954405307769775, 'epoch': 15.18}
{'loss': 0.0142, 'grad_norm': 5.118042945861816, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.006976950913667679, 'loss_2': 0.007266998291015625, 'loss_3': -16.43362808227539, 'loss_4': -0.6338616013526917, 'epoch': 15.19}
{'loss': 0.0178, 'grad_norm': 5.207835674285889, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.008005688898265362, 'loss_2': 0.0098419189453125, 'loss_3': -16.499183654785156, 'loss_4': 0.1790076196193695, 'epoch': 15.19}
{'loss': 0.0107, 'grad_norm': 5.67272424697876, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.008961600251495838, 'loss_2': 0.00176239013671875, 'loss_3': -16.39474868774414, 'loss_4': -0.3549988865852356, 'epoch': 15.2}
{'loss': 0.0151, 'grad_norm': 6.73822021484375, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.012825749814510345, 'loss_2': 0.002269744873046875, 'loss_3': -16.387027740478516, 'loss_4': -0.915752649307251, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 13:25:32,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:32,959 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:52<43:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:40,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017945922911167145, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.252, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.014634467661380768, 'eval_loss_2': 0.003311455249786377, 'eval_loss_3': -18.266292572021484, 'eval_loss_4': -0.6784929037094116, 'epoch': 15.2}
{'loss': 0.0133, 'grad_norm': 5.350142955780029, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.010347368195652962, 'loss_2': 0.002902984619140625, 'loss_3': -16.272705078125, 'loss_4': -0.46624284982681274, 'epoch': 15.21}
{'loss': 0.0092, 'grad_norm': 6.418937683105469, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.008575755171477795, 'loss_2': 0.0006322860717773438, 'loss_3': -16.192150115966797, 'loss_4': -0.5664099454879761, 'epoch': 15.22}
{'loss': 0.0604, 'grad_norm': 33.21215057373047, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.056615546345710754, 'loss_2': 0.003772735595703125, 'loss_3': -16.31664276123047, 'loss_4': -0.34258487820625305, 'epoch': 15.22}
{'loss': 0.0285, 'grad_norm': 21.154903411865234, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.026346758008003235, 'loss_2': 0.002178192138671875, 'loss_3': -16.31998062133789, 'loss_4': -0.4466110169887543, 'epoch': 15.23}
{'loss': 0.0095, 'grad_norm': 5.224289894104004, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.005875185132026672, 'loss_2': 0.003589630126953125, 'loss_3': -16.34734344482422, 'loss_4': 0.0030674338340759277, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 13:25:40,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:40,308 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:04:59<43:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:47,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023516230285167694, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.193, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.015950612723827362, 'eval_loss_2': 0.007565617561340332, 'eval_loss_3': -18.227087020874023, 'eval_loss_4': -0.8181180357933044, 'epoch': 15.23}
{'loss': 0.0432, 'grad_norm': 15.062172889709473, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.039752811193466187, 'loss_2': 0.00345611572265625, 'loss_3': -16.262393951416016, 'loss_4': 0.30665937066078186, 'epoch': 15.24}
{'loss': 0.0319, 'grad_norm': 13.148235321044922, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.026938235387206078, 'loss_2': 0.004993438720703125, 'loss_3': -16.30523681640625, 'loss_4': -0.5588974952697754, 'epoch': 15.24}
{'loss': 0.0117, 'grad_norm': 7.174135208129883, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.01090933382511139, 'loss_2': 0.0007953643798828125, 'loss_3': -16.220069885253906, 'loss_4': -0.6279733180999756, 'epoch': 15.25}
{'loss': 0.0136, 'grad_norm': 4.267537593841553, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.004105935804545879, 'loss_2': 0.009490966796875, 'loss_3': -16.468246459960938, 'loss_4': -0.7911673784255981, 'epoch': 15.26}
{'loss': 0.0187, 'grad_norm': 5.541873931884766, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.00977566558867693, 'loss_2': 0.0088958740234375, 'loss_3': -16.29741668701172, 'loss_4': -0.6895498037338257, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 13:25:47,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:47,649 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:05:06<43:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:54,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0234969649463892, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.998, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01761350966989994, 'eval_loss_2': 0.005883455276489258, 'eval_loss_3': -18.238794326782227, 'eval_loss_4': -0.9205376505851746, 'epoch': 15.26}
{'loss': 0.012, 'grad_norm': 6.245276927947998, 'learning_rate': 1.475e-05, 'loss_1': 0.009963300079107285, 'loss_2': 0.001995086669921875, 'loss_3': -16.251190185546875, 'loss_4': -0.7240379452705383, 'epoch': 15.27}
{'loss': 0.0103, 'grad_norm': 5.295694351196289, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.008072977885603905, 'loss_2': 0.002239227294921875, 'loss_3': -16.329940795898438, 'loss_4': -0.7566613554954529, 'epoch': 15.27}
{'loss': 0.0086, 'grad_norm': 4.852666854858398, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.007134964689612389, 'loss_2': 0.0015115737915039062, 'loss_3': -16.15814208984375, 'loss_4': -0.9746211767196655, 'epoch': 15.28}
{'loss': 0.0113, 'grad_norm': 5.849367618560791, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.007289488799870014, 'loss_2': 0.00396728515625, 'loss_3': -16.432687759399414, 'loss_4': -0.9880880117416382, 'epoch': 15.28}
{'loss': 0.0178, 'grad_norm': 6.202205657958984, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.01028161309659481, 'loss_2': 0.007556915283203125, 'loss_3': -16.351634979248047, 'loss_4': -0.8822847604751587, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 13:25:54,983 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:54,983 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:14<43:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:02,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022807806730270386, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.736, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.019592182710766792, 'eval_loss_2': 0.0032156258821487427, 'eval_loss_3': -18.22649383544922, 'eval_loss_4': -0.9379383325576782, 'epoch': 15.29}
{'loss': 0.01, 'grad_norm': 6.024608135223389, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.007918698713183403, 'loss_2': 0.002086639404296875, 'loss_3': -16.223222732543945, 'loss_4': -1.0415488481521606, 'epoch': 15.3}
{'loss': 0.0123, 'grad_norm': 6.9015302658081055, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.011826521717011929, 'loss_2': 0.00048351287841796875, 'loss_3': -16.239585876464844, 'loss_4': -0.7770682573318481, 'epoch': 15.3}
{'loss': 0.0095, 'grad_norm': 5.631491184234619, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.008575061336159706, 'loss_2': 0.0009527206420898438, 'loss_3': -16.111391067504883, 'loss_4': -1.3067288398742676, 'epoch': 15.31}
{'loss': 0.0188, 'grad_norm': 10.796317100524902, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.01496472954750061, 'loss_2': 0.00384521484375, 'loss_3': -16.24612808227539, 'loss_4': -0.8588013648986816, 'epoch': 15.31}
{'loss': 0.0094, 'grad_norm': 5.399340629577637, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.005761304870247841, 'loss_2': 0.0036754608154296875, 'loss_3': -16.31186866760254, 'loss_4': -0.6271013021469116, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 13:26:02,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:02,327 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:21<43:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:09,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025774821639060974, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.756, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.021948229521512985, 'eval_loss_2': 0.0038265883922576904, 'eval_loss_3': -18.195049285888672, 'eval_loss_4': -0.9468579292297363, 'epoch': 15.32}
{'loss': 0.0206, 'grad_norm': 8.91584300994873, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.015594434924423695, 'loss_2': 0.00501251220703125, 'loss_3': -16.197616577148438, 'loss_4': -0.810319185256958, 'epoch': 15.33}
{'loss': 0.0158, 'grad_norm': 5.2592315673828125, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.010529213584959507, 'loss_2': 0.005279541015625, 'loss_3': -16.557092666625977, 'loss_4': -0.7622430920600891, 'epoch': 15.33}
{'loss': 0.0055, 'grad_norm': 4.51283073425293, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.0035461573861539364, 'loss_2': 0.0019426345825195312, 'loss_3': -16.241090774536133, 'loss_4': -0.3863694667816162, 'epoch': 15.34}
{'loss': 0.0044, 'grad_norm': 5.001011371612549, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.004142362158745527, 'loss_2': 0.0002574920654296875, 'loss_3': -16.367734909057617, 'loss_4': -0.7385687828063965, 'epoch': 15.34}
{'loss': 0.0206, 'grad_norm': 7.715910911560059, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.01084736455231905, 'loss_2': 0.009796142578125, 'loss_3': -16.47189712524414, 'loss_4': -0.5615840554237366, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 13:26:09,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:09,666 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:28<43:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:16,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026620347052812576, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.274, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.022194555029273033, 'eval_loss_2': 0.004425793886184692, 'eval_loss_3': -18.21893882751465, 'eval_loss_4': -0.820959746837616, 'epoch': 15.35}
{'loss': 0.0074, 'grad_norm': 5.104446887969971, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.006417633965611458, 'loss_2': 0.0009655952453613281, 'loss_3': -16.255781173706055, 'loss_4': -0.5031295418739319, 'epoch': 15.35}
{'loss': 0.0099, 'grad_norm': 5.948721885681152, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.009700394235551357, 'loss_2': 0.0002377033233642578, 'loss_3': -16.315143585205078, 'loss_4': -1.1299304962158203, 'epoch': 15.36}
{'loss': 0.0139, 'grad_norm': 4.632225513458252, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.0069379862397909164, 'loss_2': 0.006923675537109375, 'loss_3': -16.354679107666016, 'loss_4': -0.6240208148956299, 'epoch': 15.37}
{'loss': 0.026, 'grad_norm': 10.76778793334961, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.025119595229625702, 'loss_2': 0.0008702278137207031, 'loss_3': -16.17845344543457, 'loss_4': -1.0189133882522583, 'epoch': 15.37}
{'loss': 0.007, 'grad_norm': 4.278814315795898, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.0042898827232420444, 'loss_2': 0.002696990966796875, 'loss_3': -16.548646926879883, 'loss_4': -0.8387660980224609, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 13:26:16,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:16,997 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:36<43:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:24,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025960184633731842, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.02300567366182804, 'eval_loss_2': 0.00295451283454895, 'eval_loss_3': -18.21681785583496, 'eval_loss_4': -0.7876208424568176, 'epoch': 15.38}
{'loss': 0.0129, 'grad_norm': 8.488496780395508, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.009771659970283508, 'loss_2': 0.003116607666015625, 'loss_3': -16.414182662963867, 'loss_4': -0.6259332895278931, 'epoch': 15.38}
{'loss': 0.0227, 'grad_norm': 5.898594856262207, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.011030087247490883, 'loss_2': 0.01171112060546875, 'loss_3': -16.29736328125, 'loss_4': -0.12156376242637634, 'epoch': 15.39}
{'loss': 0.0335, 'grad_norm': 14.623907089233398, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.0326143279671669, 'loss_2': 0.0008726119995117188, 'loss_3': -16.484941482543945, 'loss_4': -0.3868720531463623, 'epoch': 15.4}
{'loss': 0.017, 'grad_norm': 8.115811347961426, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.011128203943371773, 'loss_2': 0.0058441162109375, 'loss_3': -16.523469924926758, 'loss_4': -1.0364041328430176, 'epoch': 15.4}
{'loss': 0.0135, 'grad_norm': 6.0444865226745605, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.009188538417220116, 'loss_2': 0.004344940185546875, 'loss_3': -16.216888427734375, 'loss_4': -0.449729323387146, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 13:26:24,333 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:24,333 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:43<43:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:31,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02664165198802948, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.114, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.02151946909725666, 'eval_loss_2': 0.005122184753417969, 'eval_loss_3': -18.218109130859375, 'eval_loss_4': -0.6180525422096252, 'epoch': 15.41}
{'loss': 0.0154, 'grad_norm': 5.268889427185059, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.0068740444257855415, 'loss_2': 0.008544921875, 'loss_3': -16.3538818359375, 'loss_4': -0.4685862362384796, 'epoch': 15.41}
{'loss': 0.0094, 'grad_norm': 6.13534688949585, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.009182298555970192, 'loss_2': 0.00019860267639160156, 'loss_3': -16.432106018066406, 'loss_4': -0.554919421672821, 'epoch': 15.42}
{'loss': 0.0152, 'grad_norm': 6.481329441070557, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.014347433112561703, 'loss_2': 0.000843048095703125, 'loss_3': -16.32782554626465, 'loss_4': -0.6293014287948608, 'epoch': 15.42}
{'loss': 0.0092, 'grad_norm': 5.370913028717041, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.008837304078042507, 'loss_2': 0.00039649009704589844, 'loss_3': -16.524059295654297, 'loss_4': -0.44621044397354126, 'epoch': 15.43}
{'loss': 0.011, 'grad_norm': 5.798583507537842, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.009819242171943188, 'loss_2': 0.00119781494140625, 'loss_3': -16.388526916503906, 'loss_4': -0.5650273561477661, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 13:26:31,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:31,670 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:50<43:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:39,006 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023853037506341934, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.19, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.020630378276109695, 'eval_loss_2': 0.0032226592302322388, 'eval_loss_3': -18.235919952392578, 'eval_loss_4': -0.32260358333587646, 'epoch': 15.44}
{'loss': 0.0182, 'grad_norm': 6.466440200805664, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.014342587441205978, 'loss_2': 0.00388336181640625, 'loss_3': -16.340240478515625, 'loss_4': -0.2604633867740631, 'epoch': 15.44}
{'loss': 0.013, 'grad_norm': 5.8189849853515625, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.01130606047809124, 'loss_2': 0.001708984375, 'loss_3': -16.407506942749023, 'loss_4': 0.015309154987335205, 'epoch': 15.45}
{'loss': 0.0168, 'grad_norm': 5.987619876861572, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.010341017507016659, 'loss_2': 0.006504058837890625, 'loss_3': -16.376258850097656, 'loss_4': -0.06878235936164856, 'epoch': 15.45}
{'loss': 0.0203, 'grad_norm': 11.953267097473145, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.015315162017941475, 'loss_2': 0.0049896240234375, 'loss_3': -16.37096405029297, 'loss_4': -0.20719784498214722, 'epoch': 15.46}
{'loss': 0.0141, 'grad_norm': 5.545714855194092, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.010927611961960793, 'loss_2': 0.00316619873046875, 'loss_3': -16.509075164794922, 'loss_4': -0.14638260006904602, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 13:26:39,006 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:39,006 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:05:58<43:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:46,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028420627117156982, 'eval_runtime': 3.7922, 'eval_samples_per_second': 270.03, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.023299159482121468, 'eval_loss_2': 0.005121469497680664, 'eval_loss_3': -18.23094940185547, 'eval_loss_4': -0.04170724004507065, 'epoch': 15.47}
{'loss': 0.0161, 'grad_norm': 6.063260078430176, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.00827628094702959, 'loss_2': 0.00780487060546875, 'loss_3': -16.311004638671875, 'loss_4': 0.16793303191661835, 'epoch': 15.47}
{'loss': 0.0242, 'grad_norm': 7.808456897735596, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.019500846043229103, 'loss_2': 0.00467681884765625, 'loss_3': -16.185964584350586, 'loss_4': 0.12102741748094559, 'epoch': 15.48}
{'loss': 0.0099, 'grad_norm': 4.696573257446289, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.004994019865989685, 'loss_2': 0.004909515380859375, 'loss_3': -16.5010986328125, 'loss_4': -0.08137191832065582, 'epoch': 15.48}
{'loss': 0.0233, 'grad_norm': 7.085903644561768, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.015105095691978931, 'loss_2': 0.0082244873046875, 'loss_3': -16.35263442993164, 'loss_4': -0.05751305818557739, 'epoch': 15.49}
{'loss': 0.0142, 'grad_norm': 5.487753391265869, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.01055536326020956, 'loss_2': 0.003681182861328125, 'loss_3': -16.35582160949707, 'loss_4': -0.16912955045700073, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 13:26:46,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:46,346 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:06:05<43:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:53,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026838432997465134, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.234, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.023262031376361847, 'eval_loss_2': 0.0035763978958129883, 'eval_loss_3': -18.210277557373047, 'eval_loss_4': 0.14482182264328003, 'epoch': 15.49}
{'loss': 0.0145, 'grad_norm': 5.804269313812256, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.00933106616139412, 'loss_2': 0.005168914794921875, 'loss_3': -16.304645538330078, 'loss_4': 0.41476011276245117, 'epoch': 15.5}
{'loss': 0.0087, 'grad_norm': 4.574239730834961, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.006249590776860714, 'loss_2': 0.002410888671875, 'loss_3': -16.296907424926758, 'loss_4': 0.40302324295043945, 'epoch': 15.51}
{'loss': 0.0152, 'grad_norm': 4.910322189331055, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.013310007750988007, 'loss_2': 0.00193023681640625, 'loss_3': -16.299793243408203, 'loss_4': 0.15554746985435486, 'epoch': 15.51}
{'loss': 0.0115, 'grad_norm': 5.4307732582092285, 'learning_rate': 1.45e-05, 'loss_1': 0.011374411173164845, 'loss_2': 9.381771087646484e-05, 'loss_3': -16.5083065032959, 'loss_4': 0.5632558465003967, 'epoch': 15.52}
{'loss': 0.0163, 'grad_norm': 5.971101760864258, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.00713780103251338, 'loss_2': 0.00916290283203125, 'loss_3': -16.450525283813477, 'loss_4': 0.4177371859550476, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 13:26:53,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:53,684 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:13<43:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:01,030 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02662527933716774, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.978, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.021648552268743515, 'eval_loss_2': 0.004976727068424225, 'eval_loss_3': -18.190814971923828, 'eval_loss_4': 0.22567535936832428, 'epoch': 15.52}
{'loss': 0.0163, 'grad_norm': 5.489758014678955, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.0070841750130057335, 'loss_2': 0.009185791015625, 'loss_3': -16.602859497070312, 'loss_4': 0.1237553060054779, 'epoch': 15.53}
{'loss': 0.0177, 'grad_norm': 5.440569877624512, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.009565104730427265, 'loss_2': 0.0081024169921875, 'loss_3': -16.289981842041016, 'loss_4': 0.42258772253990173, 'epoch': 15.53}
{'loss': 0.0122, 'grad_norm': 4.5709228515625, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.00649681594222784, 'loss_2': 0.0056610107421875, 'loss_3': -16.42733383178711, 'loss_4': 0.4848867952823639, 'epoch': 15.54}
{'loss': 0.0224, 'grad_norm': 11.22693157196045, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.016713233664631844, 'loss_2': 0.00571441650390625, 'loss_3': -16.393600463867188, 'loss_4': 0.4381682276725769, 'epoch': 15.55}
{'loss': 0.058, 'grad_norm': 22.68266487121582, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.05043269693851471, 'loss_2': 0.007568359375, 'loss_3': -16.485057830810547, 'loss_4': 0.6671361923217773, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 13:27:01,030 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:01,030 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:20<42:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:08,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02601657621562481, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.020942850038409233, 'eval_loss_2': 0.005073726177215576, 'eval_loss_3': -18.19207763671875, 'eval_loss_4': 0.22906962037086487, 'epoch': 15.55}
{'loss': 0.0172, 'grad_norm': 5.709964752197266, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.008808800019323826, 'loss_2': 0.00838470458984375, 'loss_3': -16.42733383178711, 'loss_4': 0.25523248314857483, 'epoch': 15.56}
{'loss': 0.0195, 'grad_norm': 5.963460445404053, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.009790807031095028, 'loss_2': 0.00972747802734375, 'loss_3': -16.25308609008789, 'loss_4': 0.12265659123659134, 'epoch': 15.56}
{'loss': 0.0126, 'grad_norm': 5.552303791046143, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.011937124654650688, 'loss_2': 0.0007009506225585938, 'loss_3': -16.34579086303711, 'loss_4': 0.639958918094635, 'epoch': 15.57}
{'loss': 0.0093, 'grad_norm': 4.462580680847168, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.005577622912824154, 'loss_2': 0.003711700439453125, 'loss_3': -16.39940643310547, 'loss_4': 0.8432929515838623, 'epoch': 15.58}
{'loss': 0.1063, 'grad_norm': 19.696752548217773, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.10508228093385696, 'loss_2': 0.0012102127075195312, 'loss_3': -16.314279556274414, 'loss_4': 0.6092411279678345, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 13:27:08,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:08,376 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:27<42:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:15,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024024881422519684, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.153, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.021107450127601624, 'eval_loss_2': 0.0029174312949180603, 'eval_loss_3': -18.168701171875, 'eval_loss_4': 0.29983943700790405, 'epoch': 15.58}
{'loss': 0.0199, 'grad_norm': 5.3275346755981445, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.011948379687964916, 'loss_2': 0.0079193115234375, 'loss_3': -16.277185440063477, 'loss_4': 0.03906942531466484, 'epoch': 15.59}
{'loss': 0.0105, 'grad_norm': 4.933072090148926, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.005007622297853231, 'loss_2': 0.00548553466796875, 'loss_3': -16.36391830444336, 'loss_4': 0.7332953810691833, 'epoch': 15.59}
{'loss': 0.0113, 'grad_norm': 4.888880252838135, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.006678630597889423, 'loss_2': 0.004573822021484375, 'loss_3': -16.29170799255371, 'loss_4': 0.37924981117248535, 'epoch': 15.6}
{'loss': 0.0245, 'grad_norm': 6.028607368469238, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.011849167756736279, 'loss_2': 0.0126495361328125, 'loss_3': -16.173768997192383, 'loss_4': 0.5868992805480957, 'epoch': 15.6}
{'loss': 0.0312, 'grad_norm': 9.671924591064453, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.027882160618901253, 'loss_2': 0.003307342529296875, 'loss_3': -16.181121826171875, 'loss_4': 0.40342360734939575, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 13:27:15,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:15,717 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:35<42:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:23,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02117629535496235, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.038, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01847570203244686, 'eval_loss_2': 0.0027005933225154877, 'eval_loss_3': -18.176532745361328, 'eval_loss_4': 0.29095345735549927, 'epoch': 15.61}
{'loss': 0.0118, 'grad_norm': 4.670563697814941, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.00443942379206419, 'loss_2': 0.00733184814453125, 'loss_3': -16.409305572509766, 'loss_4': 0.6886787414550781, 'epoch': 15.62}
{'loss': 0.0063, 'grad_norm': 4.973134994506836, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.00433973828330636, 'loss_2': 0.00193023681640625, 'loss_3': -16.305160522460938, 'loss_4': 0.9277505874633789, 'epoch': 15.62}
{'loss': 0.0089, 'grad_norm': 5.312093257904053, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.008221369236707687, 'loss_2': 0.000667572021484375, 'loss_3': -16.383094787597656, 'loss_4': 0.7526791095733643, 'epoch': 15.63}
{'loss': 0.0306, 'grad_norm': 11.755071640014648, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.022269854322075844, 'loss_2': 0.00832366943359375, 'loss_3': -16.300512313842773, 'loss_4': 0.6370334625244141, 'epoch': 15.63}
{'loss': 0.0083, 'grad_norm': 4.441882610321045, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.004821857437491417, 'loss_2': 0.00347900390625, 'loss_3': -16.351970672607422, 'loss_4': 0.5212682485580444, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 13:27:23,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:23,053 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:42<42:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:30,394 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023575345054268837, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.775, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.018734198063611984, 'eval_loss_2': 0.004841148853302002, 'eval_loss_3': -18.16745376586914, 'eval_loss_4': 0.35519152879714966, 'epoch': 15.64}
{'loss': 0.0158, 'grad_norm': 9.37138843536377, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.012551583349704742, 'loss_2': 0.00322723388671875, 'loss_3': -16.43523406982422, 'loss_4': 0.7936381101608276, 'epoch': 15.65}
{'loss': 0.0124, 'grad_norm': 4.942066669464111, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.006364210043102503, 'loss_2': 0.00605010986328125, 'loss_3': -16.193166732788086, 'loss_4': 0.22130781412124634, 'epoch': 15.65}
{'loss': 0.016, 'grad_norm': 5.456815719604492, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.006101211067289114, 'loss_2': 0.009857177734375, 'loss_3': -16.363555908203125, 'loss_4': 0.9303492307662964, 'epoch': 15.66}
{'loss': 0.0178, 'grad_norm': 5.156515121459961, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.008160421624779701, 'loss_2': 0.00960540771484375, 'loss_3': -16.376689910888672, 'loss_4': 0.8593063354492188, 'epoch': 15.66}
{'loss': 0.0065, 'grad_norm': 4.988025665283203, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.004807397723197937, 'loss_2': 0.0016689300537109375, 'loss_3': -16.217708587646484, 'loss_4': 0.6367774605751038, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 13:27:30,394 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:30,394 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:49<42:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:37,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024345707148313522, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.004, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01960695907473564, 'eval_loss_2': 0.004738748073577881, 'eval_loss_3': -18.176063537597656, 'eval_loss_4': 0.5069729685783386, 'epoch': 15.67}
{'loss': 0.0099, 'grad_norm': 4.911970615386963, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.006133427377790213, 'loss_2': 0.0037384033203125, 'loss_3': -16.335641860961914, 'loss_4': 0.6962310075759888, 'epoch': 15.67}
{'loss': 0.012, 'grad_norm': 4.975890636444092, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.005569658242166042, 'loss_2': 0.006458282470703125, 'loss_3': -16.400400161743164, 'loss_4': 0.4962848424911499, 'epoch': 15.68}
{'loss': 0.0114, 'grad_norm': 5.476160049438477, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.010430919006466866, 'loss_2': 0.001018524169921875, 'loss_3': -16.3186092376709, 'loss_4': 0.912460207939148, 'epoch': 15.69}
{'loss': 0.0102, 'grad_norm': 6.206601142883301, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.009745213203132153, 'loss_2': 0.0004870891571044922, 'loss_3': -16.393146514892578, 'loss_4': 0.7083463668823242, 'epoch': 15.69}
{'loss': 0.0226, 'grad_norm': 9.740779876708984, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.021451858803629875, 'loss_2': 0.0011224746704101562, 'loss_3': -16.321693420410156, 'loss_4': 0.18759942054748535, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 13:27:37,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:37,734 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:06:57<42:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:45,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021700657904148102, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.277, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.019320031628012657, 'eval_loss_2': 0.0023806244134902954, 'eval_loss_3': -18.175708770751953, 'eval_loss_4': 0.8103285431861877, 'epoch': 15.7}
{'loss': 0.0087, 'grad_norm': 5.278545379638672, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.007477985229343176, 'loss_2': 0.0012035369873046875, 'loss_3': -16.416393280029297, 'loss_4': 0.6365036368370056, 'epoch': 15.7}
{'loss': 0.0094, 'grad_norm': 4.618150234222412, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.006274106912314892, 'loss_2': 0.0031490325927734375, 'loss_3': -16.4742488861084, 'loss_4': 1.363415002822876, 'epoch': 15.71}
{'loss': 0.008, 'grad_norm': 4.11864709854126, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.004429485648870468, 'loss_2': 0.003566741943359375, 'loss_3': -16.537229537963867, 'loss_4': 0.9453415274620056, 'epoch': 15.72}
{'loss': 0.0204, 'grad_norm': 8.474656105041504, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.013731060549616814, 'loss_2': 0.0066375732421875, 'loss_3': -16.324893951416016, 'loss_4': 1.2902024984359741, 'epoch': 15.72}
{'loss': 0.0181, 'grad_norm': 6.198237895965576, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.015102293342351913, 'loss_2': 0.0029754638671875, 'loss_3': -16.22690200805664, 'loss_4': 1.5535145998001099, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 13:27:45,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:45,073 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:07:04<42:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:52,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026006465777754784, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.072, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01947689801454544, 'eval_loss_2': 0.006529569625854492, 'eval_loss_3': -18.181978225708008, 'eval_loss_4': 1.153153657913208, 'epoch': 15.73}
{'loss': 0.0264, 'grad_norm': 7.184434413909912, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.016779933124780655, 'loss_2': 0.00958251953125, 'loss_3': -16.23973846435547, 'loss_4': 1.0025886297225952, 'epoch': 15.73}
{'loss': 0.0212, 'grad_norm': 7.879944801330566, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.0172869972884655, 'loss_2': 0.00391387939453125, 'loss_3': -16.289403915405273, 'loss_4': 0.9313831329345703, 'epoch': 15.74}
{'loss': 0.0454, 'grad_norm': 21.681011199951172, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.032024282962083817, 'loss_2': 0.01335906982421875, 'loss_3': -16.362802505493164, 'loss_4': 1.6415691375732422, 'epoch': 15.74}
{'loss': 0.0202, 'grad_norm': 7.095149517059326, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.014183664694428444, 'loss_2': 0.006000518798828125, 'loss_3': -16.236698150634766, 'loss_4': 1.6903014183044434, 'epoch': 15.75}
{'loss': 0.0131, 'grad_norm': 4.307707786560059, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.004881903529167175, 'loss_2': 0.0082550048828125, 'loss_3': -16.22989273071289, 'loss_4': 0.9247181415557861, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 13:27:52,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:52,411 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:07:11<42:50,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:27:59,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027797820046544075, 'eval_runtime': 3.9868, 'eval_samples_per_second': 256.848, 'eval_steps_per_second': 4.013, 'eval_loss_1': 0.020875006914138794, 'eval_loss_2': 0.006922811269760132, 'eval_loss_3': -18.184232711791992, 'eval_loss_4': 1.4807159900665283, 'epoch': 15.76}
{'loss': 0.0379, 'grad_norm': 13.985849380493164, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.03448564559221268, 'loss_2': 0.00342559814453125, 'loss_3': -16.50041389465332, 'loss_4': 2.028892755508423, 'epoch': 15.76}
{'loss': 0.0459, 'grad_norm': 11.560553550720215, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.04060807451605797, 'loss_2': 0.005298614501953125, 'loss_3': -16.061561584472656, 'loss_4': 1.799588680267334, 'epoch': 15.77}
{'loss': 0.0283, 'grad_norm': 9.634922981262207, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.021913709118962288, 'loss_2': 0.0064239501953125, 'loss_3': -16.32530975341797, 'loss_4': 1.5681877136230469, 'epoch': 15.77}
{'loss': 0.0242, 'grad_norm': 5.888444900512695, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.013272290118038654, 'loss_2': 0.0109100341796875, 'loss_3': -16.247169494628906, 'loss_4': 1.7672600746154785, 'epoch': 15.78}
{'loss': 0.0118, 'grad_norm': 5.507595062255859, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.0103834830224514, 'loss_2': 0.0014629364013671875, 'loss_3': -16.459293365478516, 'loss_4': 1.8768458366394043, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 13:27:59,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:59,944 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:19<42:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:07,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022626008838415146, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.938, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.019950296729803085, 'eval_loss_2': 0.0026757121086120605, 'eval_loss_3': -18.20830726623535, 'eval_loss_4': 1.5686306953430176, 'epoch': 15.78}
{'loss': 0.0165, 'grad_norm': 4.988609313964844, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.009547674097120762, 'loss_2': 0.006992340087890625, 'loss_3': -16.533720016479492, 'loss_4': 1.4714269638061523, 'epoch': 15.79}
{'loss': 0.0509, 'grad_norm': 13.483264923095703, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.049923889338970184, 'loss_2': 0.0009722709655761719, 'loss_3': -16.291500091552734, 'loss_4': 1.578823208808899, 'epoch': 15.8}
{'loss': 0.0105, 'grad_norm': 4.450217247009277, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.006120653823018074, 'loss_2': 0.004367828369140625, 'loss_3': -16.386627197265625, 'loss_4': 1.84840989112854, 'epoch': 15.8}
{'loss': 0.008, 'grad_norm': 4.596796035766602, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.00755841052159667, 'loss_2': 0.0004036426544189453, 'loss_3': -16.1773624420166, 'loss_4': 1.4089425802230835, 'epoch': 15.81}
{'loss': 0.0121, 'grad_norm': 4.933493137359619, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.007562451064586639, 'loss_2': 0.004581451416015625, 'loss_3': -16.429183959960938, 'loss_4': 1.8108983039855957, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 13:28:07,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:07,284 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:26<42:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:14,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024838246405124664, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.188, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.020368734374642372, 'eval_loss_2': 0.004469513893127441, 'eval_loss_3': -18.205869674682617, 'eval_loss_4': 1.4692716598510742, 'epoch': 15.81}
{'loss': 0.0082, 'grad_norm': 4.885859489440918, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.005031286273151636, 'loss_2': 0.0031223297119140625, 'loss_3': -16.256181716918945, 'loss_4': 1.2352566719055176, 'epoch': 15.82}
{'loss': 0.0171, 'grad_norm': 5.486349582672119, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.010821836069226265, 'loss_2': 0.00626373291015625, 'loss_3': -16.364517211914062, 'loss_4': 1.4630799293518066, 'epoch': 15.83}
{'loss': 0.028, 'grad_norm': 9.968518257141113, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.02527759224176407, 'loss_2': 0.0027027130126953125, 'loss_3': -16.4075870513916, 'loss_4': 1.659338116645813, 'epoch': 15.83}
{'loss': 0.0174, 'grad_norm': 5.1933674812316895, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.007580520585179329, 'loss_2': 0.0097808837890625, 'loss_3': -16.538999557495117, 'loss_4': 1.9827938079833984, 'epoch': 15.84}
{'loss': 0.0128, 'grad_norm': 5.300858974456787, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.008109095506370068, 'loss_2': 0.004734039306640625, 'loss_3': -16.183670043945312, 'loss_4': 0.8528745174407959, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 13:28:14,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:14,620 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:33<41:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:21,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027457186952233315, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.224, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.022514797747135162, 'eval_loss_2': 0.004942387342453003, 'eval_loss_3': -18.17192840576172, 'eval_loss_4': 1.223333477973938, 'epoch': 15.84}
{'loss': 0.0186, 'grad_norm': 7.018964767456055, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.01758791133761406, 'loss_2': 0.00099945068359375, 'loss_3': -16.41423797607422, 'loss_4': 1.3346014022827148, 'epoch': 15.85}
{'loss': 0.0123, 'grad_norm': 4.655717849731445, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.007314387243241072, 'loss_2': 0.00496673583984375, 'loss_3': -16.43447494506836, 'loss_4': 1.4813942909240723, 'epoch': 15.85}
{'loss': 0.0163, 'grad_norm': 6.2389140129089355, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.010940110310912132, 'loss_2': 0.005352020263671875, 'loss_3': -16.40811538696289, 'loss_4': 0.7046314477920532, 'epoch': 15.86}
{'loss': 0.0195, 'grad_norm': 5.865672588348389, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.01528247445821762, 'loss_2': 0.00421142578125, 'loss_3': -16.29764175415039, 'loss_4': 1.0400094985961914, 'epoch': 15.87}
{'loss': 0.019, 'grad_norm': 6.010135650634766, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.009927227161824703, 'loss_2': 0.0090789794921875, 'loss_3': -16.24529266357422, 'loss_4': 0.949042558670044, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 13:28:21,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:21,945 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:41<41:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:29,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027356768026947975, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.348, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.024474062025547028, 'eval_loss_2': 0.002882707864046097, 'eval_loss_3': -18.160621643066406, 'eval_loss_4': 1.0424435138702393, 'epoch': 15.87}
{'loss': 0.05, 'grad_norm': 20.81683349609375, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.04851138964295387, 'loss_2': 0.0015163421630859375, 'loss_3': -16.28152084350586, 'loss_4': 0.9569569230079651, 'epoch': 15.88}
{'loss': 0.0127, 'grad_norm': 5.452545166015625, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.011022424325346947, 'loss_2': 0.0017042160034179688, 'loss_3': -16.40645408630371, 'loss_4': 1.8168662786483765, 'epoch': 15.88}
{'loss': 0.077, 'grad_norm': 26.96281623840332, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.0738128051161766, 'loss_2': 0.0032329559326171875, 'loss_3': -16.397842407226562, 'loss_4': 1.1114360094070435, 'epoch': 15.89}
{'loss': 0.016, 'grad_norm': 5.419070243835449, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.010859057307243347, 'loss_2': 0.005092620849609375, 'loss_3': -16.440650939941406, 'loss_4': 1.3956586122512817, 'epoch': 15.9}
{'loss': 0.0179, 'grad_norm': 7.15119743347168, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.016871336847543716, 'loss_2': 0.0010204315185546875, 'loss_3': -16.157886505126953, 'loss_4': 0.8040106296539307, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 13:28:29,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:29,272 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:48<41:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:36,599 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029907111078500748, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.296, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.027004297822713852, 'eval_loss_2': 0.002902816981077194, 'eval_loss_3': -18.153596878051758, 'eval_loss_4': 0.9455121159553528, 'epoch': 15.9}
{'loss': 0.0072, 'grad_norm': 5.622561931610107, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.007063455414026976, 'loss_2': 9.578466415405273e-05, 'loss_3': -16.388626098632812, 'loss_4': 1.5435295104980469, 'epoch': 15.91}
{'loss': 0.016, 'grad_norm': 5.789892196655273, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.013361042365431786, 'loss_2': 0.002658843994140625, 'loss_3': -16.324859619140625, 'loss_4': 1.54744553565979, 'epoch': 15.91}
{'loss': 0.0108, 'grad_norm': 5.542219638824463, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.009146343916654587, 'loss_2': 0.0016422271728515625, 'loss_3': -16.177364349365234, 'loss_4': 1.3397310972213745, 'epoch': 15.92}
{'loss': 0.0121, 'grad_norm': 5.755590438842773, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.008216832764446735, 'loss_2': 0.003894805908203125, 'loss_3': -16.37653350830078, 'loss_4': 1.2806870937347412, 'epoch': 15.92}
{'loss': 0.0144, 'grad_norm': 6.210638999938965, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.013084562495350838, 'loss_2': 0.0013179779052734375, 'loss_3': -16.46941375732422, 'loss_4': 1.1863336563110352, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 13:28:36,599 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:36,599 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:07:55<41:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:43,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.038707174360752106, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.073, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.034883178770542145, 'eval_loss_2': 0.003823995590209961, 'eval_loss_3': -18.11663055419922, 'eval_loss_4': 1.0020503997802734, 'epoch': 15.93}
{'loss': 0.0121, 'grad_norm': 5.15685510635376, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.008246845565736294, 'loss_2': 0.003879547119140625, 'loss_3': -16.28541374206543, 'loss_4': 1.1108065843582153, 'epoch': 15.94}
{'loss': 0.0088, 'grad_norm': 4.93101167678833, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.005936764180660248, 'loss_2': 0.0028629302978515625, 'loss_3': -16.390674591064453, 'loss_4': 0.7580610513687134, 'epoch': 15.94}
{'loss': 0.017, 'grad_norm': 6.311629295349121, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.009932523593306541, 'loss_2': 0.00702667236328125, 'loss_3': -16.279226303100586, 'loss_4': 0.9717715382575989, 'epoch': 15.95}
{'loss': 0.0218, 'grad_norm': 8.186463356018066, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.012522127479314804, 'loss_2': 0.0092620849609375, 'loss_3': -16.32391357421875, 'loss_4': 0.5646380186080933, 'epoch': 15.95}
{'loss': 0.0101, 'grad_norm': 4.9576592445373535, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.007289470639079809, 'loss_2': 0.0028228759765625, 'loss_3': -16.195430755615234, 'loss_4': 1.2198302745819092, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 13:28:43,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:43,934 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:08:03<41:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:51,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04759024456143379, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.814, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.04322518780827522, 'eval_loss_2': 0.004365056753158569, 'eval_loss_3': -18.080718994140625, 'eval_loss_4': 1.0441640615463257, 'epoch': 15.96}
{'loss': 0.0059, 'grad_norm': 4.567500114440918, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.005841042380779982, 'loss_2': 9.72747802734375e-05, 'loss_3': -16.236364364624023, 'loss_4': 1.4156174659729004, 'epoch': 15.97}
{'loss': 0.0178, 'grad_norm': 6.0944085121154785, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.015582963824272156, 'loss_2': 0.002254486083984375, 'loss_3': -16.190631866455078, 'loss_4': 1.301769733428955, 'epoch': 15.97}
{'loss': 0.0288, 'grad_norm': 8.212137222290039, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.024454494938254356, 'loss_2': 0.004375457763671875, 'loss_3': -16.1994686126709, 'loss_4': 0.8246290683746338, 'epoch': 15.98}
{'loss': 0.0071, 'grad_norm': 4.881092548370361, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.006555142812430859, 'loss_2': 0.0005373954772949219, 'loss_3': -16.479936599731445, 'loss_4': 1.4727782011032104, 'epoch': 15.98}
{'loss': 0.009, 'grad_norm': 4.500368118286133, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.004895260091871023, 'loss_2': 0.00409698486328125, 'loss_3': -16.11368751525879, 'loss_4': 1.33416748046875, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 13:28:51,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:51,275 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:08:10<40:21,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:28:58,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06631148606538773, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.277, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.06147417798638344, 'eval_loss_2': 0.004837304353713989, 'eval_loss_3': -18.030275344848633, 'eval_loss_4': 1.0704436302185059, 'epoch': 15.99}
{'loss': 0.015, 'grad_norm': 6.740952968597412, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.0119205042719841, 'loss_2': 0.0030975341796875, 'loss_3': -16.31760597229004, 'loss_4': 1.6544685363769531, 'epoch': 15.99}
{'loss': 0.0095, 'grad_norm': 7.650228500366211, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.00850155670195818, 'loss_2': 0.0010471343994140625, 'loss_3': -16.095975875854492, 'loss_4': 1.7105509042739868, 'epoch': 16.0}
{'loss': 0.0067, 'grad_norm': 4.847875118255615, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.006430283188819885, 'loss_2': 0.0002727508544921875, 'loss_3': -16.331138610839844, 'loss_4': 1.0907461643218994, 'epoch': 16.01}
{'loss': 0.0452, 'grad_norm': 19.779146194458008, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.04331226646900177, 'loss_2': 0.0019073486328125, 'loss_3': -15.907907485961914, 'loss_4': 1.1530015468597412, 'epoch': 16.01}
{'loss': 0.0093, 'grad_norm': 5.15716552734375, 'learning_rate': 1.4e-05, 'loss_1': 0.004218465648591518, 'loss_2': 0.005126953125, 'loss_3': -16.515640258789062, 'loss_4': 1.0437039136886597, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 13:28:58,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:58,297 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:17<41:14,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:29:05,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06920009106397629, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.198, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.06640765815973282, 'eval_loss_2': 0.0027924329042434692, 'eval_loss_3': -18.01786994934082, 'eval_loss_4': 0.9454106688499451, 'epoch': 16.02}
{'loss': 0.0866, 'grad_norm': 20.563167572021484, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.07814578711986542, 'loss_2': 0.0084381103515625, 'loss_3': -16.614622116088867, 'loss_4': 1.0430017709732056, 'epoch': 16.02}
{'loss': 0.0092, 'grad_norm': 5.965149402618408, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.008747287094593048, 'loss_2': 0.0004448890686035156, 'loss_3': -16.260761260986328, 'loss_4': 1.0532385110855103, 'epoch': 16.03}
{'loss': 0.0139, 'grad_norm': 6.145575523376465, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.013792571611702442, 'loss_2': 0.0001385211944580078, 'loss_3': -16.09809112548828, 'loss_4': 1.2150641679763794, 'epoch': 16.03}
{'loss': 0.0431, 'grad_norm': 13.66091537475586, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.035779792815446854, 'loss_2': 0.00733184814453125, 'loss_3': -16.246736526489258, 'loss_4': 1.0080444812774658, 'epoch': 16.04}
{'loss': 0.0589, 'grad_norm': 5.100335597991943, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.05455910041928291, 'loss_2': 0.004329681396484375, 'loss_3': -16.178363800048828, 'loss_4': 0.6034895181655884, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 13:29:05,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:05,627 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:24<41:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:12,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06766606867313385, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.224, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.06416133046150208, 'eval_loss_2': 0.003504738211631775, 'eval_loss_3': -18.055219650268555, 'eval_loss_4': 0.5980604887008667, 'epoch': 16.05}
{'loss': 0.0159, 'grad_norm': 7.562325477600098, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.015822285786271095, 'loss_2': 8.386373519897461e-05, 'loss_3': -16.27579116821289, 'loss_4': 0.8974999785423279, 'epoch': 16.05}
{'loss': 0.0124, 'grad_norm': 5.490270137786865, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.008781807497143745, 'loss_2': 0.00357818603515625, 'loss_3': -16.415624618530273, 'loss_4': 0.8943086862564087, 'epoch': 16.06}
{'loss': 0.0287, 'grad_norm': 8.819479942321777, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.026845457032322884, 'loss_2': 0.0018901824951171875, 'loss_3': -16.44842529296875, 'loss_4': 0.5298160314559937, 'epoch': 16.06}
{'loss': 0.0083, 'grad_norm': 4.931036472320557, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.006513213273137808, 'loss_2': 0.0018024444580078125, 'loss_3': -16.166751861572266, 'loss_4': 0.4922744333744049, 'epoch': 16.07}
{'loss': 0.0144, 'grad_norm': 5.73149299621582, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.013571653515100479, 'loss_2': 0.0008516311645507812, 'loss_3': -16.40416717529297, 'loss_4': 0.09327422827482224, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 13:29:12,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:12,958 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:32<41:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:20,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.041466400027275085, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.331, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.03838559612631798, 'eval_loss_2': 0.003080800175666809, 'eval_loss_3': -18.131160736083984, 'eval_loss_4': 0.20808705687522888, 'epoch': 16.08}
{'loss': 0.0179, 'grad_norm': 11.740669250488281, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.015839530155062675, 'loss_2': 0.0020751953125, 'loss_3': -16.419132232666016, 'loss_4': 0.3449002504348755, 'epoch': 16.08}
{'loss': 0.0245, 'grad_norm': 10.16921615600586, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.020933736115694046, 'loss_2': 0.003582000732421875, 'loss_3': -16.2449951171875, 'loss_4': 0.34153372049331665, 'epoch': 16.09}
{'loss': 0.0122, 'grad_norm': 5.764403343200684, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.009151250123977661, 'loss_2': 0.0030078887939453125, 'loss_3': -16.332857131958008, 'loss_4': 0.3866141438484192, 'epoch': 16.09}
{'loss': 0.0101, 'grad_norm': 4.709166049957275, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.005502041894942522, 'loss_2': 0.0045928955078125, 'loss_3': -16.5177059173584, 'loss_4': -0.05804251879453659, 'epoch': 16.1}
{'loss': 0.0116, 'grad_norm': 4.718473434448242, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.006269363220781088, 'loss_2': 0.00536346435546875, 'loss_3': -16.55207633972168, 'loss_4': 0.020676981657743454, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 13:29:20,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:20,292 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:39<41:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:27,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02982063964009285, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.026922930032014847, 'eval_loss_2': 0.002897709608078003, 'eval_loss_3': -18.18030548095703, 'eval_loss_4': 0.03894029185175896, 'epoch': 16.1}
{'loss': 0.0105, 'grad_norm': 4.845551013946533, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.006716334726661444, 'loss_2': 0.0037975311279296875, 'loss_3': -16.44668960571289, 'loss_4': 0.525860607624054, 'epoch': 16.11}
{'loss': 0.0081, 'grad_norm': 5.302957534790039, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.007089017424732447, 'loss_2': 0.0010089874267578125, 'loss_3': -16.08285140991211, 'loss_4': 0.2883983552455902, 'epoch': 16.12}
{'loss': 0.0107, 'grad_norm': 5.05428409576416, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.003369725774973631, 'loss_2': 0.007312774658203125, 'loss_3': -16.47149085998535, 'loss_4': 0.10806065797805786, 'epoch': 16.12}
{'loss': 0.0084, 'grad_norm': 4.267975330352783, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.004628799390047789, 'loss_2': 0.00374603271484375, 'loss_3': -16.337556838989258, 'loss_4': -0.013800010085105896, 'epoch': 16.13}
{'loss': 0.0135, 'grad_norm': 5.416092395782471, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.009176289662718773, 'loss_2': 0.00431060791015625, 'loss_3': -16.35489273071289, 'loss_4': 0.057219862937927246, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 13:29:27,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:27,620 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:46<41:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:34,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028485625982284546, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.1, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.023292390629649162, 'eval_loss_2': 0.005193233489990234, 'eval_loss_3': -18.204376220703125, 'eval_loss_4': 0.009969484992325306, 'epoch': 16.13}
{'loss': 0.0118, 'grad_norm': 5.634189605712891, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.008883124217391014, 'loss_2': 0.0029239654541015625, 'loss_3': -16.249547958374023, 'loss_4': 0.20656225085258484, 'epoch': 16.14}
{'loss': 0.0086, 'grad_norm': 5.038578510284424, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.006282952148467302, 'loss_2': 0.002346038818359375, 'loss_3': -16.395004272460938, 'loss_4': -0.09107786417007446, 'epoch': 16.15}
{'loss': 0.0072, 'grad_norm': 4.876766681671143, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.006460931617766619, 'loss_2': 0.0007615089416503906, 'loss_3': -16.548561096191406, 'loss_4': -0.24284546077251434, 'epoch': 16.15}
{'loss': 0.0185, 'grad_norm': 5.503403186798096, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.00893388595432043, 'loss_2': 0.009521484375, 'loss_3': -16.324661254882812, 'loss_4': 0.5755397081375122, 'epoch': 16.16}
{'loss': 0.0135, 'grad_norm': 4.895151138305664, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.004116680007427931, 'loss_2': 0.00936126708984375, 'loss_3': -16.413644790649414, 'loss_4': 0.09043019264936447, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 13:29:34,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:34,950 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:08:54<40:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:42,278 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030216166749596596, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.425, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.022455165162682533, 'eval_loss_2': 0.0077610015869140625, 'eval_loss_3': -18.222450256347656, 'eval_loss_4': 0.00018486054614186287, 'epoch': 16.16}
{'loss': 0.0252, 'grad_norm': 7.482425212860107, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.016843169927597046, 'loss_2': 0.00835418701171875, 'loss_3': -16.521034240722656, 'loss_4': -0.08854495733976364, 'epoch': 16.17}
{'loss': 0.0359, 'grad_norm': 8.460701942443848, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.030096519738435745, 'loss_2': 0.00580596923828125, 'loss_3': -16.311832427978516, 'loss_4': 0.7425225973129272, 'epoch': 16.17}
{'loss': 0.0185, 'grad_norm': 6.045094966888428, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.00805035512894392, 'loss_2': 0.01044464111328125, 'loss_3': -16.296398162841797, 'loss_4': 0.5048843026161194, 'epoch': 16.18}
{'loss': 0.014, 'grad_norm': 5.3527655601501465, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.006952650845050812, 'loss_2': 0.0070343017578125, 'loss_3': -16.366954803466797, 'loss_4': 0.11225622147321701, 'epoch': 16.19}
{'loss': 0.0123, 'grad_norm': 5.403930187225342, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.005294038448482752, 'loss_2': 0.006999969482421875, 'loss_3': -16.35326385498047, 'loss_4': 0.2505500316619873, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 13:29:42,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:42,279 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:09:01<40:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:49,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024767957627773285, 'eval_runtime': 3.7853, 'eval_samples_per_second': 270.524, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01977105811238289, 'eval_loss_2': 0.004996895790100098, 'eval_loss_3': -18.245635986328125, 'eval_loss_4': -0.10893969237804413, 'epoch': 16.19}
{'loss': 0.0296, 'grad_norm': 8.494195938110352, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.02226310409605503, 'loss_2': 0.007305145263671875, 'loss_3': -16.504718780517578, 'loss_4': -0.05032084882259369, 'epoch': 16.2}
{'loss': 0.017, 'grad_norm': 6.351992130279541, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.010184611193835735, 'loss_2': 0.00677490234375, 'loss_3': -16.272958755493164, 'loss_4': 0.2140451967716217, 'epoch': 16.2}
{'loss': 0.0269, 'grad_norm': 7.976025104522705, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.020571814849972725, 'loss_2': 0.006328582763671875, 'loss_3': -16.31405258178711, 'loss_4': -0.024781353771686554, 'epoch': 16.21}
{'loss': 0.0079, 'grad_norm': 4.934706687927246, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.006091779097914696, 'loss_2': 0.0018482208251953125, 'loss_3': -16.318958282470703, 'loss_4': 0.20345216989517212, 'epoch': 16.22}
{'loss': 0.0221, 'grad_norm': 8.446917533874512, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.01931806094944477, 'loss_2': 0.002765655517578125, 'loss_3': -16.279155731201172, 'loss_4': -0.024281442165374756, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 13:29:49,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:49,606 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:09:08<40:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:56,939 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022533440962433815, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.949, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01867988333106041, 'eval_loss_2': 0.0038535594940185547, 'eval_loss_3': -18.25855255126953, 'eval_loss_4': -0.35058677196502686, 'epoch': 16.22}
{'loss': 0.017, 'grad_norm': 5.24221658706665, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.008169080130755901, 'loss_2': 0.008819580078125, 'loss_3': -16.271814346313477, 'loss_4': -0.0836205780506134, 'epoch': 16.23}
{'loss': 0.0479, 'grad_norm': 15.273859024047852, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.04050634801387787, 'loss_2': 0.00738525390625, 'loss_3': -16.246309280395508, 'loss_4': -0.22137035429477692, 'epoch': 16.23}
{'loss': 0.0197, 'grad_norm': 7.033660411834717, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.00864080898463726, 'loss_2': 0.0111083984375, 'loss_3': -16.376066207885742, 'loss_4': -0.3300277888774872, 'epoch': 16.24}
{'loss': 0.0314, 'grad_norm': 10.67436408996582, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.018489625304937363, 'loss_2': 0.0128631591796875, 'loss_3': -16.374582290649414, 'loss_4': -0.9809507131576538, 'epoch': 16.24}
{'loss': 0.0164, 'grad_norm': 6.331507205963135, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.010154151357710361, 'loss_2': 0.00628662109375, 'loss_3': -16.29559326171875, 'loss_4': -0.6656473278999329, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 13:29:56,939 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:56,939 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:16<40:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:04,266 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02546631172299385, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.273, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.018150320276618004, 'eval_loss_2': 0.007315993309020996, 'eval_loss_3': -18.263721466064453, 'eval_loss_4': -0.4699474573135376, 'epoch': 16.25}
{'loss': 0.0156, 'grad_norm': 4.607958793640137, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.005747130606323481, 'loss_2': 0.0098876953125, 'loss_3': -16.322927474975586, 'loss_4': -0.1720672845840454, 'epoch': 16.26}
{'loss': 0.0103, 'grad_norm': 4.947828769683838, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.006959577556699514, 'loss_2': 0.003330230712890625, 'loss_3': -16.44122314453125, 'loss_4': 0.05051625519990921, 'epoch': 16.26}
{'loss': 0.007, 'grad_norm': 5.039800643920898, 'learning_rate': 1.375e-05, 'loss_1': 0.00547844497486949, 'loss_2': 0.0015687942504882812, 'loss_3': -16.38991928100586, 'loss_4': -0.25909432768821716, 'epoch': 16.27}
{'loss': 0.0126, 'grad_norm': 7.224848747253418, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.012552664615213871, 'loss_2': 4.875659942626953e-05, 'loss_3': -16.50539207458496, 'loss_4': -0.30895209312438965, 'epoch': 16.27}
{'loss': 0.0185, 'grad_norm': 11.764906883239746, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.01797747053205967, 'loss_2': 0.00048828125, 'loss_3': -16.462963104248047, 'loss_4': 0.1161588653922081, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 13:30:04,266 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:04,267 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:23<40:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:11,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02380007691681385, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.098, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.02034205198287964, 'eval_loss_2': 0.0034580230712890625, 'eval_loss_3': -18.256807327270508, 'eval_loss_4': -0.4723069369792938, 'epoch': 16.28}
{'loss': 0.01, 'grad_norm': 5.183157920837402, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.006401675753295422, 'loss_2': 0.00360107421875, 'loss_3': -16.437026977539062, 'loss_4': -0.2469121515750885, 'epoch': 16.28}
{'loss': 0.0218, 'grad_norm': 7.46038293838501, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.0149851618334651, 'loss_2': 0.00681304931640625, 'loss_3': -16.39117431640625, 'loss_4': -0.26091235876083374, 'epoch': 16.29}
{'loss': 0.0192, 'grad_norm': 6.401939392089844, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.014407687820494175, 'loss_2': 0.00481414794921875, 'loss_3': -16.373884201049805, 'loss_4': -0.05877386033535004, 'epoch': 16.3}
{'loss': 0.0079, 'grad_norm': 7.386241912841797, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.0077053154818713665, 'loss_2': 0.00014591217041015625, 'loss_3': -16.383079528808594, 'loss_4': -0.2750822901725769, 'epoch': 16.3}
{'loss': 0.0184, 'grad_norm': 7.703807830810547, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.01794573664665222, 'loss_2': 0.0004191398620605469, 'loss_3': -16.3595027923584, 'loss_4': -0.20024463534355164, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 13:30:11,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:11,603 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:30<40:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:18,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027015388011932373, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.005, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.020370183512568474, 'eval_loss_2': 0.00664520263671875, 'eval_loss_3': -18.250457763671875, 'eval_loss_4': -0.4240325689315796, 'epoch': 16.31}
{'loss': 0.0173, 'grad_norm': 9.132792472839355, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.015875831246376038, 'loss_2': 0.0014400482177734375, 'loss_3': -16.164657592773438, 'loss_4': -0.18609172105789185, 'epoch': 16.31}
{'loss': 0.0116, 'grad_norm': 4.762253284454346, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.005554203409701586, 'loss_2': 0.00606536865234375, 'loss_3': -16.41167449951172, 'loss_4': 0.10257630795240402, 'epoch': 16.32}
{'loss': 0.0196, 'grad_norm': 8.24773120880127, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.014283721335232258, 'loss_2': 0.005340576171875, 'loss_3': -16.53857421875, 'loss_4': -0.45415571331977844, 'epoch': 16.33}
{'loss': 0.0178, 'grad_norm': 4.682773590087891, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.009844895452260971, 'loss_2': 0.00791168212890625, 'loss_3': -16.45138168334961, 'loss_4': -0.010987013578414917, 'epoch': 16.33}
{'loss': 0.0162, 'grad_norm': 6.355756759643555, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.01030243095010519, 'loss_2': 0.005931854248046875, 'loss_3': -16.51984977722168, 'loss_4': -0.013785921037197113, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 13:30:18,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:18,931 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:38<40:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:26,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02993549220263958, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.218, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.022441279143095016, 'eval_loss_2': 0.007494211196899414, 'eval_loss_3': -18.208288192749023, 'eval_loss_4': -0.223425954580307, 'epoch': 16.34}
{'loss': 0.0169, 'grad_norm': 6.33375358581543, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.016120420768857002, 'loss_2': 0.0007810592651367188, 'loss_3': -16.259429931640625, 'loss_4': -0.14569851756095886, 'epoch': 16.34}
{'loss': 0.0178, 'grad_norm': 4.879160404205322, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.006674290169030428, 'loss_2': 0.0111541748046875, 'loss_3': -16.319856643676758, 'loss_4': 0.8764070272445679, 'epoch': 16.35}
{'loss': 0.0148, 'grad_norm': 5.006677150726318, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.006288151256740093, 'loss_2': 0.0084686279296875, 'loss_3': -16.339614868164062, 'loss_4': 0.1499955952167511, 'epoch': 16.35}
{'loss': 0.0185, 'grad_norm': 6.328413963317871, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.01747419685125351, 'loss_2': 0.0009937286376953125, 'loss_3': -16.40930938720703, 'loss_4': 0.23804734647274017, 'epoch': 16.36}
{'loss': 0.01, 'grad_norm': 5.224308013916016, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.009719894267618656, 'loss_2': 0.0002582073211669922, 'loss_3': -16.337207794189453, 'loss_4': -0.005299568176269531, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 13:30:26,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:26,265 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:45<40:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:33,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024620071053504944, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.411, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.02149106375873089, 'eval_loss_2': 0.0031290054321289062, 'eval_loss_3': -18.19359016418457, 'eval_loss_4': -0.254568487405777, 'epoch': 16.37}
{'loss': 0.0154, 'grad_norm': 6.202998638153076, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.013705919496715069, 'loss_2': 0.0016956329345703125, 'loss_3': -16.280839920043945, 'loss_4': 0.07853154838085175, 'epoch': 16.37}
{'loss': 0.0109, 'grad_norm': 4.774404048919678, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.005400682333856821, 'loss_2': 0.005458831787109375, 'loss_3': -16.42940330505371, 'loss_4': -0.2726801037788391, 'epoch': 16.38}
{'loss': 0.0187, 'grad_norm': 6.560544490814209, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.016348136588931084, 'loss_2': 0.002391815185546875, 'loss_3': -16.544879913330078, 'loss_4': -0.35640066862106323, 'epoch': 16.38}
{'loss': 0.013, 'grad_norm': 5.279983043670654, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.010622804053127766, 'loss_2': 0.002368927001953125, 'loss_3': -16.156505584716797, 'loss_4': -0.3014383316040039, 'epoch': 16.39}
{'loss': 0.0408, 'grad_norm': 15.022564888000488, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.037267476320266724, 'loss_2': 0.003482818603515625, 'loss_3': -16.298437118530273, 'loss_4': -0.021825402975082397, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 13:30:33,592 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:33,592 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:09:52<40:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:40,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026539873331785202, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.47, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.022378424182534218, 'eval_loss_2': 0.004161447286605835, 'eval_loss_3': -18.185335159301758, 'eval_loss_4': -0.31788313388824463, 'epoch': 16.4}
{'loss': 0.0111, 'grad_norm': 7.142974376678467, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.009680566377937794, 'loss_2': 0.0013933181762695312, 'loss_3': -16.391189575195312, 'loss_4': 0.4013197124004364, 'epoch': 16.4}
{'loss': 0.0101, 'grad_norm': 5.697697639465332, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.007558735553175211, 'loss_2': 0.0025768280029296875, 'loss_3': -16.34136962890625, 'loss_4': -0.0823533684015274, 'epoch': 16.41}
{'loss': 0.0087, 'grad_norm': 4.927068710327148, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.0061004674062132835, 'loss_2': 0.0025634765625, 'loss_3': -16.3369140625, 'loss_4': -0.17696376144886017, 'epoch': 16.41}
{'loss': 0.0122, 'grad_norm': 5.219229698181152, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.006035263184458017, 'loss_2': 0.0061492919921875, 'loss_3': -16.203643798828125, 'loss_4': 0.637474000453949, 'epoch': 16.42}
{'loss': 0.0164, 'grad_norm': 7.908798694610596, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.012301082722842693, 'loss_2': 0.0041046142578125, 'loss_3': -16.37110137939453, 'loss_4': -0.4497716426849365, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 13:30:40,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:40,918 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:10:00<40:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:48,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027755621820688248, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.987, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.022953853011131287, 'eval_loss_2': 0.0048017725348472595, 'eval_loss_3': -18.175254821777344, 'eval_loss_4': -0.43084198236465454, 'epoch': 16.42}
{'loss': 0.0125, 'grad_norm': 4.473735809326172, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.006068570073693991, 'loss_2': 0.006412506103515625, 'loss_3': -16.343246459960938, 'loss_4': -0.14611175656318665, 'epoch': 16.43}
{'loss': 0.0165, 'grad_norm': 7.706190586090088, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.011157279834151268, 'loss_2': 0.00537109375, 'loss_3': -16.217512130737305, 'loss_4': -0.050158075988292694, 'epoch': 16.44}
{'loss': 0.0205, 'grad_norm': 10.204936981201172, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.013342617079615593, 'loss_2': 0.0071563720703125, 'loss_3': -16.23293685913086, 'loss_4': -0.30080220103263855, 'epoch': 16.44}
{'loss': 0.0074, 'grad_norm': 4.694772243499756, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.005216221325099468, 'loss_2': 0.002170562744140625, 'loss_3': -16.38274383544922, 'loss_4': -0.13208463788032532, 'epoch': 16.45}
{'loss': 0.0111, 'grad_norm': 5.573331356048584, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.009955450892448425, 'loss_2': 0.0011806488037109375, 'loss_3': -16.394546508789062, 'loss_4': 0.21322597563266754, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 13:30:48,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:48,247 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:10:07<40:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:30:55,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027895305305719376, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.98, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.02362872287631035, 'eval_loss_2': 0.004266582429409027, 'eval_loss_3': -18.148488998413086, 'eval_loss_4': -0.37523749470710754, 'epoch': 16.45}
{'loss': 0.0074, 'grad_norm': 5.6142578125, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.005661909002810717, 'loss_2': 0.0017442703247070312, 'loss_3': -16.33460235595703, 'loss_4': -0.059784963726997375, 'epoch': 16.46}
{'loss': 0.0588, 'grad_norm': 20.085031509399414, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.057342685759067535, 'loss_2': 0.00144195556640625, 'loss_3': -16.01799201965332, 'loss_4': 0.005458477884531021, 'epoch': 16.47}
{'loss': 0.0159, 'grad_norm': 5.318822860717773, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.00875664409250021, 'loss_2': 0.007183074951171875, 'loss_3': -16.475488662719727, 'loss_4': 0.37823033332824707, 'epoch': 16.47}
{'loss': 0.0252, 'grad_norm': 10.061474800109863, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.021697338670492172, 'loss_2': 0.00354766845703125, 'loss_3': -16.118764877319336, 'loss_4': 0.4802885055541992, 'epoch': 16.48}
{'loss': 0.0171, 'grad_norm': 6.856780052185059, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.014755917713046074, 'loss_2': 0.00237274169921875, 'loss_3': -16.248132705688477, 'loss_4': -0.15598106384277344, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 13:30:55,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:55,578 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:14<40:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:02,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03966086357831955, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.03512903302907944, 'eval_loss_2': 0.004531830549240112, 'eval_loss_3': -18.080978393554688, 'eval_loss_4': -0.33555111289024353, 'epoch': 16.48}
{'loss': 0.0087, 'grad_norm': 4.795608043670654, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.006892713252454996, 'loss_2': 0.0017910003662109375, 'loss_3': -16.437152862548828, 'loss_4': -0.14193284511566162, 'epoch': 16.49}
{'loss': 0.0341, 'grad_norm': 17.853103637695312, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.02834940142929554, 'loss_2': 0.005764007568359375, 'loss_3': -16.24427032470703, 'loss_4': -0.14923344552516937, 'epoch': 16.49}
{'loss': 0.0182, 'grad_norm': 6.809145927429199, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.01578129082918167, 'loss_2': 0.00241851806640625, 'loss_3': -16.06925392150879, 'loss_4': -0.11144383251667023, 'epoch': 16.5}
{'loss': 0.0191, 'grad_norm': 6.899171829223633, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.014974912628531456, 'loss_2': 0.004131317138671875, 'loss_3': -16.120285034179688, 'loss_4': -0.3820640444755554, 'epoch': 16.51}
{'loss': 0.0146, 'grad_norm': 6.781503200531006, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.008132307790219784, 'loss_2': 0.0064239501953125, 'loss_3': -16.336071014404297, 'loss_4': 0.056241557002067566, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 13:31:02,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:02,903 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:22<39:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:10,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.055203620344400406, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.513, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.052371516823768616, 'eval_loss_2': 0.00283210352063179, 'eval_loss_3': -18.028772354125977, 'eval_loss_4': -0.238779678940773, 'epoch': 16.51}
{'loss': 0.0196, 'grad_norm': 5.53342342376709, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.009843447245657444, 'loss_2': 0.0097503662109375, 'loss_3': -16.227497100830078, 'loss_4': -0.2513119578361511, 'epoch': 16.52}
{'loss': 0.014, 'grad_norm': 5.934286594390869, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.009683768264949322, 'loss_2': 0.004364013671875, 'loss_3': -16.048439025878906, 'loss_4': 0.20238427817821503, 'epoch': 16.52}
{'loss': 0.0333, 'grad_norm': 17.585289001464844, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.03236866742372513, 'loss_2': 0.0009050369262695312, 'loss_3': -16.323060989379883, 'loss_4': -0.014398157596588135, 'epoch': 16.53}
{'loss': 0.0098, 'grad_norm': 4.521552085876465, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.00571406539529562, 'loss_2': 0.004062652587890625, 'loss_3': -16.308452606201172, 'loss_4': 0.2751151919364929, 'epoch': 16.53}
{'loss': 0.0835, 'grad_norm': inf, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.07673332095146179, 'loss_2': 0.006755828857421875, 'loss_3': -16.157886505126953, 'loss_4': 0.21696242690086365, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 13:31:10,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:10,217 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:29<39:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:31:17,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07723287492990494, 'eval_runtime': 3.7827, 'eval_samples_per_second': 270.705, 'eval_steps_per_second': 4.23, 'eval_loss_1': 0.07439706474542618, 'eval_loss_2': 0.0028358101844787598, 'eval_loss_3': -17.975818634033203, 'eval_loss_4': -0.1901780217885971, 'epoch': 16.54}
{'loss': 0.0172, 'grad_norm': 5.487410068511963, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.011158686131238937, 'loss_2': 0.00601959228515625, 'loss_3': -16.338382720947266, 'loss_4': 0.019330978393554688, 'epoch': 16.55}
{'loss': 0.0182, 'grad_norm': 8.15672779083252, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.014446456916630268, 'loss_2': 0.00371551513671875, 'loss_3': -16.187088012695312, 'loss_4': 0.2783561646938324, 'epoch': 16.55}
{'loss': 0.0145, 'grad_norm': 11.997700691223145, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.010962204076349735, 'loss_2': 0.0035858154296875, 'loss_3': -16.307628631591797, 'loss_4': -0.09359218180179596, 'epoch': 16.56}
{'loss': 0.023, 'grad_norm': 7.626313209533691, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.01975190080702305, 'loss_2': 0.003265380859375, 'loss_3': -16.16993522644043, 'loss_4': -0.06101216375827789, 'epoch': 16.56}
{'loss': 0.0187, 'grad_norm': 7.138557434082031, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.017865130677819252, 'loss_2': 0.00084686279296875, 'loss_3': -16.353635787963867, 'loss_4': 0.2681626081466675, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 13:31:17,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:17,535 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:36<39:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:31:24,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07933621108531952, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.343, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.07639117538928986, 'eval_loss_2': 0.002945035696029663, 'eval_loss_3': -17.966182708740234, 'eval_loss_4': -0.1697869598865509, 'epoch': 16.57}
{'loss': 0.0704, 'grad_norm': 22.398921966552734, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.06574384868144989, 'loss_2': 0.004669189453125, 'loss_3': -16.104473114013672, 'loss_4': -0.28732556104660034, 'epoch': 16.58}
{'loss': 0.0119, 'grad_norm': 6.177119731903076, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.010685297660529613, 'loss_2': 0.0011768341064453125, 'loss_3': -16.460636138916016, 'loss_4': 0.312818706035614, 'epoch': 16.58}
{'loss': 0.0157, 'grad_norm': 7.168067455291748, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.01406608335673809, 'loss_2': 0.0016651153564453125, 'loss_3': -16.273300170898438, 'loss_4': 0.31794482469558716, 'epoch': 16.59}
{'loss': 0.0076, 'grad_norm': 4.800858974456787, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.006099125370383263, 'loss_2': 0.0015239715576171875, 'loss_3': -16.45627784729004, 'loss_4': 0.36511969566345215, 'epoch': 16.59}
{'loss': 0.0196, 'grad_norm': 7.5212602615356445, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.01361575722694397, 'loss_2': 0.006011962890625, 'loss_3': -16.47338104248047, 'loss_4': -0.0030267201364040375, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 13:31:24,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:24,862 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:44<39:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:32,197 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028533849865198135, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.026241939514875412, 'eval_loss_2': 0.0022919103503227234, 'eval_loss_3': -18.146997451782227, 'eval_loss_4': -0.08571072667837143, 'epoch': 16.6}
{'loss': 0.0095, 'grad_norm': 5.092981815338135, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.006411388982087374, 'loss_2': 0.003082275390625, 'loss_3': -16.366039276123047, 'loss_4': 0.14286577701568604, 'epoch': 16.6}
{'loss': 0.0148, 'grad_norm': 7.119695663452148, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.014326149597764015, 'loss_2': 0.0004887580871582031, 'loss_3': -16.244091033935547, 'loss_4': 0.2806016206741333, 'epoch': 16.61}
{'loss': 0.0152, 'grad_norm': 6.0639472007751465, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.013112462125718594, 'loss_2': 0.002124786376953125, 'loss_3': -16.30345916748047, 'loss_4': 0.4895004332065582, 'epoch': 16.62}
{'loss': 0.01, 'grad_norm': 5.790843486785889, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.009639502502977848, 'loss_2': 0.0003452301025390625, 'loss_3': -16.303165435791016, 'loss_4': 0.4662630558013916, 'epoch': 16.62}
{'loss': 0.0365, 'grad_norm': 11.557205200195312, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.027743598446249962, 'loss_2': 0.0087890625, 'loss_3': -16.374950408935547, 'loss_4': 0.8306447267532349, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 13:31:32,197 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:32,197 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:51<39:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:39,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018800564110279083, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.207, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.016013212502002716, 'eval_loss_2': 0.002787351608276367, 'eval_loss_3': -18.21429443359375, 'eval_loss_4': 0.17419591546058655, 'epoch': 16.63}
{'loss': 0.0082, 'grad_norm': 5.906439781188965, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.007262175437062979, 'loss_2': 0.0009255409240722656, 'loss_3': -16.339569091796875, 'loss_4': 0.6416231393814087, 'epoch': 16.63}
{'loss': 0.0119, 'grad_norm': 6.575860023498535, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.011547631584107876, 'loss_2': 0.0003180503845214844, 'loss_3': -16.337312698364258, 'loss_4': 0.8483807444572449, 'epoch': 16.64}
{'loss': 0.0112, 'grad_norm': 6.394742488861084, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.010716192424297333, 'loss_2': 0.00044918060302734375, 'loss_3': -16.43264389038086, 'loss_4': 0.38991403579711914, 'epoch': 16.65}
{'loss': 0.0124, 'grad_norm': 5.790085315704346, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.00981546938419342, 'loss_2': 0.0025691986083984375, 'loss_3': -16.48211097717285, 'loss_4': 0.16637077927589417, 'epoch': 16.65}
{'loss': 0.005, 'grad_norm': 4.346860408782959, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.0034489331301301718, 'loss_2': 0.0015430450439453125, 'loss_3': -16.314952850341797, 'loss_4': 0.5654408931732178, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 13:31:39,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:39,525 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:10:58<39:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:46,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015149671584367752, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.455, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012660933658480644, 'eval_loss_2': 0.002488739788532257, 'eval_loss_3': -18.230331420898438, 'eval_loss_4': 0.37657609581947327, 'epoch': 16.66}
{'loss': 0.0208, 'grad_norm': 6.352360248565674, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.016696657985448837, 'loss_2': 0.004093170166015625, 'loss_3': -16.34967613220215, 'loss_4': 0.12981760501861572, 'epoch': 16.66}
{'loss': 0.0078, 'grad_norm': 4.905426502227783, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.006347810849547386, 'loss_2': 0.001422882080078125, 'loss_3': -16.32452392578125, 'loss_4': 0.9031268358230591, 'epoch': 16.67}
{'loss': 0.0155, 'grad_norm': 6.558657646179199, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.012747365981340408, 'loss_2': 0.0027313232421875, 'loss_3': -16.34463119506836, 'loss_4': 0.4368453323841095, 'epoch': 16.67}
{'loss': 0.016, 'grad_norm': 9.065178871154785, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.015392201952636242, 'loss_2': 0.0005712509155273438, 'loss_3': -16.36578369140625, 'loss_4': 0.879827618598938, 'epoch': 16.68}
{'loss': 0.0227, 'grad_norm': 9.722978591918945, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.019374066963791847, 'loss_2': 0.0033721923828125, 'loss_3': -16.334802627563477, 'loss_4': 0.7358716726303101, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 13:31:46,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:46,858 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:11:06<39:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:54,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013323301449418068, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.066, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010925681330263615, 'eval_loss_2': 0.0023976191878318787, 'eval_loss_3': -18.246484756469727, 'eval_loss_4': 0.42089343070983887, 'epoch': 16.69}
{'loss': 0.024, 'grad_norm': 6.317992210388184, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.01620127260684967, 'loss_2': 0.007778167724609375, 'loss_3': -16.22557830810547, 'loss_4': 0.7050449252128601, 'epoch': 16.69}
{'loss': 0.0299, 'grad_norm': 10.389687538146973, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.02799144573509693, 'loss_2': 0.0018749237060546875, 'loss_3': -16.368946075439453, 'loss_4': 0.929582953453064, 'epoch': 16.7}
{'loss': 0.0096, 'grad_norm': 5.1708173751831055, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.008054067380726337, 'loss_2': 0.0015096664428710938, 'loss_3': -16.23189353942871, 'loss_4': 0.7450193762779236, 'epoch': 16.7}
{'loss': 0.0132, 'grad_norm': 6.692628860473633, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.01097982656210661, 'loss_2': 0.002262115478515625, 'loss_3': -16.295114517211914, 'loss_4': 1.1605870723724365, 'epoch': 16.71}
{'loss': 0.0111, 'grad_norm': 4.723147869110107, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.007232385687530041, 'loss_2': 0.003864288330078125, 'loss_3': -16.514698028564453, 'loss_4': 0.9022632837295532, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 13:31:54,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:54,189 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:13<39:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:01,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013951417058706284, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.378, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01165663730353117, 'eval_loss_2': 0.002294778823852539, 'eval_loss_3': -18.251996994018555, 'eval_loss_4': 0.3622385561466217, 'epoch': 16.72}
{'loss': 0.0083, 'grad_norm': 4.62407112121582, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.006658170372247696, 'loss_2': 0.0016536712646484375, 'loss_3': -16.321287155151367, 'loss_4': 1.0978587865829468, 'epoch': 16.72}
{'loss': 0.0115, 'grad_norm': 5.77344274520874, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.011138777248561382, 'loss_2': 0.0003743171691894531, 'loss_3': -16.631065368652344, 'loss_4': 0.8327370882034302, 'epoch': 16.73}
{'loss': 0.0119, 'grad_norm': 4.680774211883545, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.009570321068167686, 'loss_2': 0.0023784637451171875, 'loss_3': -16.33464241027832, 'loss_4': 0.2910429835319519, 'epoch': 16.73}
{'loss': 0.0218, 'grad_norm': 14.411439895629883, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.020833132788538933, 'loss_2': 0.0009365081787109375, 'loss_3': -16.397470474243164, 'loss_4': 1.1882638931274414, 'epoch': 16.74}
{'loss': 0.0076, 'grad_norm': 4.945603847503662, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.007023949641734362, 'loss_2': 0.0006198883056640625, 'loss_3': -16.27968978881836, 'loss_4': 0.47703853249549866, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 13:32:01,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:01,518 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:20<39:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:08,847 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0162334181368351, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.972, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012623961083590984, 'eval_loss_2': 0.0036094561219215393, 'eval_loss_3': -18.24884796142578, 'eval_loss_4': 0.18234796822071075, 'epoch': 16.74}
{'loss': 0.0121, 'grad_norm': 5.468568325042725, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.007280608639121056, 'loss_2': 0.00484466552734375, 'loss_3': -16.61126708984375, 'loss_4': 1.1241613626480103, 'epoch': 16.75}
{'loss': 0.0126, 'grad_norm': 6.758334636688232, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.010455984622240067, 'loss_2': 0.0020961761474609375, 'loss_3': -16.345279693603516, 'loss_4': 0.7949132919311523, 'epoch': 16.76}
{'loss': 0.0309, 'grad_norm': 6.482603073120117, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.01990559510886669, 'loss_2': 0.0110321044921875, 'loss_3': -16.66793441772461, 'loss_4': 0.8328360915184021, 'epoch': 16.76}
{'loss': 0.0148, 'grad_norm': 5.071078300476074, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.00879701692610979, 'loss_2': 0.006008148193359375, 'loss_3': -16.522018432617188, 'loss_4': 0.4700503647327423, 'epoch': 16.77}
{'loss': 0.0158, 'grad_norm': 4.9294257164001465, 'learning_rate': 1.325e-05, 'loss_1': 0.012926674447953701, 'loss_2': 0.00287628173828125, 'loss_3': -16.263484954833984, 'loss_4': 0.1376858353614807, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 13:32:08,847 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:08,847 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:28<39:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:16,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016228236258029938, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.014, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01357528567314148, 'eval_loss_2': 0.0026529505848884583, 'eval_loss_3': -18.249305725097656, 'eval_loss_4': 0.14797477424144745, 'epoch': 16.77}
{'loss': 0.0188, 'grad_norm': 7.06965970993042, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.013731073588132858, 'loss_2': 0.0050506591796875, 'loss_3': -16.41830062866211, 'loss_4': -0.0019268617033958435, 'epoch': 16.78}
{'loss': 0.0474, 'grad_norm': 20.4355411529541, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.04189044237136841, 'loss_2': 0.005489349365234375, 'loss_3': -16.351865768432617, 'loss_4': 0.5135138034820557, 'epoch': 16.78}
{'loss': 0.0214, 'grad_norm': 7.396348476409912, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.021152788773179054, 'loss_2': 0.0002570152282714844, 'loss_3': -16.356674194335938, 'loss_4': 0.6500824093818665, 'epoch': 16.79}
{'loss': 0.0122, 'grad_norm': 5.08056116104126, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.009708509780466557, 'loss_2': 0.002452850341796875, 'loss_3': -16.281652450561523, 'loss_4': 0.3669115900993347, 'epoch': 16.8}
{'loss': 0.0336, 'grad_norm': 18.498598098754883, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.03332128748297691, 'loss_2': 0.00024080276489257812, 'loss_3': -16.39099884033203, 'loss_4': 0.4824993908405304, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 13:32:16,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:16,180 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:35<39:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:23,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01611100137233734, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.103, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013436277396976948, 'eval_loss_2': 0.002674724906682968, 'eval_loss_3': -18.235668182373047, 'eval_loss_4': 0.18506845831871033, 'epoch': 16.8}
{'loss': 0.0177, 'grad_norm': 6.596420764923096, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.013525119982659817, 'loss_2': 0.00418853759765625, 'loss_3': -16.435832977294922, 'loss_4': 0.48493650555610657, 'epoch': 16.81}
{'loss': 0.0485, 'grad_norm': 21.742809295654297, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.044580765068531036, 'loss_2': 0.003963470458984375, 'loss_3': -16.46746826171875, 'loss_4': 0.976410448551178, 'epoch': 16.81}
{'loss': 0.009, 'grad_norm': 4.846921443939209, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.006273194681853056, 'loss_2': 0.00269317626953125, 'loss_3': -16.444116592407227, 'loss_4': 0.576103925704956, 'epoch': 16.82}
{'loss': 0.009, 'grad_norm': 5.706988334655762, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.006170894950628281, 'loss_2': 0.00284576416015625, 'loss_3': -16.456401824951172, 'loss_4': 0.013632029294967651, 'epoch': 16.83}
{'loss': 0.0217, 'grad_norm': 6.532223701477051, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.014463087543845177, 'loss_2': 0.00726318359375, 'loss_3': -16.395172119140625, 'loss_4': 0.7654097080230713, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 13:32:23,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:23,508 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:42<38:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:32:30,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01894392818212509, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.391, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015594622120261192, 'eval_loss_2': 0.00334930419921875, 'eval_loss_3': -18.228734970092773, 'eval_loss_4': 0.28421473503112793, 'epoch': 16.83}
{'loss': 0.0105, 'grad_norm': 5.903618812561035, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.0095909358933568, 'loss_2': 0.0008707046508789062, 'loss_3': -16.305389404296875, 'loss_4': 0.35395902395248413, 'epoch': 16.84}
{'loss': 0.008, 'grad_norm': 4.485074520111084, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.006708335597068071, 'loss_2': 0.0012798309326171875, 'loss_3': -16.513145446777344, 'loss_4': 0.5846285820007324, 'epoch': 16.84}
{'loss': 0.0119, 'grad_norm': 5.167088508605957, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.0054884254932403564, 'loss_2': 0.0063934326171875, 'loss_3': -16.368484497070312, 'loss_4': 0.36040186882019043, 'epoch': 16.85}
{'loss': 0.0093, 'grad_norm': 5.409441947937012, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.008754294365644455, 'loss_2': 0.0005640983581542969, 'loss_3': -16.323284149169922, 'loss_4': 0.6270250678062439, 'epoch': 16.85}
{'loss': 0.0578, 'grad_norm': 8.437820434570312, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.05380108207464218, 'loss_2': 0.004024505615234375, 'loss_3': -16.450326919555664, 'loss_4': 0.7162833213806152, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 13:32:30,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:30,831 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:50<38:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:32:38,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01989586651325226, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.456, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.016277804970741272, 'eval_loss_2': 0.0036180615425109863, 'eval_loss_3': -18.237558364868164, 'eval_loss_4': 0.3859415352344513, 'epoch': 16.86}
{'loss': 0.0191, 'grad_norm': 7.061551094055176, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.014734144322574139, 'loss_2': 0.0043792724609375, 'loss_3': -16.333898544311523, 'loss_4': 0.6959920525550842, 'epoch': 16.87}
{'loss': 0.0235, 'grad_norm': 6.716399192810059, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.012479383498430252, 'loss_2': 0.0110015869140625, 'loss_3': -16.3297061920166, 'loss_4': 1.1146240234375, 'epoch': 16.87}
{'loss': 0.0394, 'grad_norm': 20.425926208496094, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.037645407021045685, 'loss_2': 0.0017147064208984375, 'loss_3': -16.444021224975586, 'loss_4': 0.6952223777770996, 'epoch': 16.88}
{'loss': 0.017, 'grad_norm': 5.272568225860596, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.012395503930747509, 'loss_2': 0.00455474853515625, 'loss_3': -16.424880981445312, 'loss_4': 0.6993156671524048, 'epoch': 16.88}
{'loss': 0.0081, 'grad_norm': 5.965056419372559, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.00798374880105257, 'loss_2': 7.200241088867188e-05, 'loss_3': -16.142423629760742, 'loss_4': 0.6470487713813782, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 13:32:38,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:38,152 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:11:57<38:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:32:45,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01890755631029606, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.498, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.016339072957634926, 'eval_loss_2': 0.002568483352661133, 'eval_loss_3': -18.238319396972656, 'eval_loss_4': 0.4127245545387268, 'epoch': 16.89}
{'loss': 0.0135, 'grad_norm': 5.415643215179443, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.01023408118635416, 'loss_2': 0.003307342529296875, 'loss_3': -16.33955192565918, 'loss_4': 0.4791519343852997, 'epoch': 16.9}
{'loss': 0.0159, 'grad_norm': 7.071249008178711, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.012909818440675735, 'loss_2': 0.0029697418212890625, 'loss_3': -16.173946380615234, 'loss_4': 1.0124698877334595, 'epoch': 16.9}
{'loss': 0.0173, 'grad_norm': 11.773838996887207, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.017204545438289642, 'loss_2': 5.906820297241211e-05, 'loss_3': -16.395030975341797, 'loss_4': 0.23141071200370789, 'epoch': 16.91}
{'loss': 0.0174, 'grad_norm': 7.508323669433594, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.012978807091712952, 'loss_2': 0.00446319580078125, 'loss_3': -16.152021408081055, 'loss_4': 0.3687398433685303, 'epoch': 16.91}
{'loss': 0.0112, 'grad_norm': 6.545289516448975, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.008055444806814194, 'loss_2': 0.003143310546875, 'loss_3': -16.219236373901367, 'loss_4': 0.36299604177474976, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 13:32:45,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:45,473 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:12:04<38:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:52,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016468016430735588, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.791, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01429284829646349, 'eval_loss_2': 0.002175167202949524, 'eval_loss_3': -18.253963470458984, 'eval_loss_4': 0.41237136721611023, 'epoch': 16.92}
{'loss': 0.0164, 'grad_norm': 5.575292587280273, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.01568959467113018, 'loss_2': 0.0007572174072265625, 'loss_3': -16.319969177246094, 'loss_4': 0.6362132430076599, 'epoch': 16.92}
{'loss': 0.014, 'grad_norm': 4.843435764312744, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.006759295240044594, 'loss_2': 0.007228851318359375, 'loss_3': -16.515113830566406, 'loss_4': 0.5159998536109924, 'epoch': 16.93}
{'loss': 0.017, 'grad_norm': 9.472232818603516, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.015790974721312523, 'loss_2': 0.0012531280517578125, 'loss_3': -16.379610061645508, 'loss_4': 0.764715850353241, 'epoch': 16.94}
{'loss': 0.009, 'grad_norm': 4.947259902954102, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.008236581459641457, 'loss_2': 0.0007510185241699219, 'loss_3': -16.47835922241211, 'loss_4': 1.0791187286376953, 'epoch': 16.94}
{'loss': 0.0165, 'grad_norm': 6.027035713195801, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.013484107330441475, 'loss_2': 0.003021240234375, 'loss_3': -16.44015121459961, 'loss_4': 0.6680944561958313, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 13:32:52,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:52,811 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:12<38:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:33:00,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01931791380047798, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.34, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015753943473100662, 'eval_loss_2': 0.0035639703273773193, 'eval_loss_3': -18.26304054260254, 'eval_loss_4': 0.3096903860569, 'epoch': 16.95}
{'loss': 0.0319, 'grad_norm': 17.830120086669922, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.030142148956656456, 'loss_2': 0.0017671585083007812, 'loss_3': -16.456951141357422, 'loss_4': 0.24726490676403046, 'epoch': 16.95}
{'loss': 0.0167, 'grad_norm': 6.171801567077637, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.010336189530789852, 'loss_2': 0.00638580322265625, 'loss_3': -16.395998001098633, 'loss_4': 0.9395292401313782, 'epoch': 16.96}
{'loss': 0.0121, 'grad_norm': 4.529791355133057, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.005759414751082659, 'loss_2': 0.00629425048828125, 'loss_3': -16.396472930908203, 'loss_4': 0.5902864336967468, 'epoch': 16.97}
{'loss': 0.0253, 'grad_norm': 8.887824058532715, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.019235752522945404, 'loss_2': 0.00609588623046875, 'loss_3': -16.27106285095215, 'loss_4': 0.38495171070098877, 'epoch': 16.97}
{'loss': 0.0162, 'grad_norm': 4.927897930145264, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.005924952682107687, 'loss_2': 0.01031494140625, 'loss_3': -16.356779098510742, 'loss_4': 0.1799369901418686, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 13:33:00,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:00,134 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:19<36:16,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 13:33:07,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020312121137976646, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.349, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016906118020415306, 'eval_loss_2': 0.0034060031175613403, 'eval_loss_3': -18.240638732910156, 'eval_loss_4': 0.11529180407524109, 'epoch': 16.98}
{'loss': 0.0261, 'grad_norm': 13.825563430786133, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.020795168355107307, 'loss_2': 0.005313873291015625, 'loss_3': -16.373641967773438, 'loss_4': 0.6203867793083191, 'epoch': 16.98}
{'loss': 0.0145, 'grad_norm': 5.302403450012207, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.003791619325056672, 'loss_2': 0.0106658935546875, 'loss_3': -16.468746185302734, 'loss_4': -0.09602832794189453, 'epoch': 16.99}
{'loss': 0.0102, 'grad_norm': 5.322454452514648, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.006352693308144808, 'loss_2': 0.0038318634033203125, 'loss_3': -16.43447494506836, 'loss_4': 0.1658245325088501, 'epoch': 16.99}
{'loss': 0.008, 'grad_norm': 6.32867431640625, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.004841628484427929, 'loss_2': 0.003116607666015625, 'loss_3': -16.347074508666992, 'loss_4': 0.7241947054862976, 'epoch': 17.0}
{'loss': 0.0207, 'grad_norm': 5.90783166885376, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.014181187376379967, 'loss_2': 0.0065155029296875, 'loss_3': -16.455814361572266, 'loss_4': 0.05742082744836807, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 13:33:07,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:07,145 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:26<38:04,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:33:14,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021491151303052902, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.21, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01741347648203373, 'eval_loss_2': 0.0040776729583740234, 'eval_loss_3': -18.229568481445312, 'eval_loss_4': -0.08098722249269485, 'epoch': 17.01}
{'loss': 0.0121, 'grad_norm': 5.425271034240723, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.008980177342891693, 'loss_2': 0.003086090087890625, 'loss_3': -16.49858856201172, 'loss_4': 0.4601559340953827, 'epoch': 17.01}
{'loss': 0.0104, 'grad_norm': 6.200386047363281, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.008414738811552525, 'loss_2': 0.0019664764404296875, 'loss_3': -16.237621307373047, 'loss_4': 0.49149614572525024, 'epoch': 17.02}
{'loss': 0.0217, 'grad_norm': 6.07521915435791, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.010025578550994396, 'loss_2': 0.01165771484375, 'loss_3': -16.604633331298828, 'loss_4': -0.20755510032176971, 'epoch': 17.02}
{'loss': 0.0139, 'grad_norm': 5.122352123260498, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.002718067029491067, 'loss_2': 0.011138916015625, 'loss_3': -16.355497360229492, 'loss_4': -0.08612985163927078, 'epoch': 17.03}
{'loss': 0.0141, 'grad_norm': 5.194882392883301, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.00953579694032669, 'loss_2': 0.00458526611328125, 'loss_3': -16.302814483642578, 'loss_4': -0.370974063873291, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 13:33:14,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:14,467 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:33<38:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:33:21,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0229388028383255, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.36, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.019296102225780487, 'eval_loss_2': 0.0036427006125450134, 'eval_loss_3': -18.221813201904297, 'eval_loss_4': -0.19360144436359406, 'epoch': 17.03}
{'loss': 0.0101, 'grad_norm': 5.22531270980835, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.007384771015495062, 'loss_2': 0.00275421142578125, 'loss_3': -16.461931228637695, 'loss_4': -0.09127819538116455, 'epoch': 17.04}
{'loss': 0.008, 'grad_norm': 4.793734550476074, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.0068043433129787445, 'loss_2': 0.0011463165283203125, 'loss_3': -16.469385147094727, 'loss_4': -0.3139321804046631, 'epoch': 17.05}
{'loss': 0.01, 'grad_norm': 5.448178291320801, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.006927620619535446, 'loss_2': 0.003063201904296875, 'loss_3': -16.32281494140625, 'loss_4': 0.059928640723228455, 'epoch': 17.05}
{'loss': 0.0068, 'grad_norm': 5.103419780731201, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.006773869972676039, 'loss_2': 5.805492401123047e-05, 'loss_3': -16.235862731933594, 'loss_4': 0.04403723031282425, 'epoch': 17.06}
{'loss': 0.056, 'grad_norm': 16.691434860229492, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.05493374541401863, 'loss_2': 0.0010929107666015625, 'loss_3': -16.3763427734375, 'loss_4': -0.0862932950258255, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 13:33:21,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:21,782 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:41<38:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:33:29,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021512441337108612, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.206, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.018779851496219635, 'eval_loss_2': 0.002732589840888977, 'eval_loss_3': -18.221731185913086, 'eval_loss_4': -0.21426790952682495, 'epoch': 17.06}
{'loss': 0.0173, 'grad_norm': 6.128159999847412, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.013449981808662415, 'loss_2': 0.0038356781005859375, 'loss_3': -16.313644409179688, 'loss_4': -0.203273206949234, 'epoch': 17.07}
{'loss': 0.0123, 'grad_norm': 5.509027481079102, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.009359163232147694, 'loss_2': 0.002941131591796875, 'loss_3': -16.471874237060547, 'loss_4': 0.004596807062625885, 'epoch': 17.08}
{'loss': 0.0117, 'grad_norm': 5.898587703704834, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.010335605591535568, 'loss_2': 0.0013341903686523438, 'loss_3': -16.413663864135742, 'loss_4': -0.21699436008930206, 'epoch': 17.08}
{'loss': 0.0116, 'grad_norm': 5.158354759216309, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.007478578016161919, 'loss_2': 0.004146575927734375, 'loss_3': -16.370485305786133, 'loss_4': -0.028878986835479736, 'epoch': 17.09}
{'loss': 0.0111, 'grad_norm': 5.165365219116211, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.00718656275421381, 'loss_2': 0.00391387939453125, 'loss_3': -16.41442108154297, 'loss_4': 0.4202861487865448, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 13:33:29,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:29,107 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:48<38:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:36,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02203594706952572, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01828812249004841, 'eval_loss_2': 0.0037478208541870117, 'eval_loss_3': -18.222007751464844, 'eval_loss_4': -0.25865471363067627, 'epoch': 17.09}
{'loss': 0.0202, 'grad_norm': 9.412093162536621, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.012212802655994892, 'loss_2': 0.0079803466796875, 'loss_3': -16.294635772705078, 'loss_4': 0.10277572274208069, 'epoch': 17.1}
{'loss': 0.0043, 'grad_norm': 5.057596683502197, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.0040783872827887535, 'loss_2': 0.00025010108947753906, 'loss_3': -16.26274871826172, 'loss_4': -0.3648334741592407, 'epoch': 17.1}
{'loss': 0.0089, 'grad_norm': 4.572272777557373, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.0039696404710412025, 'loss_2': 0.00495147705078125, 'loss_3': -16.47566032409668, 'loss_4': 0.07685942947864532, 'epoch': 17.11}
{'loss': 0.0122, 'grad_norm': 5.339478015899658, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.008086650632321835, 'loss_2': 0.00415802001953125, 'loss_3': -16.50865936279297, 'loss_4': -0.16627764701843262, 'epoch': 17.12}
{'loss': 0.01, 'grad_norm': 5.027823448181152, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.007991922087967396, 'loss_2': 0.0019683837890625, 'loss_3': -16.3001708984375, 'loss_4': 0.3622512221336365, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 13:33:36,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:36,449 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:12:55<38:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:43,777 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0203567948192358, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.273, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.016996918246150017, 'eval_loss_2': 0.003359876573085785, 'eval_loss_3': -18.225482940673828, 'eval_loss_4': -0.25143057107925415, 'epoch': 17.12}
{'loss': 0.0149, 'grad_norm': 5.837252140045166, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.007786767557263374, 'loss_2': 0.007114410400390625, 'loss_3': -16.519664764404297, 'loss_4': -0.47321364283561707, 'epoch': 17.13}
{'loss': 0.0062, 'grad_norm': 4.995613098144531, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.004696747753769159, 'loss_2': 0.0014705657958984375, 'loss_3': -16.682952880859375, 'loss_4': -0.29403674602508545, 'epoch': 17.13}
{'loss': 0.0055, 'grad_norm': 4.495521545410156, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.003363976953551173, 'loss_2': 0.002166748046875, 'loss_3': -16.662551879882812, 'loss_4': -0.16251780092716217, 'epoch': 17.14}
{'loss': 0.0046, 'grad_norm': 5.039731979370117, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.003472853684797883, 'loss_2': 0.001129150390625, 'loss_3': -16.46095848083496, 'loss_4': -0.06502993404865265, 'epoch': 17.15}
{'loss': 0.0157, 'grad_norm': 6.031184673309326, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.012447339482605457, 'loss_2': 0.003204345703125, 'loss_3': -16.41192626953125, 'loss_4': -0.21465212106704712, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 13:33:43,778 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:43,778 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:13:03<38:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:51,109 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020755916833877563, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01708168163895607, 'eval_loss_2': 0.003674238920211792, 'eval_loss_3': -18.23091697692871, 'eval_loss_4': -0.27824875712394714, 'epoch': 17.15}
{'loss': 0.0082, 'grad_norm': 4.928375244140625, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.005686002783477306, 'loss_2': 0.00249481201171875, 'loss_3': -16.470565795898438, 'loss_4': -0.5684921145439148, 'epoch': 17.16}
{'loss': 0.0332, 'grad_norm': 24.30788230895996, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.03133116662502289, 'loss_2': 0.001819610595703125, 'loss_3': -16.291658401489258, 'loss_4': 0.20670002698898315, 'epoch': 17.16}
{'loss': 0.0256, 'grad_norm': 13.036059379577637, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.017906632274389267, 'loss_2': 0.00768280029296875, 'loss_3': -16.493854522705078, 'loss_4': -0.24764840304851532, 'epoch': 17.17}
{'loss': 0.0061, 'grad_norm': 5.166555881500244, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.005099278409034014, 'loss_2': 0.0010232925415039062, 'loss_3': -16.451736450195312, 'loss_4': -0.6879510879516602, 'epoch': 17.17}
{'loss': 0.0052, 'grad_norm': 4.8440165519714355, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.005185316316783428, 'loss_2': 1.1801719665527344e-05, 'loss_3': -16.508235931396484, 'loss_4': 0.0877949446439743, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 13:33:51,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:51,109 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:13:10<37:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:33:58,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020202046260237694, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.379, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.017452139407396317, 'eval_loss_2': 0.002749904990196228, 'eval_loss_3': -18.244365692138672, 'eval_loss_4': -0.3408443033695221, 'epoch': 17.18}
{'loss': 0.009, 'grad_norm': 5.50344181060791, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.006640298292040825, 'loss_2': 0.0023956298828125, 'loss_3': -16.476499557495117, 'loss_4': -0.7757007479667664, 'epoch': 17.19}
{'loss': 0.0091, 'grad_norm': 7.073881149291992, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.00758713111281395, 'loss_2': 0.0015201568603515625, 'loss_3': -16.466106414794922, 'loss_4': -0.07030579447746277, 'epoch': 17.19}
{'loss': 0.006, 'grad_norm': 4.499046325683594, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.005369899794459343, 'loss_2': 0.0005884170532226562, 'loss_3': -16.29175567626953, 'loss_4': -0.7565394639968872, 'epoch': 17.2}
{'loss': 0.0078, 'grad_norm': 4.7651591300964355, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.0053154886700212955, 'loss_2': 0.00244140625, 'loss_3': -16.38132095336914, 'loss_4': -0.3873710334300995, 'epoch': 17.2}
{'loss': 0.0058, 'grad_norm': 5.180347442626953, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.0039801932871341705, 'loss_2': 0.001834869384765625, 'loss_3': -16.338542938232422, 'loss_4': -0.28574854135513306, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 13:33:58,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:58,431 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:17<37:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:05,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021245479583740234, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.239, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01793750934302807, 'eval_loss_2': 0.0033079683780670166, 'eval_loss_3': -18.247961044311523, 'eval_loss_4': -0.4285593032836914, 'epoch': 17.21}
{'loss': 0.0196, 'grad_norm': 6.4277849197387695, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.012148925103247166, 'loss_2': 0.00740814208984375, 'loss_3': -16.460433959960938, 'loss_4': -0.25171470642089844, 'epoch': 17.22}
{'loss': 0.0653, 'grad_norm': 20.983808517456055, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.0646282359957695, 'loss_2': 0.0007066726684570312, 'loss_3': -16.533885955810547, 'loss_4': 0.5403028726577759, 'epoch': 17.22}
{'loss': 0.0074, 'grad_norm': 4.450436592102051, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.0023711584508419037, 'loss_2': 0.00504302978515625, 'loss_3': -16.515954971313477, 'loss_4': -0.006721809506416321, 'epoch': 17.23}
{'loss': 0.022, 'grad_norm': 7.657736778259277, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.015688525512814522, 'loss_2': 0.00634765625, 'loss_3': -16.378992080688477, 'loss_4': 0.002037644386291504, 'epoch': 17.23}
{'loss': 0.0232, 'grad_norm': 7.05550479888916, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.01882687211036682, 'loss_2': 0.00441741943359375, 'loss_3': -16.456756591796875, 'loss_4': -0.0018016397953033447, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 13:34:05,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:05,757 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:25<37:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:13,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021004311740398407, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.136, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.017613673582673073, 'eval_loss_2': 0.0033906400203704834, 'eval_loss_3': -18.24365234375, 'eval_loss_4': -0.3984413146972656, 'epoch': 17.24}
{'loss': 0.0115, 'grad_norm': 5.589454174041748, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.0068825166672468185, 'loss_2': 0.00461578369140625, 'loss_3': -16.411592483520508, 'loss_4': -0.23993611335754395, 'epoch': 17.24}
{'loss': 0.0111, 'grad_norm': 5.196565628051758, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.007591236848384142, 'loss_2': 0.0035305023193359375, 'loss_3': -16.504419326782227, 'loss_4': 0.3130902647972107, 'epoch': 17.25}
{'loss': 0.0173, 'grad_norm': 6.825890064239502, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.007845770567655563, 'loss_2': 0.0094757080078125, 'loss_3': -16.3472900390625, 'loss_4': 0.15814688801765442, 'epoch': 17.26}
{'loss': 0.0118, 'grad_norm': 5.964977264404297, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.010370133444666862, 'loss_2': 0.0014247894287109375, 'loss_3': -16.366230010986328, 'loss_4': -0.48561906814575195, 'epoch': 17.26}
{'loss': 0.0077, 'grad_norm': 4.765560626983643, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.004237180110067129, 'loss_2': 0.0034427642822265625, 'loss_3': -16.487014770507812, 'loss_4': -0.4417286217212677, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 13:34:13,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:13,090 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:32<37:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:20,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020130550488829613, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.137, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016953976824879646, 'eval_loss_2': 0.003176569938659668, 'eval_loss_3': -18.241729736328125, 'eval_loss_4': -0.3321749269962311, 'epoch': 17.27}
{'loss': 0.0122, 'grad_norm': 4.815104961395264, 'learning_rate': 1.275e-05, 'loss_1': 0.008898993022739887, 'loss_2': 0.003299713134765625, 'loss_3': -16.46271514892578, 'loss_4': -0.5388171076774597, 'epoch': 17.27}
{'loss': 0.0128, 'grad_norm': 5.551109790802002, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.008789190091192722, 'loss_2': 0.0040435791015625, 'loss_3': -16.474945068359375, 'loss_4': -0.1781550943851471, 'epoch': 17.28}
{'loss': 0.0149, 'grad_norm': 5.730989456176758, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.012481320649385452, 'loss_2': 0.00240325927734375, 'loss_3': -16.507965087890625, 'loss_4': 0.49068188667297363, 'epoch': 17.28}
{'loss': 0.0122, 'grad_norm': 5.386719703674316, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.010454460978507996, 'loss_2': 0.0017910003662109375, 'loss_3': -16.332427978515625, 'loss_4': -0.04861500859260559, 'epoch': 17.29}
{'loss': 0.0092, 'grad_norm': 4.542266845703125, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.003890957683324814, 'loss_2': 0.00533294677734375, 'loss_3': -16.3858642578125, 'loss_4': 0.37678542733192444, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 13:34:20,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:20,419 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:39<37:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:34:27,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02011830545961857, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.378, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.016860807314515114, 'eval_loss_2': 0.0032574981451034546, 'eval_loss_3': -18.21918487548828, 'eval_loss_4': -0.05375276505947113, 'epoch': 17.3}
{'loss': 0.0117, 'grad_norm': 4.811463832855225, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.007671275641769171, 'loss_2': 0.00402069091796875, 'loss_3': -16.41800880432129, 'loss_4': -0.24382513761520386, 'epoch': 17.3}
{'loss': 0.0144, 'grad_norm': 4.394320964813232, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.0032721892930567265, 'loss_2': 0.01116943359375, 'loss_3': -16.374191284179688, 'loss_4': 0.030766405165195465, 'epoch': 17.31}
{'loss': 0.0041, 'grad_norm': 4.6388139724731445, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.003761723404750228, 'loss_2': 0.0003452301025390625, 'loss_3': -16.484622955322266, 'loss_4': 0.5080257654190063, 'epoch': 17.31}
{'loss': 0.0078, 'grad_norm': 5.032088279724121, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.0071104480884969234, 'loss_2': 0.000705718994140625, 'loss_3': -16.455909729003906, 'loss_4': 0.3600509762763977, 'epoch': 17.32}
{'loss': 0.0102, 'grad_norm': 6.317424774169922, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.006091701798141003, 'loss_2': 0.0040740966796875, 'loss_3': -16.320476531982422, 'loss_4': 0.3793541193008423, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 13:34:27,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:27,739 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:47<37:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:35,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022166458889842033, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.526, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.017214780673384666, 'eval_loss_2': 0.004951678216457367, 'eval_loss_3': -18.24110221862793, 'eval_loss_4': 0.25314173102378845, 'epoch': 17.33}
{'loss': 0.0391, 'grad_norm': 11.016267776489258, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.034735191613435745, 'loss_2': 0.00440216064453125, 'loss_3': -16.499460220336914, 'loss_4': 0.4783073663711548, 'epoch': 17.33}
{'loss': 0.0229, 'grad_norm': 9.867289543151855, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.02008742280304432, 'loss_2': 0.0028247833251953125, 'loss_3': -16.532211303710938, 'loss_4': 0.9025444984436035, 'epoch': 17.34}
{'loss': 0.0062, 'grad_norm': 4.7025532722473145, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.005601260811090469, 'loss_2': 0.0005893707275390625, 'loss_3': -16.335128784179688, 'loss_4': 0.0008194670081138611, 'epoch': 17.34}
{'loss': 0.0163, 'grad_norm': 5.272633075714111, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.010512270964682102, 'loss_2': 0.005741119384765625, 'loss_3': -16.559497833251953, 'loss_4': 0.2802242338657379, 'epoch': 17.35}
{'loss': 0.0104, 'grad_norm': 4.5420918464660645, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.008879105560481548, 'loss_2': 0.001495361328125, 'loss_3': -16.491840362548828, 'loss_4': 0.2516273260116577, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 13:34:35,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:35,062 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:13:54<37:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:34:42,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022073835134506226, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.158, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.018929552286863327, 'eval_loss_2': 0.0031442791223526, 'eval_loss_3': -18.241479873657227, 'eval_loss_4': 0.4320142865180969, 'epoch': 17.35}
{'loss': 0.0118, 'grad_norm': 4.647449493408203, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.010434309020638466, 'loss_2': 0.001316070556640625, 'loss_3': -16.35439109802246, 'loss_4': 0.488397479057312, 'epoch': 17.36}
{'loss': 0.0258, 'grad_norm': 9.656865119934082, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.024338234215974808, 'loss_2': 0.001468658447265625, 'loss_3': -16.304832458496094, 'loss_4': 0.13380998373031616, 'epoch': 17.37}
{'loss': 0.0053, 'grad_norm': 4.56528902053833, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.0048889825120568275, 'loss_2': 0.0004291534423828125, 'loss_3': -16.278356552124023, 'loss_4': 0.35744065046310425, 'epoch': 17.37}
{'loss': 0.0124, 'grad_norm': 5.92047643661499, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.009087475016713142, 'loss_2': 0.00328826904296875, 'loss_3': -16.3631649017334, 'loss_4': 1.0179001092910767, 'epoch': 17.38}
{'loss': 0.0082, 'grad_norm': 4.218995094299316, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.003994359169155359, 'loss_2': 0.00417327880859375, 'loss_3': -16.58643341064453, 'loss_4': 0.8118174076080322, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 13:34:42,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:42,388 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:14:01<37:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:49,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024763427674770355, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.297, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.020143739879131317, 'eval_loss_2': 0.004619687795639038, 'eval_loss_3': -18.23090934753418, 'eval_loss_4': 0.5117460489273071, 'epoch': 17.38}
{'loss': 0.0169, 'grad_norm': 6.271541118621826, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.010709933005273342, 'loss_2': 0.00621795654296875, 'loss_3': -16.340782165527344, 'loss_4': 0.6739997863769531, 'epoch': 17.39}
{'loss': 0.0097, 'grad_norm': 4.898808002471924, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.0051737623289227486, 'loss_2': 0.0045013427734375, 'loss_3': -16.397201538085938, 'loss_4': 0.6616075038909912, 'epoch': 17.4}
{'loss': 0.0192, 'grad_norm': 6.167032241821289, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.011086178943514824, 'loss_2': 0.00806427001953125, 'loss_3': -16.233978271484375, 'loss_4': 0.4676591157913208, 'epoch': 17.4}
{'loss': 0.0096, 'grad_norm': 5.1027512550354, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.007406638935208321, 'loss_2': 0.0021610260009765625, 'loss_3': -16.411521911621094, 'loss_4': 0.7098914384841919, 'epoch': 17.41}
{'loss': 0.0138, 'grad_norm': 5.36350154876709, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.010137011297047138, 'loss_2': 0.0036468505859375, 'loss_3': -16.59809112548828, 'loss_4': 0.5227500200271606, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 13:34:49,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:49,717 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:14:09<37:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:57,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024404466152191162, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.579, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.020392419770359993, 'eval_loss_2': 0.004012048244476318, 'eval_loss_3': -18.234909057617188, 'eval_loss_4': 0.7090271711349487, 'epoch': 17.41}
{'loss': 0.0214, 'grad_norm': 6.59769868850708, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.017690980806946754, 'loss_2': 0.00374603271484375, 'loss_3': -16.549667358398438, 'loss_4': 0.5921926498413086, 'epoch': 17.42}
{'loss': 0.016, 'grad_norm': 8.098496437072754, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.013476149179041386, 'loss_2': 0.00252532958984375, 'loss_3': -16.385730743408203, 'loss_4': 0.9709240198135376, 'epoch': 17.42}
{'loss': 0.0153, 'grad_norm': 5.6026482582092285, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.010371115058660507, 'loss_2': 0.00492095947265625, 'loss_3': -16.447959899902344, 'loss_4': 0.49895617365837097, 'epoch': 17.43}
{'loss': 0.0111, 'grad_norm': 4.931392669677734, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.0071435049176216125, 'loss_2': 0.0039520263671875, 'loss_3': -16.534536361694336, 'loss_4': 1.555956244468689, 'epoch': 17.44}
{'loss': 0.0163, 'grad_norm': 5.515635967254639, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.008172907866537571, 'loss_2': 0.00814056396484375, 'loss_3': -16.424190521240234, 'loss_4': 1.0628671646118164, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 13:34:57,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:57,055 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:16<37:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:04,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02306274138391018, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.283, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.019969934597611427, 'eval_loss_2': 0.0030928105115890503, 'eval_loss_3': -18.234758377075195, 'eval_loss_4': 0.9392719268798828, 'epoch': 17.44}
{'loss': 0.0118, 'grad_norm': 5.903665065765381, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.010783609002828598, 'loss_2': 0.00101470947265625, 'loss_3': -16.31011199951172, 'loss_4': 1.0727131366729736, 'epoch': 17.45}
{'loss': 0.0168, 'grad_norm': 5.302079677581787, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.007755901664495468, 'loss_2': 0.00907135009765625, 'loss_3': -16.445709228515625, 'loss_4': 0.6486021280288696, 'epoch': 17.45}
{'loss': 0.0177, 'grad_norm': 6.402740955352783, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.013618161901831627, 'loss_2': 0.00405120849609375, 'loss_3': -16.36038589477539, 'loss_4': 1.1433976888656616, 'epoch': 17.46}
{'loss': 0.0165, 'grad_norm': 7.294234752655029, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.013089667074382305, 'loss_2': 0.0033855438232421875, 'loss_3': -16.420551300048828, 'loss_4': 1.46415114402771, 'epoch': 17.47}
{'loss': 0.0067, 'grad_norm': 5.035401344299316, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.005989740137010813, 'loss_2': 0.0006604194641113281, 'loss_3': -16.583179473876953, 'loss_4': 0.66412353515625, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 13:35:04,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:04,382 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:23<37:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:35:11,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020860705524683, 'eval_runtime': 3.7851, 'eval_samples_per_second': 270.531, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.017370015382766724, 'eval_loss_2': 0.0034906938672065735, 'eval_loss_3': -18.241744995117188, 'eval_loss_4': 0.9195266962051392, 'epoch': 17.47}
{'loss': 0.0224, 'grad_norm': 7.204598903656006, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.017013737931847572, 'loss_2': 0.0053863525390625, 'loss_3': -16.531593322753906, 'loss_4': 1.0582025051116943, 'epoch': 17.48}
{'loss': 0.0088, 'grad_norm': 4.7503557205200195, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.0065901391208171844, 'loss_2': 0.002185821533203125, 'loss_3': -16.604509353637695, 'loss_4': 0.6325113773345947, 'epoch': 17.48}
{'loss': 0.0066, 'grad_norm': 4.357474327087402, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.004443704150617123, 'loss_2': 0.00220489501953125, 'loss_3': -16.386228561401367, 'loss_4': 1.2413554191589355, 'epoch': 17.49}
{'loss': 0.0048, 'grad_norm': 4.224738597869873, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.0046361591666936874, 'loss_2': 0.000171661376953125, 'loss_3': -16.31235694885254, 'loss_4': 1.3082828521728516, 'epoch': 17.49}
{'loss': 0.0169, 'grad_norm': 5.127435207366943, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.010131483897566795, 'loss_2': 0.00679779052734375, 'loss_3': -16.439041137695312, 'loss_4': 0.7084221243858337, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 13:35:11,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:11,701 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:31<36:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:35:19,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020150627940893173, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.339, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015660399571061134, 'eval_loss_2': 0.00449022650718689, 'eval_loss_3': -18.240922927856445, 'eval_loss_4': 0.7307617664337158, 'epoch': 17.5}
{'loss': 0.0203, 'grad_norm': 7.288669586181641, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.01616360805928707, 'loss_2': 0.004150390625, 'loss_3': -16.353120803833008, 'loss_4': 0.6299537420272827, 'epoch': 17.51}
{'loss': 0.01, 'grad_norm': 4.507730484008789, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.006296641193330288, 'loss_2': 0.00372314453125, 'loss_3': -16.594348907470703, 'loss_4': 0.9384706020355225, 'epoch': 17.51}
{'loss': 0.099, 'grad_norm': 22.79498291015625, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.09798816591501236, 'loss_2': 0.000995635986328125, 'loss_3': -16.36220359802246, 'loss_4': 0.941031813621521, 'epoch': 17.52}
{'loss': 0.0101, 'grad_norm': 5.1147003173828125, 'learning_rate': 1.25e-05, 'loss_1': 0.0091889388859272, 'loss_2': 0.0009121894836425781, 'loss_3': -16.328781127929688, 'loss_4': 0.8840878009796143, 'epoch': 17.52}
{'loss': 0.0168, 'grad_norm': 12.008403778076172, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.011602363549172878, 'loss_2': 0.00522613525390625, 'loss_3': -16.451581954956055, 'loss_4': 0.8253514170646667, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 13:35:19,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:19,020 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:38<36:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:26,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01958858221769333, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.387, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015471747145056725, 'eval_loss_2': 0.004116833209991455, 'eval_loss_3': -18.24195098876953, 'eval_loss_4': 0.672615647315979, 'epoch': 17.53}
{'loss': 0.0099, 'grad_norm': 5.123217582702637, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.007624303922057152, 'loss_2': 0.00231170654296875, 'loss_3': -16.28118896484375, 'loss_4': 0.9759407043457031, 'epoch': 17.53}
{'loss': 0.0173, 'grad_norm': 6.535358905792236, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.011022426187992096, 'loss_2': 0.006237030029296875, 'loss_3': -16.58722686767578, 'loss_4': 0.5993880033493042, 'epoch': 17.54}
{'loss': 0.0556, 'grad_norm': 7.430893898010254, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.051958613097667694, 'loss_2': 0.003627777099609375, 'loss_3': -16.574607849121094, 'loss_4': 1.19252610206604, 'epoch': 17.55}
{'loss': 0.018, 'grad_norm': 7.741497993469238, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.014297233894467354, 'loss_2': 0.003658294677734375, 'loss_3': -16.401878356933594, 'loss_4': 0.8327631950378418, 'epoch': 17.55}
{'loss': 0.0099, 'grad_norm': 4.7888383865356445, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.005304219666868448, 'loss_2': 0.004638671875, 'loss_3': -16.343523025512695, 'loss_4': 0.7953627109527588, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 13:35:26,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:26,353 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:45<36:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:33,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019487865269184113, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.984, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.015487655065953732, 'eval_loss_2': 0.004000209271907806, 'eval_loss_3': -18.215923309326172, 'eval_loss_4': 0.7158922553062439, 'epoch': 17.56}
{'loss': 0.0138, 'grad_norm': 5.782505035400391, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.011173591949045658, 'loss_2': 0.0026531219482421875, 'loss_3': -16.37555694580078, 'loss_4': 1.2142446041107178, 'epoch': 17.56}
{'loss': 0.0079, 'grad_norm': 4.277249813079834, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.006087074987590313, 'loss_2': 0.0017948150634765625, 'loss_3': -16.48289680480957, 'loss_4': 1.0486210584640503, 'epoch': 17.57}
{'loss': 0.0151, 'grad_norm': 4.5518903732299805, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.008124581538140774, 'loss_2': 0.006938934326171875, 'loss_3': -16.545682907104492, 'loss_4': 1.134365439414978, 'epoch': 17.58}
{'loss': 0.008, 'grad_norm': 4.791557788848877, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.005708037409931421, 'loss_2': 0.002285003662109375, 'loss_3': -16.307132720947266, 'loss_4': 0.7698510885238647, 'epoch': 17.58}
{'loss': 0.0072, 'grad_norm': 4.9726128578186035, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.005598016548901796, 'loss_2': 0.0016260147094726562, 'loss_3': -16.37091064453125, 'loss_4': 0.3534577488899231, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 13:35:33,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:33,689 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:14:53<36:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:41,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019325636327266693, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.987, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.016256744042038918, 'eval_loss_2': 0.003068894147872925, 'eval_loss_3': -18.210514068603516, 'eval_loss_4': 0.6642296314239502, 'epoch': 17.59}
{'loss': 0.0062, 'grad_norm': 4.566593170166016, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.005014803726226091, 'loss_2': 0.001201629638671875, 'loss_3': -16.563730239868164, 'loss_4': 0.7674508094787598, 'epoch': 17.59}
{'loss': 0.0256, 'grad_norm': 10.305142402648926, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.019285278394818306, 'loss_2': 0.00628662109375, 'loss_3': -16.309799194335938, 'loss_4': 0.64564049243927, 'epoch': 17.6}
{'loss': 0.0133, 'grad_norm': 5.152623653411865, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.00623246468603611, 'loss_2': 0.00710296630859375, 'loss_3': -16.423160552978516, 'loss_4': 0.7395250797271729, 'epoch': 17.6}
{'loss': 0.0111, 'grad_norm': 5.527138710021973, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.010065906681120396, 'loss_2': 0.0010433197021484375, 'loss_3': -16.42099952697754, 'loss_4': 0.9170915484428406, 'epoch': 17.61}
{'loss': 0.0074, 'grad_norm': 5.015922546386719, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.0064532640390098095, 'loss_2': 0.0009698867797851562, 'loss_3': -16.31532096862793, 'loss_4': 0.3744625151157379, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 13:35:41,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:41,018 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:15:00<36:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:48,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01909143477678299, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.334, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015954559668898582, 'eval_loss_2': 0.003136873245239258, 'eval_loss_3': -18.201770782470703, 'eval_loss_4': 0.6471201181411743, 'epoch': 17.62}
{'loss': 0.0117, 'grad_norm': 5.182551383972168, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.00667699845507741, 'loss_2': 0.00501251220703125, 'loss_3': -16.35065460205078, 'loss_4': 0.9809948205947876, 'epoch': 17.62}
{'loss': 0.0095, 'grad_norm': 5.182958602905273, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.0071431659162044525, 'loss_2': 0.002323150634765625, 'loss_3': -16.746471405029297, 'loss_4': 0.8700138330459595, 'epoch': 17.63}
{'loss': 0.0134, 'grad_norm': 5.764588356018066, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.009346996434032917, 'loss_2': 0.004058837890625, 'loss_3': -16.521257400512695, 'loss_4': 0.9507052898406982, 'epoch': 17.63}
{'loss': 0.0114, 'grad_norm': 5.722771167755127, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.009126197546720505, 'loss_2': 0.002277374267578125, 'loss_3': -16.573352813720703, 'loss_4': 1.1461597681045532, 'epoch': 17.64}
{'loss': 0.0177, 'grad_norm': 11.696516990661621, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.016959121450781822, 'loss_2': 0.00072479248046875, 'loss_3': -16.262737274169922, 'loss_4': 1.064481496810913, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 13:35:48,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:48,347 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:15:07<36:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:35:55,663 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022642500698566437, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.46, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.019006799906492233, 'eval_loss_2': 0.003635704517364502, 'eval_loss_3': -18.187747955322266, 'eval_loss_4': 0.6752825975418091, 'epoch': 17.65}
{'loss': 0.0152, 'grad_norm': 5.228941917419434, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.008139397017657757, 'loss_2': 0.00710296630859375, 'loss_3': -16.354753494262695, 'loss_4': 0.7468793392181396, 'epoch': 17.65}
{'loss': 0.0161, 'grad_norm': 8.070940971374512, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.014619858004152775, 'loss_2': 0.00146484375, 'loss_3': -16.496492385864258, 'loss_4': 0.5137852430343628, 'epoch': 17.66}
{'loss': 0.0205, 'grad_norm': 8.023544311523438, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.013220149092376232, 'loss_2': 0.0072784423828125, 'loss_3': -16.536376953125, 'loss_4': 1.0174624919891357, 'epoch': 17.66}
{'loss': 0.0261, 'grad_norm': 9.02026081085205, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.022243333980441093, 'loss_2': 0.00382232666015625, 'loss_3': -16.29613494873047, 'loss_4': 0.5357519388198853, 'epoch': 17.67}
{'loss': 0.0109, 'grad_norm': 4.8118438720703125, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.00700706010684371, 'loss_2': 0.003871917724609375, 'loss_3': -16.398954391479492, 'loss_4': 1.2220985889434814, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 13:35:55,663 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:55,663 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:14<36:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:02,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030852291733026505, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.428, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.027142440900206566, 'eval_loss_2': 0.003709852695465088, 'eval_loss_3': -18.136417388916016, 'eval_loss_4': 0.7402089834213257, 'epoch': 17.67}
{'loss': 0.0212, 'grad_norm': 5.4423322677612305, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.009616739116609097, 'loss_2': 0.01161956787109375, 'loss_3': -16.33610725402832, 'loss_4': 0.7102806568145752, 'epoch': 17.68}
{'loss': 0.0146, 'grad_norm': 5.087967872619629, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.009927420876920223, 'loss_2': 0.004638671875, 'loss_3': -16.48201560974121, 'loss_4': 0.8802887201309204, 'epoch': 17.69}
{'loss': 0.0239, 'grad_norm': 8.451037406921387, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.010307944379746914, 'loss_2': 0.01355743408203125, 'loss_3': -16.343246459960938, 'loss_4': 0.6131247282028198, 'epoch': 17.69}
{'loss': 0.0216, 'grad_norm': 7.07664680480957, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.012209941633045673, 'loss_2': 0.0094146728515625, 'loss_3': -16.08477783203125, 'loss_4': 0.7296736240386963, 'epoch': 17.7}
{'loss': 0.0076, 'grad_norm': 4.064903259277344, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.003992253448814154, 'loss_2': 0.003574371337890625, 'loss_3': -16.495037078857422, 'loss_4': 0.6203106045722961, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 13:36:02,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:02,990 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:22<36:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:36:10,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03486571088433266, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.412, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.032121215015649796, 'eval_loss_2': 0.0027444958686828613, 'eval_loss_3': -18.09296226501465, 'eval_loss_4': 0.7587817311286926, 'epoch': 17.7}
{'loss': 0.0121, 'grad_norm': 6.658229827880859, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.007845116779208183, 'loss_2': 0.0042572021484375, 'loss_3': -16.452198028564453, 'loss_4': 0.4298931360244751, 'epoch': 17.71}
{'loss': 0.0063, 'grad_norm': 4.562222003936768, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.005854043643921614, 'loss_2': 0.00043201446533203125, 'loss_3': -16.47649574279785, 'loss_4': 1.1811212301254272, 'epoch': 17.72}
{'loss': 0.0187, 'grad_norm': 5.486080169677734, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.010179848410189152, 'loss_2': 0.00853729248046875, 'loss_3': -16.412940979003906, 'loss_4': 0.9093393087387085, 'epoch': 17.72}
{'loss': 0.0106, 'grad_norm': 5.3562116622924805, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.008389108814299107, 'loss_2': 0.0022430419921875, 'loss_3': -16.53021240234375, 'loss_4': 1.0395272970199585, 'epoch': 17.73}
{'loss': 0.0091, 'grad_norm': 5.468433856964111, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.00751361483708024, 'loss_2': 0.0015659332275390625, 'loss_3': -16.31834602355957, 'loss_4': 0.5647974014282227, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 13:36:10,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:10,310 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:29<36:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:17,638 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03721744194626808, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.021, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.03258857503533363, 'eval_loss_2': 0.004628866910934448, 'eval_loss_3': -18.09134864807129, 'eval_loss_4': 0.699933648109436, 'epoch': 17.73}
{'loss': 0.0297, 'grad_norm': 14.814620971679688, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.023278072476387024, 'loss_2': 0.00643157958984375, 'loss_3': -16.399036407470703, 'loss_4': 1.3321518898010254, 'epoch': 17.74}
{'loss': 0.0271, 'grad_norm': 9.154345512390137, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.016039803624153137, 'loss_2': 0.0110321044921875, 'loss_3': -16.264076232910156, 'loss_4': 0.8461465835571289, 'epoch': 17.74}
{'loss': 0.0103, 'grad_norm': 4.5783209800720215, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.006654042284935713, 'loss_2': 0.003604888916015625, 'loss_3': -16.335607528686523, 'loss_4': 1.4572350978851318, 'epoch': 17.75}
{'loss': 0.017, 'grad_norm': 7.492774486541748, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.013546103611588478, 'loss_2': 0.0034847259521484375, 'loss_3': -16.094480514526367, 'loss_4': 0.8024752736091614, 'epoch': 17.76}
{'loss': 0.0115, 'grad_norm': 5.79506254196167, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.009232045151293278, 'loss_2': 0.0022869110107421875, 'loss_3': -16.314285278320312, 'loss_4': 0.9248782992362976, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 13:36:17,639 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:17,639 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:36<36:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:24,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04169274866580963, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.425, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.0354355163872242, 'eval_loss_2': 0.006257236003875732, 'eval_loss_3': -18.076763153076172, 'eval_loss_4': 0.5495458841323853, 'epoch': 17.76}
{'loss': 0.0083, 'grad_norm': 7.376193046569824, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.008043864741921425, 'loss_2': 0.0002770423889160156, 'loss_3': -16.30082893371582, 'loss_4': 0.5881106853485107, 'epoch': 17.77}
{'loss': 0.0155, 'grad_norm': 5.752299785614014, 'learning_rate': 1.225e-05, 'loss_1': 0.0078922463580966, 'loss_2': 0.007598876953125, 'loss_3': -16.49386215209961, 'loss_4': 0.6178902983665466, 'epoch': 17.77}
{'loss': 0.0383, 'grad_norm': 12.52928352355957, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.02871222048997879, 'loss_2': 0.009552001953125, 'loss_3': -16.19469451904297, 'loss_4': 0.9406466484069824, 'epoch': 17.78}
{'loss': 0.0136, 'grad_norm': 5.972273826599121, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.010230605490505695, 'loss_2': 0.003414154052734375, 'loss_3': -16.367382049560547, 'loss_4': 0.36553284525871277, 'epoch': 17.78}
{'loss': 0.0194, 'grad_norm': 10.69622802734375, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.01920851692557335, 'loss_2': 0.0001938343048095703, 'loss_3': -16.35147476196289, 'loss_4': 0.7116395831108093, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 13:36:24,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:24,965 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:44<36:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:32,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05723895505070686, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.264, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.05402204394340515, 'eval_loss_2': 0.0032169073820114136, 'eval_loss_3': -18.029693603515625, 'eval_loss_4': 0.4255550801753998, 'epoch': 17.79}
{'loss': 0.0197, 'grad_norm': 6.76081657409668, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.011480683460831642, 'loss_2': 0.0082550048828125, 'loss_3': -16.306074142456055, 'loss_4': 0.6960315108299255, 'epoch': 17.8}
{'loss': 0.0177, 'grad_norm': 8.422417640686035, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.01657830737531185, 'loss_2': 0.0010852813720703125, 'loss_3': -16.446922302246094, 'loss_4': 0.534420907497406, 'epoch': 17.8}
{'loss': 0.0168, 'grad_norm': 4.81990385055542, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.013235094957053661, 'loss_2': 0.00353240966796875, 'loss_3': -16.301868438720703, 'loss_4': 0.22769120335578918, 'epoch': 17.81}
{'loss': 0.0101, 'grad_norm': 6.055891513824463, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.0074125025421381, 'loss_2': 0.0026493072509765625, 'loss_3': -16.507301330566406, 'loss_4': 0.7431837916374207, 'epoch': 17.81}
{'loss': 0.0259, 'grad_norm': 7.447377681732178, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.023586289957165718, 'loss_2': 0.0023193359375, 'loss_3': -16.471994400024414, 'loss_4': 0.654764711856842, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 13:36:32,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:32,292 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:51<36:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:36:39,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0773201659321785, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.402, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.07463864237070084, 'eval_loss_2': 0.002681523561477661, 'eval_loss_3': -17.969724655151367, 'eval_loss_4': 0.34839847683906555, 'epoch': 17.82}
{'loss': 0.0133, 'grad_norm': 6.307796001434326, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.011836583726108074, 'loss_2': 0.0015087127685546875, 'loss_3': -16.23102378845215, 'loss_4': 0.1320686936378479, 'epoch': 17.83}
{'loss': 0.1277, 'grad_norm': 31.30035400390625, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.1267605572938919, 'loss_2': 0.0008897781372070312, 'loss_3': -16.2331485748291, 'loss_4': 0.7140756845474243, 'epoch': 17.83}
{'loss': 0.0093, 'grad_norm': 5.531764030456543, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.008558904752135277, 'loss_2': 0.0007181167602539062, 'loss_3': -16.360700607299805, 'loss_4': 0.6717663407325745, 'epoch': 17.84}
{'loss': 0.0094, 'grad_norm': 4.3094024658203125, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.0051909517496824265, 'loss_2': 0.004192352294921875, 'loss_3': -16.435714721679688, 'loss_4': 0.1380511075258255, 'epoch': 17.84}
{'loss': 0.0091, 'grad_norm': 5.3475165367126465, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.0062094577588140965, 'loss_2': 0.00293731689453125, 'loss_3': -16.373584747314453, 'loss_4': 0.5355671644210815, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 13:36:39,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:39,614 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:15:59<36:27,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:36:47,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03675743192434311, 'eval_runtime': 3.9912, 'eval_samples_per_second': 256.565, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.03467225283384323, 'eval_loss_2': 0.002085179090499878, 'eval_loss_3': -18.098655700683594, 'eval_loss_4': 0.22327524423599243, 'epoch': 17.85}
{'loss': 0.0231, 'grad_norm': 8.67028522491455, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.009694581851363182, 'loss_2': 0.01336669921875, 'loss_3': -16.21419906616211, 'loss_4': 0.24396298825740814, 'epoch': 17.85}
{'loss': 0.0071, 'grad_norm': 4.6139936447143555, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.004341410472989082, 'loss_2': 0.0027618408203125, 'loss_3': -16.317893981933594, 'loss_4': 0.37362322211265564, 'epoch': 17.86}
{'loss': 0.0109, 'grad_norm': 6.892724990844727, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.01083302404731512, 'loss_2': 9.232759475708008e-05, 'loss_3': -16.468055725097656, 'loss_4': 0.2213805615901947, 'epoch': 17.87}
{'loss': 0.0222, 'grad_norm': 6.54831600189209, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.012740648351609707, 'loss_2': 0.0094757080078125, 'loss_3': -16.289379119873047, 'loss_4': 0.5667257308959961, 'epoch': 17.87}
{'loss': 0.0123, 'grad_norm': 5.604903697967529, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.007948817685246468, 'loss_2': 0.00437164306640625, 'loss_3': -16.307125091552734, 'loss_4': 0.7233635783195496, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 13:36:47,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:47,142 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:16:06<35:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:54,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024244416505098343, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.02219291590154171, 'eval_loss_2': 0.0020515024662017822, 'eval_loss_3': -18.167110443115234, 'eval_loss_4': 0.11640508472919464, 'epoch': 17.88}
{'loss': 0.0185, 'grad_norm': 5.248923301696777, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.00828416459262371, 'loss_2': 0.01021575927734375, 'loss_3': -16.410728454589844, 'loss_4': 0.32850927114486694, 'epoch': 17.88}
{'loss': 0.0104, 'grad_norm': 4.409250736236572, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.005526104010641575, 'loss_2': 0.00490570068359375, 'loss_3': -16.475997924804688, 'loss_4': -0.019085371866822243, 'epoch': 17.89}
{'loss': 0.0085, 'grad_norm': 5.055841445922852, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.007204434368759394, 'loss_2': 0.0013284683227539062, 'loss_3': -16.308063507080078, 'loss_4': 0.29286304116249084, 'epoch': 17.9}
{'loss': 0.0103, 'grad_norm': 6.749858379364014, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.010103991255164146, 'loss_2': 0.0001952648162841797, 'loss_3': -16.187496185302734, 'loss_4': 0.08488782495260239, 'epoch': 17.9}
{'loss': 0.0193, 'grad_norm': 8.482867240905762, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.01822228915989399, 'loss_2': 0.0010900497436523438, 'loss_3': -16.1837158203125, 'loss_4': -0.164913147687912, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 13:36:54,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:54,474 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:13<35:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:01,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021037202328443527, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01774541661143303, 'eval_loss_2': 0.003291785717010498, 'eval_loss_3': -18.192092895507812, 'eval_loss_4': 0.01327439583837986, 'epoch': 17.91}
{'loss': 0.0103, 'grad_norm': 5.152000427246094, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.005117753520607948, 'loss_2': 0.00522613525390625, 'loss_3': -16.421476364135742, 'loss_4': 0.10084067285060883, 'epoch': 17.91}
{'loss': 0.068, 'grad_norm': 19.63597297668457, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.06332192569971085, 'loss_2': 0.004638671875, 'loss_3': -16.572267532348633, 'loss_4': 0.5802470445632935, 'epoch': 17.92}
{'loss': 0.0275, 'grad_norm': 13.872321128845215, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.024681871756911278, 'loss_2': 0.00283050537109375, 'loss_3': -16.407821655273438, 'loss_4': -0.2288256138563156, 'epoch': 17.92}
{'loss': 0.007, 'grad_norm': 5.272475719451904, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.006727298256009817, 'loss_2': 0.0002498626708984375, 'loss_3': -16.505111694335938, 'loss_4': 0.3089558780193329, 'epoch': 17.93}
{'loss': 0.0102, 'grad_norm': 5.674923419952393, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.006418803706765175, 'loss_2': 0.00377655029296875, 'loss_3': -16.297697067260742, 'loss_4': 0.3566741645336151, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 13:37:01,806 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:01,806 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:21<35:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:09,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023552175611257553, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.272, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.018035318702459335, 'eval_loss_2': 0.005516856908798218, 'eval_loss_3': -18.214506149291992, 'eval_loss_4': -0.002171561121940613, 'epoch': 17.94}
{'loss': 0.0167, 'grad_norm': 5.431973457336426, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.011675817891955376, 'loss_2': 0.00505828857421875, 'loss_3': -16.47926139831543, 'loss_4': 0.3478461503982544, 'epoch': 17.94}
{'loss': 0.0145, 'grad_norm': 6.827909469604492, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.009346160106360912, 'loss_2': 0.00518035888671875, 'loss_3': -16.431297302246094, 'loss_4': 0.14081265032291412, 'epoch': 17.95}
{'loss': 0.0129, 'grad_norm': 5.09160852432251, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.009343241341412067, 'loss_2': 0.00359344482421875, 'loss_3': -16.374378204345703, 'loss_4': 0.4634725749492645, 'epoch': 17.95}
{'loss': 0.0656, 'grad_norm': 23.157470703125, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.06357073038816452, 'loss_2': 0.002079010009765625, 'loss_3': -16.517183303833008, 'loss_4': 0.33975309133529663, 'epoch': 17.96}
{'loss': 0.0098, 'grad_norm': 4.92576789855957, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.00773335387930274, 'loss_2': 0.0020351409912109375, 'loss_3': -16.543893814086914, 'loss_4': 0.21607451140880585, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 13:37:09,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:09,136 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:28<35:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:37:16,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019802074879407883, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.261, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.017277056351304054, 'eval_loss_2': 0.002525016665458679, 'eval_loss_3': -18.204679489135742, 'eval_loss_4': 0.07289903610944748, 'epoch': 17.97}
{'loss': 0.0225, 'grad_norm': 12.416351318359375, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.019871894270181656, 'loss_2': 0.002674102783203125, 'loss_3': -16.497814178466797, 'loss_4': 0.3880045711994171, 'epoch': 17.97}
{'loss': 0.0133, 'grad_norm': 4.54010009765625, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.006833097897469997, 'loss_2': 0.006435394287109375, 'loss_3': -16.472978591918945, 'loss_4': 0.18641109764575958, 'epoch': 17.98}
{'loss': 0.0132, 'grad_norm': 5.211361885070801, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.012438366189599037, 'loss_2': 0.0007572174072265625, 'loss_3': -16.27718734741211, 'loss_4': 0.2270919233560562, 'epoch': 17.98}
{'loss': 0.0111, 'grad_norm': 6.566495895385742, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.010571522638201714, 'loss_2': 0.0005235671997070312, 'loss_3': -16.216266632080078, 'loss_4': 0.34441229701042175, 'epoch': 17.99}
{'loss': 0.0092, 'grad_norm': 6.849917888641357, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.009213674813508987, 'loss_2': 3.0159950256347656e-05, 'loss_3': -16.327194213867188, 'loss_4': 0.43145886063575745, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 13:37:16,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:16,453 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:35<34:49,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:37:23,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020899411290884018, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.105, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.018115805462002754, 'eval_loss_2': 0.002783607691526413, 'eval_loss_3': -18.20562171936035, 'eval_loss_4': 0.2738782465457916, 'epoch': 17.99}
{'loss': 0.0029, 'grad_norm': 6.509073734283447, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.002525055082514882, 'loss_2': 0.0003330707550048828, 'loss_3': -16.126007080078125, 'loss_4': 0.014901258982717991, 'epoch': 18.0}
{'loss': 0.0255, 'grad_norm': 7.651662826538086, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.018071001395583153, 'loss_2': 0.0074615478515625, 'loss_3': -16.542469024658203, 'loss_4': 1.2171003818511963, 'epoch': 18.01}
{'loss': 0.0387, 'grad_norm': 17.829378128051758, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.034627385437488556, 'loss_2': 0.00406646728515625, 'loss_3': -16.287315368652344, 'loss_4': 0.39956146478652954, 'epoch': 18.01}
{'loss': 0.0051, 'grad_norm': 4.131399631500244, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.0035273695830255747, 'loss_2': 0.0015239715576171875, 'loss_3': -16.64279556274414, 'loss_4': 0.2944484353065491, 'epoch': 18.02}
{'loss': 0.0099, 'grad_norm': 6.531247138977051, 'learning_rate': 1.2e-05, 'loss_1': 0.008226445876061916, 'loss_2': 0.0016803741455078125, 'loss_3': -16.39510154724121, 'loss_4': 1.0122027397155762, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 13:37:23,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:23,486 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:42<35:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:37:30,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022403208538889885, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.178, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01916222833096981, 'eval_loss_2': 0.0032409802079200745, 'eval_loss_3': -18.189668655395508, 'eval_loss_4': 0.3380025625228882, 'epoch': 18.02}
{'loss': 0.0084, 'grad_norm': 4.36859655380249, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.0044992039911448956, 'loss_2': 0.00392913818359375, 'loss_3': -16.400815963745117, 'loss_4': 0.7856354713439941, 'epoch': 18.03}
{'loss': 0.0137, 'grad_norm': 6.057099342346191, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.00891022477298975, 'loss_2': 0.00475311279296875, 'loss_3': -16.59294319152832, 'loss_4': 0.21041353046894073, 'epoch': 18.03}
{'loss': 0.0087, 'grad_norm': 4.749815940856934, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.005404194816946983, 'loss_2': 0.0032501220703125, 'loss_3': -16.339590072631836, 'loss_4': 0.4514427185058594, 'epoch': 18.04}
{'loss': 0.012, 'grad_norm': 5.1111016273498535, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.007699120324105024, 'loss_2': 0.00431060791015625, 'loss_3': -16.501365661621094, 'loss_4': 0.4383713901042938, 'epoch': 18.05}
{'loss': 0.0264, 'grad_norm': 8.364095687866211, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.013777229934930801, 'loss_2': 0.01261138916015625, 'loss_3': -16.400123596191406, 'loss_4': 0.7813234329223633, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 13:37:30,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:30,816 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:50<35:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:38,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02237667888402939, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.194, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.019443105906248093, 'eval_loss_2': 0.0029335729777812958, 'eval_loss_3': -18.19178581237793, 'eval_loss_4': 0.315625935792923, 'epoch': 18.05}
{'loss': 0.0113, 'grad_norm': 4.681231498718262, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.0071425423957407475, 'loss_2': 0.00414276123046875, 'loss_3': -16.33496856689453, 'loss_4': 0.4225643277168274, 'epoch': 18.06}
{'loss': 0.0142, 'grad_norm': 5.206360340118408, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.00602461863309145, 'loss_2': 0.00817108154296875, 'loss_3': -16.403480529785156, 'loss_4': 0.7318516969680786, 'epoch': 18.06}
{'loss': 0.0129, 'grad_norm': 5.286954402923584, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.007418970577418804, 'loss_2': 0.005462646484375, 'loss_3': -16.36676025390625, 'loss_4': 0.2011619657278061, 'epoch': 18.07}
{'loss': 0.0116, 'grad_norm': 5.3972086906433105, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.008011778816580772, 'loss_2': 0.00360870361328125, 'loss_3': -16.403474807739258, 'loss_4': 0.7692582607269287, 'epoch': 18.08}
{'loss': 0.022, 'grad_norm': 11.895691871643066, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.020359812304377556, 'loss_2': 0.001628875732421875, 'loss_3': -16.249486923217773, 'loss_4': 0.4783158302307129, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 13:37:38,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:38,147 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:16:57<35:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:37:45,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02448159269988537, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.303, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.021094318479299545, 'eval_loss_2': 0.003387272357940674, 'eval_loss_3': -18.189437866210938, 'eval_loss_4': 0.15285615622997284, 'epoch': 18.08}
{'loss': 0.0194, 'grad_norm': 9.034308433532715, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.012653728015720844, 'loss_2': 0.00672149658203125, 'loss_3': -16.484092712402344, 'loss_4': 0.39663317799568176, 'epoch': 18.09}
{'loss': 0.0141, 'grad_norm': 5.878835678100586, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.013282976113259792, 'loss_2': 0.0007886886596679688, 'loss_3': -16.449607849121094, 'loss_4': 0.3737395703792572, 'epoch': 18.09}
{'loss': 0.0091, 'grad_norm': 4.8595356941223145, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.004787416663020849, 'loss_2': 0.004302978515625, 'loss_3': -16.47740364074707, 'loss_4': 0.24658751487731934, 'epoch': 18.1}
{'loss': 0.0058, 'grad_norm': 4.673873424530029, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.00454220175743103, 'loss_2': 0.0012960433959960938, 'loss_3': -16.526546478271484, 'loss_4': -0.382009893655777, 'epoch': 18.1}
{'loss': 0.0362, 'grad_norm': 14.35822582244873, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.03161032125353813, 'loss_2': 0.004573822021484375, 'loss_3': -16.50326919555664, 'loss_4': 0.3870526850223541, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 13:37:45,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:45,471 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:17:04<35:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:37:52,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02522018924355507, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.368, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.022437484934926033, 'eval_loss_2': 0.0027827024459838867, 'eval_loss_3': -18.182170867919922, 'eval_loss_4': 0.10594485700130463, 'epoch': 18.11}
{'loss': 0.0084, 'grad_norm': 4.971378803253174, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.006817508488893509, 'loss_2': 0.001537322998046875, 'loss_3': -16.421398162841797, 'loss_4': 0.1518544852733612, 'epoch': 18.12}
{'loss': 0.0253, 'grad_norm': 27.204036712646484, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.022206299006938934, 'loss_2': 0.0031299591064453125, 'loss_3': -16.426441192626953, 'loss_4': 0.3114309012889862, 'epoch': 18.12}
{'loss': 0.0138, 'grad_norm': 5.67894983291626, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.013707950711250305, 'loss_2': 7.605552673339844e-05, 'loss_3': -16.52480697631836, 'loss_4': -0.0025199949741363525, 'epoch': 18.13}
{'loss': 0.0237, 'grad_norm': 12.928580284118652, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.022601760923862457, 'loss_2': 0.0011444091796875, 'loss_3': -16.250843048095703, 'loss_4': -0.19397732615470886, 'epoch': 18.13}
{'loss': 0.0201, 'grad_norm': 7.011017322540283, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.013730489648878574, 'loss_2': 0.006404876708984375, 'loss_3': -16.16519546508789, 'loss_4': 0.49463871121406555, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 13:37:52,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:52,788 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:12<35:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:00,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023278113454580307, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.396, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01973242312669754, 'eval_loss_2': 0.0035456866025924683, 'eval_loss_3': -18.182769775390625, 'eval_loss_4': 0.1599046289920807, 'epoch': 18.14}
{'loss': 0.0123, 'grad_norm': 4.992082595825195, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.0065682874992489815, 'loss_2': 0.005767822265625, 'loss_3': -16.50092887878418, 'loss_4': 0.11316093057394028, 'epoch': 18.15}
{'loss': 0.008, 'grad_norm': 4.432307243347168, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.004160234704613686, 'loss_2': 0.0038356781005859375, 'loss_3': -16.388317108154297, 'loss_4': 0.3050041198730469, 'epoch': 18.15}
{'loss': 0.0089, 'grad_norm': 4.573716640472412, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.004021742381155491, 'loss_2': 0.004856109619140625, 'loss_3': -16.334728240966797, 'loss_4': 0.8327268362045288, 'epoch': 18.16}
{'loss': 0.0073, 'grad_norm': 4.334470272064209, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.005367509089410305, 'loss_2': 0.001918792724609375, 'loss_3': -16.513572692871094, 'loss_4': 1.1135492324829102, 'epoch': 18.16}
{'loss': 0.0134, 'grad_norm': 4.650181770324707, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.008203864097595215, 'loss_2': 0.00519561767578125, 'loss_3': -16.29123878479004, 'loss_4': 0.4302818179130554, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 13:38:00,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:00,117 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:19<35:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:38:07,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022248584777116776, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.3, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01817803457379341, 'eval_loss_2': 0.004070550203323364, 'eval_loss_3': -18.201513290405273, 'eval_loss_4': 0.16048064827919006, 'epoch': 18.17}
{'loss': 0.01, 'grad_norm': 5.551259517669678, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.00488335220143199, 'loss_2': 0.00513458251953125, 'loss_3': -16.33306312561035, 'loss_4': 0.2427913099527359, 'epoch': 18.17}
{'loss': 0.0148, 'grad_norm': 5.4224395751953125, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.009965712204575539, 'loss_2': 0.00482940673828125, 'loss_3': -16.44794464111328, 'loss_4': 0.38808178901672363, 'epoch': 18.18}
{'loss': 0.0098, 'grad_norm': 5.318496227264404, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.0071790642105042934, 'loss_2': 0.0026226043701171875, 'loss_3': -16.334253311157227, 'loss_4': 0.4555341899394989, 'epoch': 18.19}
{'loss': 0.0249, 'grad_norm': 10.091606140136719, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.019018955528736115, 'loss_2': 0.00585174560546875, 'loss_3': -16.282821655273438, 'loss_4': 0.47204887866973877, 'epoch': 18.19}
{'loss': 0.0096, 'grad_norm': 4.701240539550781, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.008276124484837055, 'loss_2': 0.001369476318359375, 'loss_3': -16.519336700439453, 'loss_4': 0.39940714836120605, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 13:38:07,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:07,440 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:26<34:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:14,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018617253750562668, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.415, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015457266010344028, 'eval_loss_2': 0.003159988671541214, 'eval_loss_3': -18.211435317993164, 'eval_loss_4': 0.0985935777425766, 'epoch': 18.2}
{'loss': 0.0078, 'grad_norm': 5.195945739746094, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.006657078396528959, 'loss_2': 0.0011587142944335938, 'loss_3': -16.368473052978516, 'loss_4': 0.4676905870437622, 'epoch': 18.2}
{'loss': 0.0089, 'grad_norm': 4.506886959075928, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.0035260047297924757, 'loss_2': 0.005405426025390625, 'loss_3': -16.424497604370117, 'loss_4': 0.6281201243400574, 'epoch': 18.21}
{'loss': 0.0055, 'grad_norm': 5.196990966796875, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.004978087265044451, 'loss_2': 0.0005321502685546875, 'loss_3': -16.44272232055664, 'loss_4': 0.25992080569267273, 'epoch': 18.22}
{'loss': 0.013, 'grad_norm': 4.979950428009033, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.008156544528901577, 'loss_2': 0.00482177734375, 'loss_3': -16.52005958557129, 'loss_4': 0.10072286427021027, 'epoch': 18.22}
{'loss': 0.015, 'grad_norm': 5.8407673835754395, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.00999803002923727, 'loss_2': 0.004985809326171875, 'loss_3': -16.417179107666016, 'loss_4': 0.6160103678703308, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 13:38:14,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:14,766 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:34<34:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:22,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01845027506351471, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.568, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015095576643943787, 'eval_loss_2': 0.003354698419570923, 'eval_loss_3': -18.22022819519043, 'eval_loss_4': 0.08417695015668869, 'epoch': 18.23}
{'loss': 0.0101, 'grad_norm': 5.857620716094971, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.009878870099782944, 'loss_2': 0.00018656253814697266, 'loss_3': -16.337078094482422, 'loss_4': 0.22167235612869263, 'epoch': 18.23}
{'loss': 0.0143, 'grad_norm': 6.149815559387207, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.009137310087680817, 'loss_2': 0.005126953125, 'loss_3': -16.413921356201172, 'loss_4': 0.08340466022491455, 'epoch': 18.24}
{'loss': 0.0181, 'grad_norm': 5.942545413970947, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.00932383630424738, 'loss_2': 0.00872802734375, 'loss_3': -16.409250259399414, 'loss_4': 0.31568390130996704, 'epoch': 18.24}
{'loss': 0.0198, 'grad_norm': 11.031073570251465, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.018816547468304634, 'loss_2': 0.0010280609130859375, 'loss_3': -16.450206756591797, 'loss_4': 0.22296147048473358, 'epoch': 18.25}
{'loss': 0.0058, 'grad_norm': 4.37392520904541, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.004151829052716494, 'loss_2': 0.0016345977783203125, 'loss_3': -16.498109817504883, 'loss_4': 0.5507160425186157, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 13:38:22,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:22,105 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:41<34:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:29,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01741461455821991, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.046, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014087514020502567, 'eval_loss_2': 0.003327101469039917, 'eval_loss_3': -18.228899002075195, 'eval_loss_4': 0.0636373981833458, 'epoch': 18.26}
{'loss': 0.005, 'grad_norm': 4.622735977172852, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.0034010077361017466, 'loss_2': 0.00164031982421875, 'loss_3': -16.462905883789062, 'loss_4': 0.005582764744758606, 'epoch': 18.26}
{'loss': 0.0159, 'grad_norm': 6.021216869354248, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.009820815175771713, 'loss_2': 0.006103515625, 'loss_3': -16.54326057434082, 'loss_4': 0.7722432613372803, 'epoch': 18.27}
{'loss': 0.0491, 'grad_norm': 18.005748748779297, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.04354429244995117, 'loss_2': 0.00555419921875, 'loss_3': -16.37457847595215, 'loss_4': 0.7415012121200562, 'epoch': 18.27}
{'loss': 0.0219, 'grad_norm': 10.25366497039795, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.019720857962965965, 'loss_2': 0.002223968505859375, 'loss_3': -16.424560546875, 'loss_4': -0.02552706003189087, 'epoch': 18.28}
{'loss': 0.0058, 'grad_norm': 4.901437282562256, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.004535457585006952, 'loss_2': 0.0012969970703125, 'loss_3': -16.350637435913086, 'loss_4': -0.03046250343322754, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 13:38:29,435 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:29,435 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:48<34:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:36,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01662011817097664, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.305, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013898428529500961, 'eval_loss_2': 0.0027216896414756775, 'eval_loss_3': -18.262802124023438, 'eval_loss_4': 0.07104597240686417, 'epoch': 18.28}
{'loss': 0.0104, 'grad_norm': 5.724956035614014, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.0073628053069114685, 'loss_2': 0.003040313720703125, 'loss_3': -16.311756134033203, 'loss_4': 0.2389560043811798, 'epoch': 18.29}
{'loss': 0.0206, 'grad_norm': 6.135796070098877, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.017688652500510216, 'loss_2': 0.002933502197265625, 'loss_3': -16.445344924926758, 'loss_4': 0.4972427785396576, 'epoch': 18.3}
{'loss': 0.0199, 'grad_norm': 6.771625995635986, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.014181003905832767, 'loss_2': 0.005672454833984375, 'loss_3': -16.36270523071289, 'loss_4': 0.4243257939815521, 'epoch': 18.3}
{'loss': 0.0107, 'grad_norm': 5.516377925872803, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.007940514013171196, 'loss_2': 0.0027484893798828125, 'loss_3': -16.45575714111328, 'loss_4': 0.04494316130876541, 'epoch': 18.31}
{'loss': 0.012, 'grad_norm': 5.098511695861816, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.009809416718780994, 'loss_2': 0.002185821533203125, 'loss_3': -16.39144515991211, 'loss_4': 0.7288346886634827, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 13:38:36,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:36,765 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:17:56<34:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:38:44,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016387004405260086, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.443, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013999956659972668, 'eval_loss_2': 0.0023870468139648438, 'eval_loss_3': -18.2640380859375, 'eval_loss_4': 0.09592029452323914, 'epoch': 18.31}
{'loss': 0.0095, 'grad_norm': 4.334500312805176, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.005677816923707724, 'loss_2': 0.00384521484375, 'loss_3': -16.480575561523438, 'loss_4': 1.1856565475463867, 'epoch': 18.32}
{'loss': 0.0101, 'grad_norm': 4.941566467285156, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.005998409818857908, 'loss_2': 0.00408172607421875, 'loss_3': -16.499746322631836, 'loss_4': 0.347345232963562, 'epoch': 18.33}
{'loss': 0.0116, 'grad_norm': 5.135873317718506, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.00930110178887844, 'loss_2': 0.0023097991943359375, 'loss_3': -16.52138900756836, 'loss_4': 0.9853688478469849, 'epoch': 18.33}
{'loss': 0.0161, 'grad_norm': 6.3533196449279785, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.01024386752396822, 'loss_2': 0.005859375, 'loss_3': -16.48847198486328, 'loss_4': 0.6126875281333923, 'epoch': 18.34}
{'loss': 0.01, 'grad_norm': 5.773297309875488, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.009125689044594765, 'loss_2': 0.0008859634399414062, 'loss_3': -16.317981719970703, 'loss_4': -0.07709573954343796, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 13:38:44,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:44,088 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:18:03<34:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:38:51,412 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01868307590484619, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.56, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015275358222424984, 'eval_loss_2': 0.003407716751098633, 'eval_loss_3': -18.255165100097656, 'eval_loss_4': 0.21219423413276672, 'epoch': 18.34}
{'loss': 0.0149, 'grad_norm': 5.360631942749023, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.007751055993139744, 'loss_2': 0.0071868896484375, 'loss_3': -16.530900955200195, 'loss_4': 0.7669238448143005, 'epoch': 18.35}
{'loss': 0.0249, 'grad_norm': 8.011448860168457, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.015949733555316925, 'loss_2': 0.00899505615234375, 'loss_3': -16.483314514160156, 'loss_4': 0.34733739495277405, 'epoch': 18.35}
{'loss': 0.0105, 'grad_norm': 5.205359935760498, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.004563287831842899, 'loss_2': 0.00595855712890625, 'loss_3': -16.275493621826172, 'loss_4': 0.48177123069763184, 'epoch': 18.36}
{'loss': 0.0243, 'grad_norm': 8.087963104248047, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.01654987968504429, 'loss_2': 0.00775909423828125, 'loss_3': -16.51837921142578, 'loss_4': 0.5969867706298828, 'epoch': 18.37}
{'loss': 0.0243, 'grad_norm': 6.95026159286499, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.01886342279613018, 'loss_2': 0.00539398193359375, 'loss_3': -16.312519073486328, 'loss_4': 0.89621901512146, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 13:38:51,412 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:51,412 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:10<34:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:58,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020722489804029465, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.965, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.017392298206686974, 'eval_loss_2': 0.003330189734697342, 'eval_loss_3': -18.24814796447754, 'eval_loss_4': 0.31885188817977905, 'epoch': 18.37}
{'loss': 0.0073, 'grad_norm': 4.40297794342041, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.006710660178214312, 'loss_2': 0.0005426406860351562, 'loss_3': -16.321203231811523, 'loss_4': 0.6693283319473267, 'epoch': 18.38}
{'loss': 0.0102, 'grad_norm': 4.45720100402832, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.006265440955758095, 'loss_2': 0.00392913818359375, 'loss_3': -16.510478973388672, 'loss_4': 0.8431748747825623, 'epoch': 18.38}
{'loss': 0.009, 'grad_norm': 4.891541957855225, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.006378633435815573, 'loss_2': 0.002643585205078125, 'loss_3': -16.462963104248047, 'loss_4': 1.0341308116912842, 'epoch': 18.39}
{'loss': 0.0177, 'grad_norm': 5.051152229309082, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.008703503757715225, 'loss_2': 0.0090179443359375, 'loss_3': -16.483673095703125, 'loss_4': 0.5101860761642456, 'epoch': 18.4}
{'loss': 0.0112, 'grad_norm': 6.111924648284912, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.010826526209712029, 'loss_2': 0.0003757476806640625, 'loss_3': -16.333433151245117, 'loss_4': 0.932275652885437, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 13:38:58,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:58,749 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:18<34:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:06,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020301461219787598, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.125, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01737731508910656, 'eval_loss_2': 0.0029241442680358887, 'eval_loss_3': -18.258541107177734, 'eval_loss_4': 0.398280531167984, 'epoch': 18.4}
{'loss': 0.0233, 'grad_norm': 13.415365219116211, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.0176597461104393, 'loss_2': 0.00560760498046875, 'loss_3': -16.522069931030273, 'loss_4': 0.36339712142944336, 'epoch': 18.41}
{'loss': 0.0168, 'grad_norm': 5.9423723220825195, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.012853417545557022, 'loss_2': 0.003917694091796875, 'loss_3': -16.303424835205078, 'loss_4': 0.6497300863265991, 'epoch': 18.41}
{'loss': 0.0211, 'grad_norm': 9.383709907531738, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.014452533796429634, 'loss_2': 0.00662994384765625, 'loss_3': -16.466466903686523, 'loss_4': 0.7745330333709717, 'epoch': 18.42}
{'loss': 0.0077, 'grad_norm': 4.841049671173096, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.0044424389488995075, 'loss_2': 0.003299713134765625, 'loss_3': -16.539478302001953, 'loss_4': 0.5598777532577515, 'epoch': 18.42}
{'loss': 0.014, 'grad_norm': 5.648182392120361, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.011691685765981674, 'loss_2': 0.002330780029296875, 'loss_3': -16.418832778930664, 'loss_4': 0.8527330756187439, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 13:39:06,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:06,079 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:25<34:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:13,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020589765161275864, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.332, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01790551468729973, 'eval_loss_2': 0.0026842504739761353, 'eval_loss_3': -18.259000778198242, 'eval_loss_4': 0.3842288851737976, 'epoch': 18.43}
{'loss': 0.0099, 'grad_norm': 4.702334403991699, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.006244778633117676, 'loss_2': 0.003620147705078125, 'loss_3': -16.387920379638672, 'loss_4': 0.6704866886138916, 'epoch': 18.44}
{'loss': 0.0101, 'grad_norm': 5.2081379890441895, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.007485754322260618, 'loss_2': 0.0026187896728515625, 'loss_3': -16.469114303588867, 'loss_4': 0.2305140495300293, 'epoch': 18.44}
{'loss': 0.0095, 'grad_norm': 5.255867004394531, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.007333673071116209, 'loss_2': 0.00212860107421875, 'loss_3': -16.525915145874023, 'loss_4': 0.9056535959243774, 'epoch': 18.45}
{'loss': 0.0272, 'grad_norm': 8.916057586669922, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.01733890362083912, 'loss_2': 0.00983428955078125, 'loss_3': -16.330955505371094, 'loss_4': 1.0787371397018433, 'epoch': 18.45}
{'loss': 0.0146, 'grad_norm': 5.817122936248779, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.011848432943224907, 'loss_2': 0.002735137939453125, 'loss_3': -16.33460807800293, 'loss_4': 0.40447354316711426, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 13:39:13,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:13,407 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:32<34:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:39:20,733 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020267874002456665, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.019, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.017232179641723633, 'eval_loss_2': 0.0030356943607330322, 'eval_loss_3': -18.27892303466797, 'eval_loss_4': 0.3028343915939331, 'epoch': 18.46}
{'loss': 0.011, 'grad_norm': 5.108251094818115, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.010286680422723293, 'loss_2': 0.0007524490356445312, 'loss_3': -16.42803192138672, 'loss_4': 0.4025431275367737, 'epoch': 18.47}
{'loss': 0.0116, 'grad_norm': 4.942209720611572, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.010878382250666618, 'loss_2': 0.0006861686706542969, 'loss_3': -16.36492156982422, 'loss_4': 0.8759027719497681, 'epoch': 18.47}
{'loss': 0.047, 'grad_norm': 14.295238494873047, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.03976302221417427, 'loss_2': 0.00727081298828125, 'loss_3': -16.62238121032715, 'loss_4': 1.115242838859558, 'epoch': 18.48}
{'loss': 0.0542, 'grad_norm': 17.039810180664062, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.04417891427874565, 'loss_2': 0.010009765625, 'loss_3': -16.67407989501953, 'loss_4': 0.5992509722709656, 'epoch': 18.48}
{'loss': 0.0116, 'grad_norm': 5.296972751617432, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.011502883397042751, 'loss_2': 6.198883056640625e-05, 'loss_3': -16.503328323364258, 'loss_4': 0.4504764676094055, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 13:39:20,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:20,734 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:40<34:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:39:28,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020106250420212746, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.51, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015572596341371536, 'eval_loss_2': 0.004533655941486359, 'eval_loss_3': -18.28413200378418, 'eval_loss_4': 0.31249555945396423, 'epoch': 18.49}
{'loss': 0.0313, 'grad_norm': 8.382766723632812, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.019143138080835342, 'loss_2': 0.01218414306640625, 'loss_3': -16.537857055664062, 'loss_4': 1.1895699501037598, 'epoch': 18.49}
{'loss': 0.0183, 'grad_norm': 5.103522300720215, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.008699923753738403, 'loss_2': 0.00963592529296875, 'loss_3': -16.5648193359375, 'loss_4': 0.10023272037506104, 'epoch': 18.5}
{'loss': 0.0111, 'grad_norm': 6.439125061035156, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.010621833615005016, 'loss_2': 0.0005116462707519531, 'loss_3': -16.44949722290039, 'loss_4': 0.4888421595096588, 'epoch': 18.51}
{'loss': 0.0141, 'grad_norm': 6.446951866149902, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.010687833651900291, 'loss_2': 0.003391265869140625, 'loss_3': -16.32200813293457, 'loss_4': 0.4563275873661041, 'epoch': 18.51}
{'loss': 0.0153, 'grad_norm': 6.266141891479492, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.011995861306786537, 'loss_2': 0.003322601318359375, 'loss_3': -16.57871437072754, 'loss_4': 0.4073573350906372, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 13:39:28,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:28,055 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:47<34:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:35,383 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018660206347703934, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.357, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014473247341811657, 'eval_loss_2': 0.004186958074569702, 'eval_loss_3': -18.305463790893555, 'eval_loss_4': 0.32034817337989807, 'epoch': 18.52}
{'loss': 0.011, 'grad_norm': 4.986724376678467, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.006981215439736843, 'loss_2': 0.00399017333984375, 'loss_3': -16.508041381835938, 'loss_4': 0.9891680479049683, 'epoch': 18.52}
{'loss': 0.021, 'grad_norm': 6.980055332183838, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.01527848094701767, 'loss_2': 0.005702972412109375, 'loss_3': -16.34153175354004, 'loss_4': 0.4164736568927765, 'epoch': 18.53}
{'loss': 0.0186, 'grad_norm': 12.492321014404297, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.01516079343855381, 'loss_2': 0.0034027099609375, 'loss_3': -16.43914031982422, 'loss_4': 0.17482934892177582, 'epoch': 18.53}
{'loss': 0.0297, 'grad_norm': 17.22542381286621, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.025973200798034668, 'loss_2': 0.0037326812744140625, 'loss_3': -16.4808292388916, 'loss_4': 0.6762005090713501, 'epoch': 18.54}
{'loss': 0.0254, 'grad_norm': 11.306516647338867, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.01956755667924881, 'loss_2': 0.00586700439453125, 'loss_3': -16.440452575683594, 'loss_4': 0.6586757302284241, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 13:39:35,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:35,384 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:18:54<33:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:42,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01752340979874134, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01454989891499281, 'eval_loss_2': 0.002973511815071106, 'eval_loss_3': -18.335281372070312, 'eval_loss_4': 0.4274720847606659, 'epoch': 18.55}
{'loss': 0.0188, 'grad_norm': 7.316512107849121, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.015121090225875378, 'loss_2': 0.0036487579345703125, 'loss_3': -16.513065338134766, 'loss_4': 0.8421669602394104, 'epoch': 18.55}
{'loss': 0.0122, 'grad_norm': 4.63209867477417, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.008523550815880299, 'loss_2': 0.003688812255859375, 'loss_3': -16.472326278686523, 'loss_4': 0.8828315734863281, 'epoch': 18.56}
{'loss': 0.0276, 'grad_norm': 8.320343017578125, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.021872736513614655, 'loss_2': 0.0056915283203125, 'loss_3': -16.301902770996094, 'loss_4': 0.47167515754699707, 'epoch': 18.56}
{'loss': 0.0112, 'grad_norm': 4.907520294189453, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.007689866237342358, 'loss_2': 0.0035228729248046875, 'loss_3': -16.528783798217773, 'loss_4': 0.5240689516067505, 'epoch': 18.57}
{'loss': 0.0127, 'grad_norm': 4.196224212646484, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.006317091174423695, 'loss_2': 0.00635528564453125, 'loss_3': -16.637454986572266, 'loss_4': 0.8426267504692078, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 13:39:42,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:42,718 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:19:02<33:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:39:50,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016733873635530472, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.439, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01346269529312849, 'eval_loss_2': 0.0032711774110794067, 'eval_loss_3': -18.328577041625977, 'eval_loss_4': 0.5133694410324097, 'epoch': 18.58}
{'loss': 0.0302, 'grad_norm': 19.71378517150879, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.02799529768526554, 'loss_2': 0.0021800994873046875, 'loss_3': -16.565486907958984, 'loss_4': 0.9241487979888916, 'epoch': 18.58}
{'loss': 0.023, 'grad_norm': 5.259894847869873, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.012803846970200539, 'loss_2': 0.01019287109375, 'loss_3': -16.462467193603516, 'loss_4': 0.7229620218276978, 'epoch': 18.59}
{'loss': 0.0118, 'grad_norm': 6.233964920043945, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.0091948127374053, 'loss_2': 0.0026264190673828125, 'loss_3': -16.50746726989746, 'loss_4': 0.6897438764572144, 'epoch': 18.59}
{'loss': 0.0234, 'grad_norm': 8.895751953125, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.017495911568403244, 'loss_2': 0.005893707275390625, 'loss_3': -16.2896728515625, 'loss_4': 0.9412784576416016, 'epoch': 18.6}
{'loss': 0.0331, 'grad_norm': 12.44002914428711, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.030495258048176765, 'loss_2': 0.00255584716796875, 'loss_3': -16.463762283325195, 'loss_4': 1.2813880443572998, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 13:39:50,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:50,039 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:09<33:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:39:57,360 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018183894455432892, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.524, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.013711566105484962, 'eval_loss_2': 0.004472330212593079, 'eval_loss_3': -18.331558227539062, 'eval_loss_4': 0.5420313477516174, 'epoch': 18.6}
{'loss': 0.0588, 'grad_norm': 13.76806926727295, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.05345401540398598, 'loss_2': 0.005313873291015625, 'loss_3': -16.56559181213379, 'loss_4': 1.1145793199539185, 'epoch': 18.61}
{'loss': 0.0093, 'grad_norm': 5.016162872314453, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.008943608961999416, 'loss_2': 0.0003829002380371094, 'loss_3': -16.34142303466797, 'loss_4': 0.7383463978767395, 'epoch': 18.62}
{'loss': 0.015, 'grad_norm': 4.853625297546387, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.011789832264184952, 'loss_2': 0.003173828125, 'loss_3': -16.68431282043457, 'loss_4': 1.0930910110473633, 'epoch': 18.62}
{'loss': 0.0172, 'grad_norm': 6.721573829650879, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.013979783281683922, 'loss_2': 0.0031909942626953125, 'loss_3': -16.544050216674805, 'loss_4': 0.42423102259635925, 'epoch': 18.63}
{'loss': 0.027, 'grad_norm': 10.187990188598633, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.020585356280207634, 'loss_2': 0.006427764892578125, 'loss_3': -16.41851043701172, 'loss_4': 0.7366577982902527, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 13:39:57,360 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:57,360 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:16<33:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:40:04,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01779414713382721, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.299, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013668029569089413, 'eval_loss_2': 0.004126116633415222, 'eval_loss_3': -18.326841354370117, 'eval_loss_4': 0.571456789970398, 'epoch': 18.63}
{'loss': 0.0114, 'grad_norm': 5.27631139755249, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.009255009703338146, 'loss_2': 0.0021209716796875, 'loss_3': -16.412158966064453, 'loss_4': 1.5298998355865479, 'epoch': 18.64}
{'loss': 0.0143, 'grad_norm': 5.362423896789551, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.013351934030652046, 'loss_2': 0.0009822845458984375, 'loss_3': -16.417255401611328, 'loss_4': 0.9086675643920898, 'epoch': 18.65}
{'loss': 0.0104, 'grad_norm': 4.549736499786377, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.0054872119799256325, 'loss_2': 0.0048828125, 'loss_3': -16.467849731445312, 'loss_4': 0.8172467947006226, 'epoch': 18.65}
{'loss': 0.0072, 'grad_norm': 4.217045783996582, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.006472396664321423, 'loss_2': 0.0007228851318359375, 'loss_3': -16.24991226196289, 'loss_4': 0.9723867177963257, 'epoch': 18.66}
{'loss': 0.0158, 'grad_norm': 6.233059406280518, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.010298352688550949, 'loss_2': 0.005523681640625, 'loss_3': -16.518705368041992, 'loss_4': 1.1247296333312988, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 13:40:04,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:04,684 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:23<33:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:40:12,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017666790634393692, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.277, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.015186761505901814, 'eval_loss_2': 0.002480030059814453, 'eval_loss_3': -18.311283111572266, 'eval_loss_4': 0.5580698847770691, 'epoch': 18.66}
{'loss': 0.0139, 'grad_norm': 6.000848770141602, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.012753319926559925, 'loss_2': 0.0011539459228515625, 'loss_3': -16.464357376098633, 'loss_4': 0.18580353260040283, 'epoch': 18.67}
{'loss': 0.0196, 'grad_norm': 6.787996292114258, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.017414139583706856, 'loss_2': 0.00214385986328125, 'loss_3': -16.37091636657715, 'loss_4': 1.2035679817199707, 'epoch': 18.67}
{'loss': 0.016, 'grad_norm': 5.974064350128174, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.008718038909137249, 'loss_2': 0.007259368896484375, 'loss_3': -16.643510818481445, 'loss_4': 1.0627540349960327, 'epoch': 18.68}
{'loss': 0.037, 'grad_norm': 12.041739463806152, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.03629811480641365, 'loss_2': 0.0007114410400390625, 'loss_3': -16.505054473876953, 'loss_4': 0.7860956788063049, 'epoch': 18.69}
{'loss': 0.0142, 'grad_norm': 5.5716776847839355, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.009303225204348564, 'loss_2': 0.00494384765625, 'loss_3': -16.59184455871582, 'loss_4': 1.2976319789886475, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 13:40:12,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:12,010 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:31<33:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:19,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019150029867887497, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.737, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01713392697274685, 'eval_loss_2': 0.002016104757785797, 'eval_loss_3': -18.297149658203125, 'eval_loss_4': 0.4507943391799927, 'epoch': 18.69}
{'loss': 0.0076, 'grad_norm': 4.662344455718994, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.005478252656757832, 'loss_2': 0.00208282470703125, 'loss_3': -16.513782501220703, 'loss_4': 0.8948926329612732, 'epoch': 18.7}
{'loss': 0.0115, 'grad_norm': 4.98540735244751, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.010633171536028385, 'loss_2': 0.0008821487426757812, 'loss_3': -16.60690689086914, 'loss_4': 0.9741531014442444, 'epoch': 18.7}
{'loss': 0.0092, 'grad_norm': 5.286225318908691, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.0056093065068125725, 'loss_2': 0.003559112548828125, 'loss_3': -16.364301681518555, 'loss_4': 0.6188853979110718, 'epoch': 18.71}
{'loss': 0.0093, 'grad_norm': 4.93915319442749, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.006294455844908953, 'loss_2': 0.00301361083984375, 'loss_3': -16.45032501220703, 'loss_4': 0.6054432392120361, 'epoch': 18.72}
{'loss': 0.0111, 'grad_norm': 4.797612190246582, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.0047631217166781425, 'loss_2': 0.00638580322265625, 'loss_3': -16.537696838378906, 'loss_4': 0.32362061738967896, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 13:40:19,355 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:19,355 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:38<33:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:26,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01902065798640251, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.338, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01657877303659916, 'eval_loss_2': 0.002441883087158203, 'eval_loss_3': -18.296825408935547, 'eval_loss_4': 0.322634220123291, 'epoch': 18.72}
{'loss': 0.0097, 'grad_norm': 5.2882771492004395, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.007429986726492643, 'loss_2': 0.00228118896484375, 'loss_3': -16.43826675415039, 'loss_4': 0.42082053422927856, 'epoch': 18.73}
{'loss': 0.0095, 'grad_norm': 5.747716426849365, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.009032577276229858, 'loss_2': 0.00047326087951660156, 'loss_3': -16.335811614990234, 'loss_4': 0.6497061252593994, 'epoch': 18.73}
{'loss': 0.0127, 'grad_norm': 5.109921932220459, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.007942725904285908, 'loss_2': 0.00476837158203125, 'loss_3': -16.51034164428711, 'loss_4': 0.3356470465660095, 'epoch': 18.74}
{'loss': 0.0117, 'grad_norm': 4.586588382720947, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.006809641607105732, 'loss_2': 0.004901885986328125, 'loss_3': -16.39056396484375, 'loss_4': 0.77593994140625, 'epoch': 18.74}
{'loss': 0.0071, 'grad_norm': 5.2058610916137695, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.00453678285703063, 'loss_2': 0.002559661865234375, 'loss_3': -16.510324478149414, 'loss_4': 0.3860405683517456, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 13:40:26,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:26,678 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:45<33:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:40:34,003 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0203963965177536, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.272, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.016031354665756226, 'eval_loss_2': 0.0043650418519973755, 'eval_loss_3': -18.28791618347168, 'eval_loss_4': 0.257901668548584, 'epoch': 18.75}
{'loss': 0.0074, 'grad_norm': 4.595465183258057, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.00470815459266305, 'loss_2': 0.0026702880859375, 'loss_3': -16.368227005004883, 'loss_4': 0.8195235133171082, 'epoch': 18.76}
{'loss': 0.0167, 'grad_norm': 5.113743782043457, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.006297190673649311, 'loss_2': 0.01038360595703125, 'loss_3': -16.363109588623047, 'loss_4': 0.6108478307723999, 'epoch': 18.76}
{'loss': 0.0092, 'grad_norm': 5.082230567932129, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.004788735881447792, 'loss_2': 0.00445556640625, 'loss_3': -16.226848602294922, 'loss_4': 0.570520281791687, 'epoch': 18.77}
{'loss': 0.0155, 'grad_norm': 5.2962260246276855, 'learning_rate': 1.125e-05, 'loss_1': 0.010958150029182434, 'loss_2': 0.00449371337890625, 'loss_3': -16.26677703857422, 'loss_4': 0.7196629643440247, 'epoch': 18.77}
{'loss': 0.0131, 'grad_norm': 4.75958251953125, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.005967463832348585, 'loss_2': 0.007171630859375, 'loss_3': -16.487384796142578, 'loss_4': 0.8820712566375732, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 13:40:34,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:34,003 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:19:53<33:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:40:41,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02076055109500885, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.574, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.017442017793655396, 'eval_loss_2': 0.0033185333013534546, 'eval_loss_3': -18.275266647338867, 'eval_loss_4': 0.2521446943283081, 'epoch': 18.78}
{'loss': 0.0267, 'grad_norm': 8.542920112609863, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.021138129755854607, 'loss_2': 0.00555419921875, 'loss_3': -16.422866821289062, 'loss_4': 0.6777152419090271, 'epoch': 18.78}
{'loss': 0.0189, 'grad_norm': 8.653984069824219, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.018075840547680855, 'loss_2': 0.0007991790771484375, 'loss_3': -16.459972381591797, 'loss_4': 0.38025736808776855, 'epoch': 18.79}
{'loss': 0.0042, 'grad_norm': 4.620336055755615, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.0037794040981680155, 'loss_2': 0.00037097930908203125, 'loss_3': -16.252952575683594, 'loss_4': 0.31226643919944763, 'epoch': 18.8}
{'loss': 0.0093, 'grad_norm': 4.288937091827393, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.005060767754912376, 'loss_2': 0.0042266845703125, 'loss_3': -16.695629119873047, 'loss_4': 0.833810567855835, 'epoch': 18.8}
{'loss': 0.0102, 'grad_norm': 5.047957420349121, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.006809585262089968, 'loss_2': 0.003368377685546875, 'loss_3': -16.32164192199707, 'loss_4': 0.5844016671180725, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 13:40:41,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:41,321 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:20:00<33:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:40:48,640 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020263178274035454, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.484, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01733282022178173, 'eval_loss_2': 0.002930358052253723, 'eval_loss_3': -18.28667449951172, 'eval_loss_4': 0.27088603377342224, 'epoch': 18.81}
{'loss': 0.0247, 'grad_norm': 8.846628189086914, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.019685029983520508, 'loss_2': 0.0050048828125, 'loss_3': -16.285594940185547, 'loss_4': 0.8265589475631714, 'epoch': 18.81}
{'loss': 0.0058, 'grad_norm': 4.879482269287109, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.0054441094398498535, 'loss_2': 0.0003871917724609375, 'loss_3': -16.387195587158203, 'loss_4': 0.6119046807289124, 'epoch': 18.82}
{'loss': 0.0168, 'grad_norm': 5.22098970413208, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.007318142335861921, 'loss_2': 0.00946044921875, 'loss_3': -16.547103881835938, 'loss_4': 0.475411057472229, 'epoch': 18.83}
{'loss': 0.0214, 'grad_norm': 4.994977951049805, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.00695361802354455, 'loss_2': 0.014495849609375, 'loss_3': -16.611812591552734, 'loss_4': 0.8928481936454773, 'epoch': 18.83}
{'loss': 0.0163, 'grad_norm': 4.692282676696777, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.004344946704804897, 'loss_2': 0.01195526123046875, 'loss_3': -16.37405776977539, 'loss_4': 0.857624888420105, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 13:40:48,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:48,640 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:20:07<33:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:40:55,966 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021420452743768692, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.199, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01716730184853077, 'eval_loss_2': 0.0042531490325927734, 'eval_loss_3': -18.284034729003906, 'eval_loss_4': 0.19529962539672852, 'epoch': 18.84}
{'loss': 0.0338, 'grad_norm': 9.748634338378906, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.018102247267961502, 'loss_2': 0.01568603515625, 'loss_3': -16.367694854736328, 'loss_4': 0.516252875328064, 'epoch': 18.84}
{'loss': 0.0117, 'grad_norm': 5.283597946166992, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.007120504975318909, 'loss_2': 0.00461578369140625, 'loss_3': -16.453250885009766, 'loss_4': 0.9030397534370422, 'epoch': 18.85}
{'loss': 0.0103, 'grad_norm': 4.349738597869873, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.0055407327599823475, 'loss_2': 0.0047607421875, 'loss_3': -16.519838333129883, 'loss_4': 0.4879617989063263, 'epoch': 18.85}
{'loss': 0.0468, 'grad_norm': 12.580699920654297, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.036858271807432175, 'loss_2': 0.0099334716796875, 'loss_3': -16.53423309326172, 'loss_4': 0.638396143913269, 'epoch': 18.86}
{'loss': 0.0105, 'grad_norm': 5.695291519165039, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.008337119594216347, 'loss_2': 0.00220489501953125, 'loss_3': -16.40139389038086, 'loss_4': 0.8288846015930176, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 13:40:55,966 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:55,967 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:15<32:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:03,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01957247592508793, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.642, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016134211793541908, 'eval_loss_2': 0.0034382641315460205, 'eval_loss_3': -18.29907989501953, 'eval_loss_4': 0.15870100259780884, 'epoch': 18.87}
{'loss': 0.0139, 'grad_norm': 4.932649612426758, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.007410064805299044, 'loss_2': 0.00652313232421875, 'loss_3': -16.447429656982422, 'loss_4': 0.46583592891693115, 'epoch': 18.87}
{'loss': 0.0132, 'grad_norm': 6.716060638427734, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.01145815011113882, 'loss_2': 0.001789093017578125, 'loss_3': -16.37044906616211, 'loss_4': 0.17142213881015778, 'epoch': 18.88}
{'loss': 0.021, 'grad_norm': 7.966499328613281, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.013201318681240082, 'loss_2': 0.00775909423828125, 'loss_3': -16.470626831054688, 'loss_4': 0.14267206192016602, 'epoch': 18.88}
{'loss': 0.0962, 'grad_norm': 10.796711921691895, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.09155421704053879, 'loss_2': 0.004650115966796875, 'loss_3': -16.364662170410156, 'loss_4': 0.1766548752784729, 'epoch': 18.89}
{'loss': 0.0061, 'grad_norm': 5.060606956481934, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.005477130878716707, 'loss_2': 0.0006556510925292969, 'loss_3': -16.381282806396484, 'loss_4': 0.3098822236061096, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 13:41:03,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:03,300 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:22<32:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:10,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018353886902332306, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.402, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015270880423486233, 'eval_loss_2': 0.0030830055475234985, 'eval_loss_3': -18.317073822021484, 'eval_loss_4': 0.174172043800354, 'epoch': 18.9}
{'loss': 0.0086, 'grad_norm': 4.581109046936035, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.006568449549376965, 'loss_2': 0.0020656585693359375, 'loss_3': -16.43822479248047, 'loss_4': 0.9728380441665649, 'epoch': 18.9}
{'loss': 0.0135, 'grad_norm': 4.779478549957275, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.005973171442747116, 'loss_2': 0.007564544677734375, 'loss_3': -16.60516929626465, 'loss_4': 0.4023306369781494, 'epoch': 18.91}
{'loss': 0.0176, 'grad_norm': 6.849958419799805, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.01229210663586855, 'loss_2': 0.00528717041015625, 'loss_3': -16.313488006591797, 'loss_4': 0.4619796574115753, 'epoch': 18.91}
{'loss': 0.0145, 'grad_norm': 5.621418476104736, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.00821989681571722, 'loss_2': 0.006313323974609375, 'loss_3': -16.54648208618164, 'loss_4': 0.23972348868846893, 'epoch': 18.92}
{'loss': 0.0115, 'grad_norm': 5.143266677856445, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.007572775240987539, 'loss_2': 0.00392913818359375, 'loss_3': -16.318897247314453, 'loss_4': 0.6580696105957031, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 13:41:10,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:10,619 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:29<32:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:17,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016269346699118614, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.165, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013561969622969627, 'eval_loss_2': 0.002707377076148987, 'eval_loss_3': -18.309911727905273, 'eval_loss_4': 0.33510929346084595, 'epoch': 18.92}
{'loss': 0.0079, 'grad_norm': 6.310550689697266, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.00701023219153285, 'loss_2': 0.0009336471557617188, 'loss_3': -16.371509552001953, 'loss_4': 0.28087785840034485, 'epoch': 18.93}
{'loss': 0.0143, 'grad_norm': 5.523042678833008, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.012228227220475674, 'loss_2': 0.002109527587890625, 'loss_3': -16.48525047302246, 'loss_4': 0.6149464845657349, 'epoch': 18.94}
{'loss': 0.0155, 'grad_norm': 5.57899284362793, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.00730162812396884, 'loss_2': 0.0081939697265625, 'loss_3': -16.240642547607422, 'loss_4': 0.5079236626625061, 'epoch': 18.94}
{'loss': 0.0129, 'grad_norm': 4.698208332061768, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.007347337435930967, 'loss_2': 0.005584716796875, 'loss_3': -16.438142776489258, 'loss_4': 0.9439147710800171, 'epoch': 18.95}
{'loss': 0.0141, 'grad_norm': 5.662994384765625, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.007929845713078976, 'loss_2': 0.00621795654296875, 'loss_3': -16.495018005371094, 'loss_4': 0.5986933708190918, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 13:41:17,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:17,946 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:37<32:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:25,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016536395996809006, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.352, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013309227302670479, 'eval_loss_2': 0.0032271668314933777, 'eval_loss_3': -18.29783821105957, 'eval_loss_4': 0.5167967677116394, 'epoch': 18.95}
{'loss': 0.0136, 'grad_norm': 4.5725884437561035, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.006960906088352203, 'loss_2': 0.006664276123046875, 'loss_3': -16.50603675842285, 'loss_4': 1.4996588230133057, 'epoch': 18.96}
{'loss': 0.0149, 'grad_norm': 5.40336799621582, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.00842158030718565, 'loss_2': 0.00649261474609375, 'loss_3': -16.351966857910156, 'loss_4': 1.4465291500091553, 'epoch': 18.97}
{'loss': 0.0064, 'grad_norm': 4.6985554695129395, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.006354858633130789, 'loss_2': 8.666515350341797e-05, 'loss_3': -16.449480056762695, 'loss_4': 0.7120438814163208, 'epoch': 18.97}
{'loss': 0.012, 'grad_norm': 4.984000205993652, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.006289179436862469, 'loss_2': 0.0057373046875, 'loss_3': -16.45650291442871, 'loss_4': 0.7344767451286316, 'epoch': 18.98}
{'loss': 0.0072, 'grad_norm': 4.276132106781006, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.0066347988322377205, 'loss_2': 0.000583648681640625, 'loss_3': -16.548381805419922, 'loss_4': 0.9435527324676514, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 13:41:25,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:25,270 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:44<31:15,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 13:41:32,283 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01567726396024227, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.23, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013105317950248718, 'eval_loss_2': 0.0025719478726387024, 'eval_loss_3': -18.288833618164062, 'eval_loss_4': 0.6354079842567444, 'epoch': 18.98}
{'loss': 0.0087, 'grad_norm': 4.533938407897949, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.005218563135713339, 'loss_2': 0.00347137451171875, 'loss_3': -16.600635528564453, 'loss_4': 0.47271454334259033, 'epoch': 18.99}
{'loss': 0.0106, 'grad_norm': 5.879233360290527, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.009188258089125156, 'loss_2': 0.0014085769653320312, 'loss_3': -16.37972068786621, 'loss_4': 1.003051996231079, 'epoch': 18.99}
{'loss': 0.0177, 'grad_norm': 10.616978645324707, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.014352351427078247, 'loss_2': 0.0033626556396484375, 'loss_3': -16.429275512695312, 'loss_4': 1.4112712144851685, 'epoch': 19.0}
{'loss': 0.0102, 'grad_norm': 5.285074234008789, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.006775970105081797, 'loss_2': 0.0033779144287109375, 'loss_3': -16.218137741088867, 'loss_4': 0.8052619099617004, 'epoch': 19.01}
{'loss': 0.0106, 'grad_norm': 7.071390151977539, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.009541778825223446, 'loss_2': 0.0011014938354492188, 'loss_3': -16.3829288482666, 'loss_4': 1.0669689178466797, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 13:41:32,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:32,283 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:20:51<32:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:39,619 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01712143048644066, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.778, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013917702250182629, 'eval_loss_2': 0.0032037273049354553, 'eval_loss_3': -18.30955696105957, 'eval_loss_4': 0.6971681118011475, 'epoch': 19.01}
{'loss': 0.0309, 'grad_norm': 17.49077033996582, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.029943082481622696, 'loss_2': 0.0009641647338867188, 'loss_3': -16.370054244995117, 'loss_4': 0.5503062009811401, 'epoch': 19.02}
{'loss': 0.0132, 'grad_norm': 5.633335590362549, 'learning_rate': 1.1e-05, 'loss_1': 0.009460918605327606, 'loss_2': 0.0037746429443359375, 'loss_3': -16.420244216918945, 'loss_4': 1.1208665370941162, 'epoch': 19.02}
{'loss': 0.0129, 'grad_norm': 4.9963178634643555, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.007601436693221331, 'loss_2': 0.0052642822265625, 'loss_3': -16.439359664916992, 'loss_4': 1.0885190963745117, 'epoch': 19.03}
{'loss': 0.0081, 'grad_norm': 4.608358860015869, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.005248764529824257, 'loss_2': 0.00284576416015625, 'loss_3': -16.635013580322266, 'loss_4': 1.2522913217544556, 'epoch': 19.03}
{'loss': 0.0175, 'grad_norm': 13.415011405944824, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.017278257757425308, 'loss_2': 0.00017213821411132812, 'loss_3': -16.584617614746094, 'loss_4': 0.969646692276001, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 13:41:39,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:39,619 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:20:58<32:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:46,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01728763058781624, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.574, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.013794171623885632, 'eval_loss_2': 0.0034934580326080322, 'eval_loss_3': -18.311386108398438, 'eval_loss_4': 0.7796407341957092, 'epoch': 19.04}
{'loss': 0.0085, 'grad_norm': 5.561102390289307, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.00785207562148571, 'loss_2': 0.000682830810546875, 'loss_3': -16.279144287109375, 'loss_4': 0.8217939734458923, 'epoch': 19.05}
{'loss': 0.0081, 'grad_norm': 5.0083537101745605, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.007583192549645901, 'loss_2': 0.0005154609680175781, 'loss_3': -16.371532440185547, 'loss_4': 1.3880043029785156, 'epoch': 19.05}
{'loss': 0.0711, 'grad_norm': 9.296174049377441, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.06892278045415878, 'loss_2': 0.002166748046875, 'loss_3': -16.645092010498047, 'loss_4': 1.0660110712051392, 'epoch': 19.06}
{'loss': 0.0276, 'grad_norm': 15.758186340332031, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.023787448182702065, 'loss_2': 0.0037899017333984375, 'loss_3': -16.187088012695312, 'loss_4': 1.2898788452148438, 'epoch': 19.06}
{'loss': 0.0061, 'grad_norm': 4.54503870010376, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.0038813180290162563, 'loss_2': 0.00220489501953125, 'loss_3': -16.381149291992188, 'loss_4': 0.6742071509361267, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 13:41:46,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:46,937 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:21:06<32:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:54,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015596659854054451, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.363, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012553798034787178, 'eval_loss_2': 0.003042861819267273, 'eval_loss_3': -18.276065826416016, 'eval_loss_4': 0.8246479034423828, 'epoch': 19.07}
{'loss': 0.0287, 'grad_norm': 10.071990013122559, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.023928984999656677, 'loss_2': 0.0047607421875, 'loss_3': -16.665538787841797, 'loss_4': 0.9211728572845459, 'epoch': 19.08}
{'loss': 0.0131, 'grad_norm': 5.103784084320068, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.007633169647306204, 'loss_2': 0.0054779052734375, 'loss_3': -16.38326644897461, 'loss_4': 1.007196307182312, 'epoch': 19.08}
{'loss': 0.0138, 'grad_norm': 7.21580696105957, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.00834929384291172, 'loss_2': 0.005462646484375, 'loss_3': -16.60000991821289, 'loss_4': 1.4898974895477295, 'epoch': 19.09}
{'loss': 0.0085, 'grad_norm': 5.3788251876831055, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.008164725266397, 'loss_2': 0.0003228187561035156, 'loss_3': -16.41197395324707, 'loss_4': 1.0434083938598633, 'epoch': 19.09}
{'loss': 0.0088, 'grad_norm': 4.9516987800598145, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.006186468526721001, 'loss_2': 0.002613067626953125, 'loss_3': -16.31730842590332, 'loss_4': 0.8825104236602783, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 13:41:54,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:54,268 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:13<32:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:01,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01689121685922146, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.271, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013704096898436546, 'eval_loss_2': 0.003187119960784912, 'eval_loss_3': -18.288494110107422, 'eval_loss_4': 0.8762724995613098, 'epoch': 19.1}
{'loss': 0.0057, 'grad_norm': 4.80707311630249, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.005252750590443611, 'loss_2': 0.0004696846008300781, 'loss_3': -16.39218521118164, 'loss_4': 0.8903601765632629, 'epoch': 19.1}
{'loss': 0.0166, 'grad_norm': 9.561467170715332, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.01243196614086628, 'loss_2': 0.00420379638671875, 'loss_3': -16.578495025634766, 'loss_4': 1.2196495532989502, 'epoch': 19.11}
{'loss': 0.008, 'grad_norm': 5.1748948097229, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.004362997133284807, 'loss_2': 0.003627777099609375, 'loss_3': -16.763473510742188, 'loss_4': 1.0137536525726318, 'epoch': 19.12}
{'loss': 0.0194, 'grad_norm': 8.804451942443848, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.014822128228843212, 'loss_2': 0.00461578369140625, 'loss_3': -16.55833625793457, 'loss_4': 1.1242297887802124, 'epoch': 19.12}
{'loss': 0.0074, 'grad_norm': 4.710895538330078, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.007338418159633875, 'loss_2': 8.207559585571289e-05, 'loss_3': -16.73057746887207, 'loss_4': 0.8030153512954712, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 13:42:01,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:01,597 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:20<32:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:08,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01853359118103981, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.015198949724435806, 'eval_loss_2': 0.003334641456604004, 'eval_loss_3': -18.277400970458984, 'eval_loss_4': 1.0109483003616333, 'epoch': 19.13}
{'loss': 0.004, 'grad_norm': 4.6614766120910645, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.003286593360826373, 'loss_2': 0.00067901611328125, 'loss_3': -16.495548248291016, 'loss_4': 1.0604472160339355, 'epoch': 19.13}
{'loss': 0.0244, 'grad_norm': 24.371448516845703, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.01967478357255459, 'loss_2': 0.004703521728515625, 'loss_3': -16.69760513305664, 'loss_4': 1.6195677518844604, 'epoch': 19.14}
{'loss': 0.0149, 'grad_norm': 7.7407050132751465, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.009755865670740604, 'loss_2': 0.00514984130859375, 'loss_3': -16.483890533447266, 'loss_4': 1.6922650337219238, 'epoch': 19.15}
{'loss': 0.0204, 'grad_norm': 10.369290351867676, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.012607944197952747, 'loss_2': 0.00782012939453125, 'loss_3': -16.25413703918457, 'loss_4': 1.3901488780975342, 'epoch': 19.15}
{'loss': 0.0172, 'grad_norm': 7.712273597717285, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.016941426321864128, 'loss_2': 0.0002727508544921875, 'loss_3': -16.45427703857422, 'loss_4': 1.515625, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 13:42:08,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:08,925 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:28<32:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:16,251 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014310354366898537, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.327, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011382156051695347, 'eval_loss_2': 0.0029281973838806152, 'eval_loss_3': -18.299942016601562, 'eval_loss_4': 1.170992374420166, 'epoch': 19.16}
{'loss': 0.0044, 'grad_norm': 4.584789276123047, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.00415266677737236, 'loss_2': 0.0002071857452392578, 'loss_3': -16.31996726989746, 'loss_4': 1.077547550201416, 'epoch': 19.16}
{'loss': 0.0248, 'grad_norm': 7.993099212646484, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.0163210928440094, 'loss_2': 0.0084381103515625, 'loss_3': -16.69256591796875, 'loss_4': 1.3998156785964966, 'epoch': 19.17}
{'loss': 0.01, 'grad_norm': 5.401017665863037, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.006878206972032785, 'loss_2': 0.00313568115234375, 'loss_3': -16.490219116210938, 'loss_4': 1.2408874034881592, 'epoch': 19.17}
{'loss': 0.0061, 'grad_norm': 4.911369323730469, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.004804947413504124, 'loss_2': 0.001316070556640625, 'loss_3': -16.483701705932617, 'loss_4': 1.47861909866333, 'epoch': 19.18}
{'loss': 0.0177, 'grad_norm': 6.239960670471191, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.014617613516747952, 'loss_2': 0.003108978271484375, 'loss_3': -16.4816837310791, 'loss_4': 1.6375775337219238, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 13:42:16,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:16,251 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:35<32:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:23,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01266072504222393, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.905, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009593918919563293, 'eval_loss_2': 0.003066807985305786, 'eval_loss_3': -18.305166244506836, 'eval_loss_4': 1.3119652271270752, 'epoch': 19.19}
{'loss': 0.0203, 'grad_norm': 8.923264503479004, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.01062847301363945, 'loss_2': 0.0096893310546875, 'loss_3': -16.314298629760742, 'loss_4': 1.049851417541504, 'epoch': 19.19}
{'loss': 0.0121, 'grad_norm': 5.376483917236328, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.00985771231353283, 'loss_2': 0.0022430419921875, 'loss_3': -16.5271053314209, 'loss_4': 1.9741382598876953, 'epoch': 19.2}
{'loss': 0.011, 'grad_norm': 4.810957431793213, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.0075344811193645, 'loss_2': 0.0035114288330078125, 'loss_3': -16.357582092285156, 'loss_4': 1.6005170345306396, 'epoch': 19.2}
{'loss': 0.0175, 'grad_norm': 7.700709342956543, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.014506797306239605, 'loss_2': 0.003002166748046875, 'loss_3': -16.33919906616211, 'loss_4': 1.1647796630859375, 'epoch': 19.21}
{'loss': 0.0055, 'grad_norm': 4.8707709312438965, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.004777875728905201, 'loss_2': 0.0006766319274902344, 'loss_3': -16.609949111938477, 'loss_4': 1.8737196922302246, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 13:42:23,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:23,580 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:42<31:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:42:30,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01219850778579712, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.473, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.009261280298233032, 'eval_loss_2': 0.002937227487564087, 'eval_loss_3': -18.32443618774414, 'eval_loss_4': 1.4988316297531128, 'epoch': 19.22}
{'loss': 0.013, 'grad_norm': 6.1699981689453125, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.010176118463277817, 'loss_2': 0.0028476715087890625, 'loss_3': -16.277034759521484, 'loss_4': 1.6510685682296753, 'epoch': 19.22}
{'loss': 0.0088, 'grad_norm': 4.874972820281982, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.0054093641228973866, 'loss_2': 0.0033969879150390625, 'loss_3': -16.695697784423828, 'loss_4': 2.02103590965271, 'epoch': 19.23}
{'loss': 0.0258, 'grad_norm': 8.58967113494873, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.016910402104258537, 'loss_2': 0.0089263916015625, 'loss_3': -16.484256744384766, 'loss_4': 1.582116723060608, 'epoch': 19.23}
{'loss': 0.0129, 'grad_norm': 4.879703998565674, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.0057059661485254765, 'loss_2': 0.0071868896484375, 'loss_3': -16.539377212524414, 'loss_4': 1.7929104566574097, 'epoch': 19.24}
{'loss': 0.0064, 'grad_norm': 4.675113677978516, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.00562798697501421, 'loss_2': 0.0008101463317871094, 'loss_3': -16.41376304626465, 'loss_4': 2.2701592445373535, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 13:42:30,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:30,905 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:50<31:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:38,227 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012832139618694782, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.653, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.009968792088329792, 'eval_loss_2': 0.0028633475303649902, 'eval_loss_3': -18.31662368774414, 'eval_loss_4': 1.5286576747894287, 'epoch': 19.24}
{'loss': 0.0145, 'grad_norm': 5.72470760345459, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.012272417545318604, 'loss_2': 0.0022640228271484375, 'loss_3': -16.484912872314453, 'loss_4': 1.9838272333145142, 'epoch': 19.25}
{'loss': 0.0113, 'grad_norm': 6.511904239654541, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.00873514637351036, 'loss_2': 0.0025768280029296875, 'loss_3': -16.575244903564453, 'loss_4': 1.7551639080047607, 'epoch': 19.26}
{'loss': 0.0058, 'grad_norm': 5.221439838409424, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.005329909734427929, 'loss_2': 0.0004906654357910156, 'loss_3': -16.56910514831543, 'loss_4': 2.0523393154144287, 'epoch': 19.26}
{'loss': 0.011, 'grad_norm': 5.566436767578125, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.009654180146753788, 'loss_2': 0.0013017654418945312, 'loss_3': -16.600976943969727, 'loss_4': 1.4397108554840088, 'epoch': 19.27}
{'loss': 0.0152, 'grad_norm': 4.707766532897949, 'learning_rate': 1.075e-05, 'loss_1': 0.005855428986251354, 'loss_2': 0.0093841552734375, 'loss_3': -16.447505950927734, 'loss_4': 2.0124258995056152, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 13:42:38,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:38,227 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:21:57<31:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:45,561 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014538874849677086, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.135, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010791880078613758, 'eval_loss_2': 0.003746993839740753, 'eval_loss_3': -18.305923461914062, 'eval_loss_4': 1.4864479303359985, 'epoch': 19.27}
{'loss': 0.0156, 'grad_norm': 5.341412544250488, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.0060813636519014835, 'loss_2': 0.009552001953125, 'loss_3': -16.32950210571289, 'loss_4': 1.9433132410049438, 'epoch': 19.28}
{'loss': 0.0125, 'grad_norm': 5.137026309967041, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.007978764362633228, 'loss_2': 0.00457000732421875, 'loss_3': -16.385486602783203, 'loss_4': 1.6070153713226318, 'epoch': 19.28}
{'loss': 0.0057, 'grad_norm': 5.036828517913818, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.005092311184853315, 'loss_2': 0.0006237030029296875, 'loss_3': -16.4178466796875, 'loss_4': 1.746476173400879, 'epoch': 19.29}
{'loss': 0.0236, 'grad_norm': 8.578271865844727, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.022279147058725357, 'loss_2': 0.0013151168823242188, 'loss_3': -16.375141143798828, 'loss_4': 2.292631149291992, 'epoch': 19.3}
{'loss': 0.0132, 'grad_norm': 8.748205184936523, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.012021420523524284, 'loss_2': 0.001132965087890625, 'loss_3': -16.319782257080078, 'loss_4': 2.0181479454040527, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 13:42:45,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:45,562 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:22:04<31:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:52,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01458269264549017, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.203, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.011193512938916683, 'eval_loss_2': 0.0033891797065734863, 'eval_loss_3': -18.311729431152344, 'eval_loss_4': 1.423764944076538, 'epoch': 19.3}
{'loss': 0.0084, 'grad_norm': 7.257016658782959, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.007055655121803284, 'loss_2': 0.00133514404296875, 'loss_3': -16.4847469329834, 'loss_4': 2.0703201293945312, 'epoch': 19.31}
{'loss': 0.0315, 'grad_norm': 18.328006744384766, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.03072839044034481, 'loss_2': 0.0007534027099609375, 'loss_3': -16.49694061279297, 'loss_4': 1.062583565711975, 'epoch': 19.31}
{'loss': 0.0112, 'grad_norm': 5.280031681060791, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.010195215232670307, 'loss_2': 0.001033782958984375, 'loss_3': -16.49966812133789, 'loss_4': 2.013827323913574, 'epoch': 19.32}
{'loss': 0.0107, 'grad_norm': 4.860908031463623, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.006202160846441984, 'loss_2': 0.00444793701171875, 'loss_3': -16.511394500732422, 'loss_4': 1.9326131343841553, 'epoch': 19.33}
{'loss': 0.0067, 'grad_norm': 4.9985671043396, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.004684355575591326, 'loss_2': 0.00205230712890625, 'loss_3': -16.23592758178711, 'loss_4': 1.4678730964660645, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 13:42:52,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:52,892 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:12<31:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:00,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014512774534523487, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.977, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.011303119361400604, 'eval_loss_2': 0.0032096542418003082, 'eval_loss_3': -18.30878257751465, 'eval_loss_4': 1.2947652339935303, 'epoch': 19.33}
{'loss': 0.0232, 'grad_norm': 10.178373336791992, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.017426341772079468, 'loss_2': 0.005794525146484375, 'loss_3': -16.480010986328125, 'loss_4': 1.4829045534133911, 'epoch': 19.34}
{'loss': 0.0079, 'grad_norm': 5.162815570831299, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.007234363351017237, 'loss_2': 0.0006341934204101562, 'loss_3': -16.321632385253906, 'loss_4': 1.6987531185150146, 'epoch': 19.34}
{'loss': 0.0098, 'grad_norm': 5.073494911193848, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.005088833160698414, 'loss_2': 0.004695892333984375, 'loss_3': -16.463539123535156, 'loss_4': 1.6580147743225098, 'epoch': 19.35}
{'loss': 0.0183, 'grad_norm': 7.54251766204834, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.01219957135617733, 'loss_2': 0.006092071533203125, 'loss_3': -16.478763580322266, 'loss_4': 1.2849717140197754, 'epoch': 19.35}
{'loss': 0.0101, 'grad_norm': 7.726388454437256, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.009828035719692707, 'loss_2': 0.0003082752227783203, 'loss_3': -16.350643157958984, 'loss_4': 1.3843399286270142, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 13:43:00,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:00,229 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:19<31:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:07,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015702754259109497, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.521, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012494267895817757, 'eval_loss_2': 0.0032084882259368896, 'eval_loss_3': -18.294281005859375, 'eval_loss_4': 1.1375744342803955, 'epoch': 19.36}
{'loss': 0.0335, 'grad_norm': 21.16473388671875, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.02887323498725891, 'loss_2': 0.00466156005859375, 'loss_3': -16.527374267578125, 'loss_4': 1.7245099544525146, 'epoch': 19.37}
{'loss': 0.0063, 'grad_norm': 5.045104503631592, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.005566337611526251, 'loss_2': 0.000782012939453125, 'loss_3': -16.33514404296875, 'loss_4': 1.458174467086792, 'epoch': 19.37}
{'loss': 0.0165, 'grad_norm': 7.947462558746338, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.014757810160517693, 'loss_2': 0.00177001953125, 'loss_3': -16.433582305908203, 'loss_4': 1.0212079286575317, 'epoch': 19.38}
{'loss': 0.0133, 'grad_norm': 10.013742446899414, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.010889934375882149, 'loss_2': 0.00244903564453125, 'loss_3': -16.555011749267578, 'loss_4': 1.0861334800720215, 'epoch': 19.38}
{'loss': 0.0119, 'grad_norm': 5.934973239898682, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.009707638062536716, 'loss_2': 0.002178192138671875, 'loss_3': -16.679584503173828, 'loss_4': 1.1586954593658447, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 13:43:07,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:07,567 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:26<31:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:43:14,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014417125843465328, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.409, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.011451796628534794, 'eval_loss_2': 0.0029653310775756836, 'eval_loss_3': -18.287982940673828, 'eval_loss_4': 0.9448006749153137, 'epoch': 19.39}
{'loss': 0.0061, 'grad_norm': 4.7022247314453125, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.005230360198765993, 'loss_2': 0.00086212158203125, 'loss_3': -16.566120147705078, 'loss_4': 1.5000405311584473, 'epoch': 19.4}
{'loss': 0.0088, 'grad_norm': 5.135213851928711, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.005524966400116682, 'loss_2': 0.0032787322998046875, 'loss_3': -16.335376739501953, 'loss_4': 1.0878651142120361, 'epoch': 19.4}
{'loss': 0.03, 'grad_norm': 17.337390899658203, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.028700251132249832, 'loss_2': 0.0012807846069335938, 'loss_3': -16.36174774169922, 'loss_4': 1.2314205169677734, 'epoch': 19.41}
{'loss': 0.0084, 'grad_norm': 5.123215675354004, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.007041709963232279, 'loss_2': 0.0013952255249023438, 'loss_3': -16.423587799072266, 'loss_4': 0.8460444211959839, 'epoch': 19.41}
{'loss': 0.0093, 'grad_norm': 4.811298370361328, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.005829886998981237, 'loss_2': 0.0034313201904296875, 'loss_3': -16.382156372070312, 'loss_4': 1.0218687057495117, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 13:43:14,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:14,889 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:34<31:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:43:22,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015329109504818916, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.329, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011460291221737862, 'eval_loss_2': 0.0038688182830810547, 'eval_loss_3': -18.291378021240234, 'eval_loss_4': 0.9268287420272827, 'epoch': 19.42}
{'loss': 0.0176, 'grad_norm': 6.27827787399292, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.013340621255338192, 'loss_2': 0.00424957275390625, 'loss_3': -16.586620330810547, 'loss_4': 1.1337064504623413, 'epoch': 19.42}
{'loss': 0.0078, 'grad_norm': 5.115677833557129, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.004512278828769922, 'loss_2': 0.003269195556640625, 'loss_3': -16.45884895324707, 'loss_4': 0.9933832883834839, 'epoch': 19.43}
{'loss': 0.0118, 'grad_norm': 5.141598701477051, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.005454206373542547, 'loss_2': 0.00632476806640625, 'loss_3': -16.655513763427734, 'loss_4': 1.1161470413208008, 'epoch': 19.44}
{'loss': 0.0082, 'grad_norm': 4.836947917938232, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.005908885970711708, 'loss_2': 0.0022430419921875, 'loss_3': -16.57525634765625, 'loss_4': 1.4750957489013672, 'epoch': 19.44}
{'loss': 0.0108, 'grad_norm': 4.851633548736572, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.007736434228718281, 'loss_2': 0.003032684326171875, 'loss_3': -16.392179489135742, 'loss_4': 1.6081862449645996, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 13:43:22,209 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:22,209 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:41<31:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:29,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014967834576964378, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.309, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011686142534017563, 'eval_loss_2': 0.0032816901803016663, 'eval_loss_3': -18.278423309326172, 'eval_loss_4': 1.0012054443359375, 'epoch': 19.45}
{'loss': 0.0076, 'grad_norm': 5.456757545471191, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.007472417317330837, 'loss_2': 0.00017142295837402344, 'loss_3': -16.566917419433594, 'loss_4': 1.5706281661987305, 'epoch': 19.45}
{'loss': 0.0054, 'grad_norm': 4.649315357208252, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.0036989536602050066, 'loss_2': 0.0017185211181640625, 'loss_3': -16.60174560546875, 'loss_4': 1.8919464349746704, 'epoch': 19.46}
{'loss': 0.0068, 'grad_norm': 5.206260681152344, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.004116218537092209, 'loss_2': 0.00264739990234375, 'loss_3': -16.487789154052734, 'loss_4': 1.5095782279968262, 'epoch': 19.47}
{'loss': 0.0072, 'grad_norm': 4.944163799285889, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.005366734229028225, 'loss_2': 0.0017871856689453125, 'loss_3': -16.572921752929688, 'loss_4': 1.238785743713379, 'epoch': 19.47}
{'loss': 0.0095, 'grad_norm': 5.404421329498291, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.004708799067884684, 'loss_2': 0.00482940673828125, 'loss_3': -16.397600173950195, 'loss_4': 1.1873081922531128, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 13:43:29,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:29,538 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:48<31:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:43:36,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01490732654929161, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.342, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011822388507425785, 'eval_loss_2': 0.0030849389731884003, 'eval_loss_3': -18.288183212280273, 'eval_loss_4': 1.0208146572113037, 'epoch': 19.48}
{'loss': 0.0209, 'grad_norm': 10.270766258239746, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.018976937979459763, 'loss_2': 0.00196075439453125, 'loss_3': -16.44560432434082, 'loss_4': 1.509939432144165, 'epoch': 19.48}
{'loss': 0.0337, 'grad_norm': 12.683104515075684, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.029045289382338524, 'loss_2': 0.004669189453125, 'loss_3': -16.42896842956543, 'loss_4': 0.7561520338058472, 'epoch': 19.49}
{'loss': 0.0118, 'grad_norm': 5.908520221710205, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.008430931717157364, 'loss_2': 0.003383636474609375, 'loss_3': -16.453536987304688, 'loss_4': 1.0595252513885498, 'epoch': 19.49}
{'loss': 0.0222, 'grad_norm': 7.586416244506836, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.016083652153611183, 'loss_2': 0.006076812744140625, 'loss_3': -16.550994873046875, 'loss_4': 1.0627813339233398, 'epoch': 19.5}
{'loss': 0.0062, 'grad_norm': 4.538091659545898, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.004263231530785561, 'loss_2': 0.001956939697265625, 'loss_3': -16.543760299682617, 'loss_4': 1.6078829765319824, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 13:43:36,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:36,862 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:22:56<31:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:44,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015874434262514114, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.975, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012896757572889328, 'eval_loss_2': 0.0029776766896247864, 'eval_loss_3': -18.308460235595703, 'eval_loss_4': 0.9069088101387024, 'epoch': 19.51}
{'loss': 0.0229, 'grad_norm': 9.698901176452637, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.022080019116401672, 'loss_2': 0.0007848739624023438, 'loss_3': -16.4118595123291, 'loss_4': 0.8719013929367065, 'epoch': 19.51}
{'loss': 0.0153, 'grad_norm': 4.870148181915283, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.006400098092854023, 'loss_2': 0.00894927978515625, 'loss_3': -16.522754669189453, 'loss_4': 1.163257360458374, 'epoch': 19.52}
{'loss': 0.0043, 'grad_norm': 4.574545860290527, 'learning_rate': 1.05e-05, 'loss_1': 0.004274097271263599, 'loss_2': 5.334615707397461e-05, 'loss_3': -16.504043579101562, 'loss_4': 0.8049253225326538, 'epoch': 19.52}
{'loss': 0.012, 'grad_norm': 5.6537017822265625, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.011191592551767826, 'loss_2': 0.0007753372192382812, 'loss_3': -16.525257110595703, 'loss_4': 1.294836401939392, 'epoch': 19.53}
{'loss': 0.0105, 'grad_norm': 5.722242832183838, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.006720667704939842, 'loss_2': 0.00382232666015625, 'loss_3': -16.44422721862793, 'loss_4': 1.1492379903793335, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 13:43:44,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:44,195 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:23:03<30:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:51,524 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01659448817372322, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.475, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013782549649477005, 'eval_loss_2': 0.002811938524246216, 'eval_loss_3': -18.300432205200195, 'eval_loss_4': 0.738558292388916, 'epoch': 19.53}
{'loss': 0.0086, 'grad_norm': 4.743259429931641, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.006253751460462809, 'loss_2': 0.0023345947265625, 'loss_3': -16.526241302490234, 'loss_4': 1.092904806137085, 'epoch': 19.54}
{'loss': 0.0053, 'grad_norm': 4.854552268981934, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.004018800798803568, 'loss_2': 0.001262664794921875, 'loss_3': -16.704954147338867, 'loss_4': 0.9845783710479736, 'epoch': 19.55}
{'loss': 0.0092, 'grad_norm': 6.037899494171143, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.00685702171176672, 'loss_2': 0.0023651123046875, 'loss_3': -16.545806884765625, 'loss_4': 1.154936671257019, 'epoch': 19.55}
{'loss': 0.0093, 'grad_norm': 5.492567539215088, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.004539329558610916, 'loss_2': 0.0047760009765625, 'loss_3': -16.458959579467773, 'loss_4': 0.7700169682502747, 'epoch': 19.56}
{'loss': 0.0081, 'grad_norm': 4.790943622589111, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.0038932987954467535, 'loss_2': 0.00418853759765625, 'loss_3': -16.52468490600586, 'loss_4': 0.6050000786781311, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 13:43:51,524 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:51,524 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:10<30:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:58,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016446344554424286, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.387, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013888655230402946, 'eval_loss_2': 0.0025576911866664886, 'eval_loss_3': -18.296838760375977, 'eval_loss_4': 0.6025434732437134, 'epoch': 19.56}
{'loss': 0.0065, 'grad_norm': 4.8301825523376465, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.004959209822118282, 'loss_2': 0.0015544891357421875, 'loss_3': -16.498027801513672, 'loss_4': 0.7301108837127686, 'epoch': 19.57}
{'loss': 0.0053, 'grad_norm': 4.938432693481445, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.005172912497073412, 'loss_2': 8.690357208251953e-05, 'loss_3': -16.63236427307129, 'loss_4': 1.2220911979675293, 'epoch': 19.58}
{'loss': 0.0162, 'grad_norm': 6.149478435516357, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.01211368665099144, 'loss_2': 0.004058837890625, 'loss_3': -16.661739349365234, 'loss_4': 0.7813965082168579, 'epoch': 19.58}
{'loss': 0.0155, 'grad_norm': 10.683923721313477, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.014090773649513721, 'loss_2': 0.0014286041259765625, 'loss_3': -16.449419021606445, 'loss_4': 1.1167067289352417, 'epoch': 19.59}
{'loss': 0.0096, 'grad_norm': 4.728596210479736, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.004720455501228571, 'loss_2': 0.00489044189453125, 'loss_3': -16.447317123413086, 'loss_4': 1.3332431316375732, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 13:43:58,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:58,850 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:18<30:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:06,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01673729531466961, 'eval_runtime': 3.7843, 'eval_samples_per_second': 270.594, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.013970686122775078, 'eval_loss_2': 0.0027666091918945312, 'eval_loss_3': -18.302749633789062, 'eval_loss_4': 0.4720419645309448, 'epoch': 19.59}
{'loss': 0.0101, 'grad_norm': 4.745425224304199, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.008845196105539799, 'loss_2': 0.0012836456298828125, 'loss_3': -16.562015533447266, 'loss_4': 0.8635498285293579, 'epoch': 19.6}
{'loss': 0.0068, 'grad_norm': 4.509135723114014, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.005593417212367058, 'loss_2': 0.0011615753173828125, 'loss_3': -16.539365768432617, 'loss_4': 0.31834354996681213, 'epoch': 19.6}
{'loss': 0.0071, 'grad_norm': 5.080989837646484, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.006823326926678419, 'loss_2': 0.0002522468566894531, 'loss_3': -16.533924102783203, 'loss_4': 0.6940040588378906, 'epoch': 19.61}
{'loss': 0.03, 'grad_norm': 11.421431541442871, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.02487797848880291, 'loss_2': 0.00507354736328125, 'loss_3': -16.447734832763672, 'loss_4': 0.6894733309745789, 'epoch': 19.62}
{'loss': 0.0219, 'grad_norm': 9.299161911010742, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.014063491486012936, 'loss_2': 0.0078125, 'loss_3': -16.52479362487793, 'loss_4': 0.41583073139190674, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 13:44:06,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:06,174 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:25<30:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:44:13,490 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01773124188184738, 'eval_runtime': 3.7871, 'eval_samples_per_second': 270.395, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.014885865151882172, 'eval_loss_2': 0.00284537672996521, 'eval_loss_3': -18.3042049407959, 'eval_loss_4': 0.30978477001190186, 'epoch': 19.62}
{'loss': 0.0144, 'grad_norm': 7.137061595916748, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.01276699174195528, 'loss_2': 0.0016326904296875, 'loss_3': -16.532642364501953, 'loss_4': 0.5824058651924133, 'epoch': 19.63}
{'loss': 0.0114, 'grad_norm': 4.751036167144775, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.0046486156061291695, 'loss_2': 0.00677490234375, 'loss_3': -16.608604431152344, 'loss_4': 0.5750800967216492, 'epoch': 19.63}
{'loss': 0.0097, 'grad_norm': 5.7923102378845215, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.007479386869817972, 'loss_2': 0.00218963623046875, 'loss_3': -16.580078125, 'loss_4': 0.7053459882736206, 'epoch': 19.64}
{'loss': 0.032, 'grad_norm': 9.49693775177002, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.028390122577548027, 'loss_2': 0.0035858154296875, 'loss_3': -16.413776397705078, 'loss_4': 0.7592318654060364, 'epoch': 19.65}
{'loss': 0.0268, 'grad_norm': 11.2168550491333, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.025013331323862076, 'loss_2': 0.0018062591552734375, 'loss_3': -16.35742950439453, 'loss_4': 0.33686891198158264, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 13:44:13,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:13,490 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:32<30:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:44:20,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018146324902772903, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.236, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.014853674918413162, 'eval_loss_2': 0.003292649984359741, 'eval_loss_3': -18.304458618164062, 'eval_loss_4': 0.20540454983711243, 'epoch': 19.65}
{'loss': 0.0096, 'grad_norm': 4.922769546508789, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.006196481641381979, 'loss_2': 0.003398895263671875, 'loss_3': -16.53170394897461, 'loss_4': -0.030433788895606995, 'epoch': 19.66}
{'loss': 0.0136, 'grad_norm': 6.789200782775879, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.011488675139844418, 'loss_2': 0.002132415771484375, 'loss_3': -16.59449577331543, 'loss_4': 0.7509304285049438, 'epoch': 19.66}
{'loss': 0.022, 'grad_norm': 7.538187503814697, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.017368042841553688, 'loss_2': 0.00458526611328125, 'loss_3': -16.590587615966797, 'loss_4': 0.3605843782424927, 'epoch': 19.67}
{'loss': 0.0155, 'grad_norm': 5.180514335632324, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.010871549136936665, 'loss_2': 0.0045928955078125, 'loss_3': -16.410982131958008, 'loss_4': 0.21086488664150238, 'epoch': 19.67}
{'loss': 0.0194, 'grad_norm': 4.947671413421631, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.007703864946961403, 'loss_2': 0.011688232421875, 'loss_3': -16.58808135986328, 'loss_4': 0.697803258895874, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 13:44:20,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:20,816 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:40<30:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:28,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02046867273747921, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.637, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014814038760960102, 'eval_loss_2': 0.005654633045196533, 'eval_loss_3': -18.29629135131836, 'eval_loss_4': 0.16488176584243774, 'epoch': 19.68}
{'loss': 0.0325, 'grad_norm': 10.140192985534668, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.02424207329750061, 'loss_2': 0.0082855224609375, 'loss_3': -16.565702438354492, 'loss_4': 0.4553540349006653, 'epoch': 19.69}
{'loss': 0.0199, 'grad_norm': 5.106621742248535, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.006862599868327379, 'loss_2': 0.013031005859375, 'loss_3': -16.398889541625977, 'loss_4': 0.4558796286582947, 'epoch': 19.69}
{'loss': 0.0174, 'grad_norm': 4.915431022644043, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.007435970474034548, 'loss_2': 0.009918212890625, 'loss_3': -16.652366638183594, 'loss_4': 0.3633968234062195, 'epoch': 19.7}
{'loss': 0.015, 'grad_norm': 5.397841930389404, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.006759253796190023, 'loss_2': 0.00823211669921875, 'loss_3': -16.560434341430664, 'loss_4': 0.013490840792655945, 'epoch': 19.7}
{'loss': 0.02, 'grad_norm': 6.224400520324707, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.011808296665549278, 'loss_2': 0.0081787109375, 'loss_3': -16.77045440673828, 'loss_4': 0.3823488652706146, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 13:44:28,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:28,147 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:47<30:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:35,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01729895919561386, 'eval_runtime': 3.789, 'eval_samples_per_second': 270.26, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013683340512216091, 'eval_loss_2': 0.0036156177520751953, 'eval_loss_3': -18.294235229492188, 'eval_loss_4': 0.125535249710083, 'epoch': 19.71}
{'loss': 0.0092, 'grad_norm': 5.081145286560059, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.007406606338918209, 'loss_2': 0.00176239013671875, 'loss_3': -16.475215911865234, 'loss_4': 0.8049102425575256, 'epoch': 19.72}
{'loss': 0.0274, 'grad_norm': 11.091268539428711, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.017861895263195038, 'loss_2': 0.00958251953125, 'loss_3': -16.663028717041016, 'loss_4': 0.15460817515850067, 'epoch': 19.72}
{'loss': 0.0238, 'grad_norm': 10.854663848876953, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.01844174601137638, 'loss_2': 0.00537109375, 'loss_3': -16.72908592224121, 'loss_4': 0.2196483314037323, 'epoch': 19.73}
{'loss': 0.0162, 'grad_norm': 6.547939300537109, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.01370532438158989, 'loss_2': 0.002506256103515625, 'loss_3': -16.3961238861084, 'loss_4': 0.5581870079040527, 'epoch': 19.73}
{'loss': 0.0126, 'grad_norm': 6.768182277679443, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.011985227465629578, 'loss_2': 0.0005860328674316406, 'loss_3': -16.617305755615234, 'loss_4': 0.0923953428864479, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 13:44:35,475 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:35,475 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:23:54<30:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:42,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01783164218068123, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.016, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013625461608171463, 'eval_loss_2': 0.004206180572509766, 'eval_loss_3': -18.281822204589844, 'eval_loss_4': 0.10655500739812851, 'epoch': 19.74}
{'loss': 0.0159, 'grad_norm': 8.299007415771484, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.012761369347572327, 'loss_2': 0.0031280517578125, 'loss_3': -16.733699798583984, 'loss_4': 0.2386474609375, 'epoch': 19.74}
{'loss': 0.0337, 'grad_norm': 8.454917907714844, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.02524351328611374, 'loss_2': 0.00847625732421875, 'loss_3': -16.451566696166992, 'loss_4': -0.28470444679260254, 'epoch': 19.75}
{'loss': 0.0166, 'grad_norm': 5.56630802154541, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.006951586343348026, 'loss_2': 0.0096282958984375, 'loss_3': -16.485687255859375, 'loss_4': 0.19280315935611725, 'epoch': 19.76}
{'loss': 0.0176, 'grad_norm': 5.625240802764893, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.011904053390026093, 'loss_2': 0.005680084228515625, 'loss_3': -16.40532684326172, 'loss_4': 0.29648908972740173, 'epoch': 19.76}
{'loss': 0.0147, 'grad_norm': 4.892000675201416, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.007088708225637674, 'loss_2': 0.00763702392578125, 'loss_3': -16.51787567138672, 'loss_4': 0.5301455855369568, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 13:44:42,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:42,809 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:24:02<30:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:50,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02046991139650345, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.481, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014404459856450558, 'eval_loss_2': 0.006065450608730316, 'eval_loss_3': -18.286592483520508, 'eval_loss_4': 0.040733855217695236, 'epoch': 19.77}
{'loss': 0.0136, 'grad_norm': 6.658223628997803, 'learning_rate': 1.025e-05, 'loss_1': 0.012285713106393814, 'loss_2': 0.0013360977172851562, 'loss_3': -16.437625885009766, 'loss_4': -0.02110990881919861, 'epoch': 19.77}
{'loss': 0.0098, 'grad_norm': 4.820324897766113, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.00626756576821208, 'loss_2': 0.0035572052001953125, 'loss_3': -16.623538970947266, 'loss_4': 0.0958993136882782, 'epoch': 19.78}
{'loss': 0.0103, 'grad_norm': 5.233133316040039, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.009796250611543655, 'loss_2': 0.0005240440368652344, 'loss_3': -16.41727066040039, 'loss_4': 0.40477555990219116, 'epoch': 19.78}
{'loss': 0.0211, 'grad_norm': 5.979699611663818, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.013780924491584301, 'loss_2': 0.00727081298828125, 'loss_3': -16.512571334838867, 'loss_4': 0.47477656602859497, 'epoch': 19.79}
{'loss': 0.01, 'grad_norm': 4.565298557281494, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.008093556389212608, 'loss_2': 0.0019283294677734375, 'loss_3': -16.54826545715332, 'loss_4': 0.29133671522140503, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 13:44:50,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:50,131 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:09<30:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:57,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019392769783735275, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.18, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.014821152202785015, 'eval_loss_2': 0.0045716166496276855, 'eval_loss_3': -18.28935432434082, 'eval_loss_4': 0.038055241107940674, 'epoch': 19.8}
{'loss': 0.0087, 'grad_norm': 4.84105110168457, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.007943365722894669, 'loss_2': 0.0007252693176269531, 'loss_3': -16.567073822021484, 'loss_4': 0.2010110318660736, 'epoch': 19.8}
{'loss': 0.0069, 'grad_norm': 4.50804328918457, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.005679345689713955, 'loss_2': 0.001186370849609375, 'loss_3': -16.561256408691406, 'loss_4': -0.0388694703578949, 'epoch': 19.81}
{'loss': 0.0075, 'grad_norm': 5.064248085021973, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.005674202926456928, 'loss_2': 0.001781463623046875, 'loss_3': -16.57093620300293, 'loss_4': -0.18467997014522552, 'epoch': 19.81}
{'loss': 0.016, 'grad_norm': 6.297699451446533, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.01194126345217228, 'loss_2': 0.004047393798828125, 'loss_3': -16.561241149902344, 'loss_4': 0.371219664812088, 'epoch': 19.82}
{'loss': 0.0322, 'grad_norm': 16.802000045776367, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.024357732385396957, 'loss_2': 0.007801055908203125, 'loss_3': -16.700424194335938, 'loss_4': -0.09295661002397537, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 13:44:57,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:57,461 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:16<30:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:04,796 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017217304557561874, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.965, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.013783656060695648, 'eval_loss_2': 0.003433648496866226, 'eval_loss_3': -18.272401809692383, 'eval_loss_4': 0.013919846154749393, 'epoch': 19.83}
{'loss': 0.0254, 'grad_norm': 7.642360687255859, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.017750246450304985, 'loss_2': 0.0076751708984375, 'loss_3': -16.431352615356445, 'loss_4': 0.4076232314109802, 'epoch': 19.83}
{'loss': 0.0029, 'grad_norm': 4.707924842834473, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.0028381722513586283, 'loss_2': 1.919269561767578e-05, 'loss_3': -16.482744216918945, 'loss_4': 0.3655611276626587, 'epoch': 19.84}
{'loss': 0.0101, 'grad_norm': 5.679773330688477, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.00956736784428358, 'loss_2': 0.00049591064453125, 'loss_3': -16.46995735168457, 'loss_4': 0.43600136041641235, 'epoch': 19.84}
{'loss': 0.0092, 'grad_norm': 6.755841255187988, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.006586927454918623, 'loss_2': 0.0026092529296875, 'loss_3': -16.483163833618164, 'loss_4': 0.07952779531478882, 'epoch': 19.85}
{'loss': 0.0131, 'grad_norm': 5.134664058685303, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.007232243195176125, 'loss_2': 0.00588226318359375, 'loss_3': -16.425662994384766, 'loss_4': 0.2700420618057251, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 13:45:04,796 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:04,796 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:24<30:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:12,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017083648592233658, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.197, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013527018949389458, 'eval_loss_2': 0.003556627780199051, 'eval_loss_3': -18.265199661254883, 'eval_loss_4': -0.020089924335479736, 'epoch': 19.85}
{'loss': 0.0548, 'grad_norm': 6.608898162841797, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.04707049950957298, 'loss_2': 0.00768280029296875, 'loss_3': -16.653392791748047, 'loss_4': 0.31413328647613525, 'epoch': 19.86}
{'loss': 0.0133, 'grad_norm': 5.381840229034424, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.007233342621475458, 'loss_2': 0.0060272216796875, 'loss_3': -16.551942825317383, 'loss_4': 0.6592762470245361, 'epoch': 19.87}
{'loss': 0.0145, 'grad_norm': 5.100008964538574, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.009495421312749386, 'loss_2': 0.005001068115234375, 'loss_3': -16.73069190979004, 'loss_4': -0.10828065127134323, 'epoch': 19.87}
{'loss': 0.017, 'grad_norm': 4.646928787231445, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.006978875026106834, 'loss_2': 0.01003265380859375, 'loss_3': -16.489349365234375, 'loss_4': 0.5694018006324768, 'epoch': 19.88}
{'loss': 0.0096, 'grad_norm': 4.866021633148193, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.005548005923628807, 'loss_2': 0.0040740966796875, 'loss_3': -16.460445404052734, 'loss_4': 0.3371555507183075, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 13:45:12,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:12,124 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:31<29:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:19,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015840083360671997, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.32, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01198918279260397, 'eval_loss_2': 0.003850899636745453, 'eval_loss_3': -18.282625198364258, 'eval_loss_4': 0.05797016620635986, 'epoch': 19.88}
{'loss': 0.0061, 'grad_norm': 4.9867143630981445, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.00412170821800828, 'loss_2': 0.001956939697265625, 'loss_3': -16.630781173706055, 'loss_4': 0.25506728887557983, 'epoch': 19.89}
{'loss': 0.0137, 'grad_norm': 7.225017070770264, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.011798051185905933, 'loss_2': 0.001903533935546875, 'loss_3': -16.330280303955078, 'loss_4': 0.6053974628448486, 'epoch': 19.9}
{'loss': 0.0114, 'grad_norm': 4.7208123207092285, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.004979035817086697, 'loss_2': 0.006427764892578125, 'loss_3': -16.555479049682617, 'loss_4': 0.7587127089500427, 'epoch': 19.9}
{'loss': 0.008, 'grad_norm': 5.0266947746276855, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.006510312203317881, 'loss_2': 0.0015287399291992188, 'loss_3': -16.463857650756836, 'loss_4': -0.18163755536079407, 'epoch': 19.91}
{'loss': 0.0134, 'grad_norm': 6.860701084136963, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.01128403190523386, 'loss_2': 0.0020847320556640625, 'loss_3': -16.521892547607422, 'loss_4': 0.20288705825805664, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 13:45:19,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:19,450 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:38<29:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:26,773 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01556592620909214, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.327, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011490728706121445, 'eval_loss_2': 0.004075199365615845, 'eval_loss_3': -18.274024963378906, 'eval_loss_4': 0.08213943243026733, 'epoch': 19.91}
{'loss': 0.0034, 'grad_norm': 4.866485595703125, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.003076036460697651, 'loss_2': 0.00029659271240234375, 'loss_3': -16.64258575439453, 'loss_4': 0.4022487998008728, 'epoch': 19.92}
{'loss': 0.0165, 'grad_norm': 8.331615447998047, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.010792266577482224, 'loss_2': 0.005748748779296875, 'loss_3': -16.475589752197266, 'loss_4': 0.29086941480636597, 'epoch': 19.92}
{'loss': 0.0072, 'grad_norm': 4.549088954925537, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.0037991052959114313, 'loss_2': 0.00341796875, 'loss_3': -16.668930053710938, 'loss_4': 0.668362557888031, 'epoch': 19.93}
{'loss': 0.0078, 'grad_norm': 4.897851467132568, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.0077974372543394566, 'loss_2': 7.152557373046875e-06, 'loss_3': -16.50318145751953, 'loss_4': 0.4354614019393921, 'epoch': 19.94}
{'loss': 0.0137, 'grad_norm': 6.182750225067139, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.01362282782793045, 'loss_2': 5.53131103515625e-05, 'loss_3': -16.65593910217285, 'loss_4': 0.281655490398407, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 13:45:26,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:26,774 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:46<30:57,  1.08s/it][INFO|trainer.py:4226] 2025-01-21 13:45:34,296 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015083950944244862, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.325, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011310523375868797, 'eval_loss_2': 0.003773428499698639, 'eval_loss_3': -18.29334259033203, 'eval_loss_4': 0.009796995669603348, 'epoch': 19.94}
{'loss': 0.0089, 'grad_norm': 5.349137306213379, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.006261150818318129, 'loss_2': 0.0026531219482421875, 'loss_3': -16.496829986572266, 'loss_4': 0.3189958930015564, 'epoch': 19.95}
{'loss': 0.0175, 'grad_norm': 8.600898742675781, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.01266909297555685, 'loss_2': 0.00485992431640625, 'loss_3': -16.635974884033203, 'loss_4': 0.14117583632469177, 'epoch': 19.95}
{'loss': 0.0104, 'grad_norm': 7.958167552947998, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.010401292704045773, 'loss_2': 3.504753112792969e-05, 'loss_3': -16.62578582763672, 'loss_4': 0.27870410680770874, 'epoch': 19.96}
{'loss': 0.0216, 'grad_norm': 5.34513521194458, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.011501523666083813, 'loss_2': 0.01012420654296875, 'loss_3': -16.478981018066406, 'loss_4': -0.16317059099674225, 'epoch': 19.97}
{'loss': 0.0823, 'grad_norm': 10.707523345947266, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.07673805207014084, 'loss_2': 0.005611419677734375, 'loss_3': -16.490062713623047, 'loss_4': 0.21171408891677856, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 13:45:34,296 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:34,297 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:24:53<26:52,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:45:41,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015307104215025902, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.168, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010605251416563988, 'eval_loss_2': 0.004701852798461914, 'eval_loss_3': -18.302471160888672, 'eval_loss_4': -0.062474269419908524, 'epoch': 19.97}
{'loss': 0.0102, 'grad_norm': 5.677806377410889, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.008223230950534344, 'loss_2': 0.00200653076171875, 'loss_3': -16.552490234375, 'loss_4': 0.023145213723182678, 'epoch': 19.98}
{'loss': 0.0089, 'grad_norm': 5.239100456237793, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.008679070509970188, 'loss_2': 0.0001838207244873047, 'loss_3': -16.71684455871582, 'loss_4': 0.007244706153869629, 'epoch': 19.98}
{'loss': 0.0237, 'grad_norm': 9.001428604125977, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.016847699880599976, 'loss_2': 0.006816864013671875, 'loss_3': -16.34678077697754, 'loss_4': -0.03813090920448303, 'epoch': 19.99}
{'loss': 0.0103, 'grad_norm': 5.242306232452393, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.007017020136117935, 'loss_2': 0.00323486328125, 'loss_3': -16.515522003173828, 'loss_4': -0.14131495356559753, 'epoch': 19.99}
{'loss': 0.004, 'grad_norm': 6.018514156341553, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.0013417756417766213, 'loss_2': 0.0026645660400390625, 'loss_3': -16.41911506652832, 'loss_4': -0.00015595380682498217, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 13:45:41,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:41,270 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:25:00<29:12,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:45:48,639 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01513715647161007, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012009253725409508, 'eval_loss_2': 0.0031279027462005615, 'eval_loss_3': -18.320537567138672, 'eval_loss_4': -0.16368919610977173, 'epoch': 20.0}
{'loss': 0.0263, 'grad_norm': 10.375879287719727, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.017889201641082764, 'loss_2': 0.0084381103515625, 'loss_3': -16.47761344909668, 'loss_4': 0.04766768962144852, 'epoch': 20.01}
{'loss': 0.0131, 'grad_norm': 6.181187152862549, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.012977326288819313, 'loss_2': 8.463859558105469e-05, 'loss_3': -16.34381866455078, 'loss_4': 0.24406272172927856, 'epoch': 20.01}
{'loss': 0.0133, 'grad_norm': 4.836429595947266, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.006463271100074053, 'loss_2': 0.0067901611328125, 'loss_3': -16.321186065673828, 'loss_4': -0.24748259782791138, 'epoch': 20.02}
{'loss': 0.0334, 'grad_norm': 15.750813484191895, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.02665800042450428, 'loss_2': 0.0067901611328125, 'loss_3': -16.240188598632812, 'loss_4': 0.5794675350189209, 'epoch': 20.02}
{'loss': 0.0105, 'grad_norm': 5.701292514801025, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.009007439948618412, 'loss_2': 0.0014905929565429688, 'loss_3': -16.66716766357422, 'loss_4': 0.13366387784481049, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 13:45:48,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:48,640 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:25:07<29:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:45:55,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016628174111247063, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.317, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01210048608481884, 'eval_loss_2': 0.004527688026428223, 'eval_loss_3': -18.320419311523438, 'eval_loss_4': -0.1932578682899475, 'epoch': 20.03}
{'loss': 0.0108, 'grad_norm': 4.961623191833496, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.008840534836053848, 'loss_2': 0.001934051513671875, 'loss_3': -16.54793357849121, 'loss_4': -0.19391849637031555, 'epoch': 20.03}
{'loss': 0.0344, 'grad_norm': 18.230026245117188, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.03402736410498619, 'loss_2': 0.0003590583801269531, 'loss_3': -16.375221252441406, 'loss_4': 0.23605147004127502, 'epoch': 20.04}
{'loss': 0.0097, 'grad_norm': 5.9760613441467285, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.007630155421793461, 'loss_2': 0.0020599365234375, 'loss_3': -16.613807678222656, 'loss_4': -0.051514774560928345, 'epoch': 20.05}
{'loss': 0.0048, 'grad_norm': 4.558333396911621, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.00466408533975482, 'loss_2': 0.00010877847671508789, 'loss_3': -16.644577026367188, 'loss_4': 0.5681197047233582, 'epoch': 20.05}
{'loss': 0.0195, 'grad_norm': 7.265133380889893, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.010959860868752003, 'loss_2': 0.00855255126953125, 'loss_3': -16.626998901367188, 'loss_4': 0.44849690794944763, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 13:45:55,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:55,965 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:15<29:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:46:03,290 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016140686348080635, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010448206216096878, 'eval_loss_2': 0.005692481994628906, 'eval_loss_3': -18.319381713867188, 'eval_loss_4': -0.14814281463623047, 'epoch': 20.06}
{'loss': 0.0172, 'grad_norm': 8.616206169128418, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.01467321440577507, 'loss_2': 0.0025177001953125, 'loss_3': -16.500591278076172, 'loss_4': 0.35719889402389526, 'epoch': 20.06}
{'loss': 0.0166, 'grad_norm': 5.476891994476318, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.009967424906790257, 'loss_2': 0.00667572021484375, 'loss_3': -16.540040969848633, 'loss_4': 0.1784028559923172, 'epoch': 20.07}
{'loss': 0.0197, 'grad_norm': 5.267214298248291, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.008671483024954796, 'loss_2': 0.011077880859375, 'loss_3': -16.58715057373047, 'loss_4': 0.48519420623779297, 'epoch': 20.08}
{'loss': 0.0199, 'grad_norm': 9.026132583618164, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.01682760752737522, 'loss_2': 0.0030460357666015625, 'loss_3': -16.570932388305664, 'loss_4': 0.12798571586608887, 'epoch': 20.08}
{'loss': 0.0104, 'grad_norm': 5.2101287841796875, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.00659915991127491, 'loss_2': 0.0037841796875, 'loss_3': -16.666261672973633, 'loss_4': 0.33051177859306335, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 13:46:03,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:03,290 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:22<29:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:46:10,614 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014146324247121811, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.181, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.010514047928154469, 'eval_loss_2': 0.003632277250289917, 'eval_loss_3': -18.33053970336914, 'eval_loss_4': -0.16960330307483673, 'epoch': 20.09}
{'loss': 0.0127, 'grad_norm': 8.047825813293457, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.011016123928129673, 'loss_2': 0.0017147064208984375, 'loss_3': -16.581558227539062, 'loss_4': 0.8020870685577393, 'epoch': 20.09}
{'loss': 0.081, 'grad_norm': 16.724838256835938, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.0773291140794754, 'loss_2': 0.0036334991455078125, 'loss_3': -16.35353660583496, 'loss_4': 0.6835157871246338, 'epoch': 20.1}
{'loss': 0.0087, 'grad_norm': 4.938837051391602, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.0047041685320436954, 'loss_2': 0.003955841064453125, 'loss_3': -16.459043502807617, 'loss_4': 0.1518957018852234, 'epoch': 20.1}
{'loss': 0.0157, 'grad_norm': 10.97412109375, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.014680121093988419, 'loss_2': 0.00103759765625, 'loss_3': -16.6900634765625, 'loss_4': 0.20699872076511383, 'epoch': 20.11}
{'loss': 0.0344, 'grad_norm': 7.526860237121582, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.027692023664712906, 'loss_2': 0.006748199462890625, 'loss_3': -16.335020065307617, 'loss_4': -0.10328468680381775, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 13:46:10,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:10,614 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:29<29:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:46:17,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014847963117063046, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.318, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.010799461044371128, 'eval_loss_2': 0.004048503935337067, 'eval_loss_3': -18.344770431518555, 'eval_loss_4': -0.1698533594608307, 'epoch': 20.12}
{'loss': 0.011, 'grad_norm': 5.219322681427002, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.008032825775444508, 'loss_2': 0.0029659271240234375, 'loss_3': -16.495155334472656, 'loss_4': 0.4520550072193146, 'epoch': 20.12}
{'loss': 0.0099, 'grad_norm': 5.193349361419678, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.0036394367925822735, 'loss_2': 0.0063018798828125, 'loss_3': -16.541229248046875, 'loss_4': -0.24887584149837494, 'epoch': 20.13}
{'loss': 0.0165, 'grad_norm': 4.660233020782471, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.006317739840596914, 'loss_2': 0.01013946533203125, 'loss_3': -16.436248779296875, 'loss_4': 0.3767390847206116, 'epoch': 20.13}
{'loss': 0.0378, 'grad_norm': 15.386807441711426, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.033091653138399124, 'loss_2': 0.004680633544921875, 'loss_3': -16.667926788330078, 'loss_4': 0.342830091714859, 'epoch': 20.14}
{'loss': 0.0218, 'grad_norm': 6.837457656860352, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.017000149935483932, 'loss_2': 0.0047760009765625, 'loss_3': -16.570375442504883, 'loss_4': 0.9228454828262329, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 13:46:17,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:17,934 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:37<29:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:25,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013963060453534126, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.669, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009804625064134598, 'eval_loss_2': 0.004158437252044678, 'eval_loss_3': -18.34044647216797, 'eval_loss_4': -0.165042906999588, 'epoch': 20.15}
{'loss': 0.0115, 'grad_norm': 5.647465229034424, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.004244799260050058, 'loss_2': 0.007305145263671875, 'loss_3': -16.71036148071289, 'loss_4': -0.3722935616970062, 'epoch': 20.15}
{'loss': 0.008, 'grad_norm': 5.154231548309326, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.004376287572085857, 'loss_2': 0.003620147705078125, 'loss_3': -16.561071395874023, 'loss_4': 0.33319854736328125, 'epoch': 20.16}
{'loss': 0.0044, 'grad_norm': 4.8321614265441895, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.002926628338173032, 'loss_2': 0.0015201568603515625, 'loss_3': -16.553058624267578, 'loss_4': -0.29237061738967896, 'epoch': 20.16}
{'loss': 0.0073, 'grad_norm': 5.235281467437744, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.006563492119312286, 'loss_2': 0.00069427490234375, 'loss_3': -16.682891845703125, 'loss_4': 0.21367548406124115, 'epoch': 20.17}
{'loss': 0.0321, 'grad_norm': 12.096627235412598, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.029831988736987114, 'loss_2': 0.002292633056640625, 'loss_3': -16.485807418823242, 'loss_4': -0.17573130130767822, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 13:46:25,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:25,267 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:44<29:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:32,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014284349977970123, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.032, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.00993422418832779, 'eval_loss_2': 0.004350125789642334, 'eval_loss_3': -18.33912467956543, 'eval_loss_4': -0.16028204560279846, 'epoch': 20.17}
{'loss': 0.0045, 'grad_norm': 4.607608318328857, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.00419430760666728, 'loss_2': 0.00027179718017578125, 'loss_3': -16.743179321289062, 'loss_4': 0.3615226149559021, 'epoch': 20.18}
{'loss': 0.0085, 'grad_norm': 4.887664794921875, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.006359937600791454, 'loss_2': 0.002162933349609375, 'loss_3': -16.47840690612793, 'loss_4': 0.038994453847408295, 'epoch': 20.19}
{'loss': 0.0486, 'grad_norm': 21.85358238220215, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.0473630465567112, 'loss_2': 0.0012378692626953125, 'loss_3': -16.473360061645508, 'loss_4': -0.12197256833314896, 'epoch': 20.19}
{'loss': 0.0172, 'grad_norm': 7.146550178527832, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.012040569446980953, 'loss_2': 0.005153656005859375, 'loss_3': -16.445037841796875, 'loss_4': -0.4570731520652771, 'epoch': 20.2}
{'loss': 0.0147, 'grad_norm': 5.231485843658447, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.007594575174152851, 'loss_2': 0.00711822509765625, 'loss_3': -16.514774322509766, 'loss_4': 0.5486919283866882, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 13:46:32,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:32,597 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:25:51<28:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:46:39,922 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01618088036775589, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.066, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011270172894001007, 'eval_loss_2': 0.004910707473754883, 'eval_loss_3': -18.334495544433594, 'eval_loss_4': -0.1491079181432724, 'epoch': 20.2}
{'loss': 0.0111, 'grad_norm': 5.619503021240234, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.005810623988509178, 'loss_2': 0.00531005859375, 'loss_3': -16.566007614135742, 'loss_4': 0.08437003195285797, 'epoch': 20.21}
{'loss': 0.0154, 'grad_norm': 7.117473602294922, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.011008820496499538, 'loss_2': 0.004425048828125, 'loss_3': -16.641735076904297, 'loss_4': 0.13614964485168457, 'epoch': 20.22}
{'loss': 0.0191, 'grad_norm': 10.92652702331543, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.01789201609790325, 'loss_2': 0.00124359130859375, 'loss_3': -16.53346824645996, 'loss_4': 0.07002899050712585, 'epoch': 20.22}
{'loss': 0.0065, 'grad_norm': 5.164173603057861, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.005663551855832338, 'loss_2': 0.0008640289306640625, 'loss_3': -16.43744659423828, 'loss_4': -0.1147848591208458, 'epoch': 20.23}
{'loss': 0.0123, 'grad_norm': 4.82313346862793, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.005721530877053738, 'loss_2': 0.006534576416015625, 'loss_3': -16.61844825744629, 'loss_4': 0.0818653404712677, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 13:46:39,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:39,923 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:25:59<28:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:46:47,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016311880201101303, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.351, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011503693647682667, 'eval_loss_2': 0.004808187484741211, 'eval_loss_3': -18.333513259887695, 'eval_loss_4': -0.11638395488262177, 'epoch': 20.23}
{'loss': 0.0211, 'grad_norm': 5.900986194610596, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.018462540581822395, 'loss_2': 0.002685546875, 'loss_3': -16.311120986938477, 'loss_4': -0.03276292607188225, 'epoch': 20.24}
{'loss': 0.0131, 'grad_norm': 4.426173686981201, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.007007744628936052, 'loss_2': 0.006134033203125, 'loss_3': -16.60373306274414, 'loss_4': 0.04428577423095703, 'epoch': 20.24}
{'loss': 0.0163, 'grad_norm': 5.226267337799072, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.014895055443048477, 'loss_2': 0.0013761520385742188, 'loss_3': -16.466941833496094, 'loss_4': 0.02160733938217163, 'epoch': 20.25}
{'loss': 0.0124, 'grad_norm': 5.158215522766113, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.009151902981102467, 'loss_2': 0.0032596588134765625, 'loss_3': -16.260852813720703, 'loss_4': -0.11873822659254074, 'epoch': 20.26}
{'loss': 0.0106, 'grad_norm': 4.72853946685791, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.0065278480760753155, 'loss_2': 0.004085540771484375, 'loss_3': -16.658761978149414, 'loss_4': 0.19066405296325684, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 13:46:47,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:47,247 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:26:06<28:47,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:46:54,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0163591131567955, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.909, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011919043026864529, 'eval_loss_2': 0.0044400691986083984, 'eval_loss_3': -18.33012580871582, 'eval_loss_4': -0.04192466288805008, 'epoch': 20.26}
{'loss': 0.0111, 'grad_norm': 5.0120978355407715, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.008551402948796749, 'loss_2': 0.002574920654296875, 'loss_3': -16.57012367248535, 'loss_4': 0.11373767256736755, 'epoch': 20.27}
{'loss': 0.0131, 'grad_norm': 7.276493072509766, 'learning_rate': 9.75e-06, 'loss_1': 0.012128391303122044, 'loss_2': 0.0009613037109375, 'loss_3': -16.430089950561523, 'loss_4': 0.04039476066827774, 'epoch': 20.27}
{'loss': 0.0115, 'grad_norm': 4.946169853210449, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.006916841957718134, 'loss_2': 0.00458526611328125, 'loss_3': -16.634010314941406, 'loss_4': 0.32231414318084717, 'epoch': 20.28}
{'loss': 0.0092, 'grad_norm': 4.3498640060424805, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.004108445718884468, 'loss_2': 0.005046844482421875, 'loss_3': -16.484020233154297, 'loss_4': -0.14880165457725525, 'epoch': 20.28}
{'loss': 0.0081, 'grad_norm': 5.540806770324707, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.007151395548135042, 'loss_2': 0.0009245872497558594, 'loss_3': -16.329673767089844, 'loss_4': 0.18537743389606476, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 13:46:54,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:54,579 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:13<28:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:01,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015334350988268852, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.136, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.011322853155434132, 'eval_loss_2': 0.004011496901512146, 'eval_loss_3': -18.343978881835938, 'eval_loss_4': -0.018207935616374016, 'epoch': 20.29}
{'loss': 0.0122, 'grad_norm': 6.453778266906738, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.010201136581599712, 'loss_2': 0.00197601318359375, 'loss_3': -16.49798583984375, 'loss_4': 0.3697245717048645, 'epoch': 20.3}
{'loss': 0.0174, 'grad_norm': 6.325992584228516, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.011146711185574532, 'loss_2': 0.00624847412109375, 'loss_3': -16.62163543701172, 'loss_4': 0.05080182105302811, 'epoch': 20.3}
{'loss': 0.0034, 'grad_norm': 4.112338066101074, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.0029025075491517782, 'loss_2': 0.00047659873962402344, 'loss_3': -16.726367950439453, 'loss_4': -0.08969298005104065, 'epoch': 20.31}
{'loss': 0.0128, 'grad_norm': 4.829775810241699, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.009308852255344391, 'loss_2': 0.00347900390625, 'loss_3': -16.532976150512695, 'loss_4': 0.43381673097610474, 'epoch': 20.31}
{'loss': 0.0061, 'grad_norm': 5.468730449676514, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.005223196465522051, 'loss_2': 0.0009226799011230469, 'loss_3': -16.454341888427734, 'loss_4': 0.28709667921066284, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 13:47:01,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:01,909 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:21<28:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:09,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014067372307181358, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010899251326918602, 'eval_loss_2': 0.0031681209802627563, 'eval_loss_3': -18.337297439575195, 'eval_loss_4': -0.018612602725625038, 'epoch': 20.32}
{'loss': 0.0097, 'grad_norm': 4.832740783691406, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.009355653077363968, 'loss_2': 0.00031495094299316406, 'loss_3': -16.60418701171875, 'loss_4': 0.3313666880130768, 'epoch': 20.33}
{'loss': 0.0068, 'grad_norm': 4.732973575592041, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.005771138239651918, 'loss_2': 0.0010242462158203125, 'loss_3': -16.45794105529785, 'loss_4': 0.1585177481174469, 'epoch': 20.33}
{'loss': 0.0191, 'grad_norm': 13.49828052520752, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.019032325595617294, 'loss_2': 0.0001043081283569336, 'loss_3': -16.62810707092285, 'loss_4': 0.49148663878440857, 'epoch': 20.34}
{'loss': 0.0121, 'grad_norm': 5.148038864135742, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.005997128784656525, 'loss_2': 0.006107330322265625, 'loss_3': -16.385225296020508, 'loss_4': 0.29563671350479126, 'epoch': 20.34}
{'loss': 0.0093, 'grad_norm': 6.8534321784973145, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.008573872968554497, 'loss_2': 0.0006985664367675781, 'loss_3': -16.451316833496094, 'loss_4': 0.12466561794281006, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 13:47:09,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:09,250 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:28<28:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:16,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014064464718103409, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.010673110373318195, 'eval_loss_2': 0.003391355276107788, 'eval_loss_3': -18.327852249145508, 'eval_loss_4': 0.0991508811712265, 'epoch': 20.35}
{'loss': 0.0489, 'grad_norm': 16.324817657470703, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.04570925608277321, 'loss_2': 0.0032024383544921875, 'loss_3': -16.426124572753906, 'loss_4': 0.5818897485733032, 'epoch': 20.35}
{'loss': 0.0604, 'grad_norm': 18.66450309753418, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.05803890898823738, 'loss_2': 0.002391815185546875, 'loss_3': -16.45448875427246, 'loss_4': 0.40960097312927246, 'epoch': 20.36}
{'loss': 0.0068, 'grad_norm': 4.6232991218566895, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.006093580741435289, 'loss_2': 0.0007152557373046875, 'loss_3': -16.624408721923828, 'loss_4': 0.6934317350387573, 'epoch': 20.37}
{'loss': 0.0073, 'grad_norm': 4.967628479003906, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.004363558255136013, 'loss_2': 0.0029144287109375, 'loss_3': -16.508546829223633, 'loss_4': -0.02133585512638092, 'epoch': 20.37}
{'loss': 0.0154, 'grad_norm': 5.528273105621338, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.012437005527317524, 'loss_2': 0.00292205810546875, 'loss_3': -16.394001007080078, 'loss_4': -0.19557976722717285, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 13:47:16,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:16,580 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:35<28:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:23,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014361119829118252, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.018, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01142573356628418, 'eval_loss_2': 0.0029353871941566467, 'eval_loss_3': -18.30944061279297, 'eval_loss_4': 0.1368650496006012, 'epoch': 20.38}
{'loss': 0.0082, 'grad_norm': 4.6223626136779785, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.008039413951337337, 'loss_2': 0.00017189979553222656, 'loss_3': -16.48757553100586, 'loss_4': 0.5169685482978821, 'epoch': 20.38}
{'loss': 0.0123, 'grad_norm': 9.891399383544922, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.012097240425646305, 'loss_2': 0.00023031234741210938, 'loss_3': -16.586727142333984, 'loss_4': 0.08025363087654114, 'epoch': 20.39}
{'loss': 0.0075, 'grad_norm': 4.574349880218506, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.004988411907106638, 'loss_2': 0.00255584716796875, 'loss_3': -16.62415313720703, 'loss_4': 0.7511469125747681, 'epoch': 20.4}
{'loss': 0.0112, 'grad_norm': 6.205443859100342, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.0067472681403160095, 'loss_2': 0.00444793701171875, 'loss_3': -16.582263946533203, 'loss_4': 0.28887391090393066, 'epoch': 20.4}
{'loss': 0.0069, 'grad_norm': 4.602390766143799, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.003943880088627338, 'loss_2': 0.002964019775390625, 'loss_3': -16.535327911376953, 'loss_4': 0.6470527648925781, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 13:47:23,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:23,905 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:43<28:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:47:31,230 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013524038717150688, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.212, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.010683699510991573, 'eval_loss_2': 0.0028403401374816895, 'eval_loss_3': -18.293195724487305, 'eval_loss_4': 0.09565819054841995, 'epoch': 20.41}
{'loss': 0.0111, 'grad_norm': 6.018399238586426, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.007542329374700785, 'loss_2': 0.0035800933837890625, 'loss_3': -16.37601089477539, 'loss_4': 0.5341929197311401, 'epoch': 20.41}
{'loss': 0.008, 'grad_norm': 5.116384983062744, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.007494681980460882, 'loss_2': 0.0005483627319335938, 'loss_3': -16.528579711914062, 'loss_4': 0.501463770866394, 'epoch': 20.42}
{'loss': 0.0105, 'grad_norm': 4.69313383102417, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.007883022539317608, 'loss_2': 0.00262451171875, 'loss_3': -16.604724884033203, 'loss_4': 0.46256810426712036, 'epoch': 20.42}
{'loss': 0.0072, 'grad_norm': 4.599559783935547, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.006938381120562553, 'loss_2': 0.0002505779266357422, 'loss_3': -16.53661346435547, 'loss_4': 0.45613333582878113, 'epoch': 20.43}
{'loss': 0.0093, 'grad_norm': 4.632979393005371, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.005445100367069244, 'loss_2': 0.0038738250732421875, 'loss_3': -16.547012329101562, 'loss_4': 0.2689893841743469, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 13:47:31,230 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:31,231 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:50<28:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:47:38,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01576066203415394, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.495, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.010915041901171207, 'eval_loss_2': 0.004845619201660156, 'eval_loss_3': -18.266841888427734, 'eval_loss_4': 0.10450578480958939, 'epoch': 20.44}
{'loss': 0.009, 'grad_norm': 5.372171878814697, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.0068816510029137135, 'loss_2': 0.00209808349609375, 'loss_3': -16.562803268432617, 'loss_4': 0.5165339708328247, 'epoch': 20.44}
{'loss': 0.0179, 'grad_norm': 6.367825984954834, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.010771660134196281, 'loss_2': 0.00708770751953125, 'loss_3': -16.5900936126709, 'loss_4': 0.6941295862197876, 'epoch': 20.45}
{'loss': 0.0125, 'grad_norm': 5.2596869468688965, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.006180858705192804, 'loss_2': 0.006317138671875, 'loss_3': -16.276865005493164, 'loss_4': 0.2623016834259033, 'epoch': 20.45}
{'loss': 0.013, 'grad_norm': 4.6792311668396, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.006929297931492329, 'loss_2': 0.0061187744140625, 'loss_3': -16.65824317932129, 'loss_4': 0.2828013598918915, 'epoch': 20.46}
{'loss': 0.0109, 'grad_norm': 5.914170742034912, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.009115603752434254, 'loss_2': 0.0018281936645507812, 'loss_3': -16.564912796020508, 'loss_4': -0.13080042600631714, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 13:47:38,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:38,555 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:26:57<28:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:45,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01627400517463684, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.011, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011809676885604858, 'eval_loss_2': 0.004464328289031982, 'eval_loss_3': -18.244239807128906, 'eval_loss_4': 0.13282936811447144, 'epoch': 20.47}
{'loss': 0.0076, 'grad_norm': 5.88336181640625, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.007357132621109486, 'loss_2': 0.0002338886260986328, 'loss_3': -16.575769424438477, 'loss_4': 0.4734608232975006, 'epoch': 20.47}
{'loss': 0.0095, 'grad_norm': 5.263911247253418, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.004767908249050379, 'loss_2': 0.00470733642578125, 'loss_3': -16.502042770385742, 'loss_4': 0.5414413213729858, 'epoch': 20.48}
{'loss': 0.0675, 'grad_norm': 16.370468139648438, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.05832481011748314, 'loss_2': 0.00922393798828125, 'loss_3': -16.484172821044922, 'loss_4': 0.7717100381851196, 'epoch': 20.48}
{'loss': 0.0121, 'grad_norm': 4.896519660949707, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.005997676867991686, 'loss_2': 0.006137847900390625, 'loss_3': -16.50874900817871, 'loss_4': 0.572022020816803, 'epoch': 20.49}
{'loss': 0.0115, 'grad_norm': 5.841789245605469, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.00720629096031189, 'loss_2': 0.00434112548828125, 'loss_3': -16.54946517944336, 'loss_4': 0.17414414882659912, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 13:47:45,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:45,886 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:27:05<28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:53,212 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01574021577835083, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.147, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012361555360257626, 'eval_loss_2': 0.00337865948677063, 'eval_loss_3': -18.24312400817871, 'eval_loss_4': 0.06827554851770401, 'epoch': 20.49}
{'loss': 0.0057, 'grad_norm': 5.0477190017700195, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.004539028275758028, 'loss_2': 0.001201629638671875, 'loss_3': -16.412267684936523, 'loss_4': 0.322660356760025, 'epoch': 20.5}
{'loss': 0.0139, 'grad_norm': 5.150454998016357, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.006113747600466013, 'loss_2': 0.007778167724609375, 'loss_3': -16.41021728515625, 'loss_4': -0.21459630131721497, 'epoch': 20.51}
{'loss': 0.0099, 'grad_norm': 5.074091911315918, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.00884484313428402, 'loss_2': 0.0010738372802734375, 'loss_3': -16.55279541015625, 'loss_4': 0.2756444811820984, 'epoch': 20.51}
{'loss': 0.0178, 'grad_norm': 5.538025856018066, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.010414528660476208, 'loss_2': 0.0074310302734375, 'loss_3': -16.621841430664062, 'loss_4': 0.4351169466972351, 'epoch': 20.52}
{'loss': 0.0244, 'grad_norm': 9.713719367980957, 'learning_rate': 9.5e-06, 'loss_1': 0.022697769105434418, 'loss_2': 0.00170135498046875, 'loss_3': -16.521947860717773, 'loss_4': 0.3193055987358093, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 13:47:53,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:53,213 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:12<27:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:48:00,529 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016726087778806686, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.224, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012800435535609722, 'eval_loss_2': 0.00392565131187439, 'eval_loss_3': -18.23097801208496, 'eval_loss_4': -0.013838457874953747, 'epoch': 20.52}
{'loss': 0.0307, 'grad_norm': 14.74562931060791, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.02406221814453602, 'loss_2': 0.0066680908203125, 'loss_3': -16.427722930908203, 'loss_4': -0.07606691122055054, 'epoch': 20.53}
{'loss': 0.0105, 'grad_norm': 5.180022239685059, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.005743317771703005, 'loss_2': 0.00476837158203125, 'loss_3': -16.373023986816406, 'loss_4': 0.5323964953422546, 'epoch': 20.53}
{'loss': 0.0212, 'grad_norm': 6.532929420471191, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.013888267800211906, 'loss_2': 0.00730133056640625, 'loss_3': -16.430423736572266, 'loss_4': 0.13178592920303345, 'epoch': 20.54}
{'loss': 0.0257, 'grad_norm': 14.603804588317871, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.020820384845137596, 'loss_2': 0.0048980712890625, 'loss_3': -16.37264060974121, 'loss_4': 0.020720604807138443, 'epoch': 20.55}
{'loss': 0.0129, 'grad_norm': 4.323703765869141, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.003595537506043911, 'loss_2': 0.00926971435546875, 'loss_3': -16.461708068847656, 'loss_4': 0.47037607431411743, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 13:48:00,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:00,530 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:19<27:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:07,860 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017438117414712906, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.082, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012191538698971272, 'eval_loss_2': 0.005246579647064209, 'eval_loss_3': -18.234861373901367, 'eval_loss_4': -0.11736969649791718, 'epoch': 20.55}
{'loss': 0.0118, 'grad_norm': 5.052475929260254, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.006694736424833536, 'loss_2': 0.005126953125, 'loss_3': -16.276309967041016, 'loss_4': -0.47376441955566406, 'epoch': 20.56}
{'loss': 0.0081, 'grad_norm': 4.497585773468018, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.003733308520168066, 'loss_2': 0.004367828369140625, 'loss_3': -16.68891143798828, 'loss_4': -0.21559284627437592, 'epoch': 20.56}
{'loss': 0.011, 'grad_norm': 6.17270040512085, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.01016274094581604, 'loss_2': 0.000804901123046875, 'loss_3': -16.680574417114258, 'loss_4': -0.1550849825143814, 'epoch': 20.57}
{'loss': 0.0069, 'grad_norm': 4.863369464874268, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.0044900598004460335, 'loss_2': 0.00241851806640625, 'loss_3': -16.457746505737305, 'loss_4': 0.09766658395528793, 'epoch': 20.58}
{'loss': 0.0119, 'grad_norm': 4.530853271484375, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.006267044227570295, 'loss_2': 0.005615234375, 'loss_3': -16.593557357788086, 'loss_4': 0.13938775658607483, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 13:48:07,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:07,860 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:27<27:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:15,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015281164087355137, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.067, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012411169707775116, 'eval_loss_2': 0.0028699934482574463, 'eval_loss_3': -18.220006942749023, 'eval_loss_4': -0.10668965429067612, 'epoch': 20.58}
{'loss': 0.0167, 'grad_norm': 5.745053768157959, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.008387445472180843, 'loss_2': 0.008270263671875, 'loss_3': -16.5947265625, 'loss_4': 0.1100703775882721, 'epoch': 20.59}
{'loss': 0.004, 'grad_norm': 4.672918319702148, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.0032991033513098955, 'loss_2': 0.0007276535034179688, 'loss_3': -16.61841583251953, 'loss_4': 0.3302193582057953, 'epoch': 20.59}
{'loss': 0.0176, 'grad_norm': 8.664162635803223, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.0159870944917202, 'loss_2': 0.0015926361083984375, 'loss_3': -16.631303787231445, 'loss_4': 0.35785457491874695, 'epoch': 20.6}
{'loss': 0.0087, 'grad_norm': 5.658548831939697, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.007922898977994919, 'loss_2': 0.000732421875, 'loss_3': -16.6541690826416, 'loss_4': -0.1590147316455841, 'epoch': 20.6}
{'loss': 0.03, 'grad_norm': 14.165678024291992, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.020181292667984962, 'loss_2': 0.00981903076171875, 'loss_3': -16.482383728027344, 'loss_4': 0.5095217227935791, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 13:48:15,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:15,186 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:34<27:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:22,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014996761456131935, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012363160029053688, 'eval_loss_2': 0.002633601427078247, 'eval_loss_3': -18.209177017211914, 'eval_loss_4': -0.1486610472202301, 'epoch': 20.61}
{'loss': 0.0122, 'grad_norm': 4.394779205322266, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.005210269242525101, 'loss_2': 0.007030487060546875, 'loss_3': -16.566009521484375, 'loss_4': 0.016491129994392395, 'epoch': 20.62}
{'loss': 0.0061, 'grad_norm': 4.93748664855957, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.004904367960989475, 'loss_2': 0.001209259033203125, 'loss_3': -16.41440200805664, 'loss_4': 0.05332311987876892, 'epoch': 20.62}
{'loss': 0.0073, 'grad_norm': 4.9845404624938965, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.006461692973971367, 'loss_2': 0.0008063316345214844, 'loss_3': -16.480239868164062, 'loss_4': -0.3701399564743042, 'epoch': 20.63}
{'loss': 0.0138, 'grad_norm': 5.246744632720947, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.011646071448922157, 'loss_2': 0.002185821533203125, 'loss_3': -16.590290069580078, 'loss_4': 0.21529926359653473, 'epoch': 20.63}
{'loss': 0.0125, 'grad_norm': 6.001034259796143, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.009931128472089767, 'loss_2': 0.0025882720947265625, 'loss_3': -16.295373916625977, 'loss_4': 0.006079047918319702, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 13:48:22,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:22,513 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:41<27:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:29,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014964361675083637, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.405, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012098182924091816, 'eval_loss_2': 0.0028661787509918213, 'eval_loss_3': -18.20624542236328, 'eval_loss_4': -0.17762988805770874, 'epoch': 20.64}
{'loss': 0.0083, 'grad_norm': 4.735743999481201, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.004701434168964624, 'loss_2': 0.003589630126953125, 'loss_3': -16.32923698425293, 'loss_4': 0.09432321041822433, 'epoch': 20.65}
{'loss': 0.0202, 'grad_norm': 7.853259563446045, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.018981140106916428, 'loss_2': 0.001190185546875, 'loss_3': -16.525638580322266, 'loss_4': 0.13044549524784088, 'epoch': 20.65}
{'loss': 0.0108, 'grad_norm': 5.124403953552246, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.008645172230899334, 'loss_2': 0.0021419525146484375, 'loss_3': -16.508394241333008, 'loss_4': 0.062229424715042114, 'epoch': 20.66}
{'loss': 0.0161, 'grad_norm': 8.267345428466797, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.013673298060894012, 'loss_2': 0.002471923828125, 'loss_3': -16.49151611328125, 'loss_4': 0.2017964869737625, 'epoch': 20.66}
{'loss': 0.0096, 'grad_norm': 4.501530647277832, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.003276146948337555, 'loss_2': 0.006320953369140625, 'loss_3': -16.79684829711914, 'loss_4': 0.0747695192694664, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 13:48:29,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:29,852 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:49<27:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:48:37,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015219749882817268, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.478, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012945832684636116, 'eval_loss_2': 0.0022739171981811523, 'eval_loss_3': -18.190448760986328, 'eval_loss_4': -0.17887240648269653, 'epoch': 20.67}
{'loss': 0.0091, 'grad_norm': 5.497873306274414, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.008395928889513016, 'loss_2': 0.00070953369140625, 'loss_3': -16.50945281982422, 'loss_4': 0.24674615263938904, 'epoch': 20.67}
{'loss': 0.0088, 'grad_norm': 4.780813217163086, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.003578431671485305, 'loss_2': 0.0051727294921875, 'loss_3': -16.776594161987305, 'loss_4': 0.06297913193702698, 'epoch': 20.68}
{'loss': 0.0228, 'grad_norm': 9.246187210083008, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.017337899655103683, 'loss_2': 0.0054779052734375, 'loss_3': -16.436643600463867, 'loss_4': -0.06196850538253784, 'epoch': 20.69}
{'loss': 0.0115, 'grad_norm': 4.925535678863525, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.0046599549241364, 'loss_2': 0.006866455078125, 'loss_3': -16.31512451171875, 'loss_4': 0.20305734872817993, 'epoch': 20.69}
{'loss': 0.0055, 'grad_norm': 4.772664546966553, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.0046646613627672195, 'loss_2': 0.0008130073547363281, 'loss_3': -16.59956169128418, 'loss_4': 0.23682907223701477, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 13:48:37,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:37,174 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:27:56<27:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:48:44,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016298966482281685, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.475, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012878971174359322, 'eval_loss_2': 0.0034199953079223633, 'eval_loss_3': -18.190807342529297, 'eval_loss_4': -0.1316068023443222, 'epoch': 20.7}
{'loss': 0.0071, 'grad_norm': 4.879549980163574, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.00434853183105588, 'loss_2': 0.002750396728515625, 'loss_3': -16.432689666748047, 'loss_4': 0.4713177978992462, 'epoch': 20.7}
{'loss': 0.0222, 'grad_norm': 8.480998039245605, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.019459471106529236, 'loss_2': 0.002742767333984375, 'loss_3': -16.554519653320312, 'loss_4': 0.048547759652137756, 'epoch': 20.71}
{'loss': 0.0198, 'grad_norm': 13.606353759765625, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.01591545343399048, 'loss_2': 0.003917694091796875, 'loss_3': -16.432235717773438, 'loss_4': 0.07761391252279282, 'epoch': 20.72}
{'loss': 0.0085, 'grad_norm': 4.724959373474121, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.00356769235804677, 'loss_2': 0.00490570068359375, 'loss_3': -16.609161376953125, 'loss_4': -0.02967005968093872, 'epoch': 20.72}
{'loss': 0.0109, 'grad_norm': 4.879315376281738, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.005224965512752533, 'loss_2': 0.00563812255859375, 'loss_3': -16.438770294189453, 'loss_4': 0.3051396906375885, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 13:48:44,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:44,495 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:28:03<27:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:51,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016761386767029762, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.384, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012211146764457226, 'eval_loss_2': 0.004550240933895111, 'eval_loss_3': -18.196992874145508, 'eval_loss_4': -0.08186613023281097, 'epoch': 20.73}
{'loss': 0.0125, 'grad_norm': 4.87460994720459, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.007674256339669228, 'loss_2': 0.00482177734375, 'loss_3': -16.45736312866211, 'loss_4': 0.19558826088905334, 'epoch': 20.73}
{'loss': 0.0056, 'grad_norm': 4.556295394897461, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.0032153548672795296, 'loss_2': 0.0023651123046875, 'loss_3': -16.579124450683594, 'loss_4': -0.12373244762420654, 'epoch': 20.74}
{'loss': 0.0216, 'grad_norm': 7.254149913787842, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.015529250726103783, 'loss_2': 0.00609588623046875, 'loss_3': -16.334205627441406, 'loss_4': 0.030726775527000427, 'epoch': 20.74}
{'loss': 0.0121, 'grad_norm': 7.067645072937012, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.0107671357691288, 'loss_2': 0.0012874603271484375, 'loss_3': -16.581443786621094, 'loss_4': 0.22965118288993835, 'epoch': 20.75}
{'loss': 0.0409, 'grad_norm': 7.576923847198486, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.04009144753217697, 'loss_2': 0.0007925033569335938, 'loss_3': -16.562959671020508, 'loss_4': 0.4119046628475189, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 13:48:51,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:51,824 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:11<27:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:59,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017041005194187164, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.18, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012755637057125568, 'eval_loss_2': 0.004285365343093872, 'eval_loss_3': -18.205955505371094, 'eval_loss_4': -0.020420894026756287, 'epoch': 20.76}
{'loss': 0.0121, 'grad_norm': 4.864471912384033, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.006824110634624958, 'loss_2': 0.00528717041015625, 'loss_3': -16.591201782226562, 'loss_4': -0.13692313432693481, 'epoch': 20.76}
{'loss': 0.0039, 'grad_norm': 4.7928147315979, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.003488849848508835, 'loss_2': 0.0004067420959472656, 'loss_3': -16.72450065612793, 'loss_4': 0.48647189140319824, 'epoch': 20.77}
{'loss': 0.0108, 'grad_norm': 5.690049648284912, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.00948916282504797, 'loss_2': 0.0012826919555664062, 'loss_3': -16.54581069946289, 'loss_4': -0.008939236402511597, 'epoch': 20.77}
{'loss': 0.0119, 'grad_norm': 5.291843891143799, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.007257645018398762, 'loss_2': 0.004638671875, 'loss_3': -16.341716766357422, 'loss_4': 0.41631191968917847, 'epoch': 20.78}
{'loss': 0.0048, 'grad_norm': 4.856975555419922, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.003229868831112981, 'loss_2': 0.0015354156494140625, 'loss_3': -16.47916030883789, 'loss_4': 0.2556897699832916, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 13:48:59,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:59,154 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:18<27:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:06,480 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015685822814702988, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.994, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.012912276200950146, 'eval_loss_2': 0.0027735456824302673, 'eval_loss_3': -18.218177795410156, 'eval_loss_4': 0.07111334055662155, 'epoch': 20.78}
{'loss': 0.0087, 'grad_norm': 4.707194805145264, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.007370836567133665, 'loss_2': 0.0013427734375, 'loss_3': -16.449495315551758, 'loss_4': -0.10552816092967987, 'epoch': 20.79}
{'loss': 0.0132, 'grad_norm': 6.311648368835449, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.0103986244648695, 'loss_2': 0.002841949462890625, 'loss_3': -16.409820556640625, 'loss_4': -0.16839076578617096, 'epoch': 20.8}
{'loss': 0.014, 'grad_norm': 5.3093671798706055, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.010647672228515148, 'loss_2': 0.0033397674560546875, 'loss_3': -16.540666580200195, 'loss_4': 0.5074382424354553, 'epoch': 20.8}
{'loss': 0.0108, 'grad_norm': 5.632526874542236, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.008776895701885223, 'loss_2': 0.002033233642578125, 'loss_3': -16.403339385986328, 'loss_4': 0.4535031318664551, 'epoch': 20.81}
{'loss': 0.0089, 'grad_norm': 5.113270282745361, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.00558826420456171, 'loss_2': 0.003276824951171875, 'loss_3': -16.493806838989258, 'loss_4': 0.5862810015678406, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 13:49:06,480 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:06,480 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:25<27:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:13,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01569255068898201, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.833, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012856243178248405, 'eval_loss_2': 0.0028363093733787537, 'eval_loss_3': -18.22702407836914, 'eval_loss_4': 0.0870421975851059, 'epoch': 20.81}
{'loss': 0.016, 'grad_norm': 5.391104221343994, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.0068008447997272015, 'loss_2': 0.0091552734375, 'loss_3': -16.583759307861328, 'loss_4': 0.3765321969985962, 'epoch': 20.82}
{'loss': 0.0126, 'grad_norm': 5.1696553230285645, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.006559626664966345, 'loss_2': 0.00601959228515625, 'loss_3': -16.55790138244629, 'loss_4': 0.2048918902873993, 'epoch': 20.83}
{'loss': 0.0087, 'grad_norm': 4.7947845458984375, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.007633717730641365, 'loss_2': 0.0010738372802734375, 'loss_3': -16.670433044433594, 'loss_4': 0.15139912068843842, 'epoch': 20.83}
{'loss': 0.0153, 'grad_norm': 5.231053829193115, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.007901650853455067, 'loss_2': 0.007354736328125, 'loss_3': -16.378559112548828, 'loss_4': 0.048136740922927856, 'epoch': 20.84}
{'loss': 0.0087, 'grad_norm': 5.066593170166016, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.007270313799381256, 'loss_2': 0.0014057159423828125, 'loss_3': -16.605899810791016, 'loss_4': 0.4611111283302307, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 13:49:13,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:13,810 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:33<27:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:21,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01638904958963394, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.299, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012537574395537376, 'eval_loss_2': 0.003851473331451416, 'eval_loss_3': -18.2222900390625, 'eval_loss_4': 0.04876847565174103, 'epoch': 20.84}
{'loss': 0.0092, 'grad_norm': 4.897006988525391, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.003693012520670891, 'loss_2': 0.005527496337890625, 'loss_3': -16.54659080505371, 'loss_4': -0.14454910159111023, 'epoch': 20.85}
{'loss': 0.0082, 'grad_norm': 4.997814178466797, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.0071987551636993885, 'loss_2': 0.0010089874267578125, 'loss_3': -16.35605239868164, 'loss_4': 0.1341228485107422, 'epoch': 20.85}
{'loss': 0.0103, 'grad_norm': 5.2216339111328125, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.00565367192029953, 'loss_2': 0.004695892333984375, 'loss_3': -16.79680061340332, 'loss_4': -0.16296321153640747, 'epoch': 20.86}
{'loss': 0.0073, 'grad_norm': 4.958561420440674, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.006335563957691193, 'loss_2': 0.0009665489196777344, 'loss_3': -16.581687927246094, 'loss_4': 0.06437921524047852, 'epoch': 20.87}
{'loss': 0.0106, 'grad_norm': 4.834952354431152, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.003992057405412197, 'loss_2': 0.006622314453125, 'loss_3': -16.639446258544922, 'loss_4': -0.10997655987739563, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 13:49:21,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:21,132 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:40<26:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:28,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016503605991601944, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.369, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012520436197519302, 'eval_loss_2': 0.003983169794082642, 'eval_loss_3': -18.22304916381836, 'eval_loss_4': -0.0031062616035342216, 'epoch': 20.87}
{'loss': 0.0104, 'grad_norm': 5.386188983917236, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.009607105515897274, 'loss_2': 0.0008087158203125, 'loss_3': -16.495038986206055, 'loss_4': 0.416203111410141, 'epoch': 20.88}
{'loss': 0.0086, 'grad_norm': 4.676117420196533, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.004592602141201496, 'loss_2': 0.00396728515625, 'loss_3': -16.3745174407959, 'loss_4': -0.19300734996795654, 'epoch': 20.88}
{'loss': 0.0079, 'grad_norm': 5.061952114105225, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.006873365957289934, 'loss_2': 0.001033782958984375, 'loss_3': -16.493915557861328, 'loss_4': 0.506992757320404, 'epoch': 20.89}
{'loss': 0.0158, 'grad_norm': 5.762629985809326, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.013472579419612885, 'loss_2': 0.002353668212890625, 'loss_3': -16.352937698364258, 'loss_4': -0.026211492717266083, 'epoch': 20.9}
{'loss': 0.0099, 'grad_norm': 6.010106563568115, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.006206302437931299, 'loss_2': 0.0037384033203125, 'loss_3': -16.38994789123535, 'loss_4': 0.25435319542884827, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 13:49:28,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:28,448 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:47<26:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:35,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01500650867819786, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.28, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012621563859283924, 'eval_loss_2': 0.0023849457502365112, 'eval_loss_3': -18.22208023071289, 'eval_loss_4': -0.06713143736124039, 'epoch': 20.9}
{'loss': 0.0162, 'grad_norm': 5.386288166046143, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.006755141541361809, 'loss_2': 0.0094757080078125, 'loss_3': -16.505062103271484, 'loss_4': 0.6237962245941162, 'epoch': 20.91}
{'loss': 0.0165, 'grad_norm': 10.151514053344727, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.014637709595263004, 'loss_2': 0.0018558502197265625, 'loss_3': -16.564640045166016, 'loss_4': -0.08659395575523376, 'epoch': 20.91}
{'loss': 0.0133, 'grad_norm': 9.232643127441406, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.012762181460857391, 'loss_2': 0.0004949569702148438, 'loss_3': -16.524951934814453, 'loss_4': -0.14840608835220337, 'epoch': 20.92}
{'loss': 0.0108, 'grad_norm': 4.9791412353515625, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.008031484670937061, 'loss_2': 0.002788543701171875, 'loss_3': -16.547195434570312, 'loss_4': -0.04708780348300934, 'epoch': 20.92}
{'loss': 0.0106, 'grad_norm': 5.766654968261719, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.00793601106852293, 'loss_2': 0.0026798248291015625, 'loss_3': -16.355276107788086, 'loss_4': 0.42133933305740356, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 13:49:35,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:35,771 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:28:55<26:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:43,101 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014630729332566261, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.089, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.011805991642177105, 'eval_loss_2': 0.002824738621711731, 'eval_loss_3': -18.224742889404297, 'eval_loss_4': -0.04588354006409645, 'epoch': 20.93}
{'loss': 0.0111, 'grad_norm': 5.097997665405273, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.00714446883648634, 'loss_2': 0.00391387939453125, 'loss_3': -16.562294006347656, 'loss_4': 0.23622238636016846, 'epoch': 20.94}
{'loss': 0.0062, 'grad_norm': 4.252154350280762, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.004779942333698273, 'loss_2': 0.0013713836669921875, 'loss_3': -16.65426254272461, 'loss_4': 0.43536412715911865, 'epoch': 20.94}
{'loss': 0.0037, 'grad_norm': 4.436898231506348, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.0030644582584500313, 'loss_2': 0.0006093978881835938, 'loss_3': -16.588943481445312, 'loss_4': 0.18137545883655548, 'epoch': 20.95}
{'loss': 0.0054, 'grad_norm': 4.845203876495361, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.004789384081959724, 'loss_2': 0.0006022453308105469, 'loss_3': -16.590099334716797, 'loss_4': 0.13391715288162231, 'epoch': 20.95}
{'loss': 0.0162, 'grad_norm': 8.244649887084961, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.01537491288036108, 'loss_2': 0.0008258819580078125, 'loss_3': -16.047300338745117, 'loss_4': 0.07444234937429428, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 13:49:43,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:43,101 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:29:02<26:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:50,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014843545854091644, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.881, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.011703095398843288, 'eval_loss_2': 0.0031404495239257812, 'eval_loss_3': -18.229143142700195, 'eval_loss_4': -0.03367260843515396, 'epoch': 20.96}
{'loss': 0.0115, 'grad_norm': 5.801636695861816, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.010760887525975704, 'loss_2': 0.0007104873657226562, 'loss_3': -16.525964736938477, 'loss_4': -0.1050579696893692, 'epoch': 20.97}
{'loss': 0.011, 'grad_norm': 4.613375186920166, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.006528162397444248, 'loss_2': 0.0045013427734375, 'loss_3': -16.481712341308594, 'loss_4': -0.024654265493154526, 'epoch': 20.97}
{'loss': 0.0113, 'grad_norm': 6.151907444000244, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.008695966564118862, 'loss_2': 0.00261688232421875, 'loss_3': -16.343276977539062, 'loss_4': 0.19203029572963715, 'epoch': 20.98}
{'loss': 0.0149, 'grad_norm': 7.737890243530273, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.012013248167932034, 'loss_2': 0.002887725830078125, 'loss_3': -16.39082908630371, 'loss_4': 0.01783628761768341, 'epoch': 20.98}
{'loss': 0.0156, 'grad_norm': 4.728400230407715, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.007873858325183392, 'loss_2': 0.0077362060546875, 'loss_3': -16.401779174804688, 'loss_4': 0.39803677797317505, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 13:49:50,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:50,431 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:09<25:51,  1.00s/it][INFO|trainer.py:4226] 2025-01-21 13:49:57,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014576833695173264, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.357, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011935670860111713, 'eval_loss_2': 0.0026411637663841248, 'eval_loss_3': -18.2331485748291, 'eval_loss_4': -0.0031891129910945892, 'epoch': 20.99}
{'loss': 0.0176, 'grad_norm': 4.9431915283203125, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.006345111411064863, 'loss_2': 0.01129150390625, 'loss_3': -16.451801300048828, 'loss_4': 0.19187676906585693, 'epoch': 20.99}
{'loss': 0.0037, 'grad_norm': 5.778232574462891, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.0024131860118359327, 'loss_2': 0.00128173828125, 'loss_3': -16.527189254760742, 'loss_4': 0.6660800576210022, 'epoch': 21.0}
{'loss': 0.0095, 'grad_norm': 4.592083930969238, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.005763656925410032, 'loss_2': 0.0037670135498046875, 'loss_3': -16.54092025756836, 'loss_4': 0.6974125504493713, 'epoch': 21.01}
{'loss': 0.0192, 'grad_norm': 10.767890930175781, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.01871609501540661, 'loss_2': 0.00046825408935546875, 'loss_3': -16.61466407775879, 'loss_4': 0.07398585230112076, 'epoch': 21.01}
{'loss': 0.0091, 'grad_norm': 4.3969197273254395, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.00554920407012105, 'loss_2': 0.0035266876220703125, 'loss_3': -16.51822280883789, 'loss_4': 0.09447143226861954, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 13:49:57,438 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:57,438 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:16<26:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:50:04,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01580634154379368, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.351, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012629576958715916, 'eval_loss_2': 0.003176763653755188, 'eval_loss_3': -18.226408004760742, 'eval_loss_4': 0.019766952842473984, 'epoch': 21.02}
{'loss': 0.0087, 'grad_norm': 5.397564888000488, 'learning_rate': 9e-06, 'loss_1': 0.006319505162537098, 'loss_2': 0.002407073974609375, 'loss_3': -16.43244171142578, 'loss_4': 0.5704265832901001, 'epoch': 21.02}
{'loss': 0.0115, 'grad_norm': 4.609602928161621, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.0044366586953401566, 'loss_2': 0.00702667236328125, 'loss_3': -16.64624786376953, 'loss_4': 0.4653305113315582, 'epoch': 21.03}
{'loss': 0.0119, 'grad_norm': 6.690392971038818, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.009973565116524696, 'loss_2': 0.0018987655639648438, 'loss_3': -16.56458854675293, 'loss_4': 0.38494744896888733, 'epoch': 21.03}
{'loss': 0.0161, 'grad_norm': 5.445873737335205, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.009513923898339272, 'loss_2': 0.0065460205078125, 'loss_3': -16.344545364379883, 'loss_4': 0.9392164349555969, 'epoch': 21.04}
{'loss': 0.0119, 'grad_norm': 5.545021057128906, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.008735300041735172, 'loss_2': 0.0031795501708984375, 'loss_3': -16.46941566467285, 'loss_4': 0.3427692651748657, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 13:50:04,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:04,757 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:24<26:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:50:12,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016796568408608437, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.505, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.013752858154475689, 'eval_loss_2': 0.0030437111854553223, 'eval_loss_3': -18.228214263916016, 'eval_loss_4': 0.016157329082489014, 'epoch': 21.05}
{'loss': 0.0067, 'grad_norm': 4.9290289878845215, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.005160203203558922, 'loss_2': 0.0015821456909179688, 'loss_3': -16.44839096069336, 'loss_4': 0.4588336944580078, 'epoch': 21.05}
{'loss': 0.0174, 'grad_norm': 6.427279949188232, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.011762861162424088, 'loss_2': 0.0056610107421875, 'loss_3': -16.601852416992188, 'loss_4': 0.20906955003738403, 'epoch': 21.06}
{'loss': 0.0075, 'grad_norm': 5.0611491203308105, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.0061395904049277306, 'loss_2': 0.0013256072998046875, 'loss_3': -16.58877944946289, 'loss_4': 0.2943890392780304, 'epoch': 21.06}
{'loss': 0.019, 'grad_norm': 5.403926849365234, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.007255828473716974, 'loss_2': 0.01171112060546875, 'loss_3': -16.52566909790039, 'loss_4': 0.0865333080291748, 'epoch': 21.07}
{'loss': 0.0053, 'grad_norm': 5.5330095291137695, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.004548044875264168, 'loss_2': 0.0007228851318359375, 'loss_3': -16.469158172607422, 'loss_4': 0.21840113401412964, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 13:50:12,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:12,082 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:31<26:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:50:19,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016897348687052727, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.13, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013915388844907284, 'eval_loss_2': 0.0029819607734680176, 'eval_loss_3': -18.231815338134766, 'eval_loss_4': 0.00531198363751173, 'epoch': 21.08}
{'loss': 0.007, 'grad_norm': 4.842190265655518, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.006593002006411552, 'loss_2': 0.0003826618194580078, 'loss_3': -16.50352668762207, 'loss_4': 0.5544296503067017, 'epoch': 21.08}
{'loss': 0.0172, 'grad_norm': 5.961043834686279, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.011553077027201653, 'loss_2': 0.00560760498046875, 'loss_3': -16.43171501159668, 'loss_4': 0.14903604984283447, 'epoch': 21.09}
{'loss': 0.0195, 'grad_norm': 9.25949764251709, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.016155485063791275, 'loss_2': 0.003360748291015625, 'loss_3': -16.49412727355957, 'loss_4': 0.34949231147766113, 'epoch': 21.09}
{'loss': 0.0113, 'grad_norm': 5.544895648956299, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.010321520268917084, 'loss_2': 0.000949859619140625, 'loss_3': -16.618349075317383, 'loss_4': 0.2619766294956207, 'epoch': 21.1}
{'loss': 0.0111, 'grad_norm': 5.707390308380127, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.005975348874926567, 'loss_2': 0.0051727294921875, 'loss_3': -16.463396072387695, 'loss_4': 0.3342069983482361, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 13:50:19,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:19,402 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:38<26:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:26,730 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017160233110189438, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.188, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013822916895151138, 'eval_loss_2': 0.0033373162150382996, 'eval_loss_3': -18.229204177856445, 'eval_loss_4': -0.029327120631933212, 'epoch': 21.1}
{'loss': 0.0121, 'grad_norm': 4.820207118988037, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.006567373871803284, 'loss_2': 0.00548553466796875, 'loss_3': -16.437911987304688, 'loss_4': 0.05680590495467186, 'epoch': 21.11}
{'loss': 0.0228, 'grad_norm': 9.454565048217773, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.016829680651426315, 'loss_2': 0.00597381591796875, 'loss_3': -16.43065643310547, 'loss_4': 0.0029425472021102905, 'epoch': 21.12}
{'loss': 0.0128, 'grad_norm': 5.922811985015869, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.009856721386313438, 'loss_2': 0.0029163360595703125, 'loss_3': -16.42096710205078, 'loss_4': 0.3634282350540161, 'epoch': 21.12}
{'loss': 0.0069, 'grad_norm': 4.9359259605407715, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.006531727034598589, 'loss_2': 0.0003337860107421875, 'loss_3': -16.37950325012207, 'loss_4': 0.21984286606311798, 'epoch': 21.13}
{'loss': 0.003, 'grad_norm': 4.499434947967529, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.002988118212670088, 'loss_2': 3.4570693969726562e-06, 'loss_3': -16.655546188354492, 'loss_4': 0.0454801544547081, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 13:50:26,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:26,730 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:46<26:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:34,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01861945167183876, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.35, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01478345412760973, 'eval_loss_2': 0.0038359984755516052, 'eval_loss_3': -18.223918914794922, 'eval_loss_4': 0.004656498786062002, 'epoch': 21.13}
{'loss': 0.0102, 'grad_norm': 4.90005350112915, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.005054346285760403, 'loss_2': 0.005161285400390625, 'loss_3': -16.48349380493164, 'loss_4': 0.7098392248153687, 'epoch': 21.14}
{'loss': 0.0071, 'grad_norm': 4.10897159576416, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.005210482981055975, 'loss_2': 0.0018978118896484375, 'loss_3': -16.455890655517578, 'loss_4': -0.012876197695732117, 'epoch': 21.15}
{'loss': 0.0099, 'grad_norm': 5.692644119262695, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.008993862196803093, 'loss_2': 0.0009222030639648438, 'loss_3': -16.34613800048828, 'loss_4': 0.4683956205844879, 'epoch': 21.15}
{'loss': 0.0078, 'grad_norm': 4.643298625946045, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.004079975187778473, 'loss_2': 0.00374603271484375, 'loss_3': -16.572050094604492, 'loss_4': 0.8319313526153564, 'epoch': 21.16}
{'loss': 0.0082, 'grad_norm': 4.353156089782715, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.005550752859562635, 'loss_2': 0.00264739990234375, 'loss_3': -16.56116485595703, 'loss_4': 0.2102179378271103, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 13:50:34,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:34,055 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:29:53<26:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:41,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01691013015806675, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.506, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01363418996334076, 'eval_loss_2': 0.003275938332080841, 'eval_loss_3': -18.224191665649414, 'eval_loss_4': 0.05434168502688408, 'epoch': 21.16}
{'loss': 0.0071, 'grad_norm': 14.748799324035645, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.003297565970569849, 'loss_2': 0.00376129150390625, 'loss_3': -16.441465377807617, 'loss_4': 0.4277186691761017, 'epoch': 21.17}
{'loss': 0.0186, 'grad_norm': 11.439742088317871, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.0153458621352911, 'loss_2': 0.0032100677490234375, 'loss_3': -16.498815536499023, 'loss_4': -0.19284749031066895, 'epoch': 21.17}
{'loss': 0.0169, 'grad_norm': 5.124603271484375, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.003748904215171933, 'loss_2': 0.013153076171875, 'loss_3': -16.56205940246582, 'loss_4': 0.48041245341300964, 'epoch': 21.18}
{'loss': 0.0104, 'grad_norm': 6.188324928283691, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.009413070045411587, 'loss_2': 0.0010023117065429688, 'loss_3': -16.43507194519043, 'loss_4': 0.5029666423797607, 'epoch': 21.19}
{'loss': 0.0096, 'grad_norm': 5.020273685455322, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.007328068371862173, 'loss_2': 0.002288818359375, 'loss_3': -16.59371566772461, 'loss_4': 0.647867739200592, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 13:50:41,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:41,385 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:00<26:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:50:48,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017974214628338814, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.437, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013825997710227966, 'eval_loss_2': 0.004148215055465698, 'eval_loss_3': -18.221317291259766, 'eval_loss_4': 0.1500919610261917, 'epoch': 21.19}
{'loss': 0.0087, 'grad_norm': 5.877594470977783, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.00815463438630104, 'loss_2': 0.0005230903625488281, 'loss_3': -16.564207077026367, 'loss_4': 0.5224485397338867, 'epoch': 21.2}
{'loss': 0.0102, 'grad_norm': 5.085090160369873, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.006483874749392271, 'loss_2': 0.003753662109375, 'loss_3': -16.274972915649414, 'loss_4': 0.414081871509552, 'epoch': 21.2}
{'loss': 0.0307, 'grad_norm': 6.968219757080078, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.029510360211133957, 'loss_2': 0.0012187957763671875, 'loss_3': -16.233661651611328, 'loss_4': 0.5669993162155151, 'epoch': 21.21}
{'loss': 0.006, 'grad_norm': 5.027768611907959, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.004860636778175831, 'loss_2': 0.0011615753173828125, 'loss_3': -16.506629943847656, 'loss_4': 0.37439852952957153, 'epoch': 21.22}
{'loss': 0.0141, 'grad_norm': 4.965515613555908, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.0059944819658994675, 'loss_2': 0.00807952880859375, 'loss_3': -16.647249221801758, 'loss_4': 0.3861861228942871, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 13:50:48,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:48,707 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:08<25:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:50:56,029 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017828503623604774, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.688, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.013962873257696629, 'eval_loss_2': 0.0038656294345855713, 'eval_loss_3': -18.230911254882812, 'eval_loss_4': 0.23325583338737488, 'epoch': 21.22}
{'loss': 0.0084, 'grad_norm': 4.597877025604248, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.007286763750016689, 'loss_2': 0.0010833740234375, 'loss_3': -16.437843322753906, 'loss_4': 0.34549427032470703, 'epoch': 21.23}
{'loss': 0.013, 'grad_norm': 4.700785160064697, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.006206213030964136, 'loss_2': 0.00679779052734375, 'loss_3': -16.36005973815918, 'loss_4': 0.9130138754844666, 'epoch': 21.23}
{'loss': 0.004, 'grad_norm': 4.511102676391602, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.003965354058891535, 'loss_2': 2.7954578399658203e-05, 'loss_3': -16.50641441345215, 'loss_4': 0.001243937760591507, 'epoch': 21.24}
{'loss': 0.0106, 'grad_norm': 5.4199018478393555, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.009786284528672695, 'loss_2': 0.0008006095886230469, 'loss_3': -16.62750244140625, 'loss_4': 0.11719582229852676, 'epoch': 21.24}
{'loss': 0.0177, 'grad_norm': 7.889047622680664, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.01449675764888525, 'loss_2': 0.0032501220703125, 'loss_3': -16.510705947875977, 'loss_4': 0.8277648091316223, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 13:50:56,029 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:56,029 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:15<25:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:51:03,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01756051741540432, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.337, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014227493666112423, 'eval_loss_2': 0.0033330246806144714, 'eval_loss_3': -18.224271774291992, 'eval_loss_4': 0.28003108501434326, 'epoch': 21.25}
{'loss': 0.0093, 'grad_norm': 4.881734848022461, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.005399421788752079, 'loss_2': 0.00394439697265625, 'loss_3': -16.655231475830078, 'loss_4': 0.2992187738418579, 'epoch': 21.26}
{'loss': 0.0107, 'grad_norm': 4.374114990234375, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.003568527987226844, 'loss_2': 0.00714111328125, 'loss_3': -16.374441146850586, 'loss_4': 0.4171484112739563, 'epoch': 21.26}
{'loss': 0.0089, 'grad_norm': 4.655345916748047, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.003915474284440279, 'loss_2': 0.0049896240234375, 'loss_3': -16.54380989074707, 'loss_4': 0.3605876564979553, 'epoch': 21.27}
{'loss': 0.0102, 'grad_norm': 5.512474060058594, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.006876641418784857, 'loss_2': 0.003314971923828125, 'loss_3': -16.448139190673828, 'loss_4': 0.26589658856391907, 'epoch': 21.27}
{'loss': 0.0161, 'grad_norm': 10.245863914489746, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.014475301839411259, 'loss_2': 0.001621246337890625, 'loss_3': -16.501590728759766, 'loss_4': 1.104002833366394, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 13:51:03,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:03,352 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:22<25:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:51:10,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017103902995586395, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.7, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013579660095274448, 'eval_loss_2': 0.0035242438316345215, 'eval_loss_3': -18.227418899536133, 'eval_loss_4': 0.32776448130607605, 'epoch': 21.28}
{'loss': 0.0052, 'grad_norm': 4.640918254852295, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.005050040315836668, 'loss_2': 0.00015211105346679688, 'loss_3': -16.48278045654297, 'loss_4': 0.37675410509109497, 'epoch': 21.28}
{'loss': 0.0216, 'grad_norm': 6.641453742980957, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.016093168407678604, 'loss_2': 0.0054779052734375, 'loss_3': -16.352458953857422, 'loss_4': 1.0672430992126465, 'epoch': 21.29}
{'loss': 0.0072, 'grad_norm': 4.802224636077881, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.004133317619562149, 'loss_2': 0.0030517578125, 'loss_3': -16.52977752685547, 'loss_4': 0.4325842261314392, 'epoch': 21.3}
{'loss': 0.0068, 'grad_norm': 4.6836981773376465, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.004837799817323685, 'loss_2': 0.0019245147705078125, 'loss_3': -16.377376556396484, 'loss_4': 1.1134811639785767, 'epoch': 21.3}
{'loss': 0.0068, 'grad_norm': 5.106268882751465, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.0046558985486626625, 'loss_2': 0.002101898193359375, 'loss_3': -16.47469711303711, 'loss_4': 1.1042706966400146, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 13:51:10,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:10,679 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:29<25:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:51:18,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018277427181601524, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.288, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.014930151402950287, 'eval_loss_2': 0.0033472776412963867, 'eval_loss_3': -18.228666305541992, 'eval_loss_4': 0.4535059630870819, 'epoch': 21.31}
{'loss': 0.0129, 'grad_norm': 6.924476623535156, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.009127584286034107, 'loss_2': 0.003726959228515625, 'loss_3': -16.47842788696289, 'loss_4': 0.5616863369941711, 'epoch': 21.31}
{'loss': 0.009, 'grad_norm': 5.241875648498535, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.005854395683854818, 'loss_2': 0.003139495849609375, 'loss_3': -16.569284439086914, 'loss_4': 0.8629106283187866, 'epoch': 21.32}
{'loss': 0.0116, 'grad_norm': 4.592777252197266, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.004994086921215057, 'loss_2': 0.0066375732421875, 'loss_3': -16.416122436523438, 'loss_4': 0.3554607927799225, 'epoch': 21.33}
{'loss': 0.0089, 'grad_norm': 5.9121928215026855, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.007232372183352709, 'loss_2': 0.0016231536865234375, 'loss_3': -16.43313980102539, 'loss_4': 0.4882398843765259, 'epoch': 21.33}
{'loss': 0.0074, 'grad_norm': 5.492632865905762, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.007409634068608284, 'loss_2': 1.0967254638671875e-05, 'loss_3': -16.403156280517578, 'loss_4': 0.8876618146896362, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 13:51:18,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:18,002 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:37<25:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:25,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017194638028740883, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.276, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013844143599271774, 'eval_loss_2': 0.003350496292114258, 'eval_loss_3': -18.218830108642578, 'eval_loss_4': 0.5593125820159912, 'epoch': 21.34}
{'loss': 0.0123, 'grad_norm': 5.852023601531982, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.009690120816230774, 'loss_2': 0.00264739990234375, 'loss_3': -16.42809295654297, 'loss_4': 1.1360223293304443, 'epoch': 21.34}
{'loss': 0.0099, 'grad_norm': 4.746576309204102, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.005601434502750635, 'loss_2': 0.004253387451171875, 'loss_3': -16.491056442260742, 'loss_4': 0.693108081817627, 'epoch': 21.35}
{'loss': 0.0093, 'grad_norm': 4.991951942443848, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.006250905338674784, 'loss_2': 0.0030670166015625, 'loss_3': -16.3688907623291, 'loss_4': 0.7124459147453308, 'epoch': 21.35}
{'loss': 0.0091, 'grad_norm': 5.309136867523193, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.005604630336165428, 'loss_2': 0.0034618377685546875, 'loss_3': -16.50326919555664, 'loss_4': 0.9916394352912903, 'epoch': 21.36}
{'loss': 0.0081, 'grad_norm': 4.90687370300293, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.006025591865181923, 'loss_2': 0.0020427703857421875, 'loss_3': -16.351642608642578, 'loss_4': 1.2620577812194824, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 13:51:25,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:25,330 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:44<25:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:32,657 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01796700619161129, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.406, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.014296448789536953, 'eval_loss_2': 0.0036705583333969116, 'eval_loss_3': -18.216211318969727, 'eval_loss_4': 0.5744286179542542, 'epoch': 21.37}
{'loss': 0.0124, 'grad_norm': 5.251992702484131, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.009134192019701004, 'loss_2': 0.003292083740234375, 'loss_3': -16.56101417541504, 'loss_4': 0.7775793075561523, 'epoch': 21.37}
{'loss': 0.0057, 'grad_norm': 4.591742038726807, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.004722982179373503, 'loss_2': 0.0009918212890625, 'loss_3': -16.43152618408203, 'loss_4': 0.889445424079895, 'epoch': 21.38}
{'loss': 0.0234, 'grad_norm': 9.471094131469727, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.022296195849776268, 'loss_2': 0.0010662078857421875, 'loss_3': -16.829566955566406, 'loss_4': 1.2600443363189697, 'epoch': 21.38}
{'loss': 0.0086, 'grad_norm': 4.074735641479492, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.0038467596750706434, 'loss_2': 0.00478363037109375, 'loss_3': -16.466693878173828, 'loss_4': 0.8708484172821045, 'epoch': 21.39}
{'loss': 0.0115, 'grad_norm': 4.385041236877441, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.0077872066758573055, 'loss_2': 0.003681182861328125, 'loss_3': -16.314590454101562, 'loss_4': 1.212220311164856, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 13:51:32,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:32,658 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:30:51<25:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:39,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018286699429154396, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.29, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.014393678866326809, 'eval_loss_2': 0.0038930177688598633, 'eval_loss_3': -18.20365333557129, 'eval_loss_4': 0.5047967433929443, 'epoch': 21.4}
{'loss': 0.0057, 'grad_norm': 5.034958362579346, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.00520299980416894, 'loss_2': 0.0005035400390625, 'loss_3': -16.61258316040039, 'loss_4': 0.9308719635009766, 'epoch': 21.4}
{'loss': 0.0127, 'grad_norm': 5.6671857833862305, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.011646129190921783, 'loss_2': 0.0010366439819335938, 'loss_3': -16.352949142456055, 'loss_4': 0.8357839584350586, 'epoch': 21.41}
{'loss': 0.038, 'grad_norm': 14.360075950622559, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.03741735965013504, 'loss_2': 0.0005831718444824219, 'loss_3': -16.541908264160156, 'loss_4': 1.0805338621139526, 'epoch': 21.41}
{'loss': 0.029, 'grad_norm': 10.475512504577637, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.02768145501613617, 'loss_2': 0.00136566162109375, 'loss_3': -16.47517967224121, 'loss_4': 0.31772640347480774, 'epoch': 21.42}
{'loss': 0.025, 'grad_norm': 16.612699508666992, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.023936541751027107, 'loss_2': 0.001071929931640625, 'loss_3': -16.482769012451172, 'loss_4': 0.8742461800575256, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 13:51:39,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:39,985 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:30:59<25:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:47,312 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01861356571316719, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.023, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014627743512392044, 'eval_loss_2': 0.0039858222007751465, 'eval_loss_3': -18.205917358398438, 'eval_loss_4': 0.397028386592865, 'epoch': 21.42}
{'loss': 0.0137, 'grad_norm': 4.5402703285217285, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.006979973986744881, 'loss_2': 0.00667572021484375, 'loss_3': -16.58768081665039, 'loss_4': 1.2621827125549316, 'epoch': 21.43}
{'loss': 0.0208, 'grad_norm': 10.350181579589844, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.015750713646411896, 'loss_2': 0.005031585693359375, 'loss_3': -16.448572158813477, 'loss_4': 0.7340918779373169, 'epoch': 21.44}
{'loss': 0.0199, 'grad_norm': 8.296613693237305, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.013215141370892525, 'loss_2': 0.00666046142578125, 'loss_3': -16.373809814453125, 'loss_4': 0.570559561252594, 'epoch': 21.44}
{'loss': 0.0074, 'grad_norm': 4.773221969604492, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.007135686930269003, 'loss_2': 0.000255584716796875, 'loss_3': -16.44391632080078, 'loss_4': 0.42786937952041626, 'epoch': 21.45}
{'loss': 0.0167, 'grad_norm': 5.1623053550720215, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.009315592236816883, 'loss_2': 0.007404327392578125, 'loss_3': -16.524982452392578, 'loss_4': 0.6577913165092468, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 13:51:47,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:47,312 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:31:06<25:16,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:51:54,640 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0178412813693285, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.101, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013311329297721386, 'eval_loss_2': 0.0045299530029296875, 'eval_loss_3': -18.181060791015625, 'eval_loss_4': 0.2784273624420166, 'epoch': 21.45}
{'loss': 0.0317, 'grad_norm': 13.554856300354004, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.02926367148756981, 'loss_2': 0.002414703369140625, 'loss_3': -16.452945709228516, 'loss_4': 0.7812995314598083, 'epoch': 21.46}
{'loss': 0.0209, 'grad_norm': 6.565183639526367, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.010179886594414711, 'loss_2': 0.01068115234375, 'loss_3': -16.49456787109375, 'loss_4': 0.7067327499389648, 'epoch': 21.47}
{'loss': 0.0119, 'grad_norm': 5.917728900909424, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.007158196531236172, 'loss_2': 0.00470733642578125, 'loss_3': -16.569791793823242, 'loss_4': 0.4779735505580902, 'epoch': 21.47}
{'loss': 0.0089, 'grad_norm': 5.6346211433410645, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.007932135835289955, 'loss_2': 0.0009365081787109375, 'loss_3': -16.504596710205078, 'loss_4': 0.24212300777435303, 'epoch': 21.48}
{'loss': 0.0179, 'grad_norm': 5.084869861602783, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.016219250857830048, 'loss_2': 0.0016889572143554688, 'loss_3': -16.614870071411133, 'loss_4': 0.5647657513618469, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 13:51:54,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:54,640 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:13<25:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:52:01,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018340691924095154, 'eval_runtime': 3.7867, 'eval_samples_per_second': 270.423, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013249319978058338, 'eval_loss_2': 0.005091369152069092, 'eval_loss_3': -18.188915252685547, 'eval_loss_4': 0.24790021777153015, 'epoch': 21.48}
{'loss': 0.0098, 'grad_norm': 5.342968940734863, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.005998548585921526, 'loss_2': 0.0037994384765625, 'loss_3': -16.61837387084961, 'loss_4': 0.601940393447876, 'epoch': 21.49}
{'loss': 0.021, 'grad_norm': 6.451567649841309, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.011382018215954304, 'loss_2': 0.0096282958984375, 'loss_3': -16.444698333740234, 'loss_4': 0.7403987050056458, 'epoch': 21.49}
{'loss': 0.0046, 'grad_norm': 4.915372371673584, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0027566079515963793, 'loss_2': 0.00188446044921875, 'loss_3': -16.512596130371094, 'loss_4': 0.36871859431266785, 'epoch': 21.5}
{'loss': 0.0048, 'grad_norm': 4.413498401641846, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.002553995233029127, 'loss_2': 0.002216339111328125, 'loss_3': -16.546131134033203, 'loss_4': 0.3477138876914978, 'epoch': 21.51}
{'loss': 0.0111, 'grad_norm': 5.218782901763916, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.00430485513061285, 'loss_2': 0.00682830810546875, 'loss_3': -16.430362701416016, 'loss_4': 0.021713130176067352, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 13:52:01,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:01,954 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:21<25:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:52:09,281 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017955444753170013, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.233, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012571177445352077, 'eval_loss_2': 0.005384266376495361, 'eval_loss_3': -18.195022583007812, 'eval_loss_4': 0.2062707245349884, 'epoch': 21.51}
{'loss': 0.0072, 'grad_norm': 5.136753082275391, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.0043818149715662, 'loss_2': 0.002780914306640625, 'loss_3': -16.5654354095459, 'loss_4': 0.4894091486930847, 'epoch': 21.52}
{'loss': 0.0073, 'grad_norm': 5.666374206542969, 'learning_rate': 8.5e-06, 'loss_1': 0.004844223149120808, 'loss_2': 0.0024967193603515625, 'loss_3': -16.722923278808594, 'loss_4': 0.6284372806549072, 'epoch': 21.52}
{'loss': 0.0047, 'grad_norm': 4.806339263916016, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.004648248199373484, 'loss_2': 6.67572021484375e-06, 'loss_3': -16.552894592285156, 'loss_4': 0.6733192205429077, 'epoch': 21.53}
{'loss': 0.0121, 'grad_norm': 5.051627159118652, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.006695709656924009, 'loss_2': 0.005401611328125, 'loss_3': -16.60342788696289, 'loss_4': 0.6534792184829712, 'epoch': 21.53}
{'loss': 0.0085, 'grad_norm': 4.799681186676025, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.004560707602649927, 'loss_2': 0.003936767578125, 'loss_3': -16.584932327270508, 'loss_4': 0.4273959696292877, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 13:52:09,281 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:09,282 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:28<25:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:16,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016660258173942566, 'eval_runtime': 3.7838, 'eval_samples_per_second': 270.63, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.012456014752388, 'eval_loss_2': 0.004204243421554565, 'eval_loss_3': -18.194908142089844, 'eval_loss_4': 0.12908092141151428, 'epoch': 21.54}
{'loss': 0.007, 'grad_norm': 5.54593563079834, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.006199698429554701, 'loss_2': 0.0008249282836914062, 'loss_3': -16.39227294921875, 'loss_4': 0.27835744619369507, 'epoch': 21.55}
{'loss': 0.0084, 'grad_norm': 5.198812484741211, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.005213395692408085, 'loss_2': 0.003154754638671875, 'loss_3': -16.275917053222656, 'loss_4': 0.2279670685529709, 'epoch': 21.55}
{'loss': 0.0074, 'grad_norm': 4.933353900909424, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.00409516878426075, 'loss_2': 0.0032787322998046875, 'loss_3': -16.486831665039062, 'loss_4': 0.19893410801887512, 'epoch': 21.56}
{'loss': 0.0092, 'grad_norm': 5.4679646492004395, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.006654303055256605, 'loss_2': 0.0024967193603515625, 'loss_3': -16.660018920898438, 'loss_4': 0.1397131383419037, 'epoch': 21.56}
{'loss': 0.0127, 'grad_norm': 5.603182315826416, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.008259101770818233, 'loss_2': 0.004482269287109375, 'loss_3': -16.306110382080078, 'loss_4': 0.7102925777435303, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 13:52:16,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:16,606 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:35<24:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:23,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01630600169301033, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.793, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012151699513196945, 'eval_loss_2': 0.004154302179813385, 'eval_loss_3': -18.185413360595703, 'eval_loss_4': 0.08222374320030212, 'epoch': 21.57}
{'loss': 0.009, 'grad_norm': 4.367667198181152, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.0061089773662388325, 'loss_2': 0.002849578857421875, 'loss_3': -16.31221580505371, 'loss_4': 0.6065322160720825, 'epoch': 21.58}
{'loss': 0.0145, 'grad_norm': 8.444961547851562, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.013501178473234177, 'loss_2': 0.0009698867797851562, 'loss_3': -16.498096466064453, 'loss_4': 0.5565646886825562, 'epoch': 21.58}
{'loss': 0.0054, 'grad_norm': 4.646949768066406, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.005218230187892914, 'loss_2': 0.0001938343048095703, 'loss_3': -16.51171875, 'loss_4': 0.3523063063621521, 'epoch': 21.59}
{'loss': 0.0159, 'grad_norm': 8.324566841125488, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.012351898476481438, 'loss_2': 0.0035037994384765625, 'loss_3': -16.407644271850586, 'loss_4': 0.6507523059844971, 'epoch': 21.59}
{'loss': 0.0267, 'grad_norm': 23.71074867248535, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.02560630813241005, 'loss_2': 0.0011043548583984375, 'loss_3': -16.31275749206543, 'loss_4': 0.7842588424682617, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 13:52:23,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:23,937 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:43<24:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:52:31,264 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017083417624235153, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.904, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.012741157785058022, 'eval_loss_2': 0.004342257976531982, 'eval_loss_3': -18.186954498291016, 'eval_loss_4': 0.06575216352939606, 'epoch': 21.6}
{'loss': 0.0539, 'grad_norm': 10.275835990905762, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.04611179605126381, 'loss_2': 0.00775146484375, 'loss_3': -16.513587951660156, 'loss_4': -0.12178900837898254, 'epoch': 21.6}
{'loss': 0.008, 'grad_norm': 4.744745254516602, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.004548324272036552, 'loss_2': 0.0034027099609375, 'loss_3': -16.651981353759766, 'loss_4': 0.01495564728975296, 'epoch': 21.61}
{'loss': 0.0085, 'grad_norm': 4.464751243591309, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.0029815188609063625, 'loss_2': 0.005474090576171875, 'loss_3': -16.462196350097656, 'loss_4': -0.04367918521165848, 'epoch': 21.62}
{'loss': 0.0115, 'grad_norm': 5.690117835998535, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.008805026300251484, 'loss_2': 0.0027256011962890625, 'loss_3': -16.441986083984375, 'loss_4': -0.13423649966716766, 'epoch': 21.62}
{'loss': 0.0098, 'grad_norm': 4.856998920440674, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.005386729259043932, 'loss_2': 0.0044403076171875, 'loss_3': -16.56352996826172, 'loss_4': 0.08726407587528229, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 13:52:31,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:31,264 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:31:50<24:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:52:38,577 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01705235242843628, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.457, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013190983794629574, 'eval_loss_2': 0.003861367702484131, 'eval_loss_3': -18.17136001586914, 'eval_loss_4': 0.11489982157945633, 'epoch': 21.63}
{'loss': 0.0185, 'grad_norm': 5.686454772949219, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.011390017345547676, 'loss_2': 0.00714874267578125, 'loss_3': -16.270034790039062, 'loss_4': 0.31134408712387085, 'epoch': 21.63}
{'loss': 0.0126, 'grad_norm': 6.681544303894043, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.008784606121480465, 'loss_2': 0.00384521484375, 'loss_3': -16.458688735961914, 'loss_4': 0.26594820618629456, 'epoch': 21.64}
{'loss': 0.0138, 'grad_norm': 4.904726505279541, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.008196868002414703, 'loss_2': 0.005580902099609375, 'loss_3': -16.407981872558594, 'loss_4': 0.5456241369247437, 'epoch': 21.65}
{'loss': 0.0113, 'grad_norm': 5.217950820922852, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.008876414969563484, 'loss_2': 0.002468109130859375, 'loss_3': -16.474384307861328, 'loss_4': 0.30857327580451965, 'epoch': 21.65}
{'loss': 0.0137, 'grad_norm': 5.499969959259033, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.008398250676691532, 'loss_2': 0.005313873291015625, 'loss_3': -16.385784149169922, 'loss_4': 0.6877592206001282, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 13:52:38,577 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:38,577 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:31:57<24:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:52:45,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016945842653512955, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.106, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012868273071944714, 'eval_loss_2': 0.0040775686502456665, 'eval_loss_3': -18.170942306518555, 'eval_loss_4': 0.13553689420223236, 'epoch': 21.66}
{'loss': 0.0149, 'grad_norm': 7.948785781860352, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.013604647479951382, 'loss_2': 0.00128173828125, 'loss_3': -16.47976303100586, 'loss_4': 0.23124244809150696, 'epoch': 21.66}
{'loss': 0.0049, 'grad_norm': 4.786484241485596, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.003479840699583292, 'loss_2': 0.0014562606811523438, 'loss_3': -16.513395309448242, 'loss_4': 0.22368818521499634, 'epoch': 21.67}
{'loss': 0.0143, 'grad_norm': 5.266748428344727, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.00845780037343502, 'loss_2': 0.00586700439453125, 'loss_3': -16.393789291381836, 'loss_4': 0.11972922086715698, 'epoch': 21.67}
{'loss': 0.0144, 'grad_norm': 5.024571418762207, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.005107649136334658, 'loss_2': 0.00933074951171875, 'loss_3': -16.456344604492188, 'loss_4': 0.29712775349617004, 'epoch': 21.68}
{'loss': 0.0094, 'grad_norm': 5.550543308258057, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.006623807363212109, 'loss_2': 0.002796173095703125, 'loss_3': -16.4114990234375, 'loss_4': 0.5023381114006042, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 13:52:45,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:45,905 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:32:05<24:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:52:53,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01882217451930046, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.442, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012238961644470692, 'eval_loss_2': 0.006583213806152344, 'eval_loss_3': -18.179752349853516, 'eval_loss_4': 0.1719847023487091, 'epoch': 21.69}
{'loss': 0.0137, 'grad_norm': 4.629765033721924, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.004038046579807997, 'loss_2': 0.0096588134765625, 'loss_3': -16.67000389099121, 'loss_4': 0.5021624565124512, 'epoch': 21.69}
{'loss': 0.0094, 'grad_norm': 4.777956008911133, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.005909757222980261, 'loss_2': 0.00347900390625, 'loss_3': -16.383220672607422, 'loss_4': 0.3163299262523651, 'epoch': 21.7}
{'loss': 0.0116, 'grad_norm': 5.164824485778809, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.006177067756652832, 'loss_2': 0.005466461181640625, 'loss_3': -16.316959381103516, 'loss_4': 0.08810184895992279, 'epoch': 21.7}
{'loss': 0.0115, 'grad_norm': 6.061683654785156, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.008945779874920845, 'loss_2': 0.00252532958984375, 'loss_3': -16.45977210998535, 'loss_4': 0.6684508323669434, 'epoch': 21.71}
{'loss': 0.0173, 'grad_norm': 5.022093296051025, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.0075218589045107365, 'loss_2': 0.00980377197265625, 'loss_3': -16.40353012084961, 'loss_4': 0.08457715809345245, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 13:52:53,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:53,226 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:12<24:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:00,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01735244318842888, 'eval_runtime': 3.7882, 'eval_samples_per_second': 270.313, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012222128920257092, 'eval_loss_2': 0.005130313336849213, 'eval_loss_3': -18.176454544067383, 'eval_loss_4': 0.1636916697025299, 'epoch': 21.72}
{'loss': 0.013, 'grad_norm': 7.927504062652588, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.012775789014995098, 'loss_2': 0.00018906593322753906, 'loss_3': -16.59210205078125, 'loss_4': 0.48872801661491394, 'epoch': 21.72}
{'loss': 0.0088, 'grad_norm': 5.406553268432617, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.006518607027828693, 'loss_2': 0.0022373199462890625, 'loss_3': -16.325788497924805, 'loss_4': 0.3635314106941223, 'epoch': 21.73}
{'loss': 0.0103, 'grad_norm': 4.4157609939575195, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.005137934349477291, 'loss_2': 0.005126953125, 'loss_3': -16.331253051757812, 'loss_4': 0.6372499465942383, 'epoch': 21.73}
{'loss': 0.0271, 'grad_norm': 7.2085490226745605, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.025544006377458572, 'loss_2': 0.0015764236450195312, 'loss_3': -16.66898536682129, 'loss_4': 0.039143823087215424, 'epoch': 21.74}
{'loss': 0.0045, 'grad_norm': 4.410473823547363, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.0034400755539536476, 'loss_2': 0.001041412353515625, 'loss_3': -16.444564819335938, 'loss_4': 0.8444114923477173, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 13:53:00,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:00,556 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:19<24:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:07,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016668085008859634, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.761, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012438077479600906, 'eval_loss_2': 0.004230007529258728, 'eval_loss_3': -18.174287796020508, 'eval_loss_4': 0.24473562836647034, 'epoch': 21.74}
{'loss': 0.0119, 'grad_norm': 5.260262966156006, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.007276049815118313, 'loss_2': 0.00458526611328125, 'loss_3': -16.277109146118164, 'loss_4': 0.0983542799949646, 'epoch': 21.75}
{'loss': 0.0062, 'grad_norm': 4.6428375244140625, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.00342954252846539, 'loss_2': 0.0027446746826171875, 'loss_3': -16.46774673461914, 'loss_4': 0.49693095684051514, 'epoch': 21.76}
{'loss': 0.0096, 'grad_norm': 5.667474269866943, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.006249234080314636, 'loss_2': 0.00334930419921875, 'loss_3': -16.640300750732422, 'loss_4': 0.13374140858650208, 'epoch': 21.76}
{'loss': 0.0082, 'grad_norm': 4.613480091094971, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.004403179511427879, 'loss_2': 0.003765106201171875, 'loss_3': -16.23829460144043, 'loss_4': 0.34729787707328796, 'epoch': 21.77}
{'loss': 0.0074, 'grad_norm': 4.839918613433838, 'learning_rate': 8.25e-06, 'loss_1': 0.004754772875458002, 'loss_2': 0.002689361572265625, 'loss_3': -16.567480087280273, 'loss_4': -0.11330656707286835, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 13:53:07,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:07,902 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:27<24:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:53:15,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016561925411224365, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.442, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01289613451808691, 'eval_loss_2': 0.0036657899618148804, 'eval_loss_3': -18.19257926940918, 'eval_loss_4': 0.36203140020370483, 'epoch': 21.77}
{'loss': 0.0069, 'grad_norm': 4.755553722381592, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.006443031597882509, 'loss_2': 0.00044918060302734375, 'loss_3': -16.513755798339844, 'loss_4': 0.07871172577142715, 'epoch': 21.78}
{'loss': 0.0136, 'grad_norm': 8.008893966674805, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.010770697146654129, 'loss_2': 0.0028018951416015625, 'loss_3': -16.447174072265625, 'loss_4': 0.9776444435119629, 'epoch': 21.78}
{'loss': 0.0074, 'grad_norm': 5.195455074310303, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.0048880488611757755, 'loss_2': 0.0024814605712890625, 'loss_3': -16.199874877929688, 'loss_4': 0.5752943754196167, 'epoch': 21.79}
{'loss': 0.0067, 'grad_norm': 5.270627975463867, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.005905290599912405, 'loss_2': 0.0007457733154296875, 'loss_3': -16.314716339111328, 'loss_4': 0.44183245301246643, 'epoch': 21.8}
{'loss': 0.0074, 'grad_norm': 4.984335899353027, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.00636236323043704, 'loss_2': 0.0010318756103515625, 'loss_3': -16.532184600830078, 'loss_4': 0.3434474766254425, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 13:53:15,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:15,223 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:34<24:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:22,554 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016956046223640442, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013524516485631466, 'eval_loss_2': 0.0034315288066864014, 'eval_loss_3': -18.193201065063477, 'eval_loss_4': 0.45492932200431824, 'epoch': 21.8}
{'loss': 0.0096, 'grad_norm': 4.738572120666504, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.006814528256654739, 'loss_2': 0.0028076171875, 'loss_3': -16.463821411132812, 'loss_4': 0.9666091203689575, 'epoch': 21.81}
{'loss': 0.0066, 'grad_norm': 4.6036553382873535, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.0034525995142757893, 'loss_2': 0.003124237060546875, 'loss_3': -16.447160720825195, 'loss_4': 0.6292065978050232, 'epoch': 21.81}
{'loss': 0.0069, 'grad_norm': 4.199907302856445, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.0049260277301073074, 'loss_2': 0.0019989013671875, 'loss_3': -16.279094696044922, 'loss_4': 1.0420955419540405, 'epoch': 21.82}
{'loss': 0.0152, 'grad_norm': 6.262454032897949, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.00894769374281168, 'loss_2': 0.00628662109375, 'loss_3': -16.16440200805664, 'loss_4': 0.2785235643386841, 'epoch': 21.83}
{'loss': 0.0111, 'grad_norm': 5.003854751586914, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.006476903334259987, 'loss_2': 0.0045928955078125, 'loss_3': -16.393774032592773, 'loss_4': 0.8204517364501953, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 13:53:22,554 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:22,554 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:41<24:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:53:29,875 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01755787804722786, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.077, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01377962063997984, 'eval_loss_2': 0.0037782564759254456, 'eval_loss_3': -18.189729690551758, 'eval_loss_4': 0.4751720130443573, 'epoch': 21.83}
{'loss': 0.0045, 'grad_norm': 4.470245838165283, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.003180883591994643, 'loss_2': 0.0012722015380859375, 'loss_3': -16.468414306640625, 'loss_4': 0.5402055978775024, 'epoch': 21.84}
{'loss': 0.0091, 'grad_norm': 6.243782997131348, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.008201966062188148, 'loss_2': 0.0009250640869140625, 'loss_3': -16.48426055908203, 'loss_4': 0.9403274059295654, 'epoch': 21.84}
{'loss': 0.0272, 'grad_norm': 8.214166641235352, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.020031845197081566, 'loss_2': 0.007175445556640625, 'loss_3': -16.399364471435547, 'loss_4': 0.799083948135376, 'epoch': 21.85}
{'loss': 0.0254, 'grad_norm': 11.569793701171875, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.02001703716814518, 'loss_2': 0.00534820556640625, 'loss_3': -16.58523941040039, 'loss_4': 0.39934200048446655, 'epoch': 21.85}
{'loss': 0.0353, 'grad_norm': 12.168962478637695, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.029904354363679886, 'loss_2': 0.005405426025390625, 'loss_3': -16.60616683959961, 'loss_4': 0.477679967880249, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 13:53:29,875 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:29,875 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:49<24:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:53:37,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017080210149288177, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.438, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013163038529455662, 'eval_loss_2': 0.00391717255115509, 'eval_loss_3': -18.188762664794922, 'eval_loss_4': 0.46736347675323486, 'epoch': 21.86}
{'loss': 0.0244, 'grad_norm': 8.120552062988281, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.022916190326213837, 'loss_2': 0.00150299072265625, 'loss_3': -16.316471099853516, 'loss_4': 0.42636531591415405, 'epoch': 21.87}
{'loss': 0.023, 'grad_norm': 11.461031913757324, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.020536251366138458, 'loss_2': 0.002498626708984375, 'loss_3': -16.425783157348633, 'loss_4': 1.1101676225662231, 'epoch': 21.87}
{'loss': 0.0154, 'grad_norm': 6.988412380218506, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.008007205091416836, 'loss_2': 0.007434844970703125, 'loss_3': -16.174217224121094, 'loss_4': 0.6747974157333374, 'epoch': 21.88}
{'loss': 0.0144, 'grad_norm': 9.623687744140625, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.014227226376533508, 'loss_2': 0.0002200603485107422, 'loss_3': -16.412368774414062, 'loss_4': 0.7782354354858398, 'epoch': 21.88}
{'loss': 0.0045, 'grad_norm': 4.416249752044678, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.0041068061254918575, 'loss_2': 0.0004220008850097656, 'loss_3': -16.443593978881836, 'loss_4': 0.7180518507957458, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 13:53:37,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:37,188 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:32:56<23:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:44,516 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017909670248627663, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.142, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013441646471619606, 'eval_loss_2': 0.004468023777008057, 'eval_loss_3': -18.20184898376465, 'eval_loss_4': 0.4615965485572815, 'epoch': 21.89}
{'loss': 0.0075, 'grad_norm': 4.940752983093262, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.0044311583042144775, 'loss_2': 0.0030670166015625, 'loss_3': -16.516929626464844, 'loss_4': 0.10723854601383209, 'epoch': 21.9}
{'loss': 0.0049, 'grad_norm': 4.489226341247559, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.0035731028765439987, 'loss_2': 0.0013408660888671875, 'loss_3': -16.46380615234375, 'loss_4': 0.3356897830963135, 'epoch': 21.9}
{'loss': 0.0111, 'grad_norm': 4.917634963989258, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.008220174349844456, 'loss_2': 0.002841949462890625, 'loss_3': -16.390483856201172, 'loss_4': 0.501084566116333, 'epoch': 21.91}
{'loss': 0.0113, 'grad_norm': 5.004042148590088, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.007207043468952179, 'loss_2': 0.004123687744140625, 'loss_3': -16.460285186767578, 'loss_4': 0.5420901775360107, 'epoch': 21.91}
{'loss': 0.0103, 'grad_norm': 4.2918291091918945, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.0029374940786510706, 'loss_2': 0.007354736328125, 'loss_3': -16.55267333984375, 'loss_4': 0.44753772020339966, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 13:53:44,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:44,516 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:33:03<23:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:51,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01862662471830845, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.726, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013498959131538868, 'eval_loss_2': 0.005127664655447006, 'eval_loss_3': -18.199132919311523, 'eval_loss_4': 0.5221191644668579, 'epoch': 21.92}
{'loss': 0.016, 'grad_norm': 6.268146991729736, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.009526913985610008, 'loss_2': 0.00650787353515625, 'loss_3': -16.331119537353516, 'loss_4': 0.3788621425628662, 'epoch': 21.92}
{'loss': 0.0141, 'grad_norm': 7.387002468109131, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.010602522641420364, 'loss_2': 0.003536224365234375, 'loss_3': -16.375205993652344, 'loss_4': 0.6759618520736694, 'epoch': 21.93}
{'loss': 0.0148, 'grad_norm': 6.4100165367126465, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.011407779529690742, 'loss_2': 0.0034008026123046875, 'loss_3': -16.435489654541016, 'loss_4': 0.41021865606307983, 'epoch': 21.94}
{'loss': 0.0093, 'grad_norm': 5.36315393447876, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.009222432971000671, 'loss_2': 6.759166717529297e-05, 'loss_3': -16.388874053955078, 'loss_4': 0.6651203632354736, 'epoch': 21.94}
{'loss': 0.0125, 'grad_norm': 4.72726583480835, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.005254294257611036, 'loss_2': 0.0072021484375, 'loss_3': -16.416460037231445, 'loss_4': 0.9465877413749695, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 13:53:51,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:51,851 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:11<23:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:59,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019669312983751297, 'eval_runtime': 3.786, 'eval_samples_per_second': 270.468, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015166464261710644, 'eval_loss_2': 0.004502847790718079, 'eval_loss_3': -18.182273864746094, 'eval_loss_4': 0.538123369216919, 'epoch': 21.95}
{'loss': 0.0141, 'grad_norm': 6.131777763366699, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.010333220474421978, 'loss_2': 0.0037784576416015625, 'loss_3': -16.577743530273438, 'loss_4': 0.5283376574516296, 'epoch': 21.95}
{'loss': 0.0098, 'grad_norm': 4.128477096557617, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.0036033315118402243, 'loss_2': 0.00620269775390625, 'loss_3': -16.773174285888672, 'loss_4': 0.9204532504081726, 'epoch': 21.96}
{'loss': 0.0093, 'grad_norm': 5.092683792114258, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.004169319290667772, 'loss_2': 0.0050811767578125, 'loss_3': -16.424583435058594, 'loss_4': 0.4429556131362915, 'epoch': 21.97}
{'loss': 0.0663, 'grad_norm': 10.462773323059082, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.05957453325390816, 'loss_2': 0.00669097900390625, 'loss_3': -16.533065795898438, 'loss_4': 0.7529850602149963, 'epoch': 21.97}
{'loss': 0.0091, 'grad_norm': 4.826632976531982, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.0029914183542132378, 'loss_2': 0.006084442138671875, 'loss_3': -16.431591033935547, 'loss_4': 0.6374008655548096, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 13:53:59,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:59,175 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:18<22:23,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 13:54:06,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01888810470700264, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01560111716389656, 'eval_loss_2': 0.003286987543106079, 'eval_loss_3': -18.167448043823242, 'eval_loss_4': 0.5160284042358398, 'epoch': 21.98}
{'loss': 0.0133, 'grad_norm': 4.785067558288574, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.009891560301184654, 'loss_2': 0.00341033935546875, 'loss_3': -16.393638610839844, 'loss_4': 0.6301264762878418, 'epoch': 21.98}
{'loss': 0.0054, 'grad_norm': 4.469821929931641, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.004221238195896149, 'loss_2': 0.0011749267578125, 'loss_3': -16.621660232543945, 'loss_4': 0.5631369948387146, 'epoch': 21.99}
{'loss': 0.0081, 'grad_norm': 7.028100490570068, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.006943943910300732, 'loss_2': 0.001201629638671875, 'loss_3': -16.618837356567383, 'loss_4': 0.44741135835647583, 'epoch': 21.99}
{'loss': 0.0037, 'grad_norm': 6.665628910064697, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.0028099603950977325, 'loss_2': 0.0009098052978515625, 'loss_3': -16.66765594482422, 'loss_4': 0.00024458239204250276, 'epoch': 22.0}
{'loss': 0.034, 'grad_norm': 15.973628997802734, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.030228281393647194, 'loss_2': 0.0037441253662109375, 'loss_3': -16.495616912841797, 'loss_4': 0.5760184526443481, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 13:54:06,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:06,200 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:25<23:22,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:54:13,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0205139871686697, 'eval_runtime': 3.7872, 'eval_samples_per_second': 270.387, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01580045185983181, 'eval_loss_2': 0.004713535308837891, 'eval_loss_3': -18.144155502319336, 'eval_loss_4': 0.4271888732910156, 'epoch': 22.01}
{'loss': 0.0105, 'grad_norm': 8.060708999633789, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.007519725244492292, 'loss_2': 0.002964019775390625, 'loss_3': -16.307289123535156, 'loss_4': 0.7056905627250671, 'epoch': 22.01}
{'loss': 0.0042, 'grad_norm': 4.841014385223389, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.0032135292422026396, 'loss_2': 0.001007080078125, 'loss_3': -16.341243743896484, 'loss_4': 0.5546786189079285, 'epoch': 22.02}
{'loss': 0.0098, 'grad_norm': 4.982919216156006, 'learning_rate': 8e-06, 'loss_1': 0.007161148823797703, 'loss_2': 0.002655029296875, 'loss_3': -16.426876068115234, 'loss_4': 0.5015579462051392, 'epoch': 22.02}
{'loss': 0.0133, 'grad_norm': 5.505638599395752, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.00899465475231409, 'loss_2': 0.004337310791015625, 'loss_3': -16.527860641479492, 'loss_4': 0.3877764940261841, 'epoch': 22.03}
{'loss': 0.0106, 'grad_norm': 5.276128768920898, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.006471364293247461, 'loss_2': 0.00409698486328125, 'loss_3': -16.36518096923828, 'loss_4': 0.6580765843391418, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 13:54:13,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:13,517 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:32<23:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:54:20,843 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022354731336236, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.489, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01623649150133133, 'eval_loss_2': 0.0061182379722595215, 'eval_loss_3': -18.12774658203125, 'eval_loss_4': 0.32616883516311646, 'epoch': 22.03}
{'loss': 0.0079, 'grad_norm': 4.747351169586182, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.002983680460602045, 'loss_2': 0.0049285888671875, 'loss_3': -16.462268829345703, 'loss_4': 0.6984888911247253, 'epoch': 22.04}
{'loss': 0.0085, 'grad_norm': 6.556914329528809, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.005492655094712973, 'loss_2': 0.00301361083984375, 'loss_3': -16.273605346679688, 'loss_4': 0.20285667479038239, 'epoch': 22.05}
{'loss': 0.0189, 'grad_norm': 5.551118850708008, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.008089829236268997, 'loss_2': 0.01079559326171875, 'loss_3': -16.561277389526367, 'loss_4': 0.6130263805389404, 'epoch': 22.05}
{'loss': 0.0032, 'grad_norm': 4.523557662963867, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.002608084585517645, 'loss_2': 0.0005855560302734375, 'loss_3': -16.508468627929688, 'loss_4': 0.4708229899406433, 'epoch': 22.06}
{'loss': 0.0124, 'grad_norm': 4.986589431762695, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.005518489051610231, 'loss_2': 0.0069122314453125, 'loss_3': -16.422088623046875, 'loss_4': 0.6788256764411926, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 13:54:20,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:20,844 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:40<23:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:28,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02179379016160965, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.504, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01735696941614151, 'eval_loss_2': 0.00443682074546814, 'eval_loss_3': -18.12396240234375, 'eval_loss_4': 0.31669914722442627, 'epoch': 22.06}
{'loss': 0.006, 'grad_norm': 4.727316379547119, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.003602825105190277, 'loss_2': 0.00243377685546875, 'loss_3': -16.27254295349121, 'loss_4': 0.46543923020362854, 'epoch': 22.07}
{'loss': 0.0078, 'grad_norm': 5.480747699737549, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.007042240351438522, 'loss_2': 0.0007476806640625, 'loss_3': -16.45543670654297, 'loss_4': 0.5770409107208252, 'epoch': 22.08}
{'loss': 0.0151, 'grad_norm': 5.161469459533691, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.009204440750181675, 'loss_2': 0.005878448486328125, 'loss_3': -16.282737731933594, 'loss_4': 0.5183570384979248, 'epoch': 22.08}
{'loss': 0.008, 'grad_norm': 4.413381099700928, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.004116576164960861, 'loss_2': 0.00384521484375, 'loss_3': -16.645326614379883, 'loss_4': 0.501122236251831, 'epoch': 22.09}
{'loss': 0.0304, 'grad_norm': 9.297404289245605, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.028862083330750465, 'loss_2': 0.001506805419921875, 'loss_3': -16.2918701171875, 'loss_4': 0.31833121180534363, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 13:54:28,183 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:28,184 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:47<23:43,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:54:35,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019410081207752228, 'eval_runtime': 3.9975, 'eval_samples_per_second': 256.16, 'eval_steps_per_second': 4.002, 'eval_loss_1': 0.016586745157837868, 'eval_loss_2': 0.0028233379125595093, 'eval_loss_3': -18.118494033813477, 'eval_loss_4': 0.37175431847572327, 'epoch': 22.09}
{'loss': 0.003, 'grad_norm': 4.40635347366333, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.0022079222835600376, 'loss_2': 0.0007724761962890625, 'loss_3': -16.239538192749023, 'loss_4': 0.8557088375091553, 'epoch': 22.1}
{'loss': 0.0077, 'grad_norm': 4.547055721282959, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.005087840836495161, 'loss_2': 0.00257110595703125, 'loss_3': -16.442596435546875, 'loss_4': 0.35284778475761414, 'epoch': 22.1}
{'loss': 0.0085, 'grad_norm': 5.227435111999512, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.006048921961337328, 'loss_2': 0.00241851806640625, 'loss_3': -16.44917869567871, 'loss_4': 0.5718646049499512, 'epoch': 22.11}
{'loss': 0.0088, 'grad_norm': 4.825048446655273, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.005403259769082069, 'loss_2': 0.003387451171875, 'loss_3': -16.250930786132812, 'loss_4': 0.710898220539093, 'epoch': 22.12}
{'loss': 0.0098, 'grad_norm': 5.183624267578125, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.0030869795009493828, 'loss_2': 0.00669097900390625, 'loss_3': -16.214414596557617, 'loss_4': 0.11568033695220947, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 13:54:35,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:35,721 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:33:55<23:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:43,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017949260771274567, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.857, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.014990990981459618, 'eval_loss_2': 0.0029582679271698, 'eval_loss_3': -18.130090713500977, 'eval_loss_4': 0.43702927231788635, 'epoch': 22.12}
{'loss': 0.0241, 'grad_norm': 17.001747131347656, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.023387998342514038, 'loss_2': 0.0007295608520507812, 'loss_3': -16.210247039794922, 'loss_4': 0.4326302707195282, 'epoch': 22.13}
{'loss': 0.0062, 'grad_norm': 5.397304534912109, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.005793124902993441, 'loss_2': 0.00036144256591796875, 'loss_3': -16.198209762573242, 'loss_4': 0.6425706148147583, 'epoch': 22.13}
{'loss': 0.0108, 'grad_norm': 4.506994724273682, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.004565783776342869, 'loss_2': 0.0062255859375, 'loss_3': -16.193130493164062, 'loss_4': 0.5356926321983337, 'epoch': 22.14}
{'loss': 0.0044, 'grad_norm': 4.938440322875977, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.0034326843451708555, 'loss_2': 0.0009260177612304688, 'loss_3': -16.465412139892578, 'loss_4': 0.2538478970527649, 'epoch': 22.15}
{'loss': 0.0612, 'grad_norm': 21.473575592041016, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.056450601667165756, 'loss_2': 0.004787445068359375, 'loss_3': -16.431682586669922, 'loss_4': 0.6585450172424316, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 13:54:43,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:43,057 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:34:02<23:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:50,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019403360784053802, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.971, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.016674555838108063, 'eval_loss_2': 0.0027288049459457397, 'eval_loss_3': -18.132814407348633, 'eval_loss_4': 0.45787250995635986, 'epoch': 22.15}
{'loss': 0.0203, 'grad_norm': 11.981461524963379, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.017418455332517624, 'loss_2': 0.0029239654541015625, 'loss_3': -16.357675552368164, 'loss_4': 0.1471979022026062, 'epoch': 22.16}
{'loss': 0.0122, 'grad_norm': 4.7988128662109375, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.009174305014312267, 'loss_2': 0.0030040740966796875, 'loss_3': -16.259201049804688, 'loss_4': 0.3306984305381775, 'epoch': 22.16}
{'loss': 0.0086, 'grad_norm': 5.063995361328125, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.008233275264501572, 'loss_2': 0.0003764629364013672, 'loss_3': -16.42522621154785, 'loss_4': 0.5944178104400635, 'epoch': 22.17}
{'loss': 0.0166, 'grad_norm': 4.9355854988098145, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.009565354324877262, 'loss_2': 0.007076263427734375, 'loss_3': -16.342134475708008, 'loss_4': 0.6056727766990662, 'epoch': 22.17}
{'loss': 0.0059, 'grad_norm': 4.456878662109375, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.004610680975019932, 'loss_2': 0.001285552978515625, 'loss_3': -16.443161010742188, 'loss_4': 0.4850681722164154, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 13:54:50,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:50,389 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:09<23:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:57,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018917759880423546, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01595902629196644, 'eval_loss_2': 0.0029587335884571075, 'eval_loss_3': -18.134174346923828, 'eval_loss_4': 0.48688700795173645, 'epoch': 22.18}
{'loss': 0.0191, 'grad_norm': 6.665378570556641, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.013324224390089512, 'loss_2': 0.005748748779296875, 'loss_3': -16.587520599365234, 'loss_4': 0.487185537815094, 'epoch': 22.19}
{'loss': 0.0257, 'grad_norm': 7.803832530975342, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.01776520349085331, 'loss_2': 0.00792694091796875, 'loss_3': -16.636362075805664, 'loss_4': 0.8380743861198425, 'epoch': 22.19}
{'loss': 0.0045, 'grad_norm': 4.3696489334106445, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.004088098183274269, 'loss_2': 0.0003714561462402344, 'loss_3': -16.467323303222656, 'loss_4': 0.05232429504394531, 'epoch': 22.2}
{'loss': 0.0744, 'grad_norm': 16.633026123046875, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.07354602962732315, 'loss_2': 0.0008335113525390625, 'loss_3': -16.6392822265625, 'loss_4': 0.972136378288269, 'epoch': 22.2}
{'loss': 0.02, 'grad_norm': 7.827021598815918, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.01442089956253767, 'loss_2': 0.00559234619140625, 'loss_3': -16.443405151367188, 'loss_4': 0.7550979852676392, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 13:54:57,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:57,729 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:17<23:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:05,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02037629298865795, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.662, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.016359418630599976, 'eval_loss_2': 0.004016876220703125, 'eval_loss_3': -18.12885093688965, 'eval_loss_4': 0.5136579275131226, 'epoch': 22.21}
{'loss': 0.0205, 'grad_norm': 8.236594200134277, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.01825844496488571, 'loss_2': 0.00228118896484375, 'loss_3': -16.522491455078125, 'loss_4': 0.4893738329410553, 'epoch': 22.22}
{'loss': 0.012, 'grad_norm': 4.465758800506592, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.003340422874316573, 'loss_2': 0.008697509765625, 'loss_3': -16.636356353759766, 'loss_4': 0.7141308784484863, 'epoch': 22.22}
{'loss': 0.0073, 'grad_norm': 4.762991905212402, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.003225787077099085, 'loss_2': 0.00408172607421875, 'loss_3': -16.779621124267578, 'loss_4': 0.37321701645851135, 'epoch': 22.23}
{'loss': 0.0052, 'grad_norm': 4.896276950836182, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.004541853908449411, 'loss_2': 0.0006952285766601562, 'loss_3': -16.501426696777344, 'loss_4': 0.5923494696617126, 'epoch': 22.23}
{'loss': 0.028, 'grad_norm': 28.22019386291504, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.024584904313087463, 'loss_2': 0.0033702850341796875, 'loss_3': -16.432392120361328, 'loss_4': 1.0680313110351562, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 13:55:05,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:05,076 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:24<23:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:12,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022314196452498436, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.017360934987664223, 'eval_loss_2': 0.004953265190124512, 'eval_loss_3': -18.15511131286621, 'eval_loss_4': 0.5154404044151306, 'epoch': 22.24}
{'loss': 0.0101, 'grad_norm': 6.868146896362305, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.009261546656489372, 'loss_2': 0.0008335113525390625, 'loss_3': -16.473609924316406, 'loss_4': 0.3312486410140991, 'epoch': 22.24}
{'loss': 0.0212, 'grad_norm': 18.187639236450195, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.019861159846186638, 'loss_2': 0.0013113021850585938, 'loss_3': -16.31793212890625, 'loss_4': 0.14681726694107056, 'epoch': 22.25}
{'loss': 0.0123, 'grad_norm': 4.763659477233887, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.004283539019525051, 'loss_2': 0.00799560546875, 'loss_3': -16.526447296142578, 'loss_4': 0.174035906791687, 'epoch': 22.26}
{'loss': 0.0112, 'grad_norm': 5.920967102050781, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.0087279649451375, 'loss_2': 0.002460479736328125, 'loss_3': -16.361328125, 'loss_4': 0.9273363351821899, 'epoch': 22.26}
{'loss': 0.0085, 'grad_norm': 4.7273640632629395, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.005570635665208101, 'loss_2': 0.0029315948486328125, 'loss_3': -16.570425033569336, 'loss_4': 0.7373878955841064, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 13:55:12,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:12,427 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:31<22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:19,767 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022121213376522064, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.695, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01850551925599575, 'eval_loss_2': 0.0036156922578811646, 'eval_loss_3': -18.154739379882812, 'eval_loss_4': 0.4341548681259155, 'epoch': 22.27}
{'loss': 0.0137, 'grad_norm': 5.3251237869262695, 'learning_rate': 7.75e-06, 'loss_1': 0.007194920442998409, 'loss_2': 0.00646209716796875, 'loss_3': -16.574153900146484, 'loss_4': 0.8548671007156372, 'epoch': 22.27}
{'loss': 0.0125, 'grad_norm': 4.680543422698975, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.004448694176971912, 'loss_2': 0.00801849365234375, 'loss_3': -16.4754695892334, 'loss_4': 0.1658019870519638, 'epoch': 22.28}
{'loss': 0.0104, 'grad_norm': 5.191762924194336, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.007241662126034498, 'loss_2': 0.00319671630859375, 'loss_3': -16.711135864257812, 'loss_4': 0.6729171276092529, 'epoch': 22.28}
{'loss': 0.0129, 'grad_norm': 5.617882251739502, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.01224474050104618, 'loss_2': 0.0006470680236816406, 'loss_3': -16.61754608154297, 'loss_4': 0.7487450242042542, 'epoch': 22.29}
{'loss': 0.011, 'grad_norm': 5.17008638381958, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.005701816640794277, 'loss_2': 0.0053253173828125, 'loss_3': -16.57969856262207, 'loss_4': 0.6671934127807617, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 13:55:19,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:19,768 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:39<22:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:27,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021002216264605522, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018402915447950363, 'eval_loss_2': 0.0025992989540100098, 'eval_loss_3': -18.13974380493164, 'eval_loss_4': 0.40751755237579346, 'epoch': 22.3}
{'loss': 0.0071, 'grad_norm': 4.6788787841796875, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.0056048426777124405, 'loss_2': 0.0014505386352539062, 'loss_3': -16.37240219116211, 'loss_4': 0.0999315083026886, 'epoch': 22.3}
{'loss': 0.0093, 'grad_norm': 5.69914436340332, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.0068242778070271015, 'loss_2': 0.0024356842041015625, 'loss_3': -16.311752319335938, 'loss_4': 0.3368021249771118, 'epoch': 22.31}
{'loss': 0.0123, 'grad_norm': 6.559788703918457, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.011099916882812977, 'loss_2': 0.001239776611328125, 'loss_3': -16.43067169189453, 'loss_4': 0.5596863031387329, 'epoch': 22.31}
{'loss': 0.0093, 'grad_norm': 5.310635566711426, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.004948778077960014, 'loss_2': 0.0043487548828125, 'loss_3': -16.574052810668945, 'loss_4': 0.4348613917827606, 'epoch': 22.32}
{'loss': 0.0265, 'grad_norm': 10.776259422302246, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.016224419698119164, 'loss_2': 0.01032257080078125, 'loss_3': -16.427505493164062, 'loss_4': 0.6476837396621704, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 13:55:27,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:27,110 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:46<22:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:34,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025607308372855186, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.844, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.019939055666327477, 'eval_loss_2': 0.00566825270652771, 'eval_loss_3': -18.14533805847168, 'eval_loss_4': 0.24361805617809296, 'epoch': 22.33}
{'loss': 0.0167, 'grad_norm': 6.717167854309082, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.01036330871284008, 'loss_2': 0.00630950927734375, 'loss_3': -16.50558853149414, 'loss_4': 0.480037659406662, 'epoch': 22.33}
{'loss': 0.005, 'grad_norm': 4.619287967681885, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.0035474300384521484, 'loss_2': 0.0014848709106445312, 'loss_3': -16.4293270111084, 'loss_4': 0.21367351710796356, 'epoch': 22.34}
{'loss': 0.0052, 'grad_norm': 4.647600173950195, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.004104794934391975, 'loss_2': 0.0011386871337890625, 'loss_3': -16.573745727539062, 'loss_4': 0.2538512349128723, 'epoch': 22.34}
{'loss': 0.0122, 'grad_norm': 5.414300918579102, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.008864295668900013, 'loss_2': 0.003326416015625, 'loss_3': -16.52554702758789, 'loss_4': 0.47308221459388733, 'epoch': 22.35}
{'loss': 0.0094, 'grad_norm': 4.165192604064941, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.0037189978174865246, 'loss_2': 0.00569915771484375, 'loss_3': -16.51012420654297, 'loss_4': 0.3395676910877228, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 13:55:34,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:34,449 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:34:53<22:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:41,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026840131729841232, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.05, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.021426301449537277, 'eval_loss_2': 0.005413830280303955, 'eval_loss_3': -18.14696502685547, 'eval_loss_4': 0.12987616658210754, 'epoch': 22.35}
{'loss': 0.0158, 'grad_norm': 5.6139726638793945, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.0089235445484519, 'loss_2': 0.006855010986328125, 'loss_3': -16.54730987548828, 'loss_4': 0.1094665378332138, 'epoch': 22.36}
{'loss': 0.0114, 'grad_norm': 5.266294956207275, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.009271588176488876, 'loss_2': 0.00215911865234375, 'loss_3': -16.34326171875, 'loss_4': 0.36294451355934143, 'epoch': 22.37}
{'loss': 0.0171, 'grad_norm': 5.790393352508545, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.007426300551742315, 'loss_2': 0.0096435546875, 'loss_3': -16.385141372680664, 'loss_4': 0.6846526861190796, 'epoch': 22.37}
{'loss': 0.008, 'grad_norm': 5.477822780609131, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.006799552123993635, 'loss_2': 0.00122833251953125, 'loss_3': -16.321491241455078, 'loss_4': -0.015453100204467773, 'epoch': 22.38}
{'loss': 0.0107, 'grad_norm': 5.2548089027404785, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.006176704075187445, 'loss_2': 0.00457000732421875, 'loss_3': -16.55029296875, 'loss_4': 0.35647669434547424, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 13:55:41,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:41,784 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:35:01<22:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:49,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02453107386827469, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.906, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.021051587536931038, 'eval_loss_2': 0.0034794881939888, 'eval_loss_3': -18.147863388061523, 'eval_loss_4': 0.05572354793548584, 'epoch': 22.38}
{'loss': 0.0078, 'grad_norm': 4.63119649887085, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.0052056764252483845, 'loss_2': 0.002590179443359375, 'loss_3': -16.585227966308594, 'loss_4': 0.36035531759262085, 'epoch': 22.39}
{'loss': 0.0116, 'grad_norm': 4.871135234832764, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.0056299748830497265, 'loss_2': 0.005950927734375, 'loss_3': -16.47234344482422, 'loss_4': 0.26974254846572876, 'epoch': 22.4}
{'loss': 0.0106, 'grad_norm': 5.003880023956299, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.008917462080717087, 'loss_2': 0.0016727447509765625, 'loss_3': -16.319000244140625, 'loss_4': 0.3784412443637848, 'epoch': 22.4}
{'loss': 0.0123, 'grad_norm': 7.615060329437256, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.008288372308015823, 'loss_2': 0.003971099853515625, 'loss_3': -16.446937561035156, 'loss_4': -0.17665834724903107, 'epoch': 22.41}
{'loss': 0.0111, 'grad_norm': 5.183877944946289, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.007683680392801762, 'loss_2': 0.003368377685546875, 'loss_3': -16.384017944335938, 'loss_4': 0.13129910826683044, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 13:55:49,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:49,142 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:08<22:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:56,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022563494741916656, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.019632946699857712, 'eval_loss_2': 0.0029305480420589447, 'eval_loss_3': -18.15513801574707, 'eval_loss_4': 0.05711156874895096, 'epoch': 22.41}
{'loss': 0.0103, 'grad_norm': 5.483779430389404, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.00790842529386282, 'loss_2': 0.0023441314697265625, 'loss_3': -16.385765075683594, 'loss_4': 0.0024578720331192017, 'epoch': 22.42}
{'loss': 0.0055, 'grad_norm': 5.344486236572266, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.005125683732330799, 'loss_2': 0.00042319297790527344, 'loss_3': -16.36865997314453, 'loss_4': 0.18848159909248352, 'epoch': 22.42}
{'loss': 0.0156, 'grad_norm': 6.556657314300537, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.013082039542496204, 'loss_2': 0.002475738525390625, 'loss_3': -16.353059768676758, 'loss_4': 0.20599377155303955, 'epoch': 22.43}
{'loss': 0.0067, 'grad_norm': 5.961779594421387, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.00599891459569335, 'loss_2': 0.0007028579711914062, 'loss_3': -16.616188049316406, 'loss_4': 0.47289565205574036, 'epoch': 22.44}
{'loss': 0.0099, 'grad_norm': 6.80444860458374, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.009380615316331387, 'loss_2': 0.000476837158203125, 'loss_3': -16.399669647216797, 'loss_4': 0.4058675467967987, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 13:55:56,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:56,477 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:15<22:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:03,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022011008113622665, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.919, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0191133301705122, 'eval_loss_2': 0.0028976798057556152, 'eval_loss_3': -18.149503707885742, 'eval_loss_4': 0.04632746800780296, 'epoch': 22.44}
{'loss': 0.0086, 'grad_norm': 5.02347469329834, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.005434728227555752, 'loss_2': 0.0031642913818359375, 'loss_3': -16.374629974365234, 'loss_4': -0.015573948621749878, 'epoch': 22.45}
{'loss': 0.0202, 'grad_norm': 6.798727035522461, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.015188422054052353, 'loss_2': 0.00505828857421875, 'loss_3': -16.41843032836914, 'loss_4': 0.2242761105298996, 'epoch': 22.45}
{'loss': 0.0057, 'grad_norm': 4.5926289558410645, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.004457172006368637, 'loss_2': 0.001224517822265625, 'loss_3': -16.431900024414062, 'loss_4': -0.1345103234052658, 'epoch': 22.46}
{'loss': 0.01, 'grad_norm': 5.599159240722656, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.008833162486553192, 'loss_2': 0.00115203857421875, 'loss_3': -16.54812240600586, 'loss_4': 0.1781618893146515, 'epoch': 22.47}
{'loss': 0.0058, 'grad_norm': 4.958612442016602, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.004647147376090288, 'loss_2': 0.001132965087890625, 'loss_3': -16.410423278808594, 'loss_4': -0.4370063543319702, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 13:56:03,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:03,812 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:23<22:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:11,141 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021166091784834862, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.042, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.018447551876306534, 'eval_loss_2': 0.0027185380458831787, 'eval_loss_3': -18.146839141845703, 'eval_loss_4': -0.06355197727680206, 'epoch': 22.47}
{'loss': 0.0081, 'grad_norm': 4.636695384979248, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.004081841558218002, 'loss_2': 0.0040130615234375, 'loss_3': -16.373109817504883, 'loss_4': -0.031357571482658386, 'epoch': 22.48}
{'loss': 0.0125, 'grad_norm': 4.258737087249756, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.005119292996823788, 'loss_2': 0.0074005126953125, 'loss_3': -16.271560668945312, 'loss_4': -0.3217085599899292, 'epoch': 22.48}
{'loss': 0.0132, 'grad_norm': 4.963656902313232, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.0039049636106938124, 'loss_2': 0.0092620849609375, 'loss_3': -16.436595916748047, 'loss_4': 0.0048501938581466675, 'epoch': 22.49}
{'loss': 0.0119, 'grad_norm': 4.711665630340576, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.00655737891793251, 'loss_2': 0.005352020263671875, 'loss_3': -16.399131774902344, 'loss_4': -0.30577102303504944, 'epoch': 22.49}
{'loss': 0.0066, 'grad_norm': 4.434131145477295, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.003907831385731697, 'loss_2': 0.002727508544921875, 'loss_3': -16.461170196533203, 'loss_4': -0.06553284823894501, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 13:56:11,141 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:11,141 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:30<22:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:18,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0220144372433424, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.951, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018987830728292465, 'eval_loss_2': 0.003026604652404785, 'eval_loss_3': -18.16122055053711, 'eval_loss_4': -0.18673163652420044, 'epoch': 22.5}
{'loss': 0.0251, 'grad_norm': 9.125661849975586, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.017838871106505394, 'loss_2': 0.00727081298828125, 'loss_3': -16.315143585205078, 'loss_4': -0.33722203969955444, 'epoch': 22.51}
{'loss': 0.0115, 'grad_norm': 6.305849552154541, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.008487489074468613, 'loss_2': 0.002986907958984375, 'loss_3': -16.430875778198242, 'loss_4': -0.23502828180789948, 'epoch': 22.51}
{'loss': 0.0083, 'grad_norm': 4.151118755340576, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.003530035261064768, 'loss_2': 0.00476837158203125, 'loss_3': -16.472213745117188, 'loss_4': 0.37057584524154663, 'epoch': 22.52}
{'loss': 0.024, 'grad_norm': 10.093427658081055, 'learning_rate': 7.5e-06, 'loss_1': 0.02093811146914959, 'loss_2': 0.0030231475830078125, 'loss_3': -16.37649154663086, 'loss_4': -0.4135540723800659, 'epoch': 22.52}
{'loss': 0.0073, 'grad_norm': 5.040935516357422, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.00582425482571125, 'loss_2': 0.00144195556640625, 'loss_3': -16.56612777709961, 'loss_4': -0.4584098160266876, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 13:56:18,476 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:18,477 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:37<22:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:25,812 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02119523659348488, 'eval_runtime': 3.7921, 'eval_samples_per_second': 270.035, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.019082386046648026, 'eval_loss_2': 0.002112850546836853, 'eval_loss_3': -18.14760971069336, 'eval_loss_4': -0.3193735182285309, 'epoch': 22.53}
{'loss': 0.0179, 'grad_norm': 11.338582992553711, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.016274886205792427, 'loss_2': 0.001659393310546875, 'loss_3': -16.515146255493164, 'loss_4': -0.46997904777526855, 'epoch': 22.53}
{'loss': 0.0236, 'grad_norm': 6.5088396072387695, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.012829449959099293, 'loss_2': 0.01081085205078125, 'loss_3': -16.601428985595703, 'loss_4': -0.23701223731040955, 'epoch': 22.54}
{'loss': 0.0245, 'grad_norm': 8.650655746459961, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.016184359788894653, 'loss_2': 0.00836181640625, 'loss_3': -16.56344223022461, 'loss_4': -0.11075055599212646, 'epoch': 22.55}
{'loss': 0.0128, 'grad_norm': 7.972295761108398, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.010856145061552525, 'loss_2': 0.0019388198852539062, 'loss_3': -16.55844497680664, 'loss_4': -0.4337059557437897, 'epoch': 22.55}
{'loss': 0.0095, 'grad_norm': 4.867692947387695, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.008542618714272976, 'loss_2': 0.0009822845458984375, 'loss_3': -16.577987670898438, 'loss_4': -0.2746903896331787, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 13:56:25,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:25,812 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:45<22:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:33,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022926587611436844, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.525, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.020197365432977676, 'eval_loss_2': 0.0027292221784591675, 'eval_loss_3': -18.17595100402832, 'eval_loss_4': -0.46124565601348877, 'epoch': 22.56}
{'loss': 0.0083, 'grad_norm': 6.784397125244141, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.008036697283387184, 'loss_2': 0.0002875328063964844, 'loss_3': -16.68116569519043, 'loss_4': -0.45583704113960266, 'epoch': 22.56}
{'loss': 0.0116, 'grad_norm': 5.264510154724121, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.005964238196611404, 'loss_2': 0.0056610107421875, 'loss_3': -16.467145919799805, 'loss_4': -0.5705926418304443, 'epoch': 22.57}
{'loss': 0.0127, 'grad_norm': 6.657684803009033, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.012517784722149372, 'loss_2': 0.00013494491577148438, 'loss_3': -16.516769409179688, 'loss_4': -0.024033769965171814, 'epoch': 22.58}
{'loss': 0.0072, 'grad_norm': 4.315123081207275, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.0040862075984478, 'loss_2': 0.0031414031982421875, 'loss_3': -16.46742820739746, 'loss_4': -0.3057832419872284, 'epoch': 22.58}
{'loss': 0.0076, 'grad_norm': 5.074286460876465, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.006085455417633057, 'loss_2': 0.001529693603515625, 'loss_3': -16.36897850036621, 'loss_4': -0.6367276906967163, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 13:56:33,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:33,155 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:35:52<21:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:40,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023417437449097633, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.061, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.02107527107000351, 'eval_loss_2': 0.0023421645164489746, 'eval_loss_3': -18.17474365234375, 'eval_loss_4': -0.5539361238479614, 'epoch': 22.59}
{'loss': 0.0058, 'grad_norm': 4.752045154571533, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.00529171247035265, 'loss_2': 0.0004725456237792969, 'loss_3': -16.335363388061523, 'loss_4': 0.00453658401966095, 'epoch': 22.59}
{'loss': 0.0087, 'grad_norm': 4.659398555755615, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.008333261124789715, 'loss_2': 0.0003457069396972656, 'loss_3': -16.537010192871094, 'loss_4': -0.43177366256713867, 'epoch': 22.6}
{'loss': 0.0098, 'grad_norm': 4.541209697723389, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.004257167689502239, 'loss_2': 0.00559234619140625, 'loss_3': -16.381118774414062, 'loss_4': -0.5888847708702087, 'epoch': 22.6}
{'loss': 0.0108, 'grad_norm': 7.262251377105713, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.0102146677672863, 'loss_2': 0.0005369186401367188, 'loss_3': -16.492576599121094, 'loss_4': -0.6270194053649902, 'epoch': 22.61}
{'loss': 0.0061, 'grad_norm': 4.828823089599609, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.005383643787354231, 'loss_2': 0.0007457733154296875, 'loss_3': -16.71162986755371, 'loss_4': -0.9048910140991211, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 13:56:40,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:40,492 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:35:59<21:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:47,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023816369473934174, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.788, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.022010795772075653, 'eval_loss_2': 0.0018055737018585205, 'eval_loss_3': -18.17263412475586, 'eval_loss_4': -0.6382160782814026, 'epoch': 22.62}
{'loss': 0.0163, 'grad_norm': 5.8080973625183105, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.01326384861022234, 'loss_2': 0.002986907958984375, 'loss_3': -16.45356559753418, 'loss_4': -0.7904421091079712, 'epoch': 22.62}
{'loss': 0.0085, 'grad_norm': 5.778546333312988, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.006230885628610849, 'loss_2': 0.0022945404052734375, 'loss_3': -16.52501106262207, 'loss_4': -0.9390065670013428, 'epoch': 22.63}
{'loss': 0.0124, 'grad_norm': 5.789801120758057, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.009775325655937195, 'loss_2': 0.002593994140625, 'loss_3': -16.382568359375, 'loss_4': -0.7582688331604004, 'epoch': 22.63}
{'loss': 0.0216, 'grad_norm': 6.183175563812256, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.011073091067373753, 'loss_2': 0.0105743408203125, 'loss_3': -16.65229034423828, 'loss_4': -1.0808111429214478, 'epoch': 22.64}
{'loss': 0.0187, 'grad_norm': 5.900130748748779, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.00946833100169897, 'loss_2': 0.0092315673828125, 'loss_3': -16.352834701538086, 'loss_4': -0.9282949566841125, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 13:56:47,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:47,834 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:07<21:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:55,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02507198415696621, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.808, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.022901875898241997, 'eval_loss_2': 0.0021701082587242126, 'eval_loss_3': -18.159543991088867, 'eval_loss_4': -0.7426613569259644, 'epoch': 22.65}
{'loss': 0.0127, 'grad_norm': 5.3149590492248535, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.012497697956860065, 'loss_2': 0.00022399425506591797, 'loss_3': -16.69375228881836, 'loss_4': -0.5440962910652161, 'epoch': 22.65}
{'loss': 0.0113, 'grad_norm': 5.953039646148682, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.010655641555786133, 'loss_2': 0.0006098747253417969, 'loss_3': -16.44999122619629, 'loss_4': -0.9847099184989929, 'epoch': 22.66}
{'loss': 0.0176, 'grad_norm': 6.401827335357666, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.008690658025443554, 'loss_2': 0.008941650390625, 'loss_3': -16.666702270507812, 'loss_4': -0.8095552921295166, 'epoch': 22.66}
{'loss': 0.0128, 'grad_norm': 4.749660968780518, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.005766561254858971, 'loss_2': 0.007053375244140625, 'loss_3': -16.680818557739258, 'loss_4': -1.0949409008026123, 'epoch': 22.67}
{'loss': 0.0184, 'grad_norm': 7.416049480438232, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.013152341358363628, 'loss_2': 0.0052947998046875, 'loss_3': -16.413007736206055, 'loss_4': -0.18323597311973572, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 13:56:55,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:55,169 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:14<21:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:02,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025195065885782242, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.022159282118082047, 'eval_loss_2': 0.0030357837677001953, 'eval_loss_3': -18.15997314453125, 'eval_loss_4': -0.7221096754074097, 'epoch': 22.67}
{'loss': 0.0046, 'grad_norm': 4.630651473999023, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.0033592814579606056, 'loss_2': 0.001255035400390625, 'loss_3': -16.64055824279785, 'loss_4': -0.6438738107681274, 'epoch': 22.68}
{'loss': 0.0145, 'grad_norm': 12.268563270568848, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.012744996696710587, 'loss_2': 0.0017452239990234375, 'loss_3': -16.28791618347168, 'loss_4': -0.7413637042045593, 'epoch': 22.69}
{'loss': 0.0115, 'grad_norm': 10.026067733764648, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.01140136830508709, 'loss_2': 0.00010395050048828125, 'loss_3': -16.60947608947754, 'loss_4': -0.7764391899108887, 'epoch': 22.69}
{'loss': 0.0173, 'grad_norm': 7.59081506729126, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.017068568617105484, 'loss_2': 0.00022673606872558594, 'loss_3': -16.60348129272461, 'loss_4': -0.5831365585327148, 'epoch': 22.7}
{'loss': 0.0056, 'grad_norm': 4.514786243438721, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.004012641962617636, 'loss_2': 0.0015535354614257812, 'loss_3': -16.577335357666016, 'loss_4': -0.5384184718132019, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 13:57:02,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:02,508 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:21<21:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:09,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026623765006661415, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.62, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.02388879656791687, 'eval_loss_2': 0.0027349665760993958, 'eval_loss_3': -18.14719581604004, 'eval_loss_4': -0.7133930921554565, 'epoch': 22.7}
{'loss': 0.0352, 'grad_norm': 9.516435623168945, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.026999877765774727, 'loss_2': 0.008209228515625, 'loss_3': -16.420326232910156, 'loss_4': -0.6332527995109558, 'epoch': 22.71}
{'loss': 0.0077, 'grad_norm': 4.529954433441162, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.004409081768244505, 'loss_2': 0.003337860107421875, 'loss_3': -16.514873504638672, 'loss_4': -0.7123116254806519, 'epoch': 22.72}
{'loss': 0.0095, 'grad_norm': 5.931782245635986, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.007333158515393734, 'loss_2': 0.00213623046875, 'loss_3': -16.500938415527344, 'loss_4': -0.7528877258300781, 'epoch': 22.72}
{'loss': 0.0089, 'grad_norm': 5.145659923553467, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.005269510205835104, 'loss_2': 0.003635406494140625, 'loss_3': -16.486080169677734, 'loss_4': -1.1074976921081543, 'epoch': 22.73}
{'loss': 0.0125, 'grad_norm': 5.272642612457275, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.010037499479949474, 'loss_2': 0.0024871826171875, 'loss_3': -16.6292724609375, 'loss_4': -0.722856879234314, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 13:57:09,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:09,848 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:29<21:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:17,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0267579834908247, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.024946479126811028, 'eval_loss_2': 0.0018115043640136719, 'eval_loss_3': -18.130401611328125, 'eval_loss_4': -0.7182249426841736, 'epoch': 22.73}
{'loss': 0.0161, 'grad_norm': 4.69063138961792, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.007583560887724161, 'loss_2': 0.00855255126953125, 'loss_3': -16.433908462524414, 'loss_4': -0.4865262508392334, 'epoch': 22.74}
{'loss': 0.0086, 'grad_norm': 4.785556793212891, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.006589505355805159, 'loss_2': 0.0020008087158203125, 'loss_3': -16.611839294433594, 'loss_4': -0.2760675847530365, 'epoch': 22.74}
{'loss': 0.0176, 'grad_norm': 11.673627853393555, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.017271339893341064, 'loss_2': 0.0003345012664794922, 'loss_3': -16.236705780029297, 'loss_4': -0.7738431692123413, 'epoch': 22.75}
{'loss': 0.0101, 'grad_norm': 5.299903392791748, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.007162387948483229, 'loss_2': 0.002960205078125, 'loss_3': -16.369659423828125, 'loss_4': -0.7521551847457886, 'epoch': 22.76}
{'loss': 0.0121, 'grad_norm': 6.083784580230713, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.011656729504466057, 'loss_2': 0.0004494190216064453, 'loss_3': -16.391094207763672, 'loss_4': -0.11864930391311646, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 13:57:17,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:17,189 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:36<21:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:24,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02721390686929226, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02529440075159073, 'eval_loss_2': 0.0019195079803466797, 'eval_loss_3': -18.12263298034668, 'eval_loss_4': -0.696946918964386, 'epoch': 22.76}
{'loss': 0.0114, 'grad_norm': 5.953456878662109, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.007600107695907354, 'loss_2': 0.003803253173828125, 'loss_3': -16.406822204589844, 'loss_4': -0.8772340416908264, 'epoch': 22.77}
{'loss': 0.0179, 'grad_norm': 5.135132789611816, 'learning_rate': 7.25e-06, 'loss_1': 0.015335297212004662, 'loss_2': 0.00255584716796875, 'loss_3': -16.531661987304688, 'loss_4': -0.21327003836631775, 'epoch': 22.77}
{'loss': 0.0127, 'grad_norm': 4.489177227020264, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.0042115370742976665, 'loss_2': 0.00852203369140625, 'loss_3': -16.557750701904297, 'loss_4': -0.6006421446800232, 'epoch': 22.78}
{'loss': 0.0072, 'grad_norm': 5.0210771560668945, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.00416151899844408, 'loss_2': 0.003032684326171875, 'loss_3': -16.45425796508789, 'loss_4': -0.8503482341766357, 'epoch': 22.78}
{'loss': 0.0064, 'grad_norm': 4.581904888153076, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.0037749051116406918, 'loss_2': 0.002628326416015625, 'loss_3': -16.49423599243164, 'loss_4': -0.7658578157424927, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 13:57:24,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:24,529 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:43<21:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:31,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02616063505411148, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.708, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.02334526926279068, 'eval_loss_2': 0.0028153657913208008, 'eval_loss_3': -18.141977310180664, 'eval_loss_4': -0.6660656332969666, 'epoch': 22.79}
{'loss': 0.0646, 'grad_norm': 23.793102264404297, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.06432921439409256, 'loss_2': 0.00029397010803222656, 'loss_3': -16.649511337280273, 'loss_4': -0.16871246695518494, 'epoch': 22.8}
{'loss': 0.017, 'grad_norm': 5.6100754737854, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.009816397912800312, 'loss_2': 0.00719451904296875, 'loss_3': -16.458553314208984, 'loss_4': -0.48070743680000305, 'epoch': 22.8}
{'loss': 0.0167, 'grad_norm': 7.464998245239258, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.009025025181472301, 'loss_2': 0.0076446533203125, 'loss_3': -16.611303329467773, 'loss_4': -0.8698335289955139, 'epoch': 22.81}
{'loss': 0.0086, 'grad_norm': 5.349220275878906, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.0069163087755441666, 'loss_2': 0.001667022705078125, 'loss_3': -16.435771942138672, 'loss_4': -0.7588965892791748, 'epoch': 22.81}
{'loss': 0.0128, 'grad_norm': 4.665907382965088, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.004438305273652077, 'loss_2': 0.00835418701171875, 'loss_3': -16.408428192138672, 'loss_4': -0.6505213975906372, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 13:57:31,867 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:31,867 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:36:51<21:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:39,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02207893133163452, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.96, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018466338515281677, 'eval_loss_2': 0.0036125928163528442, 'eval_loss_3': -18.162288665771484, 'eval_loss_4': -0.6069868803024292, 'epoch': 22.82}
{'loss': 0.006, 'grad_norm': 4.693423271179199, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.003111965721473098, 'loss_2': 0.002849578857421875, 'loss_3': -16.402515411376953, 'loss_4': -0.049153320491313934, 'epoch': 22.83}
{'loss': 0.0184, 'grad_norm': 5.8026123046875, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.012208004482090473, 'loss_2': 0.0061492919921875, 'loss_3': -16.28585433959961, 'loss_4': -0.6718934774398804, 'epoch': 22.83}
{'loss': 0.0119, 'grad_norm': 9.015875816345215, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.010389095172286034, 'loss_2': 0.0014743804931640625, 'loss_3': -16.419422149658203, 'loss_4': -0.37703895568847656, 'epoch': 22.84}
{'loss': 0.014, 'grad_norm': 7.815840721130371, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.011361846700310707, 'loss_2': 0.002635955810546875, 'loss_3': -16.52138900756836, 'loss_4': -1.120147705078125, 'epoch': 22.84}
{'loss': 0.0057, 'grad_norm': 4.327227592468262, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.0031397531274706125, 'loss_2': 0.002532958984375, 'loss_3': -16.311664581298828, 'loss_4': -0.5437532663345337, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 13:57:39,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:39,198 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:36:58<21:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:57:46,522 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01903078891336918, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.226, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.016620049253106117, 'eval_loss_2': 0.0024107396602630615, 'eval_loss_3': -18.172496795654297, 'eval_loss_4': -0.6165245771408081, 'epoch': 22.85}
{'loss': 0.016, 'grad_norm': 5.15338659286499, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.009614214301109314, 'loss_2': 0.00638580322265625, 'loss_3': -16.408370971679688, 'loss_4': -0.7453919649124146, 'epoch': 22.85}
{'loss': 0.0111, 'grad_norm': 5.014282703399658, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.005354255437850952, 'loss_2': 0.00576019287109375, 'loss_3': -16.540266036987305, 'loss_4': -0.4747239947319031, 'epoch': 22.86}
{'loss': 0.0147, 'grad_norm': 5.768458843231201, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.012903342954814434, 'loss_2': 0.0018463134765625, 'loss_3': -16.3326358795166, 'loss_4': -0.7827035188674927, 'epoch': 22.87}
{'loss': 0.0084, 'grad_norm': 5.029082775115967, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.008001813665032387, 'loss_2': 0.0003840923309326172, 'loss_3': -16.53964614868164, 'loss_4': -0.635430634021759, 'epoch': 22.87}
{'loss': 0.0047, 'grad_norm': 4.800919532775879, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.0038816879969090223, 'loss_2': 0.0007762908935546875, 'loss_3': -16.476909637451172, 'loss_4': -0.3416813910007477, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 13:57:46,522 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:46,522 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:37:05<21:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:53,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017949046567082405, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.015067597851157188, 'eval_loss_2': 0.0028814487159252167, 'eval_loss_3': -18.18013572692871, 'eval_loss_4': -0.6566776037216187, 'epoch': 22.88}
{'loss': 0.0087, 'grad_norm': 5.994259834289551, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.006613542791455984, 'loss_2': 0.0020751953125, 'loss_3': -16.651973724365234, 'loss_4': -0.8797434568405151, 'epoch': 22.88}
{'loss': 0.0139, 'grad_norm': 6.003137588500977, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.009389849379658699, 'loss_2': 0.0045013427734375, 'loss_3': -16.491535186767578, 'loss_4': -0.48161864280700684, 'epoch': 22.89}
{'loss': 0.0059, 'grad_norm': 4.302469253540039, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.003018850926309824, 'loss_2': 0.00290679931640625, 'loss_3': -16.479135513305664, 'loss_4': -0.4989112913608551, 'epoch': 22.9}
{'loss': 0.0281, 'grad_norm': 13.153133392333984, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.0237160362303257, 'loss_2': 0.004367828369140625, 'loss_3': -16.397287368774414, 'loss_4': -0.24324925243854523, 'epoch': 22.9}
{'loss': 0.0064, 'grad_norm': 5.337045669555664, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.004268586169928312, 'loss_2': 0.002105712890625, 'loss_3': -16.602508544921875, 'loss_4': -0.4214093089103699, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 13:57:53,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:53,862 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:13<20:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:01,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01963159069418907, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.906, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.015604564920067787, 'eval_loss_2': 0.004027023911476135, 'eval_loss_3': -18.169021606445312, 'eval_loss_4': -0.6868578195571899, 'epoch': 22.91}
{'loss': 0.0211, 'grad_norm': 9.257092475891113, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.017683854326605797, 'loss_2': 0.0033740997314453125, 'loss_3': -16.40412139892578, 'loss_4': -0.8674612045288086, 'epoch': 22.91}
{'loss': 0.0052, 'grad_norm': 4.686532497406006, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.0051282490603625774, 'loss_2': 4.661083221435547e-05, 'loss_3': -16.602367401123047, 'loss_4': -0.5946652293205261, 'epoch': 22.92}
{'loss': 0.0138, 'grad_norm': 4.379039287567139, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.004514651373028755, 'loss_2': 0.009246826171875, 'loss_3': -16.566038131713867, 'loss_4': -0.6462778449058533, 'epoch': 22.92}
{'loss': 0.0329, 'grad_norm': 17.668628692626953, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.02645515650510788, 'loss_2': 0.00647735595703125, 'loss_3': -16.32485580444336, 'loss_4': -0.9720755815505981, 'epoch': 22.93}
{'loss': 0.0078, 'grad_norm': 4.709446430206299, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.0031525155063718557, 'loss_2': 0.0046539306640625, 'loss_3': -16.649250030517578, 'loss_4': -0.8427417278289795, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 13:58:01,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:01,190 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:20<20:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:08,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020105428993701935, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.116, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014997012913227081, 'eval_loss_2': 0.0051084160804748535, 'eval_loss_3': -18.175216674804688, 'eval_loss_4': -0.6689585447311401, 'epoch': 22.94}
{'loss': 0.0052, 'grad_norm': 5.489149570465088, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.005071267485618591, 'loss_2': 0.00015354156494140625, 'loss_3': -16.510053634643555, 'loss_4': 0.0938311368227005, 'epoch': 22.94}
{'loss': 0.0095, 'grad_norm': 4.808314800262451, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.007173962891101837, 'loss_2': 0.002361297607421875, 'loss_3': -16.38210105895996, 'loss_4': -0.8424572944641113, 'epoch': 22.95}
{'loss': 0.0166, 'grad_norm': 5.331912040710449, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.006552658975124359, 'loss_2': 0.010009765625, 'loss_3': -16.48003387451172, 'loss_4': -0.7797995209693909, 'epoch': 22.95}
{'loss': 0.0073, 'grad_norm': 4.44921350479126, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.005316645838320255, 'loss_2': 0.0019664764404296875, 'loss_3': -16.492908477783203, 'loss_4': -0.42802655696868896, 'epoch': 22.96}
{'loss': 0.0091, 'grad_norm': 4.8667988777160645, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.004282256588339806, 'loss_2': 0.004795074462890625, 'loss_3': -16.389413833618164, 'loss_4': -0.967724621295929, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 13:58:08,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:08,520 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:27<20:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:58:15,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020453978329896927, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.062, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.015747597441077232, 'eval_loss_2': 0.004706382751464844, 'eval_loss_3': -18.160541534423828, 'eval_loss_4': -0.6692605018615723, 'epoch': 22.97}
{'loss': 0.0242, 'grad_norm': 6.277560234069824, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.014623066410422325, 'loss_2': 0.00962066650390625, 'loss_3': -16.664897918701172, 'loss_4': -0.7477197647094727, 'epoch': 22.97}
{'loss': 0.0224, 'grad_norm': 10.077363967895508, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.019892780110239983, 'loss_2': 0.0024890899658203125, 'loss_3': -16.366886138916016, 'loss_4': -0.6604698896408081, 'epoch': 22.98}
{'loss': 0.0106, 'grad_norm': 5.141567230224609, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.007385568227618933, 'loss_2': 0.00316619873046875, 'loss_3': -16.591537475585938, 'loss_4': -0.4356752932071686, 'epoch': 22.98}
{'loss': 0.0105, 'grad_norm': 4.808183193206787, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.008521415293216705, 'loss_2': 0.00201416015625, 'loss_3': -16.51676368713379, 'loss_4': -0.7746322751045227, 'epoch': 22.99}
{'loss': 0.0175, 'grad_norm': 10.16506290435791, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.015179194509983063, 'loss_2': 0.0023345947265625, 'loss_3': -16.636356353759766, 'loss_4': -1.0235788822174072, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 13:58:15,832 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:15,832 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:34<20:17,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:58:22,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020901909098029137, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.907, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01684211753308773, 'eval_loss_2': 0.004059791564941406, 'eval_loss_3': -18.159774780273438, 'eval_loss_4': -0.7202328443527222, 'epoch': 22.99}
{'loss': 0.0115, 'grad_norm': 6.929742336273193, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.005796986632049084, 'loss_2': 0.005695343017578125, 'loss_3': -16.115503311157227, 'loss_4': -1.1766406297683716, 'epoch': 23.0}
{'loss': 0.0135, 'grad_norm': 4.979115962982178, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.005127135664224625, 'loss_2': 0.00835418701171875, 'loss_3': -16.5394287109375, 'loss_4': -0.5976133346557617, 'epoch': 23.01}
{'loss': 0.0108, 'grad_norm': 5.588389873504639, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.008582540787756443, 'loss_2': 0.0022220611572265625, 'loss_3': -16.60672378540039, 'loss_4': -0.9762639999389648, 'epoch': 23.01}
{'loss': 0.0086, 'grad_norm': 5.470613956451416, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.006005812436342239, 'loss_2': 0.002544403076171875, 'loss_3': -16.409761428833008, 'loss_4': -0.3611728549003601, 'epoch': 23.02}
{'loss': 0.0083, 'grad_norm': 4.92738151550293, 'learning_rate': 7e-06, 'loss_1': 0.004451696295291185, 'loss_2': 0.0038967132568359375, 'loss_3': -16.44477653503418, 'loss_4': -0.772585391998291, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 13:58:22,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:22,868 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:42<20:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:58:30,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01994185708463192, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.063, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.016911646351218224, 'eval_loss_2': 0.0030302107334136963, 'eval_loss_3': -18.146921157836914, 'eval_loss_4': -0.7533308267593384, 'epoch': 23.02}
{'loss': 0.016, 'grad_norm': 8.320829391479492, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.013050626963376999, 'loss_2': 0.00298309326171875, 'loss_3': -16.536846160888672, 'loss_4': -0.3489912152290344, 'epoch': 23.03}
{'loss': 0.012, 'grad_norm': 6.6680908203125, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.010409119538962841, 'loss_2': 0.0015802383422851562, 'loss_3': -16.541675567626953, 'loss_4': -0.7164396047592163, 'epoch': 23.03}
{'loss': 0.0102, 'grad_norm': 5.76172399520874, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.006011744029819965, 'loss_2': 0.004215240478515625, 'loss_3': -16.53508949279785, 'loss_4': -0.7286776304244995, 'epoch': 23.04}
{'loss': 0.0152, 'grad_norm': 6.468499660491943, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.012211618945002556, 'loss_2': 0.0029621124267578125, 'loss_3': -16.219486236572266, 'loss_4': -0.5355451703071594, 'epoch': 23.05}
{'loss': 0.007, 'grad_norm': 4.587550640106201, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.0035041728988289833, 'loss_2': 0.003448486328125, 'loss_3': -16.518863677978516, 'loss_4': -0.6118756532669067, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 13:58:30,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:30,200 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:49<20:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:37,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021471165120601654, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.138, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.017932554706931114, 'eval_loss_2': 0.0035386085510253906, 'eval_loss_3': -18.144968032836914, 'eval_loss_4': -0.7600421905517578, 'epoch': 23.05}
{'loss': 0.0092, 'grad_norm': 4.439245223999023, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.005166235845535994, 'loss_2': 0.0040283203125, 'loss_3': -16.724580764770508, 'loss_4': -0.20855340361595154, 'epoch': 23.06}
{'loss': 0.0085, 'grad_norm': 4.149193286895752, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.004767400212585926, 'loss_2': 0.003772735595703125, 'loss_3': -16.526355743408203, 'loss_4': -0.4978868365287781, 'epoch': 23.06}
{'loss': 0.0127, 'grad_norm': 4.952572822570801, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.0040873149409890175, 'loss_2': 0.0085906982421875, 'loss_3': -16.46328353881836, 'loss_4': -0.6030182242393494, 'epoch': 23.07}
{'loss': 0.0117, 'grad_norm': 7.339575290679932, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.011381746269762516, 'loss_2': 0.0002925395965576172, 'loss_3': -16.44910430908203, 'loss_4': -0.724382221698761, 'epoch': 23.08}
{'loss': 0.0129, 'grad_norm': 5.2172465324401855, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.008388831280171871, 'loss_2': 0.00449371337890625, 'loss_3': -16.5457763671875, 'loss_4': -0.6331571340560913, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 13:58:37,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:37,546 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:37:56<20:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:44,883 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022387538105249405, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.818, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01881820522248745, 'eval_loss_2': 0.0035693347454071045, 'eval_loss_3': -18.141048431396484, 'eval_loss_4': -0.7258403301239014, 'epoch': 23.08}
{'loss': 0.013, 'grad_norm': 5.024704933166504, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.003474536584690213, 'loss_2': 0.00949859619140625, 'loss_3': -16.54615592956543, 'loss_4': -0.7670208811759949, 'epoch': 23.09}
{'loss': 0.0102, 'grad_norm': 4.968396186828613, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.01000578235834837, 'loss_2': 0.00023877620697021484, 'loss_3': -16.355607986450195, 'loss_4': -0.5777099132537842, 'epoch': 23.09}
{'loss': 0.0078, 'grad_norm': 4.9235405921936035, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.006406198721379042, 'loss_2': 0.0013608932495117188, 'loss_3': -16.561481475830078, 'loss_4': -0.925778865814209, 'epoch': 23.1}
{'loss': 0.0067, 'grad_norm': 4.893809795379639, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.004203491378575563, 'loss_2': 0.00252532958984375, 'loss_3': -16.553050994873047, 'loss_4': -0.5858404636383057, 'epoch': 23.1}
{'loss': 0.0187, 'grad_norm': 5.941096782684326, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.009263250976800919, 'loss_2': 0.0093994140625, 'loss_3': -16.452167510986328, 'loss_4': -1.2562406063079834, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 13:58:44,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:44,883 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:38:04<20:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:52,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022263573482632637, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.933, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.018807748332619667, 'eval_loss_2': 0.00345582515001297, 'eval_loss_3': -18.139488220214844, 'eval_loss_4': -0.6305049657821655, 'epoch': 23.11}
{'loss': 0.0087, 'grad_norm': 4.965393543243408, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.006026621907949448, 'loss_2': 0.002704620361328125, 'loss_3': -16.364171981811523, 'loss_4': -1.0437543392181396, 'epoch': 23.12}
{'loss': 0.0086, 'grad_norm': 5.444372653961182, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.004907389637082815, 'loss_2': 0.003719329833984375, 'loss_3': -16.651710510253906, 'loss_4': -0.6293015480041504, 'epoch': 23.12}
{'loss': 0.0068, 'grad_norm': 4.367745399475098, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.0040558092296123505, 'loss_2': 0.0027713775634765625, 'loss_3': -16.598602294921875, 'loss_4': -0.22781556844711304, 'epoch': 23.13}
{'loss': 0.0188, 'grad_norm': 6.3812971115112305, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.016425156965851784, 'loss_2': 0.0023956298828125, 'loss_3': -16.31729507446289, 'loss_4': -0.3671538829803467, 'epoch': 23.13}
{'loss': 0.0763, 'grad_norm': 25.568363189697266, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.07471133023500443, 'loss_2': 0.0016345977783203125, 'loss_3': -16.240209579467773, 'loss_4': -0.4336520731449127, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 13:58:52,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:52,217 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:11<20:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:59,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02034500241279602, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.357, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01764354109764099, 'eval_loss_2': 0.0027014613151550293, 'eval_loss_3': -18.14004898071289, 'eval_loss_4': -0.5467337369918823, 'epoch': 23.14}
{'loss': 0.0149, 'grad_norm': 7.775156497955322, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.008254806511104107, 'loss_2': 0.006671905517578125, 'loss_3': -16.577415466308594, 'loss_4': -0.30813688039779663, 'epoch': 23.15}
{'loss': 0.0091, 'grad_norm': 4.8809638023376465, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.006779784336686134, 'loss_2': 0.002361297607421875, 'loss_3': -16.590740203857422, 'loss_4': -0.9984124898910522, 'epoch': 23.15}
{'loss': 0.0123, 'grad_norm': 5.276808738708496, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.00726323714479804, 'loss_2': 0.00502777099609375, 'loss_3': -16.32863426208496, 'loss_4': -0.585719108581543, 'epoch': 23.16}
{'loss': 0.0069, 'grad_norm': 5.231255531311035, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.0056860377080738544, 'loss_2': 0.00125885009765625, 'loss_3': -16.523454666137695, 'loss_4': -0.5300233960151672, 'epoch': 23.16}
{'loss': 0.0218, 'grad_norm': 12.210737228393555, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.021311825141310692, 'loss_2': 0.0005350112915039062, 'loss_3': -16.272756576538086, 'loss_4': -0.5143182277679443, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 13:58:59,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:59,546 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:18<20:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:06,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019476570188999176, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.164, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016068361699581146, 'eval_loss_2': 0.00340820848941803, 'eval_loss_3': -18.15549659729004, 'eval_loss_4': -0.5830907821655273, 'epoch': 23.17}
{'loss': 0.0123, 'grad_norm': 5.941957950592041, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.0075921546667814255, 'loss_2': 0.004673004150390625, 'loss_3': -16.502277374267578, 'loss_4': -0.3614751398563385, 'epoch': 23.17}
{'loss': 0.013, 'grad_norm': 4.646516799926758, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.007202467881143093, 'loss_2': 0.00576019287109375, 'loss_3': -16.418262481689453, 'loss_4': -0.15769577026367188, 'epoch': 23.18}
{'loss': 0.0133, 'grad_norm': 5.74751615524292, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.01306446734815836, 'loss_2': 0.0002522468566894531, 'loss_3': -16.617748260498047, 'loss_4': -0.7230539321899414, 'epoch': 23.19}
{'loss': 0.0049, 'grad_norm': 4.499269485473633, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.0046862950548529625, 'loss_2': 0.00018453598022460938, 'loss_3': -16.433422088623047, 'loss_4': -0.6546351313591003, 'epoch': 23.19}
{'loss': 0.0029, 'grad_norm': 4.632763862609863, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.002441331511363387, 'loss_2': 0.0004506111145019531, 'loss_3': -16.517559051513672, 'loss_4': -0.4768538475036621, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 13:59:06,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:06,874 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:26<20:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:14,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019572097808122635, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01654871366918087, 'eval_loss_2': 0.003023386001586914, 'eval_loss_3': -18.162569046020508, 'eval_loss_4': -0.63521409034729, 'epoch': 23.2}
{'loss': 0.0093, 'grad_norm': 5.8268303871154785, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.00893213227391243, 'loss_2': 0.000331878662109375, 'loss_3': -16.577085494995117, 'loss_4': -0.6359173059463501, 'epoch': 23.2}
{'loss': 0.0109, 'grad_norm': 4.59325647354126, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.003991971258074045, 'loss_2': 0.00693511962890625, 'loss_3': -16.458110809326172, 'loss_4': -0.5326547622680664, 'epoch': 23.21}
{'loss': 0.0189, 'grad_norm': 11.430262565612793, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.014763535931706429, 'loss_2': 0.00412750244140625, 'loss_3': -16.55222511291504, 'loss_4': -0.3871821165084839, 'epoch': 23.22}
{'loss': 0.0119, 'grad_norm': 5.164576530456543, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.008158662356436253, 'loss_2': 0.003726959228515625, 'loss_3': -16.522380828857422, 'loss_4': -0.5622660517692566, 'epoch': 23.22}
{'loss': 0.0061, 'grad_norm': 4.759225845336914, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.004874544683843851, 'loss_2': 0.0011806488037109375, 'loss_3': -16.5178165435791, 'loss_4': -0.39377954602241516, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 13:59:14,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:14,216 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:33<20:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:21,549 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0196708794683218, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016895925626158714, 'eval_loss_2': 0.002774953842163086, 'eval_loss_3': -18.16053009033203, 'eval_loss_4': -0.6022384166717529, 'epoch': 23.23}
{'loss': 0.018, 'grad_norm': 7.445217132568359, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.010091612115502357, 'loss_2': 0.0078887939453125, 'loss_3': -16.4732666015625, 'loss_4': -0.6861823797225952, 'epoch': 23.23}
{'loss': 0.0047, 'grad_norm': 4.640264987945557, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.004451087210327387, 'loss_2': 0.0002570152282714844, 'loss_3': -16.434350967407227, 'loss_4': -0.49754446744918823, 'epoch': 23.24}
{'loss': 0.0109, 'grad_norm': 4.930288314819336, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.004292473196983337, 'loss_2': 0.00665283203125, 'loss_3': -16.561092376708984, 'loss_4': -0.47019487619400024, 'epoch': 23.24}
{'loss': 0.0096, 'grad_norm': 5.343474388122559, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.0069387806579470634, 'loss_2': 0.0027008056640625, 'loss_3': -16.656206130981445, 'loss_4': -0.7313288450241089, 'epoch': 23.25}
{'loss': 0.0085, 'grad_norm': 4.39069128036499, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.004489859100431204, 'loss_2': 0.0039825439453125, 'loss_3': -16.594877243041992, 'loss_4': -0.6924697756767273, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 13:59:21,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:21,549 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:40<19:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:59:28,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019923696294426918, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.349, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.017091896384954453, 'eval_loss_2': 0.0028317980468273163, 'eval_loss_3': -18.168121337890625, 'eval_loss_4': -0.5055710077285767, 'epoch': 23.26}
{'loss': 0.0073, 'grad_norm': 4.974643230438232, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.004419439006596804, 'loss_2': 0.002902984619140625, 'loss_3': -16.482227325439453, 'loss_4': -0.6607145071029663, 'epoch': 23.26}
{'loss': 0.0146, 'grad_norm': 8.766698837280273, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.013000650331377983, 'loss_2': 0.0015716552734375, 'loss_3': -16.364789962768555, 'loss_4': -0.7242031693458557, 'epoch': 23.27}
{'loss': 0.0123, 'grad_norm': 5.2869462966918945, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.006885266862809658, 'loss_2': 0.005451202392578125, 'loss_3': -16.679180145263672, 'loss_4': -0.32863593101501465, 'epoch': 23.27}
{'loss': 0.0077, 'grad_norm': 6.186734676361084, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.0071792989037930965, 'loss_2': 0.0005168914794921875, 'loss_3': -16.567115783691406, 'loss_4': -0.8433260917663574, 'epoch': 23.28}
{'loss': 0.0207, 'grad_norm': 6.805550575256348, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.01258254423737526, 'loss_2': 0.008148193359375, 'loss_3': -16.59255027770996, 'loss_4': -0.555924654006958, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 13:59:28,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:28,873 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:48<19:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:36,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0210503488779068, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.546, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.018126649782061577, 'eval_loss_2': 0.0029236972332000732, 'eval_loss_3': -18.160480499267578, 'eval_loss_4': -0.3821682631969452, 'epoch': 23.28}
{'loss': 0.0063, 'grad_norm': 4.974164962768555, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.005562846083194017, 'loss_2': 0.0007333755493164062, 'loss_3': -16.547502517700195, 'loss_4': 0.10459449142217636, 'epoch': 23.29}
{'loss': 0.0222, 'grad_norm': 16.92093849182129, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.021023238077759743, 'loss_2': 0.001194000244140625, 'loss_3': -16.204814910888672, 'loss_4': -0.30252665281295776, 'epoch': 23.3}
{'loss': 0.0051, 'grad_norm': 4.4179582595825195, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.0023081789258867502, 'loss_2': 0.0027637481689453125, 'loss_3': -16.25464630126953, 'loss_4': -0.05832601338624954, 'epoch': 23.3}
{'loss': 0.006, 'grad_norm': 5.322852611541748, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.004347857553511858, 'loss_2': 0.0016469955444335938, 'loss_3': -16.625959396362305, 'loss_4': -0.46069636940956116, 'epoch': 23.31}
{'loss': 0.0056, 'grad_norm': 5.198668003082275, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.004821796901524067, 'loss_2': 0.0007891654968261719, 'loss_3': -16.49443244934082, 'loss_4': -0.6105086803436279, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 13:59:36,196 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:36,196 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:38:55<19:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:43,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02129966765642166, 'eval_runtime': 3.7887, 'eval_samples_per_second': 270.278, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01804520934820175, 'eval_loss_2': 0.0032544583082199097, 'eval_loss_3': -18.148969650268555, 'eval_loss_4': -0.32497161626815796, 'epoch': 23.31}
{'loss': 0.0084, 'grad_norm': 5.896059036254883, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.007268945220857859, 'loss_2': 0.001178741455078125, 'loss_3': -16.571441650390625, 'loss_4': 0.04729312285780907, 'epoch': 23.32}
{'loss': 0.0101, 'grad_norm': 5.685173988342285, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.008664350025355816, 'loss_2': 0.0014295578002929688, 'loss_3': -16.587329864501953, 'loss_4': -0.7379584908485413, 'epoch': 23.33}
{'loss': 0.0088, 'grad_norm': 5.503560543060303, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.006057314574718475, 'loss_2': 0.002727508544921875, 'loss_3': -16.503578186035156, 'loss_4': -0.39059722423553467, 'epoch': 23.33}
{'loss': 0.0095, 'grad_norm': 5.525424480438232, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.007262538652867079, 'loss_2': 0.0022029876708984375, 'loss_3': -16.517927169799805, 'loss_4': -0.209206223487854, 'epoch': 23.34}
{'loss': 0.0066, 'grad_norm': 4.847620010375977, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.005694475024938583, 'loss_2': 0.0009360313415527344, 'loss_3': -16.64870834350586, 'loss_4': -0.3036334812641144, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 13:59:43,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:43,521 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:39:02<19:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:50,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02211323380470276, 'eval_runtime': 3.7902, 'eval_samples_per_second': 270.17, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.017990589141845703, 'eval_loss_2': 0.004122644662857056, 'eval_loss_3': -18.14043426513672, 'eval_loss_4': -0.30888012051582336, 'epoch': 23.34}
{'loss': 0.0096, 'grad_norm': 5.630380630493164, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.003217093413695693, 'loss_2': 0.006359100341796875, 'loss_3': -16.610933303833008, 'loss_4': -0.19068342447280884, 'epoch': 23.35}
{'loss': 0.0091, 'grad_norm': 6.084625720977783, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.005870387423783541, 'loss_2': 0.00327301025390625, 'loss_3': -16.63959312438965, 'loss_4': -0.932805061340332, 'epoch': 23.35}
{'loss': 0.0088, 'grad_norm': 5.192836761474609, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.004826600197702646, 'loss_2': 0.003978729248046875, 'loss_3': -16.46251678466797, 'loss_4': -0.3094868063926697, 'epoch': 23.36}
{'loss': 0.0105, 'grad_norm': 5.002435207366943, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.005334820598363876, 'loss_2': 0.00516510009765625, 'loss_3': -16.674015045166016, 'loss_4': -0.3103810250759125, 'epoch': 23.37}
{'loss': 0.0142, 'grad_norm': 5.141792297363281, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.0077215987257659435, 'loss_2': 0.006504058837890625, 'loss_3': -16.523433685302734, 'loss_4': -0.32371005415916443, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 13:59:50,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:50,851 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:10<19:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:59:58,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021240169182419777, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.133, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016924286261200905, 'eval_loss_2': 0.004315882921218872, 'eval_loss_3': -18.144702911376953, 'eval_loss_4': -0.2663469910621643, 'epoch': 23.37}
{'loss': 0.0138, 'grad_norm': 10.075034141540527, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.013100910931825638, 'loss_2': 0.0007190704345703125, 'loss_3': -16.38005828857422, 'loss_4': -0.25745242834091187, 'epoch': 23.38}
{'loss': 0.0098, 'grad_norm': 4.854526996612549, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.006374042015522718, 'loss_2': 0.00345611572265625, 'loss_3': -16.47423553466797, 'loss_4': -0.01797865331172943, 'epoch': 23.38}
{'loss': 0.007, 'grad_norm': 4.790581703186035, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.004050001967698336, 'loss_2': 0.002910614013671875, 'loss_3': -16.542957305908203, 'loss_4': -0.21479880809783936, 'epoch': 23.39}
{'loss': 0.016, 'grad_norm': 5.103936195373535, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.009267168119549751, 'loss_2': 0.00669097900390625, 'loss_3': -16.32504653930664, 'loss_4': -0.24482636153697968, 'epoch': 23.4}
{'loss': 0.0122, 'grad_norm': 5.165127277374268, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.00703654158860445, 'loss_2': 0.005123138427734375, 'loss_3': -16.32780647277832, 'loss_4': -0.04108595848083496, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 13:59:58,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:58,179 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:17<19:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:05,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021137366071343422, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.347, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01742486096918583, 'eval_loss_2': 0.0037125051021575928, 'eval_loss_3': -18.157508850097656, 'eval_loss_4': -0.21704727411270142, 'epoch': 23.4}
{'loss': 0.0079, 'grad_norm': 5.221062183380127, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.005889663938432932, 'loss_2': 0.0020236968994140625, 'loss_3': -16.620569229125977, 'loss_4': 0.4928775429725647, 'epoch': 23.41}
{'loss': 0.0102, 'grad_norm': 4.962472438812256, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.00585574097931385, 'loss_2': 0.004367828369140625, 'loss_3': -16.548381805419922, 'loss_4': 0.028213530778884888, 'epoch': 23.41}
{'loss': 0.0051, 'grad_norm': 4.767801761627197, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.004140056204050779, 'loss_2': 0.0009398460388183594, 'loss_3': -16.485443115234375, 'loss_4': 0.44257527589797974, 'epoch': 23.42}
{'loss': 0.0039, 'grad_norm': 4.873197555541992, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.002095394069328904, 'loss_2': 0.0018529891967773438, 'loss_3': -16.650894165039062, 'loss_4': -0.21886788308620453, 'epoch': 23.42}
{'loss': 0.0062, 'grad_norm': 4.657127857208252, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.0030478702392429113, 'loss_2': 0.0031795501708984375, 'loss_3': -16.448184967041016, 'loss_4': -0.3572278618812561, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 14:00:05,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:05,506 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:24<19:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:00:12,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019562508910894394, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.115, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.016208583489060402, 'eval_loss_2': 0.0033539235591888428, 'eval_loss_3': -18.161495208740234, 'eval_loss_4': -0.2483125776052475, 'epoch': 23.43}
{'loss': 0.0133, 'grad_norm': 5.647763252258301, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.007660326082259417, 'loss_2': 0.005645751953125, 'loss_3': -16.426076889038086, 'loss_4': -0.5432007908821106, 'epoch': 23.44}
{'loss': 0.0135, 'grad_norm': 4.485673904418945, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.004021975211799145, 'loss_2': 0.00943756103515625, 'loss_3': -16.425527572631836, 'loss_4': -0.8202780485153198, 'epoch': 23.44}
{'loss': 0.0097, 'grad_norm': 4.811705589294434, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.005048150662332773, 'loss_2': 0.00467681884765625, 'loss_3': -16.501996994018555, 'loss_4': -0.05290225148200989, 'epoch': 23.45}
{'loss': 0.0068, 'grad_norm': 4.664121627807617, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.0038851401768624783, 'loss_2': 0.0029144287109375, 'loss_3': -16.55729866027832, 'loss_4': -0.4593592882156372, 'epoch': 23.45}
{'loss': 0.0086, 'grad_norm': 5.404654502868652, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.007518340367823839, 'loss_2': 0.001094818115234375, 'loss_3': -16.299518585205078, 'loss_4': -0.4819434881210327, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 14:00:12,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:12,829 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:32<19:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:00:20,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018441159278154373, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.579, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01536700502038002, 'eval_loss_2': 0.003074154257774353, 'eval_loss_3': -18.17533302307129, 'eval_loss_4': -0.3241676688194275, 'epoch': 23.46}
{'loss': 0.0059, 'grad_norm': 5.032137393951416, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.004751234780997038, 'loss_2': 0.0011148452758789062, 'loss_3': -16.465944290161133, 'loss_4': -0.46039074659347534, 'epoch': 23.47}
{'loss': 0.046, 'grad_norm': 25.424976348876953, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.04499928653240204, 'loss_2': 0.0009679794311523438, 'loss_3': -16.586872100830078, 'loss_4': -0.422288715839386, 'epoch': 23.47}
{'loss': 0.0094, 'grad_norm': 4.629523277282715, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.003141628112643957, 'loss_2': 0.00621795654296875, 'loss_3': -16.489765167236328, 'loss_4': -0.47057709097862244, 'epoch': 23.48}
{'loss': 0.0145, 'grad_norm': 6.09993839263916, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.011726600117981434, 'loss_2': 0.00281524658203125, 'loss_3': -16.67959213256836, 'loss_4': -0.4993310868740082, 'epoch': 23.48}
{'loss': 0.0232, 'grad_norm': 7.363022804260254, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.017487185075879097, 'loss_2': 0.005748748779296875, 'loss_3': -16.51167106628418, 'loss_4': -0.816936194896698, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 14:00:20,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:20,150 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:39<19:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:27,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018813876435160637, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.489, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015204319730401039, 'eval_loss_2': 0.0036095567047595978, 'eval_loss_3': -18.1865234375, 'eval_loss_4': -0.36427831649780273, 'epoch': 23.49}
{'loss': 0.0123, 'grad_norm': 6.357502460479736, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.008129056543111801, 'loss_2': 0.0041961669921875, 'loss_3': -16.366350173950195, 'loss_4': -0.3131270110607147, 'epoch': 23.49}
{'loss': 0.0147, 'grad_norm': 6.398569107055664, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.013010190799832344, 'loss_2': 0.0017366409301757812, 'loss_3': -16.398399353027344, 'loss_4': -0.39918389916419983, 'epoch': 23.5}
{'loss': 0.0122, 'grad_norm': 5.112507343292236, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.0049614571034908295, 'loss_2': 0.00719451904296875, 'loss_3': -16.53986930847168, 'loss_4': -0.34505194425582886, 'epoch': 23.51}
{'loss': 0.004, 'grad_norm': 4.920791149139404, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.00305948150344193, 'loss_2': 0.0009717941284179688, 'loss_3': -16.62973403930664, 'loss_4': -0.5643625259399414, 'epoch': 23.51}
{'loss': 0.0153, 'grad_norm': 10.431385040283203, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.014396961778402328, 'loss_2': 0.0008831024169921875, 'loss_3': -16.4268856048584, 'loss_4': -0.5250116586685181, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 14:00:27,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:27,472 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:46<19:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:34,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016729921102523804, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.019, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013336287811398506, 'eval_loss_2': 0.0033936351537704468, 'eval_loss_3': -18.18511199951172, 'eval_loss_4': -0.37148505449295044, 'epoch': 23.52}
{'loss': 0.0128, 'grad_norm': 4.709324359893799, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.012128819711506367, 'loss_2': 0.000705718994140625, 'loss_3': -16.430261611938477, 'loss_4': -0.49534881114959717, 'epoch': 23.52}
{'loss': 0.0054, 'grad_norm': 4.829873085021973, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.004083535168319941, 'loss_2': 0.001354217529296875, 'loss_3': -16.460783004760742, 'loss_4': -0.6129800081253052, 'epoch': 23.53}
{'loss': 0.0181, 'grad_norm': 8.070233345031738, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.016966212540864944, 'loss_2': 0.0011386871337890625, 'loss_3': -16.49566078186035, 'loss_4': -0.28782573342323303, 'epoch': 23.53}
{'loss': 0.0082, 'grad_norm': 5.49213171005249, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.007658868562430143, 'loss_2': 0.0005464553833007812, 'loss_3': -16.55112075805664, 'loss_4': -0.08049828559160233, 'epoch': 23.54}
{'loss': 0.0066, 'grad_norm': 4.602775573730469, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.00529190618544817, 'loss_2': 0.0013484954833984375, 'loss_3': -16.540573120117188, 'loss_4': -0.550629734992981, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 14:00:34,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:34,807 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:39:54<19:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:00:42,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01722918637096882, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.824, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013639097101986408, 'eval_loss_2': 0.003590088337659836, 'eval_loss_3': -18.18230628967285, 'eval_loss_4': -0.4195183515548706, 'epoch': 23.55}
{'loss': 0.0091, 'grad_norm': 4.8226704597473145, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.0072461385279893875, 'loss_2': 0.0018529891967773438, 'loss_3': -16.325138092041016, 'loss_4': -0.17095759510993958, 'epoch': 23.55}
{'loss': 0.0059, 'grad_norm': 4.667234897613525, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.0051643322221934795, 'loss_2': 0.0007476806640625, 'loss_3': -16.63718605041504, 'loss_4': -0.2861638069152832, 'epoch': 23.56}
{'loss': 0.0064, 'grad_norm': 4.859835147857666, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.004019606858491898, 'loss_2': 0.0024166107177734375, 'loss_3': -16.604629516601562, 'loss_4': -0.25656628608703613, 'epoch': 23.56}
{'loss': 0.008, 'grad_norm': 5.085179328918457, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.005690464749932289, 'loss_2': 0.0023021697998046875, 'loss_3': -16.487415313720703, 'loss_4': -0.3591137230396271, 'epoch': 23.57}
{'loss': 0.0136, 'grad_norm': 5.233242511749268, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.0057914662174880505, 'loss_2': 0.0078125, 'loss_3': -16.495777130126953, 'loss_4': 0.22255288064479828, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 14:00:42,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:42,130 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:40:01<18:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:00:49,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019094722345471382, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.348, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015247121453285217, 'eval_loss_2': 0.0038475990295410156, 'eval_loss_3': -18.17388343811035, 'eval_loss_4': -0.4375825822353363, 'epoch': 23.58}
{'loss': 0.0105, 'grad_norm': 4.8894219398498535, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.004250799305737019, 'loss_2': 0.006206512451171875, 'loss_3': -16.522315979003906, 'loss_4': -0.012678593397140503, 'epoch': 23.58}
{'loss': 0.0113, 'grad_norm': 7.057906150817871, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.006914989091455936, 'loss_2': 0.00437164306640625, 'loss_3': -16.46929931640625, 'loss_4': -0.3762543499469757, 'epoch': 23.59}
{'loss': 0.0036, 'grad_norm': 4.691047191619873, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.002526261145249009, 'loss_2': 0.0011119842529296875, 'loss_3': -16.615093231201172, 'loss_4': -0.3840079605579376, 'epoch': 23.59}
{'loss': 0.0177, 'grad_norm': 9.171979904174805, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.012660355307161808, 'loss_2': 0.005008697509765625, 'loss_3': -16.477035522460938, 'loss_4': -0.16686144471168518, 'epoch': 23.6}
{'loss': 0.0123, 'grad_norm': 4.987637042999268, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.004633069038391113, 'loss_2': 0.0076904296875, 'loss_3': -16.618785858154297, 'loss_4': -0.4399583339691162, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 14:00:49,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:49,450 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:08<18:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:00:56,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020226428285241127, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.446, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.016843553632497787, 'eval_loss_2': 0.0033828765153884888, 'eval_loss_3': -18.175750732421875, 'eval_loss_4': -0.44231081008911133, 'epoch': 23.6}
{'loss': 0.0219, 'grad_norm': 7.15712308883667, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.019886218011379242, 'loss_2': 0.001979827880859375, 'loss_3': -16.448949813842773, 'loss_4': -0.0749981477856636, 'epoch': 23.61}
{'loss': 0.0071, 'grad_norm': 4.845264434814453, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.005953738000243902, 'loss_2': 0.0011234283447265625, 'loss_3': -16.490150451660156, 'loss_4': -0.46975553035736084, 'epoch': 23.62}
{'loss': 0.005, 'grad_norm': 4.355409145355225, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.004035499412566423, 'loss_2': 0.0009889602661132812, 'loss_3': -16.50444793701172, 'loss_4': -0.454292893409729, 'epoch': 23.62}
{'loss': 0.0055, 'grad_norm': 5.220883369445801, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.004837170243263245, 'loss_2': 0.0006437301635742188, 'loss_3': -16.318313598632812, 'loss_4': -0.1720513105392456, 'epoch': 23.63}
{'loss': 0.0137, 'grad_norm': 7.993625164031982, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.008908837102353573, 'loss_2': 0.004779815673828125, 'loss_3': -16.56309700012207, 'loss_4': -0.6232337951660156, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 14:00:56,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:56,770 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:16<18:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:01:04,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018548214808106422, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.429, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015489652752876282, 'eval_loss_2': 0.0030585601925849915, 'eval_loss_3': -18.180133819580078, 'eval_loss_4': -0.46949511766433716, 'epoch': 23.63}
{'loss': 0.0211, 'grad_norm': 7.389200210571289, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.014388646930456161, 'loss_2': 0.00667572021484375, 'loss_3': -16.469375610351562, 'loss_4': -0.6254351139068604, 'epoch': 23.64}
{'loss': 0.0065, 'grad_norm': 4.951852321624756, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.006090944167226553, 'loss_2': 0.00044155120849609375, 'loss_3': -16.384624481201172, 'loss_4': -0.46108219027519226, 'epoch': 23.65}
{'loss': 0.02, 'grad_norm': 10.527956008911133, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.019263358786702156, 'loss_2': 0.0007452964782714844, 'loss_3': -16.430879592895508, 'loss_4': -0.4594890773296356, 'epoch': 23.65}
{'loss': 0.013, 'grad_norm': 5.962452411651611, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.010561098344624043, 'loss_2': 0.0024261474609375, 'loss_3': -16.488109588623047, 'loss_4': -0.4056392312049866, 'epoch': 23.66}
{'loss': 0.0089, 'grad_norm': 4.673742294311523, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.004083564039319754, 'loss_2': 0.004810333251953125, 'loss_3': -16.518707275390625, 'loss_4': -0.7741580605506897, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 14:01:04,094 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:04,094 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:23<18:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:11,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017882732674479485, 'eval_runtime': 3.7866, 'eval_samples_per_second': 270.426, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.014606758952140808, 'eval_loss_2': 0.0032759755849838257, 'eval_loss_3': -18.185365676879883, 'eval_loss_4': -0.49941927194595337, 'epoch': 23.66}
{'loss': 0.013, 'grad_norm': 5.408393383026123, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.00774393230676651, 'loss_2': 0.005290985107421875, 'loss_3': -16.431716918945312, 'loss_4': -0.3935111165046692, 'epoch': 23.67}
{'loss': 0.0114, 'grad_norm': 4.886877059936523, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.008719789795577526, 'loss_2': 0.0027103424072265625, 'loss_3': -16.490846633911133, 'loss_4': -0.485892653465271, 'epoch': 23.67}
{'loss': 0.0181, 'grad_norm': 5.652153491973877, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.01123092882335186, 'loss_2': 0.006900787353515625, 'loss_3': -16.571138381958008, 'loss_4': -0.5294488668441772, 'epoch': 23.68}
{'loss': 0.0167, 'grad_norm': 5.114819526672363, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.005118453409522772, 'loss_2': 0.01157379150390625, 'loss_3': -16.622112274169922, 'loss_4': -0.05028975009918213, 'epoch': 23.69}
{'loss': 0.0095, 'grad_norm': 5.704238414764404, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.008355116471648216, 'loss_2': 0.0011844635009765625, 'loss_3': -16.358232498168945, 'loss_4': -0.14764729142189026, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 14:01:11,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:11,420 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:30<18:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:18,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017148351296782494, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.937, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.013863224536180496, 'eval_loss_2': 0.003285124897956848, 'eval_loss_3': -18.1867733001709, 'eval_loss_4': -0.5560436248779297, 'epoch': 23.69}
{'loss': 0.0039, 'grad_norm': 4.332457542419434, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.0035649766214191914, 'loss_2': 0.0002942085266113281, 'loss_3': -16.48442840576172, 'loss_4': -0.7549914121627808, 'epoch': 23.7}
{'loss': 0.0059, 'grad_norm': 4.646081924438477, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.004485270474106073, 'loss_2': 0.0014104843139648438, 'loss_3': -16.612932205200195, 'loss_4': -0.6734658479690552, 'epoch': 23.7}
{'loss': 0.0546, 'grad_norm': 31.186038970947266, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.05236917734146118, 'loss_2': 0.002262115478515625, 'loss_3': -16.573837280273438, 'loss_4': -0.03093530237674713, 'epoch': 23.71}
{'loss': 0.0038, 'grad_norm': 4.94141149520874, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.0035406805109232664, 'loss_2': 0.0002453327178955078, 'loss_3': -16.38983917236328, 'loss_4': -0.518294095993042, 'epoch': 23.72}
{'loss': 0.0119, 'grad_norm': 6.300663948059082, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.01165402214974165, 'loss_2': 0.00020170211791992188, 'loss_3': -16.380531311035156, 'loss_4': -0.18785470724105835, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 14:01:18,756 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:18,756 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:38<18:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:01:26,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018103335052728653, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.402, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01345065701752901, 'eval_loss_2': 0.004652678966522217, 'eval_loss_3': -18.185718536376953, 'eval_loss_4': -0.6035248637199402, 'epoch': 23.72}
{'loss': 0.0102, 'grad_norm': 6.217029571533203, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.008129636757075787, 'loss_2': 0.0020904541015625, 'loss_3': -16.18087387084961, 'loss_4': -0.33681178092956543, 'epoch': 23.73}
{'loss': 0.0133, 'grad_norm': 4.806883335113525, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.008004962466657162, 'loss_2': 0.0052490234375, 'loss_3': -16.548402786254883, 'loss_4': -0.7809354662895203, 'epoch': 23.73}
{'loss': 0.0199, 'grad_norm': 6.529543399810791, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.01638798974454403, 'loss_2': 0.0035400390625, 'loss_3': -16.518264770507812, 'loss_4': -0.787578821182251, 'epoch': 23.74}
{'loss': 0.0115, 'grad_norm': 5.2555832862854, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.007919405587017536, 'loss_2': 0.003612518310546875, 'loss_3': -16.62155532836914, 'loss_4': -0.5738062262535095, 'epoch': 23.74}
{'loss': 0.0182, 'grad_norm': 10.354403495788574, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.016002224758267403, 'loss_2': 0.00222015380859375, 'loss_3': -16.43852424621582, 'loss_4': -0.8606024384498596, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 14:01:26,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:26,076 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:45<18:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:33,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01803286373615265, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.2, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013362483121454716, 'eval_loss_2': 0.004670381546020508, 'eval_loss_3': -18.1898136138916, 'eval_loss_4': -0.6093026995658875, 'epoch': 23.75}
{'loss': 0.0215, 'grad_norm': 8.979120254516602, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.012279490940272808, 'loss_2': 0.00919342041015625, 'loss_3': -16.34604263305664, 'loss_4': -0.5057758092880249, 'epoch': 23.76}
{'loss': 0.013, 'grad_norm': 6.771613597869873, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.008908997289836407, 'loss_2': 0.0040740966796875, 'loss_3': -16.300647735595703, 'loss_4': -0.6513271331787109, 'epoch': 23.76}
{'loss': 0.009, 'grad_norm': 4.932541847229004, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.008708612993359566, 'loss_2': 0.0002429485321044922, 'loss_3': -16.566194534301758, 'loss_4': -0.5041507482528687, 'epoch': 23.77}
{'loss': 0.0141, 'grad_norm': 4.5998921394348145, 'learning_rate': 6.25e-06, 'loss_1': 0.004143712110817432, 'loss_2': 0.009918212890625, 'loss_3': -16.457141876220703, 'loss_4': -0.2698040306568146, 'epoch': 23.77}
{'loss': 0.0106, 'grad_norm': 5.482649803161621, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.007346371654421091, 'loss_2': 0.00322723388671875, 'loss_3': -16.421825408935547, 'loss_4': -0.9833228588104248, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 14:01:33,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:33,400 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:40:52<18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:40,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015950394794344902, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.404, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012846870347857475, 'eval_loss_2': 0.0031035244464874268, 'eval_loss_3': -18.192424774169922, 'eval_loss_4': -0.5611355304718018, 'epoch': 23.78}
{'loss': 0.0172, 'grad_norm': 6.266420364379883, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.013599595986306667, 'loss_2': 0.0036296844482421875, 'loss_3': -16.456768035888672, 'loss_4': -0.6421607136726379, 'epoch': 23.78}
{'loss': 0.0114, 'grad_norm': 4.764715194702148, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.00565320486202836, 'loss_2': 0.00576019287109375, 'loss_3': -16.472307205200195, 'loss_4': -0.8143006563186646, 'epoch': 23.79}
{'loss': 0.006, 'grad_norm': 5.147400856018066, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.003323565237224102, 'loss_2': 0.00264739990234375, 'loss_3': -16.486509323120117, 'loss_4': -0.579245924949646, 'epoch': 23.8}
{'loss': 0.0504, 'grad_norm': 16.952838897705078, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.05039692670106888, 'loss_2': 9.417533874511719e-06, 'loss_3': -16.56509017944336, 'loss_4': -0.7246570587158203, 'epoch': 23.8}
{'loss': 0.0101, 'grad_norm': 6.727187633514404, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.008220480754971504, 'loss_2': 0.0018587112426757812, 'loss_3': -16.32102394104004, 'loss_4': -0.5230461359024048, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 14:01:40,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:40,726 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:41:00<18:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:48,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01591719128191471, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.203, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013380596414208412, 'eval_loss_2': 0.002536594867706299, 'eval_loss_3': -18.192771911621094, 'eval_loss_4': -0.518240213394165, 'epoch': 23.81}
{'loss': 0.0122, 'grad_norm': 5.308496952056885, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.0081478888168931, 'loss_2': 0.0040435791015625, 'loss_3': -16.319379806518555, 'loss_4': -0.3828834891319275, 'epoch': 23.81}
{'loss': 0.0126, 'grad_norm': 5.6520233154296875, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.008274298161268234, 'loss_2': 0.0043182373046875, 'loss_3': -16.426219940185547, 'loss_4': -1.0664457082748413, 'epoch': 23.82}
{'loss': 0.0062, 'grad_norm': 5.384511470794678, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.0047483122907578945, 'loss_2': 0.00142669677734375, 'loss_3': -16.493017196655273, 'loss_4': -0.6634243726730347, 'epoch': 23.83}
{'loss': 0.0153, 'grad_norm': 5.709672451019287, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.009768317453563213, 'loss_2': 0.005489349365234375, 'loss_3': -16.57645034790039, 'loss_4': -0.3140518069267273, 'epoch': 23.83}
{'loss': 0.0127, 'grad_norm': 9.131893157958984, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.011985182762145996, 'loss_2': 0.0006999969482421875, 'loss_3': -16.412988662719727, 'loss_4': -0.7461211085319519, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 14:01:48,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:48,053 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:07<18:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:55,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016129691153764725, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.401, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012907165102660656, 'eval_loss_2': 0.003222525119781494, 'eval_loss_3': -18.194664001464844, 'eval_loss_4': -0.5109215974807739, 'epoch': 23.84}
{'loss': 0.0072, 'grad_norm': 4.810513496398926, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.005989804398268461, 'loss_2': 0.00125885009765625, 'loss_3': -16.43439292907715, 'loss_4': -0.13855068385601044, 'epoch': 23.84}
{'loss': 0.01, 'grad_norm': 5.605818271636963, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.005504668224602938, 'loss_2': 0.0045318603515625, 'loss_3': -16.217710494995117, 'loss_4': -0.5506490468978882, 'epoch': 23.85}
{'loss': 0.0162, 'grad_norm': 7.854400634765625, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.014602262526750565, 'loss_2': 0.0016002655029296875, 'loss_3': -16.293746948242188, 'loss_4': 0.17035192251205444, 'epoch': 23.85}
{'loss': 0.0055, 'grad_norm': 5.382608890533447, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.0034996478352695704, 'loss_2': 0.002044677734375, 'loss_3': -16.454864501953125, 'loss_4': -0.6171529293060303, 'epoch': 23.86}
{'loss': 0.0071, 'grad_norm': 4.548251628875732, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.003889682935550809, 'loss_2': 0.00323486328125, 'loss_3': -16.62580108642578, 'loss_4': -0.5338002443313599, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 14:01:55,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:55,380 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:14<18:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:02,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018731605261564255, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014626952819526196, 'eval_loss_2': 0.004104651510715485, 'eval_loss_3': -18.18128204345703, 'eval_loss_4': -0.5002208352088928, 'epoch': 23.87}
{'loss': 0.0082, 'grad_norm': 4.838819980621338, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.0057168928906321526, 'loss_2': 0.0024547576904296875, 'loss_3': -16.49187469482422, 'loss_4': -1.2206295728683472, 'epoch': 23.87}
{'loss': 0.0146, 'grad_norm': 5.0648627281188965, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.008649146184325218, 'loss_2': 0.00591278076171875, 'loss_3': -16.46561622619629, 'loss_4': -0.918009877204895, 'epoch': 23.88}
{'loss': 0.0076, 'grad_norm': 4.942208766937256, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.0045674326829612255, 'loss_2': 0.002994537353515625, 'loss_3': -16.388946533203125, 'loss_4': -0.8607422709465027, 'epoch': 23.88}
{'loss': 0.0101, 'grad_norm': 5.321746826171875, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.007907986640930176, 'loss_2': 0.0021610260009765625, 'loss_3': -16.677268981933594, 'loss_4': -0.24721309542655945, 'epoch': 23.89}
{'loss': 0.0118, 'grad_norm': 4.983007907867432, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.008467956446111202, 'loss_2': 0.003337860107421875, 'loss_3': -16.307960510253906, 'loss_4': -0.5738223791122437, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 14:02:02,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:02,709 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:22<18:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:10,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018974971026182175, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.183, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.015071640722453594, 'eval_loss_2': 0.003903329372406006, 'eval_loss_3': -18.183612823486328, 'eval_loss_4': -0.48225486278533936, 'epoch': 23.9}
{'loss': 0.0108, 'grad_norm': 5.28933048248291, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.00787422526627779, 'loss_2': 0.002971649169921875, 'loss_3': -16.47708511352539, 'loss_4': -0.3210437595844269, 'epoch': 23.9}
{'loss': 0.0051, 'grad_norm': 4.382390022277832, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.004420601762831211, 'loss_2': 0.0007224082946777344, 'loss_3': -16.44009780883789, 'loss_4': -1.0245281457901, 'epoch': 23.91}
{'loss': 0.007, 'grad_norm': 4.758243560791016, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.0052940561436116695, 'loss_2': 0.0016956329345703125, 'loss_3': -16.409515380859375, 'loss_4': -0.7792995572090149, 'epoch': 23.91}
{'loss': 0.0112, 'grad_norm': 5.260337829589844, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.007177161052823067, 'loss_2': 0.003997802734375, 'loss_3': -16.522415161132812, 'loss_4': -0.5816069841384888, 'epoch': 23.92}
{'loss': 0.0126, 'grad_norm': 7.063569068908691, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.012195685878396034, 'loss_2': 0.0004515647888183594, 'loss_3': -16.4337215423584, 'loss_4': -0.7987656593322754, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 14:02:10,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:10,031 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:29<17:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:17,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018506139516830444, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.459, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014628739096224308, 'eval_loss_2': 0.003877401351928711, 'eval_loss_3': -18.175363540649414, 'eval_loss_4': -0.4887302815914154, 'epoch': 23.92}
{'loss': 0.0056, 'grad_norm': 4.575750350952148, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.004889694042503834, 'loss_2': 0.0006794929504394531, 'loss_3': -16.47018814086914, 'loss_4': -0.6515834927558899, 'epoch': 23.93}
{'loss': 0.0106, 'grad_norm': 5.4209136962890625, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.009357264265418053, 'loss_2': 0.0012798309326171875, 'loss_3': -16.384918212890625, 'loss_4': -0.9335194826126099, 'epoch': 23.94}
{'loss': 0.0125, 'grad_norm': 5.14166784286499, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.007748896721750498, 'loss_2': 0.00472259521484375, 'loss_3': -16.50581169128418, 'loss_4': -0.5587737560272217, 'epoch': 23.94}
{'loss': 0.008, 'grad_norm': 4.496779441833496, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.007283539976924658, 'loss_2': 0.0007352828979492188, 'loss_3': -16.544071197509766, 'loss_4': -0.9202853441238403, 'epoch': 23.95}
{'loss': 0.0092, 'grad_norm': 5.468267917633057, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.007407644763588905, 'loss_2': 0.001827239990234375, 'loss_3': -16.65172576904297, 'loss_4': -0.3667624592781067, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 14:02:17,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:17,353 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:36<17:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:24,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019141191616654396, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.15, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.015160956420004368, 'eval_loss_2': 0.003980234265327454, 'eval_loss_3': -18.18017578125, 'eval_loss_4': -0.4967663586139679, 'epoch': 23.95}
{'loss': 0.0115, 'grad_norm': 5.448750972747803, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.0055488417856395245, 'loss_2': 0.005962371826171875, 'loss_3': -16.698869705200195, 'loss_4': 0.14793594181537628, 'epoch': 23.96}
{'loss': 0.0124, 'grad_norm': 7.613696098327637, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.009703239426016808, 'loss_2': 0.0026493072509765625, 'loss_3': -16.44120979309082, 'loss_4': -0.2856706380844116, 'epoch': 23.97}
{'loss': 0.0134, 'grad_norm': 5.8651628494262695, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.010951525531709194, 'loss_2': 0.002399444580078125, 'loss_3': -16.652982711791992, 'loss_4': 0.2393476814031601, 'epoch': 23.97}
{'loss': 0.0123, 'grad_norm': 5.389233589172363, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.007551853079348803, 'loss_2': 0.004749298095703125, 'loss_3': -16.640426635742188, 'loss_4': -0.424985408782959, 'epoch': 23.98}
{'loss': 0.0066, 'grad_norm': 5.307473659515381, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.003726984141394496, 'loss_2': 0.0029010772705078125, 'loss_3': -16.532543182373047, 'loss_4': -0.5499936938285828, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 14:02:24,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:24,681 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:43<17:00,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 14:02:31,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01934211328625679, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.488, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015524586662650108, 'eval_loss_2': 0.003817528486251831, 'eval_loss_3': -18.169099807739258, 'eval_loss_4': -0.5274030566215515, 'epoch': 23.98}
{'loss': 0.0077, 'grad_norm': 4.880639553070068, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.0034803589805960655, 'loss_2': 0.004241943359375, 'loss_3': -16.38651466369629, 'loss_4': -0.6459556221961975, 'epoch': 23.99}
{'loss': 0.0109, 'grad_norm': 5.667830944061279, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.009187611751258373, 'loss_2': 0.0017156600952148438, 'loss_3': -16.538837432861328, 'loss_4': -0.4970460534095764, 'epoch': 23.99}
{'loss': 0.0049, 'grad_norm': 6.55542516708374, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.002456380520015955, 'loss_2': 0.0024280548095703125, 'loss_3': -16.342744827270508, 'loss_4': -0.13561518490314484, 'epoch': 24.0}
{'loss': 0.0089, 'grad_norm': 4.79089879989624, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.006266056559979916, 'loss_2': 0.002590179443359375, 'loss_3': -16.510339736938477, 'loss_4': -0.2724650502204895, 'epoch': 24.01}
{'loss': 0.016, 'grad_norm': 6.326218605041504, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.01111468393355608, 'loss_2': 0.00490570068359375, 'loss_3': -16.302595138549805, 'loss_4': -0.4497883915901184, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 14:02:31,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:31,684 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:41:51<17:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:39,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019119184464216232, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.057, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.015447258949279785, 'eval_loss_2': 0.003671925514936447, 'eval_loss_3': -18.167383193969727, 'eval_loss_4': -0.4868534803390503, 'epoch': 24.01}
{'loss': 0.009, 'grad_norm': 5.32388973236084, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.0050828889943659306, 'loss_2': 0.003902435302734375, 'loss_3': -16.541900634765625, 'loss_4': -0.8388609290122986, 'epoch': 24.02}
{'loss': 0.0164, 'grad_norm': 5.2093825340271, 'learning_rate': 6e-06, 'loss_1': 0.008459657430648804, 'loss_2': 0.00792694091796875, 'loss_3': -16.411319732666016, 'loss_4': -0.9854656457901001, 'epoch': 24.02}
{'loss': 0.0082, 'grad_norm': 5.82886266708374, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.006370102055370808, 'loss_2': 0.0018444061279296875, 'loss_3': -16.637042999267578, 'loss_4': -0.8378486037254333, 'epoch': 24.03}
{'loss': 0.0265, 'grad_norm': 13.175793647766113, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.025090577080845833, 'loss_2': 0.0014247894287109375, 'loss_3': -16.390777587890625, 'loss_4': -0.7945830821990967, 'epoch': 24.03}
{'loss': 0.0125, 'grad_norm': 5.470911979675293, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.007181832101196051, 'loss_2': 0.00530242919921875, 'loss_3': -16.410327911376953, 'loss_4': -0.910490095615387, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 14:02:39,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:39,019 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:41:58<17:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:46,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01897917315363884, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.076, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.014929442666471004, 'eval_loss_2': 0.004049729555845261, 'eval_loss_3': -18.17190170288086, 'eval_loss_4': -0.41115090250968933, 'epoch': 24.04}
{'loss': 0.0082, 'grad_norm': 5.186725616455078, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.006807152647525072, 'loss_2': 0.0014171600341796875, 'loss_3': -16.451292037963867, 'loss_4': -0.4510877728462219, 'epoch': 24.05}
{'loss': 0.0107, 'grad_norm': 7.078139781951904, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.010707040317356586, 'loss_2': 3.5762786865234375e-06, 'loss_3': -16.419593811035156, 'loss_4': -0.46224215626716614, 'epoch': 24.05}
{'loss': 0.0065, 'grad_norm': 4.477375507354736, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.0054620434530079365, 'loss_2': 0.0010404586791992188, 'loss_3': -16.525367736816406, 'loss_4': -0.5669755935668945, 'epoch': 24.06}
{'loss': 0.0083, 'grad_norm': 4.83480978012085, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.004571353551000357, 'loss_2': 0.003757476806640625, 'loss_3': -16.45667839050293, 'loss_4': -0.17867137491703033, 'epoch': 24.06}
{'loss': 0.0088, 'grad_norm': 4.933685779571533, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.004179301671683788, 'loss_2': 0.004638671875, 'loss_3': -16.336624145507812, 'loss_4': 0.03793730586767197, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 14:02:46,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:46,353 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:05<17:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:53,673 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019063718616962433, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.336, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01505622174590826, 'eval_loss_2': 0.004007495939731598, 'eval_loss_3': -18.173870086669922, 'eval_loss_4': -0.3305898606777191, 'epoch': 24.07}
{'loss': 0.0067, 'grad_norm': 5.090728759765625, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.005815685726702213, 'loss_2': 0.0008616447448730469, 'loss_3': -16.460155487060547, 'loss_4': -0.8407225608825684, 'epoch': 24.08}
{'loss': 0.0104, 'grad_norm': 6.598283767700195, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.008924346417188644, 'loss_2': 0.0015125274658203125, 'loss_3': -16.18000602722168, 'loss_4': -0.319713294506073, 'epoch': 24.08}
{'loss': 0.0046, 'grad_norm': 5.013467788696289, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.004123710561543703, 'loss_2': 0.0004954338073730469, 'loss_3': -16.637779235839844, 'loss_4': -0.5205026865005493, 'epoch': 24.09}
{'loss': 0.0066, 'grad_norm': 4.4742655754089355, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.0022901520133018494, 'loss_2': 0.0043182373046875, 'loss_3': -16.553728103637695, 'loss_4': -0.6493731141090393, 'epoch': 24.09}
{'loss': 0.0062, 'grad_norm': 4.462172508239746, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.006000351160764694, 'loss_2': 0.00022220611572265625, 'loss_3': -16.491384506225586, 'loss_4': -0.06764695048332214, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 14:02:53,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:53,673 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:12<17:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:03:00,994 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018731920048594475, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.261, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.014474121853709221, 'eval_loss_2': 0.004257798194885254, 'eval_loss_3': -18.162410736083984, 'eval_loss_4': -0.2798164486885071, 'epoch': 24.1}
{'loss': 0.0088, 'grad_norm': 4.569669246673584, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.005531542934477329, 'loss_2': 0.00328826904296875, 'loss_3': -16.637807846069336, 'loss_4': -0.6471561193466187, 'epoch': 24.1}
{'loss': 0.0067, 'grad_norm': 5.348559856414795, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.006071858108043671, 'loss_2': 0.0006361007690429688, 'loss_3': -16.378498077392578, 'loss_4': -0.41505688428878784, 'epoch': 24.11}
{'loss': 0.0078, 'grad_norm': 5.391534805297852, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.006434279959648848, 'loss_2': 0.001331329345703125, 'loss_3': -16.659706115722656, 'loss_4': -0.2536909580230713, 'epoch': 24.12}
{'loss': 0.0122, 'grad_norm': 5.793082237243652, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.0077704377472400665, 'loss_2': 0.00446319580078125, 'loss_3': -16.26583480834961, 'loss_4': 0.23987887799739838, 'epoch': 24.12}
{'loss': 0.0163, 'grad_norm': 8.475448608398438, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.013442317955195904, 'loss_2': 0.002872467041015625, 'loss_3': -16.59832000732422, 'loss_4': -0.2145041823387146, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 14:03:00,994 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:00,995 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:20<17:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:08,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018577978014945984, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.995, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.014030203223228455, 'eval_loss_2': 0.004547774791717529, 'eval_loss_3': -18.1713924407959, 'eval_loss_4': -0.23142839968204498, 'epoch': 24.13}
{'loss': 0.0097, 'grad_norm': 5.397287845611572, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.007989359088242054, 'loss_2': 0.001720428466796875, 'loss_3': -16.51651954650879, 'loss_4': 0.2611393928527832, 'epoch': 24.13}
{'loss': 0.0161, 'grad_norm': 4.820131778717041, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.008212131448090076, 'loss_2': 0.007843017578125, 'loss_3': -16.42728614807129, 'loss_4': -0.21696791052818298, 'epoch': 24.14}
{'loss': 0.0095, 'grad_norm': 4.73682165145874, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.005700693000108004, 'loss_2': 0.00376129150390625, 'loss_3': -16.367412567138672, 'loss_4': -1.1816790103912354, 'epoch': 24.15}
{'loss': 0.0107, 'grad_norm': 4.555280685424805, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.002994533395394683, 'loss_2': 0.00774383544921875, 'loss_3': -16.404312133789062, 'loss_4': -0.09361869096755981, 'epoch': 24.15}
{'loss': 0.0114, 'grad_norm': 4.9014410972595215, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.007044958882033825, 'loss_2': 0.00439453125, 'loss_3': -16.50934410095215, 'loss_4': -0.4184277653694153, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 14:03:08,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:08,328 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:27<17:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:15,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017906833440065384, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.014253336936235428, 'eval_loss_2': 0.003653496503829956, 'eval_loss_3': -18.16805648803711, 'eval_loss_4': -0.26032981276512146, 'epoch': 24.16}
{'loss': 0.0061, 'grad_norm': 4.75960636138916, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.005224848166108131, 'loss_2': 0.0008697509765625, 'loss_3': -16.402687072753906, 'loss_4': -0.6843454837799072, 'epoch': 24.16}
{'loss': 0.0361, 'grad_norm': 7.626930236816406, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.0330192930996418, 'loss_2': 0.0030727386474609375, 'loss_3': -16.615158081054688, 'loss_4': 0.3661123216152191, 'epoch': 24.17}
{'loss': 0.0172, 'grad_norm': 5.3905463218688965, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.0074139805510640144, 'loss_2': 0.00980377197265625, 'loss_3': -16.592443466186523, 'loss_4': -0.14506939053535461, 'epoch': 24.17}
{'loss': 0.0102, 'grad_norm': 6.003430366516113, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.008843955583870411, 'loss_2': 0.0013980865478515625, 'loss_3': -16.596872329711914, 'loss_4': -0.4015156328678131, 'epoch': 24.18}
{'loss': 0.0054, 'grad_norm': 4.525457382202148, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.0050566066056489944, 'loss_2': 0.0003628730773925781, 'loss_3': -16.586618423461914, 'loss_4': -0.1427602767944336, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 14:03:15,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:15,671 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:34<17:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:23,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01747310534119606, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.891, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.013930773362517357, 'eval_loss_2': 0.0035423338413238525, 'eval_loss_3': -18.158674240112305, 'eval_loss_4': -0.2865954041481018, 'epoch': 24.19}
{'loss': 0.009, 'grad_norm': 4.873446941375732, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.0033090459182858467, 'loss_2': 0.0056915283203125, 'loss_3': -16.612300872802734, 'loss_4': 0.14997458457946777, 'epoch': 24.19}
{'loss': 0.0607, 'grad_norm': 17.279470443725586, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.05762272700667381, 'loss_2': 0.0031070709228515625, 'loss_3': -16.554203033447266, 'loss_4': 0.38195133209228516, 'epoch': 24.2}
{'loss': 0.0117, 'grad_norm': 6.065309524536133, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.008338551968336105, 'loss_2': 0.0033721923828125, 'loss_3': -16.449352264404297, 'loss_4': -0.5455537438392639, 'epoch': 24.2}
{'loss': 0.0112, 'grad_norm': 4.281246185302734, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.0037367274053394794, 'loss_2': 0.00748443603515625, 'loss_3': -16.44231414794922, 'loss_4': -0.44019004702568054, 'epoch': 24.21}
{'loss': 0.0136, 'grad_norm': 6.165834903717041, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.010726816020905972, 'loss_2': 0.00292205810546875, 'loss_3': -16.459814071655273, 'loss_4': -0.5019734501838684, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 14:03:23,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:23,002 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:42<17:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:30,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01765849068760872, 'eval_runtime': 3.789, 'eval_samples_per_second': 270.254, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01395637821406126, 'eval_loss_2': 0.003702111542224884, 'eval_loss_3': -18.175291061401367, 'eval_loss_4': -0.2687050700187683, 'epoch': 24.22}
{'loss': 0.0037, 'grad_norm': 4.594209671020508, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.002963129198178649, 'loss_2': 0.0007581710815429688, 'loss_3': -16.504587173461914, 'loss_4': 0.0007529482245445251, 'epoch': 24.22}
{'loss': 0.0087, 'grad_norm': 4.214231014251709, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.0035502237733453512, 'loss_2': 0.005157470703125, 'loss_3': -16.573863983154297, 'loss_4': -0.3144104480743408, 'epoch': 24.23}
{'loss': 0.0087, 'grad_norm': 4.247165203094482, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.0026188574265688658, 'loss_2': 0.00609588623046875, 'loss_3': -16.498706817626953, 'loss_4': -0.42352989315986633, 'epoch': 24.23}
{'loss': 0.0109, 'grad_norm': 5.049400329589844, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.004188867285847664, 'loss_2': 0.006671905517578125, 'loss_3': -16.520320892333984, 'loss_4': -0.05177410691976547, 'epoch': 24.24}
{'loss': 0.0087, 'grad_norm': 4.593595027923584, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.0056590912863612175, 'loss_2': 0.003040313720703125, 'loss_3': -16.392580032348633, 'loss_4': -0.37015247344970703, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 14:03:30,335 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:30,335 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:42:49<17:13,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:03:37,863 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018118247389793396, 'eval_runtime': 3.9964, 'eval_samples_per_second': 256.229, 'eval_steps_per_second': 4.004, 'eval_loss_1': 0.014123222790658474, 'eval_loss_2': 0.003995023667812347, 'eval_loss_3': -18.17398452758789, 'eval_loss_4': -0.34369081258773804, 'epoch': 24.24}
{'loss': 0.0116, 'grad_norm': 7.891941547393799, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.009822177700698376, 'loss_2': 0.0017604827880859375, 'loss_3': -16.295059204101562, 'loss_4': 0.18980413675308228, 'epoch': 24.25}
{'loss': 0.0117, 'grad_norm': 4.482706069946289, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.004422504920512438, 'loss_2': 0.007236480712890625, 'loss_3': -16.421613693237305, 'loss_4': -0.5114549398422241, 'epoch': 24.26}
{'loss': 0.0066, 'grad_norm': 4.779722213745117, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.0036156487185508013, 'loss_2': 0.00302886962890625, 'loss_3': -16.56821632385254, 'loss_4': -0.3312087059020996, 'epoch': 24.26}
{'loss': 0.0086, 'grad_norm': 4.219911575317383, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.003177169943228364, 'loss_2': 0.005401611328125, 'loss_3': -16.326324462890625, 'loss_4': -0.058238424360752106, 'epoch': 24.27}
{'loss': 0.0133, 'grad_norm': 5.3173346519470215, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.007283377461135387, 'loss_2': 0.0060577392578125, 'loss_3': -16.432723999023438, 'loss_4': -0.4508950412273407, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 14:03:37,863 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:37,863 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:42:57<16:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:45,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017718711867928505, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.119, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013763434253633022, 'eval_loss_2': 0.003955274820327759, 'eval_loss_3': -18.181020736694336, 'eval_loss_4': -0.3444198668003082, 'epoch': 24.27}
{'loss': 0.0164, 'grad_norm': 10.150368690490723, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.016005270183086395, 'loss_2': 0.0003571510314941406, 'loss_3': -16.55910873413086, 'loss_4': -0.7385774254798889, 'epoch': 24.28}
{'loss': 0.011, 'grad_norm': 7.568121433258057, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.0068797767162323, 'loss_2': 0.00408172607421875, 'loss_3': -16.16684341430664, 'loss_4': -0.38511428236961365, 'epoch': 24.28}
{'loss': 0.0071, 'grad_norm': 4.7467217445373535, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.004731460008770227, 'loss_2': 0.0023193359375, 'loss_3': -16.361892700195312, 'loss_4': -0.14752469956874847, 'epoch': 24.29}
{'loss': 0.0123, 'grad_norm': 5.116374969482422, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.009800346568226814, 'loss_2': 0.002529144287109375, 'loss_3': -16.559782028198242, 'loss_4': -0.45498183369636536, 'epoch': 24.3}
{'loss': 0.0086, 'grad_norm': 5.144066333770752, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.0077573154121637344, 'loss_2': 0.00083160400390625, 'loss_3': -16.37461280822754, 'loss_4': -0.10676103085279465, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 14:03:45,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:45,182 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:43:04<16:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:03:52,501 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018026381731033325, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.015, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013788970187306404, 'eval_loss_2': 0.00423741340637207, 'eval_loss_3': -18.186079025268555, 'eval_loss_4': -0.37687787413597107, 'epoch': 24.3}
{'loss': 0.0111, 'grad_norm': 5.33973503112793, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.007462965324521065, 'loss_2': 0.00362396240234375, 'loss_3': -16.38151741027832, 'loss_4': -0.22249995172023773, 'epoch': 24.31}
{'loss': 0.0118, 'grad_norm': 5.731044292449951, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.00588183430954814, 'loss_2': 0.0059661865234375, 'loss_3': -16.66777801513672, 'loss_4': -0.45712369680404663, 'epoch': 24.31}
{'loss': 0.0155, 'grad_norm': 4.72124719619751, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.006645223591476679, 'loss_2': 0.00882720947265625, 'loss_3': -16.455509185791016, 'loss_4': -0.7090344429016113, 'epoch': 24.32}
{'loss': 0.0039, 'grad_norm': 4.645668029785156, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.0035444574896246195, 'loss_2': 0.00032329559326171875, 'loss_3': -16.283050537109375, 'loss_4': -0.5546430349349976, 'epoch': 24.33}
{'loss': 0.0111, 'grad_norm': 5.259052753448486, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.004305729176849127, 'loss_2': 0.00676727294921875, 'loss_3': -16.48076820373535, 'loss_4': -0.23708385229110718, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 14:03:52,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:52,501 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:11<16:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:59,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017952268943190575, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.013646815903484821, 'eval_loss_2': 0.004305452108383179, 'eval_loss_3': -18.18891143798828, 'eval_loss_4': -0.4229445159435272, 'epoch': 24.33}
{'loss': 0.0127, 'grad_norm': 7.767782688140869, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.009387917816638947, 'loss_2': 0.0032672882080078125, 'loss_3': -16.510223388671875, 'loss_4': -0.4094350337982178, 'epoch': 24.34}
{'loss': 0.0093, 'grad_norm': 7.863881587982178, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.007490181364119053, 'loss_2': 0.0017948150634765625, 'loss_3': -16.43448257446289, 'loss_4': -0.24030092358589172, 'epoch': 24.34}
{'loss': 0.0167, 'grad_norm': 8.783650398254395, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.012333746999502182, 'loss_2': 0.00433349609375, 'loss_3': -16.502450942993164, 'loss_4': -0.8211595416069031, 'epoch': 24.35}
{'loss': 0.0114, 'grad_norm': 4.821756839752197, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.006347499787807465, 'loss_2': 0.00505828857421875, 'loss_3': -16.5164794921875, 'loss_4': -0.44157543778419495, 'epoch': 24.35}
{'loss': 0.0137, 'grad_norm': 6.144520282745361, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.011924216523766518, 'loss_2': 0.0017299652099609375, 'loss_3': -16.540786743164062, 'loss_4': -0.2711044251918793, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 14:03:59,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:59,836 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:19<16:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:04:07,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017290014773607254, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.537, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013339472934603691, 'eval_loss_2': 0.003950539976358414, 'eval_loss_3': -18.18905258178711, 'eval_loss_4': -0.4548580050468445, 'epoch': 24.36}
{'loss': 0.015, 'grad_norm': 5.301702499389648, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.008839401416480541, 'loss_2': 0.0061187744140625, 'loss_3': -16.37574005126953, 'loss_4': -0.1704786866903305, 'epoch': 24.37}
{'loss': 0.0061, 'grad_norm': 5.09505558013916, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.002963259117677808, 'loss_2': 0.0030975341796875, 'loss_3': -16.49073028564453, 'loss_4': -0.39934825897216797, 'epoch': 24.37}
{'loss': 0.0571, 'grad_norm': 22.74749183654785, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.05157782882452011, 'loss_2': 0.0055694580078125, 'loss_3': -16.52766990661621, 'loss_4': 0.0259706974029541, 'epoch': 24.38}
{'loss': 0.0144, 'grad_norm': 9.290252685546875, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.012806547805666924, 'loss_2': 0.0016374588012695312, 'loss_3': -16.53265953063965, 'loss_4': -0.3418259024620056, 'epoch': 24.38}
{'loss': 0.0101, 'grad_norm': 5.371520042419434, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.007085599470883608, 'loss_2': 0.00296783447265625, 'loss_3': -16.329479217529297, 'loss_4': -0.09360237419605255, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 14:04:07,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:07,164 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:26<16:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:04:14,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018010171130299568, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.241, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013944747857749462, 'eval_loss_2': 0.004065424203872681, 'eval_loss_3': -18.1814022064209, 'eval_loss_4': -0.4608362317085266, 'epoch': 24.39}
{'loss': 0.0218, 'grad_norm': 18.56151580810547, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.020265711471438408, 'loss_2': 0.0015125274658203125, 'loss_3': -16.58091163635254, 'loss_4': -0.5181277990341187, 'epoch': 24.4}
{'loss': 0.0096, 'grad_norm': 4.775575160980225, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.005451389588415623, 'loss_2': 0.00412750244140625, 'loss_3': -16.528011322021484, 'loss_4': -0.43472135066986084, 'epoch': 24.4}
{'loss': 0.0055, 'grad_norm': 4.327563762664795, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.002448414219543338, 'loss_2': 0.003055572509765625, 'loss_3': -16.584789276123047, 'loss_4': -0.4603843688964844, 'epoch': 24.41}
{'loss': 0.0158, 'grad_norm': 10.233132362365723, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.012259000912308693, 'loss_2': 0.0035858154296875, 'loss_3': -16.455299377441406, 'loss_4': -0.22040057182312012, 'epoch': 24.41}
{'loss': 0.0087, 'grad_norm': 4.99935245513916, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.003925248049199581, 'loss_2': 0.00479888916015625, 'loss_3': -16.399011611938477, 'loss_4': -0.6422106623649597, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 14:04:14,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:14,487 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:33<16:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:04:21,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017753446474671364, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.176, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01354139856994152, 'eval_loss_2': 0.004212047904729843, 'eval_loss_3': -18.178014755249023, 'eval_loss_4': -0.46837618947029114, 'epoch': 24.42}
{'loss': 0.0147, 'grad_norm': 6.159743785858154, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.00981034804135561, 'loss_2': 0.00484466552734375, 'loss_3': -16.659637451171875, 'loss_4': -0.2628164291381836, 'epoch': 24.42}
{'loss': 0.0143, 'grad_norm': 5.479112148284912, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.00940302200615406, 'loss_2': 0.00493621826171875, 'loss_3': -16.756505966186523, 'loss_4': -0.27728748321533203, 'epoch': 24.43}
{'loss': 0.0184, 'grad_norm': 8.94108772277832, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.014999737963080406, 'loss_2': 0.003414154052734375, 'loss_3': -16.294403076171875, 'loss_4': -0.859140157699585, 'epoch': 24.44}
{'loss': 0.0091, 'grad_norm': 4.537088394165039, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.0062573133036494255, 'loss_2': 0.0028228759765625, 'loss_3': -16.377178192138672, 'loss_4': -0.528258204460144, 'epoch': 24.44}
{'loss': 0.0087, 'grad_norm': 4.762698173522949, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.006708607077598572, 'loss_2': 0.002002716064453125, 'loss_3': -16.490337371826172, 'loss_4': -0.6793363690376282, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 14:04:21,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:21,803 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:41<16:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:04:29,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01827811822295189, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.205, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.014163460582494736, 'eval_loss_2': 0.004114657640457153, 'eval_loss_3': -18.172130584716797, 'eval_loss_4': -0.45553892850875854, 'epoch': 24.45}
{'loss': 0.0053, 'grad_norm': 4.66847562789917, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.005197265651077032, 'loss_2': 0.00012505054473876953, 'loss_3': -16.37451171875, 'loss_4': -0.22698645293712616, 'epoch': 24.45}
{'loss': 0.0063, 'grad_norm': 4.824638843536377, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.002743182238191366, 'loss_2': 0.0035305023193359375, 'loss_3': -16.415315628051758, 'loss_4': -0.5928460955619812, 'epoch': 24.46}
{'loss': 0.0065, 'grad_norm': 5.033468246459961, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.004804456140846014, 'loss_2': 0.0016536712646484375, 'loss_3': -16.586807250976562, 'loss_4': -0.7052243947982788, 'epoch': 24.47}
{'loss': 0.0086, 'grad_norm': 5.6462907791137695, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.005606275517493486, 'loss_2': 0.003017425537109375, 'loss_3': -16.530181884765625, 'loss_4': -0.6302974224090576, 'epoch': 24.47}
{'loss': 0.0062, 'grad_norm': 4.899746894836426, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.005104678217321634, 'loss_2': 0.0011157989501953125, 'loss_3': -16.5684814453125, 'loss_4': -0.5783557891845703, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 14:04:29,128 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:29,128 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:43:48<16:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:36,455 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019052371382713318, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.126, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014860629104077816, 'eval_loss_2': 0.004191741347312927, 'eval_loss_3': -18.176727294921875, 'eval_loss_4': -0.4105934500694275, 'epoch': 24.48}
{'loss': 0.0088, 'grad_norm': 6.301655292510986, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.007476408500224352, 'loss_2': 0.0012941360473632812, 'loss_3': -16.38477897644043, 'loss_4': -0.4850780665874481, 'epoch': 24.48}
{'loss': 0.0086, 'grad_norm': 4.838123798370361, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.005473637953400612, 'loss_2': 0.003116607666015625, 'loss_3': -16.501197814941406, 'loss_4': -0.6832225322723389, 'epoch': 24.49}
{'loss': 0.0092, 'grad_norm': 4.756927967071533, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.005208172835409641, 'loss_2': 0.004032135009765625, 'loss_3': -16.580204010009766, 'loss_4': -0.10111910104751587, 'epoch': 24.49}
{'loss': 0.0102, 'grad_norm': 5.98409366607666, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.009398002177476883, 'loss_2': 0.0007715225219726562, 'loss_3': -16.337900161743164, 'loss_4': -0.7204647660255432, 'epoch': 24.5}
{'loss': 0.0089, 'grad_norm': 4.892706394195557, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.0045385221019387245, 'loss_2': 0.0043182373046875, 'loss_3': -16.590423583984375, 'loss_4': -0.7002402544021606, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 14:04:36,455 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:36,455 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:43:55<16:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:43,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018508758395910263, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.72, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014513502828776836, 'eval_loss_2': 0.003995254635810852, 'eval_loss_3': -18.170637130737305, 'eval_loss_4': -0.3715663552284241, 'epoch': 24.51}
{'loss': 0.0065, 'grad_norm': 4.725396156311035, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.005249449517577887, 'loss_2': 0.0012598037719726562, 'loss_3': -16.504796981811523, 'loss_4': -0.4105280041694641, 'epoch': 24.51}
{'loss': 0.014, 'grad_norm': 9.029153823852539, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.012984491884708405, 'loss_2': 0.0010318756103515625, 'loss_3': -16.391414642333984, 'loss_4': -0.35330796241760254, 'epoch': 24.52}
{'loss': 0.0131, 'grad_norm': 4.118701934814453, 'learning_rate': 5.5e-06, 'loss_1': 0.0047689941711723804, 'loss_2': 0.00832366943359375, 'loss_3': -16.547578811645508, 'loss_4': -0.2989582419395447, 'epoch': 24.52}
{'loss': 0.0476, 'grad_norm': 23.84691619873047, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.046443767845630646, 'loss_2': 0.00115966796875, 'loss_3': -16.353931427001953, 'loss_4': -0.30960366129875183, 'epoch': 24.53}
{'loss': 0.0114, 'grad_norm': 6.125621318817139, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.008018177933990955, 'loss_2': 0.003429412841796875, 'loss_3': -16.292293548583984, 'loss_4': -0.22672462463378906, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 14:04:43,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:43,798 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:44:03<16:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:04:51,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019456705078482628, 'eval_runtime': 3.7864, 'eval_samples_per_second': 270.442, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015788858756422997, 'eval_loss_2': 0.0036678463220596313, 'eval_loss_3': -18.161903381347656, 'eval_loss_4': -0.3125825524330139, 'epoch': 24.53}
{'loss': 0.011, 'grad_norm': 5.234119415283203, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.0057563637383282185, 'loss_2': 0.00519561767578125, 'loss_3': -16.421905517578125, 'loss_4': -0.28041523694992065, 'epoch': 24.54}
{'loss': 0.0165, 'grad_norm': 8.119336128234863, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.012405021116137505, 'loss_2': 0.0041046142578125, 'loss_3': -16.443843841552734, 'loss_4': -0.7648102045059204, 'epoch': 24.55}
{'loss': 0.0093, 'grad_norm': 5.911556720733643, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.008304730989038944, 'loss_2': 0.0009632110595703125, 'loss_3': -16.44464683532715, 'loss_4': -0.22621271014213562, 'epoch': 24.55}
{'loss': 0.011, 'grad_norm': 5.929584503173828, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.007375159300863743, 'loss_2': 0.003643035888671875, 'loss_3': -16.566041946411133, 'loss_4': -0.1531790792942047, 'epoch': 24.56}
{'loss': 0.0111, 'grad_norm': 4.754064083099365, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.0030425034929066896, 'loss_2': 0.00809478759765625, 'loss_3': -16.39432144165039, 'loss_4': -0.356949120759964, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 14:04:51,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:51,119 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:10<16:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:04:58,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01921883411705494, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.416, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.015499385073781013, 'eval_loss_2': 0.0037194490432739258, 'eval_loss_3': -18.162885665893555, 'eval_loss_4': -0.19505569338798523, 'epoch': 24.56}
{'loss': 0.009, 'grad_norm': 4.939151287078857, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.004227917641401291, 'loss_2': 0.0048065185546875, 'loss_3': -16.563810348510742, 'loss_4': -0.5661123394966125, 'epoch': 24.57}
{'loss': 0.0102, 'grad_norm': 6.8389363288879395, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.009882059879601002, 'loss_2': 0.0002803802490234375, 'loss_3': -16.625431060791016, 'loss_4': -0.88371741771698, 'epoch': 24.58}
{'loss': 0.0107, 'grad_norm': 5.49269437789917, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.006078251171857119, 'loss_2': 0.0046234130859375, 'loss_3': -16.54347801208496, 'loss_4': -0.4497414231300354, 'epoch': 24.58}
{'loss': 0.0127, 'grad_norm': 6.093393325805664, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.011815960519015789, 'loss_2': 0.000858306884765625, 'loss_3': -16.25446319580078, 'loss_4': 0.12086701393127441, 'epoch': 24.59}
{'loss': 0.0195, 'grad_norm': 9.290297508239746, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.00861143134534359, 'loss_2': 0.010894775390625, 'loss_3': -16.4316463470459, 'loss_4': -0.09520195424556732, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 14:04:58,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:58,436 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:17<15:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:05,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020040413364768028, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.319, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016262253746390343, 'eval_loss_2': 0.0037781596183776855, 'eval_loss_3': -18.159833908081055, 'eval_loss_4': -0.1403288096189499, 'epoch': 24.59}
{'loss': 0.0098, 'grad_norm': 5.188446044921875, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.003943709656596184, 'loss_2': 0.0059051513671875, 'loss_3': -16.494604110717773, 'loss_4': -0.3722878694534302, 'epoch': 24.6}
{'loss': 0.0116, 'grad_norm': 5.799187183380127, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.009247584268450737, 'loss_2': 0.00231170654296875, 'loss_3': -16.465885162353516, 'loss_4': -0.010059580206871033, 'epoch': 24.6}
{'loss': 0.0273, 'grad_norm': 11.792115211486816, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.025722794234752655, 'loss_2': 0.0015583038330078125, 'loss_3': -16.34275245666504, 'loss_4': 0.11401865631341934, 'epoch': 24.61}
{'loss': 0.0048, 'grad_norm': 4.378927230834961, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.004689657595008612, 'loss_2': 0.00013363361358642578, 'loss_3': -16.389930725097656, 'loss_4': 0.36077815294265747, 'epoch': 24.62}
{'loss': 0.0082, 'grad_norm': 6.65031099319458, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.006687658838927746, 'loss_2': 0.001499176025390625, 'loss_3': -16.514341354370117, 'loss_4': -0.06053973734378815, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 14:05:05,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:05,759 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:25<15:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:13,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02001984789967537, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.366, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01646299846470356, 'eval_loss_2': 0.00355684757232666, 'eval_loss_3': -18.168895721435547, 'eval_loss_4': -0.0786135196685791, 'epoch': 24.62}
{'loss': 0.0164, 'grad_norm': 5.20888090133667, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.010403023101389408, 'loss_2': 0.00603485107421875, 'loss_3': -16.358013153076172, 'loss_4': 0.3344801664352417, 'epoch': 24.63}
{'loss': 0.0075, 'grad_norm': 4.705163478851318, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.003929504659026861, 'loss_2': 0.0035228729248046875, 'loss_3': -16.562793731689453, 'loss_4': 0.015337944030761719, 'epoch': 24.63}
{'loss': 0.0158, 'grad_norm': 7.700377941131592, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.00894714705646038, 'loss_2': 0.00682830810546875, 'loss_3': -16.507795333862305, 'loss_4': 0.0009061619639396667, 'epoch': 24.64}
{'loss': 0.0585, 'grad_norm': 33.92390441894531, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.05790528282523155, 'loss_2': 0.0005712509155273438, 'loss_3': -16.583940505981445, 'loss_4': 0.46664750576019287, 'epoch': 24.65}
{'loss': 0.0118, 'grad_norm': 5.360185623168945, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.006326482631266117, 'loss_2': 0.0054779052734375, 'loss_3': -16.53034782409668, 'loss_4': -0.12246893346309662, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 14:05:13,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:13,076 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:32<15:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:20,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020043589174747467, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.098, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.016153519973158836, 'eval_loss_2': 0.0038900673389434814, 'eval_loss_3': -18.17353630065918, 'eval_loss_4': -0.004717878997325897, 'epoch': 24.65}
{'loss': 0.0111, 'grad_norm': 6.262220859527588, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.008513704873621464, 'loss_2': 0.0025787353515625, 'loss_3': -16.626489639282227, 'loss_4': 0.24066747725009918, 'epoch': 24.66}
{'loss': 0.01, 'grad_norm': 4.1820573806762695, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.0032920122612267733, 'loss_2': 0.006664276123046875, 'loss_3': -16.46653938293457, 'loss_4': 0.16443988680839539, 'epoch': 24.66}
{'loss': 0.0121, 'grad_norm': 5.910119533538818, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.007960179820656776, 'loss_2': 0.00412750244140625, 'loss_3': -16.188371658325195, 'loss_4': 0.4162837266921997, 'epoch': 24.67}
{'loss': 0.0133, 'grad_norm': 7.856874942779541, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.012082815170288086, 'loss_2': 0.0012054443359375, 'loss_3': -16.58574676513672, 'loss_4': 0.1555766612291336, 'epoch': 24.67}
{'loss': 0.0128, 'grad_norm': 5.3362250328063965, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.007537619676440954, 'loss_2': 0.00527191162109375, 'loss_3': -16.694198608398438, 'loss_4': 0.37019601464271545, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 14:05:20,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:20,399 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:39<15:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:27,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019179051741957664, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.839, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01548919640481472, 'eval_loss_2': 0.0036898553371429443, 'eval_loss_3': -18.16522216796875, 'eval_loss_4': 0.07481736689805984, 'epoch': 24.68}
{'loss': 0.0147, 'grad_norm': 9.629317283630371, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.0144597627222538, 'loss_2': 0.0002142190933227539, 'loss_3': -16.537208557128906, 'loss_4': -0.06573513150215149, 'epoch': 24.69}
{'loss': 0.0131, 'grad_norm': 5.252589225769043, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.0065208482556045055, 'loss_2': 0.00661468505859375, 'loss_3': -16.523895263671875, 'loss_4': -0.09564566612243652, 'epoch': 24.69}
{'loss': 0.0111, 'grad_norm': 5.728381633758545, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.007596197072416544, 'loss_2': 0.0034770965576171875, 'loss_3': -16.495025634765625, 'loss_4': 0.21140439808368683, 'epoch': 24.7}
{'loss': 0.0097, 'grad_norm': 5.249270915985107, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.005537292454391718, 'loss_2': 0.00421142578125, 'loss_3': -16.543426513671875, 'loss_4': -0.21471239626407623, 'epoch': 24.7}
{'loss': 0.0071, 'grad_norm': 4.830014228820801, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.0035371489357203245, 'loss_2': 0.003612518310546875, 'loss_3': -16.660505294799805, 'loss_4': 0.29781776666641235, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 14:05:27,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:27,724 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:47<15:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:35,046 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018885161727666855, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.504, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.015033621340990067, 'eval_loss_2': 0.0038515403866767883, 'eval_loss_3': -18.169675827026367, 'eval_loss_4': 0.15720044076442719, 'epoch': 24.71}
{'loss': 0.0108, 'grad_norm': 5.4868388175964355, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.009852334856987, 'loss_2': 0.0009403228759765625, 'loss_3': -16.337860107421875, 'loss_4': 0.14086413383483887, 'epoch': 24.72}
{'loss': 0.0056, 'grad_norm': 4.62676477432251, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.0038969062734395266, 'loss_2': 0.0017414093017578125, 'loss_3': -16.474578857421875, 'loss_4': 0.31182926893234253, 'epoch': 24.72}
{'loss': 0.0059, 'grad_norm': 4.583663463592529, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.0035900240764021873, 'loss_2': 0.002323150634765625, 'loss_3': -16.389860153198242, 'loss_4': 0.1948336958885193, 'epoch': 24.73}
{'loss': 0.0121, 'grad_norm': 4.362790107727051, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.005250331945717335, 'loss_2': 0.006832122802734375, 'loss_3': -16.479564666748047, 'loss_4': 0.5153017640113831, 'epoch': 24.73}
{'loss': 0.0193, 'grad_norm': 12.876372337341309, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.01410739403218031, 'loss_2': 0.005229949951171875, 'loss_3': -16.371063232421875, 'loss_4': 0.06364642083644867, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 14:05:35,047 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:35,047 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:44:54<15:30,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:42,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01750362664461136, 'eval_runtime': 3.7861, 'eval_samples_per_second': 270.465, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013768859207630157, 'eval_loss_2': 0.003734767436981201, 'eval_loss_3': -18.173254013061523, 'eval_loss_4': 0.2145490050315857, 'epoch': 24.74}
{'loss': 0.0101, 'grad_norm': 5.297818660736084, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.006576762534677982, 'loss_2': 0.003520965576171875, 'loss_3': -16.602941513061523, 'loss_4': 0.5639907717704773, 'epoch': 24.74}
{'loss': 0.0094, 'grad_norm': 7.045654773712158, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.008642504923045635, 'loss_2': 0.0007348060607910156, 'loss_3': -16.356807708740234, 'loss_4': -0.07947245240211487, 'epoch': 24.75}
{'loss': 0.0178, 'grad_norm': 19.85472869873047, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.013836762867867947, 'loss_2': 0.00396728515625, 'loss_3': -16.422901153564453, 'loss_4': 0.30666762590408325, 'epoch': 24.76}
{'loss': 0.0111, 'grad_norm': 4.580249309539795, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.002579404041171074, 'loss_2': 0.0084991455078125, 'loss_3': -16.42430877685547, 'loss_4': 0.4065694808959961, 'epoch': 24.76}
{'loss': 0.0109, 'grad_norm': 5.603859901428223, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.009925066493451595, 'loss_2': 0.0009593963623046875, 'loss_3': -16.404626846313477, 'loss_4': 0.5466518998146057, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 14:05:42,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:42,367 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:45:01<15:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:49,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017718587070703506, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.274, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013845858164131641, 'eval_loss_2': 0.0038727298378944397, 'eval_loss_3': -18.179956436157227, 'eval_loss_4': 0.23656219244003296, 'epoch': 24.77}
{'loss': 0.0155, 'grad_norm': 4.930575370788574, 'learning_rate': 5.25e-06, 'loss_1': 0.007244487293064594, 'loss_2': 0.008209228515625, 'loss_3': -16.421464920043945, 'loss_4': 0.0655035451054573, 'epoch': 24.77}
{'loss': 0.0118, 'grad_norm': 7.510452747344971, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.010944254696369171, 'loss_2': 0.0008983612060546875, 'loss_3': -16.5711669921875, 'loss_4': 0.6753535270690918, 'epoch': 24.78}
{'loss': 0.0064, 'grad_norm': 4.808627128601074, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.0038221036083996296, 'loss_2': 0.002529144287109375, 'loss_3': -16.586830139160156, 'loss_4': 0.6175309419631958, 'epoch': 24.78}
{'loss': 0.0046, 'grad_norm': 5.127585411071777, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.004614443052560091, 'loss_2': 6.4373016357421875e-06, 'loss_3': -16.637786865234375, 'loss_4': 0.3817591369152069, 'epoch': 24.79}
{'loss': 0.0034, 'grad_norm': 4.234165191650391, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.0029615405946969986, 'loss_2': 0.0004177093505859375, 'loss_3': -16.777584075927734, 'loss_4': 0.257998526096344, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 14:05:49,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:49,690 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:09<15:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:05:57,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018716324120759964, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.288, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.014680551365017891, 'eval_loss_2': 0.004035770893096924, 'eval_loss_3': -18.172958374023438, 'eval_loss_4': 0.2441956102848053, 'epoch': 24.8}
{'loss': 0.0161, 'grad_norm': 10.74473762512207, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.013071652501821518, 'loss_2': 0.00299072265625, 'loss_3': -16.614612579345703, 'loss_4': -0.11277725547552109, 'epoch': 24.8}
{'loss': 0.0044, 'grad_norm': 4.64528751373291, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.0038050159346312284, 'loss_2': 0.0005931854248046875, 'loss_3': -16.462074279785156, 'loss_4': 0.2760218679904938, 'epoch': 24.81}
{'loss': 0.008, 'grad_norm': 6.676255702972412, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.0062761143781244755, 'loss_2': 0.0017261505126953125, 'loss_3': -16.434986114501953, 'loss_4': 0.35256433486938477, 'epoch': 24.81}
{'loss': 0.0085, 'grad_norm': 4.461330890655518, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.004446592181921005, 'loss_2': 0.004085540771484375, 'loss_3': -16.52202033996582, 'loss_4': 0.2983165681362152, 'epoch': 24.82}
{'loss': 0.0058, 'grad_norm': 4.165452480316162, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.0037249946035444736, 'loss_2': 0.002025604248046875, 'loss_3': -16.500171661376953, 'loss_4': 0.21217608451843262, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 14:05:57,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:57,015 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:16<15:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:04,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018045157194137573, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.021, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013987749814987183, 'eval_loss_2': 0.004057407379150391, 'eval_loss_3': -18.16733169555664, 'eval_loss_4': 0.20758327841758728, 'epoch': 24.83}
{'loss': 0.0115, 'grad_norm': 4.715208530426025, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.004425404593348503, 'loss_2': 0.00704193115234375, 'loss_3': -16.641389846801758, 'loss_4': 0.5417940020561218, 'epoch': 24.83}
{'loss': 0.009, 'grad_norm': 6.548615455627441, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.008734345436096191, 'loss_2': 0.00030493736267089844, 'loss_3': -16.6311092376709, 'loss_4': 0.29339444637298584, 'epoch': 24.84}
{'loss': 0.0084, 'grad_norm': 4.606076717376709, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.0035586166195571423, 'loss_2': 0.00479888916015625, 'loss_3': -16.376962661743164, 'loss_4': 0.09105093777179718, 'epoch': 24.84}
{'loss': 0.0054, 'grad_norm': 6.9896650314331055, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.003554064314812422, 'loss_2': 0.00185394287109375, 'loss_3': -16.361515045166016, 'loss_4': -0.15775585174560547, 'epoch': 24.85}
{'loss': 0.0142, 'grad_norm': 5.9772257804870605, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.008001159876585007, 'loss_2': 0.00624847412109375, 'loss_3': -16.678943634033203, 'loss_4': -0.05642761290073395, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 14:06:04,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:04,348 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:23<15:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:11,678 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017725639045238495, 'eval_runtime': 3.7935, 'eval_samples_per_second': 269.936, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01368366926908493, 'eval_loss_2': 0.0040419697761535645, 'eval_loss_3': -18.153396606445312, 'eval_loss_4': 0.19343110918998718, 'epoch': 24.85}
{'loss': 0.0135, 'grad_norm': 5.080771446228027, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.005458554718643427, 'loss_2': 0.0080718994140625, 'loss_3': -16.4930477142334, 'loss_4': 0.05606457591056824, 'epoch': 24.86}
{'loss': 0.0138, 'grad_norm': 5.549476623535156, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.007669293787330389, 'loss_2': 0.006145477294921875, 'loss_3': -16.340612411499023, 'loss_4': 0.2391209602355957, 'epoch': 24.87}
{'loss': 0.0139, 'grad_norm': 6.274217128753662, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.00957950297743082, 'loss_2': 0.00434112548828125, 'loss_3': -16.50872802734375, 'loss_4': 0.44455665349960327, 'epoch': 24.87}
{'loss': 0.0033, 'grad_norm': 4.653404712677002, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.0017149510094895959, 'loss_2': 0.00154876708984375, 'loss_3': -16.470571517944336, 'loss_4': -0.07818067818880081, 'epoch': 24.88}
{'loss': 0.0089, 'grad_norm': 5.7723822593688965, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.008028155192732811, 'loss_2': 0.0008382797241210938, 'loss_3': -16.4212589263916, 'loss_4': 0.31706321239471436, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 14:06:11,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:11,678 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:30<15:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:06:19,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01740352064371109, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.364, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013962545432150364, 'eval_loss_2': 0.0034409761428833008, 'eval_loss_3': -18.148273468017578, 'eval_loss_4': 0.17681707441806793, 'epoch': 24.88}
{'loss': 0.004, 'grad_norm': 4.437366962432861, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.004008378367871046, 'loss_2': 1.424551010131836e-05, 'loss_3': -16.50585174560547, 'loss_4': 0.18619756400585175, 'epoch': 24.89}
{'loss': 0.0148, 'grad_norm': 6.722089767456055, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.010211373679339886, 'loss_2': 0.00457763671875, 'loss_3': -16.482736587524414, 'loss_4': 0.30714112520217896, 'epoch': 24.9}
{'loss': 0.0188, 'grad_norm': 6.996662616729736, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.013848388567566872, 'loss_2': 0.0049285888671875, 'loss_3': -16.322677612304688, 'loss_4': 0.36653584241867065, 'epoch': 24.9}
{'loss': 0.01, 'grad_norm': 4.559348106384277, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.0026578244287520647, 'loss_2': 0.00737762451171875, 'loss_3': -16.535987854003906, 'loss_4': -0.31330907344818115, 'epoch': 24.91}
{'loss': 0.0106, 'grad_norm': 5.046298027038574, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.00636702636256814, 'loss_2': 0.004261016845703125, 'loss_3': -16.553810119628906, 'loss_4': 0.31513071060180664, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 14:06:19,001 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:19,001 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:38<15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:26,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018032491207122803, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.436, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014530508778989315, 'eval_loss_2': 0.003501981496810913, 'eval_loss_3': -18.15125274658203, 'eval_loss_4': 0.16078099608421326, 'epoch': 24.91}
{'loss': 0.0127, 'grad_norm': 6.90115213394165, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.010463799349963665, 'loss_2': 0.0022735595703125, 'loss_3': -16.322534561157227, 'loss_4': 0.328762024641037, 'epoch': 24.92}
{'loss': 0.0157, 'grad_norm': 9.711784362792969, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.011729099787771702, 'loss_2': 0.003971099853515625, 'loss_3': -16.687477111816406, 'loss_4': 0.3631577789783478, 'epoch': 24.92}
{'loss': 0.0145, 'grad_norm': 6.821568012237549, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.009898203425109386, 'loss_2': 0.00460052490234375, 'loss_3': -16.490055084228516, 'loss_4': 0.41915085911750793, 'epoch': 24.93}
{'loss': 0.0091, 'grad_norm': 6.320968151092529, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.004654671996831894, 'loss_2': 0.00444793701171875, 'loss_3': -16.588529586791992, 'loss_4': 0.003976605832576752, 'epoch': 24.94}
{'loss': 0.015, 'grad_norm': 5.081474304199219, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.011675303801894188, 'loss_2': 0.003368377685546875, 'loss_3': -16.398502349853516, 'loss_4': 0.12764698266983032, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 14:06:26,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:26,327 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:45<14:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:06:33,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018111057579517365, 'eval_runtime': 3.7876, 'eval_samples_per_second': 270.353, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014522924087941647, 'eval_loss_2': 0.0035881325602531433, 'eval_loss_3': -18.16027069091797, 'eval_loss_4': 0.15989266335964203, 'epoch': 24.94}
{'loss': 0.0098, 'grad_norm': 5.2237958908081055, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.007297373376786709, 'loss_2': 0.0024700164794921875, 'loss_3': -16.530832290649414, 'loss_4': 0.5724141001701355, 'epoch': 24.95}
{'loss': 0.0194, 'grad_norm': 6.524599552154541, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.0129128722473979, 'loss_2': 0.00650787353515625, 'loss_3': -16.451339721679688, 'loss_4': 0.9393396973609924, 'epoch': 24.95}
{'loss': 0.0062, 'grad_norm': 4.511415481567383, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.0026784499641507864, 'loss_2': 0.0034999847412109375, 'loss_3': -16.41809844970703, 'loss_4': -0.0165272057056427, 'epoch': 24.96}
{'loss': 0.0074, 'grad_norm': 5.006020545959473, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.0053634969517588615, 'loss_2': 0.00206756591796875, 'loss_3': -16.648775100708008, 'loss_4': -0.04622584581375122, 'epoch': 24.97}
{'loss': 0.0046, 'grad_norm': 5.012613773345947, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.002315171994268894, 'loss_2': 0.002239227294921875, 'loss_3': -16.541690826416016, 'loss_4': -0.16759943962097168, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 14:06:33,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:33,647 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:45:52<13:20,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 14:06:40,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018141912296414375, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.265, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0141769303008914, 'eval_loss_2': 0.0039649829268455505, 'eval_loss_3': -18.163990020751953, 'eval_loss_4': 0.13359114527702332, 'epoch': 24.97}
{'loss': 0.0113, 'grad_norm': 5.295775890350342, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.009086924605071545, 'loss_2': 0.0022182464599609375, 'loss_3': -16.522218704223633, 'loss_4': -0.008326470851898193, 'epoch': 24.98}
{'loss': 0.0064, 'grad_norm': 6.151012420654297, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.005263180937618017, 'loss_2': 0.001140594482421875, 'loss_3': -16.62321662902832, 'loss_4': 0.7030889391899109, 'epoch': 24.98}
{'loss': 0.0087, 'grad_norm': 4.640474796295166, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.006413786672055721, 'loss_2': 0.002307891845703125, 'loss_3': -16.434871673583984, 'loss_4': -0.03812749683856964, 'epoch': 24.99}
{'loss': 0.0105, 'grad_norm': 7.1859331130981445, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.010085011832416058, 'loss_2': 0.0004050731658935547, 'loss_3': -16.43537139892578, 'loss_4': 0.01740049570798874, 'epoch': 24.99}
{'loss': 0.0028, 'grad_norm': 6.977573871612549, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0011918514501303434, 'loss_2': 0.0015869140625, 'loss_3': -16.322912216186523, 'loss_4': -0.11382818222045898, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 14:06:40,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:40,618 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:45:59<14:33,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 14:06:48,005 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017221327871084213, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.087, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013661916367709637, 'eval_loss_2': 0.003559410572052002, 'eval_loss_3': -18.169010162353516, 'eval_loss_4': 0.09844084084033966, 'epoch': 25.0}
{'loss': 0.0196, 'grad_norm': 8.74557113647461, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.014198930002748966, 'loss_2': 0.005397796630859375, 'loss_3': -16.409896850585938, 'loss_4': -0.06756698340177536, 'epoch': 25.01}
{'loss': 0.0037, 'grad_norm': 4.725119113922119, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.0021056269761174917, 'loss_2': 0.001544952392578125, 'loss_3': -16.464006423950195, 'loss_4': 0.3611985743045807, 'epoch': 25.01}
{'loss': 0.0106, 'grad_norm': 4.790892601013184, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.004692049231380224, 'loss_2': 0.00594329833984375, 'loss_3': -16.308364868164062, 'loss_4': -0.09256049245595932, 'epoch': 25.02}
{'loss': 0.0175, 'grad_norm': 9.998844146728516, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.011515570804476738, 'loss_2': 0.00594329833984375, 'loss_3': -16.429630279541016, 'loss_4': 0.4715098440647125, 'epoch': 25.02}
{'loss': 0.057, 'grad_norm': 17.10660743713379, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.05363807827234268, 'loss_2': 0.0033245086669921875, 'loss_3': -16.4431095123291, 'loss_4': 0.5842464566230774, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 14:06:48,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:48,005 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:07<14:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:06:55,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016506969928741455, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01308253314346075, 'eval_loss_2': 0.00342443585395813, 'eval_loss_3': -18.176095962524414, 'eval_loss_4': 0.10011526942253113, 'epoch': 25.03}
{'loss': 0.0198, 'grad_norm': 8.6497802734375, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.018749039620161057, 'loss_2': 0.0010328292846679688, 'loss_3': -16.484434127807617, 'loss_4': 0.23384840786457062, 'epoch': 25.03}
{'loss': 0.0105, 'grad_norm': 5.342954158782959, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.008194442838430405, 'loss_2': 0.002277374267578125, 'loss_3': -16.61178970336914, 'loss_4': -0.08415228128433228, 'epoch': 25.04}
{'loss': 0.0073, 'grad_norm': 5.348457336425781, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.006947364658117294, 'loss_2': 0.0003895759582519531, 'loss_3': -16.370887756347656, 'loss_4': 0.23435914516448975, 'epoch': 25.05}
{'loss': 0.006, 'grad_norm': 4.645638942718506, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.004124176222831011, 'loss_2': 0.0018863677978515625, 'loss_3': -16.51895523071289, 'loss_4': 0.33892929553985596, 'epoch': 25.05}
{'loss': 0.0063, 'grad_norm': 4.669496536254883, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.00465221144258976, 'loss_2': 0.00162506103515625, 'loss_3': -16.493778228759766, 'loss_4': 0.011911675333976746, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 14:06:55,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:55,326 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:14<14:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:07:02,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016354594379663467, 'eval_runtime': 3.7917, 'eval_samples_per_second': 270.062, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012468133121728897, 'eval_loss_2': 0.0038864612579345703, 'eval_loss_3': -18.179210662841797, 'eval_loss_4': 0.0926465392112732, 'epoch': 25.06}
{'loss': 0.0071, 'grad_norm': 5.372841835021973, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.006524754222482443, 'loss_2': 0.0005340576171875, 'loss_3': -16.596689224243164, 'loss_4': 0.019263073801994324, 'epoch': 25.06}
{'loss': 0.0036, 'grad_norm': 4.511829853057861, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.0027451685164123774, 'loss_2': 0.000865936279296875, 'loss_3': -16.750858306884766, 'loss_4': 0.4003981947898865, 'epoch': 25.07}
{'loss': 0.0067, 'grad_norm': 4.943230628967285, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.005318901967257261, 'loss_2': 0.0013446807861328125, 'loss_3': -16.57923126220703, 'loss_4': 0.4126335382461548, 'epoch': 25.08}
{'loss': 0.0082, 'grad_norm': 4.630056381225586, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.0025809563230723143, 'loss_2': 0.0056610107421875, 'loss_3': -16.55147361755371, 'loss_4': -0.10110421478748322, 'epoch': 25.08}
{'loss': 0.0186, 'grad_norm': 8.85711669921875, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.008941161446273327, 'loss_2': 0.00965118408203125, 'loss_3': -16.49022102355957, 'loss_4': 0.27629679441452026, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 14:07:02,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:02,653 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:21<14:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:09,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01808149740099907, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.351, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012493085116147995, 'eval_loss_2': 0.005588412284851074, 'eval_loss_3': -18.182331085205078, 'eval_loss_4': 0.08202455937862396, 'epoch': 25.09}
{'loss': 0.0111, 'grad_norm': 5.252669811248779, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.004159020259976387, 'loss_2': 0.00691986083984375, 'loss_3': -16.42731475830078, 'loss_4': 0.09757877886295319, 'epoch': 25.09}
{'loss': 0.0076, 'grad_norm': 4.680696964263916, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.0028852331452071667, 'loss_2': 0.004665374755859375, 'loss_3': -16.442062377929688, 'loss_4': 0.1315648853778839, 'epoch': 25.1}
{'loss': 0.0053, 'grad_norm': 4.656164169311523, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.00396698946133256, 'loss_2': 0.0013484954833984375, 'loss_3': -16.396793365478516, 'loss_4': -0.3466498851776123, 'epoch': 25.1}
{'loss': 0.012, 'grad_norm': 5.047548294067383, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.004327248316258192, 'loss_2': 0.00768280029296875, 'loss_3': -16.235340118408203, 'loss_4': 0.22529146075248718, 'epoch': 25.11}
{'loss': 0.0168, 'grad_norm': 4.495368480682373, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.005970983766019344, 'loss_2': 0.01080322265625, 'loss_3': -16.381732940673828, 'loss_4': -0.13187934458255768, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 14:07:09,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:09,980 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:29<14:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:07:17,304 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01878144033253193, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.324, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013091164641082287, 'eval_loss_2': 0.005690276622772217, 'eval_loss_3': -18.175312042236328, 'eval_loss_4': 0.11408567428588867, 'epoch': 25.12}
{'loss': 0.0147, 'grad_norm': 4.654352188110352, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.007214748300611973, 'loss_2': 0.007534027099609375, 'loss_3': -16.559906005859375, 'loss_4': -0.17312540113925934, 'epoch': 25.12}
{'loss': 0.0073, 'grad_norm': 4.812732219696045, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.0044320207089185715, 'loss_2': 0.0028743743896484375, 'loss_3': -16.5856990814209, 'loss_4': -0.23937079310417175, 'epoch': 25.13}
{'loss': 0.0167, 'grad_norm': 5.823370933532715, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.010811210609972477, 'loss_2': 0.005855560302734375, 'loss_3': -16.51449966430664, 'loss_4': 0.47514450550079346, 'epoch': 25.13}
{'loss': 0.0084, 'grad_norm': 4.611395359039307, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.0038168414030224085, 'loss_2': 0.00457000732421875, 'loss_3': -16.477380752563477, 'loss_4': 0.4393475651741028, 'epoch': 25.14}
{'loss': 0.021, 'grad_norm': 5.404428958892822, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.01014762744307518, 'loss_2': 0.0108642578125, 'loss_3': -16.645883560180664, 'loss_4': 0.16542840003967285, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 14:07:17,304 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:17,304 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:36<14:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:24,644 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016892295330762863, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012975362129509449, 'eval_loss_2': 0.003916934132575989, 'eval_loss_3': -18.16108512878418, 'eval_loss_4': 0.08990567922592163, 'epoch': 25.15}
{'loss': 0.0041, 'grad_norm': 4.528655052185059, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.0023981870617717505, 'loss_2': 0.001743316650390625, 'loss_3': -16.745147705078125, 'loss_4': 0.13279497623443604, 'epoch': 25.15}
{'loss': 0.0095, 'grad_norm': 4.39100980758667, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.0042076101526618, 'loss_2': 0.00528717041015625, 'loss_3': -16.773839950561523, 'loss_4': -0.11844803392887115, 'epoch': 25.16}
{'loss': 0.0128, 'grad_norm': 4.629987716674805, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.0067181456834077835, 'loss_2': 0.00608062744140625, 'loss_3': -16.3984375, 'loss_4': -0.12677806615829468, 'epoch': 25.16}
{'loss': 0.0053, 'grad_norm': 5.140531539916992, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.0048855687491595745, 'loss_2': 0.0003790855407714844, 'loss_3': -16.588844299316406, 'loss_4': 0.1319180727005005, 'epoch': 25.17}
{'loss': 0.0066, 'grad_norm': 4.1810173988342285, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.005546738859266043, 'loss_2': 0.001056671142578125, 'loss_3': -16.569026947021484, 'loss_4': 0.42979860305786133, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 14:07:24,644 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:24,644 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:43<14:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:31,983 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016390331089496613, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013459638692438602, 'eval_loss_2': 0.0029306933283805847, 'eval_loss_3': -18.150325775146484, 'eval_loss_4': 0.05314783751964569, 'epoch': 25.17}
{'loss': 0.0061, 'grad_norm': 4.498722553253174, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.0025321957655251026, 'loss_2': 0.0035858154296875, 'loss_3': -16.395753860473633, 'loss_4': -0.35093921422958374, 'epoch': 25.18}
{'loss': 0.0057, 'grad_norm': 4.4606852531433105, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.004983772058039904, 'loss_2': 0.0007104873657226562, 'loss_3': -16.48355484008789, 'loss_4': 0.04900135099887848, 'epoch': 25.19}
{'loss': 0.0073, 'grad_norm': 4.555633068084717, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.002906990237534046, 'loss_2': 0.0043792724609375, 'loss_3': -16.65599822998047, 'loss_4': -0.690886914730072, 'epoch': 25.19}
{'loss': 0.0158, 'grad_norm': 5.380124092102051, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.009110079146921635, 'loss_2': 0.006671905517578125, 'loss_3': -16.37494468688965, 'loss_4': -0.07067866623401642, 'epoch': 25.2}
{'loss': 0.0124, 'grad_norm': 5.516088008880615, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.008645599707961082, 'loss_2': 0.00376129150390625, 'loss_3': -16.515541076660156, 'loss_4': 0.02848982810974121, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 14:07:31,983 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:31,983 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:46:51<14:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:39,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016544785350561142, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.154, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013164776377379894, 'eval_loss_2': 0.003380008041858673, 'eval_loss_3': -18.15736961364746, 'eval_loss_4': 0.04192188382148743, 'epoch': 25.2}
{'loss': 0.0056, 'grad_norm': 4.441648960113525, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.003760301973670721, 'loss_2': 0.0018768310546875, 'loss_3': -16.409358978271484, 'loss_4': -0.22131818532943726, 'epoch': 25.21}
{'loss': 0.0083, 'grad_norm': 4.634355068206787, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.00593532994389534, 'loss_2': 0.0023651123046875, 'loss_3': -16.534198760986328, 'loss_4': 0.13044387102127075, 'epoch': 25.22}
{'loss': 0.0125, 'grad_norm': 6.329609394073486, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.011153912171721458, 'loss_2': 0.001373291015625, 'loss_3': -16.32567596435547, 'loss_4': 0.04373180866241455, 'epoch': 25.22}
{'loss': 0.0083, 'grad_norm': 4.711544513702393, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.0024880871642380953, 'loss_2': 0.005817413330078125, 'loss_3': -16.355405807495117, 'loss_4': 0.012509331107139587, 'epoch': 25.23}
{'loss': 0.0083, 'grad_norm': 5.220722675323486, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.003179278690367937, 'loss_2': 0.0051422119140625, 'loss_3': -16.6787109375, 'loss_4': 0.2396596223115921, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 14:07:39,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:39,309 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:46:58<14:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:46,638 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01698913425207138, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012794040143489838, 'eval_loss_2': 0.004195094108581543, 'eval_loss_3': -18.158771514892578, 'eval_loss_4': 0.017819153144955635, 'epoch': 25.23}
{'loss': 0.0046, 'grad_norm': 4.596273899078369, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.002524915151298046, 'loss_2': 0.002124786376953125, 'loss_3': -16.640724182128906, 'loss_4': 0.0018493607640266418, 'epoch': 25.24}
{'loss': 0.009, 'grad_norm': 5.2696452140808105, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.007516376208513975, 'loss_2': 0.0015268325805664062, 'loss_3': -16.364551544189453, 'loss_4': 0.3250008821487427, 'epoch': 25.24}
{'loss': 0.0171, 'grad_norm': 7.589437007904053, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.008043602108955383, 'loss_2': 0.0090789794921875, 'loss_3': -16.44981575012207, 'loss_4': 0.13929495215415955, 'epoch': 25.25}
{'loss': 0.0355, 'grad_norm': 25.780776977539062, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.03435176983475685, 'loss_2': 0.001125335693359375, 'loss_3': -16.346036911010742, 'loss_4': -0.02387801557779312, 'epoch': 25.26}
{'loss': 0.016, 'grad_norm': 8.292688369750977, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.013922196812927723, 'loss_2': 0.002063751220703125, 'loss_3': -16.33144760131836, 'loss_4': -0.014127224683761597, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 14:07:46,638 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:46,638 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:05<13:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:07:53,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01622115820646286, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.416, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012854121625423431, 'eval_loss_2': 0.0033670365810394287, 'eval_loss_3': -18.154943466186523, 'eval_loss_4': -0.01692524179816246, 'epoch': 25.26}
{'loss': 0.0192, 'grad_norm': 9.153027534484863, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.013977998867630959, 'loss_2': 0.00519561767578125, 'loss_3': -16.50253677368164, 'loss_4': 0.007142812013626099, 'epoch': 25.27}
{'loss': 0.0101, 'grad_norm': 6.645081996917725, 'learning_rate': 4.75e-06, 'loss_1': 0.00920075923204422, 'loss_2': 0.0009469985961914062, 'loss_3': -16.418834686279297, 'loss_4': -0.15081463754177094, 'epoch': 25.27}
{'loss': 0.011, 'grad_norm': 5.857983589172363, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.0055267768912017345, 'loss_2': 0.0054931640625, 'loss_3': -16.455097198486328, 'loss_4': 0.45044881105422974, 'epoch': 25.28}
{'loss': 0.0133, 'grad_norm': 4.757848739624023, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.003545239567756653, 'loss_2': 0.009735107421875, 'loss_3': -16.45871353149414, 'loss_4': -0.27906107902526855, 'epoch': 25.28}
{'loss': 0.0662, 'grad_norm': 17.469451904296875, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.05882468819618225, 'loss_2': 0.007366180419921875, 'loss_3': -16.297393798828125, 'loss_4': 0.033738620579242706, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 14:07:53,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:53,957 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:13<13:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:01,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015307841822504997, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.318, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012348856776952744, 'eval_loss_2': 0.0029589831829071045, 'eval_loss_3': -18.152618408203125, 'eval_loss_4': -0.032325468957424164, 'epoch': 25.29}
{'loss': 0.0061, 'grad_norm': 4.7443647384643555, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.0028353845700621605, 'loss_2': 0.0032444000244140625, 'loss_3': -16.505672454833984, 'loss_4': 0.07312117516994476, 'epoch': 25.3}
{'loss': 0.0057, 'grad_norm': 4.505023002624512, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.0031415745615959167, 'loss_2': 0.002582550048828125, 'loss_3': -16.51797866821289, 'loss_4': 0.2751593589782715, 'epoch': 25.3}
{'loss': 0.0146, 'grad_norm': 6.817944526672363, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.010163683444261551, 'loss_2': 0.00439453125, 'loss_3': -16.42057991027832, 'loss_4': 0.24879176914691925, 'epoch': 25.31}
{'loss': 0.015, 'grad_norm': 5.754897117614746, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.014535323716700077, 'loss_2': 0.0005044937133789062, 'loss_3': -16.545883178710938, 'loss_4': -0.04606708884239197, 'epoch': 25.31}
{'loss': 0.0068, 'grad_norm': 4.946311950683594, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.0052354480139911175, 'loss_2': 0.0015468597412109375, 'loss_3': -16.33890151977539, 'loss_4': -0.20281901955604553, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 14:08:01,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:01,287 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:20<13:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:08:08,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01576545462012291, 'eval_runtime': 3.7941, 'eval_samples_per_second': 269.89, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01269262470304966, 'eval_loss_2': 0.0030728280544281006, 'eval_loss_3': -18.1701717376709, 'eval_loss_4': -0.016588479280471802, 'epoch': 25.32}
{'loss': 0.0029, 'grad_norm': 4.5819783210754395, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.0026296256110072136, 'loss_2': 0.00022172927856445312, 'loss_3': -16.523374557495117, 'loss_4': 0.10041560232639313, 'epoch': 25.33}
{'loss': 0.0103, 'grad_norm': 5.431652069091797, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.00556197389960289, 'loss_2': 0.004756927490234375, 'loss_3': -16.492034912109375, 'loss_4': 0.3594100773334503, 'epoch': 25.33}
{'loss': 0.0038, 'grad_norm': 4.8130974769592285, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.0036530103534460068, 'loss_2': 0.00014257431030273438, 'loss_3': -16.69866180419922, 'loss_4': 0.29893970489501953, 'epoch': 25.34}
{'loss': 0.0046, 'grad_norm': 5.251893997192383, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.0038219206035137177, 'loss_2': 0.0007753372192382812, 'loss_3': -16.481332778930664, 'loss_4': -0.5301592946052551, 'epoch': 25.34}
{'loss': 0.007, 'grad_norm': 5.000416278839111, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.00534159317612648, 'loss_2': 0.001667022705078125, 'loss_3': -16.723180770874023, 'loss_4': 0.31703031063079834, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 14:08:08,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:08,609 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:27<13:42,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:08:15,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015463519841432571, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.272, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01267356425523758, 'eval_loss_2': 0.002789955586194992, 'eval_loss_3': -18.172813415527344, 'eval_loss_4': -0.004071241244673729, 'epoch': 25.35}
{'loss': 0.0066, 'grad_norm': 4.356022834777832, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.004764735698699951, 'loss_2': 0.0018787384033203125, 'loss_3': -16.239561080932617, 'loss_4': 0.2863774299621582, 'epoch': 25.35}
{'loss': 0.0149, 'grad_norm': 5.4708685874938965, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.009035740979015827, 'loss_2': 0.00591278076171875, 'loss_3': -16.513301849365234, 'loss_4': -0.018385961651802063, 'epoch': 25.36}
{'loss': 0.0079, 'grad_norm': 4.56378173828125, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.005612119100987911, 'loss_2': 0.0022830963134765625, 'loss_3': -16.48114013671875, 'loss_4': 0.23826992511749268, 'epoch': 25.37}
{'loss': 0.0307, 'grad_norm': 11.22008228302002, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.02694905921816826, 'loss_2': 0.003704071044921875, 'loss_3': -16.39263153076172, 'loss_4': 0.17552810907363892, 'epoch': 25.37}
{'loss': 0.0087, 'grad_norm': 5.109248638153076, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.007006763014942408, 'loss_2': 0.0017147064208984375, 'loss_3': -16.320606231689453, 'loss_4': 0.0018598362803459167, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 14:08:15,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:15,929 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:35<13:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:23,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015064431354403496, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.126, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01223721168935299, 'eval_loss_2': 0.0028272196650505066, 'eval_loss_3': -18.17521858215332, 'eval_loss_4': 0.007766276597976685, 'epoch': 25.38}
{'loss': 0.0069, 'grad_norm': 4.80375862121582, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.006433642935007811, 'loss_2': 0.0004906654357910156, 'loss_3': -16.4399471282959, 'loss_4': 0.12207759916782379, 'epoch': 25.38}
{'loss': 0.0057, 'grad_norm': 4.50728178024292, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.004347601439803839, 'loss_2': 0.0013179779052734375, 'loss_3': -16.421165466308594, 'loss_4': -0.16914574801921844, 'epoch': 25.39}
{'loss': 0.0101, 'grad_norm': 5.941566467285156, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.006091183051466942, 'loss_2': 0.004032135009765625, 'loss_3': -16.31485366821289, 'loss_4': 0.270114004611969, 'epoch': 25.4}
{'loss': 0.005, 'grad_norm': 4.618851661682129, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.0028958034235984087, 'loss_2': 0.002147674560546875, 'loss_3': -16.52719497680664, 'loss_4': 0.09689337015151978, 'epoch': 25.4}
{'loss': 0.0041, 'grad_norm': 4.853553295135498, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.0039461152628064156, 'loss_2': 0.00014495849609375, 'loss_3': -16.612903594970703, 'loss_4': -0.040564000606536865, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 14:08:23,264 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:23,264 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:42<13:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:30,597 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015922922641038895, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.343, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012557139620184898, 'eval_loss_2': 0.0033657848834991455, 'eval_loss_3': -18.172746658325195, 'eval_loss_4': -0.01788785494863987, 'epoch': 25.41}
{'loss': 0.0158, 'grad_norm': 6.569453239440918, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.01165545079857111, 'loss_2': 0.00411224365234375, 'loss_3': -16.48387336730957, 'loss_4': 0.3486717939376831, 'epoch': 25.41}
{'loss': 0.0055, 'grad_norm': 4.8753252029418945, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.0031932839192450047, 'loss_2': 0.0023059844970703125, 'loss_3': -16.509933471679688, 'loss_4': -0.1333620846271515, 'epoch': 25.42}
{'loss': 0.0094, 'grad_norm': 4.713871479034424, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.004730312619358301, 'loss_2': 0.0047149658203125, 'loss_3': -16.659040451049805, 'loss_4': -0.013092521578073502, 'epoch': 25.42}
{'loss': 0.0199, 'grad_norm': 7.569320201873779, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.012172635644674301, 'loss_2': 0.007686614990234375, 'loss_3': -16.46746253967285, 'loss_4': 0.19727882742881775, 'epoch': 25.43}
{'loss': 0.0135, 'grad_norm': 4.804888725280762, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.004479068331420422, 'loss_2': 0.00897216796875, 'loss_3': -16.509408950805664, 'loss_4': -0.05363328754901886, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 14:08:30,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:30,597 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:47:49<13:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:37,926 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016223441809415817, 'eval_runtime': 3.7897, 'eval_samples_per_second': 270.203, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012426219880580902, 'eval_loss_2': 0.003797221928834915, 'eval_loss_3': -18.17273712158203, 'eval_loss_4': -0.052725039422512054, 'epoch': 25.44}
{'loss': 0.0122, 'grad_norm': 5.144266605377197, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.00525620998814702, 'loss_2': 0.00689697265625, 'loss_3': -16.401227951049805, 'loss_4': -0.13036218285560608, 'epoch': 25.44}
{'loss': 0.006, 'grad_norm': 5.525525093078613, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.005538123194128275, 'loss_2': 0.0004849433898925781, 'loss_3': -16.366226196289062, 'loss_4': -0.2282431721687317, 'epoch': 25.45}
{'loss': 0.0128, 'grad_norm': 4.507480144500732, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.0066518825478851795, 'loss_2': 0.0061492919921875, 'loss_3': -16.49333953857422, 'loss_4': -0.10244621336460114, 'epoch': 25.45}
{'loss': 0.0074, 'grad_norm': 4.6095709800720215, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.004529755096882582, 'loss_2': 0.002834320068359375, 'loss_3': -16.475101470947266, 'loss_4': -0.3947064280509949, 'epoch': 25.46}
{'loss': 0.012, 'grad_norm': 6.477295398712158, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.008271128870546818, 'loss_2': 0.003692626953125, 'loss_3': -16.563488006591797, 'loss_4': -0.3109377324581146, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 14:08:37,926 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:37,926 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:47:57<13:21,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:08:45,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01689719408750534, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0133374547585845, 'eval_loss_2': 0.0035597383975982666, 'eval_loss_3': -18.16759490966797, 'eval_loss_4': -0.10275977849960327, 'epoch': 25.47}
{'loss': 0.0116, 'grad_norm': 4.8691229820251465, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.0038454087916761637, 'loss_2': 0.00775909423828125, 'loss_3': -16.432546615600586, 'loss_4': -0.2995319962501526, 'epoch': 25.47}
{'loss': 0.0068, 'grad_norm': 5.109642505645752, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.005239148624241352, 'loss_2': 0.0015354156494140625, 'loss_3': -16.34418487548828, 'loss_4': -0.4434404671192169, 'epoch': 25.48}
{'loss': 0.0187, 'grad_norm': 7.463691234588623, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.01418149471282959, 'loss_2': 0.004535675048828125, 'loss_3': -16.308027267456055, 'loss_4': -0.15199148654937744, 'epoch': 25.48}
{'loss': 0.0074, 'grad_norm': 4.808035850524902, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.003542158752679825, 'loss_2': 0.00385284423828125, 'loss_3': -16.531776428222656, 'loss_4': 0.1181752011179924, 'epoch': 25.49}
{'loss': 0.0076, 'grad_norm': 5.033969402313232, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.006438893731683493, 'loss_2': 0.0011882781982421875, 'loss_3': -16.30164337158203, 'loss_4': -0.412686824798584, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 14:08:45,249 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:45,249 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:04<13:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:08:52,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01681952178478241, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.875, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01375891175121069, 'eval_loss_2': 0.0030606091022491455, 'eval_loss_3': -18.16147804260254, 'eval_loss_4': -0.1521257758140564, 'epoch': 25.49}
{'loss': 0.0063, 'grad_norm': 5.796921253204346, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.006174573674798012, 'loss_2': 0.00012302398681640625, 'loss_3': -16.34525489807129, 'loss_4': 0.19242160022258759, 'epoch': 25.5}
{'loss': 0.0067, 'grad_norm': 4.942927360534668, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.005558589473366737, 'loss_2': 0.00116729736328125, 'loss_3': -16.324451446533203, 'loss_4': 0.06728285551071167, 'epoch': 25.51}
{'loss': 0.008, 'grad_norm': 5.361942291259766, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.005982720293104649, 'loss_2': 0.0020294189453125, 'loss_3': -16.42138671875, 'loss_4': -0.09004713594913483, 'epoch': 25.51}
{'loss': 0.0118, 'grad_norm': 5.362269878387451, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.005912336520850658, 'loss_2': 0.005924224853515625, 'loss_3': -16.618637084960938, 'loss_4': 0.02045784890651703, 'epoch': 25.52}
{'loss': 0.0116, 'grad_norm': 4.607771873474121, 'learning_rate': 4.5e-06, 'loss_1': 0.004098067060112953, 'loss_2': 0.007488250732421875, 'loss_3': -16.478824615478516, 'loss_4': -0.10277488827705383, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 14:08:52,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:52,569 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:11<13:10,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:08:59,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016574833542108536, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.489, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013669963926076889, 'eval_loss_2': 0.0029048696160316467, 'eval_loss_3': -18.163204193115234, 'eval_loss_4': -0.16916276514530182, 'epoch': 25.52}
{'loss': 0.0196, 'grad_norm': 14.98280143737793, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.01499545481055975, 'loss_2': 0.00457763671875, 'loss_3': -16.585412979125977, 'loss_4': 0.36862045526504517, 'epoch': 25.53}
{'loss': 0.012, 'grad_norm': 5.788806438446045, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.008063637651503086, 'loss_2': 0.00394439697265625, 'loss_3': -16.477792739868164, 'loss_4': -0.3853239417076111, 'epoch': 25.53}
{'loss': 0.008, 'grad_norm': 4.317575931549072, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.003192747477442026, 'loss_2': 0.00482940673828125, 'loss_3': -16.607053756713867, 'loss_4': -0.19942660629749298, 'epoch': 25.54}
{'loss': 0.0053, 'grad_norm': 4.6793437004089355, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.004802151117473841, 'loss_2': 0.0005002021789550781, 'loss_3': -16.31065559387207, 'loss_4': 0.21436956524848938, 'epoch': 25.55}
{'loss': 0.0091, 'grad_norm': 4.882383346557617, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.004188626538962126, 'loss_2': 0.00490570068359375, 'loss_3': -16.282825469970703, 'loss_4': 0.05815694108605385, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 14:08:59,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:59,884 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:19<13:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:09:07,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016600914299488068, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.459, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013649486005306244, 'eval_loss_2': 0.0029514282941818237, 'eval_loss_3': -18.161865234375, 'eval_loss_4': -0.1617724895477295, 'epoch': 25.55}
{'loss': 0.0141, 'grad_norm': 11.976543426513672, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.012177964672446251, 'loss_2': 0.0019397735595703125, 'loss_3': -16.23151397705078, 'loss_4': 0.054036930203437805, 'epoch': 25.56}
{'loss': 0.0075, 'grad_norm': 4.294905185699463, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.0024834396317601204, 'loss_2': 0.005016326904296875, 'loss_3': -16.58502960205078, 'loss_4': 0.08033159375190735, 'epoch': 25.56}
{'loss': 0.0118, 'grad_norm': 6.028324604034424, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.0063803293742239475, 'loss_2': 0.00545501708984375, 'loss_3': -16.449724197387695, 'loss_4': -0.01317496970295906, 'epoch': 25.57}
{'loss': 0.0085, 'grad_norm': 4.699462413787842, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.0031644226983189583, 'loss_2': 0.005298614501953125, 'loss_3': -16.507213592529297, 'loss_4': -0.09754398465156555, 'epoch': 25.58}
{'loss': 0.0119, 'grad_norm': 4.353446960449219, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.004012427292764187, 'loss_2': 0.00787353515625, 'loss_3': -16.40306854248047, 'loss_4': 0.11306130886077881, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 14:09:07,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:07,204 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:26<12:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:09:14,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01636049523949623, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.459, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013286512345075607, 'eval_loss_2': 0.0030739828944206238, 'eval_loss_3': -18.151958465576172, 'eval_loss_4': -0.15502957999706268, 'epoch': 25.58}
{'loss': 0.0046, 'grad_norm': 5.095155239105225, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.0028641074895858765, 'loss_2': 0.001705169677734375, 'loss_3': -16.491188049316406, 'loss_4': -0.18655920028686523, 'epoch': 25.59}
{'loss': 0.0095, 'grad_norm': 5.125779628753662, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.005919838324189186, 'loss_2': 0.00353240966796875, 'loss_3': -16.469207763671875, 'loss_4': -0.32322630286216736, 'epoch': 25.59}
{'loss': 0.0198, 'grad_norm': 10.16829776763916, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.019729522988200188, 'loss_2': 5.054473876953125e-05, 'loss_3': -16.486480712890625, 'loss_4': 0.06716056168079376, 'epoch': 25.6}
{'loss': 0.015, 'grad_norm': 6.486984729766846, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.008463514037430286, 'loss_2': 0.006561279296875, 'loss_3': -16.268165588378906, 'loss_4': -0.48207131028175354, 'epoch': 25.6}
{'loss': 0.008, 'grad_norm': 7.37806510925293, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.007593424525111914, 'loss_2': 0.0004093647003173828, 'loss_3': -16.488746643066406, 'loss_4': 0.5969074964523315, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 14:09:14,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:14,512 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:33<12:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:09:21,831 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015957247465848923, 'eval_runtime': 3.7837, 'eval_samples_per_second': 270.632, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.012846257537603378, 'eval_loss_2': 0.0031109899282455444, 'eval_loss_3': -18.154510498046875, 'eval_loss_4': -0.14861930906772614, 'epoch': 25.61}
{'loss': 0.0023, 'grad_norm': 4.388772487640381, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.002068645553663373, 'loss_2': 0.00025463104248046875, 'loss_3': -16.5849666595459, 'loss_4': 0.5602284073829651, 'epoch': 25.62}
{'loss': 0.0082, 'grad_norm': 4.474620342254639, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.004092843271791935, 'loss_2': 0.004085540771484375, 'loss_3': -16.44877052307129, 'loss_4': -0.04731982201337814, 'epoch': 25.62}
{'loss': 0.004, 'grad_norm': 4.194870948791504, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.003120213747024536, 'loss_2': 0.0009045600891113281, 'loss_3': -16.436246871948242, 'loss_4': 0.05684096738696098, 'epoch': 25.63}
{'loss': 0.0035, 'grad_norm': 4.662100315093994, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.0025643501430749893, 'loss_2': 0.0009822845458984375, 'loss_3': -16.395957946777344, 'loss_4': 0.21294760704040527, 'epoch': 25.63}
{'loss': 0.0195, 'grad_norm': 6.61400032043457, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.011357591487467289, 'loss_2': 0.0081787109375, 'loss_3': -16.211963653564453, 'loss_4': 0.02169668674468994, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 14:09:21,831 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:21,831 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:41<12:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:09:29,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015027174726128578, 'eval_runtime': 3.7906, 'eval_samples_per_second': 270.139, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012352220714092255, 'eval_loss_2': 0.0026749521493911743, 'eval_loss_3': -18.156612396240234, 'eval_loss_4': -0.14778031408786774, 'epoch': 25.64}
{'loss': 0.0069, 'grad_norm': 5.217297554016113, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.005091966595500708, 'loss_2': 0.0017948150634765625, 'loss_3': -16.332359313964844, 'loss_4': -0.3255033493041992, 'epoch': 25.65}
{'loss': 0.0164, 'grad_norm': 8.980791091918945, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.011634962633252144, 'loss_2': 0.00475311279296875, 'loss_3': -16.44357681274414, 'loss_4': 0.20848682522773743, 'epoch': 25.65}
{'loss': 0.0091, 'grad_norm': 4.4570231437683105, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.004879583604633808, 'loss_2': 0.00420379638671875, 'loss_3': -16.555400848388672, 'loss_4': 0.14131750166416168, 'epoch': 25.66}
{'loss': 0.0189, 'grad_norm': 7.032611846923828, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.0137904342263937, 'loss_2': 0.00511932373046875, 'loss_3': -16.41461944580078, 'loss_4': -0.08940780162811279, 'epoch': 25.66}
{'loss': 0.0055, 'grad_norm': 5.205114364624023, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.005498417653143406, 'loss_2': 1.430511474609375e-05, 'loss_3': -16.32758140563965, 'loss_4': -0.16801834106445312, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 14:09:29,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:29,150 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:48:48<12:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:09:36,456 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01459500938653946, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.545, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.012281491421163082, 'eval_loss_2': 0.0023135170340538025, 'eval_loss_3': -18.160200119018555, 'eval_loss_4': -0.1304636150598526, 'epoch': 25.67}
{'loss': 0.0023, 'grad_norm': 4.231276512145996, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.002136708702892065, 'loss_2': 0.00011527538299560547, 'loss_3': -16.49524688720703, 'loss_4': 0.21164000034332275, 'epoch': 25.67}
{'loss': 0.0127, 'grad_norm': 6.000028610229492, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.010234233923256397, 'loss_2': 0.00251007080078125, 'loss_3': -16.38028335571289, 'loss_4': 0.2320106327533722, 'epoch': 25.68}
{'loss': 0.0091, 'grad_norm': 4.993540287017822, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.005681514274328947, 'loss_2': 0.003429412841796875, 'loss_3': -16.395620346069336, 'loss_4': -0.11007732152938843, 'epoch': 25.69}
{'loss': 0.0047, 'grad_norm': 5.084028720855713, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.0042768907733261585, 'loss_2': 0.0003933906555175781, 'loss_3': -16.532730102539062, 'loss_4': -0.4666230380535126, 'epoch': 25.69}
{'loss': 0.0212, 'grad_norm': 19.227319717407227, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.01625705510377884, 'loss_2': 0.00494384765625, 'loss_3': -16.612659454345703, 'loss_4': -0.3068530559539795, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 14:09:36,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:36,457 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:48:55<12:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:43,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016097206622362137, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.321, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013576766476035118, 'eval_loss_2': 0.002520442008972168, 'eval_loss_3': -18.160079956054688, 'eval_loss_4': -0.1762070506811142, 'epoch': 25.7}
{'loss': 0.0081, 'grad_norm': 5.244863986968994, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.00771555257961154, 'loss_2': 0.0003986358642578125, 'loss_3': -16.293567657470703, 'loss_4': 0.035316646099090576, 'epoch': 25.7}
{'loss': 0.0117, 'grad_norm': 5.852800369262695, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.006888116709887981, 'loss_2': 0.00482940673828125, 'loss_3': -16.635536193847656, 'loss_4': -0.5269826650619507, 'epoch': 25.71}
{'loss': 0.0066, 'grad_norm': 4.609304428100586, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.0025007310323417187, 'loss_2': 0.004138946533203125, 'loss_3': -16.388870239257812, 'loss_4': -0.4146595001220703, 'epoch': 25.72}
{'loss': 0.0139, 'grad_norm': 8.884130477905273, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.013392695225775242, 'loss_2': 0.00047659873962402344, 'loss_3': -16.411026000976562, 'loss_4': 0.006470590829849243, 'epoch': 25.72}
{'loss': 0.0064, 'grad_norm': 4.727858543395996, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.0034235587809234858, 'loss_2': 0.0029506683349609375, 'loss_3': -16.615598678588867, 'loss_4': -0.04946431517601013, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 14:09:43,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:43,799 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:49:03<12:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:51,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017329087480902672, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.335, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014891523867845535, 'eval_loss_2': 0.0024375617504119873, 'eval_loss_3': -18.146915435791016, 'eval_loss_4': -0.2684323191642761, 'epoch': 25.73}
{'loss': 0.016, 'grad_norm': 4.798995494842529, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.0050236256793141365, 'loss_2': 0.0109405517578125, 'loss_3': -16.343610763549805, 'loss_4': -0.3403065800666809, 'epoch': 25.73}
{'loss': 0.0154, 'grad_norm': 7.337517738342285, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.014039968140423298, 'loss_2': 0.0013475418090820312, 'loss_3': -16.40587615966797, 'loss_4': -0.21774619817733765, 'epoch': 25.74}
{'loss': 0.0115, 'grad_norm': 4.646902084350586, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.004934878088533878, 'loss_2': 0.006526947021484375, 'loss_3': -16.494997024536133, 'loss_4': -0.2565014958381653, 'epoch': 25.74}
{'loss': 0.0062, 'grad_norm': 5.643134593963623, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.00559605099260807, 'loss_2': 0.0005769729614257812, 'loss_3': -16.48651885986328, 'loss_4': -0.06597673892974854, 'epoch': 25.75}
{'loss': 0.0097, 'grad_norm': 4.864785194396973, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.005143338814377785, 'loss_2': 0.004581451416015625, 'loss_3': -16.42444610595703, 'loss_4': 0.056874215602874756, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 14:09:51,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:51,131 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:10<12:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:58,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019017193466424942, 'eval_runtime': 3.7859, 'eval_samples_per_second': 270.474, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01629810407757759, 'eval_loss_2': 0.002719089388847351, 'eval_loss_3': -18.143722534179688, 'eval_loss_4': -0.32582658529281616, 'epoch': 25.76}
{'loss': 0.007, 'grad_norm': 4.756380081176758, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.006660417187958956, 'loss_2': 0.0003485679626464844, 'loss_3': -16.534957885742188, 'loss_4': -0.10473418235778809, 'epoch': 25.76}
{'loss': 0.0094, 'grad_norm': 5.141694068908691, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.007944582030177116, 'loss_2': 0.001453399658203125, 'loss_3': -16.514312744140625, 'loss_4': -0.6852295994758606, 'epoch': 25.77}
{'loss': 0.0059, 'grad_norm': 4.863068103790283, 'learning_rate': 4.25e-06, 'loss_1': 0.003911029547452927, 'loss_2': 0.002025604248046875, 'loss_3': -16.394895553588867, 'loss_4': -0.16104044020175934, 'epoch': 25.77}
{'loss': 0.0062, 'grad_norm': 4.6730194091796875, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.004945951979607344, 'loss_2': 0.0012340545654296875, 'loss_3': -16.55331802368164, 'loss_4': -0.13096974790096283, 'epoch': 25.78}
{'loss': 0.0027, 'grad_norm': 4.242015361785889, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.0026211112271994352, 'loss_2': 0.00010251998901367188, 'loss_3': -16.501474380493164, 'loss_4': -0.6105506420135498, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 14:09:58,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:58,459 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:17<12:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:05,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018390420824289322, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.996, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.016015950590372086, 'eval_loss_2': 0.0023744702339172363, 'eval_loss_3': -18.131502151489258, 'eval_loss_4': -0.31383058428764343, 'epoch': 25.78}
{'loss': 0.0122, 'grad_norm': 5.800800323486328, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.006237625610083342, 'loss_2': 0.005939483642578125, 'loss_3': -16.47788429260254, 'loss_4': 0.047461241483688354, 'epoch': 25.79}
{'loss': 0.0399, 'grad_norm': 14.676494598388672, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.03833920881152153, 'loss_2': 0.001529693603515625, 'loss_3': -16.403278350830078, 'loss_4': -0.5992051362991333, 'epoch': 25.8}
{'loss': 0.009, 'grad_norm': 5.661471843719482, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.005814573727548122, 'loss_2': 0.003143310546875, 'loss_3': -16.381393432617188, 'loss_4': -0.5009132623672485, 'epoch': 25.8}
{'loss': 0.0066, 'grad_norm': 4.478424072265625, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.0038271252997219563, 'loss_2': 0.00276947021484375, 'loss_3': -16.41150665283203, 'loss_4': -0.2422519475221634, 'epoch': 25.81}
{'loss': 0.0034, 'grad_norm': 4.6825971603393555, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.0022708286996930838, 'loss_2': 0.001087188720703125, 'loss_3': -16.72447967529297, 'loss_4': -0.7188646793365479, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 14:10:05,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:05,782 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:25<12:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:13,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0176561139523983, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.688, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.015298242680728436, 'eval_loss_2': 0.00235787034034729, 'eval_loss_3': -18.140121459960938, 'eval_loss_4': -0.29502445459365845, 'epoch': 25.81}
{'loss': 0.0048, 'grad_norm': 4.679853916168213, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.004646242130547762, 'loss_2': 0.00020301342010498047, 'loss_3': -16.347766876220703, 'loss_4': -0.592400074005127, 'epoch': 25.82}
{'loss': 0.0121, 'grad_norm': 7.094405651092529, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.009687031619250774, 'loss_2': 0.002391815185546875, 'loss_3': -16.211984634399414, 'loss_4': 0.13433974981307983, 'epoch': 25.83}
{'loss': 0.0114, 'grad_norm': 5.3979692459106445, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.008962547406554222, 'loss_2': 0.0024051666259765625, 'loss_3': -16.4915714263916, 'loss_4': -0.1557786911725998, 'epoch': 25.83}
{'loss': 0.0127, 'grad_norm': 7.4761857986450195, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.01044850517064333, 'loss_2': 0.002216339111328125, 'loss_3': -16.20146942138672, 'loss_4': -0.6945483684539795, 'epoch': 25.84}
{'loss': 0.0102, 'grad_norm': 5.2101969718933105, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.0048102582804858685, 'loss_2': 0.005359649658203125, 'loss_3': -16.446510314941406, 'loss_4': -0.5524505376815796, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 14:10:13,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:13,115 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:32<12:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:20,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018018869683146477, 'eval_runtime': 3.7879, 'eval_samples_per_second': 270.337, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.01533439476042986, 'eval_loss_2': 0.002684473991394043, 'eval_loss_3': -18.139846801757812, 'eval_loss_4': -0.255943238735199, 'epoch': 25.84}
{'loss': 0.0054, 'grad_norm': 4.260811805725098, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.004249156452715397, 'loss_2': 0.0011615753173828125, 'loss_3': -16.424880981445312, 'loss_4': -0.6064845323562622, 'epoch': 25.85}
{'loss': 0.0028, 'grad_norm': 5.243317604064941, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.002393601695075631, 'loss_2': 0.000423431396484375, 'loss_3': -16.40688133239746, 'loss_4': -0.5741230249404907, 'epoch': 25.85}
{'loss': 0.0331, 'grad_norm': 15.711038589477539, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.03073727898299694, 'loss_2': 0.002407073974609375, 'loss_3': -16.38132095336914, 'loss_4': -0.03055766224861145, 'epoch': 25.86}
{'loss': 0.0055, 'grad_norm': 4.441489219665527, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.0029739406891167164, 'loss_2': 0.0025577545166015625, 'loss_3': -16.40784454345703, 'loss_4': -0.035209715366363525, 'epoch': 25.87}
{'loss': 0.006, 'grad_norm': 4.798325538635254, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.005121044348925352, 'loss_2': 0.0009279251098632812, 'loss_3': -16.328392028808594, 'loss_4': -0.33447980880737305, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 14:10:20,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:20,430 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:39<12:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:27,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017453383654356003, 'eval_runtime': 3.7841, 'eval_samples_per_second': 270.605, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.015089771710336208, 'eval_loss_2': 0.00236361101269722, 'eval_loss_3': -18.147602081298828, 'eval_loss_4': -0.18438678979873657, 'epoch': 25.87}
{'loss': 0.0058, 'grad_norm': 4.476151466369629, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.004294928628951311, 'loss_2': 0.0015468597412109375, 'loss_3': -16.359474182128906, 'loss_4': -0.034175243228673935, 'epoch': 25.88}
{'loss': 0.0087, 'grad_norm': 4.275388240814209, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.0026916307397186756, 'loss_2': 0.00595855712890625, 'loss_3': -16.409656524658203, 'loss_4': -0.19139543175697327, 'epoch': 25.88}
{'loss': 0.0077, 'grad_norm': 7.087646961212158, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.007090490311384201, 'loss_2': 0.0005617141723632812, 'loss_3': -16.529541015625, 'loss_4': 0.046297892928123474, 'epoch': 25.89}
{'loss': 0.0098, 'grad_norm': 5.333742141723633, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.005249278154224157, 'loss_2': 0.00455474853515625, 'loss_3': -16.598987579345703, 'loss_4': -0.28411492705345154, 'epoch': 25.9}
{'loss': 0.0099, 'grad_norm': 4.929619789123535, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.005757110193371773, 'loss_2': 0.00409698486328125, 'loss_3': -16.493362426757812, 'loss_4': 0.059965699911117554, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 14:10:27,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:27,747 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:49:47<12:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:35,073 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01706172525882721, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.976, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.014566585421562195, 'eval_loss_2': 0.0024951398372650146, 'eval_loss_3': -18.142135620117188, 'eval_loss_4': -0.13055306673049927, 'epoch': 25.9}
{'loss': 0.0124, 'grad_norm': 8.120942115783691, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.011491048149764538, 'loss_2': 0.0009303092956542969, 'loss_3': -16.43602752685547, 'loss_4': -0.26403915882110596, 'epoch': 25.91}
{'loss': 0.0128, 'grad_norm': 6.747995853424072, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.009057535789906979, 'loss_2': 0.003765106201171875, 'loss_3': -16.37209701538086, 'loss_4': 0.019674725830554962, 'epoch': 25.91}
{'loss': 0.0369, 'grad_norm': 9.058445930480957, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.03663628548383713, 'loss_2': 0.00025391578674316406, 'loss_3': -16.554506301879883, 'loss_4': 0.051303863525390625, 'epoch': 25.92}
{'loss': 0.014, 'grad_norm': 6.762147426605225, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.011426974087953568, 'loss_2': 0.0025310516357421875, 'loss_3': -16.47378158569336, 'loss_4': -0.15991319715976715, 'epoch': 25.92}
{'loss': 0.0059, 'grad_norm': 4.594165325164795, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.0044089388102293015, 'loss_2': 0.00146484375, 'loss_3': -16.429500579833984, 'loss_4': -0.21114161610603333, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 14:10:35,074 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:35,074 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:49:54<11:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:42,380 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017676888033747673, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.482, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.014866440556943417, 'eval_loss_2': 0.002810448408126831, 'eval_loss_3': -18.133296966552734, 'eval_loss_4': -0.11379992961883545, 'epoch': 25.93}
{'loss': 0.0099, 'grad_norm': 4.719997406005859, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.006074221804738045, 'loss_2': 0.003875732421875, 'loss_3': -16.470863342285156, 'loss_4': 0.1735459864139557, 'epoch': 25.94}
{'loss': 0.011, 'grad_norm': 5.224931716918945, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.00895219761878252, 'loss_2': 0.00200653076171875, 'loss_3': -16.24660301208496, 'loss_4': -0.21512120962142944, 'epoch': 25.94}
{'loss': 0.0109, 'grad_norm': 5.503551959991455, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.007404548581689596, 'loss_2': 0.003459930419921875, 'loss_3': -16.559551239013672, 'loss_4': 0.1596231460571289, 'epoch': 25.95}
{'loss': 0.0061, 'grad_norm': 4.471818447113037, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.0033112906385213137, 'loss_2': 0.002750396728515625, 'loss_3': -16.563310623168945, 'loss_4': 0.08601154386997223, 'epoch': 25.95}
{'loss': 0.0092, 'grad_norm': 4.759881496429443, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.0061432900838553905, 'loss_2': 0.0030078887939453125, 'loss_3': -16.5639705657959, 'loss_4': -0.2325858473777771, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 14:10:42,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:42,381 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:50:01<11:53,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:10:49,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01817917264997959, 'eval_runtime': 3.7857, 'eval_samples_per_second': 270.488, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.01457118522375822, 'eval_loss_2': 0.0036079883575439453, 'eval_loss_3': -18.131153106689453, 'eval_loss_4': -0.1301785558462143, 'epoch': 25.96}
{'loss': 0.0132, 'grad_norm': 5.120197772979736, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.006667072884738445, 'loss_2': 0.00653076171875, 'loss_3': -16.3478946685791, 'loss_4': 0.1323777139186859, 'epoch': 25.97}
{'loss': 0.0325, 'grad_norm': 20.615568161010742, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.03223639354109764, 'loss_2': 0.00021839141845703125, 'loss_3': -16.39516830444336, 'loss_4': 0.01746920496225357, 'epoch': 25.97}
{'loss': 0.0161, 'grad_norm': 5.36049222946167, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.006946972105652094, 'loss_2': 0.0092010498046875, 'loss_3': -16.49371337890625, 'loss_4': 0.31589633226394653, 'epoch': 25.98}
{'loss': 0.0081, 'grad_norm': 4.774138450622559, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.0072598024271428585, 'loss_2': 0.0008182525634765625, 'loss_3': -16.464603424072266, 'loss_4': 0.008867256343364716, 'epoch': 25.98}
{'loss': 0.0047, 'grad_norm': 4.979199409484863, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.0036717820912599564, 'loss_2': 0.0010242462158203125, 'loss_3': -16.50119400024414, 'loss_4': -0.2984996438026428, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 14:10:49,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:49,703 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:08<11:28,  1.00s/it][INFO|trainer.py:4226] 2025-01-21 14:10:56,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019871197640895844, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.151, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.015611969865858555, 'eval_loss_2': 0.004259228706359863, 'eval_loss_3': -18.13096809387207, 'eval_loss_4': -0.10308466851711273, 'epoch': 25.99}
{'loss': 0.0075, 'grad_norm': 4.965489864349365, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.003993128426373005, 'loss_2': 0.00348663330078125, 'loss_3': -16.471389770507812, 'loss_4': -0.05832729488611221, 'epoch': 25.99}
{'loss': 0.0026, 'grad_norm': 6.422286033630371, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.0011536022648215294, 'loss_2': 0.00148773193359375, 'loss_3': -16.373308181762695, 'loss_4': 0.11823606491088867, 'epoch': 26.0}
{'loss': 0.005, 'grad_norm': 4.2693400382995605, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.0034581574145704508, 'loss_2': 0.0015201568603515625, 'loss_3': -16.449607849121094, 'loss_4': 0.05451996624469757, 'epoch': 26.01}
{'loss': 0.0158, 'grad_norm': 10.561126708984375, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.014395914040505886, 'loss_2': 0.0013971328735351562, 'loss_3': -16.440263748168945, 'loss_4': -0.16055810451507568, 'epoch': 26.01}
{'loss': 0.0533, 'grad_norm': 31.679384231567383, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.051689572632312775, 'loss_2': 0.0016469955444335938, 'loss_3': -16.397626876831055, 'loss_4': -0.016732901334762573, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 14:10:56,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:56,716 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:16<11:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:04,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020120183005928993, 'eval_runtime': 3.7875, 'eval_samples_per_second': 270.363, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016231248155236244, 'eval_loss_2': 0.003888934850692749, 'eval_loss_3': -18.127758026123047, 'eval_loss_4': -0.05812631919980049, 'epoch': 26.02}
{'loss': 0.0096, 'grad_norm': 5.957186698913574, 'learning_rate': 4e-06, 'loss_1': 0.008031226694583893, 'loss_2': 0.0015840530395507812, 'loss_3': -16.564239501953125, 'loss_4': -0.25580257177352905, 'epoch': 26.02}
{'loss': 0.0086, 'grad_norm': 5.155778884887695, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.0075477552600204945, 'loss_2': 0.0010890960693359375, 'loss_3': -16.33721160888672, 'loss_4': -0.14111396670341492, 'epoch': 26.03}
{'loss': 0.0048, 'grad_norm': 4.588943958282471, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.003562340047210455, 'loss_2': 0.0012493133544921875, 'loss_3': -16.442821502685547, 'loss_4': 0.3319109082221985, 'epoch': 26.03}
{'loss': 0.0122, 'grad_norm': 7.0790510177612305, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.009900633245706558, 'loss_2': 0.0022754669189453125, 'loss_3': -16.425085067749023, 'loss_4': 0.14664475619792938, 'epoch': 26.04}
{'loss': 0.0047, 'grad_norm': 4.77532958984375, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.003347162390127778, 'loss_2': 0.001369476318359375, 'loss_3': -16.343994140625, 'loss_4': -0.04889176785945892, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 14:11:04,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:04,040 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:23<11:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:11,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019159365445375443, 'eval_runtime': 3.7846, 'eval_samples_per_second': 270.569, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.016097022220492363, 'eval_loss_2': 0.0030623413622379303, 'eval_loss_3': -18.129180908203125, 'eval_loss_4': -0.03752674534916878, 'epoch': 26.05}
{'loss': 0.019, 'grad_norm': 11.544658660888672, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.01892618089914322, 'loss_2': 0.00010514259338378906, 'loss_3': -16.63308334350586, 'loss_4': -0.0392993800342083, 'epoch': 26.05}
{'loss': 0.063, 'grad_norm': 15.097101211547852, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.05981019511818886, 'loss_2': 0.0031795501708984375, 'loss_3': -16.612253189086914, 'loss_4': 0.5469967722892761, 'epoch': 26.06}
{'loss': 0.0138, 'grad_norm': 8.251081466674805, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.009911625646054745, 'loss_2': 0.003871917724609375, 'loss_3': -16.482017517089844, 'loss_4': 0.2606986165046692, 'epoch': 26.06}
{'loss': 0.0097, 'grad_norm': 5.354794979095459, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.0049603660590946674, 'loss_2': 0.004764556884765625, 'loss_3': -16.314128875732422, 'loss_4': -0.30190765857696533, 'epoch': 26.07}
{'loss': 0.0066, 'grad_norm': 4.682079315185547, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.003272074507549405, 'loss_2': 0.0032939910888671875, 'loss_3': -16.32094955444336, 'loss_4': 0.04162180423736572, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 14:11:11,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:11,352 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:30<11:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:18,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018844999372959137, 'eval_runtime': 3.7847, 'eval_samples_per_second': 270.566, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01624014973640442, 'eval_loss_2': 0.002604849636554718, 'eval_loss_3': -18.128345489501953, 'eval_loss_4': -0.035377681255340576, 'epoch': 26.08}
{'loss': 0.0061, 'grad_norm': 4.912564277648926, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.005166294984519482, 'loss_2': 0.0009593963623046875, 'loss_3': -16.530675888061523, 'loss_4': 0.05916818976402283, 'epoch': 26.08}
{'loss': 0.0091, 'grad_norm': 4.677942276000977, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.005612920504063368, 'loss_2': 0.003513336181640625, 'loss_3': -16.425968170166016, 'loss_4': 0.31251761317253113, 'epoch': 26.09}
{'loss': 0.0072, 'grad_norm': 4.2799835205078125, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.0034844393376260996, 'loss_2': 0.0037078857421875, 'loss_3': -16.508853912353516, 'loss_4': 0.20848767459392548, 'epoch': 26.09}
{'loss': 0.0102, 'grad_norm': 6.637406826019287, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.009811529889702797, 'loss_2': 0.0004024505615234375, 'loss_3': -16.44943618774414, 'loss_4': 0.10659131407737732, 'epoch': 26.1}
{'loss': 0.0045, 'grad_norm': 4.5706000328063965, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.002747217658907175, 'loss_2': 0.0017137527465820312, 'loss_3': -16.523767471313477, 'loss_4': -0.44640856981277466, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 14:11:18,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:18,668 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:37<11:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:25,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018966861069202423, 'eval_runtime': 3.7878, 'eval_samples_per_second': 270.342, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.016176437959074974, 'eval_loss_2': 0.0027904212474823, 'eval_loss_3': -18.13178825378418, 'eval_loss_4': -0.04191519320011139, 'epoch': 26.1}
{'loss': 0.007, 'grad_norm': 5.359725475311279, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.004661570768803358, 'loss_2': 0.002292633056640625, 'loss_3': -16.2890625, 'loss_4': -0.08001108467578888, 'epoch': 26.11}
{'loss': 0.0041, 'grad_norm': 4.6795125007629395, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.003824971616268158, 'loss_2': 0.0002460479736328125, 'loss_3': -16.48875617980957, 'loss_4': 0.5402606129646301, 'epoch': 26.12}
{'loss': 0.0121, 'grad_norm': 5.141707420349121, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.004841554444283247, 'loss_2': 0.007266998291015625, 'loss_3': -16.614009857177734, 'loss_4': 0.19693641364574432, 'epoch': 26.12}
{'loss': 0.0046, 'grad_norm': 4.534788131713867, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.004384683910757303, 'loss_2': 0.0001919269561767578, 'loss_3': -16.35910415649414, 'loss_4': -0.16980764269828796, 'epoch': 26.13}
{'loss': 0.0173, 'grad_norm': 6.479769229888916, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.012081597000360489, 'loss_2': 0.00518035888671875, 'loss_3': -16.393272399902344, 'loss_4': -0.12088748812675476, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 14:11:25,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:25,991 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:45<11:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:33,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01926327869296074, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.2, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.016427474096417427, 'eval_loss_2': 0.002835802733898163, 'eval_loss_3': -18.128826141357422, 'eval_loss_4': -0.015624932944774628, 'epoch': 26.13}
{'loss': 0.0147, 'grad_norm': 10.435346603393555, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.013032512739300728, 'loss_2': 0.0016870498657226562, 'loss_3': -16.4117431640625, 'loss_4': 0.4660443067550659, 'epoch': 26.14}
{'loss': 0.0065, 'grad_norm': 5.336490631103516, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.004786319565027952, 'loss_2': 0.0016937255859375, 'loss_3': -16.50735092163086, 'loss_4': 0.05478505790233612, 'epoch': 26.15}
{'loss': 0.0126, 'grad_norm': 5.906930923461914, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.008541841059923172, 'loss_2': 0.004047393798828125, 'loss_3': -16.644704818725586, 'loss_4': 0.2544739842414856, 'epoch': 26.15}
{'loss': 0.0106, 'grad_norm': 4.8737406730651855, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.009249691851437092, 'loss_2': 0.00136566162109375, 'loss_3': -16.44891357421875, 'loss_4': -0.13419198989868164, 'epoch': 26.16}
{'loss': 0.0072, 'grad_norm': 4.699410915374756, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.004719981923699379, 'loss_2': 0.002521514892578125, 'loss_3': -16.174575805664062, 'loss_4': 0.2954692542552948, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 14:11:33,316 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:33,316 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:50:52<11:17,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:40,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019534964114427567, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.652, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01647832989692688, 'eval_loss_2': 0.0030566342175006866, 'eval_loss_3': -18.115549087524414, 'eval_loss_4': 0.004480465315282345, 'epoch': 26.16}
{'loss': 0.0042, 'grad_norm': 4.206790447235107, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.0029474343173205853, 'loss_2': 0.0012693405151367188, 'loss_3': -16.46830177307129, 'loss_4': -0.17653769254684448, 'epoch': 26.17}
{'loss': 0.0117, 'grad_norm': 5.7349982261657715, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.010120709426701069, 'loss_2': 0.0015363693237304688, 'loss_3': -16.367290496826172, 'loss_4': -0.4267997145652771, 'epoch': 26.17}
{'loss': 0.0036, 'grad_norm': 4.594377040863037, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.0027822728734463453, 'loss_2': 0.0007772445678710938, 'loss_3': -16.309795379638672, 'loss_4': -0.1017439067363739, 'epoch': 26.18}
{'loss': 0.0073, 'grad_norm': 5.107465744018555, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.006011922378093004, 'loss_2': 0.001331329345703125, 'loss_3': -16.55047607421875, 'loss_4': -0.43267524242401123, 'epoch': 26.19}
{'loss': 0.0083, 'grad_norm': 4.710755348205566, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.0038630228955298662, 'loss_2': 0.00443267822265625, 'loss_3': -16.491769790649414, 'loss_4': 0.3765788674354553, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 14:11:40,632 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:40,632 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:50:59<11:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:47,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019137483090162277, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.325, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.015851600095629692, 'eval_loss_2': 0.0032858848571777344, 'eval_loss_3': -18.114238739013672, 'eval_loss_4': 0.009669490158557892, 'epoch': 26.19}
{'loss': 0.0114, 'grad_norm': 4.539329528808594, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.006490179803222418, 'loss_2': 0.00495147705078125, 'loss_3': -16.43825912475586, 'loss_4': 0.38321226835250854, 'epoch': 26.2}
{'loss': 0.0076, 'grad_norm': 4.729988098144531, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.004167786333709955, 'loss_2': 0.0034027099609375, 'loss_3': -16.534164428710938, 'loss_4': 0.3292122781276703, 'epoch': 26.2}
{'loss': 0.0101, 'grad_norm': 5.455627918243408, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.006880303379148245, 'loss_2': 0.0031890869140625, 'loss_3': -16.51636505126953, 'loss_4': 0.007567062973976135, 'epoch': 26.21}
{'loss': 0.0093, 'grad_norm': 4.788727760314941, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.003001689212396741, 'loss_2': 0.00628662109375, 'loss_3': -16.42593002319336, 'loss_4': 0.265475869178772, 'epoch': 26.22}
{'loss': 0.0199, 'grad_norm': 10.289557456970215, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.01504526473581791, 'loss_2': 0.004863739013671875, 'loss_3': -16.48148536682129, 'loss_4': 0.25852781534194946, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 14:11:47,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:47,952 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:07<11:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:11:55,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0185562577098608, 'eval_runtime': 3.784, 'eval_samples_per_second': 270.616, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.01530932355672121, 'eval_loss_2': 0.0032469332218170166, 'eval_loss_3': -18.11677360534668, 'eval_loss_4': 0.009224675595760345, 'epoch': 26.22}
{'loss': 0.0116, 'grad_norm': 5.597344398498535, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.007412567734718323, 'loss_2': 0.004180908203125, 'loss_3': -16.41437530517578, 'loss_4': 0.15925735235214233, 'epoch': 26.23}
{'loss': 0.0073, 'grad_norm': 5.074079990386963, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.003970948979258537, 'loss_2': 0.003299713134765625, 'loss_3': -16.38134002685547, 'loss_4': -0.06843429803848267, 'epoch': 26.23}
{'loss': 0.0491, 'grad_norm': 20.521574020385742, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.04650651291012764, 'loss_2': 0.002628326416015625, 'loss_3': -16.48125457763672, 'loss_4': 0.2752475440502167, 'epoch': 26.24}
{'loss': 0.0102, 'grad_norm': 5.404033184051514, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.007983758114278316, 'loss_2': 0.00220489501953125, 'loss_3': -16.403162002563477, 'loss_4': 0.04419562220573425, 'epoch': 26.24}
{'loss': 0.0071, 'grad_norm': 4.793176174163818, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.005557019729167223, 'loss_2': 0.001556396484375, 'loss_3': -16.429420471191406, 'loss_4': 0.44060230255126953, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 14:11:55,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:55,267 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:14<11:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:12:02,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016949018463492393, 'eval_runtime': 3.7856, 'eval_samples_per_second': 270.502, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.014079813845455647, 'eval_loss_2': 0.0028692036867141724, 'eval_loss_3': -18.12996482849121, 'eval_loss_4': 0.0409957617521286, 'epoch': 26.25}
{'loss': 0.0179, 'grad_norm': 6.0478901863098145, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.009456247091293335, 'loss_2': 0.00843048095703125, 'loss_3': -16.02446746826172, 'loss_4': 0.018447354435920715, 'epoch': 26.26}
{'loss': 0.0159, 'grad_norm': 11.31502914428711, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.015828285366296768, 'loss_2': 0.00011110305786132812, 'loss_3': -16.565227508544922, 'loss_4': -0.251395046710968, 'epoch': 26.26}
{'loss': 0.0118, 'grad_norm': 4.971137523651123, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.0056024761870503426, 'loss_2': 0.0062103271484375, 'loss_3': -16.418197631835938, 'loss_4': 0.2956845164299011, 'epoch': 26.27}
{'loss': 0.0069, 'grad_norm': 6.688851356506348, 'learning_rate': 3.75e-06, 'loss_1': 0.0068368627689778805, 'loss_2': 0.00010597705841064453, 'loss_3': -16.405006408691406, 'loss_4': 0.37811967730522156, 'epoch': 26.27}
{'loss': 0.0074, 'grad_norm': 5.084213733673096, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.005169037263840437, 'loss_2': 0.0022716522216796875, 'loss_3': -16.435314178466797, 'loss_4': 0.559460461139679, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 14:12:02,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:02,584 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:21<10:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:12:09,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01628078520298004, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.432, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.013363809324800968, 'eval_loss_2': 0.002916976809501648, 'eval_loss_3': -18.137285232543945, 'eval_loss_4': 0.057870592921972275, 'epoch': 26.28}
{'loss': 0.0053, 'grad_norm': 4.927079200744629, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.004191860556602478, 'loss_2': 0.0010766983032226562, 'loss_3': -16.569795608520508, 'loss_4': -0.09746989607810974, 'epoch': 26.28}
{'loss': 0.0091, 'grad_norm': 6.288826942443848, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.0059746308252215385, 'loss_2': 0.003139495849609375, 'loss_3': -16.340578079223633, 'loss_4': 0.0797395184636116, 'epoch': 26.29}
{'loss': 0.0863, 'grad_norm': 13.398234367370605, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.08216364681720734, 'loss_2': 0.00408935546875, 'loss_3': -16.592937469482422, 'loss_4': 0.6642611026763916, 'epoch': 26.3}
{'loss': 0.0063, 'grad_norm': 4.572207450866699, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.004327657166868448, 'loss_2': 0.00199127197265625, 'loss_3': -16.18537712097168, 'loss_4': -0.06375885009765625, 'epoch': 26.3}
{'loss': 0.0126, 'grad_norm': 6.42490816116333, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.010284319519996643, 'loss_2': 0.0023479461669921875, 'loss_3': -16.259296417236328, 'loss_4': 0.11332757025957108, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 14:12:09,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:09,899 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:29<10:51,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:12:17,225 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015157370828092098, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.998, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.012203610502183437, 'eval_loss_2': 0.002953760325908661, 'eval_loss_3': -18.135297775268555, 'eval_loss_4': 0.05597645789384842, 'epoch': 26.31}
{'loss': 0.0059, 'grad_norm': 6.0375752449035645, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.005732094403356314, 'loss_2': 0.00021159648895263672, 'loss_3': -16.342864990234375, 'loss_4': -0.034350790083408356, 'epoch': 26.31}
{'loss': 0.0228, 'grad_norm': 9.791077613830566, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.020002353936433792, 'loss_2': 0.002826690673828125, 'loss_3': -16.49022674560547, 'loss_4': -0.11138612031936646, 'epoch': 26.32}
{'loss': 0.0038, 'grad_norm': 4.784190654754639, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.002349289832636714, 'loss_2': 0.001499176025390625, 'loss_3': -16.451494216918945, 'loss_4': 0.6718094348907471, 'epoch': 26.33}
{'loss': 0.0085, 'grad_norm': 4.827500820159912, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.0042652832344174385, 'loss_2': 0.004261016845703125, 'loss_3': -16.479873657226562, 'loss_4': 0.02050483226776123, 'epoch': 26.33}
{'loss': 0.0158, 'grad_norm': 8.218612670898438, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.01177407056093216, 'loss_2': 0.00400543212890625, 'loss_3': -16.511638641357422, 'loss_4': 0.011598914861679077, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 14:12:17,225 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:17,225 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:36<10:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:12:24,549 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014648588374257088, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.282, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.011652388609945774, 'eval_loss_2': 0.002996198832988739, 'eval_loss_3': -18.128437042236328, 'eval_loss_4': 0.05907643958926201, 'epoch': 26.34}
{'loss': 0.0051, 'grad_norm': 4.69557523727417, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.0022628481965512037, 'loss_2': 0.002803802490234375, 'loss_3': -16.470394134521484, 'loss_4': -0.1520189344882965, 'epoch': 26.34}
{'loss': 0.0054, 'grad_norm': 5.418271541595459, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.005152553785592318, 'loss_2': 0.00022542476654052734, 'loss_3': -16.380535125732422, 'loss_4': 0.5185384154319763, 'epoch': 26.35}
{'loss': 0.0168, 'grad_norm': 8.39326000213623, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.016314126551151276, 'loss_2': 0.0004401206970214844, 'loss_3': -16.264896392822266, 'loss_4': -0.060961365699768066, 'epoch': 26.35}
{'loss': 0.0069, 'grad_norm': 4.773059368133545, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.0040310961194336414, 'loss_2': 0.002841949462890625, 'loss_3': -16.375038146972656, 'loss_4': 0.34988054633140564, 'epoch': 26.36}
{'loss': 0.0075, 'grad_norm': 5.640923023223877, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.006449240725487471, 'loss_2': 0.00103759765625, 'loss_3': -16.50548553466797, 'loss_4': 0.2966732978820801, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 14:12:24,549 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:24,549 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:43<10:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:12:31,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014585250988602638, 'eval_runtime': 3.7868, 'eval_samples_per_second': 270.411, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.011519350111484528, 'eval_loss_2': 0.0030658990144729614, 'eval_loss_3': -18.12460708618164, 'eval_loss_4': 0.04501095414161682, 'epoch': 26.37}
{'loss': 0.0159, 'grad_norm': 7.078355312347412, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.014429816976189613, 'loss_2': 0.00151824951171875, 'loss_3': -16.46245002746582, 'loss_4': 0.07317180186510086, 'epoch': 26.37}
{'loss': 0.0139, 'grad_norm': 6.291964530944824, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.008086822926998138, 'loss_2': 0.00577545166015625, 'loss_3': -16.669029235839844, 'loss_4': 0.36753594875335693, 'epoch': 26.38}
{'loss': 0.0242, 'grad_norm': 16.16139793395996, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.022809602320194244, 'loss_2': 0.00138092041015625, 'loss_3': -16.370113372802734, 'loss_4': 0.2014409303665161, 'epoch': 26.38}
{'loss': 0.0069, 'grad_norm': 4.987851142883301, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.006031426601111889, 'loss_2': 0.0008592605590820312, 'loss_3': -16.431304931640625, 'loss_4': -0.13260531425476074, 'epoch': 26.39}
{'loss': 0.0092, 'grad_norm': 5.0032453536987305, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.003459393046796322, 'loss_2': 0.005710601806640625, 'loss_3': -16.35526466369629, 'loss_4': -0.3683246672153473, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 14:12:31,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:31,872 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:51:51<10:45,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:12:39,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014497950673103333, 'eval_runtime': 3.9775, 'eval_samples_per_second': 257.448, 'eval_steps_per_second': 4.023, 'eval_loss_1': 0.011495842598378658, 'eval_loss_2': 0.0030021071434020996, 'eval_loss_3': -18.120454788208008, 'eval_loss_4': 0.022437063977122307, 'epoch': 26.4}
{'loss': 0.0074, 'grad_norm': 5.166676044464111, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.0033123085740953684, 'loss_2': 0.0041351318359375, 'loss_3': -16.416505813598633, 'loss_4': 0.3106931447982788, 'epoch': 26.4}
{'loss': 0.0219, 'grad_norm': 13.979292869567871, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.021780261769890785, 'loss_2': 0.00015091896057128906, 'loss_3': -16.547815322875977, 'loss_4': 0.10779373347759247, 'epoch': 26.41}
{'loss': 0.0063, 'grad_norm': 4.880598545074463, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.005107967648655176, 'loss_2': 0.0011749267578125, 'loss_3': -16.45819854736328, 'loss_4': 0.17078784108161926, 'epoch': 26.41}
{'loss': 0.0108, 'grad_norm': 5.579684734344482, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.008797630667686462, 'loss_2': 0.0020313262939453125, 'loss_3': -16.402423858642578, 'loss_4': 0.28555527329444885, 'epoch': 26.42}
{'loss': 0.0038, 'grad_norm': 5.164157390594482, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.0032243174500763416, 'loss_2': 0.0005512237548828125, 'loss_3': -16.41977310180664, 'loss_4': -0.08475413918495178, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 14:12:39,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:39,389 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:51:58<10:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:46,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014876484870910645, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.179, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.011883629485964775, 'eval_loss_2': 0.00299285352230072, 'eval_loss_3': -18.112276077270508, 'eval_loss_4': 0.014600607566535473, 'epoch': 26.42}
{'loss': 0.0085, 'grad_norm': 5.736166000366211, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.006545805837959051, 'loss_2': 0.0019779205322265625, 'loss_3': -16.40422821044922, 'loss_4': 0.3522201180458069, 'epoch': 26.43}
{'loss': 0.0043, 'grad_norm': 4.2095112800598145, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.0033653927966952324, 'loss_2': 0.00096893310546875, 'loss_3': -16.489307403564453, 'loss_4': -0.25218307971954346, 'epoch': 26.44}
{'loss': 0.0098, 'grad_norm': 6.904438018798828, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.008265589363873005, 'loss_2': 0.0015649795532226562, 'loss_3': -16.560077667236328, 'loss_4': -0.14723283052444458, 'epoch': 26.44}
{'loss': 0.0156, 'grad_norm': 5.2691802978515625, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.013078778050839901, 'loss_2': 0.0025424957275390625, 'loss_3': -16.555885314941406, 'loss_4': 0.23599258065223694, 'epoch': 26.45}
{'loss': 0.0096, 'grad_norm': 4.508465766906738, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.002165356185287237, 'loss_2': 0.00740814208984375, 'loss_3': -16.298847198486328, 'loss_4': 0.13288696110248566, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 14:12:46,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:46,713 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:06<10:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:54,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014516439288854599, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.839, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011872905306518078, 'eval_loss_2': 0.0026435330510139465, 'eval_loss_3': -18.112720489501953, 'eval_loss_4': 0.01964627206325531, 'epoch': 26.45}
{'loss': 0.0073, 'grad_norm': 4.5665106773376465, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.003675245214253664, 'loss_2': 0.0036144256591796875, 'loss_3': -16.32589340209961, 'loss_4': -0.25202396512031555, 'epoch': 26.46}
{'loss': 0.0092, 'grad_norm': 5.011165142059326, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0062990328297019005, 'loss_2': 0.002872467041015625, 'loss_3': -16.363283157348633, 'loss_4': -0.2409728318452835, 'epoch': 26.47}
{'loss': 0.0077, 'grad_norm': 4.806642532348633, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.007013682276010513, 'loss_2': 0.0006685256958007812, 'loss_3': -16.271554946899414, 'loss_4': -0.15839330852031708, 'epoch': 26.47}
{'loss': 0.0048, 'grad_norm': 4.309811592102051, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.002759212162345648, 'loss_2': 0.002033233642578125, 'loss_3': -16.650794982910156, 'loss_4': -0.057200562208890915, 'epoch': 26.48}
{'loss': 0.0046, 'grad_norm': 5.274060249328613, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.003968758974224329, 'loss_2': 0.0006647109985351562, 'loss_3': -16.36959457397461, 'loss_4': -0.004674278199672699, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 14:12:54,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:54,042 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:13<10:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:01,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01476225070655346, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.454, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012090018950402737, 'eval_loss_2': 0.002672232687473297, 'eval_loss_3': -18.111736297607422, 'eval_loss_4': 0.009520549327135086, 'epoch': 26.48}
{'loss': 0.0093, 'grad_norm': 4.392374038696289, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.005030856467783451, 'loss_2': 0.00424957275390625, 'loss_3': -16.561473846435547, 'loss_4': -0.5181031227111816, 'epoch': 26.49}
{'loss': 0.0166, 'grad_norm': 6.436587810516357, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.012209405191242695, 'loss_2': 0.0043487548828125, 'loss_3': -16.412254333496094, 'loss_4': 0.43135514855384827, 'epoch': 26.49}
{'loss': 0.0035, 'grad_norm': 4.521114826202393, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.002151470398530364, 'loss_2': 0.0013866424560546875, 'loss_3': -16.565425872802734, 'loss_4': -0.15033742785453796, 'epoch': 26.5}
{'loss': 0.0098, 'grad_norm': 4.6414618492126465, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.006599755957722664, 'loss_2': 0.00318145751953125, 'loss_3': -16.4384765625, 'loss_4': 0.08433637768030167, 'epoch': 26.51}
{'loss': 0.0087, 'grad_norm': 5.443498611450195, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.006691256072372198, 'loss_2': 0.0020198822021484375, 'loss_3': -16.501205444335938, 'loss_4': -0.23202145099639893, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 14:13:01,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:01,356 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:20<10:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:08,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015528153628110886, 'eval_runtime': 3.7873, 'eval_samples_per_second': 270.38, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.012445133179426193, 'eval_loss_2': 0.0030830204486846924, 'eval_loss_3': -18.106704711914062, 'eval_loss_4': -0.001326762605458498, 'epoch': 26.51}
{'loss': 0.0044, 'grad_norm': 4.345102787017822, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.002847828669473529, 'loss_2': 0.0015611648559570312, 'loss_3': -16.471357345581055, 'loss_4': -0.157268688082695, 'epoch': 26.52}
{'loss': 0.0087, 'grad_norm': 4.733992576599121, 'learning_rate': 3.5e-06, 'loss_1': 0.0038762474432587624, 'loss_2': 0.0047760009765625, 'loss_3': -16.567703247070312, 'loss_4': 0.33170926570892334, 'epoch': 26.52}
{'loss': 0.0075, 'grad_norm': 4.695034027099609, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.002742169424891472, 'loss_2': 0.004730224609375, 'loss_3': -16.453697204589844, 'loss_4': 0.37774670124053955, 'epoch': 26.53}
{'loss': 0.0128, 'grad_norm': 5.67927885055542, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.008265720680356026, 'loss_2': 0.00455474853515625, 'loss_3': -16.268762588500977, 'loss_4': 0.1781291961669922, 'epoch': 26.53}
{'loss': 0.0151, 'grad_norm': 11.288061141967773, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.014741474762558937, 'loss_2': 0.00037026405334472656, 'loss_3': -16.557659149169922, 'loss_4': -0.027563847601413727, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 14:13:08,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:08,681 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:27<10:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:16,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015580998733639717, 'eval_runtime': 3.7896, 'eval_samples_per_second': 270.214, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012467004358768463, 'eval_loss_2': 0.0031139925122261047, 'eval_loss_3': -18.10755157470703, 'eval_loss_4': -0.0012206397950649261, 'epoch': 26.54}
{'loss': 0.0117, 'grad_norm': 4.624686241149902, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.006364617496728897, 'loss_2': 0.005367279052734375, 'loss_3': -16.191177368164062, 'loss_4': -0.027011461555957794, 'epoch': 26.55}
{'loss': 0.0078, 'grad_norm': 5.770613670349121, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.0068644192069768906, 'loss_2': 0.0009236335754394531, 'loss_3': -16.476451873779297, 'loss_4': 0.6552647948265076, 'epoch': 26.55}
{'loss': 0.0099, 'grad_norm': 4.849250316619873, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.004603615030646324, 'loss_2': 0.005275726318359375, 'loss_3': -16.399492263793945, 'loss_4': 0.7605478763580322, 'epoch': 26.56}
{'loss': 0.0068, 'grad_norm': 4.819011211395264, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.002704343991354108, 'loss_2': 0.00408935546875, 'loss_3': -16.366514205932617, 'loss_4': 0.3545161783695221, 'epoch': 26.56}
{'loss': 0.0047, 'grad_norm': 4.4784040451049805, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.003164659719914198, 'loss_2': 0.0014858245849609375, 'loss_3': -16.288814544677734, 'loss_4': -0.16877895593643188, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 14:13:16,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:16,004 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:35<10:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:23,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015466628596186638, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.309, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.012714101001620293, 'eval_loss_2': 0.002752527594566345, 'eval_loss_3': -18.099315643310547, 'eval_loss_4': -0.025175396353006363, 'epoch': 26.57}
{'loss': 0.0086, 'grad_norm': 5.695151329040527, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.005127558950334787, 'loss_2': 0.00348663330078125, 'loss_3': -16.474502563476562, 'loss_4': -0.16018518805503845, 'epoch': 26.58}
{'loss': 0.0194, 'grad_norm': 6.831376552581787, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.014749684371054173, 'loss_2': 0.004680633544921875, 'loss_3': -16.44708824157715, 'loss_4': 0.12667900323867798, 'epoch': 26.58}
{'loss': 0.0062, 'grad_norm': 4.571062088012695, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.0036111765075474977, 'loss_2': 0.002620697021484375, 'loss_3': -16.408781051635742, 'loss_4': 0.09397800266742706, 'epoch': 26.59}
{'loss': 0.0233, 'grad_norm': 12.609771728515625, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.022165168076753616, 'loss_2': 0.0011548995971679688, 'loss_3': -16.20607566833496, 'loss_4': 0.1591135561466217, 'epoch': 26.59}
{'loss': 0.0077, 'grad_norm': 5.489803791046143, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.005073118954896927, 'loss_2': 0.00260162353515625, 'loss_3': -16.316465377807617, 'loss_4': -0.13273002207279205, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 14:13:23,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:23,320 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:42<09:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:30,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015396577306091785, 'eval_runtime': 3.7849, 'eval_samples_per_second': 270.546, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01290778536349535, 'eval_loss_2': 0.0024887919425964355, 'eval_loss_3': -18.09467887878418, 'eval_loss_4': -0.03703167289495468, 'epoch': 26.6}
{'loss': 0.006, 'grad_norm': 4.574132919311523, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.0024102721363306046, 'loss_2': 0.0035400390625, 'loss_3': -16.28951644897461, 'loss_4': -0.0562259666621685, 'epoch': 26.6}
{'loss': 0.0047, 'grad_norm': 4.839679718017578, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.003410679055377841, 'loss_2': 0.0013074874877929688, 'loss_3': -16.32976531982422, 'loss_4': 0.5614228248596191, 'epoch': 26.61}
{'loss': 0.0036, 'grad_norm': 4.643496513366699, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.002590947551652789, 'loss_2': 0.001007080078125, 'loss_3': -16.542133331298828, 'loss_4': -0.49246570467948914, 'epoch': 26.62}
{'loss': 0.0171, 'grad_norm': 5.423797607421875, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.012173235416412354, 'loss_2': 0.00492095947265625, 'loss_3': -16.297683715820312, 'loss_4': -0.04815893992781639, 'epoch': 26.62}
{'loss': 0.0061, 'grad_norm': 4.682063579559326, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.004853643476963043, 'loss_2': 0.001270294189453125, 'loss_3': -16.329679489135742, 'loss_4': 0.3076969087123871, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 14:13:30,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:30,633 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:52:49<09:54,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:37,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015246273949742317, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.147, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01270988117903471, 'eval_loss_2': 0.002536393702030182, 'eval_loss_3': -18.08635139465332, 'eval_loss_4': -0.06476655602455139, 'epoch': 26.63}
{'loss': 0.0139, 'grad_norm': 7.310122013092041, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.009312814101576805, 'loss_2': 0.0045928955078125, 'loss_3': -16.51243019104004, 'loss_4': 0.10721372067928314, 'epoch': 26.63}
{'loss': 0.0127, 'grad_norm': 5.471855163574219, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.005254312884062529, 'loss_2': 0.0074005126953125, 'loss_3': -16.37749481201172, 'loss_4': -0.09502924233675003, 'epoch': 26.64}
{'loss': 0.0073, 'grad_norm': 4.755021095275879, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.005566298495978117, 'loss_2': 0.00168609619140625, 'loss_3': -16.314237594604492, 'loss_4': -0.3474486172199249, 'epoch': 26.65}
{'loss': 0.0124, 'grad_norm': 4.797331809997559, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.002865003887563944, 'loss_2': 0.00958251953125, 'loss_3': -16.48329734802246, 'loss_4': 0.09978201985359192, 'epoch': 26.65}
{'loss': 0.0206, 'grad_norm': 10.98999309539795, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.01961802877485752, 'loss_2': 0.0010137557983398438, 'loss_3': -16.34181022644043, 'loss_4': 0.008657164871692657, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 14:13:37,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:37,956 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:52:57<09:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:45,281 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01548353023827076, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.234, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012671844102442265, 'eval_loss_2': 0.0028116852045059204, 'eval_loss_3': -18.081256866455078, 'eval_loss_4': -0.0714179277420044, 'epoch': 26.66}
{'loss': 0.011, 'grad_norm': 6.366950988769531, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.008453045040369034, 'loss_2': 0.002506256103515625, 'loss_3': -16.312196731567383, 'loss_4': 0.18004439771175385, 'epoch': 26.66}
{'loss': 0.0099, 'grad_norm': 5.170196056365967, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.005767319351434708, 'loss_2': 0.004169464111328125, 'loss_3': -16.457275390625, 'loss_4': 0.08633721619844437, 'epoch': 26.67}
{'loss': 0.0046, 'grad_norm': 5.391507625579834, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.0039879269897937775, 'loss_2': 0.0006151199340820312, 'loss_3': -16.457672119140625, 'loss_4': 0.16049127280712128, 'epoch': 26.67}
{'loss': 0.0093, 'grad_norm': 5.012693881988525, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.004833873361349106, 'loss_2': 0.004482269287109375, 'loss_3': -16.53622055053711, 'loss_4': -0.1285046935081482, 'epoch': 26.68}
{'loss': 0.0088, 'grad_norm': 4.634890079498291, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.004891368094831705, 'loss_2': 0.0039215087890625, 'loss_3': -16.4820556640625, 'loss_4': 0.6664151549339294, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 14:13:45,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:45,282 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:04<09:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:52,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01590562053024769, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.291, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.012846546247601509, 'eval_loss_2': 0.003059074282646179, 'eval_loss_3': -18.084705352783203, 'eval_loss_4': -0.08400864899158478, 'epoch': 26.69}
{'loss': 0.0064, 'grad_norm': 5.203518867492676, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.006264630239456892, 'loss_2': 0.00016164779663085938, 'loss_3': -16.46883773803711, 'loss_4': 0.00469527393579483, 'epoch': 26.69}
{'loss': 0.0032, 'grad_norm': 4.470668792724609, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.0026748308446258307, 'loss_2': 0.0005478858947753906, 'loss_3': -16.41947364807129, 'loss_4': -0.5332278609275818, 'epoch': 26.7}
{'loss': 0.0139, 'grad_norm': 10.581818580627441, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.013698202557861805, 'loss_2': 0.0002446174621582031, 'loss_3': -16.416391372680664, 'loss_4': 0.36484286189079285, 'epoch': 26.7}
{'loss': 0.0113, 'grad_norm': 5.5699591636657715, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.005884532351046801, 'loss_2': 0.00540924072265625, 'loss_3': -16.50958251953125, 'loss_4': -0.6085003614425659, 'epoch': 26.71}
{'loss': 0.0089, 'grad_norm': 4.93977689743042, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.006117409560829401, 'loss_2': 0.002826690673828125, 'loss_3': -16.483661651611328, 'loss_4': 0.3404167592525482, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 14:13:52,606 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:52,606 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:11<09:38,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:13:59,924 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015762845054268837, 'eval_runtime': 3.7858, 'eval_samples_per_second': 270.484, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.012683609500527382, 'eval_loss_2': 0.003079235553741455, 'eval_loss_3': -18.084035873413086, 'eval_loss_4': -0.10443869978189468, 'epoch': 26.72}
{'loss': 0.0084, 'grad_norm': 6.326414585113525, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.007462038192898035, 'loss_2': 0.0009126663208007812, 'loss_3': -16.228713989257812, 'loss_4': -0.09281644225120544, 'epoch': 26.72}
{'loss': 0.0096, 'grad_norm': 5.036460876464844, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.007035217247903347, 'loss_2': 0.0025615692138671875, 'loss_3': -16.226261138916016, 'loss_4': 0.05691681057214737, 'epoch': 26.73}
{'loss': 0.0067, 'grad_norm': 4.697467803955078, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.004141296725720167, 'loss_2': 0.00255584716796875, 'loss_3': -16.280305862426758, 'loss_4': -0.5331098437309265, 'epoch': 26.73}
{'loss': 0.0065, 'grad_norm': 4.791380882263184, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.004058121237903833, 'loss_2': 0.0024566650390625, 'loss_3': -16.188344955444336, 'loss_4': -0.22930386662483215, 'epoch': 26.74}
{'loss': 0.0116, 'grad_norm': 10.247040748596191, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.011164320632815361, 'loss_2': 0.0004582405090332031, 'loss_3': -16.50299835205078, 'loss_4': -0.17367205023765564, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 14:13:59,924 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:59,924 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:19<09:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:07,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01601029746234417, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.199, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012644094415009022, 'eval_loss_2': 0.0033662021160125732, 'eval_loss_3': -18.087677001953125, 'eval_loss_4': -0.08758476376533508, 'epoch': 26.74}
{'loss': 0.012, 'grad_norm': 7.283967018127441, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.009078044444322586, 'loss_2': 0.002960205078125, 'loss_3': -16.302610397338867, 'loss_4': -0.18831606209278107, 'epoch': 26.75}
{'loss': 0.0077, 'grad_norm': 4.693058967590332, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.004123599734157324, 'loss_2': 0.003582000732421875, 'loss_3': -16.531286239624023, 'loss_4': 0.18714189529418945, 'epoch': 26.76}
{'loss': 0.0058, 'grad_norm': 4.977605819702148, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.005411181598901749, 'loss_2': 0.00043582916259765625, 'loss_3': -16.36168098449707, 'loss_4': -0.2116299569606781, 'epoch': 26.76}
{'loss': 0.011, 'grad_norm': 4.605686187744141, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.002273157238960266, 'loss_2': 0.00875091552734375, 'loss_3': -16.364070892333984, 'loss_4': 0.4102494716644287, 'epoch': 26.77}
{'loss': 0.0051, 'grad_norm': 4.888894081115723, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.004936207085847855, 'loss_2': 0.00012874603271484375, 'loss_3': -16.39088249206543, 'loss_4': -0.07228471338748932, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 14:14:07,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:07,244 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:26<09:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:14,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016100924462080002, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.118, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012785489670932293, 'eval_loss_2': 0.0033154338598251343, 'eval_loss_3': -18.086698532104492, 'eval_loss_4': -0.0727178305387497, 'epoch': 26.77}
{'loss': 0.0082, 'grad_norm': 4.840723514556885, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.003760398831218481, 'loss_2': 0.00440216064453125, 'loss_3': -16.420896530151367, 'loss_4': -0.2513188421726227, 'epoch': 26.78}
{'loss': 0.0056, 'grad_norm': 4.547586441040039, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.0035091941244900227, 'loss_2': 0.0020961761474609375, 'loss_3': -16.431020736694336, 'loss_4': -0.3638456165790558, 'epoch': 26.78}
{'loss': 0.0087, 'grad_norm': 6.507120132446289, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.008045809343457222, 'loss_2': 0.0006575584411621094, 'loss_3': -16.518543243408203, 'loss_4': 0.020668473094701767, 'epoch': 26.79}
{'loss': 0.0042, 'grad_norm': 4.616520404815674, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.003885250771418214, 'loss_2': 0.0003211498260498047, 'loss_3': -16.511207580566406, 'loss_4': -0.1622757613658905, 'epoch': 26.8}
{'loss': 0.0086, 'grad_norm': 4.829609394073486, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.005062326323240995, 'loss_2': 0.003490447998046875, 'loss_3': -16.27328109741211, 'loss_4': -0.1249665915966034, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 14:14:14,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:14,573 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:33<09:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:21,906 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01606195978820324, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.667, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01296183280646801, 'eval_loss_2': 0.0031001269817352295, 'eval_loss_3': -18.082651138305664, 'eval_loss_4': -0.06766577064990997, 'epoch': 26.8}
{'loss': 0.0092, 'grad_norm': 4.9557108879089355, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.00670772697776556, 'loss_2': 0.0025234222412109375, 'loss_3': -16.515531539916992, 'loss_4': -0.5726731419563293, 'epoch': 26.81}
{'loss': 0.0432, 'grad_norm': 15.685040473937988, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.04307190701365471, 'loss_2': 0.00012218952178955078, 'loss_3': -16.413658142089844, 'loss_4': -0.24345332384109497, 'epoch': 26.81}
{'loss': 0.0084, 'grad_norm': 4.598321914672852, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.005507552530616522, 'loss_2': 0.002899169921875, 'loss_3': -16.183319091796875, 'loss_4': -0.03511684387922287, 'epoch': 26.82}
{'loss': 0.0095, 'grad_norm': 4.9525370597839355, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.0063620200380682945, 'loss_2': 0.0031490325927734375, 'loss_3': -16.323974609375, 'loss_4': 0.4480251371860504, 'epoch': 26.83}
{'loss': 0.0095, 'grad_norm': 6.240851879119873, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.009057425893843174, 'loss_2': 0.00045752525329589844, 'loss_3': -16.3604793548584, 'loss_4': -0.34252023696899414, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 14:14:21,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:21,906 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:41<09:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:29,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016864100471138954, 'eval_runtime': 3.7881, 'eval_samples_per_second': 270.319, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013860504142940044, 'eval_loss_2': 0.0030035972595214844, 'eval_loss_3': -18.07575225830078, 'eval_loss_4': -0.03538045659661293, 'epoch': 26.83}
{'loss': 0.0115, 'grad_norm': 4.440280437469482, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.002851212862879038, 'loss_2': 0.00865936279296875, 'loss_3': -16.581607818603516, 'loss_4': -0.19788213074207306, 'epoch': 26.84}
{'loss': 0.0061, 'grad_norm': 5.447540760040283, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.005563953425735235, 'loss_2': 0.0005741119384765625, 'loss_3': -16.310604095458984, 'loss_4': -0.3181849718093872, 'epoch': 26.84}
{'loss': 0.0069, 'grad_norm': 4.673089504241943, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.0049713957123458385, 'loss_2': 0.0019550323486328125, 'loss_3': -16.353620529174805, 'loss_4': -0.06249333918094635, 'epoch': 26.85}
{'loss': 0.007, 'grad_norm': 4.596425533294678, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.003916600253432989, 'loss_2': 0.0030975341796875, 'loss_3': -16.294147491455078, 'loss_4': 0.07626937329769135, 'epoch': 26.85}
{'loss': 0.0088, 'grad_norm': 5.148179054260254, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.005220968276262283, 'loss_2': 0.00362396240234375, 'loss_3': -16.37729263305664, 'loss_4': -0.18440666794776917, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 14:14:29,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:29,224 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:53:48<09:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:36,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016974961385130882, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.286, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.0142279751598835, 'eval_loss_2': 0.002746984362602234, 'eval_loss_3': -18.067096710205078, 'eval_loss_4': -0.006676888093352318, 'epoch': 26.86}
{'loss': 0.0074, 'grad_norm': 4.699710845947266, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.004579684231430292, 'loss_2': 0.0028476715087890625, 'loss_3': -16.375741958618164, 'loss_4': -0.359245628118515, 'epoch': 26.87}
{'loss': 0.0074, 'grad_norm': 4.705744743347168, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.00534818647429347, 'loss_2': 0.002071380615234375, 'loss_3': -16.548023223876953, 'loss_4': 0.529937207698822, 'epoch': 26.87}
{'loss': 0.0108, 'grad_norm': 5.269436836242676, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.0073544601909816265, 'loss_2': 0.003398895263671875, 'loss_3': -16.422204971313477, 'loss_4': 0.29251205921173096, 'epoch': 26.88}
{'loss': 0.0021, 'grad_norm': 4.414837837219238, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.001917208544909954, 'loss_2': 0.00018537044525146484, 'loss_3': -16.466915130615234, 'loss_4': -0.026104316115379333, 'epoch': 26.88}
{'loss': 0.0154, 'grad_norm': 6.353551387786865, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.009365173056721687, 'loss_2': 0.006072998046875, 'loss_3': -16.429594039916992, 'loss_4': 0.037949346005916595, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 14:14:36,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:36,547 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:53:55<09:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:43,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017470156773924828, 'eval_runtime': 3.7862, 'eval_samples_per_second': 270.452, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.015039999969303608, 'eval_loss_2': 0.002430155873298645, 'eval_loss_3': -18.067005157470703, 'eval_loss_4': -0.01066155917942524, 'epoch': 26.89}
{'loss': 0.0171, 'grad_norm': 7.812263488769531, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.01249459944665432, 'loss_2': 0.004638671875, 'loss_3': -16.459903717041016, 'loss_4': -0.11891964823007584, 'epoch': 26.9}
{'loss': 0.0067, 'grad_norm': 5.376391887664795, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.006180568132549524, 'loss_2': 0.0004963874816894531, 'loss_3': -16.434329986572266, 'loss_4': 0.2593960762023926, 'epoch': 26.9}
{'loss': 0.0082, 'grad_norm': 4.857667446136475, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.0020692073740065098, 'loss_2': 0.0061492919921875, 'loss_3': -16.41030502319336, 'loss_4': -0.05144774913787842, 'epoch': 26.91}
{'loss': 0.0055, 'grad_norm': 4.628711700439453, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.0034106855746358633, 'loss_2': 0.002056121826171875, 'loss_3': -16.384647369384766, 'loss_4': 0.25276631116867065, 'epoch': 26.91}
{'loss': 0.0059, 'grad_norm': 3.8670096397399902, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.0020908836741000414, 'loss_2': 0.00377655029296875, 'loss_3': -16.465190887451172, 'loss_4': 0.06000716984272003, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 14:14:43,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:43,856 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:54:03<09:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:51,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01821930520236492, 'eval_runtime': 3.7834, 'eval_samples_per_second': 270.657, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.015731794759631157, 'eval_loss_2': 0.0024875104427337646, 'eval_loss_3': -18.069725036621094, 'eval_loss_4': -0.010115276090800762, 'epoch': 26.92}
{'loss': 0.0048, 'grad_norm': 5.222427845001221, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.0032240403816103935, 'loss_2': 0.0015869140625, 'loss_3': -16.244325637817383, 'loss_4': 0.07720382511615753, 'epoch': 26.92}
{'loss': 0.0086, 'grad_norm': 5.659094333648682, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.0056788260117173195, 'loss_2': 0.00292205810546875, 'loss_3': -16.242725372314453, 'loss_4': -0.13502717018127441, 'epoch': 26.93}
{'loss': 0.0077, 'grad_norm': 4.990887641906738, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.00468809250742197, 'loss_2': 0.00301361083984375, 'loss_3': -16.526399612426758, 'loss_4': -0.2312338650226593, 'epoch': 26.94}
{'loss': 0.012, 'grad_norm': 6.686384677886963, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.008200614713132381, 'loss_2': 0.003841400146484375, 'loss_3': -16.34477424621582, 'loss_4': 0.02588389813899994, 'epoch': 26.94}
{'loss': 0.0099, 'grad_norm': 5.653806686401367, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.008056821301579475, 'loss_2': 0.0017938613891601562, 'loss_3': -16.407745361328125, 'loss_4': 0.1767858862876892, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 14:14:51,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:51,169 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:10<08:57,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:58,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018437597900629044, 'eval_runtime': 3.7901, 'eval_samples_per_second': 270.18, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01588853821158409, 'eval_loss_2': 0.0025490596890449524, 'eval_loss_3': -18.076528549194336, 'eval_loss_4': -0.011408388614654541, 'epoch': 26.95}
{'loss': 0.0055, 'grad_norm': 4.663949966430664, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.005446166265755892, 'loss_2': 2.658367156982422e-05, 'loss_3': -16.49850845336914, 'loss_4': -0.13726550340652466, 'epoch': 26.95}
{'loss': 0.0071, 'grad_norm': 5.003126621246338, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.004985606297850609, 'loss_2': 0.00212860107421875, 'loss_3': -16.31423568725586, 'loss_4': 0.35221225023269653, 'epoch': 26.96}
{'loss': 0.0129, 'grad_norm': 7.534914493560791, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.007816161029040813, 'loss_2': 0.00511932373046875, 'loss_3': -16.409992218017578, 'loss_4': 0.10844986140727997, 'epoch': 26.97}
{'loss': 0.0106, 'grad_norm': 6.006089210510254, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.008941657841205597, 'loss_2': 0.0016689300537109375, 'loss_3': -16.478416442871094, 'loss_4': -0.03652064502239227, 'epoch': 26.97}
{'loss': 0.0097, 'grad_norm': 5.507175445556641, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.006555850617587566, 'loss_2': 0.0031337738037109375, 'loss_3': -16.472219467163086, 'loss_4': -0.1710788607597351, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 14:14:58,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:58,492 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:17<08:21,  1.03it/s][INFO|trainer.py:4226] 2025-01-21 14:15:05,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018064133822917938, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.889, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.015464302152395248, 'eval_loss_2': 0.00259983167052269, 'eval_loss_3': -18.08449935913086, 'eval_loss_4': -0.01468281913548708, 'epoch': 26.98}
{'loss': 0.0173, 'grad_norm': 6.928580284118652, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.015195559710264206, 'loss_2': 0.00211334228515625, 'loss_3': -16.53732681274414, 'loss_4': 0.07375389337539673, 'epoch': 26.98}
{'loss': 0.007, 'grad_norm': 4.628814697265625, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0020200128201395273, 'loss_2': 0.00496673583984375, 'loss_3': -16.379878997802734, 'loss_4': 0.6932302117347717, 'epoch': 26.99}
{'loss': 0.0104, 'grad_norm': 5.745549201965332, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.006162253208458424, 'loss_2': 0.0042724609375, 'loss_3': -16.542734146118164, 'loss_4': 0.35884976387023926, 'epoch': 26.99}
{'loss': 0.0021, 'grad_norm': 6.736689567565918, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.0019360142759978771, 'loss_2': 0.00016927719116210938, 'loss_3': -16.372825622558594, 'loss_4': -0.15049059689044952, 'epoch': 27.0}
{'loss': 0.0064, 'grad_norm': 4.494486331939697, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.0023963951971381903, 'loss_2': 0.0040283203125, 'loss_3': -16.503231048583984, 'loss_4': 0.10365793853998184, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 14:15:05,504 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:05,505 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:24<08:42,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 14:15:12,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01772136799991131, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.512, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.014600461348891258, 'eval_loss_2': 0.00312090665102005, 'eval_loss_3': -18.09820556640625, 'eval_loss_4': -0.03853835165500641, 'epoch': 27.01}
{'loss': 0.0075, 'grad_norm': 4.610863208770752, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.004088282585144043, 'loss_2': 0.00339508056640625, 'loss_3': -16.14814567565918, 'loss_4': 0.14381060004234314, 'epoch': 27.01}
{'loss': 0.0052, 'grad_norm': 4.791092872619629, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.0025759267155081034, 'loss_2': 0.0026416778564453125, 'loss_3': -16.751258850097656, 'loss_4': 0.3615131974220276, 'epoch': 27.02}
{'loss': 0.006, 'grad_norm': 4.256150245666504, 'learning_rate': 3e-06, 'loss_1': 0.004351925570517778, 'loss_2': 0.0016689300537109375, 'loss_3': -16.289291381835938, 'loss_4': 0.5975905656814575, 'epoch': 27.02}
{'loss': 0.0196, 'grad_norm': 5.988918304443359, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.01684638299047947, 'loss_2': 0.00278472900390625, 'loss_3': -16.339231491088867, 'loss_4': -0.1522691398859024, 'epoch': 27.03}
{'loss': 0.0066, 'grad_norm': 4.989139080047607, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.005238255951553583, 'loss_2': 0.0013370513916015625, 'loss_3': -16.312393188476562, 'loss_4': -0.07935211807489395, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 14:15:12,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:12,825 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:32<08:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:20,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017018865793943405, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.508, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.013634469360113144, 'eval_loss_2': 0.0033843964338302612, 'eval_loss_3': -18.101240158081055, 'eval_loss_4': -0.06607700139284134, 'epoch': 27.03}
{'loss': 0.0047, 'grad_norm': 4.551850318908691, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.0027596005238592625, 'loss_2': 0.0019245147705078125, 'loss_3': -16.3948974609375, 'loss_4': 0.4258902072906494, 'epoch': 27.04}
{'loss': 0.006, 'grad_norm': 3.864457607269287, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.0033931653015315533, 'loss_2': 0.0026397705078125, 'loss_3': -16.360218048095703, 'loss_4': 0.30489447712898254, 'epoch': 27.05}
{'loss': 0.0083, 'grad_norm': 5.152520656585693, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.0038875225000083447, 'loss_2': 0.00438690185546875, 'loss_3': -16.429990768432617, 'loss_4': -0.10249590873718262, 'epoch': 27.05}
{'loss': 0.0114, 'grad_norm': 4.535933494567871, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.0026800050400197506, 'loss_2': 0.008697509765625, 'loss_3': -16.317214965820312, 'loss_4': -0.20651045441627502, 'epoch': 27.06}
{'loss': 0.0087, 'grad_norm': 4.566812992095947, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.006126113701611757, 'loss_2': 0.00261688232421875, 'loss_3': -16.49965476989746, 'loss_4': -0.25415340065956116, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 14:15:20,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:20,142 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:39<08:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:27,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017042212188243866, 'eval_runtime': 3.7855, 'eval_samples_per_second': 270.505, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.013485811650753021, 'eval_loss_2': 0.0035564005374908447, 'eval_loss_3': -18.10561180114746, 'eval_loss_4': -0.07070516049861908, 'epoch': 27.06}
{'loss': 0.0124, 'grad_norm': 8.772472381591797, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.009573956951498985, 'loss_2': 0.00278472900390625, 'loss_3': -16.487728118896484, 'loss_4': -0.038196906447410583, 'epoch': 27.07}
{'loss': 0.0063, 'grad_norm': 4.524040699005127, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.002402236219495535, 'loss_2': 0.0039005279541015625, 'loss_3': -16.40557098388672, 'loss_4': -0.22158753871917725, 'epoch': 27.08}
{'loss': 0.0057, 'grad_norm': 4.823048114776611, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.0034304459113627672, 'loss_2': 0.0023193359375, 'loss_3': -16.41132164001465, 'loss_4': 0.3208511173725128, 'epoch': 27.08}
{'loss': 0.0065, 'grad_norm': 4.85153341293335, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.003945665434002876, 'loss_2': 0.002529144287109375, 'loss_3': -16.381542205810547, 'loss_4': -0.37332776188850403, 'epoch': 27.09}
{'loss': 0.0085, 'grad_norm': 5.050046920776367, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.004170392639935017, 'loss_2': 0.00434112548828125, 'loss_3': -16.362895965576172, 'loss_4': 0.18475911021232605, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 14:15:27,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:27,457 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:54:46<08:31,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:34,777 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01711086742579937, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.958, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.01373516395688057, 'eval_loss_2': 0.003375701606273651, 'eval_loss_3': -18.10469627380371, 'eval_loss_4': -0.08953430503606796, 'epoch': 27.09}
{'loss': 0.0076, 'grad_norm': 4.618164539337158, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.0030272009316831827, 'loss_2': 0.00453948974609375, 'loss_3': -16.410512924194336, 'loss_4': 0.10659373551607132, 'epoch': 27.1}
{'loss': 0.0093, 'grad_norm': 4.9402899742126465, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.0050694760866463184, 'loss_2': 0.00426483154296875, 'loss_3': -16.423599243164062, 'loss_4': 0.19345948100090027, 'epoch': 27.1}
{'loss': 0.0109, 'grad_norm': 4.589992523193359, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.004356197081506252, 'loss_2': 0.0065765380859375, 'loss_3': -16.502412796020508, 'loss_4': 0.21973203122615814, 'epoch': 27.11}
{'loss': 0.0043, 'grad_norm': 4.907466888427734, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.003952661994844675, 'loss_2': 0.00034332275390625, 'loss_3': -16.29318618774414, 'loss_4': -0.08048506081104279, 'epoch': 27.12}
{'loss': 0.0099, 'grad_norm': 5.478564739227295, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.005832650698721409, 'loss_2': 0.00408172607421875, 'loss_3': -16.488990783691406, 'loss_4': 0.16639140248298645, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 14:15:34,777 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:34,777 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:54:54<08:26,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:42,101 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017063645645976067, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.668, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013820049352943897, 'eval_loss_2': 0.0032435953617095947, 'eval_loss_3': -18.106258392333984, 'eval_loss_4': -0.1204724907875061, 'epoch': 27.12}
{'loss': 0.0092, 'grad_norm': 4.850621223449707, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.004378677811473608, 'loss_2': 0.004863739013671875, 'loss_3': -16.45987319946289, 'loss_4': 0.17962788045406342, 'epoch': 27.13}
{'loss': 0.0102, 'grad_norm': 4.637890338897705, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.004781368654221296, 'loss_2': 0.00540924072265625, 'loss_3': -16.4344482421875, 'loss_4': -0.10688994079828262, 'epoch': 27.13}
{'loss': 0.0051, 'grad_norm': 4.936934947967529, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.00423339381814003, 'loss_2': 0.0008440017700195312, 'loss_3': -16.33260154724121, 'loss_4': -0.0007404237985610962, 'epoch': 27.14}
{'loss': 0.0085, 'grad_norm': 5.042851448059082, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.004050042945891619, 'loss_2': 0.00449371337890625, 'loss_3': -16.371509552001953, 'loss_4': -0.3804798722267151, 'epoch': 27.15}
{'loss': 0.0127, 'grad_norm': 5.836481094360352, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.011593140661716461, 'loss_2': 0.0010976791381835938, 'loss_3': -16.143356323242188, 'loss_4': -0.29215526580810547, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 14:15:42,101 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:42,101 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:55:01<08:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:49,412 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016930513083934784, 'eval_runtime': 3.7845, 'eval_samples_per_second': 270.58, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.014096117578446865, 'eval_loss_2': 0.0028343945741653442, 'eval_loss_3': -18.103397369384766, 'eval_loss_4': -0.11328031122684479, 'epoch': 27.15}
{'loss': 0.0103, 'grad_norm': 4.4622087478637695, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.0055918944999575615, 'loss_2': 0.004711151123046875, 'loss_3': -16.53829574584961, 'loss_4': -0.09463155269622803, 'epoch': 27.16}
{'loss': 0.022, 'grad_norm': 12.180517196655273, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.02041008323431015, 'loss_2': 0.0016040802001953125, 'loss_3': -16.398509979248047, 'loss_4': -0.3058581054210663, 'epoch': 27.16}
{'loss': 0.0082, 'grad_norm': 4.611773490905762, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.0042220428586006165, 'loss_2': 0.003940582275390625, 'loss_3': -16.211936950683594, 'loss_4': 0.08904889225959778, 'epoch': 27.17}
{'loss': 0.0063, 'grad_norm': 4.457000255584717, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.0026630025822669268, 'loss_2': 0.003658294677734375, 'loss_3': -16.28058624267578, 'loss_4': -0.2091887891292572, 'epoch': 27.17}
{'loss': 0.0069, 'grad_norm': 4.742798805236816, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.002791921840980649, 'loss_2': 0.004085540771484375, 'loss_3': -16.3613224029541, 'loss_4': -0.18664447963237762, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 14:15:49,412 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:49,412 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:08<08:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:15:56,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017420757561922073, 'eval_runtime': 3.7835, 'eval_samples_per_second': 270.646, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.014519130811095238, 'eval_loss_2': 0.002901628613471985, 'eval_loss_3': -18.103572845458984, 'eval_loss_4': -0.11138361692428589, 'epoch': 27.18}
{'loss': 0.0138, 'grad_norm': 4.982652187347412, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.0074911401607096195, 'loss_2': 0.00627899169921875, 'loss_3': -16.385711669921875, 'loss_4': -0.007771722972393036, 'epoch': 27.19}
{'loss': 0.0066, 'grad_norm': 4.995675086975098, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.0034012803807854652, 'loss_2': 0.003154754638671875, 'loss_3': -16.255882263183594, 'loss_4': -0.15790598094463348, 'epoch': 27.19}
{'loss': 0.0056, 'grad_norm': 4.701632499694824, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.003957604523748159, 'loss_2': 0.0016355514526367188, 'loss_3': -16.427349090576172, 'loss_4': -0.5819035172462463, 'epoch': 27.2}
{'loss': 0.0035, 'grad_norm': 4.657637119293213, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.0024514610413461924, 'loss_2': 0.0010852813720703125, 'loss_3': -16.28203010559082, 'loss_4': -0.04223643243312836, 'epoch': 27.2}
{'loss': 0.0026, 'grad_norm': 4.282789707183838, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.0016985863912850618, 'loss_2': 0.0009326934814453125, 'loss_3': -16.450714111328125, 'loss_4': -0.04119030386209488, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 14:15:56,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:56,722 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:16<08:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:04,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017647232860326767, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.193, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.014695582911372185, 'eval_loss_2': 0.0029516518115997314, 'eval_loss_3': -18.100223541259766, 'eval_loss_4': -0.10309511423110962, 'epoch': 27.21}
{'loss': 0.018, 'grad_norm': 6.243985652923584, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.012580843642354012, 'loss_2': 0.0054473876953125, 'loss_3': -16.26837158203125, 'loss_4': 0.13270239531993866, 'epoch': 27.22}
{'loss': 0.0107, 'grad_norm': 4.9766154289245605, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.003380843438208103, 'loss_2': 0.007366180419921875, 'loss_3': -16.38043212890625, 'loss_4': 0.0052536725997924805, 'epoch': 27.22}
{'loss': 0.0053, 'grad_norm': 4.973993301391602, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.004999500699341297, 'loss_2': 0.0003097057342529297, 'loss_3': -16.387981414794922, 'loss_4': 0.04051554203033447, 'epoch': 27.23}
{'loss': 0.0106, 'grad_norm': 6.071547508239746, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.005937360227108002, 'loss_2': 0.0046234130859375, 'loss_3': -16.616539001464844, 'loss_4': 0.017347708344459534, 'epoch': 27.23}
{'loss': 0.0075, 'grad_norm': 4.139114856719971, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.004373512230813503, 'loss_2': 0.00308990478515625, 'loss_3': -16.49273109436035, 'loss_4': 0.3359777331352234, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 14:16:04,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:04,042 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:23<08:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:11,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017630916088819504, 'eval_runtime': 3.783, 'eval_samples_per_second': 270.684, 'eval_steps_per_second': 4.229, 'eval_loss_1': 0.01460261084139347, 'eval_loss_2': 0.003028303384780884, 'eval_loss_3': -18.097070693969727, 'eval_loss_4': -0.09015073627233505, 'epoch': 27.24}
{'loss': 0.007, 'grad_norm': 4.567457675933838, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.0027076962869614363, 'loss_2': 0.00429534912109375, 'loss_3': -16.481550216674805, 'loss_4': 0.29301559925079346, 'epoch': 27.24}
{'loss': 0.0062, 'grad_norm': 4.885329246520996, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.005456981249153614, 'loss_2': 0.0007305145263671875, 'loss_3': -16.539125442504883, 'loss_4': 0.3754691481590271, 'epoch': 27.25}
{'loss': 0.0254, 'grad_norm': 13.143567085266113, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.022968506440520287, 'loss_2': 0.0024280548095703125, 'loss_3': -16.25196075439453, 'loss_4': 0.07866078615188599, 'epoch': 27.26}
{'loss': 0.0043, 'grad_norm': 8.406699180603027, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.0036622656043618917, 'loss_2': 0.0006513595581054688, 'loss_3': -16.347637176513672, 'loss_4': -0.414620041847229, 'epoch': 27.26}
{'loss': 0.017, 'grad_norm': 7.961267948150635, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.012084811925888062, 'loss_2': 0.004871368408203125, 'loss_3': -16.376312255859375, 'loss_4': 0.10138572752475739, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 14:16:11,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:11,356 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:30<08:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:18,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017224714159965515, 'eval_runtime': 3.7877, 'eval_samples_per_second': 270.35, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.014009096659719944, 'eval_loss_2': 0.0032156184315681458, 'eval_loss_3': -18.097715377807617, 'eval_loss_4': -0.07428379356861115, 'epoch': 27.27}
{'loss': 0.0068, 'grad_norm': 4.878015041351318, 'learning_rate': 2.75e-06, 'loss_1': 0.0036565694026649, 'loss_2': 0.00315093994140625, 'loss_3': -16.29935073852539, 'loss_4': -0.31962850689888, 'epoch': 27.27}
{'loss': 0.0131, 'grad_norm': 5.2125091552734375, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.008136555552482605, 'loss_2': 0.00494384765625, 'loss_3': -16.423887252807617, 'loss_4': -0.2997014820575714, 'epoch': 27.28}
{'loss': 0.0066, 'grad_norm': 5.049147129058838, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.005649937782436609, 'loss_2': 0.0009260177612304688, 'loss_3': -16.51992416381836, 'loss_4': 0.15470679104328156, 'epoch': 27.28}
{'loss': 0.0059, 'grad_norm': 4.8122172355651855, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.004904268775135279, 'loss_2': 0.0009613037109375, 'loss_3': -16.26278305053711, 'loss_4': 0.06970356404781342, 'epoch': 27.29}
{'loss': 0.0301, 'grad_norm': 18.25295639038086, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.026862556114792824, 'loss_2': 0.0032806396484375, 'loss_3': -16.361438751220703, 'loss_4': 0.7277283072471619, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 14:16:18,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:18,674 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:37<07:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:25,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017223916947841644, 'eval_runtime': 3.7889, 'eval_samples_per_second': 270.263, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.013853332959115505, 'eval_loss_2': 0.0033705830574035645, 'eval_loss_3': -18.101247787475586, 'eval_loss_4': -0.07533863186836243, 'epoch': 27.3}
{'loss': 0.0081, 'grad_norm': 5.438041687011719, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.0052093276754021645, 'loss_2': 0.00289154052734375, 'loss_3': -16.494630813598633, 'loss_4': -0.03178407996892929, 'epoch': 27.3}
{'loss': 0.0556, 'grad_norm': 18.487220764160156, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.04871271923184395, 'loss_2': 0.006862640380859375, 'loss_3': -16.48271942138672, 'loss_4': 0.4375278651714325, 'epoch': 27.31}
{'loss': 0.0349, 'grad_norm': 10.956151962280273, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.03245836868882179, 'loss_2': 0.0024127960205078125, 'loss_3': -16.490188598632812, 'loss_4': -0.3244048058986664, 'epoch': 27.31}
{'loss': 0.0146, 'grad_norm': 7.063111782073975, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.014051631093025208, 'loss_2': 0.0005397796630859375, 'loss_3': -16.445186614990234, 'loss_4': 0.07373905181884766, 'epoch': 27.32}
{'loss': 0.0124, 'grad_norm': 5.801594257354736, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.006796008907258511, 'loss_2': 0.005558013916015625, 'loss_3': -16.293869018554688, 'loss_4': 0.34497982263565063, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 14:16:25,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:25,996 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:55:45<07:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:33,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01759047992527485, 'eval_runtime': 3.7883, 'eval_samples_per_second': 270.308, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.0141378128901124, 'eval_loss_2': 0.0034526661038398743, 'eval_loss_3': -18.105335235595703, 'eval_loss_4': -0.09226512163877487, 'epoch': 27.33}
{'loss': 0.0057, 'grad_norm': 4.7580790519714355, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.00429120659828186, 'loss_2': 0.001399993896484375, 'loss_3': -16.37204360961914, 'loss_4': -0.45247524976730347, 'epoch': 27.33}
{'loss': 0.0091, 'grad_norm': 5.1937713623046875, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.003133980091661215, 'loss_2': 0.00594329833984375, 'loss_3': -16.342065811157227, 'loss_4': -0.19241566956043243, 'epoch': 27.34}
{'loss': 0.0143, 'grad_norm': 5.922831058502197, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.008244944736361504, 'loss_2': 0.0060577392578125, 'loss_3': -16.448047637939453, 'loss_4': 0.1517568975687027, 'epoch': 27.34}
{'loss': 0.0105, 'grad_norm': 4.77566385269165, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.0038058063946664333, 'loss_2': 0.00669097900390625, 'loss_3': -16.317230224609375, 'loss_4': 0.008033022284507751, 'epoch': 27.35}
{'loss': 0.0236, 'grad_norm': 15.05976676940918, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.022937513887882233, 'loss_2': 0.000637054443359375, 'loss_3': -16.370044708251953, 'loss_4': 0.2971949577331543, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 14:16:33,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:33,319 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:55:52<07:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:40,640 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017765812575817108, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.166, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014085419476032257, 'eval_loss_2': 0.003680393099784851, 'eval_loss_3': -18.103260040283203, 'eval_loss_4': -0.12314975261688232, 'epoch': 27.35}
{'loss': 0.0034, 'grad_norm': 4.223868370056152, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.0032824333757162094, 'loss_2': 7.426738739013672e-05, 'loss_3': -16.330904006958008, 'loss_4': -0.08540424704551697, 'epoch': 27.36}
{'loss': 0.009, 'grad_norm': 4.941840171813965, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.00532668037340045, 'loss_2': 0.00366973876953125, 'loss_3': -16.17529296875, 'loss_4': 0.07498452067375183, 'epoch': 27.37}
{'loss': 0.0083, 'grad_norm': 4.908336162567139, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.003615801455453038, 'loss_2': 0.004718780517578125, 'loss_3': -16.448169708251953, 'loss_4': -0.3193005323410034, 'epoch': 27.37}
{'loss': 0.0118, 'grad_norm': 7.515538692474365, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.011052819900214672, 'loss_2': 0.0007624626159667969, 'loss_3': -16.599407196044922, 'loss_4': 0.07054748386144638, 'epoch': 27.38}
{'loss': 0.0149, 'grad_norm': 7.827884674072266, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.008805138058960438, 'loss_2': 0.00609588623046875, 'loss_3': -16.470123291015625, 'loss_4': 0.22592894732952118, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 14:16:40,641 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:40,641 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:55:59<07:40,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:47,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01750975474715233, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.369, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013666121289134026, 'eval_loss_2': 0.003843635320663452, 'eval_loss_3': -18.105255126953125, 'eval_loss_4': -0.1426718831062317, 'epoch': 27.38}
{'loss': 0.0107, 'grad_norm': 5.295721054077148, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.005353466607630253, 'loss_2': 0.00536346435546875, 'loss_3': -16.24710464477539, 'loss_4': -0.2270699143409729, 'epoch': 27.39}
{'loss': 0.0079, 'grad_norm': 5.140563011169434, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.005105243530124426, 'loss_2': 0.0028285980224609375, 'loss_3': -16.346158981323242, 'loss_4': 0.4185590445995331, 'epoch': 27.4}
{'loss': 0.0585, 'grad_norm': 17.786481857299805, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.056502025574445724, 'loss_2': 0.002033233642578125, 'loss_3': -16.52086067199707, 'loss_4': 0.19579057395458221, 'epoch': 27.4}
{'loss': 0.0136, 'grad_norm': 6.378965854644775, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.012138484977185726, 'loss_2': 0.0014390945434570312, 'loss_3': -16.22262954711914, 'loss_4': 0.35994666814804077, 'epoch': 27.41}
{'loss': 0.0092, 'grad_norm': 5.9095611572265625, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.006953553296625614, 'loss_2': 0.0022373199462890625, 'loss_3': -16.340415954589844, 'loss_4': -0.04055934399366379, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 14:16:47,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:47,960 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:07<07:34,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:16:55,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016815930604934692, 'eval_runtime': 3.7869, 'eval_samples_per_second': 270.406, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.013274461030960083, 'eval_loss_2': 0.0035414695739746094, 'eval_loss_3': -18.11151885986328, 'eval_loss_4': -0.16082435846328735, 'epoch': 27.41}
{'loss': 0.0107, 'grad_norm': 4.885922908782959, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.0045568253844976425, 'loss_2': 0.00611114501953125, 'loss_3': -16.389623641967773, 'loss_4': -0.04979635775089264, 'epoch': 27.42}
{'loss': 0.0088, 'grad_norm': 5.734288215637207, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.0069837383925914764, 'loss_2': 0.0018157958984375, 'loss_3': -16.46746063232422, 'loss_4': -0.40188494324684143, 'epoch': 27.42}
{'loss': 0.0162, 'grad_norm': 7.5840744972229, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.009824656881392002, 'loss_2': 0.006412506103515625, 'loss_3': -16.165359497070312, 'loss_4': 0.07704624533653259, 'epoch': 27.43}
{'loss': 0.0085, 'grad_norm': 4.934337615966797, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.005530744791030884, 'loss_2': 0.002933502197265625, 'loss_3': -16.536893844604492, 'loss_4': 0.14064472913742065, 'epoch': 27.44}
{'loss': 0.0061, 'grad_norm': 5.912913799285889, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.0048808264546096325, 'loss_2': 0.0011768341064453125, 'loss_3': -16.435720443725586, 'loss_4': -0.32520151138305664, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 14:16:55,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:55,277 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:14<07:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:17:02,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01692410744726658, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.124, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013485277071595192, 'eval_loss_2': 0.0034388303756713867, 'eval_loss_3': -18.10959815979004, 'eval_loss_4': -0.1849168837070465, 'epoch': 27.44}
{'loss': 0.0077, 'grad_norm': 4.957810401916504, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.0033587904181331396, 'loss_2': 0.0043182373046875, 'loss_3': -16.506423950195312, 'loss_4': 0.16463005542755127, 'epoch': 27.45}
{'loss': 0.0098, 'grad_norm': 5.817512512207031, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.005987788550555706, 'loss_2': 0.003780364990234375, 'loss_3': -16.17667007446289, 'loss_4': -0.133028045296669, 'epoch': 27.45}
{'loss': 0.0176, 'grad_norm': 15.662434577941895, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.016761815175414085, 'loss_2': 0.0008697509765625, 'loss_3': -16.435993194580078, 'loss_4': -0.23926526308059692, 'epoch': 27.46}
{'loss': 0.0059, 'grad_norm': 4.823760986328125, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.005719288252294064, 'loss_2': 0.00019431114196777344, 'loss_3': -16.345230102539062, 'loss_4': 0.09660011529922485, 'epoch': 27.47}
{'loss': 0.0187, 'grad_norm': 10.078039169311523, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.014286466874182224, 'loss_2': 0.004367828369140625, 'loss_3': -16.26675033569336, 'loss_4': -0.3406757712364197, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 14:17:02,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:02,601 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:21<07:24,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:17:09,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01760164648294449, 'eval_runtime': 3.7852, 'eval_samples_per_second': 270.525, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.014024410396814346, 'eval_loss_2': 0.0035772323608398438, 'eval_loss_3': -18.107872009277344, 'eval_loss_4': -0.19089919328689575, 'epoch': 27.47}
{'loss': 0.0097, 'grad_norm': 6.036857604980469, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.007909134961664677, 'loss_2': 0.0018367767333984375, 'loss_3': -16.401933670043945, 'loss_4': -0.5391128063201904, 'epoch': 27.48}
{'loss': 0.0056, 'grad_norm': 5.274304389953613, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.0032083382830023766, 'loss_2': 0.0023746490478515625, 'loss_3': -16.474363327026367, 'loss_4': -0.22967800498008728, 'epoch': 27.48}
{'loss': 0.004, 'grad_norm': 4.652859210968018, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.003628699341788888, 'loss_2': 0.00037670135498046875, 'loss_3': -16.28539276123047, 'loss_4': 0.031973909586668015, 'epoch': 27.49}
{'loss': 0.0044, 'grad_norm': 4.449704170227051, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.0038402951322495937, 'loss_2': 0.0005311965942382812, 'loss_3': -16.358177185058594, 'loss_4': -0.13515615463256836, 'epoch': 27.49}
{'loss': 0.0076, 'grad_norm': 4.642573356628418, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.003617310430854559, 'loss_2': 0.003940582275390625, 'loss_3': -16.50200653076172, 'loss_4': 0.1958146095275879, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 14:17:09,920 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:09,920 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:29<07:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:17:17,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0178043395280838, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.129, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.014187587425112724, 'eval_loss_2': 0.0036167502403259277, 'eval_loss_3': -18.10519027709961, 'eval_loss_4': -0.22122400999069214, 'epoch': 27.5}
{'loss': 0.0107, 'grad_norm': 7.510653018951416, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.007811802439391613, 'loss_2': 0.0029087066650390625, 'loss_3': -16.242265701293945, 'loss_4': -0.2906529903411865, 'epoch': 27.51}
{'loss': 0.0058, 'grad_norm': 4.782256126403809, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.00466116052120924, 'loss_2': 0.0011186599731445312, 'loss_3': -16.4620361328125, 'loss_4': -0.30698493123054504, 'epoch': 27.51}
{'loss': 0.0051, 'grad_norm': 4.754438400268555, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.003427846822887659, 'loss_2': 0.0016613006591796875, 'loss_3': -16.442100524902344, 'loss_4': 0.2605428695678711, 'epoch': 27.52}
{'loss': 0.0055, 'grad_norm': 4.722953796386719, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.0037722503766417503, 'loss_2': 0.0017070770263671875, 'loss_3': -16.370113372802734, 'loss_4': -0.5275990962982178, 'epoch': 27.52}
{'loss': 0.0046, 'grad_norm': 4.453428268432617, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.004060715902596712, 'loss_2': 0.0005502700805664062, 'loss_3': -16.54024887084961, 'loss_4': -0.45348912477493286, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 14:17:17,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:17,246 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:36<07:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:24,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018281104043126106, 'eval_runtime': 3.7899, 'eval_samples_per_second': 270.191, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.01417333073914051, 'eval_loss_2': 0.004107773303985596, 'eval_loss_3': -18.105815887451172, 'eval_loss_4': -0.22747360169887543, 'epoch': 27.53}
{'loss': 0.013, 'grad_norm': 5.147271633148193, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.005185867194086313, 'loss_2': 0.00778961181640625, 'loss_3': -16.264535903930664, 'loss_4': -0.4656858742237091, 'epoch': 27.53}
{'loss': 0.0063, 'grad_norm': 5.257868766784668, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.003314591245725751, 'loss_2': 0.003017425537109375, 'loss_3': -16.385452270507812, 'loss_4': -0.36215853691101074, 'epoch': 27.54}
{'loss': 0.0074, 'grad_norm': 5.054809093475342, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.0028275453951209784, 'loss_2': 0.00460052490234375, 'loss_3': -16.34255599975586, 'loss_4': -0.27785593271255493, 'epoch': 27.55}
{'loss': 0.0072, 'grad_norm': 4.744295120239258, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.004667254164814949, 'loss_2': 0.0025482177734375, 'loss_3': -16.463382720947266, 'loss_4': -0.3226401209831238, 'epoch': 27.55}
{'loss': 0.006, 'grad_norm': 4.951663494110107, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.0029448906425386667, 'loss_2': 0.00301361083984375, 'loss_3': -16.28369140625, 'loss_4': -0.4342051148414612, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 14:17:24,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:24,584 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:56:43<07:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:31,922 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017182327806949615, 'eval_runtime': 3.7874, 'eval_samples_per_second': 270.367, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.013301528058946133, 'eval_loss_2': 0.003880798816680908, 'eval_loss_3': -18.103424072265625, 'eval_loss_4': -0.1992618888616562, 'epoch': 27.56}
{'loss': 0.0056, 'grad_norm': 4.800795078277588, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.0030556702986359596, 'loss_2': 0.0025634765625, 'loss_3': -16.48870849609375, 'loss_4': 0.15163101255893707, 'epoch': 27.56}
{'loss': 0.0059, 'grad_norm': 4.894384384155273, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.004010483156889677, 'loss_2': 0.00188446044921875, 'loss_3': -16.393266677856445, 'loss_4': 0.40937724709510803, 'epoch': 27.57}
{'loss': 0.0229, 'grad_norm': 11.617680549621582, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.016519879922270775, 'loss_2': 0.0063323974609375, 'loss_3': -16.47443389892578, 'loss_4': 0.11957279592752457, 'epoch': 27.58}
{'loss': 0.0255, 'grad_norm': 10.849525451660156, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.01460238080471754, 'loss_2': 0.01088714599609375, 'loss_3': -16.26936912536621, 'loss_4': -0.10029923170804977, 'epoch': 27.58}
{'loss': 0.024, 'grad_norm': 8.10163402557373, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.016779078170657158, 'loss_2': 0.0072479248046875, 'loss_3': -16.50437355041504, 'loss_4': -0.0447336807847023, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 14:17:31,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:31,922 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:56:51<07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:39,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017281413078308105, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01357068121433258, 'eval_loss_2': 0.003710731863975525, 'eval_loss_3': -18.106647491455078, 'eval_loss_4': -0.1969282478094101, 'epoch': 27.59}
{'loss': 0.0075, 'grad_norm': 4.265050888061523, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.0022895506117492914, 'loss_2': 0.0051727294921875, 'loss_3': -16.485477447509766, 'loss_4': -0.1622621715068817, 'epoch': 27.59}
{'loss': 0.0093, 'grad_norm': 5.338695049285889, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.0067300256341695786, 'loss_2': 0.00255584716796875, 'loss_3': -16.49633026123047, 'loss_4': -0.3827034831047058, 'epoch': 27.6}
{'loss': 0.0115, 'grad_norm': 4.981873035430908, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.0024015847593545914, 'loss_2': 0.0090789794921875, 'loss_3': -16.43036651611328, 'loss_4': -0.42701783776283264, 'epoch': 27.6}
{'loss': 0.0047, 'grad_norm': 4.853621959686279, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.0038210751954466105, 'loss_2': 0.000858306884765625, 'loss_3': -16.335365295410156, 'loss_4': -0.2519945502281189, 'epoch': 27.61}
{'loss': 0.0046, 'grad_norm': 5.07213020324707, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.0025164932012557983, 'loss_2': 0.0020599365234375, 'loss_3': -16.246501922607422, 'loss_4': 0.18060272932052612, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 14:17:39,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:39,273 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:56:58<06:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:46,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016524776816368103, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.092, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013218470849096775, 'eval_loss_2': 0.0033063068985939026, 'eval_loss_3': -18.11023712158203, 'eval_loss_4': -0.19221848249435425, 'epoch': 27.62}
{'loss': 0.0068, 'grad_norm': 4.836544513702393, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.0031187552958726883, 'loss_2': 0.0037078857421875, 'loss_3': -16.266273498535156, 'loss_4': 0.21443624794483185, 'epoch': 27.62}
{'loss': 0.0023, 'grad_norm': 4.661027431488037, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0022115479223430157, 'loss_2': 0.00012993812561035156, 'loss_3': -16.354263305664062, 'loss_4': -0.0841137021780014, 'epoch': 27.63}
{'loss': 0.0149, 'grad_norm': 7.976754188537598, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.014127302914857864, 'loss_2': 0.00074005126953125, 'loss_3': -16.254478454589844, 'loss_4': -0.19683510065078735, 'epoch': 27.63}
{'loss': 0.0039, 'grad_norm': 4.852318286895752, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.002578526735305786, 'loss_2': 0.001277923583984375, 'loss_3': -16.295881271362305, 'loss_4': -0.03532661497592926, 'epoch': 27.64}
{'loss': 0.009, 'grad_norm': 4.634403228759766, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.0038308475632220507, 'loss_2': 0.00521087646484375, 'loss_3': -16.292282104492188, 'loss_4': -0.1574791967868805, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 14:17:46,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:46,607 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:05<06:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:53,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016247384250164032, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.046, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013354174792766571, 'eval_loss_2': 0.002893209457397461, 'eval_loss_3': -18.105815887451172, 'eval_loss_4': -0.1746966689825058, 'epoch': 27.65}
{'loss': 0.0032, 'grad_norm': 5.130863189697266, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.002790721133351326, 'loss_2': 0.0004177093505859375, 'loss_3': -16.338111877441406, 'loss_4': -0.036725401878356934, 'epoch': 27.65}
{'loss': 0.0048, 'grad_norm': 4.691167831420898, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.0028168733697384596, 'loss_2': 0.001979827880859375, 'loss_3': -16.398950576782227, 'loss_4': -0.07481174170970917, 'epoch': 27.66}
{'loss': 0.0071, 'grad_norm': 4.777419567108154, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.0039823600091040134, 'loss_2': 0.003086090087890625, 'loss_3': -16.461851119995117, 'loss_4': 0.014853119850158691, 'epoch': 27.66}
{'loss': 0.0105, 'grad_norm': 4.350399017333984, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.004317418206483126, 'loss_2': 0.00621795654296875, 'loss_3': -16.208707809448242, 'loss_4': -0.191875159740448, 'epoch': 27.67}
{'loss': 0.0117, 'grad_norm': 9.182642936706543, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.010473697446286678, 'loss_2': 0.0012197494506835938, 'loss_3': -16.394065856933594, 'loss_4': 0.4972233772277832, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 14:17:53,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:53,952 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:13<06:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:01,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016560092568397522, 'eval_runtime': 3.7915, 'eval_samples_per_second': 270.079, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013644656166434288, 'eval_loss_2': 0.0029154345393180847, 'eval_loss_3': -18.10691261291504, 'eval_loss_4': -0.16322359442710876, 'epoch': 27.67}
{'loss': 0.005, 'grad_norm': 4.627092361450195, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.003787400433793664, 'loss_2': 0.0012531280517578125, 'loss_3': -16.380279541015625, 'loss_4': -0.22835217416286469, 'epoch': 27.68}
{'loss': 0.0065, 'grad_norm': 6.72262716293335, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.006211651489138603, 'loss_2': 0.0002923011779785156, 'loss_3': -16.330232620239258, 'loss_4': 0.3504351079463959, 'epoch': 27.69}
{'loss': 0.0104, 'grad_norm': 5.923884868621826, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.00846070982515812, 'loss_2': 0.0019378662109375, 'loss_3': -16.31024932861328, 'loss_4': -0.15766547620296478, 'epoch': 27.69}
{'loss': 0.0061, 'grad_norm': 5.358764171600342, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.004839332774281502, 'loss_2': 0.0012569427490234375, 'loss_3': -16.23274040222168, 'loss_4': -0.02042257785797119, 'epoch': 27.7}
{'loss': 0.0142, 'grad_norm': 5.002252578735352, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.0033215698786079884, 'loss_2': 0.010833740234375, 'loss_3': -16.44389533996582, 'loss_4': 0.12986420094966888, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 14:18:01,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:01,289 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:20<06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:08,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01611464098095894, 'eval_runtime': 3.7908, 'eval_samples_per_second': 270.126, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.013219553977251053, 'eval_loss_2': 0.0028950870037078857, 'eval_loss_3': -18.110694885253906, 'eval_loss_4': -0.1396331936120987, 'epoch': 27.7}
{'loss': 0.0028, 'grad_norm': 4.479644298553467, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.0026996119413524866, 'loss_2': 6.723403930664062e-05, 'loss_3': -16.448612213134766, 'loss_4': -0.4171542823314667, 'epoch': 27.71}
{'loss': 0.0083, 'grad_norm': 4.716327667236328, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.005297493655234575, 'loss_2': 0.00296783447265625, 'loss_3': -16.37633514404297, 'loss_4': 0.3079864978790283, 'epoch': 27.72}
{'loss': 0.0145, 'grad_norm': 7.066753387451172, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.009656871668994427, 'loss_2': 0.0048065185546875, 'loss_3': -16.54307746887207, 'loss_4': 0.00569424033164978, 'epoch': 27.72}
{'loss': 0.0125, 'grad_norm': 5.347010135650635, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.006186776794493198, 'loss_2': 0.00630950927734375, 'loss_3': -16.323453903198242, 'loss_4': -0.10927873849868774, 'epoch': 27.73}
{'loss': 0.0056, 'grad_norm': 4.851154804229736, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.00422009127214551, 'loss_2': 0.0014095306396484375, 'loss_3': -16.49842643737793, 'loss_4': 0.10738373547792435, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 14:18:08,627 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:08,627 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:27<06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:15,973 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015742145478725433, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012809551320970058, 'eval_loss_2': 0.0029325932264328003, 'eval_loss_3': -18.119159698486328, 'eval_loss_4': -0.11396349966526031, 'epoch': 27.73}
{'loss': 0.008, 'grad_norm': 5.035745620727539, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.00516521604731679, 'loss_2': 0.00284576416015625, 'loss_3': -16.485946655273438, 'loss_4': -0.5064826011657715, 'epoch': 27.74}
{'loss': 0.0018, 'grad_norm': 4.293178081512451, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.0017529975157231092, 'loss_2': 8.654594421386719e-05, 'loss_3': -16.45566177368164, 'loss_4': 0.10141348838806152, 'epoch': 27.74}
{'loss': 0.0041, 'grad_norm': 4.944762706756592, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.004017107654362917, 'loss_2': 0.00011026859283447266, 'loss_3': -16.41566276550293, 'loss_4': 0.17002972960472107, 'epoch': 27.75}
{'loss': 0.0055, 'grad_norm': 4.550471305847168, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.0033728615380823612, 'loss_2': 0.002147674560546875, 'loss_3': -16.424877166748047, 'loss_4': -0.10089722275733948, 'epoch': 27.76}
{'loss': 0.007, 'grad_norm': 4.543771266937256, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.004389635752886534, 'loss_2': 0.00257110595703125, 'loss_3': -16.39223861694336, 'loss_4': -0.012777842581272125, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 14:18:15,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:15,973 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:35<06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:23,316 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01617630384862423, 'eval_runtime': 3.7913, 'eval_samples_per_second': 270.092, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013262039050459862, 'eval_loss_2': 0.0029142647981643677, 'eval_loss_3': -18.12267303466797, 'eval_loss_4': -0.12146618962287903, 'epoch': 27.76}
{'loss': 0.0149, 'grad_norm': 5.453607082366943, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.006592364050447941, 'loss_2': 0.00835418701171875, 'loss_3': -16.583580017089844, 'loss_4': 0.05753936618566513, 'epoch': 27.77}
{'loss': 0.0044, 'grad_norm': 4.762495994567871, 'learning_rate': 2.25e-06, 'loss_1': 0.003432393306866288, 'loss_2': 0.000988006591796875, 'loss_3': -16.366558074951172, 'loss_4': -0.010023653507232666, 'epoch': 27.77}
{'loss': 0.0139, 'grad_norm': 5.730316162109375, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.0075029232539236546, 'loss_2': 0.00640106201171875, 'loss_3': -16.409618377685547, 'loss_4': -0.03131692111492157, 'epoch': 27.78}
{'loss': 0.0088, 'grad_norm': 4.7167067527771, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.004717591218650341, 'loss_2': 0.00405120849609375, 'loss_3': -16.5762882232666, 'loss_4': 0.0659865140914917, 'epoch': 27.78}
{'loss': 0.01, 'grad_norm': 4.524320602416992, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.004252975340932608, 'loss_2': 0.005741119384765625, 'loss_3': -16.23697853088379, 'loss_4': -0.36411648988723755, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 14:18:23,317 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:23,317 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:42<06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:30,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016334939748048782, 'eval_runtime': 3.7925, 'eval_samples_per_second': 270.007, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013549869880080223, 'eval_loss_2': 0.0027850717306137085, 'eval_loss_3': -18.126039505004883, 'eval_loss_4': -0.14062368869781494, 'epoch': 27.79}
{'loss': 0.0079, 'grad_norm': 4.753695487976074, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.0030617662705481052, 'loss_2': 0.004833221435546875, 'loss_3': -16.393917083740234, 'loss_4': -0.04182538390159607, 'epoch': 27.8}
{'loss': 0.0063, 'grad_norm': 4.5123796463012695, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.0038514751940965652, 'loss_2': 0.002452850341796875, 'loss_3': -16.274789810180664, 'loss_4': -0.3064163327217102, 'epoch': 27.8}
{'loss': 0.0062, 'grad_norm': 5.399264812469482, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.005445370450615883, 'loss_2': 0.0007266998291015625, 'loss_3': -16.340545654296875, 'loss_4': 0.06750711053609848, 'epoch': 27.81}
{'loss': 0.0144, 'grad_norm': 4.742546081542969, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.004777946043759584, 'loss_2': 0.0095977783203125, 'loss_3': -16.4209041595459, 'loss_4': -0.2730811834335327, 'epoch': 27.81}
{'loss': 0.0066, 'grad_norm': 4.660518169403076, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.003813947318121791, 'loss_2': 0.0027904510498046875, 'loss_3': -16.342147827148438, 'loss_4': -0.15585489571094513, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 14:18:30,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:30,654 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:57:49<06:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:37,998 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016522862017154694, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.05, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013504154048860073, 'eval_loss_2': 0.003018707036972046, 'eval_loss_3': -18.129648208618164, 'eval_loss_4': -0.15055719017982483, 'epoch': 27.82}
{'loss': 0.0053, 'grad_norm': 4.779809474945068, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.001973837148398161, 'loss_2': 0.003345489501953125, 'loss_3': -16.424182891845703, 'loss_4': 0.12041294574737549, 'epoch': 27.83}
{'loss': 0.011, 'grad_norm': 5.075397491455078, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.0055654654279351234, 'loss_2': 0.005462646484375, 'loss_3': -16.321372985839844, 'loss_4': -0.34713831543922424, 'epoch': 27.83}
{'loss': 0.0128, 'grad_norm': 6.475111484527588, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.00939140934497118, 'loss_2': 0.003437042236328125, 'loss_3': -16.35759162902832, 'loss_4': -0.022325485944747925, 'epoch': 27.84}
{'loss': 0.04, 'grad_norm': 7.421751976013184, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.039532314985990524, 'loss_2': 0.0004673004150390625, 'loss_3': -16.509614944458008, 'loss_4': 0.4528844952583313, 'epoch': 27.84}
{'loss': 0.0116, 'grad_norm': 6.530886173248291, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.0077393073588609695, 'loss_2': 0.00389862060546875, 'loss_3': -16.406044006347656, 'loss_4': 0.048355892300605774, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 14:18:37,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:37,998 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:57:57<06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:45,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016478020697832108, 'eval_runtime': 3.7894, 'eval_samples_per_second': 270.226, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.013483617454767227, 'eval_loss_2': 0.0029944032430648804, 'eval_loss_3': -18.12306785583496, 'eval_loss_4': -0.16009829938411713, 'epoch': 27.85}
{'loss': 0.0059, 'grad_norm': 5.253859043121338, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.004364002030342817, 'loss_2': 0.0015506744384765625, 'loss_3': -16.331581115722656, 'loss_4': -0.23324935138225555, 'epoch': 27.85}
{'loss': 0.0054, 'grad_norm': 5.141323089599609, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.0035552452318370342, 'loss_2': 0.0018596649169921875, 'loss_3': -16.392982482910156, 'loss_4': -0.12390375137329102, 'epoch': 27.86}
{'loss': 0.0055, 'grad_norm': 4.84257698059082, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.004562074784189463, 'loss_2': 0.0009670257568359375, 'loss_3': -16.268909454345703, 'loss_4': -0.3426349461078644, 'epoch': 27.87}
{'loss': 0.0027, 'grad_norm': 4.522983074188232, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.002177328569814563, 'loss_2': 0.000553131103515625, 'loss_3': -16.597497940063477, 'loss_4': -0.32498785853385925, 'epoch': 27.87}
{'loss': 0.0132, 'grad_norm': 4.53130578994751, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.004359343554824591, 'loss_2': 0.00884246826171875, 'loss_3': -16.33639144897461, 'loss_4': -0.2679292559623718, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 14:18:45,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:45,329 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:04<06:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:52,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01634066365659237, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.295, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013618819415569305, 'eval_loss_2': 0.002721846103668213, 'eval_loss_3': -18.119091033935547, 'eval_loss_4': -0.163762629032135, 'epoch': 27.88}
{'loss': 0.0061, 'grad_norm': 4.7724609375, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.00588670838624239, 'loss_2': 0.0001800060272216797, 'loss_3': -16.37700080871582, 'loss_4': -0.39084523916244507, 'epoch': 27.88}
{'loss': 0.0074, 'grad_norm': 4.654673099517822, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.0016968331765383482, 'loss_2': 0.005718231201171875, 'loss_3': -16.428260803222656, 'loss_4': -0.205282062292099, 'epoch': 27.89}
{'loss': 0.0043, 'grad_norm': 4.563209533691406, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.0038695891853421926, 'loss_2': 0.000476837158203125, 'loss_3': -16.38658905029297, 'loss_4': -0.14740337431430817, 'epoch': 27.9}
{'loss': 0.0085, 'grad_norm': 5.304615020751953, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.0035249865613877773, 'loss_2': 0.00498199462890625, 'loss_3': -16.313077926635742, 'loss_4': -0.3485147953033447, 'epoch': 27.9}
{'loss': 0.0059, 'grad_norm': 4.83069372177124, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.0030569324735552073, 'loss_2': 0.002826690673828125, 'loss_3': -16.18008804321289, 'loss_4': 0.04308406636118889, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 14:18:52,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:52,674 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:12<06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:00,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016302181407809258, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.788, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013575801625847816, 'eval_loss_2': 0.002726379781961441, 'eval_loss_3': -18.11675262451172, 'eval_loss_4': -0.16661128401756287, 'epoch': 27.91}
{'loss': 0.0092, 'grad_norm': 4.936763286590576, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.004326661117374897, 'loss_2': 0.00489044189453125, 'loss_3': -16.275020599365234, 'loss_4': -0.8748462200164795, 'epoch': 27.91}
{'loss': 0.0065, 'grad_norm': 4.66256046295166, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.003372389590367675, 'loss_2': 0.003170013427734375, 'loss_3': -16.406097412109375, 'loss_4': -0.42887812852859497, 'epoch': 27.92}
{'loss': 0.0071, 'grad_norm': 4.377789497375488, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.003112165490165353, 'loss_2': 0.0040283203125, 'loss_3': -16.339031219482422, 'loss_4': 0.3471449911594391, 'epoch': 27.92}
{'loss': 0.0484, 'grad_norm': 17.092784881591797, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.044652003794908524, 'loss_2': 0.003787994384765625, 'loss_3': -16.298133850097656, 'loss_4': 0.7368572354316711, 'epoch': 27.93}
{'loss': 0.0129, 'grad_norm': 5.245513439178467, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.0054177106358110905, 'loss_2': 0.00753021240234375, 'loss_3': -16.380828857421875, 'loss_4': -0.46135586500167847, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 14:19:00,024 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:00,025 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:19<06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:07,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015723202377557755, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.217, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.012913498096168041, 'eval_loss_2': 0.0028097033500671387, 'eval_loss_3': -18.120616912841797, 'eval_loss_4': -0.1575244665145874, 'epoch': 27.94}
{'loss': 0.0091, 'grad_norm': 8.355854988098145, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.007861838676035404, 'loss_2': 0.0012035369873046875, 'loss_3': -16.50802993774414, 'loss_4': 0.26025304198265076, 'epoch': 27.94}
{'loss': 0.0074, 'grad_norm': 4.845426559448242, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.00295115914195776, 'loss_2': 0.00446319580078125, 'loss_3': -16.524410247802734, 'loss_4': 0.25013506412506104, 'epoch': 27.95}
{'loss': 0.005, 'grad_norm': 4.814116477966309, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.0035955323837697506, 'loss_2': 0.00144195556640625, 'loss_3': -16.633333206176758, 'loss_4': 0.030314065515995026, 'epoch': 27.95}
{'loss': 0.0064, 'grad_norm': 4.475430011749268, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.0027571090031415224, 'loss_2': 0.0036182403564453125, 'loss_3': -16.39240074157715, 'loss_4': -0.022113781422376633, 'epoch': 27.96}
{'loss': 0.0105, 'grad_norm': 5.477256774902344, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.007308751344680786, 'loss_2': 0.003173828125, 'loss_3': -16.440183639526367, 'loss_4': -0.06102653592824936, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 14:19:07,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:07,364 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:26<05:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:19:14,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015940416604280472, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.993, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.013050965033471584, 'eval_loss_2': 0.0028894543647766113, 'eval_loss_3': -18.119834899902344, 'eval_loss_4': -0.14303812384605408, 'epoch': 27.97}
{'loss': 0.0112, 'grad_norm': 4.694654941558838, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.005189377348870039, 'loss_2': 0.006011962890625, 'loss_3': -16.31827163696289, 'loss_4': -0.5345941781997681, 'epoch': 27.97}
{'loss': 0.0084, 'grad_norm': 4.796692848205566, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.00378226675093174, 'loss_2': 0.0046234130859375, 'loss_3': -16.203929901123047, 'loss_4': 0.26118332147598267, 'epoch': 27.98}
{'loss': 0.011, 'grad_norm': 4.450157642364502, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.0038809478282928467, 'loss_2': 0.007110595703125, 'loss_3': -16.378307342529297, 'loss_4': -0.46642008423805237, 'epoch': 27.98}
{'loss': 0.0091, 'grad_norm': 4.85943603515625, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.004498133901506662, 'loss_2': 0.00463104248046875, 'loss_3': -16.377336502075195, 'loss_4': 0.22847668826580048, 'epoch': 27.99}
{'loss': 0.008, 'grad_norm': 5.019914627075195, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.006830556783825159, 'loss_2': 0.0011501312255859375, 'loss_3': -16.49161148071289, 'loss_4': -0.0005411058664321899, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 14:19:14,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:14,686 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:33<05:45,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 14:19:21,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01592627912759781, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013214744627475739, 'eval_loss_2': 0.0027115345001220703, 'eval_loss_3': -18.11775779724121, 'eval_loss_4': -0.13998495042324066, 'epoch': 27.99}
{'loss': 0.0057, 'grad_norm': 6.387868404388428, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0006118572782725096, 'loss_2': 0.00504302978515625, 'loss_3': -16.52569007873535, 'loss_4': 0.5064006447792053, 'epoch': 28.0}
{'loss': 0.0219, 'grad_norm': 8.943281173706055, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.011976385489106178, 'loss_2': 0.0099029541015625, 'loss_3': -16.429840087890625, 'loss_4': -0.16231971979141235, 'epoch': 28.01}
{'loss': 0.0047, 'grad_norm': 4.226670742034912, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.0025040125474333763, 'loss_2': 0.002208709716796875, 'loss_3': -16.3283748626709, 'loss_4': 0.11348667740821838, 'epoch': 28.01}
{'loss': 0.0048, 'grad_norm': 5.098488807678223, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.00317244790494442, 'loss_2': 0.0016231536865234375, 'loss_3': -16.384048461914062, 'loss_4': -0.49274590611457825, 'epoch': 28.02}
{'loss': 0.0069, 'grad_norm': 5.065308094024658, 'learning_rate': 2e-06, 'loss_1': 0.005710274446755648, 'loss_2': 0.0011587142944335938, 'loss_3': -16.506685256958008, 'loss_4': 0.5759356021881104, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 14:19:21,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:21,738 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:41<05:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:19:29,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015767911449074745, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.691, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01317615993320942, 'eval_loss_2': 0.002591751515865326, 'eval_loss_3': -18.115455627441406, 'eval_loss_4': -0.1354389488697052, 'epoch': 28.02}
{'loss': 0.0826, 'grad_norm': 14.20171070098877, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.07570432126522064, 'loss_2': 0.006916046142578125, 'loss_3': -16.315040588378906, 'loss_4': 0.4067647457122803, 'epoch': 28.03}
{'loss': 0.0052, 'grad_norm': 4.637570381164551, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.004436057526618242, 'loss_2': 0.0007781982421875, 'loss_3': -16.51931381225586, 'loss_4': -0.3301723599433899, 'epoch': 28.03}
{'loss': 0.0077, 'grad_norm': 4.673492431640625, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.004960538819432259, 'loss_2': 0.002696990966796875, 'loss_3': -16.341602325439453, 'loss_4': 0.48696595430374146, 'epoch': 28.04}
{'loss': 0.0035, 'grad_norm': 5.0006561279296875, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.0027126045897603035, 'loss_2': 0.0007910728454589844, 'loss_3': -16.4112491607666, 'loss_4': -0.16621822118759155, 'epoch': 28.05}
{'loss': 0.0124, 'grad_norm': 5.03794527053833, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.0068916622549295425, 'loss_2': 0.00553131103515625, 'loss_3': -16.227535247802734, 'loss_4': -0.060942381620407104, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 14:19:29,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:29,081 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:58:48<05:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:36,429 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015285777859389782, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.846, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012775275856256485, 'eval_loss_2': 0.0025105029344558716, 'eval_loss_3': -18.114559173583984, 'eval_loss_4': -0.10641741752624512, 'epoch': 28.05}
{'loss': 0.0138, 'grad_norm': 8.539116859436035, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.011879375204443932, 'loss_2': 0.0019235610961914062, 'loss_3': -16.3260498046875, 'loss_4': 0.09122515469789505, 'epoch': 28.06}
{'loss': 0.0044, 'grad_norm': 5.01498556137085, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.0040980251505970955, 'loss_2': 0.000324249267578125, 'loss_3': -16.379968643188477, 'loss_4': 0.18237844109535217, 'epoch': 28.06}
{'loss': 0.0068, 'grad_norm': 5.366959571838379, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.00540397921577096, 'loss_2': 0.0014247894287109375, 'loss_3': -16.256107330322266, 'loss_4': -0.16460755467414856, 'epoch': 28.07}
{'loss': 0.0076, 'grad_norm': 4.742201805114746, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.006203234661370516, 'loss_2': 0.0013933181762695312, 'loss_3': -16.474891662597656, 'loss_4': 0.2147928774356842, 'epoch': 28.08}
{'loss': 0.0045, 'grad_norm': 4.439175128936768, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.0023668059147894382, 'loss_2': 0.002124786376953125, 'loss_3': -16.39456558227539, 'loss_4': -0.38585716485977173, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 14:19:36,429 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:36,429 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:58:55<05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:43,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0150798000395298, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.158, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.01258944720029831, 'eval_loss_2': 0.002490352839231491, 'eval_loss_3': -18.10979652404785, 'eval_loss_4': -0.10288877785205841, 'epoch': 28.08}
{'loss': 0.0062, 'grad_norm': 5.358427047729492, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.005456821992993355, 'loss_2': 0.0007710456848144531, 'loss_3': -16.5770263671875, 'loss_4': -0.045478470623493195, 'epoch': 28.09}
{'loss': 0.0047, 'grad_norm': 4.481088638305664, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.0032728295773267746, 'loss_2': 0.0014133453369140625, 'loss_3': -16.448963165283203, 'loss_4': -0.1556166559457779, 'epoch': 28.09}
{'loss': 0.0062, 'grad_norm': 4.4405107498168945, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.002554377308115363, 'loss_2': 0.00360107421875, 'loss_3': -16.44327163696289, 'loss_4': -0.2785114049911499, 'epoch': 28.1}
{'loss': 0.0156, 'grad_norm': 6.869311809539795, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.0092838229611516, 'loss_2': 0.006305694580078125, 'loss_3': -16.51421356201172, 'loss_4': -0.11060928553342819, 'epoch': 28.1}
{'loss': 0.0063, 'grad_norm': 4.574312686920166, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.00413359422236681, 'loss_2': 0.002117156982421875, 'loss_3': -16.283161163330078, 'loss_4': -0.23827886581420898, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 14:19:43,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:43,771 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:03<05:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:51,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014605124481022358, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.096, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012150099501013756, 'eval_loss_2': 0.0024550259113311768, 'eval_loss_3': -18.110366821289062, 'eval_loss_4': -0.10034254938364029, 'epoch': 28.11}
{'loss': 0.0091, 'grad_norm': 4.629842281341553, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.0019140200456604362, 'loss_2': 0.00717926025390625, 'loss_3': -16.554515838623047, 'loss_4': -0.06807272136211395, 'epoch': 28.12}
{'loss': 0.0106, 'grad_norm': 4.633193492889404, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.0031905153300613165, 'loss_2': 0.007389068603515625, 'loss_3': -16.193130493164062, 'loss_4': 0.15364563465118408, 'epoch': 28.12}
{'loss': 0.0041, 'grad_norm': 4.730934143066406, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.0037886749487370253, 'loss_2': 0.0003287792205810547, 'loss_3': -16.425817489624023, 'loss_4': -0.1745644062757492, 'epoch': 28.13}
{'loss': 0.0381, 'grad_norm': 20.9107608795166, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.037133291363716125, 'loss_2': 0.0009326934814453125, 'loss_3': -16.40227508544922, 'loss_4': -0.20014075934886932, 'epoch': 28.13}
{'loss': 0.0079, 'grad_norm': 5.5414557456970215, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.00417756661772728, 'loss_2': 0.0037364959716796875, 'loss_3': -16.443876266479492, 'loss_4': 0.3749698996543884, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 14:19:51,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:51,107 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:10<05:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:19:58,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014275697991251945, 'eval_runtime': 3.793, 'eval_samples_per_second': 269.972, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.011783672496676445, 'eval_loss_2': 0.0024920254945755005, 'eval_loss_3': -18.107603073120117, 'eval_loss_4': -0.08989307284355164, 'epoch': 28.14}
{'loss': 0.0073, 'grad_norm': 5.317412853240967, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.004879905842244625, 'loss_2': 0.002460479736328125, 'loss_3': -16.14603614807129, 'loss_4': 0.32542309165000916, 'epoch': 28.15}
{'loss': 0.0098, 'grad_norm': 5.444033622741699, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.006341909058392048, 'loss_2': 0.003452301025390625, 'loss_3': -16.209415435791016, 'loss_4': -0.18896618485450745, 'epoch': 28.15}
{'loss': 0.0056, 'grad_norm': 5.181835174560547, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.005536805838346481, 'loss_2': 0.00010919570922851562, 'loss_3': -16.32850456237793, 'loss_4': -0.2575640380382538, 'epoch': 28.16}
{'loss': 0.0577, 'grad_norm': 18.943647384643555, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.05494403839111328, 'loss_2': 0.0027923583984375, 'loss_3': -16.484088897705078, 'loss_4': 0.2652483880519867, 'epoch': 28.16}
{'loss': 0.0078, 'grad_norm': 4.600419044494629, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.0033955969847738743, 'loss_2': 0.00443267822265625, 'loss_3': -16.42898178100586, 'loss_4': 0.012547045946121216, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 14:19:58,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:58,434 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:17<05:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:20:05,756 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01415556762367487, 'eval_runtime': 3.7884, 'eval_samples_per_second': 270.298, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.011600526049733162, 'eval_loss_2': 0.0025550425052642822, 'eval_loss_3': -18.107702255249023, 'eval_loss_4': -0.09572885185480118, 'epoch': 28.17}
{'loss': 0.0092, 'grad_norm': 4.8331475257873535, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.005041794385761023, 'loss_2': 0.004184722900390625, 'loss_3': -16.358257293701172, 'loss_4': -0.4535216689109802, 'epoch': 28.17}
{'loss': 0.0105, 'grad_norm': 4.619986057281494, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.005235907156020403, 'loss_2': 0.005279541015625, 'loss_3': -16.350208282470703, 'loss_4': 0.37697237730026245, 'epoch': 28.18}
{'loss': 0.004, 'grad_norm': 5.045985698699951, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.003856688505038619, 'loss_2': 0.0001100301742553711, 'loss_3': -16.376108169555664, 'loss_4': -0.6100305318832397, 'epoch': 28.19}
{'loss': 0.0037, 'grad_norm': 4.39776611328125, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.003146975999698043, 'loss_2': 0.0005712509155273438, 'loss_3': -16.255414962768555, 'loss_4': 0.08347682654857635, 'epoch': 28.19}
{'loss': 0.007, 'grad_norm': 4.919271469116211, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.004256328567862511, 'loss_2': 0.002750396728515625, 'loss_3': -16.487812042236328, 'loss_4': 0.061283718794584274, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 14:20:05,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:05,757 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:25<05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:13,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014382559806108475, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.827, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01179160363972187, 'eval_loss_2': 0.002590954303741455, 'eval_loss_3': -18.109785079956055, 'eval_loss_4': -0.08757689595222473, 'epoch': 28.2}
{'loss': 0.0132, 'grad_norm': 5.384985446929932, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.006831074599176645, 'loss_2': 0.00635528564453125, 'loss_3': -16.283287048339844, 'loss_4': -0.2830442190170288, 'epoch': 28.2}
{'loss': 0.0081, 'grad_norm': 5.687527656555176, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.006307258736342192, 'loss_2': 0.001781463623046875, 'loss_3': -16.466053009033203, 'loss_4': 0.06304723024368286, 'epoch': 28.21}
{'loss': 0.0092, 'grad_norm': 4.931066513061523, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.00416741194203496, 'loss_2': 0.005054473876953125, 'loss_3': -16.41849708557129, 'loss_4': 0.5231776833534241, 'epoch': 28.22}
{'loss': 0.0076, 'grad_norm': 4.4257121086120605, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.003663544310256839, 'loss_2': 0.00392913818359375, 'loss_3': -16.52195167541504, 'loss_4': 0.49542534351348877, 'epoch': 28.22}
{'loss': 0.0081, 'grad_norm': 7.5927581787109375, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.007644146680831909, 'loss_2': 0.0005035400390625, 'loss_3': -16.399431228637695, 'loss_4': 0.30080655217170715, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 14:20:13,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:13,096 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:32<05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:20,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014705702662467957, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.232, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.0120899248868227, 'eval_loss_2': 0.0026157796382904053, 'eval_loss_3': -18.107847213745117, 'eval_loss_4': -0.07485119253396988, 'epoch': 28.23}
{'loss': 0.005, 'grad_norm': 5.303289890289307, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.0025071657728403807, 'loss_2': 0.0024871826171875, 'loss_3': -16.395849227905273, 'loss_4': -0.3146311044692993, 'epoch': 28.23}
{'loss': 0.0039, 'grad_norm': 4.799929141998291, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.003044404089450836, 'loss_2': 0.0008749961853027344, 'loss_3': -16.286975860595703, 'loss_4': -0.06025667488574982, 'epoch': 28.24}
{'loss': 0.0155, 'grad_norm': 8.9478178024292, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.009787969291210175, 'loss_2': 0.00566864013671875, 'loss_3': -16.344196319580078, 'loss_4': -0.38060280680656433, 'epoch': 28.24}
{'loss': 0.0076, 'grad_norm': 5.666353702545166, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.006440127734094858, 'loss_2': 0.001190185546875, 'loss_3': -16.436260223388672, 'loss_4': -0.27268949151039124, 'epoch': 28.25}
{'loss': 0.0132, 'grad_norm': 4.652108192443848, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.0037533314898610115, 'loss_2': 0.0093994140625, 'loss_3': -16.108291625976562, 'loss_4': -0.062066029757261276, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 14:20:20,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:20,441 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:39<05:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:27,781 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014764344319701195, 'eval_runtime': 3.7888, 'eval_samples_per_second': 270.269, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.01218252070248127, 'eval_loss_2': 0.0025818273425102234, 'eval_loss_3': -18.102191925048828, 'eval_loss_4': -0.08914060890674591, 'epoch': 28.26}
{'loss': 0.0216, 'grad_norm': 12.156352043151855, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.02071431279182434, 'loss_2': 0.000926971435546875, 'loss_3': -16.567386627197266, 'loss_4': 0.13130329549312592, 'epoch': 28.26}
{'loss': 0.0041, 'grad_norm': 4.464926242828369, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.0019166464917361736, 'loss_2': 0.002166748046875, 'loss_3': -16.46634864807129, 'loss_4': 0.13451123237609863, 'epoch': 28.27}
{'loss': 0.0144, 'grad_norm': 4.703419208526611, 'learning_rate': 1.75e-06, 'loss_1': 0.0061902753077447414, 'loss_2': 0.0081787109375, 'loss_3': -16.34364128112793, 'loss_4': -0.048847123980522156, 'epoch': 28.27}
{'loss': 0.0101, 'grad_norm': 5.755253791809082, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.009321804158389568, 'loss_2': 0.0007643699645996094, 'loss_3': -16.365184783935547, 'loss_4': 0.0724128782749176, 'epoch': 28.28}
{'loss': 0.0073, 'grad_norm': 4.899893760681152, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.003579431679099798, 'loss_2': 0.00368499755859375, 'loss_3': -16.425235748291016, 'loss_4': -0.06773138046264648, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 14:20:27,781 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:27,781 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [1:59:47<05:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:35,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015074114315211773, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.074, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.012421024031937122, 'eval_loss_2': 0.0026530884206295013, 'eval_loss_3': -18.0997371673584, 'eval_loss_4': -0.10355392098426819, 'epoch': 28.28}
{'loss': 0.013, 'grad_norm': 9.2506742477417, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.012821855023503304, 'loss_2': 0.0001747608184814453, 'loss_3': -16.189661026000977, 'loss_4': 0.12416591495275497, 'epoch': 28.29}
{'loss': 0.0216, 'grad_norm': 15.745746612548828, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.017152486369013786, 'loss_2': 0.0044097900390625, 'loss_3': -16.294132232666016, 'loss_4': -0.3204152584075928, 'epoch': 28.3}
{'loss': 0.0057, 'grad_norm': 4.7203474044799805, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.0035153066273778677, 'loss_2': 0.00217437744140625, 'loss_3': -16.511058807373047, 'loss_4': -0.21895283460617065, 'epoch': 28.3}
{'loss': 0.0145, 'grad_norm': 4.68155574798584, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.0034740346018224955, 'loss_2': 0.011016845703125, 'loss_3': -16.28978729248047, 'loss_4': 0.14214110374450684, 'epoch': 28.31}
{'loss': 0.0109, 'grad_norm': 4.837973594665527, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.004442145116627216, 'loss_2': 0.00643157958984375, 'loss_3': -16.462875366210938, 'loss_4': -0.28758704662323, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 14:20:35,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:35,120 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [1:59:54<04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:42,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014093315228819847, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.443, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011462142691016197, 'eval_loss_2': 0.00263117253780365, 'eval_loss_3': -18.103017807006836, 'eval_loss_4': -0.08436360955238342, 'epoch': 28.31}
{'loss': 0.0083, 'grad_norm': 3.9920945167541504, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.0022283548023551702, 'loss_2': 0.0060577392578125, 'loss_3': -16.364227294921875, 'loss_4': -0.0036486685276031494, 'epoch': 28.32}
{'loss': 0.0642, 'grad_norm': 20.63294792175293, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.06156805530190468, 'loss_2': 0.002620697021484375, 'loss_3': -16.318998336791992, 'loss_4': 0.26172715425491333, 'epoch': 28.33}
{'loss': 0.0051, 'grad_norm': 4.630982875823975, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.004217222798615694, 'loss_2': 0.0008940696716308594, 'loss_3': -16.443191528320312, 'loss_4': 0.14781510829925537, 'epoch': 28.33}
{'loss': 0.0078, 'grad_norm': 4.794485092163086, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.0025138966739177704, 'loss_2': 0.005260467529296875, 'loss_3': -16.520902633666992, 'loss_4': 0.648039698600769, 'epoch': 28.34}
{'loss': 0.0056, 'grad_norm': 4.4046196937561035, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.0034681586548686028, 'loss_2': 0.00214385986328125, 'loss_3': -16.334918975830078, 'loss_4': -0.19905298948287964, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 14:20:42,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:42,461 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [2:00:01<04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:49,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013508118689060211, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.285, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.010877586901187897, 'eval_loss_2': 0.0026305317878723145, 'eval_loss_3': -18.108430862426758, 'eval_loss_4': -0.05005703866481781, 'epoch': 28.34}
{'loss': 0.0129, 'grad_norm': 6.442505836486816, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.007584382314234972, 'loss_2': 0.00528717041015625, 'loss_3': -16.26171875, 'loss_4': -0.0034072957932949066, 'epoch': 28.35}
{'loss': 0.0104, 'grad_norm': 4.60947847366333, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.00295236031524837, 'loss_2': 0.007415771484375, 'loss_3': -16.47303009033203, 'loss_4': -0.009312704205513, 'epoch': 28.35}
{'loss': 0.0051, 'grad_norm': 4.674081325531006, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.004037176724523306, 'loss_2': 0.0010204315185546875, 'loss_3': -16.494583129882812, 'loss_4': -0.1277531087398529, 'epoch': 28.36}
{'loss': 0.0058, 'grad_norm': 4.415902614593506, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.002686634659767151, 'loss_2': 0.0031032562255859375, 'loss_3': -16.354206085205078, 'loss_4': -0.06796425580978394, 'epoch': 28.37}
{'loss': 0.0098, 'grad_norm': 4.740998268127441, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.006429444067180157, 'loss_2': 0.00341033935546875, 'loss_3': -16.411523818969727, 'loss_4': -0.38046130537986755, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 14:20:49,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:49,795 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:09<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:57,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013094834983348846, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01067736092954874, 'eval_loss_2': 0.0024174749851226807, 'eval_loss_3': -18.110675811767578, 'eval_loss_4': -0.008665662258863449, 'epoch': 28.37}
{'loss': 0.0083, 'grad_norm': 4.758861064910889, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.0032465022522956133, 'loss_2': 0.00504302978515625, 'loss_3': -16.339284896850586, 'loss_4': 0.2686430811882019, 'epoch': 28.38}
{'loss': 0.0076, 'grad_norm': 4.453851699829102, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.0017156947869807482, 'loss_2': 0.00583648681640625, 'loss_3': -16.567182540893555, 'loss_4': -0.1703965961933136, 'epoch': 28.38}
{'loss': 0.006, 'grad_norm': 4.2086687088012695, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.005267313215881586, 'loss_2': 0.0007505416870117188, 'loss_3': -16.28249168395996, 'loss_4': 0.1025475561618805, 'epoch': 28.39}
{'loss': 0.0087, 'grad_norm': 6.051658630371094, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.006671468261629343, 'loss_2': 0.0019969940185546875, 'loss_3': -16.477630615234375, 'loss_4': 0.19098874926567078, 'epoch': 28.4}
{'loss': 0.008, 'grad_norm': 5.613771915435791, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.005432592239230871, 'loss_2': 0.0025310516357421875, 'loss_3': -16.225666046142578, 'loss_4': 0.12009681016206741, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 14:20:57,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:57,140 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:16<04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:04,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013445491902530193, 'eval_runtime': 3.7886, 'eval_samples_per_second': 270.288, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.011018821969628334, 'eval_loss_2': 0.0024266690015792847, 'eval_loss_3': -18.115966796875, 'eval_loss_4': 0.03272292762994766, 'epoch': 28.4}
{'loss': 0.0077, 'grad_norm': 4.938576698303223, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.0037883019540458918, 'loss_2': 0.003936767578125, 'loss_3': -16.35761833190918, 'loss_4': 0.1960107386112213, 'epoch': 28.41}
{'loss': 0.0047, 'grad_norm': 5.268594264984131, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.0031839492730796337, 'loss_2': 0.0015211105346679688, 'loss_3': -16.334980010986328, 'loss_4': 0.2923471927642822, 'epoch': 28.41}
{'loss': 0.0236, 'grad_norm': 9.324905395507812, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.019912246614694595, 'loss_2': 0.003665924072265625, 'loss_3': -16.431766510009766, 'loss_4': -0.013642992824316025, 'epoch': 28.42}
{'loss': 0.0062, 'grad_norm': 4.411805629730225, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.0038806055672466755, 'loss_2': 0.00229644775390625, 'loss_3': -16.346445083618164, 'loss_4': 0.4359433650970459, 'epoch': 28.42}
{'loss': 0.009, 'grad_norm': 5.3385090827941895, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.006307981908321381, 'loss_2': 0.0027103424072265625, 'loss_3': -16.480445861816406, 'loss_4': -0.1189100444316864, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 14:21:04,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:04,482 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:23<04:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:11,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013609437271952629, 'eval_runtime': 3.7903, 'eval_samples_per_second': 270.16, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.011095782741904259, 'eval_loss_2': 0.0025136545300483704, 'eval_loss_3': -18.120634078979492, 'eval_loss_4': 0.055688001215457916, 'epoch': 28.43}
{'loss': 0.0098, 'grad_norm': 5.854730129241943, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.006450281012803316, 'loss_2': 0.003326416015625, 'loss_3': -16.512054443359375, 'loss_4': 0.02231532707810402, 'epoch': 28.44}
{'loss': 0.0093, 'grad_norm': 8.44825267791748, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.00846406165510416, 'loss_2': 0.0008335113525390625, 'loss_3': -16.217994689941406, 'loss_4': 0.0608229786157608, 'epoch': 28.44}
{'loss': 0.0128, 'grad_norm': 8.343222618103027, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.01121622882783413, 'loss_2': 0.0015964508056640625, 'loss_3': -16.502593994140625, 'loss_4': 0.3680458664894104, 'epoch': 28.45}
{'loss': 0.0032, 'grad_norm': 4.120876789093018, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.002394755370914936, 'loss_2': 0.000804901123046875, 'loss_3': -16.512556076049805, 'loss_4': 0.5592000484466553, 'epoch': 28.45}
{'loss': 0.0133, 'grad_norm': 5.369751453399658, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.004308671224862337, 'loss_2': 0.00902557373046875, 'loss_3': -16.27890396118164, 'loss_4': 0.194193035364151, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 14:21:11,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:11,815 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:31<04:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:19,148 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013863781467080116, 'eval_runtime': 3.7911, 'eval_samples_per_second': 270.104, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01137794554233551, 'eval_loss_2': 0.0024858377873897552, 'eval_loss_3': -18.120628356933594, 'eval_loss_4': 0.059883881360292435, 'epoch': 28.46}
{'loss': 0.0025, 'grad_norm': 5.383582592010498, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.001905662938952446, 'loss_2': 0.0006341934204101562, 'loss_3': -16.406753540039062, 'loss_4': 0.08752797544002533, 'epoch': 28.47}
{'loss': 0.025, 'grad_norm': 10.774463653564453, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.01966816931962967, 'loss_2': 0.00531768798828125, 'loss_3': -16.431360244750977, 'loss_4': -0.2184838205575943, 'epoch': 28.47}
{'loss': 0.0084, 'grad_norm': 5.25634765625, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.006289022974669933, 'loss_2': 0.0020923614501953125, 'loss_3': -16.32333755493164, 'loss_4': 0.7490113973617554, 'epoch': 28.48}
{'loss': 0.0109, 'grad_norm': 5.138159275054932, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.007568589877337217, 'loss_2': 0.003368377685546875, 'loss_3': -16.352802276611328, 'loss_4': 0.24701924622058868, 'epoch': 28.48}
{'loss': 0.0077, 'grad_norm': 4.981601238250732, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.005679446272552013, 'loss_2': 0.00199127197265625, 'loss_3': -16.38399887084961, 'loss_4': 0.3877102732658386, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 14:21:19,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:19,148 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:38<04:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:26,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013634394854307175, 'eval_runtime': 3.788, 'eval_samples_per_second': 270.326, 'eval_steps_per_second': 4.224, 'eval_loss_1': 0.011211256496608257, 'eval_loss_2': 0.0024231374263763428, 'eval_loss_3': -18.12445640563965, 'eval_loss_4': 0.06170332431793213, 'epoch': 28.49}
{'loss': 0.0121, 'grad_norm': 6.429260730743408, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.008995436131954193, 'loss_2': 0.0030670166015625, 'loss_3': -16.529239654541016, 'loss_4': -0.017492525279521942, 'epoch': 28.49}
{'loss': 0.0046, 'grad_norm': 4.329168796539307, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0030975593253970146, 'loss_2': 0.0014667510986328125, 'loss_3': -16.28647804260254, 'loss_4': 0.22894930839538574, 'epoch': 28.5}
{'loss': 0.007, 'grad_norm': 4.870371341705322, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.004953694064170122, 'loss_2': 0.002079010009765625, 'loss_3': -16.37314796447754, 'loss_4': -0.1381836086511612, 'epoch': 28.51}
{'loss': 0.0071, 'grad_norm': 4.906973838806152, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0046473294496536255, 'loss_2': 0.00250244140625, 'loss_3': -16.29788589477539, 'loss_4': 0.39582815766334534, 'epoch': 28.51}
{'loss': 0.0079, 'grad_norm': 4.477749347686768, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.003109907265752554, 'loss_2': 0.004787445068359375, 'loss_3': -16.300317764282227, 'loss_4': 0.16473905742168427, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 14:21:26,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:26,474 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:00:45<04:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:33,832 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013881474733352661, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.308, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011396897956728935, 'eval_loss_2': 0.0024845749139785767, 'eval_loss_3': -18.128925323486328, 'eval_loss_4': 0.0601191446185112, 'epoch': 28.52}
{'loss': 0.0036, 'grad_norm': 4.539237022399902, 'learning_rate': 1.5e-06, 'loss_1': 0.0028439820744097233, 'loss_2': 0.0007405281066894531, 'loss_3': -16.19738006591797, 'loss_4': 0.13665364682674408, 'epoch': 28.52}
{'loss': 0.0055, 'grad_norm': 4.652117729187012, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.00259835715405643, 'loss_2': 0.002872467041015625, 'loss_3': -16.31324005126953, 'loss_4': -0.09160648286342621, 'epoch': 28.53}
{'loss': 0.0182, 'grad_norm': 9.267047882080078, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.013446643948554993, 'loss_2': 0.0047760009765625, 'loss_3': -16.34991455078125, 'loss_4': 0.07672600448131561, 'epoch': 28.53}
{'loss': 0.0177, 'grad_norm': 12.864038467407227, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.011321264319121838, 'loss_2': 0.00634765625, 'loss_3': -16.393543243408203, 'loss_4': 0.18553932011127472, 'epoch': 28.54}
{'loss': 0.0087, 'grad_norm': 5.1154465675354, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.004885456524789333, 'loss_2': 0.003787994384765625, 'loss_3': -16.414644241333008, 'loss_4': 0.5426861047744751, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 14:21:33,832 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:33,832 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:00:53<04:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:41,173 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013630453497171402, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.287, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01116618886590004, 'eval_loss_2': 0.0024642646312713623, 'eval_loss_3': -18.13349151611328, 'eval_loss_4': 0.06472021341323853, 'epoch': 28.55}
{'loss': 0.0109, 'grad_norm': 7.310428619384766, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.00645938515663147, 'loss_2': 0.0044097900390625, 'loss_3': -16.43780517578125, 'loss_4': -0.11246101558208466, 'epoch': 28.55}
{'loss': 0.0065, 'grad_norm': 5.045821666717529, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.004733392968773842, 'loss_2': 0.0018024444580078125, 'loss_3': -16.431541442871094, 'loss_4': 0.3957880735397339, 'epoch': 28.56}
{'loss': 0.009, 'grad_norm': 6.379706859588623, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.00662512332201004, 'loss_2': 0.0023937225341796875, 'loss_3': -16.259958267211914, 'loss_4': -0.044515494257211685, 'epoch': 28.56}
{'loss': 0.0093, 'grad_norm': 7.939850330352783, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.005893014371395111, 'loss_2': 0.0034008026123046875, 'loss_3': -16.53359603881836, 'loss_4': 0.37629416584968567, 'epoch': 28.57}
{'loss': 0.0033, 'grad_norm': 4.474677562713623, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.002346012042835355, 'loss_2': 0.0009469985961914062, 'loss_3': -16.469955444335938, 'loss_4': 0.24615836143493652, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 14:21:41,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:41,174 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:01:00<04:12,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:21:48,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013454568572342396, 'eval_runtime': 3.9913, 'eval_samples_per_second': 256.555, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.010934574529528618, 'eval_loss_2': 0.0025199949741363525, 'eval_loss_3': -18.135238647460938, 'eval_loss_4': 0.07687373459339142, 'epoch': 28.58}
{'loss': 0.005, 'grad_norm': 4.773538112640381, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.0038502728566527367, 'loss_2': 0.0011806488037109375, 'loss_3': -16.408935546875, 'loss_4': 0.04699048399925232, 'epoch': 28.58}
{'loss': 0.0044, 'grad_norm': 4.582759857177734, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.002589518204331398, 'loss_2': 0.0017681121826171875, 'loss_3': -16.311534881591797, 'loss_4': -0.052777305245399475, 'epoch': 28.59}
{'loss': 0.0033, 'grad_norm': 4.304741859436035, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.0025383909232914448, 'loss_2': 0.00078582763671875, 'loss_3': -16.322898864746094, 'loss_4': 0.263057142496109, 'epoch': 28.59}
{'loss': 0.0123, 'grad_norm': 6.729664325714111, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.011861261911690235, 'loss_2': 0.00039887428283691406, 'loss_3': -16.463085174560547, 'loss_4': 0.4443408250808716, 'epoch': 28.6}
{'loss': 0.0036, 'grad_norm': 4.951403617858887, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.002140186494216323, 'loss_2': 0.0014791488647460938, 'loss_3': -16.467090606689453, 'loss_4': 0.213982492685318, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 14:21:48,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:48,713 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:08<04:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:56,059 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013020060956478119, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.82, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010549076832830906, 'eval_loss_2': 0.0024709850549697876, 'eval_loss_3': -18.13187026977539, 'eval_loss_4': 0.08567584306001663, 'epoch': 28.6}
{'loss': 0.0057, 'grad_norm': 4.121969699859619, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.0016628621378913522, 'loss_2': 0.004032135009765625, 'loss_3': -16.438688278198242, 'loss_4': 0.4448249936103821, 'epoch': 28.61}
{'loss': 0.0052, 'grad_norm': 4.99510383605957, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.004410997498780489, 'loss_2': 0.000827789306640625, 'loss_3': -16.321857452392578, 'loss_4': 0.2583194375038147, 'epoch': 28.62}
{'loss': 0.0063, 'grad_norm': 4.2919816970825195, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.0054214815609157085, 'loss_2': 0.00087738037109375, 'loss_3': -16.44927215576172, 'loss_4': 0.21673192083835602, 'epoch': 28.62}
{'loss': 0.007, 'grad_norm': 4.454898357391357, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.0026128150057047606, 'loss_2': 0.004436492919921875, 'loss_3': -16.52981948852539, 'loss_4': 0.32745951414108276, 'epoch': 28.63}
{'loss': 0.0139, 'grad_norm': 8.528463363647461, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.011399099603295326, 'loss_2': 0.002498626708984375, 'loss_3': -16.315723419189453, 'loss_4': 0.47487443685531616, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 14:21:56,059 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:56,059 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:15<03:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:03,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013013743795454502, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.607, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010579326190054417, 'eval_loss_2': 0.0024344176054000854, 'eval_loss_3': -18.12729835510254, 'eval_loss_4': 0.09269791841506958, 'epoch': 28.63}
{'loss': 0.0035, 'grad_norm': 4.734314918518066, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.0033608649391680956, 'loss_2': 0.00016450881958007812, 'loss_3': -16.404172897338867, 'loss_4': -0.15070243179798126, 'epoch': 28.64}
{'loss': 0.0092, 'grad_norm': 4.778021812438965, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.005575205665081739, 'loss_2': 0.003631591796875, 'loss_3': -16.514318466186523, 'loss_4': 0.09371000528335571, 'epoch': 28.65}
{'loss': 0.0028, 'grad_norm': 4.307485103607178, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.0025356351397931576, 'loss_2': 0.0002484321594238281, 'loss_3': -16.569278717041016, 'loss_4': 0.010089583694934845, 'epoch': 28.65}
{'loss': 0.0114, 'grad_norm': 5.681309223175049, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.0042055631056427956, 'loss_2': 0.0071563720703125, 'loss_3': -16.52194595336914, 'loss_4': 0.4640105366706848, 'epoch': 28.66}
{'loss': 0.0143, 'grad_norm': 5.839313507080078, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.006706359796226025, 'loss_2': 0.00759124755859375, 'loss_3': -16.469926834106445, 'loss_4': 0.19113796949386597, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 14:22:03,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:03,410 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:22<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:10,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012985704466700554, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.694, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010498149320483208, 'eval_loss_2': 0.002487555146217346, 'eval_loss_3': -18.126462936401367, 'eval_loss_4': 0.09687254577875137, 'epoch': 28.66}
{'loss': 0.0036, 'grad_norm': 4.8692121505737305, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.0023863627575337887, 'loss_2': 0.0012140274047851562, 'loss_3': -16.497055053710938, 'loss_4': 0.3504719138145447, 'epoch': 28.67}
{'loss': 0.0066, 'grad_norm': 5.1158013343811035, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.005518288817256689, 'loss_2': 0.0010662078857421875, 'loss_3': -16.232559204101562, 'loss_4': 0.5665500164031982, 'epoch': 28.67}
{'loss': 0.0082, 'grad_norm': 5.308296203613281, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.0063712699338793755, 'loss_2': 0.0018367767333984375, 'loss_3': -16.441518783569336, 'loss_4': 0.47539597749710083, 'epoch': 28.68}
{'loss': 0.005, 'grad_norm': 4.788320541381836, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.0020438567735254765, 'loss_2': 0.002925872802734375, 'loss_3': -16.507511138916016, 'loss_4': -0.2694814205169678, 'epoch': 28.69}
{'loss': 0.007, 'grad_norm': 4.79044771194458, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.00525436969473958, 'loss_2': 0.0017948150634765625, 'loss_3': -16.244287490844727, 'loss_4': 0.16992342472076416, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 14:22:10,762 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:10,762 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:30<03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:18,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012901881709694862, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.572, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010427655652165413, 'eval_loss_2': 0.0024742260575294495, 'eval_loss_3': -18.129655838012695, 'eval_loss_4': 0.1056932583451271, 'epoch': 28.69}
{'loss': 0.0048, 'grad_norm': 4.547205924987793, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.0035779199097305536, 'loss_2': 0.0012235641479492188, 'loss_3': -16.31805419921875, 'loss_4': 0.31668275594711304, 'epoch': 28.7}
{'loss': 0.0059, 'grad_norm': 7.408405303955078, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.005718392785638571, 'loss_2': 0.00017905235290527344, 'loss_3': -16.386547088623047, 'loss_4': 0.14794890582561493, 'epoch': 28.7}
{'loss': 0.0176, 'grad_norm': 7.0758490562438965, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.015326162800192833, 'loss_2': 0.0022754669189453125, 'loss_3': -16.42306900024414, 'loss_4': -0.16086436808109283, 'epoch': 28.71}
{'loss': 0.0036, 'grad_norm': 4.890333652496338, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.0033494005911052227, 'loss_2': 0.0002639293670654297, 'loss_3': -16.489912033081055, 'loss_4': -0.05554426088929176, 'epoch': 28.72}
{'loss': 0.0055, 'grad_norm': 4.289680480957031, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.0022355320397764444, 'loss_2': 0.003265380859375, 'loss_3': -16.412765502929688, 'loss_4': 0.2682413160800934, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 14:22:18,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:18,117 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:37<03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:25,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012525385245680809, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.603, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010101085528731346, 'eval_loss_2': 0.002424299716949463, 'eval_loss_3': -18.134872436523438, 'eval_loss_4': 0.12194496393203735, 'epoch': 28.72}
{'loss': 0.0225, 'grad_norm': 9.663683891296387, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.016091279685497284, 'loss_2': 0.006359100341796875, 'loss_3': -16.42743682861328, 'loss_4': 0.10027555376291275, 'epoch': 28.73}
{'loss': 0.0034, 'grad_norm': 4.423540115356445, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.0017897142097353935, 'loss_2': 0.001583099365234375, 'loss_3': -16.5648193359375, 'loss_4': 0.31340402364730835, 'epoch': 28.73}
{'loss': 0.0075, 'grad_norm': 4.662045001983643, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.0028958425391465425, 'loss_2': 0.004634857177734375, 'loss_3': -16.332584381103516, 'loss_4': 0.35005366802215576, 'epoch': 28.74}
{'loss': 0.0068, 'grad_norm': 5.2766594886779785, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.003515765070915222, 'loss_2': 0.0032806396484375, 'loss_3': -16.532238006591797, 'loss_4': -0.12525847554206848, 'epoch': 28.74}
{'loss': 0.008, 'grad_norm': 5.022650718688965, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.004750089719891548, 'loss_2': 0.0032062530517578125, 'loss_3': -16.390104293823242, 'loss_4': -0.17123880982398987, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 14:22:25,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:25,465 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:01:44<03:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:32,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012320004403591156, 'eval_runtime': 3.791, 'eval_samples_per_second': 270.11, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009954983368515968, 'eval_loss_2': 0.002365022897720337, 'eval_loss_3': -18.13603973388672, 'eval_loss_4': 0.12823240458965302, 'epoch': 28.75}
{'loss': 0.0103, 'grad_norm': 4.8984270095825195, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.004558722022920847, 'loss_2': 0.005706787109375, 'loss_3': -16.42520523071289, 'loss_4': 0.05388365685939789, 'epoch': 28.76}
{'loss': 0.0026, 'grad_norm': 4.729360103607178, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.0019857913721352816, 'loss_2': 0.0006351470947265625, 'loss_3': -16.283531188964844, 'loss_4': -0.41985729336738586, 'epoch': 28.76}
{'loss': 0.0151, 'grad_norm': 8.740262031555176, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.009734535589814186, 'loss_2': 0.00537872314453125, 'loss_3': -16.32571029663086, 'loss_4': -0.00029900670051574707, 'epoch': 28.77}
{'loss': 0.0124, 'grad_norm': 5.163529396057129, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.010051459074020386, 'loss_2': 0.00234222412109375, 'loss_3': -16.496835708618164, 'loss_4': 0.024787530303001404, 'epoch': 28.77}
{'loss': 0.0071, 'grad_norm': 5.158498287200928, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.004353757482022047, 'loss_2': 0.002716064453125, 'loss_3': -16.447052001953125, 'loss_4': 0.2500155568122864, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 14:22:32,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:32,809 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:01:52<03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:40,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012221962213516235, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.697, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009847820736467838, 'eval_loss_2': 0.0023741424083709717, 'eval_loss_3': -18.138046264648438, 'eval_loss_4': 0.1380673497915268, 'epoch': 28.78}
{'loss': 0.0139, 'grad_norm': 9.142934799194336, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.009721959009766579, 'loss_2': 0.00418853759765625, 'loss_3': -16.526145935058594, 'loss_4': 0.35642164945602417, 'epoch': 28.78}
{'loss': 0.0049, 'grad_norm': 4.485061168670654, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.004577620420604944, 'loss_2': 0.0002918243408203125, 'loss_3': -16.387269973754883, 'loss_4': 0.3412279784679413, 'epoch': 28.79}
{'loss': 0.008, 'grad_norm': 4.921470642089844, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.0032543845009058714, 'loss_2': 0.0047454833984375, 'loss_3': -16.38842010498047, 'loss_4': 0.010325565934181213, 'epoch': 28.8}
{'loss': 0.0123, 'grad_norm': 5.390870094299316, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.00858069583773613, 'loss_2': 0.003765106201171875, 'loss_3': -16.13759994506836, 'loss_4': 0.7133684158325195, 'epoch': 28.8}
{'loss': 0.0131, 'grad_norm': 5.6774091720581055, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.008976785466074944, 'loss_2': 0.00411224365234375, 'loss_3': -16.397932052612305, 'loss_4': 0.26721659302711487, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 14:22:40,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:40,153 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:01:59<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:47,503 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01232325378805399, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.738, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009882204234600067, 'eval_loss_2': 0.0024410486221313477, 'eval_loss_3': -18.137001037597656, 'eval_loss_4': 0.13938100636005402, 'epoch': 28.81}
{'loss': 0.0103, 'grad_norm': 4.944640159606934, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.0049567315727472305, 'loss_2': 0.005390167236328125, 'loss_3': -16.35320281982422, 'loss_4': 0.44016510248184204, 'epoch': 28.81}
{'loss': 0.004, 'grad_norm': 4.617518901824951, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.002760642673820257, 'loss_2': 0.001190185546875, 'loss_3': -16.22962760925293, 'loss_4': 0.19572727382183075, 'epoch': 28.82}
{'loss': 0.0105, 'grad_norm': 5.155877590179443, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.005066439975053072, 'loss_2': 0.00542449951171875, 'loss_3': -16.48211669921875, 'loss_4': 0.34842514991760254, 'epoch': 28.83}
{'loss': 0.0057, 'grad_norm': 4.725279808044434, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.004004245158284903, 'loss_2': 0.00173187255859375, 'loss_3': -16.512123107910156, 'loss_4': 0.1708085834980011, 'epoch': 28.83}
{'loss': 0.0025, 'grad_norm': 4.539807319641113, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.0018477526027709246, 'loss_2': 0.000690460205078125, 'loss_3': -16.371118545532227, 'loss_4': 0.14855942130088806, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 14:22:47,503 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:47,503 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:06<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:54,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012687702663242817, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.132, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01023163367062807, 'eval_loss_2': 0.002456068992614746, 'eval_loss_3': -18.133533477783203, 'eval_loss_4': 0.12181811779737473, 'epoch': 28.84}
{'loss': 0.0042, 'grad_norm': 4.427867412567139, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.0027874140068888664, 'loss_2': 0.001384735107421875, 'loss_3': -16.505908966064453, 'loss_4': -0.022128425538539886, 'epoch': 28.84}
{'loss': 0.0065, 'grad_norm': 4.961574554443359, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.005438315682113171, 'loss_2': 0.0010223388671875, 'loss_3': -16.383106231689453, 'loss_4': 0.042874306440353394, 'epoch': 28.85}
{'loss': 0.0098, 'grad_norm': 5.034550666809082, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.005089118145406246, 'loss_2': 0.00470733642578125, 'loss_3': -16.325634002685547, 'loss_4': 0.25601726770401, 'epoch': 28.85}
{'loss': 0.0061, 'grad_norm': 4.70517635345459, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.002878176048398018, 'loss_2': 0.003208160400390625, 'loss_3': -16.450931549072266, 'loss_4': 0.22011324763298035, 'epoch': 28.86}
{'loss': 0.0148, 'grad_norm': 5.463629722595215, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.006792271044105291, 'loss_2': 0.00799560546875, 'loss_3': -16.384952545166016, 'loss_4': -0.01828300952911377, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 14:22:54,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:54,865 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:14<03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:02,209 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012972620315849781, 'eval_runtime': 3.7912, 'eval_samples_per_second': 270.097, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.01043992955237627, 'eval_loss_2': 0.0025326907634735107, 'eval_loss_3': -18.129009246826172, 'eval_loss_4': 0.10722366720438004, 'epoch': 28.87}
{'loss': 0.0075, 'grad_norm': 5.224928855895996, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.003145587630569935, 'loss_2': 0.004364013671875, 'loss_3': -16.30531883239746, 'loss_4': 0.2323722541332245, 'epoch': 28.87}
{'loss': 0.0148, 'grad_norm': 12.726197242736816, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.012856891378760338, 'loss_2': 0.001926422119140625, 'loss_3': -16.39607048034668, 'loss_4': 0.11152080446481705, 'epoch': 28.88}
{'loss': 0.0061, 'grad_norm': 4.585668563842773, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.004228027071803808, 'loss_2': 0.00183868408203125, 'loss_3': -16.376415252685547, 'loss_4': -0.137686625123024, 'epoch': 28.88}
{'loss': 0.0054, 'grad_norm': 4.519911766052246, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.0035399545449763536, 'loss_2': 0.0018825531005859375, 'loss_3': -16.426128387451172, 'loss_4': 0.2933119237422943, 'epoch': 28.89}
{'loss': 0.004, 'grad_norm': 5.014867782592773, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.003351107006892562, 'loss_2': 0.0006160736083984375, 'loss_3': -16.391382217407227, 'loss_4': -0.05386311560869217, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 14:23:02,210 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:02,210 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:21<03:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:09,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012940410524606705, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.992, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010438998229801655, 'eval_loss_2': 0.0025014132261276245, 'eval_loss_3': -18.12874984741211, 'eval_loss_4': 0.10408978909254074, 'epoch': 28.9}
{'loss': 0.0035, 'grad_norm': 4.406459331512451, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.002352758077904582, 'loss_2': 0.0011749267578125, 'loss_3': -16.362653732299805, 'loss_4': -0.10633675009012222, 'epoch': 28.9}
{'loss': 0.0148, 'grad_norm': 7.9046454429626465, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.011934860609471798, 'loss_2': 0.0028228759765625, 'loss_3': -16.417198181152344, 'loss_4': 0.5160578489303589, 'epoch': 28.91}
{'loss': 0.0073, 'grad_norm': 4.750715255737305, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.0033713162411004305, 'loss_2': 0.00391387939453125, 'loss_3': -16.210247039794922, 'loss_4': -0.14046934247016907, 'epoch': 28.91}
{'loss': 0.0056, 'grad_norm': 5.17310094833374, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.0055452873930335045, 'loss_2': 9.733438491821289e-05, 'loss_3': -16.387126922607422, 'loss_4': -0.06204249709844589, 'epoch': 28.92}
{'loss': 0.0081, 'grad_norm': 8.326339721679688, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.005976903717964888, 'loss_2': 0.00213623046875, 'loss_3': -16.634910583496094, 'loss_4': -0.11184236407279968, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 14:23:09,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:09,557 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:28<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:16,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012951506301760674, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.678, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010527441278100014, 'eval_loss_2': 0.00242406502366066, 'eval_loss_3': -18.125158309936523, 'eval_loss_4': 0.10059518367052078, 'epoch': 28.92}
{'loss': 0.0031, 'grad_norm': 4.771657466888428, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.00220709340646863, 'loss_2': 0.0009250640869140625, 'loss_3': -16.250734329223633, 'loss_4': 0.11345258355140686, 'epoch': 28.93}
{'loss': 0.0102, 'grad_norm': 5.418346881866455, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.009580990299582481, 'loss_2': 0.0005888938903808594, 'loss_3': -16.303955078125, 'loss_4': 0.3550577163696289, 'epoch': 28.94}
{'loss': 0.0121, 'grad_norm': 5.041409969329834, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.0038838631007820368, 'loss_2': 0.00817108154296875, 'loss_3': -16.352487564086914, 'loss_4': 0.5297480225563049, 'epoch': 28.94}
{'loss': 0.0152, 'grad_norm': 8.333022117614746, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.014588444493710995, 'loss_2': 0.0005674362182617188, 'loss_3': -16.28953742980957, 'loss_4': -0.015002749860286713, 'epoch': 28.95}
{'loss': 0.0095, 'grad_norm': 5.910203456878662, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.006154748145490885, 'loss_2': 0.0033206939697265625, 'loss_3': -16.614023208618164, 'loss_4': 0.8146406412124634, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 14:23:16,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:16,905 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:36<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:24,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013101937249302864, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.867, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010630490258336067, 'eval_loss_2': 0.002471446990966797, 'eval_loss_3': -18.123294830322266, 'eval_loss_4': 0.09826873987913132, 'epoch': 28.95}
{'loss': 0.0168, 'grad_norm': 10.098712921142578, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.014063888229429722, 'loss_2': 0.002777099609375, 'loss_3': -16.322738647460938, 'loss_4': -0.08850234746932983, 'epoch': 28.96}
{'loss': 0.0083, 'grad_norm': 6.184593677520752, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.008167191408574581, 'loss_2': 0.00013530254364013672, 'loss_3': -16.540632247924805, 'loss_4': 0.5351258516311646, 'epoch': 28.97}
{'loss': 0.0139, 'grad_norm': 6.996198654174805, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.004608999006450176, 'loss_2': 0.0092926025390625, 'loss_3': -16.380207061767578, 'loss_4': 0.051451921463012695, 'epoch': 28.97}
{'loss': 0.005, 'grad_norm': 4.725218296051025, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.0019278782419860363, 'loss_2': 0.0030975341796875, 'loss_3': -16.52435302734375, 'loss_4': -0.05851119011640549, 'epoch': 28.98}
{'loss': 0.0069, 'grad_norm': 4.622585773468018, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0032304374035447836, 'loss_2': 0.003692626953125, 'loss_3': -16.53833770751953, 'loss_4': 0.07786594331264496, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 14:23:24,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:24,250 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:02:43<02:49,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 14:23:31,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013027875684201717, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010541392490267754, 'eval_loss_2': 0.002486482262611389, 'eval_loss_3': -18.12190055847168, 'eval_loss_4': 0.09767934679985046, 'epoch': 28.98}
{'loss': 0.0123, 'grad_norm': 7.799010753631592, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.008975889533758163, 'loss_2': 0.003337860107421875, 'loss_3': -16.38762855529785, 'loss_4': 0.042735688388347626, 'epoch': 28.99}
{'loss': 0.0101, 'grad_norm': 4.923178672790527, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.003496881341561675, 'loss_2': 0.00655364990234375, 'loss_3': -16.35824203491211, 'loss_4': 0.10942962765693665, 'epoch': 28.99}
{'loss': 0.0053, 'grad_norm': 5.727088451385498, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.0026164716109633446, 'loss_2': 0.002716064453125, 'loss_3': -16.389732360839844, 'loss_4': 0.5791259407997131, 'epoch': 29.0}
{'loss': 0.006, 'grad_norm': 4.544868469238281, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.003191791009157896, 'loss_2': 0.0028095245361328125, 'loss_3': -16.463542938232422, 'loss_4': 0.2530249059200287, 'epoch': 29.01}
{'loss': 0.007, 'grad_norm': 5.677974700927734, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.005011735949665308, 'loss_2': 0.0019521713256835938, 'loss_3': -16.430030822753906, 'loss_4': -0.2675744295120239, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 14:23:31,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:31,288 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:02:50<02:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:23:38,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013158381916582584, 'eval_runtime': 3.792, 'eval_samples_per_second': 270.041, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010572375729680061, 'eval_loss_2': 0.0025860071182250977, 'eval_loss_3': -18.118301391601562, 'eval_loss_4': 0.09410635381937027, 'epoch': 29.01}
{'loss': 0.0133, 'grad_norm': 5.952203750610352, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.006982684601098299, 'loss_2': 0.00628662109375, 'loss_3': -16.57060432434082, 'loss_4': 0.5236321687698364, 'epoch': 29.02}
{'loss': 0.0035, 'grad_norm': 4.292629241943359, 'learning_rate': 1e-06, 'loss_1': 0.002755708061158657, 'loss_2': 0.0007381439208984375, 'loss_3': -16.427555084228516, 'loss_4': 0.4904193580150604, 'epoch': 29.02}
{'loss': 0.0044, 'grad_norm': 5.380270957946777, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.0027449075132608414, 'loss_2': 0.001697540283203125, 'loss_3': -16.45697784423828, 'loss_4': 0.2968461215496063, 'epoch': 29.03}
{'loss': 0.0115, 'grad_norm': 6.228503227233887, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.009368854574859142, 'loss_2': 0.00217437744140625, 'loss_3': -16.435876846313477, 'loss_4': 0.315354585647583, 'epoch': 29.03}
{'loss': 0.0047, 'grad_norm': 4.094788551330566, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.0012316199718043208, 'loss_2': 0.00348663330078125, 'loss_3': -16.60647201538086, 'loss_4': 0.054929472506046295, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 14:23:38,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:38,633 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:02:57<02:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:45,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013257966376841068, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.861, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.0105980783700943, 'eval_loss_2': 0.0026598870754241943, 'eval_loss_3': -18.11494255065918, 'eval_loss_4': 0.09026922285556793, 'epoch': 29.04}
{'loss': 0.0058, 'grad_norm': 5.082962512969971, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.0056681218557059765, 'loss_2': 0.00016689300537109375, 'loss_3': -16.494415283203125, 'loss_4': 0.23949871957302094, 'epoch': 29.05}
{'loss': 0.0094, 'grad_norm': 7.453808307647705, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.008559920825064182, 'loss_2': 0.0008563995361328125, 'loss_3': -16.34427261352539, 'loss_4': 0.07641714811325073, 'epoch': 29.05}
{'loss': 0.0116, 'grad_norm': 6.619634628295898, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.0076066600158810616, 'loss_2': 0.0040283203125, 'loss_3': -16.271472930908203, 'loss_4': 0.5261117219924927, 'epoch': 29.06}
{'loss': 0.0087, 'grad_norm': 5.678635120391846, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.008555134758353233, 'loss_2': 0.0001838207244873047, 'loss_3': -16.375164031982422, 'loss_4': 0.19116152822971344, 'epoch': 29.06}
{'loss': 0.0038, 'grad_norm': 4.54750394821167, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0021865402814000845, 'loss_2': 0.001583099365234375, 'loss_3': -16.51754379272461, 'loss_4': 0.23317760229110718, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 14:23:45,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:45,982 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:05<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:53,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013234320096671581, 'eval_runtime': 3.7914, 'eval_samples_per_second': 270.082, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.010559583082795143, 'eval_loss_2': 0.0026747360825538635, 'eval_loss_3': -18.110774993896484, 'eval_loss_4': 0.0797845721244812, 'epoch': 29.07}
{'loss': 0.0078, 'grad_norm': 5.711605548858643, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.007269934751093388, 'loss_2': 0.0005016326904296875, 'loss_3': -16.34725570678711, 'loss_4': -0.005010049790143967, 'epoch': 29.08}
{'loss': 0.0067, 'grad_norm': 4.95669412612915, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.002199620008468628, 'loss_2': 0.00453948974609375, 'loss_3': -16.65719985961914, 'loss_4': 0.35198286175727844, 'epoch': 29.08}
{'loss': 0.0039, 'grad_norm': 4.742961883544922, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.0035232407972216606, 'loss_2': 0.0003647804260253906, 'loss_3': -16.322036743164062, 'loss_4': 0.42925065755844116, 'epoch': 29.09}
{'loss': 0.0643, 'grad_norm': 23.61428451538086, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.05881026014685631, 'loss_2': 0.005451202392578125, 'loss_3': -16.340221405029297, 'loss_4': 0.7189018130302429, 'epoch': 29.09}
{'loss': 0.0033, 'grad_norm': 4.284188270568848, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.00200168346054852, 'loss_2': 0.001255035400390625, 'loss_3': -16.330780029296875, 'loss_4': 0.06345923244953156, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 14:23:53,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:53,328 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:12<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:00,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01330376323312521, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010647889226675034, 'eval_loss_2': 0.002655874937772751, 'eval_loss_3': -18.108131408691406, 'eval_loss_4': 0.06901156902313232, 'epoch': 29.1}
{'loss': 0.0074, 'grad_norm': 4.758701801300049, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.0027741012163460255, 'loss_2': 0.004634857177734375, 'loss_3': -16.466127395629883, 'loss_4': 0.22534708678722382, 'epoch': 29.1}
{'loss': 0.0043, 'grad_norm': 4.327930927276611, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.0027059451676905155, 'loss_2': 0.0016126632690429688, 'loss_3': -16.35782814025879, 'loss_4': -0.155343160033226, 'epoch': 29.11}
{'loss': 0.0192, 'grad_norm': 6.68076753616333, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.01040187943726778, 'loss_2': 0.0087738037109375, 'loss_3': -16.65047264099121, 'loss_4': 0.13960771262645721, 'epoch': 29.12}
{'loss': 0.0044, 'grad_norm': 5.3626790046691895, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.0019429292296990752, 'loss_2': 0.002468109130859375, 'loss_3': -16.493350982666016, 'loss_4': -0.2555682361125946, 'epoch': 29.12}
{'loss': 0.0098, 'grad_norm': 5.021076202392578, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.004486023914068937, 'loss_2': 0.00536346435546875, 'loss_3': -16.38492202758789, 'loss_4': 0.08976790308952332, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 14:24:00,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:00,675 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:20<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:08,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013364068232476711, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.561, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01069907657802105, 'eval_loss_2': 0.002664990723133087, 'eval_loss_3': -18.1075382232666, 'eval_loss_4': 0.06107265502214432, 'epoch': 29.13}
{'loss': 0.0165, 'grad_norm': 6.687722682952881, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.00867952685803175, 'loss_2': 0.00783538818359375, 'loss_3': -16.488357543945312, 'loss_4': 0.5517617464065552, 'epoch': 29.13}
{'loss': 0.0087, 'grad_norm': 4.9320268630981445, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.00474493158981204, 'loss_2': 0.003986358642578125, 'loss_3': -16.439374923706055, 'loss_4': -0.31255969405174255, 'epoch': 29.14}
{'loss': 0.0072, 'grad_norm': 4.569390773773193, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.002639319049194455, 'loss_2': 0.0045623779296875, 'loss_3': -16.3721866607666, 'loss_4': 0.25405263900756836, 'epoch': 29.15}
{'loss': 0.0065, 'grad_norm': 4.889774322509766, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.004637924488633871, 'loss_2': 0.0018854141235351562, 'loss_3': -16.40494155883789, 'loss_4': 0.3642873466014862, 'epoch': 29.15}
{'loss': 0.0075, 'grad_norm': 4.904580593109131, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0027267911937087774, 'loss_2': 0.004791259765625, 'loss_3': -16.472993850708008, 'loss_4': -0.023461371660232544, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 14:24:08,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:08,015 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:27<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:15,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01341946516185999, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.619, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010689632967114449, 'eval_loss_2': 0.0027298331260681152, 'eval_loss_3': -18.10801887512207, 'eval_loss_4': 0.053234949707984924, 'epoch': 29.16}
{'loss': 0.0262, 'grad_norm': 20.218122482299805, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.02290925569832325, 'loss_2': 0.003246307373046875, 'loss_3': -16.215953826904297, 'loss_4': 0.26880449056625366, 'epoch': 29.16}
{'loss': 0.0079, 'grad_norm': 5.087882995605469, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.0034197247587144375, 'loss_2': 0.00446319580078125, 'loss_3': -16.384429931640625, 'loss_4': -0.25676429271698, 'epoch': 29.17}
{'loss': 0.0066, 'grad_norm': 6.535043239593506, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.004848274402320385, 'loss_2': 0.001705169677734375, 'loss_3': -16.298307418823242, 'loss_4': -0.10151442140340805, 'epoch': 29.17}
{'loss': 0.006, 'grad_norm': 4.489236831665039, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.004304833710193634, 'loss_2': 0.001705169677734375, 'loss_3': -16.524364471435547, 'loss_4': 0.322191447019577, 'epoch': 29.18}
{'loss': 0.0076, 'grad_norm': 4.218090534210205, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.0033838378731161356, 'loss_2': 0.004238128662109375, 'loss_3': -16.123315811157227, 'loss_4': 0.17364348471164703, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 14:24:15,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:15,366 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:34<02:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:22,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013427951373159885, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.016, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010615880601108074, 'eval_loss_2': 0.0028120726346969604, 'eval_loss_3': -18.10653305053711, 'eval_loss_4': 0.052206091582775116, 'epoch': 29.19}
{'loss': 0.0111, 'grad_norm': 7.461362838745117, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.009844551794230938, 'loss_2': 0.0012350082397460938, 'loss_3': -16.429826736450195, 'loss_4': -0.12768791615962982, 'epoch': 29.19}
{'loss': 0.0047, 'grad_norm': 4.455320358276367, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.0014501481782644987, 'loss_2': 0.0032825469970703125, 'loss_3': -16.449886322021484, 'loss_4': 0.15276752412319183, 'epoch': 29.2}
{'loss': 0.0122, 'grad_norm': 5.562821388244629, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.011611812748014927, 'loss_2': 0.0006036758422851562, 'loss_3': -16.386154174804688, 'loss_4': 0.24415254592895508, 'epoch': 29.2}
{'loss': 0.0147, 'grad_norm': 4.862972259521484, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.0037451249081641436, 'loss_2': 0.01092529296875, 'loss_3': -16.334835052490234, 'loss_4': 0.07478591799736023, 'epoch': 29.21}
{'loss': 0.0059, 'grad_norm': 4.509476184844971, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.004491686820983887, 'loss_2': 0.0013875961303710938, 'loss_3': -16.581092834472656, 'loss_4': 0.744020938873291, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 14:24:22,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:22,709 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:42<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:30,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013437188230454922, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.011, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010630851611495018, 'eval_loss_2': 0.002806335687637329, 'eval_loss_3': -18.105844497680664, 'eval_loss_4': 0.05434313043951988, 'epoch': 29.22}
{'loss': 0.012, 'grad_norm': 4.653238296508789, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.003960638772696257, 'loss_2': 0.00799560546875, 'loss_3': -16.354583740234375, 'loss_4': 0.5822077989578247, 'epoch': 29.22}
{'loss': 0.0065, 'grad_norm': 5.829367637634277, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.0061614601872861385, 'loss_2': 0.0003719329833984375, 'loss_3': -16.343708038330078, 'loss_4': -0.45149534940719604, 'epoch': 29.23}
{'loss': 0.0067, 'grad_norm': 4.430691719055176, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.002553011057898402, 'loss_2': 0.0041961669921875, 'loss_3': -16.705583572387695, 'loss_4': -0.10255599021911621, 'epoch': 29.23}
{'loss': 0.0033, 'grad_norm': 4.893773078918457, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.002997330389916897, 'loss_2': 0.0002961158752441406, 'loss_3': -16.29590606689453, 'loss_4': -0.03731197118759155, 'epoch': 29.24}
{'loss': 0.0062, 'grad_norm': 4.693264484405518, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.00316004641354084, 'loss_2': 0.003009796142578125, 'loss_3': -16.4702091217041, 'loss_4': 0.2617345154285431, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 14:24:30,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:30,051 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:03:49<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:37,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013342267833650112, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.67, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010578402318060398, 'eval_loss_2': 0.0027638673782348633, 'eval_loss_3': -18.105134963989258, 'eval_loss_4': 0.056516632437705994, 'epoch': 29.24}
{'loss': 0.0079, 'grad_norm': 5.313328742980957, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.004905969835817814, 'loss_2': 0.0029926300048828125, 'loss_3': -16.476791381835938, 'loss_4': -0.06372810900211334, 'epoch': 29.25}
{'loss': 0.0395, 'grad_norm': 13.870832443237305, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.03450404480099678, 'loss_2': 0.00501251220703125, 'loss_3': -16.400360107421875, 'loss_4': 0.09229074418544769, 'epoch': 29.26}
{'loss': 0.0524, 'grad_norm': 13.767953872680664, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.05085097625851631, 'loss_2': 0.0015392303466796875, 'loss_3': -16.394067764282227, 'loss_4': 0.4947410821914673, 'epoch': 29.26}
{'loss': 0.007, 'grad_norm': 4.762237071990967, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.0043163057416677475, 'loss_2': 0.0027217864990234375, 'loss_3': -16.332042694091797, 'loss_4': 0.12939098477363586, 'epoch': 29.27}
{'loss': 0.0045, 'grad_norm': 4.524799346923828, 'learning_rate': 7.5e-07, 'loss_1': 0.004139463882893324, 'loss_2': 0.000408172607421875, 'loss_3': -16.3739013671875, 'loss_4': -0.37253597378730774, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 14:24:37,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:37,404 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:03:56<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:44,740 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013170242309570312, 'eval_runtime': 3.7898, 'eval_samples_per_second': 270.202, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.010439068078994751, 'eval_loss_2': 0.0027311742305755615, 'eval_loss_3': -18.103466033935547, 'eval_loss_4': 0.06793954968452454, 'epoch': 29.27}
{'loss': 0.0042, 'grad_norm': 4.311469078063965, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.0021942255552858114, 'loss_2': 0.00197601318359375, 'loss_3': -16.479782104492188, 'loss_4': 0.1316227912902832, 'epoch': 29.28}
{'loss': 0.0072, 'grad_norm': 6.076547622680664, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.007105464581400156, 'loss_2': 7.259845733642578e-05, 'loss_3': -16.37834930419922, 'loss_4': 0.3591632843017578, 'epoch': 29.28}
{'loss': 0.004, 'grad_norm': 4.964424133300781, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.0035264433827251196, 'loss_2': 0.0004401206970214844, 'loss_3': -16.3499755859375, 'loss_4': 0.7154464721679688, 'epoch': 29.29}
{'loss': 0.0058, 'grad_norm': 5.52853536605835, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.004619433078914881, 'loss_2': 0.00115203857421875, 'loss_3': -16.25262451171875, 'loss_4': 0.35011667013168335, 'epoch': 29.3}
{'loss': 0.007, 'grad_norm': 4.627470970153809, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.004393980372697115, 'loss_2': 0.002643585205078125, 'loss_3': -16.54785919189453, 'loss_4': 0.3064045011997223, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 14:24:44,741 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:44,741 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:04<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:52,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012836684472858906, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.696, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01015880424529314, 'eval_loss_2': 0.0026778802275657654, 'eval_loss_3': -18.103267669677734, 'eval_loss_4': 0.06970678269863129, 'epoch': 29.3}
{'loss': 0.009, 'grad_norm': 4.830676555633545, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.001747353933751583, 'loss_2': 0.00725555419921875, 'loss_3': -16.299318313598633, 'loss_4': 0.3003094494342804, 'epoch': 29.31}
{'loss': 0.0045, 'grad_norm': 4.6464433670043945, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.002092008711770177, 'loss_2': 0.0023956298828125, 'loss_3': -16.480201721191406, 'loss_4': -0.06503249704837799, 'epoch': 29.31}
{'loss': 0.0043, 'grad_norm': 5.0630106925964355, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.0038690671790391207, 'loss_2': 0.00048065185546875, 'loss_3': -16.475341796875, 'loss_4': 0.10387159883975983, 'epoch': 29.32}
{'loss': 0.0075, 'grad_norm': 4.759250164031982, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.0043664779514074326, 'loss_2': 0.00316619873046875, 'loss_3': -16.385971069335938, 'loss_4': 0.3578845262527466, 'epoch': 29.33}
{'loss': 0.0053, 'grad_norm': 4.875795364379883, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.0032978097442537546, 'loss_2': 0.00199127197265625, 'loss_3': -16.516176223754883, 'loss_4': 0.022784799337387085, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 14:24:52,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:52,088 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:11<01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:59,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012564102187752724, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.014, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009953001514077187, 'eval_loss_2': 0.002611100673675537, 'eval_loss_3': -18.103235244750977, 'eval_loss_4': 0.0691344290971756, 'epoch': 29.33}
{'loss': 0.0058, 'grad_norm': 4.167327880859375, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.0030973416287451982, 'loss_2': 0.002674102783203125, 'loss_3': -16.675039291381836, 'loss_4': 0.005610823631286621, 'epoch': 29.34}
{'loss': 0.0131, 'grad_norm': 11.561680793762207, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.0068643540143966675, 'loss_2': 0.006275177001953125, 'loss_3': -16.462921142578125, 'loss_4': 0.09635791182518005, 'epoch': 29.34}
{'loss': 0.0068, 'grad_norm': 4.587749481201172, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.005261258687824011, 'loss_2': 0.00157928466796875, 'loss_3': -16.31943130493164, 'loss_4': 0.1089610755443573, 'epoch': 29.35}
{'loss': 0.01, 'grad_norm': 5.942901611328125, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.006537888664752245, 'loss_2': 0.003498077392578125, 'loss_3': -16.317058563232422, 'loss_4': -0.1803061068058014, 'epoch': 29.35}
{'loss': 0.0046, 'grad_norm': 4.413713455200195, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.0028411932289600372, 'loss_2': 0.0017652511596679688, 'loss_3': -16.28754234313965, 'loss_4': -0.1664433777332306, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 14:24:59,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:59,433 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:18<01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:06,775 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01245918869972229, 'eval_runtime': 3.7891, 'eval_samples_per_second': 270.251, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00989410188049078, 'eval_loss_2': 0.0025650858879089355, 'eval_loss_3': -18.103086471557617, 'eval_loss_4': 0.06897002458572388, 'epoch': 29.36}
{'loss': 0.0128, 'grad_norm': 12.266752243041992, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.011693119071424007, 'loss_2': 0.0011463165283203125, 'loss_3': -16.357166290283203, 'loss_4': 0.41186651587486267, 'epoch': 29.37}
{'loss': 0.0065, 'grad_norm': 5.222330093383789, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0037425237242132425, 'loss_2': 0.002758026123046875, 'loss_3': -16.417251586914062, 'loss_4': 0.3173745572566986, 'epoch': 29.37}
{'loss': 0.0111, 'grad_norm': 7.434841632843018, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.006733358837664127, 'loss_2': 0.004322052001953125, 'loss_3': -16.18178939819336, 'loss_4': 0.36472249031066895, 'epoch': 29.38}
{'loss': 0.0111, 'grad_norm': 4.98940372467041, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.005140002351254225, 'loss_2': 0.006000518798828125, 'loss_3': -16.433345794677734, 'loss_4': 0.12035685032606125, 'epoch': 29.38}
{'loss': 0.0051, 'grad_norm': 4.549667835235596, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.002722763689234853, 'loss_2': 0.0023345947265625, 'loss_3': -16.363832473754883, 'loss_4': 0.3370765745639801, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 14:25:06,775 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:06,775 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:26<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:14,112 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012478196993470192, 'eval_runtime': 3.7924, 'eval_samples_per_second': 270.016, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009927118197083473, 'eval_loss_2': 0.0025510787963867188, 'eval_loss_3': -18.10039520263672, 'eval_loss_4': 0.07702482491731644, 'epoch': 29.39}
{'loss': 0.0076, 'grad_norm': 4.935988903045654, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.0018825818551704288, 'loss_2': 0.005672454833984375, 'loss_3': -16.424522399902344, 'loss_4': 0.020843448117375374, 'epoch': 29.4}
{'loss': 0.015, 'grad_norm': 7.13025426864624, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.00844264030456543, 'loss_2': 0.006595611572265625, 'loss_3': -16.51897621154785, 'loss_4': 0.43535515666007996, 'epoch': 29.4}
{'loss': 0.0142, 'grad_norm': 6.334257125854492, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.008264466188848019, 'loss_2': 0.0059661865234375, 'loss_3': -16.445417404174805, 'loss_4': 0.08945885300636292, 'epoch': 29.41}
{'loss': 0.0058, 'grad_norm': 4.8864336013793945, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.002153330948203802, 'loss_2': 0.0036258697509765625, 'loss_3': -16.551557540893555, 'loss_4': 0.37068426609039307, 'epoch': 29.41}
{'loss': 0.01, 'grad_norm': 4.749945163726807, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.0060342964716255665, 'loss_2': 0.003963470458984375, 'loss_3': -16.280391693115234, 'loss_4': 0.4432052969932556, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 14:25:14,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:14,113 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:33<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:21,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012380070053040981, 'eval_runtime': 3.7885, 'eval_samples_per_second': 270.289, 'eval_steps_per_second': 4.223, 'eval_loss_1': 0.00991993397474289, 'eval_loss_2': 0.0024601370096206665, 'eval_loss_3': -18.099197387695312, 'eval_loss_4': 0.0864376500248909, 'epoch': 29.42}
{'loss': 0.0034, 'grad_norm': 4.807188034057617, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.0022384512703865767, 'loss_2': 0.001155853271484375, 'loss_3': -16.350374221801758, 'loss_4': 0.3933027386665344, 'epoch': 29.42}
{'loss': 0.0031, 'grad_norm': 4.575623989105225, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.0019388494547456503, 'loss_2': 0.0011539459228515625, 'loss_3': -16.42852020263672, 'loss_4': 0.08316883444786072, 'epoch': 29.43}
{'loss': 0.0051, 'grad_norm': 4.7263689041137695, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.003402979811653495, 'loss_2': 0.001708984375, 'loss_3': -16.361387252807617, 'loss_4': 0.3258972764015198, 'epoch': 29.44}
{'loss': 0.0123, 'grad_norm': 5.530311584472656, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.006891830824315548, 'loss_2': 0.00543975830078125, 'loss_3': -16.358985900878906, 'loss_4': 0.4473685026168823, 'epoch': 29.44}
{'loss': 0.0086, 'grad_norm': 4.992125511169434, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.005308829247951508, 'loss_2': 0.003322601318359375, 'loss_3': -16.48337745666504, 'loss_4': 0.3928650915622711, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 14:25:21,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:21,445 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:40<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:28,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012300604954361916, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.756, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009958150796592236, 'eval_loss_2': 0.0023424550890922546, 'eval_loss_3': -18.09983253479004, 'eval_loss_4': 0.09141437709331512, 'epoch': 29.45}
{'loss': 0.004, 'grad_norm': 4.332409381866455, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.003277876414358616, 'loss_2': 0.000701904296875, 'loss_3': -16.374399185180664, 'loss_4': 0.16737374663352966, 'epoch': 29.45}
{'loss': 0.014, 'grad_norm': 9.04882526397705, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.013823166489601135, 'loss_2': 0.00015628337860107422, 'loss_3': -16.095998764038086, 'loss_4': 0.08407352864742279, 'epoch': 29.46}
{'loss': 0.01, 'grad_norm': 4.710498332977295, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.003271132940426469, 'loss_2': 0.006740570068359375, 'loss_3': -16.51830291748047, 'loss_4': 0.09365135431289673, 'epoch': 29.47}
{'loss': 0.0089, 'grad_norm': 4.4112229347229, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.0012540642637759447, 'loss_2': 0.007617950439453125, 'loss_3': -16.381072998046875, 'loss_4': 0.4822131097316742, 'epoch': 29.47}
{'loss': 0.0056, 'grad_norm': 4.825681686401367, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.005053813569247723, 'loss_2': 0.00052642822265625, 'loss_3': -16.33697509765625, 'loss_4': 0.18858687579631805, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 14:25:28,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:28,791 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:04:48<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:36,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012304650619626045, 'eval_runtime': 3.79, 'eval_samples_per_second': 270.185, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009964028373360634, 'eval_loss_2': 0.0023406222462654114, 'eval_loss_3': -18.10002899169922, 'eval_loss_4': 0.0893482193350792, 'epoch': 29.48}
{'loss': 0.0153, 'grad_norm': 7.444553852081299, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.011756964959204197, 'loss_2': 0.003505706787109375, 'loss_3': -16.290687561035156, 'loss_4': -0.17569245398044586, 'epoch': 29.48}
{'loss': 0.0047, 'grad_norm': 4.872677803039551, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.004589051008224487, 'loss_2': 7.283687591552734e-05, 'loss_3': -16.313974380493164, 'loss_4': 0.047009460628032684, 'epoch': 29.49}
{'loss': 0.0036, 'grad_norm': 4.60936164855957, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.002921558218076825, 'loss_2': 0.0007271766662597656, 'loss_3': -16.360347747802734, 'loss_4': 0.6002156734466553, 'epoch': 29.49}
{'loss': 0.0038, 'grad_norm': 4.959222316741943, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.002179700881242752, 'loss_2': 0.0015811920166015625, 'loss_3': -16.289112091064453, 'loss_4': 0.5095905065536499, 'epoch': 29.5}
{'loss': 0.0049, 'grad_norm': 4.793243408203125, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.004808134399354458, 'loss_2': 4.6372413635253906e-05, 'loss_3': -16.32797622680664, 'loss_4': 0.43938684463500977, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 14:25:36,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:36,140 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:04:55<01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:43,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012281606905162334, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.732, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00995183177292347, 'eval_loss_2': 0.0023297742009162903, 'eval_loss_3': -18.100589752197266, 'eval_loss_4': 0.08896860480308533, 'epoch': 29.51}
{'loss': 0.0052, 'grad_norm': 4.579755783081055, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.001828021602705121, 'loss_2': 0.003330230712890625, 'loss_3': -16.342559814453125, 'loss_4': 0.14392757415771484, 'epoch': 29.51}
{'loss': 0.0062, 'grad_norm': 5.037471294403076, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.004457117989659309, 'loss_2': 0.0017223358154296875, 'loss_3': -16.332496643066406, 'loss_4': 0.050086572766304016, 'epoch': 29.52}
{'loss': 0.0052, 'grad_norm': 4.665523529052734, 'learning_rate': 5e-07, 'loss_1': 0.0026445481926202774, 'loss_2': 0.002605438232421875, 'loss_3': -16.30343246459961, 'loss_4': 0.47101277112960815, 'epoch': 29.52}
{'loss': 0.0026, 'grad_norm': 4.81436014175415, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.0020591961219906807, 'loss_2': 0.0005273818969726562, 'loss_3': -16.494129180908203, 'loss_4': 0.06411050260066986, 'epoch': 29.53}
{'loss': 0.0041, 'grad_norm': 4.818751335144043, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.0034431684762239456, 'loss_2': 0.000652313232421875, 'loss_3': -16.368593215942383, 'loss_4': 0.12035586684942245, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 14:25:43,489 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:43,490 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:02<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:50,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01224976684898138, 'eval_runtime': 3.7919, 'eval_samples_per_second': 270.052, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009889204055070877, 'eval_loss_2': 0.002360563725233078, 'eval_loss_3': -18.101966857910156, 'eval_loss_4': 0.08781646192073822, 'epoch': 29.53}
{'loss': 0.0056, 'grad_norm': 5.5103535652160645, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.005453134886920452, 'loss_2': 0.00015354156494140625, 'loss_3': -16.401226043701172, 'loss_4': -0.18798381090164185, 'epoch': 29.54}
{'loss': 0.0083, 'grad_norm': 6.489053726196289, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.0068936641328036785, 'loss_2': 0.001384735107421875, 'loss_3': -16.244230270385742, 'loss_4': -0.1494109332561493, 'epoch': 29.55}
{'loss': 0.0139, 'grad_norm': 8.005911827087402, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.008637694641947746, 'loss_2': 0.005268096923828125, 'loss_3': -16.450496673583984, 'loss_4': 0.22924619913101196, 'epoch': 29.55}
{'loss': 0.0052, 'grad_norm': 4.453004837036133, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.002108454005792737, 'loss_2': 0.00310516357421875, 'loss_3': -16.359424591064453, 'loss_4': -0.09629976749420166, 'epoch': 29.56}
{'loss': 0.0033, 'grad_norm': 4.814620494842529, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.00317761511541903, 'loss_2': 0.00011879205703735352, 'loss_3': -16.36257553100586, 'loss_4': -0.03204213082790375, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 14:25:50,835 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:50,835 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:10<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:58,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012321334332227707, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.976, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009933797642588615, 'eval_loss_2': 0.0023875348269939423, 'eval_loss_3': -18.10103988647461, 'eval_loss_4': 0.09068270772695541, 'epoch': 29.56}
{'loss': 0.0029, 'grad_norm': 4.803311347961426, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.001980592031031847, 'loss_2': 0.000919342041015625, 'loss_3': -16.367420196533203, 'loss_4': 0.3066423535346985, 'epoch': 29.57}
{'loss': 0.0054, 'grad_norm': 5.042913913726807, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.0022988892160356045, 'loss_2': 0.0030689239501953125, 'loss_3': -16.321521759033203, 'loss_4': -0.17834380269050598, 'epoch': 29.58}
{'loss': 0.0128, 'grad_norm': 7.388273239135742, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.010819315910339355, 'loss_2': 0.0019321441650390625, 'loss_3': -16.303424835205078, 'loss_4': 0.4027486741542816, 'epoch': 29.58}
{'loss': 0.0095, 'grad_norm': 4.808526992797852, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.004235571715980768, 'loss_2': 0.0052642822265625, 'loss_3': -16.235729217529297, 'loss_4': 0.30568987131118774, 'epoch': 29.59}
{'loss': 0.0091, 'grad_norm': 4.890729904174805, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.0036206210497766733, 'loss_2': 0.0054931640625, 'loss_3': -16.267845153808594, 'loss_4': -0.11837653815746307, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 14:25:58,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:58,175 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:17<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:05,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012327037751674652, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.888, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009959369897842407, 'eval_loss_2': 0.002367667853832245, 'eval_loss_3': -18.10045623779297, 'eval_loss_4': 0.09263213723897934, 'epoch': 29.59}
{'loss': 0.0053, 'grad_norm': 4.941742897033691, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.004788936115801334, 'loss_2': 0.0004858970642089844, 'loss_3': -16.44287109375, 'loss_4': -0.14630421996116638, 'epoch': 29.6}
{'loss': 0.0082, 'grad_norm': 4.861802101135254, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.0033573515247553587, 'loss_2': 0.00482177734375, 'loss_3': -16.26723861694336, 'loss_4': -0.02814042568206787, 'epoch': 29.6}
{'loss': 0.0055, 'grad_norm': 4.833780765533447, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.002658173209056258, 'loss_2': 0.0028839111328125, 'loss_3': -16.528850555419922, 'loss_4': 0.0856427252292633, 'epoch': 29.61}
{'loss': 0.0041, 'grad_norm': 4.428735256195068, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.0019270556513220072, 'loss_2': 0.0021991729736328125, 'loss_3': -16.544292449951172, 'loss_4': 0.2554851174354553, 'epoch': 29.62}
{'loss': 0.005, 'grad_norm': 4.176112651824951, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.0038635293021798134, 'loss_2': 0.0011577606201171875, 'loss_3': -16.43320655822754, 'loss_4': 0.2604273855686188, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 14:26:05,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:05,518 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:24<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:12,850 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012273449450731277, 'eval_runtime': 3.7918, 'eval_samples_per_second': 270.059, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.009941328316926956, 'eval_loss_2': 0.0023321211338043213, 'eval_loss_3': -18.10015106201172, 'eval_loss_4': 0.09774412959814072, 'epoch': 29.62}
{'loss': 0.0076, 'grad_norm': 5.213553428649902, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.005577126517891884, 'loss_2': 0.0020503997802734375, 'loss_3': -16.095943450927734, 'loss_4': 0.2529481053352356, 'epoch': 29.63}
{'loss': 0.0036, 'grad_norm': 4.602496147155762, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.0021122118923813105, 'loss_2': 0.0014801025390625, 'loss_3': -16.366348266601562, 'loss_4': -0.23390865325927734, 'epoch': 29.63}
{'loss': 0.02, 'grad_norm': 8.341885566711426, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.01666306145489216, 'loss_2': 0.003299713134765625, 'loss_3': -16.294097900390625, 'loss_4': -0.35030096769332886, 'epoch': 29.64}
{'loss': 0.0082, 'grad_norm': 5.104881763458252, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.003973989747464657, 'loss_2': 0.004192352294921875, 'loss_3': -16.411605834960938, 'loss_4': 0.13475599884986877, 'epoch': 29.65}
{'loss': 0.006, 'grad_norm': 4.690403461456299, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.004367136396467686, 'loss_2': 0.00165557861328125, 'loss_3': -16.258460998535156, 'loss_4': 0.3047371506690979, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 14:26:12,850 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:12,850 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:32<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:20,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012240749783813953, 'eval_runtime': 3.7892, 'eval_samples_per_second': 270.24, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.00988563522696495, 'eval_loss_2': 0.0023551136255264282, 'eval_loss_3': -18.100101470947266, 'eval_loss_4': 0.09900546818971634, 'epoch': 29.65}
{'loss': 0.0053, 'grad_norm': 4.5682597160339355, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.004748320672661066, 'loss_2': 0.000514984130859375, 'loss_3': -16.464641571044922, 'loss_4': 0.3496479094028473, 'epoch': 29.66}
{'loss': 0.0083, 'grad_norm': 4.824801445007324, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.00670531764626503, 'loss_2': 0.0015773773193359375, 'loss_3': -16.424697875976562, 'loss_4': 0.3262576460838318, 'epoch': 29.66}
{'loss': 0.0104, 'grad_norm': 5.3062920570373535, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.0047797816805541515, 'loss_2': 0.00566864013671875, 'loss_3': -16.341012954711914, 'loss_4': 0.14150939881801605, 'epoch': 29.67}
{'loss': 0.0135, 'grad_norm': 10.204239845275879, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.012017563916742802, 'loss_2': 0.00150299072265625, 'loss_3': -16.391048431396484, 'loss_4': 0.02358650416135788, 'epoch': 29.67}
{'loss': 0.0048, 'grad_norm': 4.947439193725586, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.0032724663615226746, 'loss_2': 0.0015125274658203125, 'loss_3': -16.416793823242188, 'loss_4': 0.5389161109924316, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 14:26:20,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:20,190 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:39<00:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:27,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012267420068383217, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.851, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009891284629702568, 'eval_loss_2': 0.002376135438680649, 'eval_loss_3': -18.100618362426758, 'eval_loss_4': 0.09685062617063522, 'epoch': 29.68}
{'loss': 0.0055, 'grad_norm': 5.20488166809082, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.005400144029408693, 'loss_2': 9.834766387939453e-05, 'loss_3': -16.369714736938477, 'loss_4': -0.1832340657711029, 'epoch': 29.69}
{'loss': 0.0048, 'grad_norm': 4.70058012008667, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.004009915981441736, 'loss_2': 0.0007648468017578125, 'loss_3': -16.259902954101562, 'loss_4': -0.2830645442008972, 'epoch': 29.69}
{'loss': 0.0137, 'grad_norm': 6.0838775634765625, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.013062362559139729, 'loss_2': 0.0006504058837890625, 'loss_3': -16.456647872924805, 'loss_4': 0.21663321554660797, 'epoch': 29.7}
{'loss': 0.0103, 'grad_norm': 6.477327346801758, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.006075193639844656, 'loss_2': 0.004207611083984375, 'loss_3': -16.37033462524414, 'loss_4': 0.05773702263832092, 'epoch': 29.7}
{'loss': 0.017, 'grad_norm': 7.346668243408203, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.01290637906640768, 'loss_2': 0.004058837890625, 'loss_3': -16.561264038085938, 'loss_4': 0.5939939022064209, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 14:26:27,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:27,535 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:05:46<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:34,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012318517081439495, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.231, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009977537207305431, 'eval_loss_2': 0.0023409798741340637, 'eval_loss_3': -18.099700927734375, 'eval_loss_4': 0.09268036484718323, 'epoch': 29.71}
{'loss': 0.013, 'grad_norm': 10.713147163391113, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.012745066545903683, 'loss_2': 0.0002779960632324219, 'loss_3': -16.532766342163086, 'loss_4': -0.0499480664730072, 'epoch': 29.72}
{'loss': 0.0071, 'grad_norm': 5.273615837097168, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.004100959748029709, 'loss_2': 0.0030364990234375, 'loss_3': -16.315004348754883, 'loss_4': 0.18719306588172913, 'epoch': 29.72}
{'loss': 0.0042, 'grad_norm': 4.657360553741455, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.0014152075164020061, 'loss_2': 0.0027618408203125, 'loss_3': -16.56983757019043, 'loss_4': 0.33897310495376587, 'epoch': 29.73}
{'loss': 0.0077, 'grad_norm': 5.157198905944824, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.007061649579554796, 'loss_2': 0.0006418228149414062, 'loss_3': -16.353609085083008, 'loss_4': 0.17458510398864746, 'epoch': 29.73}
{'loss': 0.0077, 'grad_norm': 5.201141834259033, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.005587941501289606, 'loss_2': 0.00212860107421875, 'loss_3': -16.258996963500977, 'loss_4': 0.27944812178611755, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 14:26:34,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:34,866 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:05:54<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:42,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01232638768851757, 'eval_runtime': 3.7893, 'eval_samples_per_second': 270.238, 'eval_steps_per_second': 4.222, 'eval_loss_1': 0.009985395707190037, 'eval_loss_2': 0.002340991050004959, 'eval_loss_3': -18.098487854003906, 'eval_loss_4': 0.08697792887687683, 'epoch': 29.74}
{'loss': 0.0108, 'grad_norm': 5.760420799255371, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.00549661461263895, 'loss_2': 0.005279541015625, 'loss_3': -16.422483444213867, 'loss_4': 0.24098555743694305, 'epoch': 29.74}
{'loss': 0.007, 'grad_norm': 5.060013294219971, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.0051112547516822815, 'loss_2': 0.0018939971923828125, 'loss_3': -16.333656311035156, 'loss_4': 0.08763342350721359, 'epoch': 29.75}
{'loss': 0.0154, 'grad_norm': 5.536230564117432, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.007963458076119423, 'loss_2': 0.0074005126953125, 'loss_3': -16.62852668762207, 'loss_4': -0.00105208158493042, 'epoch': 29.76}
{'loss': 0.0047, 'grad_norm': 4.897047996520996, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.003077559173107147, 'loss_2': 0.0016689300537109375, 'loss_3': -16.40419578552246, 'loss_4': 0.0744062215089798, 'epoch': 29.76}
{'loss': 0.0039, 'grad_norm': 5.086133003234863, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.003492878284305334, 'loss_2': 0.0003685951232910156, 'loss_3': -16.37735939025879, 'loss_4': -0.17229390144348145, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 14:26:42,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:42,195 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:06:01<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:49,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012369429692626, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010014502331614494, 'eval_loss_2': 0.002354927361011505, 'eval_loss_3': -18.098709106445312, 'eval_loss_4': 0.08234204351902008, 'epoch': 29.77}
{'loss': 0.0048, 'grad_norm': 5.409710884094238, 'learning_rate': 2.5e-07, 'loss_1': 0.0018247375264763832, 'loss_2': 0.002971649169921875, 'loss_3': -16.230449676513672, 'loss_4': -0.09216677397489548, 'epoch': 29.77}
{'loss': 0.0399, 'grad_norm': 13.610549926757812, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.03880342096090317, 'loss_2': 0.0010738372802734375, 'loss_3': -16.442729949951172, 'loss_4': 0.07629702985286713, 'epoch': 29.78}
{'loss': 0.0051, 'grad_norm': 4.484907627105713, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.0030044603627175093, 'loss_2': 0.0020599365234375, 'loss_3': -16.489620208740234, 'loss_4': -0.04968816787004471, 'epoch': 29.78}
{'loss': 0.0064, 'grad_norm': 4.71506929397583, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.005130112171173096, 'loss_2': 0.001285552978515625, 'loss_3': -16.376300811767578, 'loss_4': 0.47035712003707886, 'epoch': 29.79}
{'loss': 0.008, 'grad_norm': 4.6255035400390625, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.004205335397273302, 'loss_2': 0.003826141357421875, 'loss_3': -16.33320426940918, 'loss_4': 0.18130046129226685, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 14:26:49,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:49,538 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:08<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:56,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012395331636071205, 'eval_runtime': 3.7863, 'eval_samples_per_second': 270.451, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.010062994435429573, 'eval_loss_2': 0.002332337200641632, 'eval_loss_3': -18.09857177734375, 'eval_loss_4': 0.07943391054868698, 'epoch': 29.8}
{'loss': 0.016, 'grad_norm': 5.827847957611084, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.008224273100495338, 'loss_2': 0.00772857666015625, 'loss_3': -16.239526748657227, 'loss_4': 0.5048465728759766, 'epoch': 29.8}
{'loss': 0.0096, 'grad_norm': 4.756783485412598, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.003091618651524186, 'loss_2': 0.0064697265625, 'loss_3': -16.42691993713379, 'loss_4': 0.463978111743927, 'epoch': 29.81}
{'loss': 0.0053, 'grad_norm': 5.315887928009033, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.0040269833989441395, 'loss_2': 0.0012292861938476562, 'loss_3': -16.394062042236328, 'loss_4': 0.036822885274887085, 'epoch': 29.81}
{'loss': 0.0057, 'grad_norm': 5.092623710632324, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0027942745946347713, 'loss_2': 0.002887725830078125, 'loss_3': -16.428104400634766, 'loss_4': 0.7250897884368896, 'epoch': 29.82}
{'loss': 0.0223, 'grad_norm': 10.736940383911133, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.02160840854048729, 'loss_2': 0.0007381439208984375, 'loss_3': -16.235946655273438, 'loss_4': 0.1629309356212616, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 14:26:56,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:56,873 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:16<00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:04,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012417266145348549, 'eval_runtime': 3.7865, 'eval_samples_per_second': 270.433, 'eval_steps_per_second': 4.226, 'eval_loss_1': 0.010089890100061893, 'eval_loss_2': 0.002327375113964081, 'eval_loss_3': -18.098331451416016, 'eval_loss_4': 0.07876206934452057, 'epoch': 29.83}
{'loss': 0.0109, 'grad_norm': 4.9543561935424805, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.005639148876070976, 'loss_2': 0.00522613525390625, 'loss_3': -16.206329345703125, 'loss_4': 0.11051799356937408, 'epoch': 29.83}
{'loss': 0.0028, 'grad_norm': 4.217177391052246, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.002142729703336954, 'loss_2': 0.0006260871887207031, 'loss_3': -16.370269775390625, 'loss_4': -0.14512185752391815, 'epoch': 29.84}
{'loss': 0.0061, 'grad_norm': 5.09522008895874, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.003706895047798753, 'loss_2': 0.002414703369140625, 'loss_3': -16.51978874206543, 'loss_4': 0.13050627708435059, 'epoch': 29.84}
{'loss': 0.0084, 'grad_norm': 4.647154808044434, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.005074503365904093, 'loss_2': 0.00335693359375, 'loss_3': -16.322399139404297, 'loss_4': -0.0730006992816925, 'epoch': 29.85}
{'loss': 0.0082, 'grad_norm': 5.038904666900635, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.0038771997205913067, 'loss_2': 0.0043182373046875, 'loss_3': -16.217073440551758, 'loss_4': -0.007755853235721588, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 14:27:04,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:04,214 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:23<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:11,544 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01240572426468134, 'eval_runtime': 3.784, 'eval_samples_per_second': 270.617, 'eval_steps_per_second': 4.228, 'eval_loss_1': 0.010089919902384281, 'eval_loss_2': 0.002315804362297058, 'eval_loss_3': -18.09809112548828, 'eval_loss_4': 0.07781902700662613, 'epoch': 29.85}
{'loss': 0.0094, 'grad_norm': 5.31934118270874, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.008079559542238712, 'loss_2': 0.0013294219970703125, 'loss_3': -16.32400894165039, 'loss_4': -0.061070576310157776, 'epoch': 29.86}
{'loss': 0.0206, 'grad_norm': 18.203258514404297, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.01977349817752838, 'loss_2': 0.0008335113525390625, 'loss_3': -16.385343551635742, 'loss_4': 0.2419057935476303, 'epoch': 29.87}
{'loss': 0.0087, 'grad_norm': 5.8857245445251465, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.004975395277142525, 'loss_2': 0.003757476806640625, 'loss_3': -16.422836303710938, 'loss_4': 0.24292026460170746, 'epoch': 29.87}
{'loss': 0.0088, 'grad_norm': 5.865122318267822, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.008662987500429153, 'loss_2': 0.00016880035400390625, 'loss_3': -16.354551315307617, 'loss_4': 0.4939452111721039, 'epoch': 29.88}
{'loss': 0.0103, 'grad_norm': 7.752747535705566, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.008573012426495552, 'loss_2': 0.0016937255859375, 'loss_3': -16.630050659179688, 'loss_4': 0.29648929834365845, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 14:27:11,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:11,544 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:30<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:18,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01243090070784092, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.395, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.01009437721222639, 'eval_loss_2': 0.0023365244269371033, 'eval_loss_3': -18.098114013671875, 'eval_loss_4': 0.07846857607364655, 'epoch': 29.88}
{'loss': 0.007, 'grad_norm': 4.742313385009766, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.005714992061257362, 'loss_2': 0.001251220703125, 'loss_3': -16.3793888092041, 'loss_4': 0.2334863245487213, 'epoch': 29.89}
{'loss': 0.0064, 'grad_norm': 5.294801235198975, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.003875038819387555, 'loss_2': 0.0025482177734375, 'loss_3': -16.401966094970703, 'loss_4': 0.08407188951969147, 'epoch': 29.9}
{'loss': 0.0137, 'grad_norm': 5.7892303466796875, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.008895564824342728, 'loss_2': 0.0047607421875, 'loss_3': -16.168472290039062, 'loss_4': -0.17125391960144043, 'epoch': 29.9}
{'loss': 0.0146, 'grad_norm': 4.524178981781006, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.0035787387751042843, 'loss_2': 0.0110321044921875, 'loss_3': -16.36980628967285, 'loss_4': 0.0872783213853836, 'epoch': 29.91}
{'loss': 0.0067, 'grad_norm': 4.556664943695068, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.0034504400100558996, 'loss_2': 0.00322723388671875, 'loss_3': -16.190204620361328, 'loss_4': 0.1762317419052124, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 14:27:18,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:18,879 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:38<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:26,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012424074113368988, 'eval_runtime': 3.7938, 'eval_samples_per_second': 269.912, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010076849721372128, 'eval_loss_2': 0.002347223460674286, 'eval_loss_3': -18.098466873168945, 'eval_loss_4': 0.07771575450897217, 'epoch': 29.91}
{'loss': 0.0061, 'grad_norm': 4.904955863952637, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.003713540267199278, 'loss_2': 0.0023555755615234375, 'loss_3': -16.390209197998047, 'loss_4': 0.22820812463760376, 'epoch': 29.92}
{'loss': 0.0086, 'grad_norm': 4.538559913635254, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.004090317990630865, 'loss_2': 0.00450897216796875, 'loss_3': -16.37220001220703, 'loss_4': 0.132347971200943, 'epoch': 29.92}
{'loss': 0.0084, 'grad_norm': 4.710166931152344, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.005115829408168793, 'loss_2': 0.00333404541015625, 'loss_3': -16.267366409301758, 'loss_4': -0.14265772700309753, 'epoch': 29.93}
{'loss': 0.0081, 'grad_norm': 5.062331199645996, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.006704996805638075, 'loss_2': 0.0013837814331054688, 'loss_3': -16.248268127441406, 'loss_4': 0.8798770904541016, 'epoch': 29.94}
{'loss': 0.0066, 'grad_norm': 5.2956767082214355, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.006335504353046417, 'loss_2': 0.00025653839111328125, 'loss_3': -16.346027374267578, 'loss_4': -0.09136657416820526, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 14:27:26,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:26,220 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:06:45<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:33,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012407252565026283, 'eval_runtime': 3.7854, 'eval_samples_per_second': 270.51, 'eval_steps_per_second': 4.227, 'eval_loss_1': 0.01006440632045269, 'eval_loss_2': 0.002342846244573593, 'eval_loss_3': -18.098718643188477, 'eval_loss_4': 0.07725487649440765, 'epoch': 29.94}
{'loss': 0.0087, 'grad_norm': 5.074734210968018, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.007114912383258343, 'loss_2': 0.0015659332275390625, 'loss_3': -16.408023834228516, 'loss_4': 0.48905083537101746, 'epoch': 29.95}
{'loss': 0.0191, 'grad_norm': 7.5415449142456055, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.01633957400918007, 'loss_2': 0.0028057098388671875, 'loss_3': -16.442548751831055, 'loss_4': 0.1748000979423523, 'epoch': 29.95}
{'loss': 0.0093, 'grad_norm': 4.897119522094727, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.002927258377894759, 'loss_2': 0.0063629150390625, 'loss_3': -16.310558319091797, 'loss_4': 0.1744377315044403, 'epoch': 29.96}
{'loss': 0.0088, 'grad_norm': 4.620899200439453, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.0014836251502856612, 'loss_2': 0.007358551025390625, 'loss_3': -16.360233306884766, 'loss_4': 0.36231091618537903, 'epoch': 29.97}
{'loss': 0.0114, 'grad_norm': 7.667101860046387, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.011138061992824078, 'loss_2': 0.00030350685119628906, 'loss_3': -16.36968231201172, 'loss_4': 0.2218688428401947, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 14:27:33,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:33,555 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:52<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 14:27:40,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012387419119477272, 'eval_runtime': 3.7907, 'eval_samples_per_second': 270.138, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.010050945915281773, 'eval_loss_2': 0.002336472272872925, 'eval_loss_3': -18.09908676147461, 'eval_loss_4': 0.0766669362783432, 'epoch': 29.97}
{'loss': 0.007, 'grad_norm': 4.504281044006348, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.0035134991630911827, 'loss_2': 0.00353240966796875, 'loss_3': -16.46098518371582, 'loss_4': 0.3453022837638855, 'epoch': 29.98}
{'loss': 0.0169, 'grad_norm': 7.183387279510498, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.013798474334180355, 'loss_2': 0.0030670166015625, 'loss_3': -16.199386596679688, 'loss_4': 0.46077537536621094, 'epoch': 29.98}
{'loss': 0.0094, 'grad_norm': 5.638236999511719, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.005598537623882294, 'loss_2': 0.0038318634033203125, 'loss_3': -16.272741317749023, 'loss_4': -0.20656998455524445, 'epoch': 29.99}
{'loss': 0.0027, 'grad_norm': 4.616388320922852, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.002568393712863326, 'loss_2': 0.0001556873321533203, 'loss_3': -16.430313110351562, 'loss_4': 0.344923734664917, 'epoch': 29.99}
{'loss': 0.0074, 'grad_norm': 5.845205783843994, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.0012353891506791115, 'loss_2': 0.00614166259765625, 'loss_3': -16.40018653869629, 'loss_4': -0.17949295043945312, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 14:27:40,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:40,547 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:56<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 14:27:44,363 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.012378320097923279, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.466, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010052277706563473, 'eval_loss_2': 0.0023260414600372314, 'eval_loss_3': -18.099061965942383, 'eval_loss_4': 0.07679691910743713, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 14:27:44,363 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/checkpoint-1370 (score: 0.009650643914937973).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:06:56<00:00,  1.48s/it]
{'train_runtime': 7617.3211, 'train_samples_per_second': 43.236, 'train_steps_per_second': 0.677, 'train_loss': 0.0407854706393248, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 14:27:44,441 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32
[INFO|configuration_utils.py:420] 2025-01-21 14:27:44,444 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 14:27:45,115 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:27:45,116 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:27:45,117 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl4_gr-wneg32/special_tokens_map.json
01/21/2025 14:27:45 - INFO - __main__ -   ***** Train results *****
01/21/2025 14:27:45 - INFO - __main__ -     epoch = 30.0
01/21/2025 14:27:45 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 14:27:45 - INFO - __main__ -     train_loss = 0.0407854706393248
01/21/2025 14:27:45 - INFO - __main__ -     train_runtime = 7617.3211
01/21/2025 14:27:45 - INFO - __main__ -     train_samples_per_second = 43.236
01/21/2025 14:27:45 - INFO - __main__ -     train_steps_per_second = 0.677
01/21/2025 14:27:45 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 14:27:45,388 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:27:45,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:45,388 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.39it/s]
01/21/2025 14:27:49 - INFO - __main__ -   ***** Eval results *****
01/21/2025 14:27:49 - INFO - __main__ -     epoch = 30.0
01/21/2025 14:27:49 - INFO - __main__ -     eval_loss = 0.009650643914937973
01/21/2025 14:27:49 - INFO - __main__ -     eval_loss_1 = 0.007178634870797396
01/21/2025 14:27:49 - INFO - __main__ -     eval_loss_2 = 0.0024720095098018646
01/21/2025 14:27:49 - INFO - __main__ -     eval_loss_3 = -18.169984817504883
01/21/2025 14:27:49 - INFO - __main__ -     eval_loss_4 = 0.11806853860616684
01/21/2025 14:27:49 - INFO - __main__ -     eval_runtime = 3.9523
01/21/2025 14:27:49 - INFO - __main__ -     eval_samples_per_second = 259.092
01/21/2025 14:27:49 - INFO - __main__ -     eval_steps_per_second = 4.048
