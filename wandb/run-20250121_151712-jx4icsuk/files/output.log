  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 15:17:13,432 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:05:28,  1.31it/s][INFO|trainer.py:4226] 2025-01-21 15:17:17,575 >>
{'loss': 3.7301, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.653231143951416, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 4.0846, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 4.001248836517334, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 4.0429, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.9740970134735107, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 3.6234, 'grad_norm': 135.80052185058594, 'learning_rate': 2.999418604651163e-05, 'loss_1': 3.5567235946655273, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 4.0623, 'grad_norm': 127.78450012207031, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.988661289215088, 'loss_2': 0.07366943359375, 'loss_3': -13.610179901123047, 'loss_4': 9.496049880981445, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:17,575 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:17,575 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:07<1:05:28,  1.31it/s][INFO|trainer.py:3910] 2025-01-21 15:17:21,366 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 15:17:21,369 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-5/config.json                                                                               
{'eval_loss': 2.052140951156616, 'eval_runtime': 3.7895, 'eval_samples_per_second': 270.219, 'eval_steps_per_second': 4.222, 'eval_loss_1': 2.0080714225769043, 'eval_loss_2': 0.04406929016113281, 'eval_loss_3': -17.943025588989258, 'eval_loss_4': 7.962069988250732, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:21,895 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:21,896 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:21,897 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:12<1:34:17,  1.10s/it][INFO|trainer.py:4226] 2025-01-21 15:17:26,320 >>
{'loss': 3.8292, 'grad_norm': 125.84207916259766, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.7794926166534424, 'loss_2': 0.0496826171875, 'loss_3': -14.081192970275879, 'loss_4': 8.938163757324219, 'epoch': 0.03}
{'loss': 3.4944, 'grad_norm': 118.71426391601562, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 3.466571569442749, 'loss_2': 0.0278778076171875, 'loss_3': -14.557939529418945, 'loss_4': 7.870303153991699, 'epoch': 0.04}
{'loss': 3.2578, 'grad_norm': 118.55443572998047, 'learning_rate': 2.997093023255814e-05, 'loss_1': 3.2338883876800537, 'loss_2': 0.023956298828125, 'loss_3': -14.87863540649414, 'loss_4': 5.622922897338867, 'epoch': 0.05}
{'loss': 3.2135, 'grad_norm': inf, 'learning_rate': 2.997093023255814e-05, 'loss_1': 3.1751773357391357, 'loss_2': 0.038360595703125, 'loss_3': -14.939806938171387, 'loss_4': 6.710938930511475, 'epoch': 0.05}
{'loss': 3.2958, 'grad_norm': 121.74388122558594, 'learning_rate': 2.996511627906977e-05, 'loss_1': 3.270193576812744, 'loss_2': 0.025634765625, 'loss_3': -14.857227325439453, 'loss_4': 6.403476715087891, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:26,321 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:26,321 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:34:17,  1.10s/it][INFO|trainer.py:3910] 2025-01-21 15:17:30,137 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 15:17:30,138 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-10/config.json                                                                              
{'eval_loss': 1.8494123220443726, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.436, 'eval_steps_per_second': 4.194, 'eval_loss_1': 1.8240951299667358, 'eval_loss_2': 0.02531719207763672, 'eval_loss_3': -17.88853645324707, 'eval_loss_4': 6.706411361694336, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:30,578 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:30,579 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:30,579 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:17:31,446 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:38:43,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:17:35,086 >>
{'loss': 2.7829, 'grad_norm': 103.1154556274414, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.755436897277832, 'loss_2': 0.027435302734375, 'loss_3': -15.337057113647461, 'loss_4': 7.612285614013672, 'epoch': 0.06}
{'loss': 2.9833, 'grad_norm': 123.60543060302734, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.9542250633239746, 'loss_2': 0.029052734375, 'loss_3': -15.167976379394531, 'loss_4': 6.854398727416992, 'epoch': 0.07}
{'loss': 2.8675, 'grad_norm': 110.90406036376953, 'learning_rate': 2.994767441860465e-05, 'loss_1': 2.8291449546813965, 'loss_2': 0.038360595703125, 'loss_3': -15.624354362487793, 'loss_4': 8.767135620117188, 'epoch': 0.08}
{'loss': 2.7974, 'grad_norm': 119.84451293945312, 'learning_rate': 2.994186046511628e-05, 'loss_1': 2.769221305847168, 'loss_2': 0.0282135009765625, 'loss_3': -15.546575546264648, 'loss_4': 8.258933067321777, 'epoch': 0.08}
{'loss': 2.598, 'grad_norm': 122.1861801147461, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 2.572209596633911, 'loss_2': 0.0257568359375, 'loss_3': -15.743967056274414, 'loss_4': 8.35855484008789, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:35,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:35,087 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:38:43,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:17:38,869 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 15:17:38,870 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-15/config.json                                                                              
{'eval_loss': 1.37383234500885, 'eval_runtime': 3.7809, 'eval_samples_per_second': 270.835, 'eval_steps_per_second': 4.232, 'eval_loss_1': 1.3566190004348755, 'eval_loss_2': 0.01721334457397461, 'eval_loss_3': -18.10166358947754, 'eval_loss_4': 7.227012634277344, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:39,296 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:39,297 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:39,297 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:17:40,114 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:38:36,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:17:43,743 >>
{'loss': 2.4, 'grad_norm': 119.3048324584961, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 2.3725497722625732, 'loss_2': 0.0274658203125, 'loss_3': -15.869535446166992, 'loss_4': 7.841508865356445, 'epoch': 0.09}
{'loss': 2.6772, 'grad_norm': 114.95899200439453, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 2.6612515449523926, 'loss_2': 0.0159912109375, 'loss_3': -15.489829063415527, 'loss_4': 7.607383728027344, 'epoch': 0.1}
{'loss': 2.2243, 'grad_norm': 119.00286102294922, 'learning_rate': 2.991860465116279e-05, 'loss_1': 2.2056238651275635, 'loss_2': 0.0186614990234375, 'loss_3': -15.741175651550293, 'loss_4': 7.7896599769592285, 'epoch': 0.1}
{'loss': 2.0979, 'grad_norm': 134.97860717773438, 'learning_rate': 2.991279069767442e-05, 'loss_1': 2.091461658477783, 'loss_2': 0.00644683837890625, 'loss_3': -15.805824279785156, 'loss_4': 6.960171222686768, 'epoch': 0.11}
{'loss': 1.8761, 'grad_norm': 119.77322387695312, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 1.8696250915527344, 'loss_2': 0.00652313232421875, 'loss_3': -16.007768630981445, 'loss_4': 5.992548942565918, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:43,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:43,743 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:38:36,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:17:47,531 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 15:17:47,533 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-20/config.json                                                                              
{'eval_loss': 0.7675731182098389, 'eval_runtime': 3.787, 'eval_samples_per_second': 270.4, 'eval_steps_per_second': 4.225, 'eval_loss_1': 0.7620351910591125, 'eval_loss_2': 0.005537927150726318, 'eval_loss_3': -18.12403678894043, 'eval_loss_4': 5.724095821380615, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:48,057 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:48,058 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:48,058 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:17:49,000 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:39<1:40:06,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:17:52,642 >>
{'loss': 1.82, 'grad_norm': 115.94479370117188, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 1.817777156829834, 'loss_2': 0.0021820068359375, 'loss_3': -15.841045379638672, 'loss_4': 6.270090579986572, 'epoch': 0.12}
{'loss': 1.4249, 'grad_norm': 103.4538803100586, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 1.4198694229125977, 'loss_2': 0.0049896240234375, 'loss_3': -15.962149620056152, 'loss_4': 7.258511066436768, 'epoch': 0.13}
{'loss': 1.1494, 'grad_norm': 104.4410171508789, 'learning_rate': 2.988953488372093e-05, 'loss_1': 1.1471278667449951, 'loss_2': 0.00225067138671875, 'loss_3': -15.93087387084961, 'loss_4': 6.200132369995117, 'epoch': 0.13}
{'loss': 1.3016, 'grad_norm': 98.6348876953125, 'learning_rate': 2.988372093023256e-05, 'loss_1': 1.2965219020843506, 'loss_2': 0.00511932373046875, 'loss_3': -15.73626708984375, 'loss_4': 6.320521354675293, 'epoch': 0.14}
{'loss': 1.2359, 'grad_norm': 106.342041015625, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 1.2260820865631104, 'loss_2': 0.00982666015625, 'loss_3': -15.626084327697754, 'loss_4': 5.955721378326416, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:17:52,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:17:52,642 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:43<1:40:06,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 15:17:56,434 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 15:17:56,435 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-25/config.json                                                                              
{'eval_loss': 0.37308448553085327, 'eval_runtime': 3.7904, 'eval_samples_per_second': 270.154, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.3685435652732849, 'eval_loss_2': 0.004540935158729553, 'eval_loss_3': -17.98699378967285, 'eval_loss_4': 4.80756950378418, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 15:17:56,881 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:17:56,883 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:17:56,883 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:17:57,709 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:47<1:39:13,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:18:01,370 >>
{'loss': 0.907, 'grad_norm': 100.5246810913086, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.906705379486084, 'loss_2': 0.000316619873046875, 'loss_3': -15.723402976989746, 'loss_4': 5.552746772766113, 'epoch': 0.15}
{'loss': 1.0431, 'grad_norm': 87.5031967163086, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 1.0393524169921875, 'loss_2': 0.00377655029296875, 'loss_3': -15.454313278198242, 'loss_4': 6.064233303070068, 'epoch': 0.16}
{'loss': 0.7553, 'grad_norm': 77.94998168945312, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.7409924864768982, 'loss_2': 0.01434326171875, 'loss_3': -15.472393035888672, 'loss_4': 5.2129926681518555, 'epoch': 0.16}
{'loss': 0.7854, 'grad_norm': 82.7081069946289, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.7722699046134949, 'loss_2': 0.01311492919921875, 'loss_3': -15.492025375366211, 'loss_4': 4.969033241271973, 'epoch': 0.17}
{'loss': 0.7454, 'grad_norm': 97.60506439208984, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.7364358305931091, 'loss_2': 0.008941650390625, 'loss_3': -15.34831428527832, 'loss_4': 6.351553916931152, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:01,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:01,370 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:51<1:39:13,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 15:18:05,163 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 15:18:05,165 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-30/config.json                                                                              
{'eval_loss': 0.22443555295467377, 'eval_runtime': 3.7926, 'eval_samples_per_second': 270.002, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.2191823571920395, 'eval_loss_2': 0.005253195762634277, 'eval_loss_3': -17.904539108276367, 'eval_loss_4': 5.794007778167725, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:05,629 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:05,631 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:05,631 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:06,491 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:56<1:39:02,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:18:10,112 >>
{'loss': 0.7809, 'grad_norm': 83.45056915283203, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.7749540209770203, 'loss_2': 0.005962371826171875, 'loss_3': -15.303558349609375, 'loss_4': 7.07716703414917, 'epoch': 0.18}
{'loss': 0.5777, 'grad_norm': 76.29725646972656, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.5721977949142456, 'loss_2': 0.00553131103515625, 'loss_3': -15.206300735473633, 'loss_4': 6.079421043395996, 'epoch': 0.19}
{'loss': 0.654, 'grad_norm': 79.78121948242188, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.6441087126731873, 'loss_2': 0.0098419189453125, 'loss_3': -15.19715690612793, 'loss_4': 6.524596214294434, 'epoch': 0.19}
{'loss': 0.427, 'grad_norm': 65.44107818603516, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.41331279277801514, 'loss_2': 0.0137176513671875, 'loss_3': -15.175325393676758, 'loss_4': 6.178308486938477, 'epoch': 0.2}
{'loss': 0.5054, 'grad_norm': 72.74005126953125, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.49567949771881104, 'loss_2': 0.0097198486328125, 'loss_3': -15.319214820861816, 'loss_4': 6.724867820739746, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:10,112 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:10,113 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [01:00<1:39:02,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 15:18:13,911 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 15:18:13,912 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-35/config.json                                                                              
{'eval_loss': 0.14083543419837952, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.65, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.13681231439113617, 'eval_loss_2': 0.004023134708404541, 'eval_loss_3': -17.921749114990234, 'eval_loss_4': 5.475844383239746, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:14,435 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:14,436 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:14,437 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:15,338 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:05<1:39:31,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:18:18,963 >>
{'loss': 0.4508, 'grad_norm': 67.4654769897461, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.4490514099597931, 'loss_2': 0.0017528533935546875, 'loss_3': -15.179128646850586, 'loss_4': 5.689316272735596, 'epoch': 0.21}
{'loss': 0.3629, 'grad_norm': 50.925994873046875, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.3562799394130707, 'loss_2': 0.0065765380859375, 'loss_3': -15.097661972045898, 'loss_4': 5.593438148498535, 'epoch': 0.22}
{'loss': 0.5783, 'grad_norm': 72.12267303466797, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.5768717527389526, 'loss_2': 0.0014095306396484375, 'loss_3': -14.947562217712402, 'loss_4': 5.596680641174316, 'epoch': 0.22}
{'loss': 0.3587, 'grad_norm': 47.560096740722656, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.3554173409938812, 'loss_2': 0.00331878662109375, 'loss_3': -15.038015365600586, 'loss_4': 4.318932056427002, 'epoch': 0.23}
{'loss': 0.5139, 'grad_norm': 102.20336151123047, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.5102814435958862, 'loss_2': 0.003658294677734375, 'loss_3': -14.982020378112793, 'loss_4': 4.42064094543457, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:18,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:18,963 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:12<1:30:19,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:18:26,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.14323952794075012, 'eval_runtime': 3.7905, 'eval_samples_per_second': 270.148, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.13504746556282043, 'eval_loss_2': 0.008192062377929688, 'eval_loss_3': -17.841365814208984, 'eval_loss_4': 4.205499649047852, 'epoch': 0.23}
{'loss': 0.2794, 'grad_norm': 43.86378479003906, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.27541646361351013, 'loss_2': 0.004016876220703125, 'loss_3': -14.98436450958252, 'loss_4': 3.915792942047119, 'epoch': 0.24}
{'loss': 0.2009, 'grad_norm': 42.95460510253906, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.19802430272102356, 'loss_2': 0.0029048919677734375, 'loss_3': -14.89926528930664, 'loss_4': 3.0466156005859375, 'epoch': 0.24}
{'loss': 0.2625, 'grad_norm': 39.21537780761719, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.25061067938804626, 'loss_2': 0.01184844970703125, 'loss_3': -15.095383644104004, 'loss_4': 3.5709853172302246, 'epoch': 0.25}
{'loss': 0.4101, 'grad_norm': 45.668914794921875, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.4036044478416443, 'loss_2': 0.006534576416015625, 'loss_3': -14.912142753601074, 'loss_4': 4.504273891448975, 'epoch': 0.26}
{'loss': 0.3545, 'grad_norm': 55.63131332397461, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.3484595715999603, 'loss_2': 0.00601959228515625, 'loss_3': -14.866065979003906, 'loss_4': 4.689833641052246, 'epoch': 0.26}
[INFO|trainer.py:4228] 2025-01-21 15:18:26,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:26,302 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:16<1:30:19,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:18:30,102 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-45
[INFO|configuration_utils.py:420] 2025-01-21 15:18:30,104 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-45/config.json                                                                              
{'eval_loss': 0.08494172990322113, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.08115939795970917, 'eval_loss_2': 0.003782331943511963, 'eval_loss_3': -18.055749893188477, 'eval_loss_4': 4.128486633300781, 'epoch': 0.26}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:30,597 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-45/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:30,598 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-45/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:30,598 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-45/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:31,421 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-35] due to args.save_total_limit
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:21<1:37:30,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:18:35,079 >>
{'loss': 0.2866, 'grad_norm': 49.92475128173828, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.2787322402000427, 'loss_2': 0.00789642333984375, 'loss_3': -14.897308349609375, 'loss_4': 4.702543258666992, 'epoch': 0.27}
{'loss': 0.4298, 'grad_norm': 68.4801254272461, 'learning_rate': 2.975e-05, 'loss_1': 0.4249299466609955, 'loss_2': 0.0048675537109375, 'loss_3': -15.008441925048828, 'loss_4': 4.501323223114014, 'epoch': 0.27}
{'loss': 0.4184, 'grad_norm': 65.20874786376953, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.41334378719329834, 'loss_2': 0.00507354736328125, 'loss_3': -14.906732559204102, 'loss_4': 4.256525039672852, 'epoch': 0.28}
{'loss': 0.4181, 'grad_norm': 62.1035041809082, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.41312649846076965, 'loss_2': 0.004970550537109375, 'loss_3': -14.999985694885254, 'loss_4': 4.326216697692871, 'epoch': 0.28}
{'loss': 0.2541, 'grad_norm': 42.07313919067383, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.2522948384284973, 'loss_2': 0.00182342529296875, 'loss_3': -14.974842071533203, 'loss_4': 2.6174306869506836, 'epoch': 0.29}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:35,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:35,079 >>   Batch size = 64
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:25<1:37:30,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 15:18:38,875 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-50
[INFO|configuration_utils.py:420] 2025-01-21 15:18:38,877 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-50/config.json                                                                              
{'eval_loss': 0.07539866119623184, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.07121220231056213, 'eval_loss_2': 0.004186451435089111, 'eval_loss_3': -17.957416534423828, 'eval_loss_4': 2.19111704826355, 'epoch': 0.29}
[INFO|modeling_utils.py:2988] 2025-01-21 15:18:39,396 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-50/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:18:39,397 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-50/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:18:39,397 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-50/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:18:40,263 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-45] due to args.save_total_limit
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:30<1:38:55,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:18:43,912 >>
{'loss': 0.3483, 'grad_norm': 46.28693771362305, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.3416779935359955, 'loss_2': 0.00662994384765625, 'loss_3': -14.902545928955078, 'loss_4': 2.440685272216797, 'epoch': 0.3}
{'loss': 0.221, 'grad_norm': 40.67146682739258, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.20823006331920624, 'loss_2': 0.0128173828125, 'loss_3': -14.89953327178955, 'loss_4': 2.185502052307129, 'epoch': 0.3}
{'loss': 0.1655, 'grad_norm': 45.2752685546875, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.16155220568180084, 'loss_2': 0.00392913818359375, 'loss_3': -15.073861122131348, 'loss_4': 1.6443097591400146, 'epoch': 0.31}
{'loss': 0.3095, 'grad_norm': 57.824729919433594, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.30830153822898865, 'loss_2': 0.0011720657348632812, 'loss_3': -14.830615997314453, 'loss_4': 1.545518159866333, 'epoch': 0.31}
{'loss': 0.2181, 'grad_norm': 36.24114990234375, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.21054887771606445, 'loss_2': 0.0075836181640625, 'loss_3': -14.999486923217773, 'loss_4': 1.0695382356643677, 'epoch': 0.32}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:18:43,912 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:43,912 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:37<1:30:05,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:18:51,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08990143984556198, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.512, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.08350791782140732, 'eval_loss_2': 0.006393522024154663, 'eval_loss_3': -17.84079360961914, 'eval_loss_4': 1.244381308555603, 'epoch': 0.32}
{'loss': 0.161, 'grad_norm': 54.978267669677734, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.15901322662830353, 'loss_2': 0.00199127197265625, 'loss_3': -15.081829071044922, 'loss_4': 0.8927687406539917, 'epoch': 0.33}
{'loss': 0.2519, 'grad_norm': 44.57644271850586, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.2465694397687912, 'loss_2': 0.005340576171875, 'loss_3': -14.8409423828125, 'loss_4': 1.4821267127990723, 'epoch': 0.33}
{'loss': 0.19, 'grad_norm': 37.496673583984375, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.1847381591796875, 'loss_2': 0.005245208740234375, 'loss_3': -14.870587348937988, 'loss_4': 0.706221878528595, 'epoch': 0.34}
{'loss': 0.2078, 'grad_norm': 40.90319061279297, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.2054336816072464, 'loss_2': 0.0023250579833984375, 'loss_3': -14.94525146484375, 'loss_4': 0.8230022192001343, 'epoch': 0.34}
{'loss': 0.1441, 'grad_norm': 32.14738082885742, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.13621968030929565, 'loss_2': 0.0078887939453125, 'loss_3': -14.919764518737793, 'loss_4': 0.034704916179180145, 'epoch': 0.35}
[INFO|trainer.py:4228] 2025-01-21 15:18:51,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:51,273 >>   Batch size = 64
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:45<1:28:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:18:58,629 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09342649579048157, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.54, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.08496569097042084, 'eval_loss_2': 0.008460812270641327, 'eval_loss_3': -17.827348709106445, 'eval_loss_4': 0.5597342252731323, 'epoch': 0.35}
{'loss': 0.2134, 'grad_norm': 36.40546798706055, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.2074316293001175, 'loss_2': 0.005970001220703125, 'loss_3': -14.697917938232422, 'loss_4': 0.4656776785850525, 'epoch': 0.35}
{'loss': 0.1968, 'grad_norm': 34.63900375366211, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.1877499520778656, 'loss_2': 0.00907135009765625, 'loss_3': -15.110597610473633, 'loss_4': 0.5813868045806885, 'epoch': 0.36}
{'loss': 0.147, 'grad_norm': 32.7956428527832, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.1361054629087448, 'loss_2': 0.01092529296875, 'loss_3': -14.983561515808105, 'loss_4': 0.15543164312839508, 'epoch': 0.37}
{'loss': 0.1862, 'grad_norm': 40.986961364746094, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.18555483222007751, 'loss_2': 0.0006923675537109375, 'loss_3': -14.791057586669922, 'loss_4': 0.9955874681472778, 'epoch': 0.37}
{'loss': 0.215, 'grad_norm': 35.753578186035156, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.21279439330101013, 'loss_2': 0.0022106170654296875, 'loss_3': -14.579435348510742, 'loss_4': 1.0076940059661865, 'epoch': 0.38}
[INFO|trainer.py:4228] 2025-01-21 15:18:58,629 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:18:58,630 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:52<1:28:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:05,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08230242878198624, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0783730298280716, 'eval_loss_2': 0.003929391503334045, 'eval_loss_3': -17.880905151367188, 'eval_loss_4': 0.7578147053718567, 'epoch': 0.38}
{'loss': 0.0983, 'grad_norm': 20.315040588378906, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.09525330364704132, 'loss_2': 0.0030651092529296875, 'loss_3': -15.015984535217285, 'loss_4': 0.6624000072479248, 'epoch': 0.38}
{'loss': 0.1864, 'grad_norm': 37.377281188964844, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.17373692989349365, 'loss_2': 0.0126495361328125, 'loss_3': -14.877941131591797, 'loss_4': 1.7166820764541626, 'epoch': 0.39}
{'loss': 0.227, 'grad_norm': 36.51294708251953, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.2126399427652359, 'loss_2': 0.0143280029296875, 'loss_3': -14.896484375, 'loss_4': 0.8807240724563599, 'epoch': 0.4}
{'loss': 0.138, 'grad_norm': 27.88637351989746, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.11986778676509857, 'loss_2': 0.018157958984375, 'loss_3': -14.648185729980469, 'loss_4': 1.5273593664169312, 'epoch': 0.4}
{'loss': 0.1556, 'grad_norm': 28.386337280273438, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.13982070982456207, 'loss_2': 0.0157470703125, 'loss_3': -14.805485725402832, 'loss_4': 1.0371546745300293, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 15:19:05,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:05,979 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:56<1:28:12,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:19:09,777 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-70
[INFO|configuration_utils.py:420] 2025-01-21 15:19:09,778 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-70/config.json                                                                              
{'eval_loss': 0.07434540241956711, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.734, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.062377382069826126, 'eval_loss_2': 0.011968016624450684, 'eval_loss_3': -17.970592498779297, 'eval_loss_4': 1.6168441772460938, 'epoch': 0.41}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:10,215 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-70/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:10,216 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-70/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:10,217 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-70/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:11,035 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-50] due to args.save_total_limit
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:01<1:36:15,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:19:14,670 >>
{'loss': 0.1909, 'grad_norm': 26.06635856628418, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.17841000854969025, 'loss_2': 0.0125274658203125, 'loss_3': -14.656167984008789, 'loss_4': 1.6844490766525269, 'epoch': 0.41}
{'loss': 0.271, 'grad_norm': 42.865509033203125, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.25368571281433105, 'loss_2': 0.017303466796875, 'loss_3': -14.774711608886719, 'loss_4': 1.797358512878418, 'epoch': 0.42}
{'loss': 0.2531, 'grad_norm': 37.631649017333984, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.23545370995998383, 'loss_2': 0.0176239013671875, 'loss_3': -14.82200813293457, 'loss_4': 2.5873711109161377, 'epoch': 0.42}
{'loss': 0.1208, 'grad_norm': 25.764677047729492, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.10776345431804657, 'loss_2': 0.0130615234375, 'loss_3': -14.79261589050293, 'loss_4': 1.4156959056854248, 'epoch': 0.43}
{'loss': 0.1318, 'grad_norm': 27.025836944580078, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.12091054022312164, 'loss_2': 0.01087188720703125, 'loss_3': -14.81849479675293, 'loss_4': 2.0043792724609375, 'epoch': 0.44}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:14,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:14,671 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:05<1:36:15,  1.14s/it][INFO|trainer.py:3910] 2025-01-21 15:19:18,469 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-75
[INFO|configuration_utils.py:420] 2025-01-21 15:19:18,470 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-75/config.json                                                                              
{'eval_loss': 0.04563513025641441, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.703, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.041720595210790634, 'eval_loss_2': 0.003914535045623779, 'eval_loss_3': -18.094526290893555, 'eval_loss_4': 1.7123714685440063, 'epoch': 0.44}
[INFO|modeling_utils.py:2988] 2025-01-21 15:19:18,942 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-75/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:19:18,944 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-75/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:19:18,944 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-75/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:19:19,813 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-70] due to args.save_total_limit
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:10<1:37:56,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:19:23,440 >>
{'loss': 0.1604, 'grad_norm': 31.56563377380371, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.15366899967193604, 'loss_2': 0.00676727294921875, 'loss_3': -14.823022842407227, 'loss_4': 2.227602958679199, 'epoch': 0.44}
{'loss': 0.1077, 'grad_norm': 18.98003578186035, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.10182112455368042, 'loss_2': 0.00583648681640625, 'loss_3': -15.018452644348145, 'loss_4': 1.302725076675415, 'epoch': 0.45}
{'loss': 0.2169, 'grad_norm': 35.29822540283203, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.20838308334350586, 'loss_2': 0.0085601806640625, 'loss_3': -14.920557975769043, 'loss_4': 1.5123748779296875, 'epoch': 0.45}
{'loss': 0.1637, 'grad_norm': 27.020530700683594, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.1486784964799881, 'loss_2': 0.0150299072265625, 'loss_3': -15.133003234863281, 'loss_4': 2.2121057510375977, 'epoch': 0.46}
{'loss': 0.2911, 'grad_norm': 49.642147064208984, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.2764608561992645, 'loss_2': 0.01465606689453125, 'loss_3': -15.047904968261719, 'loss_4': 1.7089558839797974, 'epoch': 0.47}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:19:23,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:23,440 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:17<1:29:41,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:19:30,800 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.057837050408124924, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.04029040038585663, 'eval_loss_2': 0.017546653747558594, 'eval_loss_3': -18.108379364013672, 'eval_loss_4': 1.094367265701294, 'epoch': 0.47}
{'loss': 0.1565, 'grad_norm': 28.77532196044922, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.1395641267299652, 'loss_2': 0.0169830322265625, 'loss_3': -14.881362915039062, 'loss_4': 1.2958135604858398, 'epoch': 0.47}
{'loss': 0.2372, 'grad_norm': 45.99224853515625, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.23228001594543457, 'loss_2': 0.00496673583984375, 'loss_3': -14.994237899780273, 'loss_4': 1.2473323345184326, 'epoch': 0.48}
{'loss': 0.1951, 'grad_norm': 37.29103469848633, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.18301208317279816, 'loss_2': 0.0121307373046875, 'loss_3': -15.338037490844727, 'loss_4': 1.1954827308654785, 'epoch': 0.48}
{'loss': 0.1803, 'grad_norm': 31.168010711669922, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.1718028485774994, 'loss_2': 0.008544921875, 'loss_3': -14.930215835571289, 'loss_4': 1.125060796737671, 'epoch': 0.49}
{'loss': 0.232, 'grad_norm': 54.807640075683594, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.22986415028572083, 'loss_2': 0.002094268798828125, 'loss_3': -14.90524673461914, 'loss_4': 2.02070689201355, 'epoch': 0.49}
[INFO|trainer.py:4228] 2025-01-21 15:19:30,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:30,800 >>   Batch size = 64
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:24<1:28:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:38,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.052552517503499985, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.93, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04737814888358116, 'eval_loss_2': 0.005174368619918823, 'eval_loss_3': -18.035669326782227, 'eval_loss_4': 1.3591022491455078, 'epoch': 0.49}
{'loss': 0.1512, 'grad_norm': 33.9571533203125, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.1504746526479721, 'loss_2': 0.0006880760192871094, 'loss_3': -14.994394302368164, 'loss_4': 1.5167672634124756, 'epoch': 0.5}
{'loss': 0.1225, 'grad_norm': 22.850265502929688, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.11590861529111862, 'loss_2': 0.0065765380859375, 'loss_3': -14.8265380859375, 'loss_4': 1.6046322584152222, 'epoch': 0.51}
{'loss': 0.1885, 'grad_norm': 36.468955993652344, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.18193788826465607, 'loss_2': 0.00656890869140625, 'loss_3': -14.935561180114746, 'loss_4': 1.4289870262145996, 'epoch': 0.51}
{'loss': 0.268, 'grad_norm': 43.01713943481445, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.26514923572540283, 'loss_2': 0.0028533935546875, 'loss_3': -14.960359573364258, 'loss_4': 1.733036756515503, 'epoch': 0.52}
{'loss': 0.1185, 'grad_norm': 28.56153678894043, 'learning_rate': 2.95e-05, 'loss_1': 0.11398795247077942, 'loss_2': 0.004486083984375, 'loss_3': -15.120104789733887, 'loss_4': 1.5657081604003906, 'epoch': 0.52}
[INFO|trainer.py:4228] 2025-01-21 15:19:38,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:38,154 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:32<1:27:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:45,509 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06112160533666611, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.491, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.056545838713645935, 'eval_loss_2': 0.004575762897729874, 'eval_loss_3': -17.986154556274414, 'eval_loss_4': 1.5744621753692627, 'epoch': 0.52}
{'loss': 0.2338, 'grad_norm': 48.02425003051758, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.23306627571582794, 'loss_2': 0.0007429122924804688, 'loss_3': -15.05214786529541, 'loss_4': 1.826789140701294, 'epoch': 0.53}
{'loss': 0.2128, 'grad_norm': 34.89122772216797, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.2075633555650711, 'loss_2': 0.0052642822265625, 'loss_3': -14.744357109069824, 'loss_4': 1.9091315269470215, 'epoch': 0.53}
{'loss': 0.1386, 'grad_norm': 30.313486099243164, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.13074001669883728, 'loss_2': 0.0078125, 'loss_3': -15.114034652709961, 'loss_4': 2.0190603733062744, 'epoch': 0.54}
{'loss': 0.2277, 'grad_norm': 40.71971893310547, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.2171916365623474, 'loss_2': 0.0105438232421875, 'loss_3': -14.870809555053711, 'loss_4': 1.4711041450500488, 'epoch': 0.55}
{'loss': 0.2313, 'grad_norm': 41.65324020385742, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.21526138484477997, 'loss_2': 0.016021728515625, 'loss_3': -14.908336639404297, 'loss_4': 1.943061113357544, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 15:19:45,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:45,509 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:39<1:27:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:19:52,864 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06439095735549927, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.407, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.05971094220876694, 'eval_loss_2': 0.004680007696151733, 'eval_loss_3': -17.937894821166992, 'eval_loss_4': 2.1021995544433594, 'epoch': 0.55}
{'loss': 0.1965, 'grad_norm': 34.92961883544922, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.1786479353904724, 'loss_2': 0.017822265625, 'loss_3': -14.997410774230957, 'loss_4': 1.4706237316131592, 'epoch': 0.56}
{'loss': 0.1461, 'grad_norm': 33.99853515625, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.14104898273944855, 'loss_2': 0.0050506591796875, 'loss_3': -14.919654846191406, 'loss_4': 1.9333446025848389, 'epoch': 0.56}
{'loss': 0.2114, 'grad_norm': 36.405921936035156, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.21037983894348145, 'loss_2': 0.0010051727294921875, 'loss_3': -14.877452850341797, 'loss_4': 2.4591095447540283, 'epoch': 0.57}
{'loss': 0.1416, 'grad_norm': 32.94643783569336, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.14149120450019836, 'loss_2': 0.00015723705291748047, 'loss_3': -14.964354515075684, 'loss_4': 2.383037567138672, 'epoch': 0.58}
{'loss': 0.1632, 'grad_norm': 33.99260711669922, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.1573571264743805, 'loss_2': 0.00588226318359375, 'loss_3': -14.821293830871582, 'loss_4': 2.3998398780822754, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 15:19:52,864 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:19:52,864 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:46<1:27:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:00,230 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07486122846603394, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.196, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0656973123550415, 'eval_loss_2': 0.009163916110992432, 'eval_loss_3': -17.83880615234375, 'eval_loss_4': 2.5653762817382812, 'epoch': 0.58}
{'loss': 0.1226, 'grad_norm': 33.84867477416992, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.11116935312747955, 'loss_2': 0.01139068603515625, 'loss_3': -15.004857063293457, 'loss_4': 2.3130431175231934, 'epoch': 0.59}
{'loss': 0.1745, 'grad_norm': 73.00447082519531, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.1666661947965622, 'loss_2': 0.007843017578125, 'loss_3': -14.848087310791016, 'loss_4': 2.660000801086426, 'epoch': 0.59}
{'loss': 0.1661, 'grad_norm': 30.11821174621582, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.15774919092655182, 'loss_2': 0.0083770751953125, 'loss_3': -15.01034927368164, 'loss_4': 3.411245822906494, 'epoch': 0.6}
{'loss': 0.1328, 'grad_norm': 29.355457305908203, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.13103598356246948, 'loss_2': 0.0017681121826171875, 'loss_3': -14.961519241333008, 'loss_4': 2.947307586669922, 'epoch': 0.6}
{'loss': 0.1174, 'grad_norm': 28.788448333740234, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.11452136188745499, 'loss_2': 0.00284576416015625, 'loss_3': -14.948590278625488, 'loss_4': 3.4174203872680664, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 15:20:00,230 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:00,230 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:54<1:27:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:07,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05042089521884918, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.04522579163312912, 'eval_loss_2': 0.005195103585720062, 'eval_loss_3': -17.97464942932129, 'eval_loss_4': 3.222723960876465, 'epoch': 0.61}
{'loss': 0.1263, 'grad_norm': 32.168975830078125, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.1223488375544548, 'loss_2': 0.003948211669921875, 'loss_3': -15.052591323852539, 'loss_4': 3.482470989227295, 'epoch': 0.62}
{'loss': 0.3395, 'grad_norm': 64.59915924072266, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.3235401511192322, 'loss_2': 0.0159454345703125, 'loss_3': -14.976879119873047, 'loss_4': 4.1312689781188965, 'epoch': 0.62}
{'loss': 0.2276, 'grad_norm': 58.1776008605957, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.21855998039245605, 'loss_2': 0.009033203125, 'loss_3': -14.805819511413574, 'loss_4': 4.19162654876709, 'epoch': 0.63}
{'loss': 0.1714, 'grad_norm': 35.69894790649414, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.1673358827829361, 'loss_2': 0.00409698486328125, 'loss_3': -14.842899322509766, 'loss_4': 3.4264163970947266, 'epoch': 0.63}
{'loss': 0.3224, 'grad_norm': 47.50823211669922, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.3194729685783386, 'loss_2': 0.002964019775390625, 'loss_3': -15.022233963012695, 'loss_4': 4.2188310623168945, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 15:20:07,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:07,592 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:01<1:27:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:14,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.046444907784461975, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.9, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04155286028981209, 'eval_loss_2': 0.0048920512199401855, 'eval_loss_3': -17.986082077026367, 'eval_loss_4': 3.2341909408569336, 'epoch': 0.64}
{'loss': 0.2972, 'grad_norm': 54.74107360839844, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.2949067950248718, 'loss_2': 0.002277374267578125, 'loss_3': -14.762075424194336, 'loss_4': 3.59507155418396, 'epoch': 0.65}
{'loss': 0.1638, 'grad_norm': 40.92190933227539, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.16350896656513214, 'loss_2': 0.0002484321594238281, 'loss_3': -15.065552711486816, 'loss_4': 3.776331901550293, 'epoch': 0.65}
{'loss': 0.144, 'grad_norm': 41.0601806640625, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.14345501363277435, 'loss_2': 0.0005922317504882812, 'loss_3': -14.99217414855957, 'loss_4': 3.0156819820404053, 'epoch': 0.66}
{'loss': 0.1445, 'grad_norm': 38.01042175292969, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.13630157709121704, 'loss_2': 0.00823974609375, 'loss_3': -14.924017906188965, 'loss_4': 3.132878303527832, 'epoch': 0.66}
{'loss': 0.1864, 'grad_norm': 46.557106018066406, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.18417933583259583, 'loss_2': 0.0022563934326171875, 'loss_3': -15.114219665527344, 'loss_4': 3.202667713165283, 'epoch': 0.67}
[INFO|trainer.py:4228] 2025-01-21 15:20:14,970 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:14,970 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:08<1:27:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:22,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04996328800916672, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.868, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0452684611082077, 'eval_loss_2': 0.004694819450378418, 'eval_loss_3': -17.977293014526367, 'eval_loss_4': 3.136549949645996, 'epoch': 0.67}
{'loss': 0.1266, 'grad_norm': 30.97776222229004, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.12124950438737869, 'loss_2': 0.005306243896484375, 'loss_3': -15.040018081665039, 'loss_4': 3.4527788162231445, 'epoch': 0.67}
{'loss': 0.1025, 'grad_norm': 23.511171340942383, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.09602547436952591, 'loss_2': 0.00650787353515625, 'loss_3': -15.09819221496582, 'loss_4': 2.595144748687744, 'epoch': 0.68}
{'loss': 0.0854, 'grad_norm': 25.271141052246094, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.08413354307413101, 'loss_2': 0.0013027191162109375, 'loss_3': -15.186139106750488, 'loss_4': 3.0294508934020996, 'epoch': 0.69}
{'loss': 0.1301, 'grad_norm': 34.615665435791016, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.12493108212947845, 'loss_2': 0.005161285400390625, 'loss_3': -15.02002239227295, 'loss_4': 3.4753637313842773, 'epoch': 0.69}
{'loss': 0.0964, 'grad_norm': 19.395753860473633, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.09175270795822144, 'loss_2': 0.004638671875, 'loss_3': -14.956478118896484, 'loss_4': 3.123866558074951, 'epoch': 0.7}
[INFO|trainer.py:4228] 2025-01-21 15:20:22,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:22,332 >>   Batch size = 64
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:16<1:27:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:29,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.11746016144752502, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.939, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.11303142458200455, 'eval_loss_2': 0.004428744316101074, 'eval_loss_3': -17.74006462097168, 'eval_loss_4': 3.6897599697113037, 'epoch': 0.7}
{'loss': 0.1369, 'grad_norm': 33.487667083740234, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.13315819203853607, 'loss_2': 0.0037689208984375, 'loss_3': -14.88853645324707, 'loss_4': 3.046649217605591, 'epoch': 0.7}
{'loss': 0.3117, 'grad_norm': 48.68561553955078, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.3089943528175354, 'loss_2': 0.002735137939453125, 'loss_3': -15.025897026062012, 'loss_4': 4.023186683654785, 'epoch': 0.71}
{'loss': 0.1733, 'grad_norm': 29.967098236083984, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.17302115261554718, 'loss_2': 0.0002474784851074219, 'loss_3': -14.978334426879883, 'loss_4': 3.2607059478759766, 'epoch': 0.72}
{'loss': 0.0818, 'grad_norm': 18.178564071655273, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.0791124626994133, 'loss_2': 0.0026531219482421875, 'loss_3': -15.139524459838867, 'loss_4': 2.9205338954925537, 'epoch': 0.72}
{'loss': 0.1538, 'grad_norm': 23.683931350708008, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.1433824896812439, 'loss_2': 0.0104217529296875, 'loss_3': -15.191429138183594, 'loss_4': 3.2495150566101074, 'epoch': 0.73}
[INFO|trainer.py:4228] 2025-01-21 15:20:29,697 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:29,697 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:23<1:27:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:37,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.11203372478485107, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.10813292860984802, 'eval_loss_2': 0.0039007961750030518, 'eval_loss_3': -17.825990676879883, 'eval_loss_4': 3.8623950481414795, 'epoch': 0.73}
{'loss': 0.0968, 'grad_norm': 21.174522399902344, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.09503298997879028, 'loss_2': 0.0017337799072265625, 'loss_3': -15.001622200012207, 'loss_4': 3.135910987854004, 'epoch': 0.73}
{'loss': 0.1392, 'grad_norm': 27.69693374633789, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.12582483887672424, 'loss_2': 0.01334381103515625, 'loss_3': -14.993064880371094, 'loss_4': 3.537639856338501, 'epoch': 0.74}
{'loss': 0.11, 'grad_norm': 24.331369400024414, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.10531384497880936, 'loss_2': 0.00469970703125, 'loss_3': -15.165913581848145, 'loss_4': 3.207383394241333, 'epoch': 0.74}
{'loss': 0.1317, 'grad_norm': 34.32624053955078, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.13135236501693726, 'loss_2': 0.00035643577575683594, 'loss_3': -15.301021575927734, 'loss_4': 3.963078498840332, 'epoch': 0.75}
{'loss': 0.1009, 'grad_norm': 29.41486167907715, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.10062392801046371, 'loss_2': 0.0002567768096923828, 'loss_3': -15.17951774597168, 'loss_4': 3.390885829925537, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 15:20:37,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:37,049 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:30<1:27:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:44,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04579215124249458, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.42, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.03836982324719429, 'eval_loss_2': 0.007422327995300293, 'eval_loss_3': -18.09818458557129, 'eval_loss_4': 3.318171977996826, 'epoch': 0.76}
{'loss': 0.1092, 'grad_norm': 29.35116195678711, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.10026609152555466, 'loss_2': 0.0089263916015625, 'loss_3': -15.007453918457031, 'loss_4': 3.296276092529297, 'epoch': 0.76}
{'loss': 0.1686, 'grad_norm': 34.73359298706055, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.16824458539485931, 'loss_2': 0.00035381317138671875, 'loss_3': -14.995001792907715, 'loss_4': 3.5315794944763184, 'epoch': 0.77}
{'loss': 0.1297, 'grad_norm': 24.4798641204834, 'learning_rate': 2.925e-05, 'loss_1': 0.12012350559234619, 'loss_2': 0.0095672607421875, 'loss_3': -15.246414184570312, 'loss_4': 3.285284996032715, 'epoch': 0.77}
{'loss': 0.1279, 'grad_norm': 30.03878402709961, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.12472598999738693, 'loss_2': 0.003170013427734375, 'loss_3': -15.422423362731934, 'loss_4': 3.8431763648986816, 'epoch': 0.78}
{'loss': 0.1106, 'grad_norm': 28.35341453552246, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.1104692742228508, 'loss_2': 0.00014019012451171875, 'loss_3': -15.206716537475586, 'loss_4': 3.6687355041503906, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 15:20:44,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:44,401 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:38<1:27:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:20:51,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04721817746758461, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.04371208697557449, 'eval_loss_2': 0.003506094217300415, 'eval_loss_3': -18.210163116455078, 'eval_loss_4': 3.1577067375183105, 'epoch': 0.78}
{'loss': 0.1183, 'grad_norm': 21.05031967163086, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.1163153201341629, 'loss_2': 0.0019474029541015625, 'loss_3': -15.300216674804688, 'loss_4': 3.731480598449707, 'epoch': 0.79}
{'loss': 0.3049, 'grad_norm': 49.79478073120117, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.3020150065422058, 'loss_2': 0.0029048919677734375, 'loss_3': -15.256651878356934, 'loss_4': 3.786116361618042, 'epoch': 0.8}
{'loss': 0.1973, 'grad_norm': 32.415283203125, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.1896231472492218, 'loss_2': 0.007724761962890625, 'loss_3': -15.199588775634766, 'loss_4': 3.1549949645996094, 'epoch': 0.8}
{'loss': 0.0976, 'grad_norm': 21.19967269897461, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.09381024539470673, 'loss_2': 0.00376129150390625, 'loss_3': -15.486013412475586, 'loss_4': 2.893832206726074, 'epoch': 0.81}
{'loss': 0.1109, 'grad_norm': 21.55553436279297, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.10588493198156357, 'loss_2': 0.00498199462890625, 'loss_3': -15.378824234008789, 'loss_4': 2.9805655479431152, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 15:20:51,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:20:51,763 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:42<1:27:02,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:20:55,579 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-140
[INFO|configuration_utils.py:420] 2025-01-21 15:20:55,581 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-140/config.json                                                                             
{'eval_loss': 0.04562008008360863, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.438, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.04154534265398979, 'eval_loss_2': 0.0040747374296188354, 'eval_loss_3': -18.210979461669922, 'eval_loss_4': 2.410207986831665, 'epoch': 0.81}
[INFO|modeling_utils.py:2988] 2025-01-21 15:20:56,099 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-140/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:20:56,100 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-140/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:20:56,101 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-140/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:20:57,098 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-75] due to args.save_total_limit
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:47<1:36:33,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:21:00,729 >>
{'loss': 0.0976, 'grad_norm': 17.11189079284668, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.0924132689833641, 'loss_2': 0.0052032470703125, 'loss_3': -15.32197093963623, 'loss_4': 2.8359572887420654, 'epoch': 0.82}
{'loss': 0.1295, 'grad_norm': 27.063291549682617, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.1246468797326088, 'loss_2': 0.004825592041015625, 'loss_3': -15.143741607666016, 'loss_4': 2.7100210189819336, 'epoch': 0.83}
{'loss': 0.2044, 'grad_norm': 32.419734954833984, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.19925205409526825, 'loss_2': 0.005100250244140625, 'loss_3': -15.304853439331055, 'loss_4': 2.4861831665039062, 'epoch': 0.83}
{'loss': 0.1106, 'grad_norm': 30.59760093688965, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.09938745945692062, 'loss_2': 0.01120758056640625, 'loss_3': -15.519831657409668, 'loss_4': 2.177790641784668, 'epoch': 0.84}
{'loss': 0.0855, 'grad_norm': 21.13064193725586, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.0733427181839943, 'loss_2': 0.01220703125, 'loss_3': -15.596700668334961, 'loss_4': 3.1170544624328613, 'epoch': 0.84}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:00,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:00,730 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:51<1:36:33,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 15:21:04,532 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-145
[INFO|configuration_utils.py:420] 2025-01-21 15:21:04,533 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-145/config.json                                                                             
{'eval_loss': 0.04106820002198219, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.035295870155096054, 'eval_loss_2': 0.005772329866886139, 'eval_loss_3': -18.183748245239258, 'eval_loss_4': 2.217423677444458, 'epoch': 0.84}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:05,007 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-145/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:05,009 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-145/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:05,009 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-145/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:05,917 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-140] due to args.save_total_limit
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [03:56<1:37:17,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:21:09,567 >>
{'loss': 0.1402, 'grad_norm': 28.5958309173584, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.1325179636478424, 'loss_2': 0.007701873779296875, 'loss_3': -15.40751838684082, 'loss_4': 2.3053061962127686, 'epoch': 0.85}
{'loss': 0.1154, 'grad_norm': 29.152061462402344, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.1121663898229599, 'loss_2': 0.003276824951171875, 'loss_3': -15.20664119720459, 'loss_4': 2.6939942836761475, 'epoch': 0.85}
{'loss': 0.0679, 'grad_norm': 15.10454273223877, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.06719329208135605, 'loss_2': 0.0007224082946777344, 'loss_3': -15.531246185302734, 'loss_4': 2.371163845062256, 'epoch': 0.86}
{'loss': 0.0681, 'grad_norm': 15.408354759216309, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.06431607902050018, 'loss_2': 0.0037670135498046875, 'loss_3': -15.478614807128906, 'loss_4': 2.4536499977111816, 'epoch': 0.87}
{'loss': 0.0846, 'grad_norm': 15.502838134765625, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.0840437039732933, 'loss_2': 0.0005674362182617188, 'loss_3': -15.154751777648926, 'loss_4': 2.1487162113189697, 'epoch': 0.87}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:09,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:09,568 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:03<1:28:16,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:21:16,907 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04221523553133011, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.404, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0376005619764328, 'eval_loss_2': 0.004614673554897308, 'eval_loss_3': -18.067161560058594, 'eval_loss_4': 1.8806241750717163, 'epoch': 0.87}
{'loss': 0.0758, 'grad_norm': 21.08661460876465, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.07437877357006073, 'loss_2': 0.0014400482177734375, 'loss_3': -15.379264831542969, 'loss_4': 1.8754633665084839, 'epoch': 0.88}
{'loss': 0.1085, 'grad_norm': 23.79180335998535, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.1071246787905693, 'loss_2': 0.001392364501953125, 'loss_3': -15.254423141479492, 'loss_4': 2.006014823913574, 'epoch': 0.88}
{'loss': 0.2239, 'grad_norm': 41.677982330322266, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.21031922101974487, 'loss_2': 0.0135650634765625, 'loss_3': -15.089441299438477, 'loss_4': 1.4430124759674072, 'epoch': 0.89}
{'loss': 0.1267, 'grad_norm': 38.612430572509766, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.12201116979122162, 'loss_2': 0.004669189453125, 'loss_3': -15.19929027557373, 'loss_4': 1.8157105445861816, 'epoch': 0.9}
{'loss': 0.0539, 'grad_norm': 14.65903091430664, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.05258238688111305, 'loss_2': 0.0013523101806640625, 'loss_3': -15.393321990966797, 'loss_4': 1.519740343093872, 'epoch': 0.9}
[INFO|trainer.py:4228] 2025-01-21 15:21:16,907 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:16,907 >>   Batch size = 64
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:07<1:28:16,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:21:20,708 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-155
[INFO|configuration_utils.py:420] 2025-01-21 15:21:20,710 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-155/config.json                                                                             
{'eval_loss': 0.035111717879772186, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02940274029970169, 'eval_loss_2': 0.005708977580070496, 'eval_loss_3': -18.036415100097656, 'eval_loss_4': 1.3974523544311523, 'epoch': 0.9}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:21,202 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-155/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:21,203 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-155/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:21,204 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-155/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:22,104 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-145] due to args.save_total_limit
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:12<1:35:48,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:21:25,748 >>
{'loss': 0.0737, 'grad_norm': 16.539003372192383, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.06847026199102402, 'loss_2': 0.005237579345703125, 'loss_3': -15.469115257263184, 'loss_4': 0.8202048540115356, 'epoch': 0.91}
{'loss': 0.104, 'grad_norm': 23.422765731811523, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.10068739205598831, 'loss_2': 0.00327301025390625, 'loss_3': -15.333013534545898, 'loss_4': 1.6534109115600586, 'epoch': 0.91}
{'loss': 0.1825, 'grad_norm': 31.37375259399414, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.17210589349269867, 'loss_2': 0.01035308837890625, 'loss_3': -15.286097526550293, 'loss_4': 1.5301982164382935, 'epoch': 0.92}
{'loss': 0.1117, 'grad_norm': 26.42183494567871, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.11032281816005707, 'loss_2': 0.0013322830200195312, 'loss_3': -15.246370315551758, 'loss_4': 1.267378807067871, 'epoch': 0.92}
{'loss': 0.0608, 'grad_norm': 12.22885513305664, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.047845564782619476, 'loss_2': 0.01293182373046875, 'loss_3': -15.377094268798828, 'loss_4': 1.5057833194732666, 'epoch': 0.93}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:25,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:25,749 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:19<1:27:56,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:21:33,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03581008315086365, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.03211456537246704, 'eval_loss_2': 0.0036955177783966064, 'eval_loss_3': -18.040388107299805, 'eval_loss_4': 1.3737356662750244, 'epoch': 0.93}
{'loss': 0.1037, 'grad_norm': 19.283035278320312, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.09858568757772446, 'loss_2': 0.00513458251953125, 'loss_3': -15.180519104003906, 'loss_4': 0.8877602219581604, 'epoch': 0.94}
{'loss': 0.05, 'grad_norm': 14.871381759643555, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.046111930161714554, 'loss_2': 0.0039215087890625, 'loss_3': -15.430816650390625, 'loss_4': 1.7726263999938965, 'epoch': 0.94}
{'loss': 0.1112, 'grad_norm': 25.120437622070312, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.1069185733795166, 'loss_2': 0.00423431396484375, 'loss_3': -15.137031555175781, 'loss_4': 1.5447947978973389, 'epoch': 0.95}
{'loss': 0.1038, 'grad_norm': 26.645244598388672, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.08705061674118042, 'loss_2': 0.0167236328125, 'loss_3': -15.29763412475586, 'loss_4': 1.2832143306732178, 'epoch': 0.95}
{'loss': 0.0739, 'grad_norm': 18.312646865844727, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.07225360721349716, 'loss_2': 0.0016918182373046875, 'loss_3': -15.417433738708496, 'loss_4': 0.9819532036781311, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 15:21:33,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:33,088 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:23<1:27:56,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:21:36,894 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-165
[INFO|configuration_utils.py:420] 2025-01-21 15:21:36,896 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-165/config.json                                                                             
{'eval_loss': 0.03338247537612915, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.02924257516860962, 'eval_loss_2': 0.004139900207519531, 'eval_loss_3': -17.99129295349121, 'eval_loss_4': 1.1209741830825806, 'epoch': 0.96}
[INFO|modeling_utils.py:2988] 2025-01-21 15:21:37,403 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-165/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:21:37,404 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-165/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:21:37,404 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-165/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:21:38,292 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-155] due to args.save_total_limit
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:28<1:35:31,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:21:41,935 >>
{'loss': 0.0813, 'grad_norm': 17.724828720092773, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.07188905030488968, 'loss_2': 0.00937652587890625, 'loss_3': -15.32453727722168, 'loss_4': 1.4536352157592773, 'epoch': 0.97}
{'loss': 0.079, 'grad_norm': 18.507749557495117, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.07516208291053772, 'loss_2': 0.0038299560546875, 'loss_3': -15.219223022460938, 'loss_4': 1.549623966217041, 'epoch': 0.97}
{'loss': 0.0592, 'grad_norm': 21.114330291748047, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.05316079407930374, 'loss_2': 0.006015777587890625, 'loss_3': -15.291616439819336, 'loss_4': 1.2576303482055664, 'epoch': 0.98}
{'loss': 0.0932, 'grad_norm': 33.13079833984375, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.09018447250127792, 'loss_2': 0.003017425537109375, 'loss_3': -15.12319278717041, 'loss_4': 0.9402032494544983, 'epoch': 0.98}
{'loss': 0.0797, 'grad_norm': 22.00152587890625, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.07861988991498947, 'loss_2': 0.0011234283447265625, 'loss_3': -15.16418743133545, 'loss_4': 1.1405807733535767, 'epoch': 0.99}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:21:41,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:41,935 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:35<1:25:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:21:48,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03459865599870682, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.837, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.028008583933115005, 'eval_loss_2': 0.006590068340301514, 'eval_loss_3': -17.920753479003906, 'eval_loss_4': 0.9755816459655762, 'epoch': 0.99}
{'loss': 0.0453, 'grad_norm': 14.22995662689209, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.03929365426301956, 'loss_2': 0.00595855712890625, 'loss_3': -15.223594665527344, 'loss_4': 0.908366322517395, 'epoch': 0.99}
{'loss': 0.027, 'grad_norm': 11.967248916625977, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.02423880435526371, 'loss_2': 0.00278472900390625, 'loss_3': -15.244854927062988, 'loss_4': 0.8264497518539429, 'epoch': 1.0}
{'loss': 0.0551, 'grad_norm': 18.572359085083008, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.04923553392291069, 'loss_2': 0.005840301513671875, 'loss_3': -15.13831901550293, 'loss_4': 1.081994652748108, 'epoch': 1.01}
{'loss': 0.0853, 'grad_norm': 19.395645141601562, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.07601796090602875, 'loss_2': 0.00927734375, 'loss_3': -15.30380916595459, 'loss_4': 1.5778725147247314, 'epoch': 1.01}
{'loss': 0.0882, 'grad_norm': 20.10616111755371, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.08297525346279144, 'loss_2': 0.0052337646484375, 'loss_3': -15.200233459472656, 'loss_4': 1.4315747022628784, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 15:21:48,967 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:48,967 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:42<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:21:56,315 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03387823700904846, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.566, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.027973320335149765, 'eval_loss_2': 0.0059049129486083984, 'eval_loss_3': -17.88044548034668, 'eval_loss_4': 1.1972804069519043, 'epoch': 1.02}
{'loss': 0.1612, 'grad_norm': 33.2630729675293, 'learning_rate': 2.9e-05, 'loss_1': 0.14846748113632202, 'loss_2': 0.01270294189453125, 'loss_3': -15.007003784179688, 'loss_4': 1.3912837505340576, 'epoch': 1.02}
{'loss': 0.0639, 'grad_norm': 15.603363990783691, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.05628542974591255, 'loss_2': 0.00759124755859375, 'loss_3': -14.988258361816406, 'loss_4': 1.5171672105789185, 'epoch': 1.03}
{'loss': 0.095, 'grad_norm': 22.74354362487793, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.08376132696866989, 'loss_2': 0.01123046875, 'loss_3': -15.273383140563965, 'loss_4': 1.7956273555755615, 'epoch': 1.03}
{'loss': 0.0765, 'grad_norm': 24.301250457763672, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.0714695006608963, 'loss_2': 0.00507354736328125, 'loss_3': -15.069419860839844, 'loss_4': 1.3530324697494507, 'epoch': 1.04}
{'loss': 0.0605, 'grad_norm': 12.822126388549805, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.05394775792956352, 'loss_2': 0.00653839111328125, 'loss_3': -15.309245109558105, 'loss_4': 1.1701350212097168, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 15:21:56,315 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:21:56,315 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:46<1:26:03,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:22:00,116 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-180
[INFO|configuration_utils.py:420] 2025-01-21 15:22:00,117 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-180/config.json                                                                             
{'eval_loss': 0.03156556189060211, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02354205772280693, 'eval_loss_2': 0.008023500442504883, 'eval_loss_3': -17.984045028686523, 'eval_loss_4': 1.1174507141113281, 'epoch': 1.05}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:00,618 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-180/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:00,620 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-180/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:00,620 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-180/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:01,511 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-165] due to args.save_total_limit
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:51<1:34:57,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:22:05,150 >>
{'loss': 0.0762, 'grad_norm': 21.02566909790039, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.07477456331253052, 'loss_2': 0.0014543533325195312, 'loss_3': -15.10508918762207, 'loss_4': 1.2631549835205078, 'epoch': 1.05}
{'loss': 0.1058, 'grad_norm': 21.478933334350586, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.09945542365312576, 'loss_2': 0.0063934326171875, 'loss_3': -15.38151741027832, 'loss_4': 1.465499758720398, 'epoch': 1.06}
{'loss': 0.1053, 'grad_norm': 22.12270736694336, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.09987489134073257, 'loss_2': 0.00547027587890625, 'loss_3': -15.18116569519043, 'loss_4': 1.666722059249878, 'epoch': 1.06}
{'loss': 0.101, 'grad_norm': 24.48540496826172, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.09334813058376312, 'loss_2': 0.00766754150390625, 'loss_3': -15.145763397216797, 'loss_4': 1.452770709991455, 'epoch': 1.07}
{'loss': 0.0822, 'grad_norm': 22.090045928955078, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.07298918068408966, 'loss_2': 0.00916290283203125, 'loss_3': -15.387849807739258, 'loss_4': 1.9528340101242065, 'epoch': 1.08}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:05,150 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:05,150 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [04:59<1:27:31,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:22:12,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035502590239048004, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.021400131285190582, 'eval_loss_2': 0.014102458953857422, 'eval_loss_3': -18.05514907836914, 'eval_loss_4': 1.2553023099899292, 'epoch': 1.08}
{'loss': 0.1321, 'grad_norm': 28.06270980834961, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.12427743524312973, 'loss_2': 0.0077972412109375, 'loss_3': -15.272764205932617, 'loss_4': 1.2288732528686523, 'epoch': 1.08}
{'loss': 0.0529, 'grad_norm': 10.251729965209961, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.04065876826643944, 'loss_2': 0.01222991943359375, 'loss_3': -15.265331268310547, 'loss_4': 1.5569831132888794, 'epoch': 1.09}
{'loss': 0.1543, 'grad_norm': 33.259864807128906, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.1497504562139511, 'loss_2': 0.00452423095703125, 'loss_3': -15.140691757202148, 'loss_4': 1.6014659404754639, 'epoch': 1.09}
{'loss': 0.0777, 'grad_norm': 17.181140899658203, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.07478058338165283, 'loss_2': 0.0029048919677734375, 'loss_3': -15.109211921691895, 'loss_4': 1.5655986070632935, 'epoch': 1.1}
{'loss': 0.0792, 'grad_norm': 20.059904098510742, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.07388964295387268, 'loss_2': 0.00531005859375, 'loss_3': -15.289023399353027, 'loss_4': 1.8418322801589966, 'epoch': 1.1}
[INFO|trainer.py:4228] 2025-01-21 15:22:12,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:12,497 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [05:02<1:27:31,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 15:22:16,308 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-190
[INFO|configuration_utils.py:420] 2025-01-21 15:22:16,309 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-190/config.json                                                                             
{'eval_loss': 0.02923324517905712, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.022908596321940422, 'eval_loss_2': 0.006324648857116699, 'eval_loss_3': -18.120141983032227, 'eval_loss_4': 1.570284128189087, 'epoch': 1.1}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:16,813 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-190/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:16,815 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-190/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:16,815 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-190/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:17,759 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-180] due to args.save_total_limit
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:08<1:35:29,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:22:21,414 >>
{'loss': 0.0754, 'grad_norm': 20.357561111450195, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.06037725880742073, 'loss_2': 0.01502227783203125, 'loss_3': -15.433324813842773, 'loss_4': 1.9728754758834839, 'epoch': 1.11}
{'loss': 0.1232, 'grad_norm': 38.74586486816406, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.11415724456310272, 'loss_2': 0.009033203125, 'loss_3': -15.496586799621582, 'loss_4': 2.3256101608276367, 'epoch': 1.12}
{'loss': 0.1377, 'grad_norm': 39.78477096557617, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.13028618693351746, 'loss_2': 0.007396697998046875, 'loss_3': -15.53795051574707, 'loss_4': 2.0221359729766846, 'epoch': 1.12}
{'loss': 0.1179, 'grad_norm': 22.510108947753906, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.1001199260354042, 'loss_2': 0.017730712890625, 'loss_3': -15.288759231567383, 'loss_4': 1.6482871770858765, 'epoch': 1.13}
{'loss': 0.1188, 'grad_norm': 29.794219970703125, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.1112726703286171, 'loss_2': 0.007526397705078125, 'loss_3': -15.276799201965332, 'loss_4': 1.5248610973358154, 'epoch': 1.13}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:21,415 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:21,415 >>   Batch size = 64
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:11<1:35:29,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:22:25,216 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-195
[INFO|configuration_utils.py:420] 2025-01-21 15:22:25,217 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-195/config.json                                                                             
{'eval_loss': 0.028426675125956535, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.475, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02523755468428135, 'eval_loss_2': 0.0031891167163848877, 'eval_loss_3': -18.06890869140625, 'eval_loss_4': 1.585799217224121, 'epoch': 1.13}
[INFO|modeling_utils.py:2988] 2025-01-21 15:22:25,718 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-195/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:22:25,719 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-195/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:22:25,719 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-195/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:22:26,601 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-190] due to args.save_total_limit
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:16<1:36:08,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:22:30,240 >>
{'loss': 0.0756, 'grad_norm': 17.58326530456543, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.07395803928375244, 'loss_2': 0.0016918182373046875, 'loss_3': -15.66329288482666, 'loss_4': 1.7101473808288574, 'epoch': 1.14}
{'loss': 0.1301, 'grad_norm': 28.972929000854492, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.12561742961406708, 'loss_2': 0.004486083984375, 'loss_3': -15.412607192993164, 'loss_4': 1.3465006351470947, 'epoch': 1.15}
{'loss': 0.135, 'grad_norm': 29.284629821777344, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.13186953961849213, 'loss_2': 0.003143310546875, 'loss_3': -15.480268478393555, 'loss_4': 1.5418431758880615, 'epoch': 1.15}
{'loss': 0.0605, 'grad_norm': 17.31622886657715, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.04599115997552872, 'loss_2': 0.01446533203125, 'loss_3': -15.287138938903809, 'loss_4': 1.763803243637085, 'epoch': 1.16}
{'loss': 0.0797, 'grad_norm': 19.802478790283203, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.06633545458316803, 'loss_2': 0.013336181640625, 'loss_3': -15.22723388671875, 'loss_4': 1.7130365371704102, 'epoch': 1.16}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:22:30,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:30,240 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:24<1:27:25,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:22:37,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04036732763051987, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.82, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.026484690606594086, 'eval_loss_2': 0.013882637023925781, 'eval_loss_3': -18.017580032348633, 'eval_loss_4': 1.537893533706665, 'epoch': 1.16}
{'loss': 0.0497, 'grad_norm': 16.572710037231445, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.04498011991381645, 'loss_2': 0.00469970703125, 'loss_3': -15.339059829711914, 'loss_4': 1.383875846862793, 'epoch': 1.17}
{'loss': 0.0826, 'grad_norm': 18.045536041259766, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.07092522829771042, 'loss_2': 0.0116424560546875, 'loss_3': -15.501993179321289, 'loss_4': 1.8857672214508057, 'epoch': 1.17}
{'loss': 0.0382, 'grad_norm': 10.933131217956543, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.03290165588259697, 'loss_2': 0.0053253173828125, 'loss_3': -15.497323036193848, 'loss_4': 1.704721450805664, 'epoch': 1.18}
{'loss': 0.1285, 'grad_norm': 33.87314224243164, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.12781943380832672, 'loss_2': 0.000640869140625, 'loss_3': -15.414907455444336, 'loss_4': 1.600165605545044, 'epoch': 1.19}
{'loss': 0.0667, 'grad_norm': 20.926517486572266, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.05712360143661499, 'loss_2': 0.00958251953125, 'loss_3': -15.141056060791016, 'loss_4': 1.680491328239441, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 15:22:37,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:37,589 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:31<1:25:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:44,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.041172824800014496, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.544, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.036001287400722504, 'eval_loss_2': 0.005171537399291992, 'eval_loss_3': -17.957561492919922, 'eval_loss_4': 1.776759386062622, 'epoch': 1.19}
{'loss': 0.0865, 'grad_norm': 23.399003982543945, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.08385463804006577, 'loss_2': 0.0026397705078125, 'loss_3': -15.192191123962402, 'loss_4': 1.5728023052215576, 'epoch': 1.2}
{'loss': 0.1691, 'grad_norm': 35.36152648925781, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.15227660536766052, 'loss_2': 0.016815185546875, 'loss_3': -15.252120018005371, 'loss_4': 2.188261032104492, 'epoch': 1.2}
{'loss': 0.1017, 'grad_norm': 25.81192970275879, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.0886198952794075, 'loss_2': 0.013031005859375, 'loss_3': -15.22956657409668, 'loss_4': 1.8001114130020142, 'epoch': 1.21}
{'loss': 0.111, 'grad_norm': 23.22102165222168, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.10363560914993286, 'loss_2': 0.00740814208984375, 'loss_3': -15.127033233642578, 'loss_4': 1.927865982055664, 'epoch': 1.22}
{'loss': 0.1264, 'grad_norm': 25.15595245361328, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.11239257454872131, 'loss_2': 0.0139617919921875, 'loss_3': -15.113421440124512, 'loss_4': 1.936851143836975, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 15:22:44,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:44,935 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:38<1:25:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:52,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07202889025211334, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.287, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.06677275896072388, 'eval_loss_2': 0.005256146192550659, 'eval_loss_3': -17.870328903198242, 'eval_loss_4': 2.1567721366882324, 'epoch': 1.22}
{'loss': 0.1037, 'grad_norm': 20.983320236206055, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.09135109931230545, 'loss_2': 0.0123291015625, 'loss_3': -15.16840934753418, 'loss_4': 2.0901737213134766, 'epoch': 1.23}
{'loss': 0.1419, 'grad_norm': 26.107019424438477, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.13847661018371582, 'loss_2': 0.003444671630859375, 'loss_3': -15.367941856384277, 'loss_4': 2.4090964794158936, 'epoch': 1.23}
{'loss': 0.0473, 'grad_norm': 12.224523544311523, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.040187980979681015, 'loss_2': 0.00707244873046875, 'loss_3': -15.313232421875, 'loss_4': 1.8459464311599731, 'epoch': 1.24}
{'loss': 0.1117, 'grad_norm': 22.817934036254883, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.10766077786684036, 'loss_2': 0.0040435791015625, 'loss_3': -15.363521575927734, 'loss_4': 1.7628073692321777, 'epoch': 1.24}
{'loss': 0.0342, 'grad_norm': 9.635233879089355, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.03114585392177105, 'loss_2': 0.00301361083984375, 'loss_3': -15.256781578063965, 'loss_4': 2.0131471157073975, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 15:22:52,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:52,288 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:46<1:25:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:22:59,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04054814577102661, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.532, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.03689189627766609, 'eval_loss_2': 0.003656245768070221, 'eval_loss_3': -17.96524429321289, 'eval_loss_4': 1.964880347251892, 'epoch': 1.25}
{'loss': 0.0767, 'grad_norm': 22.8502197265625, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.07494443655014038, 'loss_2': 0.001735687255859375, 'loss_3': -15.281208038330078, 'loss_4': 1.4225738048553467, 'epoch': 1.26}
{'loss': 0.073, 'grad_norm': 22.595888137817383, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.06915072351694107, 'loss_2': 0.003879547119140625, 'loss_3': -15.403481483459473, 'loss_4': 2.221475601196289, 'epoch': 1.26}
{'loss': 0.0673, 'grad_norm': 27.97150421142578, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.06535346806049347, 'loss_2': 0.001979827880859375, 'loss_3': -15.20417308807373, 'loss_4': 2.0903260707855225, 'epoch': 1.27}
{'loss': 0.0359, 'grad_norm': 10.723873138427734, 'learning_rate': 2.875e-05, 'loss_1': 0.02876177616417408, 'loss_2': 0.0071258544921875, 'loss_3': -15.635360717773438, 'loss_4': 2.7144508361816406, 'epoch': 1.27}
{'loss': 0.0406, 'grad_norm': 11.766890525817871, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.03619861602783203, 'loss_2': 0.004360198974609375, 'loss_3': -15.303730964660645, 'loss_4': 2.325507879257202, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 15:22:59,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:22:59,653 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:50<1:25:37,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:23:03,454 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-220
[INFO|configuration_utils.py:420] 2025-01-21 15:23:03,455 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-220/config.json                                                                             
{'eval_loss': 0.026822518557310104, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.454, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.024036772549152374, 'eval_loss_2': 0.0027857422828674316, 'eval_loss_3': -18.09259796142578, 'eval_loss_4': 2.3235387802124023, 'epoch': 1.28}
[INFO|modeling_utils.py:2988] 2025-01-21 15:23:03,938 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-220/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:23:03,939 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-220/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:23:03,940 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-220/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:23:04,899 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-195] due to args.save_total_limit
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:55<1:34:40,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:23:08,544 >>
{'loss': 0.0693, 'grad_norm': 16.62236785888672, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.062100835144519806, 'loss_2': 0.00717926025390625, 'loss_3': -15.461809158325195, 'loss_4': 2.2098522186279297, 'epoch': 1.28}
{'loss': 0.0574, 'grad_norm': 18.316394805908203, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.053311675786972046, 'loss_2': 0.004047393798828125, 'loss_3': -15.287029266357422, 'loss_4': 2.6025185585021973, 'epoch': 1.29}
{'loss': 0.073, 'grad_norm': 20.24849510192871, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.069667287170887, 'loss_2': 0.0033283233642578125, 'loss_3': -15.407119750976562, 'loss_4': 3.107138156890869, 'epoch': 1.3}
{'loss': 0.0422, 'grad_norm': 10.359992027282715, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.037481505423784256, 'loss_2': 0.004726409912109375, 'loss_3': -15.333233833312988, 'loss_4': 2.801365852355957, 'epoch': 1.3}
{'loss': 0.1186, 'grad_norm': 27.794546127319336, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.11550802737474442, 'loss_2': 0.003124237060546875, 'loss_3': -15.568771362304688, 'loss_4': 3.1933400630950928, 'epoch': 1.31}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:23:08,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:08,544 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [06:02<1:27:13,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:23:15,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028715159744024277, 'eval_runtime': 3.8207, 'eval_samples_per_second': 268.012, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.025504084303975105, 'eval_loss_2': 0.003211073577404022, 'eval_loss_3': -18.15545654296875, 'eval_loss_4': 2.490596294403076, 'epoch': 1.31}
{'loss': 0.0247, 'grad_norm': 7.923095226287842, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.02387331984937191, 'loss_2': 0.0007848739624023438, 'loss_3': -15.443930625915527, 'loss_4': 2.887183666229248, 'epoch': 1.31}
{'loss': 0.1547, 'grad_norm': 32.40608596801758, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.14659807085990906, 'loss_2': 0.008148193359375, 'loss_3': -15.570117950439453, 'loss_4': 3.7348344326019287, 'epoch': 1.32}
{'loss': 0.0504, 'grad_norm': 13.724766731262207, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.04840680956840515, 'loss_2': 0.0019483566284179688, 'loss_3': -15.463359832763672, 'loss_4': 2.7626237869262695, 'epoch': 1.33}
{'loss': 0.0754, 'grad_norm': 21.44887351989746, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.07433850318193436, 'loss_2': 0.00101470947265625, 'loss_3': -15.46117877960205, 'loss_4': 3.113891363143921, 'epoch': 1.33}
{'loss': 0.1244, 'grad_norm': 31.00007438659668, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.12221173942089081, 'loss_2': 0.002170562744140625, 'loss_3': -15.372634887695312, 'loss_4': 1.9557912349700928, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 15:23:15,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:15,934 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:09<1:25:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:23,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02808939293026924, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.8, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.024611879140138626, 'eval_loss_2': 0.0034775137901306152, 'eval_loss_3': -18.107383728027344, 'eval_loss_4': 1.619138479232788, 'epoch': 1.34}
{'loss': 0.1002, 'grad_norm': 21.574785232543945, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.09680215269327164, 'loss_2': 0.00336456298828125, 'loss_3': -15.25031566619873, 'loss_4': 1.9590814113616943, 'epoch': 1.34}
{'loss': 0.2549, 'grad_norm': 34.68363571166992, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.2535218894481659, 'loss_2': 0.001338958740234375, 'loss_3': -15.180562019348145, 'loss_4': 1.1558489799499512, 'epoch': 1.35}
{'loss': 0.1845, 'grad_norm': 43.343894958496094, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.17721812427043915, 'loss_2': 0.007305145263671875, 'loss_3': -15.377704620361328, 'loss_4': 1.4750354290008545, 'epoch': 1.35}
{'loss': 0.068, 'grad_norm': 18.158823013305664, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.059217337518930435, 'loss_2': 0.00881195068359375, 'loss_3': -15.589126586914062, 'loss_4': 1.2177114486694336, 'epoch': 1.36}
{'loss': 0.0556, 'grad_norm': 11.071349143981934, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.04629042372107506, 'loss_2': 0.0093231201171875, 'loss_3': -15.373455047607422, 'loss_4': 0.6098285913467407, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 15:23:23,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:23,298 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:17<1:25:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:30,664 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03493800759315491, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.502, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.02774152159690857, 'eval_loss_2': 0.007196485996246338, 'eval_loss_3': -18.0225772857666, 'eval_loss_4': 0.8353588581085205, 'epoch': 1.37}
{'loss': 0.1088, 'grad_norm': 30.892536163330078, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.09790605306625366, 'loss_2': 0.01092529296875, 'loss_3': -15.323596000671387, 'loss_4': 0.7511097192764282, 'epoch': 1.37}
{'loss': 0.0494, 'grad_norm': 12.009182929992676, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.04440264776349068, 'loss_2': 0.0049896240234375, 'loss_3': -15.429158210754395, 'loss_4': 0.855518639087677, 'epoch': 1.38}
{'loss': 0.0329, 'grad_norm': 10.153523445129395, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.03220228850841522, 'loss_2': 0.0006856918334960938, 'loss_3': -15.612556457519531, 'loss_4': 0.8020138144493103, 'epoch': 1.38}
{'loss': 0.0638, 'grad_norm': 20.31584930419922, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.06361843645572662, 'loss_2': 0.0001926422119140625, 'loss_3': -15.352418899536133, 'loss_4': 0.7068000435829163, 'epoch': 1.39}
{'loss': 0.0729, 'grad_norm': 29.113889694213867, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.07175964117050171, 'loss_2': 0.0010986328125, 'loss_3': -15.447253227233887, 'loss_4': 0.9400526285171509, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 15:23:30,664 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:30,664 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:24<1:25:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:38,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04392416030168533, 'eval_runtime': 3.84, 'eval_samples_per_second': 266.665, 'eval_steps_per_second': 4.167, 'eval_loss_1': 0.03871730715036392, 'eval_loss_2': 0.005206853151321411, 'eval_loss_3': -17.919124603271484, 'eval_loss_4': 0.9396345615386963, 'epoch': 1.4}
{'loss': 0.1089, 'grad_norm': 34.388427734375, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.1005851998925209, 'loss_2': 0.00827789306640625, 'loss_3': -15.396812438964844, 'loss_4': 1.6194093227386475, 'epoch': 1.4}
{'loss': 0.0492, 'grad_norm': 22.354990005493164, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.04721633344888687, 'loss_2': 0.001972198486328125, 'loss_3': -15.500490188598633, 'loss_4': 0.3690198063850403, 'epoch': 1.41}
{'loss': 0.0693, 'grad_norm': 22.90865707397461, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.0687340497970581, 'loss_2': 0.000537872314453125, 'loss_3': -15.360468864440918, 'loss_4': 1.4355945587158203, 'epoch': 1.41}
{'loss': 0.0358, 'grad_norm': 11.944272994995117, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.03486504405736923, 'loss_2': 0.0009450912475585938, 'loss_3': -15.39659595489502, 'loss_4': 0.844261884689331, 'epoch': 1.42}
{'loss': 0.0491, 'grad_norm': 16.430130004882812, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.04420248419046402, 'loss_2': 0.00493621826171875, 'loss_3': -15.594416618347168, 'loss_4': 0.8780343532562256, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 15:23:38,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:38,058 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:32<1:25:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:45,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030043024569749832, 'eval_runtime': 3.8239, 'eval_samples_per_second': 267.789, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.02596598118543625, 'eval_loss_2': 0.004077047109603882, 'eval_loss_3': -18.015369415283203, 'eval_loss_4': 1.171802282333374, 'epoch': 1.42}
{'loss': 0.1213, 'grad_norm': 33.39618682861328, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.11883183568716049, 'loss_2': 0.0024700164794921875, 'loss_3': -15.385238647460938, 'loss_4': 1.6764557361602783, 'epoch': 1.43}
{'loss': 0.1241, 'grad_norm': 27.799747467041016, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.11603434383869171, 'loss_2': 0.00807952880859375, 'loss_3': -15.228729248046875, 'loss_4': 1.7045096158981323, 'epoch': 1.44}
{'loss': 0.1606, 'grad_norm': 38.53395080566406, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.160087451338768, 'loss_2': 0.00047779083251953125, 'loss_3': -15.155531883239746, 'loss_4': 1.8765177726745605, 'epoch': 1.44}
{'loss': 0.069, 'grad_norm': 22.64390754699707, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.060624826699495316, 'loss_2': 0.00836181640625, 'loss_3': -15.419584274291992, 'loss_4': 1.7753061056137085, 'epoch': 1.45}
{'loss': 0.0657, 'grad_norm': 20.195533752441406, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.056642793118953705, 'loss_2': 0.0090789794921875, 'loss_3': -15.705523490905762, 'loss_4': 2.196434736251831, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 15:23:45,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:45,433 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:39<1:25:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:23:52,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028715038672089577, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.547, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.025084080174565315, 'eval_loss_2': 0.0036309584975242615, 'eval_loss_3': -18.064599990844727, 'eval_loss_4': 2.0949792861938477, 'epoch': 1.45}
{'loss': 0.0518, 'grad_norm': 18.249526977539062, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.04694320261478424, 'loss_2': 0.0048828125, 'loss_3': -15.497281074523926, 'loss_4': 2.482389211654663, 'epoch': 1.46}
{'loss': 0.0347, 'grad_norm': 8.396368980407715, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.032875195145606995, 'loss_2': 0.0018701553344726562, 'loss_3': -15.575672149658203, 'loss_4': 2.630046844482422, 'epoch': 1.47}
{'loss': 0.0765, 'grad_norm': 22.698911666870117, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.07312647253274918, 'loss_2': 0.003330230712890625, 'loss_3': -15.553451538085938, 'loss_4': 2.3482260704040527, 'epoch': 1.47}
{'loss': 0.1896, 'grad_norm': 39.6439323425293, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.17969705164432526, 'loss_2': 0.00994873046875, 'loss_3': -15.426227569580078, 'loss_4': 2.4633350372314453, 'epoch': 1.48}
{'loss': 0.0607, 'grad_norm': 13.489821434020996, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.05011020973324776, 'loss_2': 0.0105743408203125, 'loss_3': -15.565555572509766, 'loss_4': 2.480120897293091, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 15:23:52,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:23:52,804 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:46<1:25:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:00,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04177311062812805, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.304, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.025716569274663925, 'eval_loss_2': 0.016056537628173828, 'eval_loss_3': -18.110576629638672, 'eval_loss_4': 2.439812660217285, 'epoch': 1.48}
{'loss': 0.0725, 'grad_norm': 17.68484878540039, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.059680964797735214, 'loss_2': 0.012847900390625, 'loss_3': -15.702548027038574, 'loss_4': 2.6872642040252686, 'epoch': 1.49}
{'loss': 0.0533, 'grad_norm': 12.544157028198242, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.04104642570018768, 'loss_2': 0.0122528076171875, 'loss_3': -15.552776336669922, 'loss_4': 2.983585834503174, 'epoch': 1.49}
{'loss': 0.0806, 'grad_norm': 21.578439712524414, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.0776752158999443, 'loss_2': 0.002971649169921875, 'loss_3': -15.702600479125977, 'loss_4': 3.1712915897369385, 'epoch': 1.5}
{'loss': 0.1107, 'grad_norm': 21.860322952270508, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.0956483855843544, 'loss_2': 0.01508331298828125, 'loss_3': -15.52564525604248, 'loss_4': 3.0863265991210938, 'epoch': 1.51}
{'loss': 0.1345, 'grad_norm': 30.590354919433594, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.1306886374950409, 'loss_2': 0.003849029541015625, 'loss_3': -15.487878799438477, 'loss_4': 2.7434544563293457, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 15:24:00,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:00,179 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:54<1:24:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:07,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035418421030044556, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0311574824154377, 'eval_loss_2': 0.004260938614606857, 'eval_loss_3': -18.10097312927246, 'eval_loss_4': 2.6878161430358887, 'epoch': 1.51}
{'loss': 0.0839, 'grad_norm': 21.94259262084961, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.08208764344453812, 'loss_2': 0.001827239990234375, 'loss_3': -15.815221786499023, 'loss_4': 3.473870277404785, 'epoch': 1.52}
{'loss': 0.0623, 'grad_norm': 13.841148376464844, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.05812232941389084, 'loss_2': 0.0041351318359375, 'loss_3': -15.721427917480469, 'loss_4': 2.6484551429748535, 'epoch': 1.52}
{'loss': 0.185, 'grad_norm': 38.35365295410156, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.18454651534557343, 'loss_2': 0.00046634674072265625, 'loss_3': -15.402534484863281, 'loss_4': 3.1556432247161865, 'epoch': 1.53}
{'loss': 0.1263, 'grad_norm': 32.42931365966797, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.12205643206834793, 'loss_2': 0.00423431396484375, 'loss_3': -15.55238151550293, 'loss_4': 2.9826769828796387, 'epoch': 1.53}
{'loss': 0.0703, 'grad_norm': 16.223737716674805, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.06932057440280914, 'loss_2': 0.0010213851928710938, 'loss_3': -15.465726852416992, 'loss_4': 2.4945602416992188, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 15:24:07,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:07,542 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [07:01<1:24:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:14,902 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0320722721517086, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.748, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.027937140315771103, 'eval_loss_2': 0.0041351318359375, 'eval_loss_3': -18.098159790039062, 'eval_loss_4': 2.226022720336914, 'epoch': 1.54}
{'loss': 0.0939, 'grad_norm': 23.476350784301758, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.08862371742725372, 'loss_2': 0.00530242919921875, 'loss_3': -15.607638359069824, 'loss_4': 2.7980897426605225, 'epoch': 1.55}
{'loss': 0.1366, 'grad_norm': 29.43143653869629, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.13583584129810333, 'loss_2': 0.00080108642578125, 'loss_3': -15.201030731201172, 'loss_4': 2.306169033050537, 'epoch': 1.55}
{'loss': 0.0534, 'grad_norm': 15.442641258239746, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.05183975398540497, 'loss_2': 0.001575469970703125, 'loss_3': -15.534324645996094, 'loss_4': 1.8840370178222656, 'epoch': 1.56}
{'loss': 0.0903, 'grad_norm': 30.627613067626953, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.08533748984336853, 'loss_2': 0.004970550537109375, 'loss_3': -15.481460571289062, 'loss_4': 2.100379705429077, 'epoch': 1.56}
{'loss': 0.0656, 'grad_norm': 21.85414695739746, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.06295089423656464, 'loss_2': 0.00266265869140625, 'loss_3': -15.551471710205078, 'loss_4': 1.667988657951355, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 15:24:14,902 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:14,902 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [07:05<1:24:49,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:24:18,722 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-270
[INFO|configuration_utils.py:420] 2025-01-21 15:24:18,723 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-270/config.json                                                                             
{'eval_loss': 0.025784257799386978, 'eval_runtime': 3.8188, 'eval_samples_per_second': 268.15, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.01960015669465065, 'eval_loss_2': 0.006184101104736328, 'eval_loss_3': -18.09372329711914, 'eval_loss_4': 1.2548261880874634, 'epoch': 1.57}
[INFO|modeling_utils.py:2988] 2025-01-21 15:24:19,219 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-270/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:24:19,220 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-270/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:24:19,220 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-270/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:24:20,148 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-220] due to args.save_total_limit
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:10<1:33:27,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:24:23,774 >>
{'loss': 0.0494, 'grad_norm': 18.007980346679688, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.04562089219689369, 'loss_2': 0.0037555694580078125, 'loss_3': -15.569381713867188, 'loss_4': 1.5097488164901733, 'epoch': 1.58}
{'loss': 0.0733, 'grad_norm': 22.566064834594727, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.06676961481571198, 'loss_2': 0.006488800048828125, 'loss_3': -15.547456741333008, 'loss_4': 1.1307531595230103, 'epoch': 1.58}
{'loss': 0.0723, 'grad_norm': 18.538286209106445, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.06879688799381256, 'loss_2': 0.003509521484375, 'loss_3': -15.685327529907227, 'loss_4': 1.740248441696167, 'epoch': 1.59}
{'loss': 0.0659, 'grad_norm': 16.883901596069336, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.06453641504049301, 'loss_2': 0.0013360977172851562, 'loss_3': -15.793512344360352, 'loss_4': 1.2309620380401611, 'epoch': 1.59}
{'loss': 0.1464, 'grad_norm': 37.332359313964844, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.14139984548091888, 'loss_2': 0.00501251220703125, 'loss_3': -15.222515106201172, 'loss_4': 1.017549991607666, 'epoch': 1.6}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:24:23,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:23,774 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:14<1:33:27,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:24:27,578 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-275
[INFO|configuration_utils.py:420] 2025-01-21 15:24:27,579 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-275/config.json                                                                             
{'eval_loss': 0.024166682735085487, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.020654479041695595, 'eval_loss_2': 0.0035122036933898926, 'eval_loss_3': -18.08584213256836, 'eval_loss_4': 0.7970578074455261, 'epoch': 1.6}
[INFO|modeling_utils.py:2988] 2025-01-21 15:24:28,046 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-275/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:24:28,047 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-275/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:24:28,048 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-275/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:24:28,931 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-270] due to args.save_total_limit
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:19<1:34:36,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:24:32,589 >>
{'loss': 0.0919, 'grad_norm': 21.389368057250977, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.08497599512338638, 'loss_2': 0.0069427490234375, 'loss_3': -15.55048942565918, 'loss_4': 1.3323009014129639, 'epoch': 1.6}
{'loss': 0.0639, 'grad_norm': 15.314839363098145, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.06228064000606537, 'loss_2': 0.00160980224609375, 'loss_3': -15.638938903808594, 'loss_4': 1.634861707687378, 'epoch': 1.61}
{'loss': 0.0652, 'grad_norm': 17.23995590209961, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.06279976665973663, 'loss_2': 0.002437591552734375, 'loss_3': -15.471759796142578, 'loss_4': 1.6474273204803467, 'epoch': 1.62}
{'loss': 0.163, 'grad_norm': 32.23604965209961, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.154380664229393, 'loss_2': 0.0086669921875, 'loss_3': -15.583054542541504, 'loss_4': 1.788475513458252, 'epoch': 1.62}
{'loss': 0.0881, 'grad_norm': 18.5527400970459, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.08410678058862686, 'loss_2': 0.004009246826171875, 'loss_3': -15.650680541992188, 'loss_4': 1.0848629474639893, 'epoch': 1.63}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:24:32,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:32,589 >>   Batch size = 64
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:26<1:26:06,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:24:39,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029209770262241364, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.711, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.024518683552742004, 'eval_loss_2': 0.004691086709499359, 'eval_loss_3': -18.051395416259766, 'eval_loss_4': 1.19047212600708, 'epoch': 1.63}
{'loss': 0.0576, 'grad_norm': 13.766077041625977, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.04986567795276642, 'loss_2': 0.00769805908203125, 'loss_3': -15.637275695800781, 'loss_4': 1.3066807985305786, 'epoch': 1.63}
{'loss': 0.0607, 'grad_norm': 16.614255905151367, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.05426901578903198, 'loss_2': 0.00647735595703125, 'loss_3': -15.397985458374023, 'loss_4': 1.1728224754333496, 'epoch': 1.64}
{'loss': 0.1601, 'grad_norm': 33.24747085571289, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.1574510782957077, 'loss_2': 0.00267791748046875, 'loss_3': -15.377307891845703, 'loss_4': 1.0813416242599487, 'epoch': 1.65}
{'loss': 0.0678, 'grad_norm': 17.898847579956055, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.06622263044118881, 'loss_2': 0.0015735626220703125, 'loss_3': -15.624992370605469, 'loss_4': 1.6882922649383545, 'epoch': 1.65}
{'loss': 0.0937, 'grad_norm': 25.0457820892334, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.08636052161455154, 'loss_2': 0.00733184814453125, 'loss_3': -15.300832748413086, 'loss_4': 2.0027952194213867, 'epoch': 1.66}
[INFO|trainer.py:4228] 2025-01-21 15:24:39,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:39,944 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:34<1:25:30,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:24:47,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02894001081585884, 'eval_runtime': 3.9777, 'eval_samples_per_second': 257.437, 'eval_steps_per_second': 4.022, 'eval_loss_1': 0.019198764115571976, 'eval_loss_2': 0.009741246700286865, 'eval_loss_3': -18.117582321166992, 'eval_loss_4': 1.2135480642318726, 'epoch': 1.66}
{'loss': 0.0529, 'grad_norm': 10.593620300292969, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.04108772426843643, 'loss_2': 0.0118408203125, 'loss_3': -15.760919570922852, 'loss_4': 1.7299202680587769, 'epoch': 1.66}
{'loss': 0.0566, 'grad_norm': 13.184558868408203, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.045416075736284256, 'loss_2': 0.01123046875, 'loss_3': -15.569746017456055, 'loss_4': 1.2380216121673584, 'epoch': 1.67}
{'loss': 0.0862, 'grad_norm': 21.88494300842285, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.07507844269275665, 'loss_2': 0.011077880859375, 'loss_3': -15.3706693649292, 'loss_4': 1.6562585830688477, 'epoch': 1.67}
{'loss': 0.0667, 'grad_norm': 17.529010772705078, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.059781789779663086, 'loss_2': 0.006916046142578125, 'loss_3': -15.567811012268066, 'loss_4': 2.0280404090881348, 'epoch': 1.68}
{'loss': 0.0673, 'grad_norm': 14.956953048706055, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.06520511955022812, 'loss_2': 0.002105712890625, 'loss_3': -15.558226585388184, 'loss_4': 1.5759930610656738, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 15:24:47,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:47,462 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:41<1:24:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:24:54,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02655893750488758, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.022306203842163086, 'eval_loss_2': 0.004252731800079346, 'eval_loss_3': -18.159011840820312, 'eval_loss_4': 1.4557738304138184, 'epoch': 1.69}
{'loss': 0.118, 'grad_norm': 24.61761474609375, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.11698251217603683, 'loss_2': 0.0010423660278320312, 'loss_3': -15.65359115600586, 'loss_4': 2.1906118392944336, 'epoch': 1.69}
{'loss': 0.058, 'grad_norm': 21.241233825683594, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.057458747178316116, 'loss_2': 0.0005893707275390625, 'loss_3': -15.635830879211426, 'loss_4': 1.8286687135696411, 'epoch': 1.7}
{'loss': 0.0798, 'grad_norm': 16.335844039916992, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.07917878031730652, 'loss_2': 0.0006537437438964844, 'loss_3': -15.517847061157227, 'loss_4': 1.251530408859253, 'epoch': 1.7}
{'loss': 0.138, 'grad_norm': 29.19179344177246, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.13490116596221924, 'loss_2': 0.0031375885009765625, 'loss_3': -15.908418655395508, 'loss_4': 2.335461139678955, 'epoch': 1.71}
{'loss': 0.1162, 'grad_norm': 30.231678009033203, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.11035863310098648, 'loss_2': 0.005863189697265625, 'loss_3': -15.733866691589355, 'loss_4': 2.5635786056518555, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 15:24:54,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:24:54,811 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:48<1:24:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:02,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02892114222049713, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.018, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.026047274470329285, 'eval_loss_2': 0.0028738677501678467, 'eval_loss_3': -18.18877410888672, 'eval_loss_4': 2.0684239864349365, 'epoch': 1.72}
{'loss': 0.2179, 'grad_norm': 27.770828247070312, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.21741534769535065, 'loss_2': 0.000499725341796875, 'loss_3': -15.186226844787598, 'loss_4': 2.7128329277038574, 'epoch': 1.72}
{'loss': 0.1132, 'grad_norm': 25.22490119934082, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.11151684820652008, 'loss_2': 0.0016412734985351562, 'loss_3': -15.548182487487793, 'loss_4': 2.4153456687927246, 'epoch': 1.73}
{'loss': 0.0608, 'grad_norm': 11.175209045410156, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.04905933141708374, 'loss_2': 0.01175689697265625, 'loss_3': -15.82151985168457, 'loss_4': 3.0835046768188477, 'epoch': 1.73}
{'loss': 0.0713, 'grad_norm': 15.996054649353027, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.06733313202857971, 'loss_2': 0.0039825439453125, 'loss_3': -15.793375015258789, 'loss_4': 3.3282432556152344, 'epoch': 1.74}
{'loss': 0.0779, 'grad_norm': 25.804763793945312, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.07384877651929855, 'loss_2': 0.00408935546875, 'loss_3': -15.544490814208984, 'loss_4': 2.2944295406341553, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 15:25:02,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:02,168 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:56<1:23:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:09,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027089763432741165, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.816, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02136817015707493, 'eval_loss_2': 0.005721591413021088, 'eval_loss_3': -18.239736557006836, 'eval_loss_4': 2.1084702014923096, 'epoch': 1.74}
{'loss': 0.1127, 'grad_norm': 24.21630859375, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.1123872846364975, 'loss_2': 0.00035190582275390625, 'loss_3': -15.770298957824707, 'loss_4': 2.6580028533935547, 'epoch': 1.75}
{'loss': 0.075, 'grad_norm': 17.631826400756836, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.06955741345882416, 'loss_2': 0.005462646484375, 'loss_3': -15.544189453125, 'loss_4': 2.2617852687835693, 'epoch': 1.76}
{'loss': 0.069, 'grad_norm': 15.050278663635254, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.06613855808973312, 'loss_2': 0.00286865234375, 'loss_3': -15.681279182434082, 'loss_4': 2.685476064682007, 'epoch': 1.76}
{'loss': 0.0674, 'grad_norm': 20.77645492553711, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.0564592219889164, 'loss_2': 0.010986328125, 'loss_3': -15.542769432067871, 'loss_4': 1.848717451095581, 'epoch': 1.77}
{'loss': 0.0907, 'grad_norm': 15.713881492614746, 'learning_rate': 2.825e-05, 'loss_1': 0.0877760723233223, 'loss_2': 0.002948760986328125, 'loss_3': -15.607433319091797, 'loss_4': 2.322988510131836, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 15:25:09,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:09,517 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:03<1:24:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:16,875 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02751016616821289, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.46, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0194209236651659, 'eval_loss_2': 0.008089244365692139, 'eval_loss_3': -18.24399757385254, 'eval_loss_4': 1.4893985986709595, 'epoch': 1.77}
{'loss': 0.1325, 'grad_norm': 30.70465850830078, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.12057655304670334, 'loss_2': 0.011932373046875, 'loss_3': -15.32613754272461, 'loss_4': 1.7759006023406982, 'epoch': 1.78}
{'loss': 0.0866, 'grad_norm': 31.983936309814453, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.08023946732282639, 'loss_2': 0.006381988525390625, 'loss_3': -15.348142623901367, 'loss_4': 1.542398452758789, 'epoch': 1.78}
{'loss': 0.0837, 'grad_norm': 20.311967849731445, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.07839907705783844, 'loss_2': 0.00533294677734375, 'loss_3': -15.767354965209961, 'loss_4': 1.6975688934326172, 'epoch': 1.79}
{'loss': 0.0546, 'grad_norm': 18.447526931762695, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.053153686225414276, 'loss_2': 0.0014858245849609375, 'loss_3': -15.517297744750977, 'loss_4': 0.9951931238174438, 'epoch': 1.8}
{'loss': 0.068, 'grad_norm': 15.380088806152344, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.0647803395986557, 'loss_2': 0.003192901611328125, 'loss_3': -15.500265121459961, 'loss_4': 0.6952759027481079, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 15:25:16,875 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:16,875 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:07<1:24:03,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:25:20,686 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-310
[INFO|configuration_utils.py:420] 2025-01-21 15:25:20,687 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-310/config.json                                                                             
{'eval_loss': 0.02222423441708088, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.018043862655758858, 'eval_loss_2': 0.0041803717613220215, 'eval_loss_3': -18.20077896118164, 'eval_loss_4': 1.284740686416626, 'epoch': 1.8}
[INFO|modeling_utils.py:2988] 2025-01-21 15:25:21,168 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-310/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:25:21,169 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-310/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:25:21,169 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-310/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:25:22,056 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-275] due to args.save_total_limit
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:12<1:32:28,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:25:25,695 >>
{'loss': 0.0634, 'grad_norm': 17.37717628479004, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.05842840299010277, 'loss_2': 0.0050201416015625, 'loss_3': -15.438610076904297, 'loss_4': 1.7200024127960205, 'epoch': 1.81}
{'loss': 0.0532, 'grad_norm': 13.021806716918945, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.04543716087937355, 'loss_2': 0.0077972412109375, 'loss_3': -15.44067668914795, 'loss_4': 1.4507620334625244, 'epoch': 1.81}
{'loss': 0.0567, 'grad_norm': 12.923081398010254, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.04289336875081062, 'loss_2': 0.0137939453125, 'loss_3': -15.505522727966309, 'loss_4': 1.639214277267456, 'epoch': 1.82}
{'loss': 0.0889, 'grad_norm': 19.207714080810547, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.06605079025030136, 'loss_2': 0.0228424072265625, 'loss_3': -15.600152015686035, 'loss_4': 1.9237775802612305, 'epoch': 1.83}
{'loss': 0.1, 'grad_norm': 24.009984970092773, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.08972158282995224, 'loss_2': 0.01025390625, 'loss_3': -15.425222396850586, 'loss_4': 1.882420301437378, 'epoch': 1.83}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:25:25,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:25,695 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:19<1:25:11,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:25:33,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026547245681285858, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.299, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.019199544563889503, 'eval_loss_2': 0.007347702980041504, 'eval_loss_3': -18.161388397216797, 'eval_loss_4': 1.6879812479019165, 'epoch': 1.83}
{'loss': 0.0871, 'grad_norm': 18.942886352539062, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.0723104402422905, 'loss_2': 0.0147857666015625, 'loss_3': -15.630419731140137, 'loss_4': 2.2566776275634766, 'epoch': 1.84}
{'loss': 0.0752, 'grad_norm': 17.923093795776367, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.06660640984773636, 'loss_2': 0.00858306884765625, 'loss_3': -15.399073600769043, 'loss_4': 1.9186214208602905, 'epoch': 1.84}
{'loss': 0.0917, 'grad_norm': 24.05568504333496, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.0859154760837555, 'loss_2': 0.00574493408203125, 'loss_3': -15.26160717010498, 'loss_4': 1.887132167816162, 'epoch': 1.85}
{'loss': 0.0669, 'grad_norm': 17.182832717895508, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.05673764646053314, 'loss_2': 0.0101318359375, 'loss_3': -15.370200157165527, 'loss_4': 1.9462662935256958, 'epoch': 1.85}
{'loss': 0.1151, 'grad_norm': 29.253955841064453, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.10517558455467224, 'loss_2': 0.009918212890625, 'loss_3': -15.35365104675293, 'loss_4': 2.1258480548858643, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 15:25:33,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:33,043 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:26<1:23:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:40,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03655411675572395, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.18, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.023587245494127274, 'eval_loss_2': 0.01296687126159668, 'eval_loss_3': -18.102428436279297, 'eval_loss_4': 1.782435417175293, 'epoch': 1.86}
{'loss': 0.0566, 'grad_norm': 13.92507266998291, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.04818103834986687, 'loss_2': 0.0084686279296875, 'loss_3': -15.427929878234863, 'loss_4': 1.4930903911590576, 'epoch': 1.87}
{'loss': 0.0679, 'grad_norm': 18.252166748046875, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.05786583945155144, 'loss_2': 0.01000213623046875, 'loss_3': -15.274959564208984, 'loss_4': 1.6817080974578857, 'epoch': 1.87}
{'loss': 0.1474, 'grad_norm': 47.476280212402344, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.1262296885251999, 'loss_2': 0.0211944580078125, 'loss_3': -15.385198593139648, 'loss_4': 1.8517394065856934, 'epoch': 1.88}
{'loss': 0.1621, 'grad_norm': 25.1813907623291, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.1552271991968155, 'loss_2': 0.0069122314453125, 'loss_3': -15.409481048583984, 'loss_4': 2.1376917362213135, 'epoch': 1.88}
{'loss': 0.0715, 'grad_norm': 17.2469482421875, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.06767812371253967, 'loss_2': 0.003818511962890625, 'loss_3': -15.383790969848633, 'loss_4': 1.5381584167480469, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 15:25:40,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:40,395 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:34<1:23:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:25:47,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028789855539798737, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.718, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.024902798235416412, 'eval_loss_2': 0.0038870573043823242, 'eval_loss_3': -18.091468811035156, 'eval_loss_4': 1.4810930490493774, 'epoch': 1.89}
{'loss': 0.1064, 'grad_norm': 25.681434631347656, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.09495717287063599, 'loss_2': 0.0114593505859375, 'loss_3': -15.254146575927734, 'loss_4': 1.7485780715942383, 'epoch': 1.9}
{'loss': 0.0678, 'grad_norm': 18.811464309692383, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.06235142797231674, 'loss_2': 0.0054779052734375, 'loss_3': -15.50288200378418, 'loss_4': 1.6019774675369263, 'epoch': 1.9}
{'loss': 0.077, 'grad_norm': 16.486480712890625, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.06959859281778336, 'loss_2': 0.00738525390625, 'loss_3': -15.640115737915039, 'loss_4': 1.4749267101287842, 'epoch': 1.91}
{'loss': 0.0521, 'grad_norm': 16.5576114654541, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.04270356148481369, 'loss_2': 0.0094451904296875, 'loss_3': -15.373953819274902, 'loss_4': 0.5890907049179077, 'epoch': 1.91}
{'loss': 0.0676, 'grad_norm': 17.10189437866211, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.06300997734069824, 'loss_2': 0.00463104248046875, 'loss_3': -15.322925567626953, 'loss_4': 1.369094729423523, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 15:25:47,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:47,753 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:38<1:23:39,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:25:51,556 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-330
[INFO|configuration_utils.py:420] 2025-01-21 15:25:51,557 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-330/config.json                                                                             
{'eval_loss': 0.022138766944408417, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.353, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01854316145181656, 'eval_loss_2': 0.003595605492591858, 'eval_loss_3': -18.161090850830078, 'eval_loss_4': 0.9253562092781067, 'epoch': 1.92}
[INFO|modeling_utils.py:2988] 2025-01-21 15:25:52,031 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-330/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:25:52,032 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-330/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:25:52,032 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-330/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:25:52,913 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-310] due to args.save_total_limit
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:43<1:31:48,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:25:56,543 >>
{'loss': 0.0531, 'grad_norm': 15.658052444458008, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.04020465910434723, 'loss_2': 0.0128631591796875, 'loss_3': -15.378666877746582, 'loss_4': 0.8892669081687927, 'epoch': 1.92}
{'loss': 0.0493, 'grad_norm': 11.5382080078125, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.03904947265982628, 'loss_2': 0.0102081298828125, 'loss_3': -15.415677070617676, 'loss_4': 1.0034090280532837, 'epoch': 1.93}
{'loss': 0.1082, 'grad_norm': 27.41378402709961, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.09187393635511398, 'loss_2': 0.01629638671875, 'loss_3': -15.252389907836914, 'loss_4': 0.9781856536865234, 'epoch': 1.94}
{'loss': 0.0432, 'grad_norm': 17.30657958984375, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.03589983657002449, 'loss_2': 0.00726318359375, 'loss_3': -15.33677864074707, 'loss_4': 1.3566997051239014, 'epoch': 1.94}
{'loss': 0.0884, 'grad_norm': 25.22867774963379, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.0787883773446083, 'loss_2': 0.0095977783203125, 'loss_3': -15.37537956237793, 'loss_4': 1.6575884819030762, 'epoch': 1.95}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:25:56,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:25:56,543 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:50<1:24:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:26:03,883 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02838655561208725, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.544, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01908191293478012, 'eval_loss_2': 0.009304642677307129, 'eval_loss_3': -18.15782928466797, 'eval_loss_4': 0.9992607831954956, 'epoch': 1.95}
{'loss': 0.0713, 'grad_norm': 18.867473602294922, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.06344734877347946, 'loss_2': 0.0078277587890625, 'loss_3': -15.231130599975586, 'loss_4': 0.8096362948417664, 'epoch': 1.95}
{'loss': 0.0942, 'grad_norm': 22.63072967529297, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.08512068539857864, 'loss_2': 0.0091094970703125, 'loss_3': -15.329416275024414, 'loss_4': 1.3237285614013672, 'epoch': 1.96}
{'loss': 0.0719, 'grad_norm': 31.194250106811523, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.06790145486593246, 'loss_2': 0.00400543212890625, 'loss_3': -15.297820091247559, 'loss_4': 0.995747447013855, 'epoch': 1.97}
{'loss': 0.0598, 'grad_norm': 27.378496170043945, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.05833147093653679, 'loss_2': 0.0014362335205078125, 'loss_3': -15.430193901062012, 'loss_4': 1.394247055053711, 'epoch': 1.97}
{'loss': 0.0441, 'grad_norm': 16.592382431030273, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.044105276465415955, 'loss_2': 3.6597251892089844e-05, 'loss_3': -15.485871315002441, 'loss_4': 1.6598354578018188, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 15:26:03,883 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:03,883 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:54<1:24:42,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 15:26:07,678 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-340
[INFO|configuration_utils.py:420] 2025-01-21 15:26:07,679 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-340/config.json                                                                             
{'eval_loss': 0.02003493160009384, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.896, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.016366785392165184, 'eval_loss_2': 0.0036681443452835083, 'eval_loss_3': -18.12632179260254, 'eval_loss_4': 1.1456778049468994, 'epoch': 1.98}
[INFO|modeling_utils.py:2988] 2025-01-21 15:26:08,164 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-340/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:26:08,165 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-340/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:26:08,166 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-340/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:26:09,089 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-330] due to args.save_total_limit
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:58<1:27:07,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 15:26:12,395 >>
{'loss': 0.0374, 'grad_norm': 7.868138313293457, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.028166361153125763, 'loss_2': 0.00922393798828125, 'loss_3': -15.456600189208984, 'loss_4': 1.251967430114746, 'epoch': 1.98}
{'loss': 0.0484, 'grad_norm': 12.583077430725098, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.046795666217803955, 'loss_2': 0.0016012191772460938, 'loss_3': -15.388229370117188, 'loss_4': 1.402637004852295, 'epoch': 1.99}
{'loss': 0.0675, 'grad_norm': 16.69618797302246, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.06628847867250443, 'loss_2': 0.0011739730834960938, 'loss_3': -15.605278015136719, 'loss_4': 1.5002272129058838, 'epoch': 1.99}
{'loss': 0.0445, 'grad_norm': 23.816587448120117, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.03863736614584923, 'loss_2': 0.005863189697265625, 'loss_3': -15.725778579711914, 'loss_4': 1.3206472396850586, 'epoch': 2.0}
{'loss': 0.0669, 'grad_norm': 17.87384796142578, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.059753064066171646, 'loss_2': 0.00716400146484375, 'loss_3': -15.369550704956055, 'loss_4': 1.2613389492034912, 'epoch': 2.01}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:26:12,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:12,395 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [09:06<1:23:50,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:26:19,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027851980179548264, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.023020735010504723, 'eval_loss_2': 0.00483124703168869, 'eval_loss_3': -18.127931594848633, 'eval_loss_4': 1.0395095348358154, 'epoch': 2.01}
{'loss': 0.0384, 'grad_norm': 11.24012279510498, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.03360874205827713, 'loss_2': 0.0047760009765625, 'loss_3': -15.449438095092773, 'loss_4': 1.1598299741744995, 'epoch': 2.01}
{'loss': 0.0322, 'grad_norm': 8.768342018127441, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.027071597054600716, 'loss_2': 0.0051116943359375, 'loss_3': -15.382109642028809, 'loss_4': 1.0626237392425537, 'epoch': 2.02}
{'loss': 0.0294, 'grad_norm': 10.027573585510254, 'learning_rate': 2.8e-05, 'loss_1': 0.02712860517203808, 'loss_2': 0.002288818359375, 'loss_3': -15.606847763061523, 'loss_4': 0.8467361927032471, 'epoch': 2.02}
{'loss': 0.047, 'grad_norm': 17.55142593383789, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.04350495710968971, 'loss_2': 0.00353240966796875, 'loss_3': -15.527870178222656, 'loss_4': 0.8263223171234131, 'epoch': 2.03}
{'loss': 0.0619, 'grad_norm': 17.99678611755371, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.05321954935789108, 'loss_2': 0.0086669921875, 'loss_3': -15.82186508178711, 'loss_4': 1.5154138803482056, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 15:26:19,737 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:19,738 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:13<1:23:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:27,086 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.11692692339420319, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.969, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.11011887341737747, 'eval_loss_2': 0.006808042526245117, 'eval_loss_3': -17.966651916503906, 'eval_loss_4': 1.5170094966888428, 'epoch': 2.03}
{'loss': 0.0766, 'grad_norm': 25.74561882019043, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.07618828862905502, 'loss_2': 0.0004324913024902344, 'loss_3': -15.50196647644043, 'loss_4': 1.2482233047485352, 'epoch': 2.04}
{'loss': 0.1778, 'grad_norm': 31.574363708496094, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.17371147871017456, 'loss_2': 0.0040435791015625, 'loss_3': -15.367433547973633, 'loss_4': 1.1882935762405396, 'epoch': 2.05}
{'loss': 0.0687, 'grad_norm': 25.841154098510742, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.0624089278280735, 'loss_2': 0.00634002685546875, 'loss_3': -15.308391571044922, 'loss_4': 1.330350637435913, 'epoch': 2.05}
{'loss': 0.1993, 'grad_norm': 20.94519805908203, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.19880159199237823, 'loss_2': 0.0005025863647460938, 'loss_3': -15.59428596496582, 'loss_4': 1.7845187187194824, 'epoch': 2.06}
{'loss': 0.2173, 'grad_norm': 29.882781982421875, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.21630458533763885, 'loss_2': 0.001033782958984375, 'loss_3': -15.223108291625977, 'loss_4': 1.55067777633667, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 15:26:27,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:27,086 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:21<1:23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:34,429 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.14641594886779785, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.14219777286052704, 'eval_loss_2': 0.004218187183141708, 'eval_loss_3': -17.907119750976562, 'eval_loss_4': 1.6353788375854492, 'epoch': 2.06}
{'loss': 0.0483, 'grad_norm': 16.34682846069336, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.04118306189775467, 'loss_2': 0.007099151611328125, 'loss_3': -15.72237777709961, 'loss_4': 1.3232853412628174, 'epoch': 2.07}
{'loss': 0.0666, 'grad_norm': 24.07345199584961, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.06530869007110596, 'loss_2': 0.0012969970703125, 'loss_3': -15.535392761230469, 'loss_4': 1.4282053709030151, 'epoch': 2.08}
{'loss': 0.0614, 'grad_norm': 16.461437225341797, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.05653319135308266, 'loss_2': 0.00484466552734375, 'loss_3': -15.598148345947266, 'loss_4': 1.3538291454315186, 'epoch': 2.08}
{'loss': 0.0725, 'grad_norm': 13.825580596923828, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.07177034765481949, 'loss_2': 0.0007386207580566406, 'loss_3': -15.560596466064453, 'loss_4': 2.1955323219299316, 'epoch': 2.09}
{'loss': 0.0434, 'grad_norm': 9.170886039733887, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.036550723016262054, 'loss_2': 0.006893157958984375, 'loss_3': -15.510465621948242, 'loss_4': 1.5739164352416992, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 15:26:34,429 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:34,429 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:28<1:23:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:41,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034083761274814606, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.41, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.027846522629261017, 'eval_loss_2': 0.006237238645553589, 'eval_loss_3': -18.20779800415039, 'eval_loss_4': 1.4539389610290527, 'epoch': 2.09}
{'loss': 0.063, 'grad_norm': 13.190446853637695, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.05537731200456619, 'loss_2': 0.007663726806640625, 'loss_3': -15.515016555786133, 'loss_4': 1.3436639308929443, 'epoch': 2.1}
{'loss': 0.0278, 'grad_norm': 6.676060676574707, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.02195429988205433, 'loss_2': 0.00585174560546875, 'loss_3': -15.683124542236328, 'loss_4': 1.378657341003418, 'epoch': 2.1}
{'loss': 0.0398, 'grad_norm': 13.277688980102539, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.039152875542640686, 'loss_2': 0.0006618499755859375, 'loss_3': -15.83333969116211, 'loss_4': 1.964864730834961, 'epoch': 2.11}
{'loss': 0.0526, 'grad_norm': 11.484807014465332, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.04181748256087303, 'loss_2': 0.0107879638671875, 'loss_3': -15.823592185974121, 'loss_4': 1.6134194135665894, 'epoch': 2.12}
{'loss': 0.0548, 'grad_norm': 16.53050994873047, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.05391606315970421, 'loss_2': 0.0008549690246582031, 'loss_3': -15.580567359924316, 'loss_4': 2.0073776245117188, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 15:26:41,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:41,776 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:35<1:22:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:49,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026414407417178154, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.022753365337848663, 'eval_loss_2': 0.00366104394197464, 'eval_loss_3': -18.2617244720459, 'eval_loss_4': 1.6826026439666748, 'epoch': 2.12}
{'loss': 0.0496, 'grad_norm': 11.415546417236328, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.04241225868463516, 'loss_2': 0.007232666015625, 'loss_3': -15.747135162353516, 'loss_4': 2.0948333740234375, 'epoch': 2.13}
{'loss': 0.0777, 'grad_norm': 18.696699142456055, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.07389301806688309, 'loss_2': 0.00382232666015625, 'loss_3': -15.870161056518555, 'loss_4': 2.5924336910247803, 'epoch': 2.13}
{'loss': 0.0989, 'grad_norm': 26.974491119384766, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.09579968452453613, 'loss_2': 0.003139495849609375, 'loss_3': -15.647043228149414, 'loss_4': 1.7209560871124268, 'epoch': 2.14}
{'loss': 0.0712, 'grad_norm': 19.240726470947266, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.04580628126859665, 'loss_2': 0.025360107421875, 'loss_3': -15.601795196533203, 'loss_4': 1.6992073059082031, 'epoch': 2.15}
{'loss': 0.0765, 'grad_norm': 18.916015625, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.055326610803604126, 'loss_2': 0.021209716796875, 'loss_3': -15.768901824951172, 'loss_4': 1.7365458011627197, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 15:26:49,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:49,123 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:43<1:22:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:26:56,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0402609258890152, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.024240391328930855, 'eval_loss_2': 0.016020536422729492, 'eval_loss_3': -18.214488983154297, 'eval_loss_4': 1.1525583267211914, 'epoch': 2.15}
{'loss': 0.0647, 'grad_norm': 13.295049667358398, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.046256158500909805, 'loss_2': 0.018463134765625, 'loss_3': -15.832253456115723, 'loss_4': 1.0208275318145752, 'epoch': 2.16}
{'loss': 0.2038, 'grad_norm': 25.181671142578125, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.18057677149772644, 'loss_2': 0.023193359375, 'loss_3': -15.576995849609375, 'loss_4': 1.1982409954071045, 'epoch': 2.16}
{'loss': 0.07, 'grad_norm': 15.968608856201172, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.05573207885026932, 'loss_2': 0.01422882080078125, 'loss_3': -15.773913383483887, 'loss_4': 1.3154826164245605, 'epoch': 2.17}
{'loss': 0.0594, 'grad_norm': 10.441149711608887, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.04821910709142685, 'loss_2': 0.011199951171875, 'loss_3': -16.05173683166504, 'loss_4': 1.6739848852157593, 'epoch': 2.17}
{'loss': 0.0456, 'grad_norm': 10.338147163391113, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.03601924702525139, 'loss_2': 0.00958251953125, 'loss_3': -15.63966178894043, 'loss_4': 0.9915435314178467, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 15:26:56,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:26:56,471 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:50<1:22:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:03,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.037215523421764374, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.461, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.033010777086019516, 'eval_loss_2': 0.004204750061035156, 'eval_loss_3': -18.06926155090332, 'eval_loss_4': 1.2098097801208496, 'epoch': 2.18}
{'loss': 0.0698, 'grad_norm': 25.85570526123047, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.0651535913348198, 'loss_2': 0.004608154296875, 'loss_3': -15.752504348754883, 'loss_4': 1.2549039125442505, 'epoch': 2.19}
{'loss': 0.0477, 'grad_norm': 12.350752830505371, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.04504818096756935, 'loss_2': 0.002666473388671875, 'loss_3': -15.779491424560547, 'loss_4': 1.3317726850509644, 'epoch': 2.19}
{'loss': 0.0761, 'grad_norm': 24.992290496826172, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.07251924276351929, 'loss_2': 0.00362396240234375, 'loss_3': -15.779144287109375, 'loss_4': 1.0408143997192383, 'epoch': 2.2}
{'loss': 0.1218, 'grad_norm': 29.216405868530273, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.11636041849851608, 'loss_2': 0.00543975830078125, 'loss_3': -15.209379196166992, 'loss_4': 1.0424197912216187, 'epoch': 2.2}
{'loss': 0.0895, 'grad_norm': 22.15854263305664, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.0764726921916008, 'loss_2': 0.01300048828125, 'loss_3': -15.66736125946045, 'loss_4': 1.3374801874160767, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 15:27:03,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:03,834 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:57<1:22:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:11,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06705158948898315, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.521, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.05878228321671486, 'eval_loss_2': 0.008269309997558594, 'eval_loss_3': -17.933841705322266, 'eval_loss_4': 1.4140909910202026, 'epoch': 2.21}
{'loss': 0.0882, 'grad_norm': 27.43475914001465, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.08334499597549438, 'loss_2': 0.0048980712890625, 'loss_3': -15.37547779083252, 'loss_4': 1.2358546257019043, 'epoch': 2.22}
{'loss': 0.1433, 'grad_norm': 28.34827995300293, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.14120955765247345, 'loss_2': 0.002071380615234375, 'loss_3': -15.743968963623047, 'loss_4': 1.6065599918365479, 'epoch': 2.22}
{'loss': 0.0953, 'grad_norm': 29.324748992919922, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.08859439194202423, 'loss_2': 0.006732940673828125, 'loss_3': -15.560813903808594, 'loss_4': 1.7383583784103394, 'epoch': 2.23}
{'loss': 0.0344, 'grad_norm': 8.382314682006836, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.028062481433153152, 'loss_2': 0.0063323974609375, 'loss_3': -15.826994895935059, 'loss_4': 2.0222816467285156, 'epoch': 2.23}
{'loss': 0.0624, 'grad_norm': 19.486677169799805, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.059156302362680435, 'loss_2': 0.003231048583984375, 'loss_3': -15.516157150268555, 'loss_4': 1.7667739391326904, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 15:27:11,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:11,191 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [10:05<1:22:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:18,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034553419798612595, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.097, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.030460679903626442, 'eval_loss_2': 0.004092738032341003, 'eval_loss_3': -18.040756225585938, 'eval_loss_4': 1.7694332599639893, 'epoch': 2.24}
{'loss': 0.0339, 'grad_norm': 8.228799819946289, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.026621820405125618, 'loss_2': 0.00732421875, 'loss_3': -15.640990257263184, 'loss_4': 1.3652489185333252, 'epoch': 2.24}
{'loss': 0.1057, 'grad_norm': 26.686298370361328, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.1047198474407196, 'loss_2': 0.0009479522705078125, 'loss_3': -15.656473159790039, 'loss_4': 2.073914051055908, 'epoch': 2.25}
{'loss': 0.0749, 'grad_norm': 23.739315032958984, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.06893498450517654, 'loss_2': 0.00597381591796875, 'loss_3': -15.736294746398926, 'loss_4': 2.2944302558898926, 'epoch': 2.26}
{'loss': 0.0945, 'grad_norm': 34.53768539428711, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.08955421298742294, 'loss_2': 0.004993438720703125, 'loss_3': -15.677606582641602, 'loss_4': 2.134610176086426, 'epoch': 2.26}
{'loss': 0.0275, 'grad_norm': 6.069971084594727, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.018294459208846092, 'loss_2': 0.009246826171875, 'loss_3': -15.824676513671875, 'loss_4': 2.2060837745666504, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 15:27:18,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:18,555 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:12<1:22:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:25,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02641759067773819, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.38, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.020208515226840973, 'eval_loss_2': 0.006209075450897217, 'eval_loss_3': -18.0932559967041, 'eval_loss_4': 1.9711517095565796, 'epoch': 2.27}
{'loss': 0.0826, 'grad_norm': 24.91490936279297, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.07059052586555481, 'loss_2': 0.011962890625, 'loss_3': -15.301396369934082, 'loss_4': 1.917969822883606, 'epoch': 2.27}
{'loss': 0.0511, 'grad_norm': 11.9143648147583, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.04125809296965599, 'loss_2': 0.009796142578125, 'loss_3': -15.750457763671875, 'loss_4': 3.0016918182373047, 'epoch': 2.28}
{'loss': 0.0548, 'grad_norm': 16.006017684936523, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.05344276502728462, 'loss_2': 0.0013208389282226562, 'loss_3': -15.51028823852539, 'loss_4': 2.044506549835205, 'epoch': 2.28}
{'loss': 0.0633, 'grad_norm': 16.45020866394043, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.05909319594502449, 'loss_2': 0.00418853759765625, 'loss_3': -15.54987907409668, 'loss_4': 3.031043767929077, 'epoch': 2.29}
{'loss': 0.0465, 'grad_norm': 13.860474586486816, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.038657575845718384, 'loss_2': 0.0078887939453125, 'loss_3': -15.434845924377441, 'loss_4': 1.9151866436004639, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 15:27:25,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:25,913 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:19<1:22:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:33,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025167865678668022, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.017743926495313644, 'eval_loss_2': 0.0074239373207092285, 'eval_loss_3': -18.09937286376953, 'eval_loss_4': 1.7080233097076416, 'epoch': 2.3}
{'loss': 0.0627, 'grad_norm': 25.201236724853516, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.05654751509428024, 'loss_2': 0.006134033203125, 'loss_3': -15.437016487121582, 'loss_4': 1.408436894416809, 'epoch': 2.3}
{'loss': 0.0685, 'grad_norm': 31.009231567382812, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.06762518733739853, 'loss_2': 0.0009202957153320312, 'loss_3': -15.657304763793945, 'loss_4': 2.140972137451172, 'epoch': 2.31}
{'loss': 0.0631, 'grad_norm': 15.865312576293945, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.054116491228342056, 'loss_2': 0.00897216796875, 'loss_3': -15.589998245239258, 'loss_4': 1.7702357769012451, 'epoch': 2.31}
{'loss': 0.1371, 'grad_norm': 36.97010040283203, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.12738867104053497, 'loss_2': 0.00970458984375, 'loss_3': -15.339755058288574, 'loss_4': 1.9829050302505493, 'epoch': 2.32}
{'loss': 0.0985, 'grad_norm': 32.855899810791016, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.09284166246652603, 'loss_2': 0.00568389892578125, 'loss_3': -15.389019966125488, 'loss_4': 1.3413090705871582, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 15:27:33,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:33,269 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:27<1:22:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:40,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023279106244444847, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.001, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01910693384706974, 'eval_loss_2': 0.004172176122665405, 'eval_loss_3': -18.060298919677734, 'eval_loss_4': 1.456128478050232, 'epoch': 2.33}
{'loss': 0.0641, 'grad_norm': 18.380691528320312, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.056790679693222046, 'loss_2': 0.007289886474609375, 'loss_3': -15.485006332397461, 'loss_4': 2.1958117485046387, 'epoch': 2.33}
{'loss': 0.0226, 'grad_norm': 7.368037223815918, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.016933072358369827, 'loss_2': 0.00563812255859375, 'loss_3': -15.584207534790039, 'loss_4': 1.5360742807388306, 'epoch': 2.34}
{'loss': 0.0226, 'grad_norm': 7.451510906219482, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.022134166210889816, 'loss_2': 0.00046539306640625, 'loss_3': -15.57338809967041, 'loss_4': 1.2587684392929077, 'epoch': 2.34}
{'loss': 0.0513, 'grad_norm': 13.215968132019043, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.04918699339032173, 'loss_2': 0.00212860107421875, 'loss_3': -15.373727798461914, 'loss_4': 1.944021224975586, 'epoch': 2.35}
{'loss': 0.0724, 'grad_norm': 18.30475425720215, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.07055054605007172, 'loss_2': 0.0018329620361328125, 'loss_3': -15.416954040527344, 'loss_4': 1.8911832571029663, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 15:27:40,634 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:40,634 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:34<1:22:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:47,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02452310360968113, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.369, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.021134372800588608, 'eval_loss_2': 0.003388732671737671, 'eval_loss_3': -18.085994720458984, 'eval_loss_4': 1.6113150119781494, 'epoch': 2.35}
{'loss': 0.0433, 'grad_norm': 11.430956840515137, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.04187481850385666, 'loss_2': 0.00144195556640625, 'loss_3': -15.38786792755127, 'loss_4': 1.6081736087799072, 'epoch': 2.36}
{'loss': 0.0438, 'grad_norm': 9.349440574645996, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.03873946890234947, 'loss_2': 0.00504302978515625, 'loss_3': -15.53565788269043, 'loss_4': 1.416560173034668, 'epoch': 2.37}
{'loss': 0.0334, 'grad_norm': 8.325699806213379, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.03130209818482399, 'loss_2': 0.00212860107421875, 'loss_3': -15.449481964111328, 'loss_4': 1.149070382118225, 'epoch': 2.37}
{'loss': 0.0385, 'grad_norm': 9.91567611694336, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.0313088595867157, 'loss_2': 0.00714874267578125, 'loss_3': -15.492111206054688, 'loss_4': 1.4322595596313477, 'epoch': 2.38}
{'loss': 0.0364, 'grad_norm': 11.266804695129395, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.035607095807790756, 'loss_2': 0.00075531005859375, 'loss_3': -15.787531852722168, 'loss_4': 1.893110990524292, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 15:27:47,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:47,995 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:41<1:22:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:27:55,343 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024093158543109894, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.191, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.021117746829986572, 'eval_loss_2': 0.0029754117131233215, 'eval_loss_3': -18.182157516479492, 'eval_loss_4': 1.428653359413147, 'epoch': 2.38}
{'loss': 0.0787, 'grad_norm': 18.33442497253418, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.07153259962797165, 'loss_2': 0.00720977783203125, 'loss_3': -15.758569717407227, 'loss_4': 1.8556724786758423, 'epoch': 2.39}
{'loss': 0.1116, 'grad_norm': 28.030630111694336, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.10775450617074966, 'loss_2': 0.003814697265625, 'loss_3': -15.565437316894531, 'loss_4': 1.5491948127746582, 'epoch': 2.4}
{'loss': 0.0476, 'grad_norm': 18.5920352935791, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.04585863649845123, 'loss_2': 0.0017032623291015625, 'loss_3': -15.812515258789062, 'loss_4': 0.46768662333488464, 'epoch': 2.4}
{'loss': 0.07, 'grad_norm': 23.562707901000977, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.06606195867061615, 'loss_2': 0.00391387939453125, 'loss_3': -15.652101516723633, 'loss_4': 1.0558700561523438, 'epoch': 2.41}
{'loss': 0.1065, 'grad_norm': 28.76520347595215, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.10005836933851242, 'loss_2': 0.006465911865234375, 'loss_3': -15.631547927856445, 'loss_4': 0.7956838607788086, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 15:27:55,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:27:55,344 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:49<1:22:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:02,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03675995022058487, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.09, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.025681596249341965, 'eval_loss_2': 0.011078357696533203, 'eval_loss_3': -18.162296295166016, 'eval_loss_4': 0.8890615701675415, 'epoch': 2.41}
{'loss': 0.0455, 'grad_norm': 12.086298942565918, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.03868315368890762, 'loss_2': 0.006855010986328125, 'loss_3': -15.589106559753418, 'loss_4': 1.2103785276412964, 'epoch': 2.42}
{'loss': 0.0886, 'grad_norm': 27.240694046020508, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.07861371338367462, 'loss_2': 0.0099945068359375, 'loss_3': -15.567024230957031, 'loss_4': 0.8641701340675354, 'epoch': 2.42}
{'loss': 0.039, 'grad_norm': 8.052102088928223, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.02903939224779606, 'loss_2': 0.00994110107421875, 'loss_3': -15.891273498535156, 'loss_4': 1.1317927837371826, 'epoch': 2.43}
{'loss': 0.044, 'grad_norm': 25.12858009338379, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.0374532975256443, 'loss_2': 0.006549835205078125, 'loss_3': -15.946076393127441, 'loss_4': 0.6503952741622925, 'epoch': 2.44}
{'loss': 0.0809, 'grad_norm': 25.365468978881836, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.06818009167909622, 'loss_2': 0.01274871826171875, 'loss_3': -15.589459419250488, 'loss_4': 0.42891353368759155, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 15:28:02,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:02,704 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:56<1:22:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:10,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03605489060282707, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.963, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.029773935675621033, 'eval_loss_2': 0.006280958652496338, 'eval_loss_3': -18.092702865600586, 'eval_loss_4': 0.4598901867866516, 'epoch': 2.44}
{'loss': 0.0483, 'grad_norm': 11.956822395324707, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.040612995624542236, 'loss_2': 0.007663726806640625, 'loss_3': -15.695576667785645, 'loss_4': 0.48741188645362854, 'epoch': 2.45}
{'loss': 0.0423, 'grad_norm': 10.777165412902832, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.04082150384783745, 'loss_2': 0.0014781951904296875, 'loss_3': -15.634025573730469, 'loss_4': 0.4512655735015869, 'epoch': 2.45}
{'loss': 0.0459, 'grad_norm': 12.698328018188477, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.04290589317679405, 'loss_2': 0.00299835205078125, 'loss_3': -15.6600341796875, 'loss_4': -0.08868390321731567, 'epoch': 2.46}
{'loss': 0.0613, 'grad_norm': 16.986370086669922, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.04745972901582718, 'loss_2': 0.01380157470703125, 'loss_3': -15.588672637939453, 'loss_4': 0.6451945900917053, 'epoch': 2.47}
{'loss': 0.2384, 'grad_norm': 15.306373596191406, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.22325903177261353, 'loss_2': 0.0151519775390625, 'loss_3': -15.387123107910156, 'loss_4': 0.9395028948783875, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 15:28:10,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:10,062 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [11:04<1:21:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:17,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.046948812901973724, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.031053930521011353, 'eval_loss_2': 0.01589488983154297, 'eval_loss_3': -18.050739288330078, 'eval_loss_4': 0.6631472110748291, 'epoch': 2.47}
{'loss': 0.0439, 'grad_norm': 8.765358924865723, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.027678070589900017, 'loss_2': 0.016265869140625, 'loss_3': -15.543558120727539, 'loss_4': 0.32314175367355347, 'epoch': 2.48}
{'loss': 0.1328, 'grad_norm': 27.114543914794922, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.10869000852108002, 'loss_2': 0.0241546630859375, 'loss_3': -15.511913299560547, 'loss_4': 0.23699617385864258, 'epoch': 2.48}
{'loss': 0.0443, 'grad_norm': 9.217191696166992, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.029455823823809624, 'loss_2': 0.0148773193359375, 'loss_3': -15.527692794799805, 'loss_4': 0.25089651346206665, 'epoch': 2.49}
{'loss': 0.0423, 'grad_norm': 11.25430965423584, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.028114773333072662, 'loss_2': 0.0141448974609375, 'loss_3': -15.599661827087402, 'loss_4': 0.6802150011062622, 'epoch': 2.49}
{'loss': 0.1268, 'grad_norm': 27.167892456054688, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.10950645059347153, 'loss_2': 0.01727294921875, 'loss_3': -15.609402656555176, 'loss_4': 1.2646961212158203, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 15:28:17,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:17,425 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:11<1:22:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:24,806 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03619096800684929, 'eval_runtime': 3.8259, 'eval_samples_per_second': 267.646, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.021316982805728912, 'eval_loss_2': 0.014873981475830078, 'eval_loss_3': -18.15900421142578, 'eval_loss_4': 1.289804220199585, 'epoch': 2.5}
{'loss': 0.0662, 'grad_norm': 16.709136962890625, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.05116209760308266, 'loss_2': 0.0150146484375, 'loss_3': -15.68818473815918, 'loss_4': 1.8929038047790527, 'epoch': 2.51}
{'loss': 0.0368, 'grad_norm': 8.258713722229004, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.023309830576181412, 'loss_2': 0.0134429931640625, 'loss_3': -15.729275703430176, 'loss_4': 1.573411226272583, 'epoch': 2.51}
{'loss': 0.0505, 'grad_norm': 18.26940155029297, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.049292851239442825, 'loss_2': 0.0011796951293945312, 'loss_3': -15.658456802368164, 'loss_4': 1.4307045936584473, 'epoch': 2.52}
{'loss': 0.1199, 'grad_norm': 37.76023483276367, 'learning_rate': 2.75e-05, 'loss_1': 0.11405258625745773, 'loss_2': 0.005847930908203125, 'loss_3': -15.593283653259277, 'loss_4': 1.9305622577667236, 'epoch': 2.52}
{'loss': 0.0432, 'grad_norm': 14.567193031311035, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.03659609332680702, 'loss_2': 0.006618499755859375, 'loss_3': -15.695045471191406, 'loss_4': 1.5289491415023804, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 15:28:24,806 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:24,806 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:18<1:21:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:32,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030592549592256546, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.622, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.02032994106411934, 'eval_loss_2': 0.010262608528137207, 'eval_loss_3': -18.205026626586914, 'eval_loss_4': 1.8874890804290771, 'epoch': 2.53}
{'loss': 0.1063, 'grad_norm': 20.299396514892578, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.09734810888767242, 'loss_2': 0.00896453857421875, 'loss_3': -15.655113220214844, 'loss_4': 2.0363705158233643, 'epoch': 2.53}
{'loss': 0.0511, 'grad_norm': 9.215826988220215, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.03238098323345184, 'loss_2': 0.0186767578125, 'loss_3': -15.778843879699707, 'loss_4': 1.7594587802886963, 'epoch': 2.54}
{'loss': 0.1135, 'grad_norm': 24.68077850341797, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.10061051696538925, 'loss_2': 0.0129241943359375, 'loss_3': -15.803642272949219, 'loss_4': 2.0122015476226807, 'epoch': 2.55}
{'loss': 0.0399, 'grad_norm': 9.944737434387207, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.028053119778633118, 'loss_2': 0.011810302734375, 'loss_3': -15.620309829711914, 'loss_4': 1.6779667139053345, 'epoch': 2.55}
{'loss': 0.083, 'grad_norm': 13.843297004699707, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.06352981925010681, 'loss_2': 0.019439697265625, 'loss_3': -15.852503776550293, 'loss_4': 2.006195545196533, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 15:28:32,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:32,171 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:26<1:21:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:39,535 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031869783997535706, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.744, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.020030101761221886, 'eval_loss_2': 0.011839687824249268, 'eval_loss_3': -18.28370475769043, 'eval_loss_4': 1.894778847694397, 'epoch': 2.56}
{'loss': 0.0683, 'grad_norm': 15.942404747009277, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.054650112986564636, 'loss_2': 0.013671875, 'loss_3': -15.657247543334961, 'loss_4': 1.8427133560180664, 'epoch': 2.56}
{'loss': 0.0547, 'grad_norm': 15.731684684753418, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.04433460906147957, 'loss_2': 0.010345458984375, 'loss_3': -15.59703254699707, 'loss_4': 1.9506168365478516, 'epoch': 2.57}
{'loss': 0.0572, 'grad_norm': 18.61769676208496, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.05184329301118851, 'loss_2': 0.00537109375, 'loss_3': -15.78765869140625, 'loss_4': 1.6437402963638306, 'epoch': 2.58}
{'loss': 0.0626, 'grad_norm': 15.848094940185547, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.0578521303832531, 'loss_2': 0.00478363037109375, 'loss_3': -15.801417350769043, 'loss_4': 2.0681681632995605, 'epoch': 2.58}
{'loss': 0.1352, 'grad_norm': 33.99391555786133, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.12277092039585114, 'loss_2': 0.01241302490234375, 'loss_3': -15.739728927612305, 'loss_4': 1.5709826946258545, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 15:28:39,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:39,535 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:33<1:21:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:46,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02883182466030121, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01963837444782257, 'eval_loss_2': 0.009193450212478638, 'eval_loss_3': -18.23211669921875, 'eval_loss_4': 1.6545661687850952, 'epoch': 2.59}
{'loss': 0.0554, 'grad_norm': 21.12413787841797, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.05451660603284836, 'loss_2': 0.0008769035339355469, 'loss_3': -15.985638618469238, 'loss_4': 1.593507170677185, 'epoch': 2.59}
{'loss': 0.0873, 'grad_norm': 29.1339054107666, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.07408490777015686, 'loss_2': 0.013214111328125, 'loss_3': -15.953169822692871, 'loss_4': 2.2635691165924072, 'epoch': 2.6}
{'loss': 0.0481, 'grad_norm': 12.383648872375488, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.037465810775756836, 'loss_2': 0.01059722900390625, 'loss_3': -15.871807098388672, 'loss_4': 1.865419864654541, 'epoch': 2.6}
{'loss': 0.0575, 'grad_norm': 12.48462200164795, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.043128952383995056, 'loss_2': 0.01434326171875, 'loss_3': -15.696212768554688, 'loss_4': 1.282678484916687, 'epoch': 2.61}
{'loss': 0.0665, 'grad_norm': 18.76299476623535, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.06595592200756073, 'loss_2': 0.0005426406860351562, 'loss_3': -15.6807279586792, 'loss_4': 1.3642733097076416, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 15:28:46,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:46,910 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:40<1:21:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:28:54,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025211108848452568, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.019096089527010918, 'eval_loss_2': 0.00611501932144165, 'eval_loss_3': -18.18337059020996, 'eval_loss_4': 1.6141774654388428, 'epoch': 2.62}
{'loss': 0.0979, 'grad_norm': 19.748443603515625, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.08723190426826477, 'loss_2': 0.01065826416015625, 'loss_3': -15.708406448364258, 'loss_4': 1.6421704292297363, 'epoch': 2.62}
{'loss': 0.043, 'grad_norm': 10.53989028930664, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.03714399039745331, 'loss_2': 0.00585174560546875, 'loss_3': -15.969149589538574, 'loss_4': 1.3914525508880615, 'epoch': 2.63}
{'loss': 0.0372, 'grad_norm': 8.33397388458252, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.02863716520369053, 'loss_2': 0.008544921875, 'loss_3': -15.67722225189209, 'loss_4': 1.2460325956344604, 'epoch': 2.63}
{'loss': 0.0498, 'grad_norm': 13.917000770568848, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.03704635426402092, 'loss_2': 0.01273345947265625, 'loss_3': -15.685538291931152, 'loss_4': 1.4392542839050293, 'epoch': 2.64}
{'loss': 0.0536, 'grad_norm': 13.891077995300293, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.044914744794368744, 'loss_2': 0.00864410400390625, 'loss_3': -15.66258430480957, 'loss_4': 1.200458288192749, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 15:28:54,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:28:54,272 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:48<1:21:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:01,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025473924353718758, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.854, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0167371928691864, 'eval_loss_2': 0.008736729621887207, 'eval_loss_3': -18.196680068969727, 'eval_loss_4': 1.2999370098114014, 'epoch': 2.65}
{'loss': 0.029, 'grad_norm': 6.3622002601623535, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.018858643248677254, 'loss_2': 0.01018524169921875, 'loss_3': -15.745851516723633, 'loss_4': 0.947868824005127, 'epoch': 2.65}
{'loss': 0.0365, 'grad_norm': 11.96683120727539, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.036165546625852585, 'loss_2': 0.0003142356872558594, 'loss_3': -15.717782020568848, 'loss_4': 1.3842164278030396, 'epoch': 2.66}
{'loss': 0.0338, 'grad_norm': 7.042794227600098, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.02272436022758484, 'loss_2': 0.0110626220703125, 'loss_3': -15.653830528259277, 'loss_4': 1.5828368663787842, 'epoch': 2.66}
{'loss': 0.0308, 'grad_norm': 9.155060768127441, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.027052147313952446, 'loss_2': 0.003704071044921875, 'loss_3': -15.679947853088379, 'loss_4': 1.3070874214172363, 'epoch': 2.67}
{'loss': 0.0422, 'grad_norm': 14.042366981506348, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.04206034168601036, 'loss_2': 0.0001271963119506836, 'loss_3': -15.70113468170166, 'loss_4': 1.0349056720733643, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 15:29:01,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:01,646 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:55<1:21:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:09,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02119491994380951, 'eval_runtime': 3.8212, 'eval_samples_per_second': 267.982, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.0161657202988863, 'eval_loss_2': 0.005029201507568359, 'eval_loss_3': -18.15314483642578, 'eval_loss_4': 0.8406765460968018, 'epoch': 2.67}
{'loss': 0.0304, 'grad_norm': 8.23018741607666, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.030298622325062752, 'loss_2': 0.00011658668518066406, 'loss_3': -15.593019485473633, 'loss_4': 0.9182056188583374, 'epoch': 2.68}
{'loss': 0.0456, 'grad_norm': 8.837163925170898, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.04039251431822777, 'loss_2': 0.00519561767578125, 'loss_3': -15.415791511535645, 'loss_4': 0.6103159189224243, 'epoch': 2.69}
{'loss': 0.0307, 'grad_norm': 7.904912948608398, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.027785247191786766, 'loss_2': 0.00292205810546875, 'loss_3': -15.607312202453613, 'loss_4': 0.777155876159668, 'epoch': 2.69}
{'loss': 0.0939, 'grad_norm': 20.4200382232666, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.08228994905948639, 'loss_2': 0.0115814208984375, 'loss_3': -15.716487884521484, 'loss_4': 0.8482246398925781, 'epoch': 2.7}
{'loss': 0.066, 'grad_norm': 19.407140731811523, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.06224023550748825, 'loss_2': 0.00373077392578125, 'loss_3': -15.637372970581055, 'loss_4': 0.5047807693481445, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 15:29:09,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:09,019 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [12:02<1:21:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:16,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027874523773789406, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.703, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.022465547546744347, 'eval_loss_2': 0.005408972501754761, 'eval_loss_3': -18.13796615600586, 'eval_loss_4': 0.8697194457054138, 'epoch': 2.7}
{'loss': 0.0349, 'grad_norm': 8.7390775680542, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.025098837912082672, 'loss_2': 0.009796142578125, 'loss_3': -15.595396995544434, 'loss_4': 0.6198647618293762, 'epoch': 2.71}
{'loss': 0.0682, 'grad_norm': 15.695578575134277, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.057809315621852875, 'loss_2': 0.0103912353515625, 'loss_3': -15.55485725402832, 'loss_4': 0.8298227787017822, 'epoch': 2.72}
{'loss': 0.0589, 'grad_norm': 15.055075645446777, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.05694429576396942, 'loss_2': 0.001979827880859375, 'loss_3': -15.615617752075195, 'loss_4': 0.4116052985191345, 'epoch': 2.72}
{'loss': 0.0727, 'grad_norm': 21.72098159790039, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.07021719962358475, 'loss_2': 0.0024929046630859375, 'loss_3': -15.69014835357666, 'loss_4': 0.6149062514305115, 'epoch': 2.73}
{'loss': 0.0388, 'grad_norm': 16.562334060668945, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.03485318645834923, 'loss_2': 0.0039215087890625, 'loss_3': -15.765188217163086, 'loss_4': 0.7909926772117615, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 15:29:16,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:16,373 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:10<1:20:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:23,718 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032597340643405914, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.874, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02803371287882328, 'eval_loss_2': 0.004563629627227783, 'eval_loss_3': -18.084827423095703, 'eval_loss_4': 1.0847785472869873, 'epoch': 2.73}
{'loss': 0.1611, 'grad_norm': 25.534900665283203, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.15625961124897003, 'loss_2': 0.00481414794921875, 'loss_3': -15.599608421325684, 'loss_4': 1.3563882112503052, 'epoch': 2.74}
{'loss': 0.0887, 'grad_norm': 17.091964721679688, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.08471273630857468, 'loss_2': 0.004009246826171875, 'loss_3': -15.783712387084961, 'loss_4': 1.381608247756958, 'epoch': 2.74}
{'loss': 0.0783, 'grad_norm': 17.08424186706543, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.0761929452419281, 'loss_2': 0.0021514892578125, 'loss_3': -15.800297737121582, 'loss_4': 1.3262165784835815, 'epoch': 2.75}
{'loss': 0.0518, 'grad_norm': 12.544889450073242, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.04366976022720337, 'loss_2': 0.0081634521484375, 'loss_3': -15.693123817443848, 'loss_4': 0.6741490364074707, 'epoch': 2.76}
{'loss': 0.0654, 'grad_norm': 17.353452682495117, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.06514178961515427, 'loss_2': 0.0002918243408203125, 'loss_3': -15.617095947265625, 'loss_4': 1.2249550819396973, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 15:29:23,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:23,719 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:17<1:21:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:31,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03657851368188858, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.972, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.030446331948041916, 'eval_loss_2': 0.006132185459136963, 'eval_loss_3': -18.10243797302246, 'eval_loss_4': 1.2775441408157349, 'epoch': 2.76}
{'loss': 0.0799, 'grad_norm': 30.97603988647461, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.07561315596103668, 'loss_2': 0.00429534912109375, 'loss_3': -15.867257118225098, 'loss_4': 1.0635297298431396, 'epoch': 2.77}
{'loss': 0.1083, 'grad_norm': 27.58325958251953, 'learning_rate': 2.725e-05, 'loss_1': 0.10649190098047256, 'loss_2': 0.0017948150634765625, 'loss_3': -15.574089050292969, 'loss_4': 1.5933903455734253, 'epoch': 2.77}
{'loss': 0.1267, 'grad_norm': 24.973636627197266, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.10567241907119751, 'loss_2': 0.0210113525390625, 'loss_3': -15.498598098754883, 'loss_4': 1.1596884727478027, 'epoch': 2.78}
{'loss': 0.1369, 'grad_norm': 26.763622283935547, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.13130398094654083, 'loss_2': 0.005580902099609375, 'loss_3': -15.336311340332031, 'loss_4': 1.3860137462615967, 'epoch': 2.78}
{'loss': 0.0662, 'grad_norm': 21.416728973388672, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.055937498807907104, 'loss_2': 0.01030731201171875, 'loss_3': -15.599842071533203, 'loss_4': 1.094665765762329, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 15:29:31,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:31,077 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:25<1:20:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:38,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02422357350587845, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.912, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.017677433788776398, 'eval_loss_2': 0.006546139717102051, 'eval_loss_3': -18.20418357849121, 'eval_loss_4': 1.4296135902404785, 'epoch': 2.79}
{'loss': 0.0672, 'grad_norm': 23.321575164794922, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.0670187845826149, 'loss_2': 0.0001983642578125, 'loss_3': -15.479433059692383, 'loss_4': 1.3653544187545776, 'epoch': 2.8}
{'loss': 0.0478, 'grad_norm': 11.11688232421875, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.0425521545112133, 'loss_2': 0.005218505859375, 'loss_3': -15.478400230407715, 'loss_4': 1.3576260805130005, 'epoch': 2.8}
{'loss': 0.0439, 'grad_norm': 14.294629096984863, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.039791930466890335, 'loss_2': 0.00408172607421875, 'loss_3': -15.764413833618164, 'loss_4': 1.3948781490325928, 'epoch': 2.81}
{'loss': 0.12, 'grad_norm': 27.793363571166992, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.11944018304347992, 'loss_2': 0.0005712509155273438, 'loss_3': -15.474954605102539, 'loss_4': 1.5341287851333618, 'epoch': 2.81}
{'loss': 0.0627, 'grad_norm': 14.284290313720703, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.05718515068292618, 'loss_2': 0.005496978759765625, 'loss_3': -15.62973403930664, 'loss_4': 1.6034103631973267, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 15:29:38,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:38,427 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:32<1:21:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:45,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027123194187879562, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.572, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.017222387716174126, 'eval_loss_2': 0.009900808334350586, 'eval_loss_3': -18.29395294189453, 'eval_loss_4': 1.9212251901626587, 'epoch': 2.82}
{'loss': 0.0613, 'grad_norm': 23.730674743652344, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.05120811611413956, 'loss_2': 0.0101165771484375, 'loss_3': -15.865100860595703, 'loss_4': 1.6595134735107422, 'epoch': 2.83}
{'loss': 0.0552, 'grad_norm': 12.303449630737305, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.04646756872534752, 'loss_2': 0.0087432861328125, 'loss_3': -15.371196746826172, 'loss_4': 1.5971999168395996, 'epoch': 2.83}
{'loss': 0.0667, 'grad_norm': 28.078996658325195, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.050440605729818344, 'loss_2': 0.01629638671875, 'loss_3': -15.679289817810059, 'loss_4': 2.0296359062194824, 'epoch': 2.84}
{'loss': 0.0486, 'grad_norm': 11.022054672241211, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.036548446863889694, 'loss_2': 0.0120697021484375, 'loss_3': -15.809148788452148, 'loss_4': 1.701981544494629, 'epoch': 2.84}
{'loss': 0.0537, 'grad_norm': 26.508058547973633, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.0498187281191349, 'loss_2': 0.0038909912109375, 'loss_3': -15.849108695983887, 'loss_4': 2.1295671463012695, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 15:29:45,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:45,798 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:39<1:20:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:29:53,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02422977425158024, 'eval_runtime': 3.8175, 'eval_samples_per_second': 268.239, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.018328793346881866, 'eval_loss_2': 0.005900979042053223, 'eval_loss_3': -18.257938385009766, 'eval_loss_4': 1.8861956596374512, 'epoch': 2.85}
{'loss': 0.0428, 'grad_norm': 11.542283058166504, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.03641342744231224, 'loss_2': 0.00640869140625, 'loss_3': -15.877055168151855, 'loss_4': 1.6119062900543213, 'epoch': 2.85}
{'loss': 0.0253, 'grad_norm': 8.249460220336914, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.023333840072155, 'loss_2': 0.0019283294677734375, 'loss_3': -15.524886131286621, 'loss_4': 1.7466670274734497, 'epoch': 2.86}
{'loss': 0.0267, 'grad_norm': 10.900283813476562, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.025769831612706184, 'loss_2': 0.0009489059448242188, 'loss_3': -15.943521499633789, 'loss_4': 2.2223918437957764, 'epoch': 2.87}
{'loss': 0.0491, 'grad_norm': 13.832257270812988, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.0442475825548172, 'loss_2': 0.004856109619140625, 'loss_3': -15.897007942199707, 'loss_4': 1.4388387203216553, 'epoch': 2.87}
{'loss': 0.0371, 'grad_norm': 10.233871459960938, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.022401664406061172, 'loss_2': 0.0146636962890625, 'loss_3': -15.72830867767334, 'loss_4': 1.182631492614746, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 15:29:53,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:29:53,165 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:47<1:20:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:00,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029251709580421448, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.564, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01621021144092083, 'eval_loss_2': 0.013041496276855469, 'eval_loss_3': -18.228487014770508, 'eval_loss_4': 1.3150604963302612, 'epoch': 2.88}
{'loss': 0.0693, 'grad_norm': 12.697066307067871, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.042671579867601395, 'loss_2': 0.026580810546875, 'loss_3': -15.821537971496582, 'loss_4': 1.1250163316726685, 'epoch': 2.88}
{'loss': 0.0337, 'grad_norm': 9.916357040405273, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.020580021664500237, 'loss_2': 0.01309967041015625, 'loss_3': -15.614559173583984, 'loss_4': 1.1193101406097412, 'epoch': 2.89}
{'loss': 0.0493, 'grad_norm': 20.725601196289062, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.04820797219872475, 'loss_2': 0.0010547637939453125, 'loss_3': -15.523529052734375, 'loss_4': 1.1266844272613525, 'epoch': 2.9}
{'loss': 0.0461, 'grad_norm': 10.704758644104004, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.03353193774819374, 'loss_2': 0.01261138916015625, 'loss_3': -15.719245910644531, 'loss_4': 1.0234884023666382, 'epoch': 2.9}
{'loss': 0.049, 'grad_norm': 26.17317771911621, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.04553503543138504, 'loss_2': 0.0034999847412109375, 'loss_3': -15.466775894165039, 'loss_4': 0.9491461515426636, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 15:30:00,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:00,528 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:50<1:20:45,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:30:04,337 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-500
[INFO|configuration_utils.py:420] 2025-01-21 15:30:04,338 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-500/config.json                                                                             
{'eval_loss': 0.019536558538675308, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01517582405358553, 'eval_loss_2': 0.0043607354164123535, 'eval_loss_3': -18.16570472717285, 'eval_loss_4': 0.892802894115448, 'epoch': 2.91}
[INFO|modeling_utils.py:2988] 2025-01-21 15:30:04,815 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-500/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:30:04,816 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:30:04,816 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-500/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:30:05,740 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-340] due to args.save_total_limit
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:55<1:28:47,  1.14s/it][INFO|trainer.py:4226] 2025-01-21 15:30:09,357 >>
{'loss': 0.0192, 'grad_norm': 6.590472221374512, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.01631581224501133, 'loss_2': 0.00289154052734375, 'loss_3': -15.793174743652344, 'loss_4': 0.764358401298523, 'epoch': 2.91}
{'loss': 0.0538, 'grad_norm': 16.000633239746094, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.04319627955555916, 'loss_2': 0.01064300537109375, 'loss_3': -15.483739852905273, 'loss_4': 0.6409533023834229, 'epoch': 2.92}
{'loss': 0.0394, 'grad_norm': 13.767980575561523, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.030256573110818863, 'loss_2': 0.0091705322265625, 'loss_3': -15.680727005004883, 'loss_4': 0.4928392469882965, 'epoch': 2.92}
{'loss': 0.0262, 'grad_norm': 10.815975189208984, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.02575227990746498, 'loss_2': 0.0004649162292480469, 'loss_3': -15.87431526184082, 'loss_4': 0.3824999928474426, 'epoch': 2.93}
{'loss': 0.038, 'grad_norm': 10.587447166442871, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.032116372138261795, 'loss_2': 0.00589752197265625, 'loss_3': -15.674524307250977, 'loss_4': 0.5467259883880615, 'epoch': 2.94}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:30:09,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:09,358 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [13:03<1:21:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:30:16,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02226482518017292, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015455708838999271, 'eval_loss_2': 0.006809115409851074, 'eval_loss_3': -18.20449447631836, 'eval_loss_4': 0.6368930339813232, 'epoch': 2.94}
{'loss': 0.0438, 'grad_norm': 10.675263404846191, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.03152788057923317, 'loss_2': 0.0122222900390625, 'loss_3': -15.665496826171875, 'loss_4': 0.5268986225128174, 'epoch': 2.94}
{'loss': 0.0304, 'grad_norm': 10.091114044189453, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.02724519371986389, 'loss_2': 0.003177642822265625, 'loss_3': -15.655116081237793, 'loss_4': 0.6805598735809326, 'epoch': 2.95}
{'loss': 0.0232, 'grad_norm': 8.005720138549805, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.02181171625852585, 'loss_2': 0.0013790130615234375, 'loss_3': -15.64869213104248, 'loss_4': 0.6951273679733276, 'epoch': 2.95}
{'loss': 0.0199, 'grad_norm': 6.510773181915283, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.017921363934874535, 'loss_2': 0.001983642578125, 'loss_3': -15.765215873718262, 'loss_4': 0.46381092071533203, 'epoch': 2.96}
{'loss': 0.0358, 'grad_norm': 11.581881523132324, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.03407838195562363, 'loss_2': 0.0017185211181640625, 'loss_3': -15.673919677734375, 'loss_4': 0.6435405611991882, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 15:30:16,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:16,694 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:10<1:19:58,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:30:24,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023861324414610863, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014766372740268707, 'eval_loss_2': 0.009094953536987305, 'eval_loss_3': -18.237716674804688, 'eval_loss_4': 0.6439757943153381, 'epoch': 2.97}
{'loss': 0.0415, 'grad_norm': 8.356090545654297, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.029045511037111282, 'loss_2': 0.0124664306640625, 'loss_3': -15.513921737670898, 'loss_4': 0.5054041147232056, 'epoch': 2.97}
{'loss': 0.035, 'grad_norm': 9.321913719177246, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.021427931264042854, 'loss_2': 0.01354217529296875, 'loss_3': -15.700653076171875, 'loss_4': 0.5580677390098572, 'epoch': 2.98}
{'loss': 0.0872, 'grad_norm': 25.5238037109375, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.0811552032828331, 'loss_2': 0.00608062744140625, 'loss_3': -15.83332633972168, 'loss_4': 0.8977346420288086, 'epoch': 2.98}
{'loss': 0.0627, 'grad_norm': 16.645648956298828, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.054055117070674896, 'loss_2': 0.0086822509765625, 'loss_3': -15.625802993774414, 'loss_4': 0.013556890189647675, 'epoch': 2.99}
{'loss': 0.0298, 'grad_norm': 16.28667640686035, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.027875680476427078, 'loss_2': 0.001941680908203125, 'loss_3': -15.91336727142334, 'loss_4': 1.1195545196533203, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 15:30:24,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:24,010 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:17<1:18:41,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:30:31,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021178564056754112, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.831, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013606508262455463, 'eval_loss_2': 0.007572054862976074, 'eval_loss_3': -18.229679107666016, 'eval_loss_4': 0.9191874861717224, 'epoch': 2.99}
{'loss': 0.0267, 'grad_norm': 7.45819616317749, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.007214311044663191, 'loss_2': 0.01953125, 'loss_3': -15.894622802734375, 'loss_4': 1.3008267879486084, 'epoch': 3.0}
{'loss': 0.0381, 'grad_norm': 18.26885986328125, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.03669537603855133, 'loss_2': 0.0014133453369140625, 'loss_3': -15.830183982849121, 'loss_4': 0.8180030584335327, 'epoch': 3.01}
{'loss': 0.0373, 'grad_norm': 12.856694221496582, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.031216062605381012, 'loss_2': 0.006099700927734375, 'loss_3': -15.653379440307617, 'loss_4': 1.0187698602676392, 'epoch': 3.01}
{'loss': 0.1035, 'grad_norm': 20.401866912841797, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.09697295725345612, 'loss_2': 0.00653076171875, 'loss_3': -15.782670974731445, 'loss_4': 0.965275764465332, 'epoch': 3.02}
{'loss': 0.062, 'grad_norm': 15.076471328735352, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.05948887765407562, 'loss_2': 0.002544403076171875, 'loss_3': -15.63105297088623, 'loss_4': 1.069296956062317, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 15:30:31,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:31,069 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:25<1:19:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:30:38,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025223204866051674, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015599527396261692, 'eval_loss_2': 0.009623676538467407, 'eval_loss_3': -18.226282119750977, 'eval_loss_4': 1.2538968324661255, 'epoch': 3.02}
{'loss': 0.0585, 'grad_norm': 15.160223007202148, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.04862019419670105, 'loss_2': 0.0099029541015625, 'loss_3': -15.758941650390625, 'loss_4': 1.0446677207946777, 'epoch': 3.03}
{'loss': 0.055, 'grad_norm': 11.29610824584961, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.03982454538345337, 'loss_2': 0.01512908935546875, 'loss_3': -15.59985065460205, 'loss_4': 0.9834798574447632, 'epoch': 3.03}
{'loss': 0.0321, 'grad_norm': 8.723515510559082, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.027662934735417366, 'loss_2': 0.0044403076171875, 'loss_3': -15.623102188110352, 'loss_4': 1.5205199718475342, 'epoch': 3.04}
{'loss': 0.059, 'grad_norm': 19.02679443359375, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.051716987043619156, 'loss_2': 0.007293701171875, 'loss_3': -15.70303726196289, 'loss_4': 1.1374850273132324, 'epoch': 3.05}
{'loss': 0.058, 'grad_norm': 22.664445877075195, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.04990052431821823, 'loss_2': 0.00807952880859375, 'loss_3': -15.600364685058594, 'loss_4': 1.496846079826355, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 15:30:38,415 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:38,415 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:32<1:20:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:45,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020723039284348488, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016009101644158363, 'eval_loss_2': 0.0047139376401901245, 'eval_loss_3': -18.177446365356445, 'eval_loss_4': 1.234048843383789, 'epoch': 3.05}
{'loss': 0.0957, 'grad_norm': 19.146587371826172, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.09561077505350113, 'loss_2': 6.347894668579102e-05, 'loss_3': -15.700601577758789, 'loss_4': 1.5318487882614136, 'epoch': 3.06}
{'loss': 0.0373, 'grad_norm': 18.75327491760254, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.037083640694618225, 'loss_2': 0.0002474784851074219, 'loss_3': -15.591497421264648, 'loss_4': 1.2050106525421143, 'epoch': 3.06}
{'loss': 0.1018, 'grad_norm': 25.2143611907959, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.10025270283222198, 'loss_2': 0.0015668869018554688, 'loss_3': -15.66856575012207, 'loss_4': 1.1755280494689941, 'epoch': 3.07}
{'loss': 0.0295, 'grad_norm': 9.056018829345703, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.028847331181168556, 'loss_2': 0.0006456375122070312, 'loss_3': -15.620619773864746, 'loss_4': 1.095566749572754, 'epoch': 3.08}
{'loss': 0.0432, 'grad_norm': 11.830855369567871, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.038877978920936584, 'loss_2': 0.0042724609375, 'loss_3': -15.687032699584961, 'loss_4': 1.175579309463501, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 15:30:45,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:45,770 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:39<1:19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:30:53,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02115720883011818, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.017847303301095963, 'eval_loss_2': 0.003309905529022217, 'eval_loss_3': -18.130584716796875, 'eval_loss_4': 1.0288549661636353, 'epoch': 3.08}
{'loss': 0.0608, 'grad_norm': 21.723405838012695, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.05698278918862343, 'loss_2': 0.00380706787109375, 'loss_3': -15.619039535522461, 'loss_4': 0.8895783424377441, 'epoch': 3.09}
{'loss': 0.0181, 'grad_norm': 6.958676338195801, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.01674269698560238, 'loss_2': 0.00133514404296875, 'loss_3': -15.623600006103516, 'loss_4': 0.2880594730377197, 'epoch': 3.09}
{'loss': 0.0545, 'grad_norm': 14.554840087890625, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.04805438593029976, 'loss_2': 0.00649261474609375, 'loss_3': -15.647260665893555, 'loss_4': 0.7387855052947998, 'epoch': 3.1}
{'loss': 0.0372, 'grad_norm': 8.669060707092285, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.01886177435517311, 'loss_2': 0.0183868408203125, 'loss_3': -15.508618354797363, 'loss_4': 0.4298064410686493, 'epoch': 3.1}
{'loss': 0.0334, 'grad_norm': 8.443659782409668, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.021600794047117233, 'loss_2': 0.01178741455078125, 'loss_3': -15.67926025390625, 'loss_4': 0.05083666741847992, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 15:30:53,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:30:53,111 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:47<1:19:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:00,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022537333890795708, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01637650653719902, 'eval_loss_2': 0.006160825490951538, 'eval_loss_3': -18.084575653076172, 'eval_loss_4': 0.37789812684059143, 'epoch': 3.11}
{'loss': 0.0848, 'grad_norm': 17.094554901123047, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.0836460292339325, 'loss_2': 0.0011625289916992188, 'loss_3': -15.48680591583252, 'loss_4': 0.6471328735351562, 'epoch': 3.12}
{'loss': 0.027, 'grad_norm': 7.658517837524414, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.018228380009531975, 'loss_2': 0.00876617431640625, 'loss_3': -15.793782234191895, 'loss_4': -0.11606588959693909, 'epoch': 3.12}
{'loss': 0.0378, 'grad_norm': 11.503352165222168, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.036024171859025955, 'loss_2': 0.0017261505126953125, 'loss_3': -15.43993854522705, 'loss_4': 0.2215341329574585, 'epoch': 3.13}
{'loss': 0.0372, 'grad_norm': 15.342911720275879, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.03182187303900719, 'loss_2': 0.00533294677734375, 'loss_3': -15.709178924560547, 'loss_4': -0.6609816551208496, 'epoch': 3.13}
{'loss': 0.0231, 'grad_norm': 7.479855060577393, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.021088941022753716, 'loss_2': 0.00199127197265625, 'loss_3': -15.566144943237305, 'loss_4': -0.5376839637756348, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 15:31:00,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:00,464 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:54<1:19:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:07,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024852214381098747, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.017273960635066032, 'eval_loss_2': 0.007578253746032715, 'eval_loss_3': -18.09187889099121, 'eval_loss_4': -0.374756783246994, 'epoch': 3.14}
{'loss': 0.0388, 'grad_norm': 9.038755416870117, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.023711634799838066, 'loss_2': 0.0150604248046875, 'loss_3': -15.710783004760742, 'loss_4': -0.3639413118362427, 'epoch': 3.15}
{'loss': 0.0769, 'grad_norm': 52.99076461791992, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.0706997737288475, 'loss_2': 0.0061798095703125, 'loss_3': -15.593825340270996, 'loss_4': -0.6967021822929382, 'epoch': 3.15}
{'loss': 0.0623, 'grad_norm': 15.859919548034668, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.05461437627673149, 'loss_2': 0.0076446533203125, 'loss_3': -15.768688201904297, 'loss_4': -0.6744679808616638, 'epoch': 3.16}
{'loss': 0.0323, 'grad_norm': 9.41970443725586, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.029311859980225563, 'loss_2': 0.00301361083984375, 'loss_3': -15.597301483154297, 'loss_4': -1.2057605981826782, 'epoch': 3.16}
{'loss': 0.039, 'grad_norm': 14.84874439239502, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.036712147295475006, 'loss_2': 0.0023040771484375, 'loss_3': -15.686639785766602, 'loss_4': -1.1944807767868042, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 15:31:07,810 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:07,810 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:58<1:19:49,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:31:11,625 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-545
[INFO|configuration_utils.py:420] 2025-01-21 15:31:11,626 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-545/config.json                                                                             
{'eval_loss': 0.019501805305480957, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.527, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01459607295691967, 'eval_loss_2': 0.004905730485916138, 'eval_loss_3': -18.216106414794922, 'eval_loss_4': -1.0411396026611328, 'epoch': 3.17}
[INFO|modeling_utils.py:2988] 2025-01-21 15:31:12,117 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-545/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:31:12,118 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-545/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:31:12,118 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-545/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:31:13,088 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-500] due to args.save_total_limit
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [14:03<1:28:21,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:31:16,717 >>
{'loss': 0.0862, 'grad_norm': 21.388996124267578, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.07583431154489517, 'loss_2': 0.0103912353515625, 'loss_3': -15.809748649597168, 'loss_4': -1.4434106349945068, 'epoch': 3.17}
{'loss': 0.0693, 'grad_norm': 16.115324020385742, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.06680557131767273, 'loss_2': 0.002532958984375, 'loss_3': -15.623348236083984, 'loss_4': -1.3161001205444336, 'epoch': 3.18}
{'loss': 0.048, 'grad_norm': 12.657733917236328, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.04502685368061066, 'loss_2': 0.003002166748046875, 'loss_3': -15.787481307983398, 'loss_4': -1.5766135454177856, 'epoch': 3.19}
{'loss': 0.0365, 'grad_norm': 9.01335620880127, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.03468095883727074, 'loss_2': 0.001804351806640625, 'loss_3': -15.943455696105957, 'loss_4': -1.0176177024841309, 'epoch': 3.19}
{'loss': 0.0628, 'grad_norm': 17.05193519592285, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.05667263641953468, 'loss_2': 0.0061492919921875, 'loss_3': -15.80905818939209, 'loss_4': 0.2922457158565521, 'epoch': 3.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:31:16,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:16,717 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:10<1:20:59,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:31:24,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03002551943063736, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.601, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.020254887640476227, 'eval_loss_2': 0.009770631790161133, 'eval_loss_3': -18.30464744567871, 'eval_loss_4': -0.44856566190719604, 'epoch': 3.2}
{'loss': 0.078, 'grad_norm': 14.950965881347656, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.06319285929203033, 'loss_2': 0.01483154296875, 'loss_3': -15.883634567260742, 'loss_4': 0.21320095658302307, 'epoch': 3.2}
{'loss': 0.0697, 'grad_norm': 16.86665153503418, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.05678604915738106, 'loss_2': 0.0128936767578125, 'loss_3': -15.944782257080078, 'loss_4': 0.09415487945079803, 'epoch': 3.21}
{'loss': 0.0637, 'grad_norm': 20.31809425354004, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.05756878852844238, 'loss_2': 0.006168365478515625, 'loss_3': -15.952946662902832, 'loss_4': 0.1160399466753006, 'epoch': 3.22}
{'loss': 0.0903, 'grad_norm': 27.093294143676758, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.07138538360595703, 'loss_2': 0.0188751220703125, 'loss_3': -16.003007888793945, 'loss_4': -0.4749464988708496, 'epoch': 3.22}
{'loss': 0.069, 'grad_norm': 12.10548210144043, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.052172642201185226, 'loss_2': 0.016815185546875, 'loss_3': -15.925505638122559, 'loss_4': -0.9961749315261841, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 15:31:24,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:24,053 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:17<1:19:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:31,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027586601674556732, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.635, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.019242072477936745, 'eval_loss_2': 0.008344531059265137, 'eval_loss_3': -18.285789489746094, 'eval_loss_4': -0.9739618301391602, 'epoch': 3.23}
{'loss': 0.0816, 'grad_norm': 20.87860870361328, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.06830023974180222, 'loss_2': 0.0133209228515625, 'loss_3': -15.914993286132812, 'loss_4': -0.6381043195724487, 'epoch': 3.23}
{'loss': 0.0438, 'grad_norm': 10.622540473937988, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.039325300604104996, 'loss_2': 0.00450897216796875, 'loss_3': -15.881726264953613, 'loss_4': -0.9457242488861084, 'epoch': 3.24}
{'loss': 0.0579, 'grad_norm': 11.924534797668457, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.046649254858493805, 'loss_2': 0.0112152099609375, 'loss_3': -15.958272933959961, 'loss_4': -0.873910129070282, 'epoch': 3.24}
{'loss': 0.0478, 'grad_norm': 12.209246635437012, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.0443602092564106, 'loss_2': 0.003429412841796875, 'loss_3': -15.876838684082031, 'loss_4': -1.1475796699523926, 'epoch': 3.25}
{'loss': 0.0337, 'grad_norm': 10.277095794677734, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.03356419876217842, 'loss_2': 0.0001327991485595703, 'loss_3': -15.879805564880371, 'loss_4': -1.0337491035461426, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 15:31:31,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:31,393 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:25<1:19:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:38,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029710642993450165, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.02408575266599655, 'eval_loss_2': 0.005624890327453613, 'eval_loss_3': -18.16485595703125, 'eval_loss_4': -0.7788954377174377, 'epoch': 3.26}
{'loss': 0.0726, 'grad_norm': 15.35821533203125, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.05483892932534218, 'loss_2': 0.0177154541015625, 'loss_3': -15.711169242858887, 'loss_4': -0.42198991775512695, 'epoch': 3.26}
{'loss': 0.0255, 'grad_norm': 9.617696762084961, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.025034572929143906, 'loss_2': 0.0004744529724121094, 'loss_3': -15.822185516357422, 'loss_4': -1.0512615442276, 'epoch': 3.27}
{'loss': 0.0519, 'grad_norm': 10.377345085144043, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.04059108346700668, 'loss_2': 0.0113372802734375, 'loss_3': -15.876995086669922, 'loss_4': -0.41499635577201843, 'epoch': 3.27}
{'loss': 0.0267, 'grad_norm': 8.055377960205078, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.02542698197066784, 'loss_2': 0.00124359130859375, 'loss_3': -15.792797088623047, 'loss_4': -0.9014775156974792, 'epoch': 3.28}
{'loss': 0.0823, 'grad_norm': 22.550214767456055, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.07893474400043488, 'loss_2': 0.003368377685546875, 'loss_3': -15.524177551269531, 'loss_4': -0.7445636987686157, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 15:31:38,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:38,730 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:32<1:19:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:46,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03179728239774704, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.519, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.022020095959305763, 'eval_loss_2': 0.009777188301086426, 'eval_loss_3': -18.11878204345703, 'eval_loss_4': -0.6806411147117615, 'epoch': 3.28}
{'loss': 0.0622, 'grad_norm': 15.958558082580566, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.054214783012866974, 'loss_2': 0.008026123046875, 'loss_3': -15.616339683532715, 'loss_4': -1.0079476833343506, 'epoch': 3.29}
{'loss': 0.1278, 'grad_norm': 19.332805633544922, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.11938614398241043, 'loss_2': 0.008392333984375, 'loss_3': -15.701292991638184, 'loss_4': -0.5526551008224487, 'epoch': 3.3}
{'loss': 0.0573, 'grad_norm': 15.452715873718262, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.04521498084068298, 'loss_2': 0.01209259033203125, 'loss_3': -15.841302871704102, 'loss_4': -0.31437963247299194, 'epoch': 3.3}
{'loss': 0.0748, 'grad_norm': 21.78115463256836, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.06074200198054314, 'loss_2': 0.0140228271484375, 'loss_3': -15.843683242797852, 'loss_4': -0.9214425086975098, 'epoch': 3.31}
{'loss': 0.0439, 'grad_norm': 9.827736854553223, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.027117446064949036, 'loss_2': 0.016815185546875, 'loss_3': -16.0078125, 'loss_4': -0.17508280277252197, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 15:31:46,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:46,062 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:40<1:19:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:31:53,414 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03345319628715515, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.44, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.02099606767296791, 'eval_loss_2': 0.012457132339477539, 'eval_loss_3': -18.114025115966797, 'eval_loss_4': -0.23196357488632202, 'epoch': 3.31}
{'loss': 0.0533, 'grad_norm': 13.282075881958008, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.04664687067270279, 'loss_2': 0.00661468505859375, 'loss_3': -15.696996688842773, 'loss_4': -0.04679557681083679, 'epoch': 3.32}
{'loss': 0.0221, 'grad_norm': 8.279727935791016, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.020792409777641296, 'loss_2': 0.001316070556640625, 'loss_3': -15.761102676391602, 'loss_4': -0.1834358274936676, 'epoch': 3.33}
{'loss': 0.041, 'grad_norm': 12.017518043518066, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.03432205691933632, 'loss_2': 0.0066375732421875, 'loss_3': -15.678165435791016, 'loss_4': -0.21470844745635986, 'epoch': 3.33}
{'loss': 0.1271, 'grad_norm': 40.27627944946289, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.11761245876550674, 'loss_2': 0.00943756103515625, 'loss_3': -15.63609790802002, 'loss_4': 0.1500115692615509, 'epoch': 3.34}
{'loss': 0.1054, 'grad_norm': 26.274709701538086, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.09528235346078873, 'loss_2': 0.01007080078125, 'loss_3': -15.924219131469727, 'loss_4': 0.7996596097946167, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 15:31:53,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:31:53,414 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:47<1:19:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:00,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030935492366552353, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.024516727775335312, 'eval_loss_2': 0.006418764591217041, 'eval_loss_3': -18.077146530151367, 'eval_loss_4': 0.26108232140541077, 'epoch': 3.34}
{'loss': 0.069, 'grad_norm': 13.172721862792969, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.04547868296504021, 'loss_2': 0.02349853515625, 'loss_3': -15.735078811645508, 'loss_4': 0.05185558646917343, 'epoch': 3.35}
{'loss': 0.0463, 'grad_norm': 16.478988647460938, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.03981548547744751, 'loss_2': 0.0064849853515625, 'loss_3': -15.78077507019043, 'loss_4': -0.10323433578014374, 'epoch': 3.35}
{'loss': 0.0336, 'grad_norm': 8.155349731445312, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.02301795594394207, 'loss_2': 0.01055908203125, 'loss_3': -15.806208610534668, 'loss_4': 1.138049602508545, 'epoch': 3.36}
{'loss': 0.0664, 'grad_norm': 16.951814651489258, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.05438588932156563, 'loss_2': 0.0120391845703125, 'loss_3': -15.529256820678711, 'loss_4': 0.27796289324760437, 'epoch': 3.37}
{'loss': 0.0747, 'grad_norm': 24.035036087036133, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.06443019956350327, 'loss_2': 0.01027679443359375, 'loss_3': -15.7588472366333, 'loss_4': 0.6709479093551636, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 15:32:00,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:00,754 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:54<1:19:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:08,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03250756114721298, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.02457108534872532, 'eval_loss_2': 0.007936477661132812, 'eval_loss_3': -18.069595336914062, 'eval_loss_4': 0.3657885789871216, 'epoch': 3.37}
{'loss': 0.0835, 'grad_norm': 28.399415969848633, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.07305090129375458, 'loss_2': 0.01044464111328125, 'loss_3': -15.812103271484375, 'loss_4': 0.42685967683792114, 'epoch': 3.38}
{'loss': 0.084, 'grad_norm': 23.541780471801758, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.07431517541408539, 'loss_2': 0.00969696044921875, 'loss_3': -15.908851623535156, 'loss_4': 0.06729341298341751, 'epoch': 3.38}
{'loss': 0.0746, 'grad_norm': 18.811594009399414, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.06967698782682419, 'loss_2': 0.004924774169921875, 'loss_3': -15.847100257873535, 'loss_4': 0.3098904490470886, 'epoch': 3.39}
{'loss': 0.0474, 'grad_norm': 17.302358627319336, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.0397551953792572, 'loss_2': 0.00768280029296875, 'loss_3': -15.80654525756836, 'loss_4': 0.1595698446035385, 'epoch': 3.4}
{'loss': 0.0599, 'grad_norm': 17.927759170532227, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.05612121522426605, 'loss_2': 0.003810882568359375, 'loss_3': -15.834650993347168, 'loss_4': 0.408272385597229, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 15:32:08,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:08,097 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [15:02<1:19:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:15,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022825581952929497, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.209, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018991727381944656, 'eval_loss_2': 0.0038338564336299896, 'eval_loss_3': -18.129167556762695, 'eval_loss_4': 0.2608489692211151, 'epoch': 3.4}
{'loss': 0.111, 'grad_norm': 26.969074249267578, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.10002593696117401, 'loss_2': 0.0110015869140625, 'loss_3': -15.72014331817627, 'loss_4': 0.35805267095565796, 'epoch': 3.41}
{'loss': 0.0529, 'grad_norm': 32.220733642578125, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.05252384394407272, 'loss_2': 0.0004191398620605469, 'loss_3': -15.786066055297852, 'loss_4': 0.13216939568519592, 'epoch': 3.41}
{'loss': 0.0543, 'grad_norm': 9.689275741577148, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.05253288894891739, 'loss_2': 0.0017747879028320312, 'loss_3': -15.908880233764648, 'loss_4': 0.22347192466259003, 'epoch': 3.42}
{'loss': 0.1156, 'grad_norm': 20.339542388916016, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.11111201345920563, 'loss_2': 0.00452423095703125, 'loss_3': -15.834493637084961, 'loss_4': 0.9598803520202637, 'epoch': 3.42}
{'loss': 0.0581, 'grad_norm': 14.403987884521484, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.051266442984342575, 'loss_2': 0.006824493408203125, 'loss_3': -15.892352104187012, 'loss_4': 0.3875471353530884, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 15:32:15,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:15,442 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:09<1:18:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:22,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02045898139476776, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.501, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.017351405695080757, 'eval_loss_2': 0.0031075775623321533, 'eval_loss_3': -18.23727035522461, 'eval_loss_4': 0.46692487597465515, 'epoch': 3.43}
{'loss': 0.0512, 'grad_norm': 14.79826831817627, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.04663429036736488, 'loss_2': 0.004611968994140625, 'loss_3': -16.18501091003418, 'loss_4': 0.2638000547885895, 'epoch': 3.44}
{'loss': 0.0898, 'grad_norm': 30.688690185546875, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.08639123290777206, 'loss_2': 0.0033721923828125, 'loss_3': -15.965436935424805, 'loss_4': 0.26466596126556396, 'epoch': 3.44}
{'loss': 0.065, 'grad_norm': 19.124120712280273, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.06041973829269409, 'loss_2': 0.00455474853515625, 'loss_3': -15.992873191833496, 'loss_4': 0.608893871307373, 'epoch': 3.45}
{'loss': 0.0169, 'grad_norm': 6.76870584487915, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.015417354181408882, 'loss_2': 0.0014629364013671875, 'loss_3': -15.86287784576416, 'loss_4': 0.09033091366291046, 'epoch': 3.45}
{'loss': 0.0508, 'grad_norm': 20.18113899230957, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.04997130110859871, 'loss_2': 0.0008783340454101562, 'loss_3': -15.927497863769531, 'loss_4': 1.3497391939163208, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 15:32:22,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:22,784 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:16<1:18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:30,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020037414506077766, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.773, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.015818670392036438, 'eval_loss_2': 0.004218742251396179, 'eval_loss_3': -18.22554588317871, 'eval_loss_4': 0.792617917060852, 'epoch': 3.46}
{'loss': 0.0512, 'grad_norm': 19.661375045776367, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.049515750259160995, 'loss_2': 0.0017261505126953125, 'loss_3': -15.794899940490723, 'loss_4': 0.9289373159408569, 'epoch': 3.47}
{'loss': 0.0377, 'grad_norm': 11.14680004119873, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.03399031236767769, 'loss_2': 0.0036602020263671875, 'loss_3': -15.932629585266113, 'loss_4': 0.9102665185928345, 'epoch': 3.47}
{'loss': 0.0938, 'grad_norm': 17.498218536376953, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.07940848916769028, 'loss_2': 0.0143585205078125, 'loss_3': -15.853134155273438, 'loss_4': 1.3651021718978882, 'epoch': 3.48}
{'loss': 0.0323, 'grad_norm': 7.639556407928467, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.024212386459112167, 'loss_2': 0.0081024169921875, 'loss_3': -15.80094051361084, 'loss_4': 0.6910172700881958, 'epoch': 3.48}
{'loss': 0.0302, 'grad_norm': 9.246721267700195, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.029693804681301117, 'loss_2': 0.0005483627319335938, 'loss_3': -16.010622024536133, 'loss_4': 1.4224566221237183, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 15:32:30,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:30,140 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:20<1:18:58,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:32:33,951 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-600
[INFO|configuration_utils.py:420] 2025-01-21 15:32:33,953 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-600/config.json                                                                             
{'eval_loss': 0.019351275637745857, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01522490382194519, 'eval_loss_2': 0.004126369953155518, 'eval_loss_3': -18.175495147705078, 'eval_loss_4': 1.085277795791626, 'epoch': 3.49}
[INFO|modeling_utils.py:2988] 2025-01-21 15:32:34,427 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-600/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:32:34,429 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-600/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:32:34,429 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-600/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:32:35,376 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-545] due to args.save_total_limit
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:25<1:27:08,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:32:39,008 >>
{'loss': 0.0227, 'grad_norm': 6.726741313934326, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.016662627458572388, 'loss_2': 0.00598907470703125, 'loss_3': -16.043811798095703, 'loss_4': 1.5517125129699707, 'epoch': 3.49}
{'loss': 0.0307, 'grad_norm': 8.564327239990234, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.022325200960040092, 'loss_2': 0.00833892822265625, 'loss_3': -16.00041389465332, 'loss_4': 1.0225279331207275, 'epoch': 3.5}
{'loss': 0.072, 'grad_norm': 18.088985443115234, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.06812265515327454, 'loss_2': 0.00388336181640625, 'loss_3': -15.813925743103027, 'loss_4': 0.8720617294311523, 'epoch': 3.51}
{'loss': 0.0292, 'grad_norm': 9.158143043518066, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.020887719467282295, 'loss_2': 0.00826263427734375, 'loss_3': -15.907073974609375, 'loss_4': 0.8578349351882935, 'epoch': 3.51}
{'loss': 0.0266, 'grad_norm': 6.3351898193359375, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.01707405224442482, 'loss_2': 0.00954437255859375, 'loss_3': -15.802995681762695, 'loss_4': 1.183703064918518, 'epoch': 3.52}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:32:39,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:39,009 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:32<1:19:58,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:32:46,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023627232760190964, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.844, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.018491460010409355, 'eval_loss_2': 0.005135774612426758, 'eval_loss_3': -18.098705291748047, 'eval_loss_4': 1.1205638647079468, 'epoch': 3.52}
{'loss': 0.0381, 'grad_norm': 11.775065422058105, 'learning_rate': 2.65e-05, 'loss_1': 0.037848930805921555, 'loss_2': 0.0002110004425048828, 'loss_3': -15.74188232421875, 'loss_4': 0.5316665768623352, 'epoch': 3.52}
{'loss': 0.0409, 'grad_norm': 8.627848625183105, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.0366172268986702, 'loss_2': 0.004302978515625, 'loss_3': -15.77224063873291, 'loss_4': 0.8825936913490295, 'epoch': 3.53}
{'loss': 0.0404, 'grad_norm': 13.999809265136719, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.039008159190416336, 'loss_2': 0.0014019012451171875, 'loss_3': -15.79644775390625, 'loss_4': 1.20131254196167, 'epoch': 3.53}
{'loss': 0.1198, 'grad_norm': 28.920698165893555, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.1164197027683258, 'loss_2': 0.0033702850341796875, 'loss_3': -15.776302337646484, 'loss_4': 1.5682674646377563, 'epoch': 3.54}
{'loss': 0.2475, 'grad_norm': 43.61997985839844, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.24147143959999084, 'loss_2': 0.005985260009765625, 'loss_3': -15.805086135864258, 'loss_4': 1.9255067110061646, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 15:32:46,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:46,339 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:40<1:18:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:32:53,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04495398327708244, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.776, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.03901008889079094, 'eval_loss_2': 0.005943894386291504, 'eval_loss_3': -17.965335845947266, 'eval_loss_4': 1.7999048233032227, 'epoch': 3.55}
{'loss': 0.0226, 'grad_norm': 7.543308734893799, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.022056302055716515, 'loss_2': 0.0005927085876464844, 'loss_3': -15.75506591796875, 'loss_4': 1.30833101272583, 'epoch': 3.55}
{'loss': 0.0747, 'grad_norm': 20.683807373046875, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.07016214728355408, 'loss_2': 0.00453948974609375, 'loss_3': -15.851798057556152, 'loss_4': 1.9859051704406738, 'epoch': 3.56}
{'loss': 0.0718, 'grad_norm': 19.217063903808594, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.06099017709493637, 'loss_2': 0.01082611083984375, 'loss_3': -15.422479629516602, 'loss_4': 1.6587989330291748, 'epoch': 3.56}
{'loss': 0.1522, 'grad_norm': 24.00401496887207, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.14651572704315186, 'loss_2': 0.00572967529296875, 'loss_3': -15.373687744140625, 'loss_4': 2.0520238876342773, 'epoch': 3.57}
{'loss': 0.3172, 'grad_norm': 102.27349853515625, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.3102951645851135, 'loss_2': 0.006931304931640625, 'loss_3': -15.564690589904785, 'loss_4': 3.6258716583251953, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 15:32:53,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:32:53,677 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:47<1:19:37,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:33:01,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.1382693201303482, 'eval_runtime': 3.991, 'eval_samples_per_second': 256.579, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.1319892853498459, 'eval_loss_2': 0.006280034780502319, 'eval_loss_3': -17.76251983642578, 'eval_loss_4': 2.8415515422821045, 'epoch': 3.58}
{'loss': 0.1031, 'grad_norm': 22.00394630432129, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.09688152372837067, 'loss_2': 0.006259918212890625, 'loss_3': -15.514490127563477, 'loss_4': 2.3029260635375977, 'epoch': 3.58}
{'loss': 0.1455, 'grad_norm': 25.770633697509766, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.14501310884952545, 'loss_2': 0.00048661231994628906, 'loss_3': -15.810550689697266, 'loss_4': 3.096789836883545, 'epoch': 3.59}
{'loss': 0.2552, 'grad_norm': 41.45612716674805, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.25494465231895447, 'loss_2': 0.00022125244140625, 'loss_3': -15.956629753112793, 'loss_4': 3.206510543823242, 'epoch': 3.59}
{'loss': 0.0858, 'grad_norm': 19.6865234375, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.0766352117061615, 'loss_2': 0.0092010498046875, 'loss_3': -15.779191970825195, 'loss_4': 2.6225266456604004, 'epoch': 3.6}
{'loss': 0.0299, 'grad_norm': 8.117444038391113, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.022776968777179718, 'loss_2': 0.00714111328125, 'loss_3': -15.925691604614258, 'loss_4': 2.576547622680664, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 15:33:01,215 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:01,215 >>   Batch size = 64
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:55<1:18:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:08,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03671922907233238, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.569, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.02976861409842968, 'eval_loss_2': 0.0069506168365478516, 'eval_loss_3': -18.058469772338867, 'eval_loss_4': 2.912047863006592, 'epoch': 3.6}
{'loss': 0.0418, 'grad_norm': 15.817544937133789, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.03664979338645935, 'loss_2': 0.00510406494140625, 'loss_3': -15.820490837097168, 'loss_4': 3.1599414348602295, 'epoch': 3.61}
{'loss': 0.0458, 'grad_norm': 14.62600040435791, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.04091958329081535, 'loss_2': 0.00484466552734375, 'loss_3': -15.759440422058105, 'loss_4': 2.355349063873291, 'epoch': 3.62}
{'loss': 0.0709, 'grad_norm': 27.749774932861328, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.0681319534778595, 'loss_2': 0.00276947021484375, 'loss_3': -15.81151294708252, 'loss_4': 2.7774293422698975, 'epoch': 3.62}
{'loss': 0.0575, 'grad_norm': 14.01284122467041, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.05464803799986839, 'loss_2': 0.0028934478759765625, 'loss_3': -15.866050720214844, 'loss_4': 2.13398814201355, 'epoch': 3.63}
{'loss': 0.1024, 'grad_norm': 31.29979705810547, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.10204796493053436, 'loss_2': 0.0003561973571777344, 'loss_3': -15.965941429138184, 'loss_4': 2.817354202270508, 'epoch': 3.63}
[INFO|trainer.py:4228] 2025-01-21 15:33:08,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:08,566 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [16:02<1:18:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:15,922 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01973344385623932, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015842154622077942, 'eval_loss_2': 0.003891289234161377, 'eval_loss_3': -18.192115783691406, 'eval_loss_4': 2.58119797706604, 'epoch': 3.63}
{'loss': 0.0396, 'grad_norm': 9.224145889282227, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.03207515552639961, 'loss_2': 0.0074920654296875, 'loss_3': -15.94726848602295, 'loss_4': 2.3135950565338135, 'epoch': 3.64}
{'loss': 0.0374, 'grad_norm': 13.170495986938477, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.036353494971990585, 'loss_2': 0.001087188720703125, 'loss_3': -16.029773712158203, 'loss_4': 2.8723502159118652, 'epoch': 3.65}
{'loss': 0.0449, 'grad_norm': 10.821020126342773, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.04060126096010208, 'loss_2': 0.00432586669921875, 'loss_3': -15.931154251098633, 'loss_4': 2.952327013015747, 'epoch': 3.65}
{'loss': 0.0595, 'grad_norm': 14.53549575805664, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.04942944273352623, 'loss_2': 0.010040283203125, 'loss_3': -15.726455688476562, 'loss_4': 3.4106574058532715, 'epoch': 3.66}
{'loss': 0.035, 'grad_norm': 12.99962329864502, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.030095122754573822, 'loss_2': 0.00489044189453125, 'loss_3': -16.060836791992188, 'loss_4': 2.9404377937316895, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 15:33:15,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:15,922 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [16:09<1:18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:23,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02551961876451969, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.628, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.021060418337583542, 'eval_loss_2': 0.004459202289581299, 'eval_loss_3': -18.241741180419922, 'eval_loss_4': 2.860051393508911, 'epoch': 3.66}
{'loss': 0.0659, 'grad_norm': 17.60176658630371, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.050370581448078156, 'loss_2': 0.015533447265625, 'loss_3': -15.62279987335205, 'loss_4': 3.3527724742889404, 'epoch': 3.67}
{'loss': 0.0498, 'grad_norm': 13.754049301147461, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.044051654636859894, 'loss_2': 0.005718231201171875, 'loss_3': -15.73771858215332, 'loss_4': 2.977764129638672, 'epoch': 3.67}
{'loss': 0.0882, 'grad_norm': 22.734909057617188, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.08692273497581482, 'loss_2': 0.0012302398681640625, 'loss_3': -15.768220901489258, 'loss_4': 3.7951467037200928, 'epoch': 3.68}
{'loss': 0.0443, 'grad_norm': 10.404580116271973, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.0411805585026741, 'loss_2': 0.003078460693359375, 'loss_3': -16.009262084960938, 'loss_4': 2.81193470954895, 'epoch': 3.69}
{'loss': 0.0467, 'grad_norm': 16.452274322509766, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.040583930909633636, 'loss_2': 0.00614166259765625, 'loss_3': -16.155221939086914, 'loss_4': 3.13733172416687, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 15:33:23,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:23,270 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:17<1:18:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:30,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023012317717075348, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.125, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018991626799106598, 'eval_loss_2': 0.00402069091796875, 'eval_loss_3': -18.25711441040039, 'eval_loss_4': 2.2373034954071045, 'epoch': 3.69}
{'loss': 0.0907, 'grad_norm': 24.601831436157227, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.08511272817850113, 'loss_2': 0.00555419921875, 'loss_3': -15.718610763549805, 'loss_4': 2.453460216522217, 'epoch': 3.7}
{'loss': 0.0615, 'grad_norm': 23.142189025878906, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.05855269730091095, 'loss_2': 0.00298309326171875, 'loss_3': -15.916349411010742, 'loss_4': 2.7582650184631348, 'epoch': 3.7}
{'loss': 0.1578, 'grad_norm': 43.706443786621094, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.15365491807460785, 'loss_2': 0.0041046142578125, 'loss_3': -15.82919692993164, 'loss_4': 2.598763942718506, 'epoch': 3.71}
{'loss': 0.096, 'grad_norm': 25.45063018798828, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.09071347117424011, 'loss_2': 0.00533294677734375, 'loss_3': -16.03947639465332, 'loss_4': 1.9210643768310547, 'epoch': 3.72}
{'loss': 0.058, 'grad_norm': 20.276151657104492, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.05740126222372055, 'loss_2': 0.0006122589111328125, 'loss_3': -15.935364723205566, 'loss_4': 1.7025220394134521, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 15:33:30,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:30,621 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:24<1:18:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:37,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021740837022662163, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.191, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017771972343325615, 'eval_loss_2': 0.003968864679336548, 'eval_loss_3': -18.21473503112793, 'eval_loss_4': 1.3927198648452759, 'epoch': 3.72}
{'loss': 0.0478, 'grad_norm': 10.850624084472656, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.04702617973089218, 'loss_2': 0.0007677078247070312, 'loss_3': -15.948296546936035, 'loss_4': 1.5907185077667236, 'epoch': 3.73}
{'loss': 0.0269, 'grad_norm': 9.95594596862793, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.02310808375477791, 'loss_2': 0.003780364990234375, 'loss_3': -15.928749084472656, 'loss_4': 1.5022099018096924, 'epoch': 3.73}
{'loss': 0.0587, 'grad_norm': 20.80417251586914, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.05392234027385712, 'loss_2': 0.004756927490234375, 'loss_3': -15.739175796508789, 'loss_4': 1.058251142501831, 'epoch': 3.74}
{'loss': 0.0445, 'grad_norm': 15.552786827087402, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.036575380712747574, 'loss_2': 0.0078887939453125, 'loss_3': -15.989535331726074, 'loss_4': 0.43060311675071716, 'epoch': 3.74}
{'loss': 0.0657, 'grad_norm': 20.460559844970703, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.06128104031085968, 'loss_2': 0.00439453125, 'loss_3': -15.81471061706543, 'loss_4': 0.8873708248138428, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 15:33:37,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:37,975 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:31<1:18:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:45,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021918727084994316, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017775695770978928, 'eval_loss_2': 0.004143029451370239, 'eval_loss_3': -18.21853256225586, 'eval_loss_4': 0.5781357288360596, 'epoch': 3.75}
{'loss': 0.0333, 'grad_norm': 12.643804550170898, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.03147191181778908, 'loss_2': 0.00183868408203125, 'loss_3': -15.992223739624023, 'loss_4': 0.7296092510223389, 'epoch': 3.76}
{'loss': 0.0495, 'grad_norm': 13.187036514282227, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.04219716787338257, 'loss_2': 0.0073089599609375, 'loss_3': -16.049320220947266, 'loss_4': -0.10606632381677628, 'epoch': 3.76}
{'loss': 0.0422, 'grad_norm': 14.627546310424805, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.040029626339673996, 'loss_2': 0.002170562744140625, 'loss_3': -16.09729766845703, 'loss_4': -0.12742067873477936, 'epoch': 3.77}
{'loss': 0.0583, 'grad_norm': 15.614019393920898, 'learning_rate': 2.625e-05, 'loss_1': 0.051529042422771454, 'loss_2': 0.0067291259765625, 'loss_3': -16.022438049316406, 'loss_4': 0.18788328766822815, 'epoch': 3.77}
{'loss': 0.1161, 'grad_norm': 26.18315887451172, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.11566318571567535, 'loss_2': 0.0004470348358154297, 'loss_3': -16.15180778503418, 'loss_4': 0.2237425297498703, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 15:33:45,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:45,323 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:39<1:18:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:33:52,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023562433198094368, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.22, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.020015275105834007, 'eval_loss_2': 0.0035471543669700623, 'eval_loss_3': -18.230628967285156, 'eval_loss_4': -0.21594007313251495, 'epoch': 3.78}
{'loss': 0.0723, 'grad_norm': 22.768779754638672, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.07124502956867218, 'loss_2': 0.001087188720703125, 'loss_3': -16.029552459716797, 'loss_4': -0.3530254662036896, 'epoch': 3.78}
{'loss': 0.0864, 'grad_norm': 19.13787269592285, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.08505280315876007, 'loss_2': 0.001308441162109375, 'loss_3': -16.04226303100586, 'loss_4': -0.3761417865753174, 'epoch': 3.79}
{'loss': 0.0428, 'grad_norm': 18.152240753173828, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.037255480885505676, 'loss_2': 0.005523681640625, 'loss_3': -16.18274688720703, 'loss_4': -0.15026170015335083, 'epoch': 3.8}
{'loss': 0.0769, 'grad_norm': 17.518451690673828, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.07253497838973999, 'loss_2': 0.0043182373046875, 'loss_3': -16.195335388183594, 'loss_4': 0.16128018498420715, 'epoch': 3.8}
{'loss': 0.0508, 'grad_norm': 14.985407829284668, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.04773242026567459, 'loss_2': 0.003040313720703125, 'loss_3': -16.145797729492188, 'loss_4': -0.6505604982376099, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 15:33:52,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:33:52,690 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:46<1:17:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:00,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028043946251273155, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.085, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02173091284930706, 'eval_loss_2': 0.006313033401966095, 'eval_loss_3': -18.26411247253418, 'eval_loss_4': -0.6898746490478516, 'epoch': 3.81}
{'loss': 0.0731, 'grad_norm': 13.780660629272461, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.0650828406214714, 'loss_2': 0.00799560546875, 'loss_3': -16.09186553955078, 'loss_4': -1.0739110708236694, 'epoch': 3.81}
{'loss': 0.0543, 'grad_norm': 12.225627899169922, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.047160085290670395, 'loss_2': 0.007110595703125, 'loss_3': -16.171485900878906, 'loss_4': -0.3647652566432953, 'epoch': 3.82}
{'loss': 0.039, 'grad_norm': 9.66445541381836, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.030981838703155518, 'loss_2': 0.00800323486328125, 'loss_3': -16.046695709228516, 'loss_4': -0.9389809966087341, 'epoch': 3.83}
{'loss': 0.0607, 'grad_norm': 13.03104305267334, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.05748853459954262, 'loss_2': 0.00323486328125, 'loss_3': -15.981502532958984, 'loss_4': -0.8271914124488831, 'epoch': 3.83}
{'loss': 0.0553, 'grad_norm': 12.68996524810791, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.05092616379261017, 'loss_2': 0.004364013671875, 'loss_3': -16.259449005126953, 'loss_4': -0.9827536344528198, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 15:34:00,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:00,036 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:53<1:17:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:07,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024055523797869682, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.021933911368250847, 'eval_loss_2': 0.0021216124296188354, 'eval_loss_3': -18.269981384277344, 'eval_loss_4': -0.6129860281944275, 'epoch': 3.84}
{'loss': 0.0648, 'grad_norm': 14.626056671142578, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.060112230479717255, 'loss_2': 0.0047149658203125, 'loss_3': -16.1427059173584, 'loss_4': -0.6513276100158691, 'epoch': 3.84}
{'loss': 0.0534, 'grad_norm': 13.539129257202148, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.04217841103672981, 'loss_2': 0.0111846923828125, 'loss_3': -16.186134338378906, 'loss_4': -0.6179988384246826, 'epoch': 3.85}
{'loss': 0.0447, 'grad_norm': 12.684061050415039, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.03212442249059677, 'loss_2': 0.012542724609375, 'loss_3': -16.18296241760254, 'loss_4': -0.1644449532032013, 'epoch': 3.85}
{'loss': 0.0425, 'grad_norm': 11.602194786071777, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.036717597395181656, 'loss_2': 0.00580596923828125, 'loss_3': -15.929986953735352, 'loss_4': -0.34809499979019165, 'epoch': 3.86}
{'loss': 0.0485, 'grad_norm': 16.43959617614746, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.0474766343832016, 'loss_2': 0.001071929931640625, 'loss_3': -15.880207061767578, 'loss_4': -0.19092115759849548, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 15:34:07,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:07,389 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [17:01<1:17:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:14,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0201975479722023, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.018245017156004906, 'eval_loss_2': 0.001952528953552246, 'eval_loss_3': -18.246570587158203, 'eval_loss_4': -0.14149044454097748, 'epoch': 3.87}
{'loss': 0.0272, 'grad_norm': 9.883750915527344, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.023495269939303398, 'loss_2': 0.0036773681640625, 'loss_3': -15.961010932922363, 'loss_4': -0.1847516894340515, 'epoch': 3.87}
{'loss': 0.028, 'grad_norm': 9.835570335388184, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.025698857381939888, 'loss_2': 0.00234222412109375, 'loss_3': -16.073102951049805, 'loss_4': 0.2321961224079132, 'epoch': 3.88}
{'loss': 0.0874, 'grad_norm': 21.57568359375, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.07820810377597809, 'loss_2': 0.0092010498046875, 'loss_3': -15.977397918701172, 'loss_4': -0.06827515363693237, 'epoch': 3.88}
{'loss': 0.0549, 'grad_norm': 13.030230522155762, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.04269653186202049, 'loss_2': 0.0121917724609375, 'loss_3': -16.082040786743164, 'loss_4': 0.17488990724086761, 'epoch': 3.89}
{'loss': 0.1088, 'grad_norm': 33.54168701171875, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.1082136407494545, 'loss_2': 0.0006227493286132812, 'loss_3': -16.048614501953125, 'loss_4': 0.5292447209358215, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 15:34:14,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:14,742 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:08<1:17:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:22,095 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028227534145116806, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.021645601838827133, 'eval_loss_2': 0.006581932306289673, 'eval_loss_3': -18.205677032470703, 'eval_loss_4': 0.6262229084968567, 'epoch': 3.9}
{'loss': 0.0345, 'grad_norm': 11.053264617919922, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.028145013377070427, 'loss_2': 0.00634765625, 'loss_3': -16.145469665527344, 'loss_4': 0.47527965903282166, 'epoch': 3.9}
{'loss': 0.0359, 'grad_norm': 13.113127708435059, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.03475312516093254, 'loss_2': 0.0011796951293945312, 'loss_3': -16.00860595703125, 'loss_4': 1.113175868988037, 'epoch': 3.91}
{'loss': 0.038, 'grad_norm': 13.702259063720703, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.036018192768096924, 'loss_2': 0.00201416015625, 'loss_3': -15.928459167480469, 'loss_4': 0.5925502777099609, 'epoch': 3.91}
{'loss': 0.0312, 'grad_norm': 7.934849262237549, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.023493478074669838, 'loss_2': 0.0077362060546875, 'loss_3': -15.923454284667969, 'loss_4': 1.1954278945922852, 'epoch': 3.92}
{'loss': 0.0206, 'grad_norm': 8.125508308410645, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.020383760333061218, 'loss_2': 0.0002498626708984375, 'loss_3': -15.954229354858398, 'loss_4': 1.4405900239944458, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 15:34:22,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:22,096 >>   Batch size = 64
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:16<1:17:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:29,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03409162163734436, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.941, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0244924146682024, 'eval_loss_2': 0.00959920883178711, 'eval_loss_3': -18.19341468811035, 'eval_loss_4': 1.4673963785171509, 'epoch': 3.92}
{'loss': 0.0533, 'grad_norm': 13.375771522521973, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.04412239417433739, 'loss_2': 0.0091400146484375, 'loss_3': -16.027820587158203, 'loss_4': 1.4382045269012451, 'epoch': 3.93}
{'loss': 0.0667, 'grad_norm': 19.024394989013672, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.05486143007874489, 'loss_2': 0.01180267333984375, 'loss_3': -15.899435043334961, 'loss_4': 1.7317228317260742, 'epoch': 3.94}
{'loss': 0.1145, 'grad_norm': 23.91107940673828, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.09998153895139694, 'loss_2': 0.014495849609375, 'loss_3': -15.912477493286133, 'loss_4': 1.6314036846160889, 'epoch': 3.94}
{'loss': 0.0398, 'grad_norm': 7.772515296936035, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.023921741172671318, 'loss_2': 0.015838623046875, 'loss_3': -16.041446685791016, 'loss_4': 1.3719016313552856, 'epoch': 3.95}
{'loss': 0.1074, 'grad_norm': 18.663114547729492, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.08871957659721375, 'loss_2': 0.0187225341796875, 'loss_3': -16.10586166381836, 'loss_4': 1.971750020980835, 'epoch': 3.95}
[INFO|trainer.py:4228] 2025-01-21 15:34:29,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:29,454 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:23<1:17:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:36,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05417225509881973, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.625, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.03657982870936394, 'eval_loss_2': 0.017592430114746094, 'eval_loss_3': -18.18413543701172, 'eval_loss_4': 2.2895374298095703, 'epoch': 3.95}
{'loss': 0.1105, 'grad_norm': 21.174884796142578, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.09193696826696396, 'loss_2': 0.0185546875, 'loss_3': -16.093008041381836, 'loss_4': 1.9832566976547241, 'epoch': 3.96}
{'loss': 0.1401, 'grad_norm': 29.07443618774414, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.12157583981752396, 'loss_2': 0.0184783935546875, 'loss_3': -15.803990364074707, 'loss_4': 2.963060140609741, 'epoch': 3.97}
{'loss': 0.052, 'grad_norm': 10.200728416442871, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.03315114602446556, 'loss_2': 0.01885986328125, 'loss_3': -15.946602821350098, 'loss_4': 2.3016042709350586, 'epoch': 3.97}
{'loss': 0.0813, 'grad_norm': 19.002119064331055, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.06699565798044205, 'loss_2': 0.0143280029296875, 'loss_3': -15.97518253326416, 'loss_4': 2.770395040512085, 'epoch': 3.98}
{'loss': 0.0728, 'grad_norm': 16.527618408203125, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.0683426484465599, 'loss_2': 0.00447845458984375, 'loss_3': -15.903736114501953, 'loss_4': 3.225403308868408, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 15:34:36,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:36,818 >>   Batch size = 64
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:30<1:14:17,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 15:34:43,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04270624369382858, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.802, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.03687462955713272, 'eval_loss_2': 0.005831614136695862, 'eval_loss_3': -18.18937110900879, 'eval_loss_4': 2.9432144165039062, 'epoch': 3.98}
{'loss': 0.0991, 'grad_norm': 28.366680145263672, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.09480519592761993, 'loss_2': 0.004337310791015625, 'loss_3': -15.948073387145996, 'loss_4': 2.8010902404785156, 'epoch': 3.99}
{'loss': 0.0797, 'grad_norm': 17.733198165893555, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.07012847065925598, 'loss_2': 0.0095977783203125, 'loss_3': -16.169292449951172, 'loss_4': 3.783045530319214, 'epoch': 3.99}
{'loss': 0.0785, 'grad_norm': 24.906408309936523, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.07407739758491516, 'loss_2': 0.004436492919921875, 'loss_3': -15.735319137573242, 'loss_4': 3.6378488540649414, 'epoch': 4.0}
{'loss': 0.0385, 'grad_norm': 9.047601699829102, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.03390826657414436, 'loss_2': 0.00457000732421875, 'loss_3': -15.990362167358398, 'loss_4': 3.3257856369018555, 'epoch': 4.01}
{'loss': 0.061, 'grad_norm': 12.668822288513184, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.0533277653157711, 'loss_2': 0.0076751708984375, 'loss_3': -15.995104789733887, 'loss_4': 2.811647415161133, 'epoch': 4.01}
[INFO|trainer.py:4228] 2025-01-21 15:34:43,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:43,862 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:37<1:16:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:34:51,223 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02461690828204155, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.099, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020715605467557907, 'eval_loss_2': 0.0039013028144836426, 'eval_loss_3': -18.25181770324707, 'eval_loss_4': 2.9303712844848633, 'epoch': 4.01}
{'loss': 0.0942, 'grad_norm': 24.52783966064453, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.08716757595539093, 'loss_2': 0.0070343017578125, 'loss_3': -16.022144317626953, 'loss_4': 3.0120275020599365, 'epoch': 4.02}
{'loss': 0.1686, 'grad_norm': 56.951515197753906, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.15993276238441467, 'loss_2': 0.0087127685546875, 'loss_3': -15.862110137939453, 'loss_4': 3.212456703186035, 'epoch': 4.02}
{'loss': 0.061, 'grad_norm': 16.85692596435547, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.0573318786919117, 'loss_2': 0.003620147705078125, 'loss_3': -15.905807495117188, 'loss_4': 2.818185806274414, 'epoch': 4.03}
{'loss': 0.1103, 'grad_norm': 31.87346649169922, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.09832937270402908, 'loss_2': 0.011993408203125, 'loss_3': -16.25911521911621, 'loss_4': 3.154674530029297, 'epoch': 4.03}
{'loss': 0.0281, 'grad_norm': 9.951621055603027, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.024904092773795128, 'loss_2': 0.003170013427734375, 'loss_3': -15.99795150756836, 'loss_4': 2.6966183185577393, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 15:34:51,223 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:51,223 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:45<1:17:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:34:58,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023617703467607498, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.052, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.018354881554841995, 'eval_loss_2': 0.005262821912765503, 'eval_loss_3': -18.327234268188477, 'eval_loss_4': 2.788637161254883, 'epoch': 4.04}
{'loss': 0.0567, 'grad_norm': 21.497272491455078, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.05150848999619484, 'loss_2': 0.0051422119140625, 'loss_3': -16.030075073242188, 'loss_4': 3.08355712890625, 'epoch': 4.05}
{'loss': 0.0426, 'grad_norm': 21.030736923217773, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.04160593822598457, 'loss_2': 0.0009784698486328125, 'loss_3': -15.94108772277832, 'loss_4': 2.935257911682129, 'epoch': 4.05}
{'loss': 0.0273, 'grad_norm': 8.62039852142334, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.02532832697033882, 'loss_2': 0.0019245147705078125, 'loss_3': -15.967748641967773, 'loss_4': 2.361623764038086, 'epoch': 4.06}
{'loss': 0.0441, 'grad_norm': 11.151650428771973, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.03583754599094391, 'loss_2': 0.00821685791015625, 'loss_3': -16.087182998657227, 'loss_4': 2.9179344177246094, 'epoch': 4.06}
{'loss': 0.057, 'grad_norm': 16.08826446533203, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.05689488723874092, 'loss_2': 9.381771087646484e-05, 'loss_3': -15.764872550964355, 'loss_4': 2.563918113708496, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 15:34:58,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:34:58,580 >>   Batch size = 64
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:52<1:17:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:05,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020438287407159805, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.969, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0171956829726696, 'eval_loss_2': 0.003242604434490204, 'eval_loss_3': -18.357372283935547, 'eval_loss_4': 2.612663745880127, 'epoch': 4.07}
{'loss': 0.036, 'grad_norm': 9.438804626464844, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.032254934310913086, 'loss_2': 0.003757476806640625, 'loss_3': -15.94629955291748, 'loss_4': 2.6690802574157715, 'epoch': 4.08}
{'loss': 0.0506, 'grad_norm': 26.817161560058594, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.04222258925437927, 'loss_2': 0.0083465576171875, 'loss_3': -16.028244018554688, 'loss_4': 3.0436882972717285, 'epoch': 4.08}
{'loss': 0.0429, 'grad_norm': 7.98822546005249, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.028303727507591248, 'loss_2': 0.01457977294921875, 'loss_3': -15.998040199279785, 'loss_4': 2.2870049476623535, 'epoch': 4.09}
{'loss': 0.0343, 'grad_norm': 10.06493091583252, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.028788091614842415, 'loss_2': 0.00550079345703125, 'loss_3': -16.028804779052734, 'loss_4': 2.2771849632263184, 'epoch': 4.09}
{'loss': 0.0316, 'grad_norm': 7.408200263977051, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.019712436944246292, 'loss_2': 0.011932373046875, 'loss_3': -15.968186378479004, 'loss_4': 2.630103588104248, 'epoch': 4.1}
[INFO|trainer.py:4228] 2025-01-21 15:35:05,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:05,944 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [17:59<1:17:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:13,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020362257957458496, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.792, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.016922634094953537, 'eval_loss_2': 0.003439623862504959, 'eval_loss_3': -18.34020233154297, 'eval_loss_4': 2.1787049770355225, 'epoch': 4.1}
{'loss': 0.0249, 'grad_norm': 7.831646919250488, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.024542083963751793, 'loss_2': 0.0003161430358886719, 'loss_3': -15.974556922912598, 'loss_4': 2.1472043991088867, 'epoch': 4.1}
{'loss': 0.0369, 'grad_norm': 14.311203002929688, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.0317804254591465, 'loss_2': 0.005157470703125, 'loss_3': -15.994342803955078, 'loss_4': 2.1754133701324463, 'epoch': 4.11}
{'loss': 0.0551, 'grad_norm': 13.30124282836914, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.04737788811326027, 'loss_2': 0.007701873779296875, 'loss_3': -15.984953880310059, 'loss_4': 2.330139636993408, 'epoch': 4.12}
{'loss': 0.0305, 'grad_norm': 8.256673812866211, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.024598021060228348, 'loss_2': 0.0058746337890625, 'loss_3': -15.98753547668457, 'loss_4': 1.2269854545593262, 'epoch': 4.12}
{'loss': 0.0553, 'grad_norm': 14.62366771697998, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.04947974160313606, 'loss_2': 0.005828857421875, 'loss_3': -16.02603530883789, 'loss_4': 1.8642128705978394, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 15:35:13,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:13,308 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [18:07<1:17:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:20,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02074328437447548, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.987, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01797432079911232, 'eval_loss_2': 0.002768963575363159, 'eval_loss_3': -18.256103515625, 'eval_loss_4': 1.5753549337387085, 'epoch': 4.13}
{'loss': 0.0634, 'grad_norm': 15.822726249694824, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.061992548406124115, 'loss_2': 0.0014324188232421875, 'loss_3': -16.163070678710938, 'loss_4': 1.5236940383911133, 'epoch': 4.13}
{'loss': 0.1083, 'grad_norm': 25.3944034576416, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.10784254968166351, 'loss_2': 0.0004220008850097656, 'loss_3': -15.861358642578125, 'loss_4': 1.8542914390563965, 'epoch': 4.14}
{'loss': 0.0565, 'grad_norm': 14.160922050476074, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.05031405761837959, 'loss_2': 0.00614166259765625, 'loss_3': -15.963723182678223, 'loss_4': 1.5950267314910889, 'epoch': 4.15}
{'loss': 0.0374, 'grad_norm': 16.510547637939453, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.031780581921339035, 'loss_2': 0.00559234619140625, 'loss_3': -16.089664459228516, 'loss_4': 1.4221856594085693, 'epoch': 4.15}
{'loss': 0.0264, 'grad_norm': 6.39849853515625, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.018041497096419334, 'loss_2': 0.00836181640625, 'loss_3': -16.14243507385254, 'loss_4': 0.8116065263748169, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 15:35:20,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:20,667 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:14<1:16:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:28,021 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035190194845199585, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.855, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.032762560993433, 'eval_loss_2': 0.002427630126476288, 'eval_loss_3': -18.19807243347168, 'eval_loss_4': 1.02102792263031, 'epoch': 4.16}
{'loss': 0.0904, 'grad_norm': 33.955177307128906, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.08741413056850433, 'loss_2': 0.0030059814453125, 'loss_3': -15.941951751708984, 'loss_4': 1.0034229755401611, 'epoch': 4.16}
{'loss': 0.0399, 'grad_norm': 35.282440185546875, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.03656068444252014, 'loss_2': 0.003360748291015625, 'loss_3': -16.067825317382812, 'loss_4': 0.6046563982963562, 'epoch': 4.17}
{'loss': 0.0265, 'grad_norm': 7.426380157470703, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.023920102044939995, 'loss_2': 0.00257110595703125, 'loss_3': -16.022991180419922, 'loss_4': 0.6395705342292786, 'epoch': 4.17}
{'loss': 0.0353, 'grad_norm': 10.246074676513672, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.02347586490213871, 'loss_2': 0.0117950439453125, 'loss_3': -16.10525131225586, 'loss_4': 0.5891076326370239, 'epoch': 4.18}
{'loss': 0.0225, 'grad_norm': 6.592261791229248, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.01874048076570034, 'loss_2': 0.0038051605224609375, 'loss_3': -16.100370407104492, 'loss_4': 0.380926251411438, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 15:35:28,021 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:28,021 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:21<1:16:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:35,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020204704254865646, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.75, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01618177816271782, 'eval_loss_2': 0.004022926092147827, 'eval_loss_3': -18.346172332763672, 'eval_loss_4': 0.5327897667884827, 'epoch': 4.19}
{'loss': 0.0556, 'grad_norm': 13.729920387268066, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.046871598809957504, 'loss_2': 0.00868988037109375, 'loss_3': -16.153297424316406, 'loss_4': 0.34862247109413147, 'epoch': 4.19}
{'loss': 0.0287, 'grad_norm': 7.366596221923828, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.022220540791749954, 'loss_2': 0.0064544677734375, 'loss_3': -16.058860778808594, 'loss_4': 0.6855288147926331, 'epoch': 4.2}
{'loss': 0.0261, 'grad_norm': 7.191349983215332, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.0191057026386261, 'loss_2': 0.006977081298828125, 'loss_3': -16.22466468811035, 'loss_4': 0.2311083972454071, 'epoch': 4.2}
{'loss': 0.11, 'grad_norm': 28.297536849975586, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.10547126829624176, 'loss_2': 0.00455474853515625, 'loss_3': -16.112442016601562, 'loss_4': 1.1284583806991577, 'epoch': 4.21}
{'loss': 0.0541, 'grad_norm': 17.49455451965332, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.04108322039246559, 'loss_2': 0.0130462646484375, 'loss_3': -16.415498733520508, 'loss_4': 1.019578218460083, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 15:35:35,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:35,385 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:29<1:16:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:42,741 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025290697813034058, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.902, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.019550450146198273, 'eval_loss_2': 0.005740247666835785, 'eval_loss_3': -18.38039779663086, 'eval_loss_4': 0.8358010649681091, 'epoch': 4.22}
{'loss': 0.0501, 'grad_norm': 12.755239486694336, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.04513261839747429, 'loss_2': 0.00492095947265625, 'loss_3': -16.499801635742188, 'loss_4': 1.3991596698760986, 'epoch': 4.22}
{'loss': 0.0619, 'grad_norm': 18.155397415161133, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.05994637683033943, 'loss_2': 0.002002716064453125, 'loss_3': -16.213090896606445, 'loss_4': 1.3832989931106567, 'epoch': 4.23}
{'loss': 0.0309, 'grad_norm': 8.56685733795166, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.03026488982141018, 'loss_2': 0.0006837844848632812, 'loss_3': -16.220993041992188, 'loss_4': 1.03426194190979, 'epoch': 4.23}
{'loss': 0.0692, 'grad_norm': 21.27800941467285, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.06439719349145889, 'loss_2': 0.004810333251953125, 'loss_3': -16.062963485717773, 'loss_4': 1.7260422706604004, 'epoch': 4.24}
{'loss': 0.0588, 'grad_norm': 17.00887107849121, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.04689887911081314, 'loss_2': 0.0119171142578125, 'loss_3': -16.254165649414062, 'loss_4': 0.8277179002761841, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 15:35:42,741 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:42,741 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:36<1:16:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:50,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02509550377726555, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.76, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.020559538155794144, 'eval_loss_2': 0.004535965621471405, 'eval_loss_3': -18.406375885009766, 'eval_loss_4': 0.4850645959377289, 'epoch': 4.24}
{'loss': 0.0551, 'grad_norm': 12.842488288879395, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.054942164570093155, 'loss_2': 0.00017189979553222656, 'loss_3': -16.290658950805664, 'loss_4': 1.3502211570739746, 'epoch': 4.25}
{'loss': 0.0422, 'grad_norm': 11.399820327758789, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.03964681550860405, 'loss_2': 0.00255584716796875, 'loss_3': -16.278987884521484, 'loss_4': 0.5028339624404907, 'epoch': 4.26}
{'loss': 0.0498, 'grad_norm': 15.664602279663086, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.04535852000117302, 'loss_2': 0.0044708251953125, 'loss_3': -16.03986930847168, 'loss_4': 0.6814870834350586, 'epoch': 4.26}
{'loss': 0.0373, 'grad_norm': 8.3693208694458, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.03521346673369408, 'loss_2': 0.0021190643310546875, 'loss_3': -16.22909927368164, 'loss_4': 0.07460656762123108, 'epoch': 4.27}
{'loss': 0.0331, 'grad_norm': 8.181882858276367, 'learning_rate': 2.575e-05, 'loss_1': 0.02648526430130005, 'loss_2': 0.00665283203125, 'loss_3': -16.14913558959961, 'loss_4': 0.0869206041097641, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 15:35:50,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:50,102 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:44<1:16:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:35:57,468 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025634510442614555, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.27, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.020493101328611374, 'eval_loss_2': 0.005141407251358032, 'eval_loss_3': -18.379291534423828, 'eval_loss_4': 0.285952091217041, 'epoch': 4.27}
{'loss': 0.0717, 'grad_norm': 17.1231632232666, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.06498510390520096, 'loss_2': 0.00667572021484375, 'loss_3': -16.287853240966797, 'loss_4': 0.49641236662864685, 'epoch': 4.28}
{'loss': 0.0533, 'grad_norm': 21.02019691467285, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.04506222903728485, 'loss_2': 0.008270263671875, 'loss_3': -16.151029586791992, 'loss_4': 0.8562324643135071, 'epoch': 4.28}
{'loss': 0.0626, 'grad_norm': 25.92486572265625, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.054949525743722916, 'loss_2': 0.00763702392578125, 'loss_3': -16.240596771240234, 'loss_4': 0.6773176193237305, 'epoch': 4.29}
{'loss': 0.0307, 'grad_norm': 11.386643409729004, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.029844798147678375, 'loss_2': 0.0008974075317382812, 'loss_3': -16.223133087158203, 'loss_4': 0.035336047410964966, 'epoch': 4.3}
{'loss': 0.0276, 'grad_norm': 7.574954509735107, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.019795924425125122, 'loss_2': 0.007843017578125, 'loss_3': -16.38837242126465, 'loss_4': 0.0181799978017807, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 15:35:57,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:35:57,468 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:51<1:16:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:04,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022761503234505653, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.701, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.018324878066778183, 'eval_loss_2': 0.00443662703037262, 'eval_loss_3': -18.345251083374023, 'eval_loss_4': -0.035162005573511124, 'epoch': 4.3}
{'loss': 0.0619, 'grad_norm': 20.638925552368164, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.05081517994403839, 'loss_2': 0.0111083984375, 'loss_3': -16.242511749267578, 'loss_4': 0.24922454357147217, 'epoch': 4.31}
{'loss': 0.0432, 'grad_norm': 15.014666557312012, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.04314131662249565, 'loss_2': 6.127357482910156e-05, 'loss_3': -16.211334228515625, 'loss_4': 0.014910668134689331, 'epoch': 4.31}
{'loss': 0.035, 'grad_norm': 11.998679161071777, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.03340490162372589, 'loss_2': 0.0015668869018554688, 'loss_3': -15.890033721923828, 'loss_4': 0.30248236656188965, 'epoch': 4.32}
{'loss': 0.0837, 'grad_norm': 15.898545265197754, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.07451290637254715, 'loss_2': 0.00914764404296875, 'loss_3': -16.209339141845703, 'loss_4': 0.2983028292655945, 'epoch': 4.33}
{'loss': 0.0342, 'grad_norm': 10.885729789733887, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.03283257409930229, 'loss_2': 0.001407623291015625, 'loss_3': -16.018836975097656, 'loss_4': 0.02553468383848667, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 15:36:04,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:04,817 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:58<1:16:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:12,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022717710584402084, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.882, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01715981215238571, 'eval_loss_2': 0.005557894706726074, 'eval_loss_3': -18.310413360595703, 'eval_loss_4': -0.11287106573581696, 'epoch': 4.33}
{'loss': 0.0389, 'grad_norm': 11.493029594421387, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.03877260908484459, 'loss_2': 0.00015878677368164062, 'loss_3': -16.216575622558594, 'loss_4': -0.05710399150848389, 'epoch': 4.34}
{'loss': 0.0335, 'grad_norm': 8.547849655151367, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.03087514452636242, 'loss_2': 0.002574920654296875, 'loss_3': -16.15174102783203, 'loss_4': -0.24929583072662354, 'epoch': 4.34}
{'loss': 0.0238, 'grad_norm': 8.166168212890625, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.02333853207528591, 'loss_2': 0.0004940032958984375, 'loss_3': -16.123680114746094, 'loss_4': 0.11855976283550262, 'epoch': 4.35}
{'loss': 0.0612, 'grad_norm': 16.748188018798828, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.0532238595187664, 'loss_2': 0.00797271728515625, 'loss_3': -16.078479766845703, 'loss_4': 0.5690650939941406, 'epoch': 4.35}
{'loss': 0.0502, 'grad_norm': 8.466742515563965, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.042737215757369995, 'loss_2': 0.00746917724609375, 'loss_3': -16.01845359802246, 'loss_4': 0.334012508392334, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 15:36:12,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:12,171 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:06<1:16:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:19,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02448679506778717, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014821364544332027, 'eval_loss_2': 0.009665429592132568, 'eval_loss_3': -18.300537109375, 'eval_loss_4': 0.4172695577144623, 'epoch': 4.36}
{'loss': 0.0266, 'grad_norm': 6.5317158699035645, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.017063913866877556, 'loss_2': 0.00949859619140625, 'loss_3': -16.211910247802734, 'loss_4': 0.8674410581588745, 'epoch': 4.37}
{'loss': 0.0369, 'grad_norm': 18.12041473388672, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.03679869696497917, 'loss_2': 0.0001354217529296875, 'loss_3': -16.084962844848633, 'loss_4': 0.8475867509841919, 'epoch': 4.37}
{'loss': 0.041, 'grad_norm': 12.678064346313477, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.03900012746453285, 'loss_2': 0.001983642578125, 'loss_3': -16.104854583740234, 'loss_4': 0.05996163934469223, 'epoch': 4.38}
{'loss': 0.0402, 'grad_norm': 16.914594650268555, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.033814702183008194, 'loss_2': 0.00637054443359375, 'loss_3': -16.022830963134766, 'loss_4': 0.6986852288246155, 'epoch': 4.38}
{'loss': 0.0336, 'grad_norm': 12.20662784576416, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.02994365617632866, 'loss_2': 0.0036468505859375, 'loss_3': -16.029361724853516, 'loss_4': 0.7687286734580994, 'epoch': 4.39}
[INFO|trainer.py:4228] 2025-01-21 15:36:19,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:19,525 >>   Batch size = 64
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:09<1:16:16,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:36:23,335 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-755
[INFO|configuration_utils.py:420] 2025-01-21 15:36:23,336 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-755/config.json                                                                             
{'eval_loss': 0.016690921038389206, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.832, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013823764398694038, 'eval_loss_2': 0.0028671547770500183, 'eval_loss_3': -18.26095199584961, 'eval_loss_4': 0.8133580088615417, 'epoch': 4.39}
[INFO|modeling_utils.py:2988] 2025-01-21 15:36:23,837 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-755/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:36:23,838 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-755/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:36:23,838 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-755/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:36:24,751 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-600] due to args.save_total_limit
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:14<1:24:09,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:36:28,388 >>
{'loss': 0.0198, 'grad_norm': 6.86435604095459, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.01787993311882019, 'loss_2': 0.001956939697265625, 'loss_3': -15.98411750793457, 'loss_4': 0.3123883306980133, 'epoch': 4.4}
{'loss': 0.0461, 'grad_norm': 23.684755325317383, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.045781459659338, 'loss_2': 0.00031948089599609375, 'loss_3': -16.01177978515625, 'loss_4': 0.7132440805435181, 'epoch': 4.4}
{'loss': 0.0161, 'grad_norm': 6.199233055114746, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.015208416618406773, 'loss_2': 0.0009298324584960938, 'loss_3': -16.116363525390625, 'loss_4': 0.5424699187278748, 'epoch': 4.41}
{'loss': 0.0271, 'grad_norm': 6.93685245513916, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.019577570259571075, 'loss_2': 0.007541656494140625, 'loss_3': -15.881925582885742, 'loss_4': 0.8413562178611755, 'epoch': 4.41}
{'loss': 0.0328, 'grad_norm': 10.370100021362305, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.029393760487437248, 'loss_2': 0.0033817291259765625, 'loss_3': -15.942342758178711, 'loss_4': 0.8945928812026978, 'epoch': 4.42}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:36:28,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:28,388 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:22<1:17:32,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:36:35,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02126726135611534, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.993, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013190594501793385, 'eval_loss_2': 0.008076667785644531, 'eval_loss_3': -18.225114822387695, 'eval_loss_4': 1.0311511754989624, 'epoch': 4.42}
{'loss': 0.0378, 'grad_norm': 10.242815017700195, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.031812649220228195, 'loss_2': 0.0059661865234375, 'loss_3': -16.145854949951172, 'loss_4': 0.7303870320320129, 'epoch': 4.42}
{'loss': 0.0504, 'grad_norm': 17.44761085510254, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.038612015545368195, 'loss_2': 0.01183319091796875, 'loss_3': -15.956367492675781, 'loss_4': 1.0734546184539795, 'epoch': 4.43}
{'loss': 0.055, 'grad_norm': 11.572665214538574, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.03588693216443062, 'loss_2': 0.01910400390625, 'loss_3': -16.197101593017578, 'loss_4': 0.5048470497131348, 'epoch': 4.44}
{'loss': 0.0462, 'grad_norm': 11.855783462524414, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.041333045810461044, 'loss_2': 0.00484466552734375, 'loss_3': -15.77691650390625, 'loss_4': 1.3092364072799683, 'epoch': 4.44}
{'loss': 0.0261, 'grad_norm': 9.883661270141602, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.024346260353922844, 'loss_2': 0.0017299652099609375, 'loss_3': -16.202844619750977, 'loss_4': 1.2153043746948242, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 15:36:35,747 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:35,747 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:29<1:16:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:43,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022601701319217682, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.944, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.016877928748726845, 'eval_loss_2': 0.005723774433135986, 'eval_loss_3': -18.18044662475586, 'eval_loss_4': 1.024775505065918, 'epoch': 4.45}
{'loss': 0.0454, 'grad_norm': 10.726548194885254, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.042499836534261703, 'loss_2': 0.0028781890869140625, 'loss_3': -15.927703857421875, 'loss_4': 1.1238253116607666, 'epoch': 4.45}
{'loss': 0.1154, 'grad_norm': 27.883617401123047, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.11479529738426208, 'loss_2': 0.0006198883056640625, 'loss_3': -15.915125846862793, 'loss_4': 1.3728585243225098, 'epoch': 4.46}
{'loss': 0.0308, 'grad_norm': 10.036734580993652, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.026535427197813988, 'loss_2': 0.00431060791015625, 'loss_3': -15.981063842773438, 'loss_4': 0.4475763440132141, 'epoch': 4.47}
{'loss': 0.0334, 'grad_norm': 9.321795463562012, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.028872424736618996, 'loss_2': 0.004497528076171875, 'loss_3': -15.911051750183105, 'loss_4': 0.8288566470146179, 'epoch': 4.47}
{'loss': 0.0159, 'grad_norm': 7.01682186126709, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.013737441040575504, 'loss_2': 0.0021514892578125, 'loss_3': -15.82056999206543, 'loss_4': 0.8978110551834106, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 15:36:43,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:43,103 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:37<1:15:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:50,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021747063845396042, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.001, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01854977197945118, 'eval_loss_2': 0.003197290003299713, 'eval_loss_3': -18.20311164855957, 'eval_loss_4': 0.847579836845398, 'epoch': 4.48}
{'loss': 0.0284, 'grad_norm': 6.486934661865234, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.018900323659181595, 'loss_2': 0.00946807861328125, 'loss_3': -15.940587997436523, 'loss_4': 0.9519885778427124, 'epoch': 4.48}
{'loss': 0.0312, 'grad_norm': 13.86513614654541, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.031005859375, 'loss_2': 0.00015628337860107422, 'loss_3': -16.069520950317383, 'loss_4': 0.4172927737236023, 'epoch': 4.49}
{'loss': 0.0408, 'grad_norm': 10.646707534790039, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.030711358413100243, 'loss_2': 0.010040283203125, 'loss_3': -16.000499725341797, 'loss_4': 0.5902113914489746, 'epoch': 4.49}
{'loss': 0.0339, 'grad_norm': 9.959978103637695, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.028789393603801727, 'loss_2': 0.00507354736328125, 'loss_3': -15.896267890930176, 'loss_4': 0.548539936542511, 'epoch': 4.5}
{'loss': 0.0369, 'grad_norm': 15.894917488098145, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.03352007269859314, 'loss_2': 0.0033416748046875, 'loss_3': -16.11492347717285, 'loss_4': 0.7774266600608826, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 15:36:50,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:50,457 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:44<1:15:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:36:57,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02112620882689953, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.85, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.017265643924474716, 'eval_loss_2': 0.003860563039779663, 'eval_loss_3': -18.25124740600586, 'eval_loss_4': 0.9052134156227112, 'epoch': 4.51}
{'loss': 0.0428, 'grad_norm': 14.676338195800781, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.03622952476143837, 'loss_2': 0.006542205810546875, 'loss_3': -15.891717910766602, 'loss_4': 0.886717677116394, 'epoch': 4.51}
{'loss': 0.0191, 'grad_norm': 6.501706600189209, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.01725379377603531, 'loss_2': 0.001880645751953125, 'loss_3': -16.04802894592285, 'loss_4': 1.161333441734314, 'epoch': 4.52}
{'loss': 0.0181, 'grad_norm': 6.806159496307373, 'learning_rate': 2.55e-05, 'loss_1': 0.016452575102448463, 'loss_2': 0.0016651153564453125, 'loss_3': -16.123689651489258, 'loss_4': 1.1954724788665771, 'epoch': 4.52}
{'loss': 0.1038, 'grad_norm': 27.21611785888672, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.10300448536872864, 'loss_2': 0.0007905960083007812, 'loss_3': -15.765817642211914, 'loss_4': 1.2911043167114258, 'epoch': 4.53}
{'loss': 0.04, 'grad_norm': 9.855107307434082, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.033019308000802994, 'loss_2': 0.00702667236328125, 'loss_3': -16.00909996032715, 'loss_4': 1.7186177968978882, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 15:36:57,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:36:57,817 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:51<1:15:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:05,183 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025212803855538368, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.702, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.017385641112923622, 'eval_loss_2': 0.007827162742614746, 'eval_loss_3': -18.323123931884766, 'eval_loss_4': 1.2157323360443115, 'epoch': 4.53}
{'loss': 0.0694, 'grad_norm': 19.997060775756836, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.05999666452407837, 'loss_2': 0.0094146728515625, 'loss_3': -16.144332885742188, 'loss_4': 0.9245576858520508, 'epoch': 4.54}
{'loss': 0.0523, 'grad_norm': 12.351106643676758, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.045833032578229904, 'loss_2': 0.006439208984375, 'loss_3': -15.928707122802734, 'loss_4': 1.6034387350082397, 'epoch': 4.55}
{'loss': 0.0331, 'grad_norm': 15.235569953918457, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.024769242852926254, 'loss_2': 0.00830078125, 'loss_3': -16.05972671508789, 'loss_4': 0.9781957268714905, 'epoch': 4.55}
{'loss': 0.0343, 'grad_norm': 10.570775985717773, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.02948230877518654, 'loss_2': 0.00482177734375, 'loss_3': -16.07391357421875, 'loss_4': 1.3860485553741455, 'epoch': 4.56}
{'loss': 0.0488, 'grad_norm': 13.119599342346191, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.036191653460264206, 'loss_2': 0.012603759765625, 'loss_3': -15.855422973632812, 'loss_4': 1.3177731037139893, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 15:37:05,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:05,184 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [19:59<1:15:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:12,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027687110006809235, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.81, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017681604251265526, 'eval_loss_2': 0.01000550389289856, 'eval_loss_3': -18.371349334716797, 'eval_loss_4': 1.4994069337844849, 'epoch': 4.56}
{'loss': 0.0474, 'grad_norm': 9.470850944519043, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.039701685309410095, 'loss_2': 0.00774383544921875, 'loss_3': -16.212373733520508, 'loss_4': 2.0855469703674316, 'epoch': 4.57}
{'loss': 0.0222, 'grad_norm': 9.245747566223145, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.019519072026014328, 'loss_2': 0.002696990966796875, 'loss_3': -16.291744232177734, 'loss_4': 1.2112774848937988, 'epoch': 4.58}
{'loss': 0.0275, 'grad_norm': 5.943727970123291, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.01647546887397766, 'loss_2': 0.01107025146484375, 'loss_3': -16.169498443603516, 'loss_4': 1.486907720565796, 'epoch': 4.58}
{'loss': 0.0306, 'grad_norm': 9.729578018188477, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.03035120479762554, 'loss_2': 0.00021958351135253906, 'loss_3': -16.02138900756836, 'loss_4': 1.6245073080062866, 'epoch': 4.59}
{'loss': 0.0581, 'grad_norm': 18.249008178710938, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.05067808926105499, 'loss_2': 0.007427215576171875, 'loss_3': -15.955926895141602, 'loss_4': 1.0638856887817383, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 15:37:12,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:12,547 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [20:06<1:15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:19,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02243272215127945, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.406, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.019558429718017578, 'eval_loss_2': 0.0028742924332618713, 'eval_loss_3': -18.37590217590332, 'eval_loss_4': 1.5397109985351562, 'epoch': 4.59}
{'loss': 0.0284, 'grad_norm': 8.043526649475098, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.02267182618379593, 'loss_2': 0.005702972412109375, 'loss_3': -16.1804256439209, 'loss_4': 1.6368217468261719, 'epoch': 4.6}
{'loss': 0.0341, 'grad_norm': 10.279003143310547, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.0298879723995924, 'loss_2': 0.00417327880859375, 'loss_3': -16.063697814941406, 'loss_4': 1.0222277641296387, 'epoch': 4.6}
{'loss': 0.0454, 'grad_norm': 12.699722290039062, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.0405837744474411, 'loss_2': 0.004795074462890625, 'loss_3': -15.932628631591797, 'loss_4': 1.382455587387085, 'epoch': 4.61}
{'loss': 0.0261, 'grad_norm': 7.9904961585998535, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.021966394037008286, 'loss_2': 0.004146575927734375, 'loss_3': -15.992027282714844, 'loss_4': 1.4814188480377197, 'epoch': 4.62}
{'loss': 0.0284, 'grad_norm': 7.554468631744385, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.021450556814670563, 'loss_2': 0.00691986083984375, 'loss_3': -16.100500106811523, 'loss_4': 1.888486385345459, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 15:37:19,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:19,913 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:13<1:15:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:27,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02208927646279335, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.196, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01813894882798195, 'eval_loss_2': 0.003950327634811401, 'eval_loss_3': -18.382694244384766, 'eval_loss_4': 1.414371371269226, 'epoch': 4.62}
{'loss': 0.0775, 'grad_norm': 33.75274658203125, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.07216241955757141, 'loss_2': 0.00531768798828125, 'loss_3': -15.940227508544922, 'loss_4': 1.550032377243042, 'epoch': 4.63}
{'loss': 0.0292, 'grad_norm': 7.876981258392334, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.02283211052417755, 'loss_2': 0.006412506103515625, 'loss_3': -15.947998046875, 'loss_4': 1.689382791519165, 'epoch': 4.63}
{'loss': 0.0234, 'grad_norm': 8.385709762573242, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.023092739284038544, 'loss_2': 0.00034618377685546875, 'loss_3': -16.238605499267578, 'loss_4': 1.5927033424377441, 'epoch': 4.64}
{'loss': 0.1012, 'grad_norm': 26.30376434326172, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.10050854831933975, 'loss_2': 0.0007314682006835938, 'loss_3': -16.065237045288086, 'loss_4': 1.717451810836792, 'epoch': 4.65}
{'loss': 0.016, 'grad_norm': 5.31056022644043, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.01409814041107893, 'loss_2': 0.001861572265625, 'loss_3': -16.106159210205078, 'loss_4': 1.4496467113494873, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 15:37:27,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:27,268 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:21<1:15:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:34,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026675458997488022, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.833, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015759941190481186, 'eval_loss_2': 0.010915517807006836, 'eval_loss_3': -18.374780654907227, 'eval_loss_4': 1.4256694316864014, 'epoch': 4.65}
{'loss': 0.0481, 'grad_norm': 12.309223175048828, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.042407017201185226, 'loss_2': 0.00568389892578125, 'loss_3': -16.07961654663086, 'loss_4': 1.6936235427856445, 'epoch': 4.66}
{'loss': 0.0401, 'grad_norm': 10.878165245056152, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.02880210243165493, 'loss_2': 0.0113372802734375, 'loss_3': -16.158470153808594, 'loss_4': 1.5240700244903564, 'epoch': 4.66}
{'loss': 0.0658, 'grad_norm': 18.29621696472168, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.05099507048726082, 'loss_2': 0.0148468017578125, 'loss_3': -16.057538986206055, 'loss_4': 2.033583641052246, 'epoch': 4.67}
{'loss': 0.0657, 'grad_norm': 13.095829963684082, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.04777371883392334, 'loss_2': 0.017913818359375, 'loss_3': -16.055206298828125, 'loss_4': 1.7842680215835571, 'epoch': 4.67}
{'loss': 0.1206, 'grad_norm': 20.04326629638672, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.1005822941660881, 'loss_2': 0.0199737548828125, 'loss_3': -15.91221809387207, 'loss_4': 2.3397440910339355, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 15:37:34,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:34,636 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:28<1:15:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:41,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032217852771282196, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.919, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01635538972914219, 'eval_loss_2': 0.015862464904785156, 'eval_loss_3': -18.373889923095703, 'eval_loss_4': 1.2524865865707397, 'epoch': 4.68}
{'loss': 0.0989, 'grad_norm': 21.821834564208984, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.0746345967054367, 'loss_2': 0.0242156982421875, 'loss_3': -15.86368465423584, 'loss_4': 1.6229667663574219, 'epoch': 4.69}
{'loss': 0.0819, 'grad_norm': 23.202138900756836, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.07067027688026428, 'loss_2': 0.01126861572265625, 'loss_3': -15.98392391204834, 'loss_4': 1.532634973526001, 'epoch': 4.69}
{'loss': 0.0926, 'grad_norm': 24.296358108520508, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.07718341797590256, 'loss_2': 0.01544189453125, 'loss_3': -15.924718856811523, 'loss_4': 0.15491147339344025, 'epoch': 4.7}
{'loss': 0.0345, 'grad_norm': 10.527399063110352, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.030152468010783195, 'loss_2': 0.00437164306640625, 'loss_3': -16.05432891845703, 'loss_4': 0.7480989694595337, 'epoch': 4.7}
{'loss': 0.044, 'grad_norm': 12.817173957824707, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.04008125513792038, 'loss_2': 0.003948211669921875, 'loss_3': -16.132415771484375, 'loss_4': 0.15618309378623962, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 15:37:41,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:41,995 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:35<1:15:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:49,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02022719569504261, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.752, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01596144773066044, 'eval_loss_2': 0.004265747964382172, 'eval_loss_3': -18.34687042236328, 'eval_loss_4': 0.30067387223243713, 'epoch': 4.71}
{'loss': 0.0356, 'grad_norm': 8.721879959106445, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.031192192807793617, 'loss_2': 0.00443267822265625, 'loss_3': -16.14397430419922, 'loss_4': -0.03296400606632233, 'epoch': 4.72}
{'loss': 0.0688, 'grad_norm': 22.89295196533203, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.06390407681465149, 'loss_2': 0.004924774169921875, 'loss_3': -16.299701690673828, 'loss_4': 0.7071106433868408, 'epoch': 4.72}
{'loss': 0.0604, 'grad_norm': 15.494660377502441, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.05959039926528931, 'loss_2': 0.0008220672607421875, 'loss_3': -15.912519454956055, 'loss_4': 0.08092252910137177, 'epoch': 4.73}
{'loss': 0.0793, 'grad_norm': 21.961471557617188, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.075502909719944, 'loss_2': 0.0038299560546875, 'loss_3': -16.2348690032959, 'loss_4': -0.12124913930892944, 'epoch': 4.73}
{'loss': 0.0511, 'grad_norm': 10.200102806091309, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.03907208517193794, 'loss_2': 0.01200103759765625, 'loss_3': -16.132408142089844, 'loss_4': -0.5394617319107056, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 15:37:49,355 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:49,355 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:43<1:15:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:37:56,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02249208278954029, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.095, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.01634744182229042, 'eval_loss_2': 0.0061446428298950195, 'eval_loss_3': -18.352222442626953, 'eval_loss_4': -0.45496898889541626, 'epoch': 4.74}
{'loss': 0.0444, 'grad_norm': 9.048407554626465, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.03547465428709984, 'loss_2': 0.00894927978515625, 'loss_3': -16.193452835083008, 'loss_4': -0.4858427047729492, 'epoch': 4.74}
{'loss': 0.038, 'grad_norm': 10.71264934539795, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.03664124384522438, 'loss_2': 0.0013561248779296875, 'loss_3': -16.23269271850586, 'loss_4': -0.5946099162101746, 'epoch': 4.75}
{'loss': 0.0547, 'grad_norm': 12.794302940368652, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.04767940938472748, 'loss_2': 0.00701904296875, 'loss_3': -16.15301513671875, 'loss_4': 0.06774279475212097, 'epoch': 4.76}
{'loss': 0.0797, 'grad_norm': 23.198671340942383, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.07571128755807877, 'loss_2': 0.0040283203125, 'loss_3': -16.242156982421875, 'loss_4': -0.7611498236656189, 'epoch': 4.76}
{'loss': 0.0658, 'grad_norm': 20.82918357849121, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.06254075467586517, 'loss_2': 0.00323486328125, 'loss_3': -16.14491844177246, 'loss_4': -0.4232332110404968, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 15:37:56,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:37:56,727 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:50<1:15:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:04,085 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01902153715491295, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.574, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.015871655195951462, 'eval_loss_2': 0.003149881958961487, 'eval_loss_3': -18.36034393310547, 'eval_loss_4': -0.7416343092918396, 'epoch': 4.77}
{'loss': 0.0685, 'grad_norm': 14.827913284301758, 'learning_rate': 2.525e-05, 'loss_1': 0.06263940036296844, 'loss_2': 0.00588226318359375, 'loss_3': -16.091543197631836, 'loss_4': -0.5964560508728027, 'epoch': 4.77}
{'loss': 0.0194, 'grad_norm': 6.114485263824463, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.018761036917567253, 'loss_2': 0.000644683837890625, 'loss_3': -16.246694564819336, 'loss_4': -0.8369028568267822, 'epoch': 4.78}
{'loss': 0.1887, 'grad_norm': 38.842037200927734, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.1842404007911682, 'loss_2': 0.004425048828125, 'loss_3': -16.24745750427246, 'loss_4': -0.06916972994804382, 'epoch': 4.78}
{'loss': 0.0422, 'grad_norm': 10.956548690795898, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.0321330763399601, 'loss_2': 0.0100555419921875, 'loss_3': -16.30870819091797, 'loss_4': -0.5674119591712952, 'epoch': 4.79}
{'loss': 0.052, 'grad_norm': 14.949954986572266, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.04715169593691826, 'loss_2': 0.0048065185546875, 'loss_3': -16.33005142211914, 'loss_4': -0.6568005084991455, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 15:38:04,086 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:04,086 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:58<1:14:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:11,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02311553619801998, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.772, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.016165396198630333, 'eval_loss_2': 0.0069501399993896484, 'eval_loss_3': -18.3651065826416, 'eval_loss_4': -0.702907919883728, 'epoch': 4.8}
{'loss': 0.0439, 'grad_norm': 10.345357894897461, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.034829072654247284, 'loss_2': 0.009063720703125, 'loss_3': -16.256072998046875, 'loss_4': -1.1066488027572632, 'epoch': 4.8}
{'loss': 0.0354, 'grad_norm': 9.846683502197266, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.031549930572509766, 'loss_2': 0.00388336181640625, 'loss_3': -16.248592376708984, 'loss_4': -0.6654368042945862, 'epoch': 4.81}
{'loss': 0.0412, 'grad_norm': 12.117514610290527, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.03593927249312401, 'loss_2': 0.005279541015625, 'loss_3': -16.185449600219727, 'loss_4': -0.43502065539360046, 'epoch': 4.81}
{'loss': 0.1036, 'grad_norm': 39.83005142211914, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.10249584168195724, 'loss_2': 0.001071929931640625, 'loss_3': -16.317968368530273, 'loss_4': -0.7217248678207397, 'epoch': 4.82}
{'loss': 0.0565, 'grad_norm': 15.185694694519043, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.05585407093167305, 'loss_2': 0.00060272216796875, 'loss_3': -15.975421905517578, 'loss_4': -1.392529010772705, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 15:38:11,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:11,432 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [21:05<1:14:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:18,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020153775811195374, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.735, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.015831248834729195, 'eval_loss_2': 0.004322528839111328, 'eval_loss_3': -18.310359954833984, 'eval_loss_4': -0.7979134321212769, 'epoch': 4.83}
{'loss': 0.0486, 'grad_norm': 20.948617935180664, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.04127708822488785, 'loss_2': 0.007282257080078125, 'loss_3': -16.051143646240234, 'loss_4': -0.5870072841644287, 'epoch': 4.83}
{'loss': 0.0474, 'grad_norm': 17.181419372558594, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.03675859421491623, 'loss_2': 0.01061248779296875, 'loss_3': -16.247495651245117, 'loss_4': -0.7908470630645752, 'epoch': 4.84}
{'loss': 0.056, 'grad_norm': 19.223451614379883, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.05400944873690605, 'loss_2': 0.0019550323486328125, 'loss_3': -15.909870147705078, 'loss_4': -0.7018376588821411, 'epoch': 4.84}
{'loss': 0.0663, 'grad_norm': 21.363840103149414, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.0642678439617157, 'loss_2': 0.0020656585693359375, 'loss_3': -16.143211364746094, 'loss_4': -1.0222985744476318, 'epoch': 4.85}
{'loss': 0.1154, 'grad_norm': 29.116230010986328, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.11472848802804947, 'loss_2': 0.00069427490234375, 'loss_3': -16.436573028564453, 'loss_4': -0.511920690536499, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 15:38:18,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:18,785 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:12<1:14:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:26,131 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021315906196832657, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.876, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015836745500564575, 'eval_loss_2': 0.005479160696268082, 'eval_loss_3': -18.24768829345703, 'eval_loss_4': -0.6759473085403442, 'epoch': 4.85}
{'loss': 0.0327, 'grad_norm': 9.115078926086426, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.03266577795147896, 'loss_2': 4.8995018005371094e-05, 'loss_3': -16.332473754882812, 'loss_4': -0.6969312429428101, 'epoch': 4.86}
{'loss': 0.0505, 'grad_norm': 15.749822616577148, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.03946230933070183, 'loss_2': 0.011016845703125, 'loss_3': -16.24602508544922, 'loss_4': -0.4058782756328583, 'epoch': 4.87}
{'loss': 0.0332, 'grad_norm': 13.144302368164062, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.031126705929636955, 'loss_2': 0.0020294189453125, 'loss_3': -16.093629837036133, 'loss_4': -0.7784656286239624, 'epoch': 4.87}
{'loss': 0.0294, 'grad_norm': 8.028287887573242, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.024592876434326172, 'loss_2': 0.0047607421875, 'loss_3': -16.31705093383789, 'loss_4': -0.41828885674476624, 'epoch': 4.88}
{'loss': 0.0586, 'grad_norm': 21.566890716552734, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.05684017390012741, 'loss_2': 0.0017147064208984375, 'loss_3': -16.011781692504883, 'loss_4': -1.116108775138855, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 15:38:26,131 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:26,131 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:20<1:14:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:33,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02462681010365486, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.714, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.018833836540579796, 'eval_loss_2': 0.005792975425720215, 'eval_loss_3': -18.211164474487305, 'eval_loss_4': -0.5850737690925598, 'epoch': 4.88}
{'loss': 0.0471, 'grad_norm': 18.618467330932617, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.04473433643579483, 'loss_2': 0.0024051666259765625, 'loss_3': -16.11220932006836, 'loss_4': -0.3666636347770691, 'epoch': 4.89}
{'loss': 0.0348, 'grad_norm': 8.748767852783203, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.02631445787847042, 'loss_2': 0.0084991455078125, 'loss_3': -16.051666259765625, 'loss_4': -0.914170503616333, 'epoch': 4.9}
{'loss': 0.0341, 'grad_norm': 11.111451148986816, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.02965785190463066, 'loss_2': 0.00440216064453125, 'loss_3': -16.24604606628418, 'loss_4': -0.8155955076217651, 'epoch': 4.9}
{'loss': 0.0271, 'grad_norm': 7.977476596832275, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.02511684224009514, 'loss_2': 0.002002716064453125, 'loss_3': -16.334274291992188, 'loss_4': -0.9149268865585327, 'epoch': 4.91}
{'loss': 0.0621, 'grad_norm': 21.27913475036621, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.05826609581708908, 'loss_2': 0.00386810302734375, 'loss_3': -16.126293182373047, 'loss_4': -0.4017408788204193, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 15:38:33,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:33,487 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:27<1:14:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:40,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0180597435683012, 'eval_runtime': 3.825, 'eval_samples_per_second': 267.711, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.013936249539256096, 'eval_loss_2': 0.004123494029045105, 'eval_loss_3': -18.253034591674805, 'eval_loss_4': -0.4518045485019684, 'epoch': 4.91}
{'loss': 0.0442, 'grad_norm': 12.140815734863281, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.03782567009329796, 'loss_2': 0.0064239501953125, 'loss_3': -16.23002815246582, 'loss_4': -0.43157702684402466, 'epoch': 4.92}
{'loss': 0.1253, 'grad_norm': 33.43647003173828, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.11539870500564575, 'loss_2': 0.009918212890625, 'loss_3': -16.198951721191406, 'loss_4': -0.23597821593284607, 'epoch': 4.92}
{'loss': 0.0453, 'grad_norm': 10.351768493652344, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.036635998636484146, 'loss_2': 0.00868988037109375, 'loss_3': -16.274559020996094, 'loss_4': -0.8172786831855774, 'epoch': 4.93}
{'loss': 0.0471, 'grad_norm': 17.536327362060547, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.042689722031354904, 'loss_2': 0.0043792724609375, 'loss_3': -16.23630714416504, 'loss_4': -0.40639880299568176, 'epoch': 4.94}
{'loss': 0.036, 'grad_norm': 11.922375679016113, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.03561234846711159, 'loss_2': 0.0004096031188964844, 'loss_3': -16.232221603393555, 'loss_4': -0.520681619644165, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 15:38:40,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:40,861 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:34<1:14:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:38:48,218 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0178203284740448, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.588, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01413816213607788, 'eval_loss_2': 0.003682166337966919, 'eval_loss_3': -18.26297378540039, 'eval_loss_4': -0.2541919946670532, 'epoch': 4.94}
{'loss': 0.0361, 'grad_norm': 18.137710571289062, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.030522942543029785, 'loss_2': 0.0055694580078125, 'loss_3': -16.275745391845703, 'loss_4': -0.11922325193881989, 'epoch': 4.95}
{'loss': 0.0537, 'grad_norm': 14.923002243041992, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.05350236967206001, 'loss_2': 0.0002200603485107422, 'loss_3': -16.087488174438477, 'loss_4': -0.35790908336639404, 'epoch': 4.95}
{'loss': 0.0189, 'grad_norm': 6.221440315246582, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.01764567755162716, 'loss_2': 0.001300811767578125, 'loss_3': -16.33233070373535, 'loss_4': -0.4892638921737671, 'epoch': 4.96}
{'loss': 0.0359, 'grad_norm': 13.292762756347656, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.03269095718860626, 'loss_2': 0.003173828125, 'loss_3': -15.89295768737793, 'loss_4': -0.38648721575737, 'epoch': 4.97}
{'loss': 0.032, 'grad_norm': 13.014281272888184, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.03179120644927025, 'loss_2': 0.0002124309539794922, 'loss_3': -16.36026954650879, 'loss_4': -0.3883485794067383, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 15:38:48,218 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:48,218 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:41<1:06:55,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 15:38:55,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019135963171720505, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.033, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013700315728783607, 'eval_loss_2': 0.005435645580291748, 'eval_loss_3': -18.333675384521484, 'eval_loss_4': -0.048845961689949036, 'epoch': 4.97}
{'loss': 0.0234, 'grad_norm': 7.22191858291626, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.02319236844778061, 'loss_2': 0.00017368793487548828, 'loss_3': -16.32902717590332, 'loss_4': -0.22598561644554138, 'epoch': 4.98}
{'loss': 0.0843, 'grad_norm': 17.691484451293945, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.07927247881889343, 'loss_2': 0.0049896240234375, 'loss_3': -16.21978187561035, 'loss_4': -0.01169808954000473, 'epoch': 4.98}
{'loss': 0.0298, 'grad_norm': 9.076301574707031, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.02562885545194149, 'loss_2': 0.00418853759765625, 'loss_3': -16.285249710083008, 'loss_4': 0.13016512989997864, 'epoch': 4.99}
{'loss': 0.0214, 'grad_norm': 5.899621486663818, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.016331816092133522, 'loss_2': 0.005023956298828125, 'loss_3': -16.347570419311523, 'loss_4': 0.2682132124900818, 'epoch': 4.99}
{'loss': 0.0143, 'grad_norm': 7.342174530029297, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.012355680577456951, 'loss_2': 0.0019245147705078125, 'loss_3': -16.45781135559082, 'loss_4': 0.2508719563484192, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 15:38:55,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:38:55,216 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:49<1:13:18,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:39:02,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018863297998905182, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.745, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01346752978861332, 'eval_loss_2': 0.005395770072937012, 'eval_loss_3': -18.363882064819336, 'eval_loss_4': 0.18074098229408264, 'epoch': 5.0}
{'loss': 0.0265, 'grad_norm': 7.172229290008545, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.02089257352054119, 'loss_2': 0.00556182861328125, 'loss_3': -16.151683807373047, 'loss_4': 0.6268161535263062, 'epoch': 5.01}
{'loss': 0.0316, 'grad_norm': 8.422679901123047, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.029213927686214447, 'loss_2': 0.0023784637451171875, 'loss_3': -16.349529266357422, 'loss_4': 0.5986477732658386, 'epoch': 5.01}
{'loss': 0.0316, 'grad_norm': 7.864835739135742, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.027190931141376495, 'loss_2': 0.004364013671875, 'loss_3': -16.288639068603516, 'loss_4': 0.09105049073696136, 'epoch': 5.02}
{'loss': 0.0447, 'grad_norm': 13.820034980773926, 'learning_rate': 2.5e-05, 'loss_1': 0.041193537414073944, 'loss_2': 0.003513336181640625, 'loss_3': -16.163755416870117, 'loss_4': 0.6200570464134216, 'epoch': 5.02}
{'loss': 0.0271, 'grad_norm': 8.761999130249023, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.02496136724948883, 'loss_2': 0.002185821533203125, 'loss_3': -16.398426055908203, 'loss_4': 0.8171844482421875, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 15:39:02,613 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:02,613 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:56<1:14:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:09,966 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01942409761250019, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.014620918780565262, 'eval_loss_2': 0.004803180694580078, 'eval_loss_3': -18.378799438476562, 'eval_loss_4': 0.38880079984664917, 'epoch': 5.03}
{'loss': 0.0179, 'grad_norm': 6.523583889007568, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.016978638246655464, 'loss_2': 0.000873565673828125, 'loss_3': -16.483776092529297, 'loss_4': 0.1132010966539383, 'epoch': 5.03}
{'loss': 0.0653, 'grad_norm': 14.470131874084473, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.052989885210990906, 'loss_2': 0.0123138427734375, 'loss_3': -16.28986358642578, 'loss_4': 0.2270534336566925, 'epoch': 5.04}
{'loss': 0.0369, 'grad_norm': 7.39589786529541, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.026008708402514458, 'loss_2': 0.0109405517578125, 'loss_3': -16.276899337768555, 'loss_4': 0.6952512264251709, 'epoch': 5.05}
{'loss': 0.0879, 'grad_norm': 27.167118072509766, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.0856243148446083, 'loss_2': 0.00225067138671875, 'loss_3': -16.238117218017578, 'loss_4': 1.2499384880065918, 'epoch': 5.05}
{'loss': 0.0734, 'grad_norm': 21.57177734375, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.06040806323289871, 'loss_2': 0.0129852294921875, 'loss_3': -16.278076171875, 'loss_4': 0.9814040064811707, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 15:39:09,966 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:09,966 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [22:03<1:14:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:17,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02002997323870659, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.5, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.015415530651807785, 'eval_loss_2': 0.004614442586898804, 'eval_loss_3': -18.411457061767578, 'eval_loss_4': 0.6973886489868164, 'epoch': 5.06}
{'loss': 0.0412, 'grad_norm': 14.23139476776123, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.03792981803417206, 'loss_2': 0.00323486328125, 'loss_3': -16.53258514404297, 'loss_4': 1.3020555973052979, 'epoch': 5.06}
{'loss': 0.074, 'grad_norm': 27.563674926757812, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.07029591500759125, 'loss_2': 0.003692626953125, 'loss_3': -16.335025787353516, 'loss_4': 1.2069675922393799, 'epoch': 5.07}
{'loss': 0.0631, 'grad_norm': 32.810909271240234, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.0625799223780632, 'loss_2': 0.0005564689636230469, 'loss_3': -16.501022338867188, 'loss_4': 1.3643755912780762, 'epoch': 5.08}
{'loss': 0.0619, 'grad_norm': 11.179043769836426, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.051331114023923874, 'loss_2': 0.01055145263671875, 'loss_3': -16.40196990966797, 'loss_4': 0.5563365817070007, 'epoch': 5.08}
{'loss': 0.0308, 'grad_norm': 9.465802192687988, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.030600091442465782, 'loss_2': 0.00020647048950195312, 'loss_3': -16.45168113708496, 'loss_4': 1.284064769744873, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 15:39:17,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:17,332 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [22:11<1:14:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:24,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023051999509334564, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.759, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.016950510442256927, 'eval_loss_2': 0.006101489067077637, 'eval_loss_3': -18.418411254882812, 'eval_loss_4': 0.852774441242218, 'epoch': 5.09}
{'loss': 0.0339, 'grad_norm': 7.470934867858887, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.024427849799394608, 'loss_2': 0.00942230224609375, 'loss_3': -16.39889144897461, 'loss_4': 1.1658823490142822, 'epoch': 5.09}
{'loss': 0.0199, 'grad_norm': 6.794251918792725, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.01933814212679863, 'loss_2': 0.0005693435668945312, 'loss_3': -16.269418716430664, 'loss_4': 1.186191201210022, 'epoch': 5.1}
{'loss': 0.0944, 'grad_norm': 17.99318504333496, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.0847671627998352, 'loss_2': 0.0096282958984375, 'loss_3': -16.200599670410156, 'loss_4': 1.1460375785827637, 'epoch': 5.1}
{'loss': 0.0414, 'grad_norm': 7.736607551574707, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.030181482434272766, 'loss_2': 0.01116943359375, 'loss_3': -16.29078483581543, 'loss_4': 1.0516576766967773, 'epoch': 5.11}
{'loss': 0.0331, 'grad_norm': 10.168538093566895, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.026239652186632156, 'loss_2': 0.006866455078125, 'loss_3': -16.468822479248047, 'loss_4': 0.8513835668563843, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 15:39:24,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:24,691 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:18<1:14:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:32,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019448228180408478, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01553697232156992, 'eval_loss_2': 0.003911256790161133, 'eval_loss_3': -18.392772674560547, 'eval_loss_4': 0.9868780970573425, 'epoch': 5.12}
{'loss': 0.0496, 'grad_norm': 16.523143768310547, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.04633651673793793, 'loss_2': 0.003284454345703125, 'loss_3': -16.180156707763672, 'loss_4': 1.2912582159042358, 'epoch': 5.12}
{'loss': 0.0432, 'grad_norm': 16.110445022583008, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.038453359156847, 'loss_2': 0.00476837158203125, 'loss_3': -16.521484375, 'loss_4': 0.9341180324554443, 'epoch': 5.13}
{'loss': 0.0337, 'grad_norm': 10.1411771774292, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.03329874202609062, 'loss_2': 0.00042629241943359375, 'loss_3': -16.33696937561035, 'loss_4': 1.606310486793518, 'epoch': 5.13}
{'loss': 0.1166, 'grad_norm': 23.489234924316406, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.1148352101445198, 'loss_2': 0.0017375946044921875, 'loss_3': -16.236804962158203, 'loss_4': 1.683675765991211, 'epoch': 5.14}
{'loss': 0.0382, 'grad_norm': 16.374393463134766, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.03419668599963188, 'loss_2': 0.00397491455078125, 'loss_3': -16.313371658325195, 'loss_4': 0.686312198638916, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 15:39:32,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:32,052 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:26<1:14:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:39,412 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018236324191093445, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.194, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014627233147621155, 'eval_loss_2': 0.00360909104347229, 'eval_loss_3': -18.373153686523438, 'eval_loss_4': 0.9576427340507507, 'epoch': 5.15}
{'loss': 0.0363, 'grad_norm': 11.039259910583496, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.02977139875292778, 'loss_2': 0.006561279296875, 'loss_3': -16.4117431640625, 'loss_4': 0.9401726126670837, 'epoch': 5.15}
{'loss': 0.0374, 'grad_norm': 8.659961700439453, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.03215707466006279, 'loss_2': 0.0052032470703125, 'loss_3': -16.457637786865234, 'loss_4': 1.491747260093689, 'epoch': 5.16}
{'loss': 0.0329, 'grad_norm': 8.271029472351074, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.030523603782057762, 'loss_2': 0.002349853515625, 'loss_3': -16.39264488220215, 'loss_4': 1.1014212369918823, 'epoch': 5.16}
{'loss': 0.0329, 'grad_norm': 10.426813125610352, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.03018948808312416, 'loss_2': 0.002666473388671875, 'loss_3': -16.304180145263672, 'loss_4': 1.0662121772766113, 'epoch': 5.17}
{'loss': 0.0386, 'grad_norm': 9.485570907592773, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.033806659281253815, 'loss_2': 0.004802703857421875, 'loss_3': -16.405475616455078, 'loss_4': 1.0660672187805176, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 15:39:39,412 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:39,412 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:33<1:13:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:46,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023787062615156174, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.143, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01632646843791008, 'eval_loss_2': 0.007460594177246094, 'eval_loss_3': -18.34073257446289, 'eval_loss_4': 1.0204113721847534, 'epoch': 5.17}
{'loss': 0.025, 'grad_norm': 7.2957587242126465, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.021203823387622833, 'loss_2': 0.00383758544921875, 'loss_3': -16.27235984802246, 'loss_4': 1.0161525011062622, 'epoch': 5.18}
{'loss': 0.0411, 'grad_norm': 9.908259391784668, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.03183981403708458, 'loss_2': 0.00922393798828125, 'loss_3': -16.249876022338867, 'loss_4': 0.985055685043335, 'epoch': 5.19}
{'loss': 0.0358, 'grad_norm': 9.069865226745605, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.028584301471710205, 'loss_2': 0.00722503662109375, 'loss_3': -16.161123275756836, 'loss_4': 0.8167939186096191, 'epoch': 5.19}
{'loss': 0.0285, 'grad_norm': 10.134390830993652, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.026790622621774673, 'loss_2': 0.0016651153564453125, 'loss_3': -16.346031188964844, 'loss_4': 0.8584648966789246, 'epoch': 5.2}
{'loss': 0.0319, 'grad_norm': 10.577438354492188, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.027657419443130493, 'loss_2': 0.004268646240234375, 'loss_3': -16.148300170898438, 'loss_4': 0.8908767700195312, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 15:39:46,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:46,759 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:40<1:13:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:39:54,114 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021593570709228516, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01659134030342102, 'eval_loss_2': 0.005002230405807495, 'eval_loss_3': -18.31516456604004, 'eval_loss_4': 1.069514274597168, 'epoch': 5.2}
{'loss': 0.0403, 'grad_norm': 9.735100746154785, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.031247952952980995, 'loss_2': 0.009002685546875, 'loss_3': -16.360950469970703, 'loss_4': 1.2631323337554932, 'epoch': 5.21}
{'loss': 0.1655, 'grad_norm': 31.646406173706055, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.1571132093667984, 'loss_2': 0.00838470458984375, 'loss_3': -16.26519775390625, 'loss_4': 1.1877763271331787, 'epoch': 5.22}
{'loss': 0.0308, 'grad_norm': 9.030868530273438, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.023325426504015923, 'loss_2': 0.00748443603515625, 'loss_3': -16.32035255432129, 'loss_4': 0.5855692625045776, 'epoch': 5.22}
{'loss': 0.0703, 'grad_norm': 17.650020599365234, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.061237383633852005, 'loss_2': 0.0091094970703125, 'loss_3': -16.32530975341797, 'loss_4': 0.9417456388473511, 'epoch': 5.23}
{'loss': 0.0491, 'grad_norm': 15.275390625, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.04657944291830063, 'loss_2': 0.002544403076171875, 'loss_3': -16.28595733642578, 'loss_4': 1.2184326648712158, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 15:39:54,114 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:39:54,114 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:48<1:13:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:01,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018226664513349533, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.649, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014796964824199677, 'eval_loss_2': 0.0034296996891498566, 'eval_loss_3': -18.31058692932129, 'eval_loss_4': 1.021649718284607, 'epoch': 5.23}
{'loss': 0.0255, 'grad_norm': 6.488210201263428, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.01700158230960369, 'loss_2': 0.00848388671875, 'loss_3': -16.366056442260742, 'loss_4': 1.1769006252288818, 'epoch': 5.24}
{'loss': 0.0486, 'grad_norm': 13.353917121887207, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.0404827818274498, 'loss_2': 0.008087158203125, 'loss_3': -16.363967895507812, 'loss_4': 0.9721335172653198, 'epoch': 5.24}
{'loss': 0.0235, 'grad_norm': 6.966586112976074, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.019654300063848495, 'loss_2': 0.0038852691650390625, 'loss_3': -16.417827606201172, 'loss_4': 1.1337504386901855, 'epoch': 5.25}
{'loss': 0.0843, 'grad_norm': 21.994232177734375, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.08214350044727325, 'loss_2': 0.0021209716796875, 'loss_3': -16.147693634033203, 'loss_4': 1.4842842817306519, 'epoch': 5.26}
{'loss': 0.0339, 'grad_norm': 10.126367568969727, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.03328976780176163, 'loss_2': 0.0006375312805175781, 'loss_3': -16.09300994873047, 'loss_4': 1.4663496017456055, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 15:40:01,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:01,467 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:55<1:13:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:08,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02269364520907402, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01790822297334671, 'eval_loss_2': 0.004785418510437012, 'eval_loss_3': -18.33038902282715, 'eval_loss_4': 1.1606563329696655, 'epoch': 5.26}
{'loss': 0.0203, 'grad_norm': 6.345246315002441, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.01585800014436245, 'loss_2': 0.00444793701171875, 'loss_3': -16.443988800048828, 'loss_4': 1.0809744596481323, 'epoch': 5.27}
{'loss': 0.0305, 'grad_norm': 8.543365478515625, 'learning_rate': 2.475e-05, 'loss_1': 0.024713590741157532, 'loss_2': 0.00577545166015625, 'loss_3': -16.170257568359375, 'loss_4': 1.292973279953003, 'epoch': 5.27}
{'loss': 0.026, 'grad_norm': 7.306326389312744, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.02315432019531727, 'loss_2': 0.00283050537109375, 'loss_3': -16.141128540039062, 'loss_4': 1.3591523170471191, 'epoch': 5.28}
{'loss': 0.0439, 'grad_norm': 8.795103073120117, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.02859298326075077, 'loss_2': 0.01531219482421875, 'loss_3': -16.220970153808594, 'loss_4': 1.2698246240615845, 'epoch': 5.28}
{'loss': 0.0361, 'grad_norm': 8.278529167175293, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.02382778748869896, 'loss_2': 0.01227569580078125, 'loss_3': -16.21375846862793, 'loss_4': 1.5267674922943115, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 15:40:08,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:08,820 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [23:02<1:13:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:16,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029279522597789764, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.894, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01863436959683895, 'eval_loss_2': 0.010645151138305664, 'eval_loss_3': -18.297351837158203, 'eval_loss_4': 1.246276617050171, 'epoch': 5.29}
{'loss': 0.0498, 'grad_norm': 10.753990173339844, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.039551105350255966, 'loss_2': 0.01020050048828125, 'loss_3': -16.163360595703125, 'loss_4': 1.7609260082244873, 'epoch': 5.3}
{'loss': 0.0676, 'grad_norm': 25.987796783447266, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.057482995092868805, 'loss_2': 0.0101318359375, 'loss_3': -16.014753341674805, 'loss_4': 1.4275670051574707, 'epoch': 5.3}
{'loss': 0.0279, 'grad_norm': 9.61374282836914, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.01855665072798729, 'loss_2': 0.00933837890625, 'loss_3': -16.16965103149414, 'loss_4': 1.83345627784729, 'epoch': 5.31}
{'loss': 0.0477, 'grad_norm': 11.948723793029785, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.036798108369112015, 'loss_2': 0.01087188720703125, 'loss_3': -16.201196670532227, 'loss_4': 1.6353991031646729, 'epoch': 5.31}
{'loss': 0.0549, 'grad_norm': 17.37198829650879, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.04145316779613495, 'loss_2': 0.0134429931640625, 'loss_3': -16.153106689453125, 'loss_4': 1.350818395614624, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 15:40:16,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:16,175 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:10<1:13:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:23,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021238381043076515, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.513, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.016615476459264755, 'eval_loss_2': 0.004622906446456909, 'eval_loss_3': -18.23078155517578, 'eval_loss_4': 1.2572250366210938, 'epoch': 5.32}
{'loss': 0.028, 'grad_norm': 8.112593650817871, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.020175820216536522, 'loss_2': 0.007785797119140625, 'loss_3': -16.102262496948242, 'loss_4': 1.480028510093689, 'epoch': 5.33}
{'loss': 0.0142, 'grad_norm': 5.771795272827148, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.013237398117780685, 'loss_2': 0.0009174346923828125, 'loss_3': -16.081321716308594, 'loss_4': 1.3515535593032837, 'epoch': 5.33}
{'loss': 0.0386, 'grad_norm': 10.635310173034668, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.037058766931295395, 'loss_2': 0.0014972686767578125, 'loss_3': -15.943994522094727, 'loss_4': 1.7616539001464844, 'epoch': 5.34}
{'loss': 0.0314, 'grad_norm': 7.716678619384766, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.022151390090584755, 'loss_2': 0.009246826171875, 'loss_3': -15.989274978637695, 'loss_4': 1.279212236404419, 'epoch': 5.34}
{'loss': 0.0255, 'grad_norm': 8.53359603881836, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.023065492510795593, 'loss_2': 0.002445220947265625, 'loss_3': -16.095962524414062, 'loss_4': 1.5793412923812866, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 15:40:23,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:23,520 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:17<1:13:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:30,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020152412354946136, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.134, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015291579067707062, 'eval_loss_2': 0.004860833287239075, 'eval_loss_3': -18.189130783081055, 'eval_loss_4': 1.4516795873641968, 'epoch': 5.35}
{'loss': 0.0282, 'grad_norm': 12.872146606445312, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.026366794481873512, 'loss_2': 0.0018100738525390625, 'loss_3': -15.980175971984863, 'loss_4': 1.5325590372085571, 'epoch': 5.35}
{'loss': 0.0469, 'grad_norm': 13.25083065032959, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.045822206884622574, 'loss_2': 0.0010471343994140625, 'loss_3': -16.08881378173828, 'loss_4': 1.4038786888122559, 'epoch': 5.36}
{'loss': 0.02, 'grad_norm': 7.445420742034912, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.014944689348340034, 'loss_2': 0.00502777099609375, 'loss_3': -16.01448631286621, 'loss_4': 1.9100641012191772, 'epoch': 5.37}
{'loss': 0.0216, 'grad_norm': 7.172557830810547, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.018603701144456863, 'loss_2': 0.002979278564453125, 'loss_3': -15.949783325195312, 'loss_4': 1.0937159061431885, 'epoch': 5.37}
{'loss': 0.0759, 'grad_norm': 25.064380645751953, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.07149388641119003, 'loss_2': 0.00443267822265625, 'loss_3': -16.073074340820312, 'loss_4': 1.9624983072280884, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 15:40:30,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:30,871 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:24<1:13:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:38,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019813172519207, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.58, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.015432724729180336, 'eval_loss_2': 0.004380449652671814, 'eval_loss_3': -18.143604278564453, 'eval_loss_4': 1.7421214580535889, 'epoch': 5.38}
{'loss': 0.0161, 'grad_norm': 6.457709789276123, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.015345131978392601, 'loss_2': 0.0007863044738769531, 'loss_3': -16.08367919921875, 'loss_4': 1.1687051057815552, 'epoch': 5.38}
{'loss': 0.0337, 'grad_norm': 15.60815143585205, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.03329763188958168, 'loss_2': 0.0004112720489501953, 'loss_3': -15.972142219543457, 'loss_4': 1.526658058166504, 'epoch': 5.39}
{'loss': 0.0262, 'grad_norm': 10.531379699707031, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.025350499898195267, 'loss_2': 0.0008764266967773438, 'loss_3': -16.05168914794922, 'loss_4': 1.8088805675506592, 'epoch': 5.4}
{'loss': 0.0407, 'grad_norm': 12.94556999206543, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.039532944560050964, 'loss_2': 0.0011444091796875, 'loss_3': -15.844765663146973, 'loss_4': 1.639500617980957, 'epoch': 5.4}
{'loss': 0.0306, 'grad_norm': 7.902041912078857, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.02200588397681713, 'loss_2': 0.008575439453125, 'loss_3': -15.996935844421387, 'loss_4': 2.4263341426849365, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 15:40:38,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:38,231 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:32<1:13:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:45,583 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02048908919095993, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015721136704087257, 'eval_loss_2': 0.004767954349517822, 'eval_loss_3': -18.16934585571289, 'eval_loss_4': 1.9951834678649902, 'epoch': 5.41}
{'loss': 0.0326, 'grad_norm': 11.726834297180176, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.029230961576104164, 'loss_2': 0.00341033935546875, 'loss_3': -15.948498725891113, 'loss_4': 2.314455509185791, 'epoch': 5.41}
{'loss': 0.0383, 'grad_norm': 9.230401039123535, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.03697910159826279, 'loss_2': 0.001312255859375, 'loss_3': -16.02627182006836, 'loss_4': 2.149625539779663, 'epoch': 5.42}
{'loss': 0.0394, 'grad_norm': 11.998512268066406, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.02642122469842434, 'loss_2': 0.01296234130859375, 'loss_3': -15.992088317871094, 'loss_4': 1.7980965375900269, 'epoch': 5.42}
{'loss': 0.031, 'grad_norm': 8.970996856689453, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.02496197633445263, 'loss_2': 0.0059967041015625, 'loss_3': -15.84875774383545, 'loss_4': 1.7780711650848389, 'epoch': 5.43}
{'loss': 0.0261, 'grad_norm': 11.26131534576416, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.0255192331969738, 'loss_2': 0.0005326271057128906, 'loss_3': -16.09621810913086, 'loss_4': 1.9792993068695068, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 15:40:45,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:45,583 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:39<1:13:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:40:52,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022661738097667694, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015532382763922215, 'eval_loss_2': 0.007129356265068054, 'eval_loss_3': -18.15538787841797, 'eval_loss_4': 2.153329372406006, 'epoch': 5.44}
{'loss': 0.0365, 'grad_norm': 9.891965866088867, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.030847402289509773, 'loss_2': 0.0056304931640625, 'loss_3': -15.947929382324219, 'loss_4': 2.212578773498535, 'epoch': 5.44}
{'loss': 0.0215, 'grad_norm': 6.574254512786865, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.018114900216460228, 'loss_2': 0.0034160614013671875, 'loss_3': -16.267425537109375, 'loss_4': 2.430204391479492, 'epoch': 5.45}
{'loss': 0.0336, 'grad_norm': 13.63515853881836, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.030367879197001457, 'loss_2': 0.003276824951171875, 'loss_3': -15.861800193786621, 'loss_4': 2.168419122695923, 'epoch': 5.45}
{'loss': 0.1416, 'grad_norm': 22.100969314575195, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.13780979812145233, 'loss_2': 0.003753662109375, 'loss_3': -16.08388900756836, 'loss_4': 2.6187098026275635, 'epoch': 5.46}
{'loss': 0.0287, 'grad_norm': 7.414577484130859, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.02138655260205269, 'loss_2': 0.00734710693359375, 'loss_3': -16.181629180908203, 'loss_4': 2.2716293334960938, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 15:40:52,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:40:52,942 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:46<1:13:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:00,305 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020841538906097412, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.909, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015217936597764492, 'eval_loss_2': 0.0056236013770103455, 'eval_loss_3': -18.173370361328125, 'eval_loss_4': 2.189025640487671, 'epoch': 5.47}
{'loss': 0.0508, 'grad_norm': 14.807962417602539, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.04285312816500664, 'loss_2': 0.00791168212890625, 'loss_3': -15.92154598236084, 'loss_4': 2.398056983947754, 'epoch': 5.47}
{'loss': 0.0353, 'grad_norm': 9.505287170410156, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.03005204349756241, 'loss_2': 0.005268096923828125, 'loss_3': -16.11290168762207, 'loss_4': 1.912437081336975, 'epoch': 5.48}
{'loss': 0.043, 'grad_norm': 12.310248374938965, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.04123114049434662, 'loss_2': 0.0018177032470703125, 'loss_3': -15.820570945739746, 'loss_4': 1.970914602279663, 'epoch': 5.48}
{'loss': 0.0352, 'grad_norm': 10.007828712463379, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.03147214278578758, 'loss_2': 0.00376129150390625, 'loss_3': -16.156402587890625, 'loss_4': 1.9490505456924438, 'epoch': 5.49}
{'loss': 0.0347, 'grad_norm': 9.547404289245605, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.02682351879775524, 'loss_2': 0.007904052734375, 'loss_3': -16.16727066040039, 'loss_4': 2.1308441162109375, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 15:41:00,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:00,306 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:54<1:12:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:07,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018089711666107178, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012626530602574348, 'eval_loss_2': 0.0054631829261779785, 'eval_loss_3': -18.17042350769043, 'eval_loss_4': 1.9517567157745361, 'epoch': 5.49}
{'loss': 0.0403, 'grad_norm': 14.388795852661133, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.03224307671189308, 'loss_2': 0.00803375244140625, 'loss_3': -15.974258422851562, 'loss_4': 2.0038914680480957, 'epoch': 5.5}
{'loss': 0.0284, 'grad_norm': 8.715744972229004, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.023533891886472702, 'loss_2': 0.00490570068359375, 'loss_3': -15.957540512084961, 'loss_4': 1.7520509958267212, 'epoch': 5.51}
{'loss': 0.0242, 'grad_norm': 6.337247371673584, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.018075594678521156, 'loss_2': 0.006084442138671875, 'loss_3': -16.214122772216797, 'loss_4': 1.4199784994125366, 'epoch': 5.51}
{'loss': 0.0384, 'grad_norm': 9.5120210647583, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.03332963585853577, 'loss_2': 0.00511932373046875, 'loss_3': -16.040821075439453, 'loss_4': 1.7059767246246338, 'epoch': 5.52}
{'loss': 0.1058, 'grad_norm': 29.148035049438477, 'learning_rate': 2.45e-05, 'loss_1': 0.09872011095285416, 'loss_2': 0.007049560546875, 'loss_3': -16.00979995727539, 'loss_4': 1.4752296209335327, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 15:41:07,665 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:07,665 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [24:01<1:12:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:15,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019105777144432068, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.454, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011285411193966866, 'eval_loss_2': 0.007820367813110352, 'eval_loss_3': -18.18748664855957, 'eval_loss_4': 1.4876856803894043, 'epoch': 5.52}
{'loss': 0.0766, 'grad_norm': 18.431983947753906, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.07322240620851517, 'loss_2': 0.00341033935546875, 'loss_3': -16.040185928344727, 'loss_4': 1.7576680183410645, 'epoch': 5.53}
{'loss': 0.0558, 'grad_norm': 14.390599250793457, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.04453852400183678, 'loss_2': 0.0112457275390625, 'loss_3': -15.791938781738281, 'loss_4': 1.2663962841033936, 'epoch': 5.53}
{'loss': 0.0439, 'grad_norm': 9.665658950805664, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.02547115460038185, 'loss_2': 0.018463134765625, 'loss_3': -15.967376708984375, 'loss_4': 1.4110828638076782, 'epoch': 5.54}
{'loss': 0.0456, 'grad_norm': 11.153252601623535, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.03726484626531601, 'loss_2': 0.00830841064453125, 'loss_3': -16.149206161499023, 'loss_4': 1.093580722808838, 'epoch': 5.55}
{'loss': 0.036, 'grad_norm': 9.044182777404785, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.026610134169459343, 'loss_2': 0.00936126708984375, 'loss_3': -16.277896881103516, 'loss_4': 1.3192932605743408, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 15:41:15,031 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:15,031 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:08<1:12:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:22,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019409431144595146, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011853708885610104, 'eval_loss_2': 0.007555723190307617, 'eval_loss_3': -18.159679412841797, 'eval_loss_4': 1.1504162549972534, 'epoch': 5.55}
{'loss': 0.0306, 'grad_norm': 7.252125263214111, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.022829700261354446, 'loss_2': 0.00774383544921875, 'loss_3': -15.997013092041016, 'loss_4': 1.1063201427459717, 'epoch': 5.56}
{'loss': 0.0299, 'grad_norm': 11.533377647399902, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.025905460119247437, 'loss_2': 0.00402069091796875, 'loss_3': -16.263612747192383, 'loss_4': 1.1776518821716309, 'epoch': 5.56}
{'loss': 0.0353, 'grad_norm': 8.697628021240234, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.02691097930073738, 'loss_2': 0.0083770751953125, 'loss_3': -16.18476104736328, 'loss_4': 0.7026078701019287, 'epoch': 5.57}
{'loss': 0.0298, 'grad_norm': 7.146655082702637, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.024130744859576225, 'loss_2': 0.00566864013671875, 'loss_3': -16.050199508666992, 'loss_4': 1.240114450454712, 'epoch': 5.58}
{'loss': 0.0247, 'grad_norm': 9.100173950195312, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.021067114546895027, 'loss_2': 0.0036182403564453125, 'loss_3': -15.998591423034668, 'loss_4': 1.0329761505126953, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 15:41:22,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:22,385 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:12<1:12:44,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:41:26,379 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-960
[INFO|configuration_utils.py:420] 2025-01-21 15:41:26,380 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-960/config.json                                                                             
{'eval_loss': 0.016170652583241463, 'eval_runtime': 3.9934, 'eval_samples_per_second': 256.423, 'eval_steps_per_second': 4.007, 'eval_loss_1': 0.013310922309756279, 'eval_loss_2': 0.0028597302734851837, 'eval_loss_3': -18.1728515625, 'eval_loss_4': 1.1408003568649292, 'epoch': 5.58}
[INFO|modeling_utils.py:2988] 2025-01-21 15:41:26,864 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-960/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:41:26,866 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-960/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:41:26,866 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-960/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:41:27,777 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-755] due to args.save_total_limit
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:18<1:21:01,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 15:41:31,410 >>
{'loss': 0.0198, 'grad_norm': 7.753170490264893, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.016785912215709686, 'loss_2': 0.0030002593994140625, 'loss_3': -16.08124542236328, 'loss_4': 1.3024927377700806, 'epoch': 5.59}
{'loss': 0.049, 'grad_norm': 14.432853698730469, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.04836665093898773, 'loss_2': 0.0005855560302734375, 'loss_3': -15.853649139404297, 'loss_4': 1.12919282913208, 'epoch': 5.59}
{'loss': 0.0275, 'grad_norm': 7.382374286651611, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.021202387288212776, 'loss_2': 0.006305694580078125, 'loss_3': -16.09477996826172, 'loss_4': 1.3129265308380127, 'epoch': 5.6}
{'loss': 0.0388, 'grad_norm': 13.118550300598145, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.03457380086183548, 'loss_2': 0.00423431396484375, 'loss_3': -15.849853515625, 'loss_4': 0.965868353843689, 'epoch': 5.6}
{'loss': 0.0485, 'grad_norm': 11.974285125732422, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.048109110444784164, 'loss_2': 0.0003833770751953125, 'loss_3': -15.956653594970703, 'loss_4': 1.4480937719345093, 'epoch': 5.61}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:41:31,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:31,410 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:25<1:13:54,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:41:38,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018526088446378708, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01467328891158104, 'eval_loss_2': 0.0038527995347976685, 'eval_loss_3': -18.15580177307129, 'eval_loss_4': 1.3459272384643555, 'epoch': 5.61}
{'loss': 0.0245, 'grad_norm': 7.59393835067749, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.018470309674739838, 'loss_2': 0.005985260009765625, 'loss_3': -15.978394508361816, 'loss_4': 1.6055024862289429, 'epoch': 5.62}
{'loss': 0.0529, 'grad_norm': 11.490477561950684, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.04785663262009621, 'loss_2': 0.004993438720703125, 'loss_3': -16.122238159179688, 'loss_4': 1.4822620153427124, 'epoch': 5.62}
{'loss': 0.0303, 'grad_norm': 8.811094284057617, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.029111681506037712, 'loss_2': 0.0011653900146484375, 'loss_3': -16.080413818359375, 'loss_4': 1.8244919776916504, 'epoch': 5.63}
{'loss': 0.0162, 'grad_norm': 6.129962921142578, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.010491199791431427, 'loss_2': 0.0057525634765625, 'loss_3': -16.017719268798828, 'loss_4': 1.4665086269378662, 'epoch': 5.63}
{'loss': 0.0195, 'grad_norm': 6.631321907043457, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.016337955370545387, 'loss_2': 0.0031948089599609375, 'loss_3': -16.03704071044922, 'loss_4': 1.3356740474700928, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 15:41:38,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:38,754 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:32<1:12:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:41:46,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020605098456144333, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.473, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.013798368163406849, 'eval_loss_2': 0.006806731224060059, 'eval_loss_3': -18.138294219970703, 'eval_loss_4': 1.5168613195419312, 'epoch': 5.64}
{'loss': 0.0362, 'grad_norm': 10.75663948059082, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.02928113378584385, 'loss_2': 0.0069122314453125, 'loss_3': -15.747980117797852, 'loss_4': 1.2322795391082764, 'epoch': 5.65}
{'loss': 0.0465, 'grad_norm': 10.553064346313477, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.03669840097427368, 'loss_2': 0.00980377197265625, 'loss_3': -15.824104309082031, 'loss_4': 0.6947717070579529, 'epoch': 5.65}
{'loss': 0.0365, 'grad_norm': 11.239867210388184, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.03260352462530136, 'loss_2': 0.00385284423828125, 'loss_3': -15.980653762817383, 'loss_4': 1.2802473306655884, 'epoch': 5.66}
{'loss': 0.0217, 'grad_norm': 6.235054969787598, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.01586535945534706, 'loss_2': 0.005859375, 'loss_3': -15.790078163146973, 'loss_4': 1.0077779293060303, 'epoch': 5.66}
{'loss': 0.0437, 'grad_norm': 18.84318733215332, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.03982550650835037, 'loss_2': 0.003871917724609375, 'loss_3': -15.797463417053223, 'loss_4': 1.25052809715271, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 15:41:46,098 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:46,098 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:36<1:12:37,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:41:49,909 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-975
[INFO|configuration_utils.py:420] 2025-01-21 15:41:49,910 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-975/config.json                                                                             
{'eval_loss': 0.01561281830072403, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.762, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010402894578874111, 'eval_loss_2': 0.005209922790527344, 'eval_loss_3': -18.10511016845703, 'eval_loss_4': 1.2280685901641846, 'epoch': 5.67}
[INFO|modeling_utils.py:2988] 2025-01-21 15:41:50,409 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-975/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:41:50,411 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-975/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:41:50,411 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-975/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:41:51,340 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-960] due to args.save_total_limit
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:41<1:20:01,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:41:54,975 >>
{'loss': 0.0372, 'grad_norm': 8.017430305480957, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.02494846098124981, 'loss_2': 0.012298583984375, 'loss_3': -15.572514533996582, 'loss_4': 0.949949324131012, 'epoch': 5.67}
{'loss': 0.0222, 'grad_norm': 5.924737453460693, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.0136005450040102, 'loss_2': 0.0085906982421875, 'loss_3': -15.989297866821289, 'loss_4': 1.3604856729507446, 'epoch': 5.68}
{'loss': 0.0418, 'grad_norm': 12.514592170715332, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.035243045538663864, 'loss_2': 0.0065460205078125, 'loss_3': -16.027009963989258, 'loss_4': 1.0473369359970093, 'epoch': 5.69}
{'loss': 0.0355, 'grad_norm': 9.387035369873047, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.028978591784834862, 'loss_2': 0.006561279296875, 'loss_3': -15.639626502990723, 'loss_4': 1.059039831161499, 'epoch': 5.69}
{'loss': 0.0416, 'grad_norm': 11.881627082824707, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.03657463192939758, 'loss_2': 0.00502777099609375, 'loss_3': -15.712875366210938, 'loss_4': 1.144948124885559, 'epoch': 5.7}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:41:54,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:41:54,975 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:45<1:20:01,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 15:41:58,773 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-980
[INFO|configuration_utils.py:420] 2025-01-21 15:41:58,774 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-980/config.json                                                                             
{'eval_loss': 0.014568856917321682, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.714, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010403119027614594, 'eval_loss_2': 0.004165738821029663, 'eval_loss_3': -18.075021743774414, 'eval_loss_4': 1.2569336891174316, 'epoch': 5.7}
[INFO|modeling_utils.py:2988] 2025-01-21 15:41:59,263 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-980/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:41:59,264 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-980/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:41:59,265 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-980/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:42:00,231 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-975] due to args.save_total_limit
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:50<1:21:16,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 15:42:03,871 >>
{'loss': 0.028, 'grad_norm': 8.388089179992676, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.021641839295625687, 'loss_2': 0.00632476806640625, 'loss_3': -15.877988815307617, 'loss_4': 0.9235116243362427, 'epoch': 5.7}
{'loss': 0.0479, 'grad_norm': 18.851093292236328, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.046122219413518906, 'loss_2': 0.0018253326416015625, 'loss_3': -16.024158477783203, 'loss_4': 1.5026826858520508, 'epoch': 5.71}
{'loss': 0.0266, 'grad_norm': 9.496299743652344, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.020941054448485374, 'loss_2': 0.0056304931640625, 'loss_3': -15.763877868652344, 'loss_4': 1.1425482034683228, 'epoch': 5.72}
{'loss': 0.0223, 'grad_norm': 6.544616222381592, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.016187479719519615, 'loss_2': 0.00611114501953125, 'loss_3': -15.800558090209961, 'loss_4': 0.7588291168212891, 'epoch': 5.72}
{'loss': 0.0693, 'grad_norm': 13.73415756225586, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.06245388090610504, 'loss_2': 0.0068817138671875, 'loss_3': -15.73910140991211, 'loss_4': 0.9010592699050903, 'epoch': 5.73}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:42:03,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:03,871 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:57<1:13:27,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:42:11,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019978277385234833, 'eval_runtime': 3.7933, 'eval_samples_per_second': 269.949, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.013362637721002102, 'eval_loss_2': 0.006615638732910156, 'eval_loss_3': -18.059614181518555, 'eval_loss_4': 0.8521509170532227, 'epoch': 5.73}
{'loss': 0.0215, 'grad_norm': 7.918024063110352, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.021275456994771957, 'loss_2': 0.0002422332763671875, 'loss_3': -15.798433303833008, 'loss_4': 1.0901848077774048, 'epoch': 5.73}
{'loss': 0.0199, 'grad_norm': 5.980563640594482, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.013583088293671608, 'loss_2': 0.0063323974609375, 'loss_3': -15.696761131286621, 'loss_4': 0.5836193561553955, 'epoch': 5.74}
{'loss': 0.0304, 'grad_norm': 14.345463752746582, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.027254188433289528, 'loss_2': 0.00311279296875, 'loss_3': -15.887064933776855, 'loss_4': 0.4558025300502777, 'epoch': 5.74}
{'loss': 0.0591, 'grad_norm': 13.676200866699219, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.05242864787578583, 'loss_2': 0.00662994384765625, 'loss_3': -15.704608917236328, 'loss_4': 0.05221543461084366, 'epoch': 5.75}
{'loss': 0.0262, 'grad_norm': 13.898188591003418, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.024885378777980804, 'loss_2': 0.0013065338134765625, 'loss_3': -15.831818580627441, 'loss_4': 0.5039546489715576, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 15:42:11,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:11,199 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [25:05<1:12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:18,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0173862986266613, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012504976242780685, 'eval_loss_2': 0.004881322383880615, 'eval_loss_3': -18.049983978271484, 'eval_loss_4': 0.36169666051864624, 'epoch': 5.76}
{'loss': 0.0437, 'grad_norm': 14.260435104370117, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.036867983639240265, 'loss_2': 0.006870269775390625, 'loss_3': -15.909265518188477, 'loss_4': 0.3677791655063629, 'epoch': 5.76}
{'loss': 0.0242, 'grad_norm': 7.444382190704346, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.02085837908089161, 'loss_2': 0.003376007080078125, 'loss_3': -15.761800765991211, 'loss_4': 0.2667738199234009, 'epoch': 5.77}
{'loss': 0.0317, 'grad_norm': 9.259106636047363, 'learning_rate': 2.425e-05, 'loss_1': 0.022764889523386955, 'loss_2': 0.0088958740234375, 'loss_3': -15.973551750183105, 'loss_4': -0.11081454157829285, 'epoch': 5.77}
{'loss': 0.036, 'grad_norm': 7.899178504943848, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.02400512620806694, 'loss_2': 0.01195526123046875, 'loss_3': -15.90572738647461, 'loss_4': -0.06694010645151138, 'epoch': 5.78}
{'loss': 0.0666, 'grad_norm': 13.662872314453125, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.05402505025267601, 'loss_2': 0.012603759765625, 'loss_3': -16.071807861328125, 'loss_4': 0.5658376216888428, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 15:42:18,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:18,531 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [25:12<1:11:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:25,866 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022516073659062386, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.77, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011821212247014046, 'eval_loss_2': 0.01069486141204834, 'eval_loss_3': -18.09721565246582, 'eval_loss_4': 0.13858310878276825, 'epoch': 5.78}
{'loss': 0.0398, 'grad_norm': 8.830458641052246, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.027256222441792488, 'loss_2': 0.0125274658203125, 'loss_3': -15.909571647644043, 'loss_4': 0.04234562814235687, 'epoch': 5.79}
{'loss': 0.0361, 'grad_norm': 8.753751754760742, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.026562174782156944, 'loss_2': 0.00958251953125, 'loss_3': -16.013507843017578, 'loss_4': 0.3897537291049957, 'epoch': 5.8}
{'loss': 0.0239, 'grad_norm': 8.664295196533203, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.01700914278626442, 'loss_2': 0.0068817138671875, 'loss_3': -15.844518661499023, 'loss_4': 0.23100903630256653, 'epoch': 5.8}
{'loss': 0.0426, 'grad_norm': 13.784090995788574, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.032826270908117294, 'loss_2': 0.0098114013671875, 'loss_3': -16.21599769592285, 'loss_4': -0.04735371470451355, 'epoch': 5.81}
{'loss': 0.0285, 'grad_norm': 8.098204612731934, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.02418883703649044, 'loss_2': 0.004314422607421875, 'loss_3': -15.971101760864258, 'loss_4': -0.0480843260884285, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 15:42:25,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:25,866 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:19<1:11:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:33,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02201574295759201, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.848, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01860957406461239, 'eval_loss_2': 0.0034061670303344727, 'eval_loss_3': -18.086109161376953, 'eval_loss_4': 0.1339731514453888, 'epoch': 5.81}
{'loss': 0.0394, 'grad_norm': 7.440694808959961, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.0283309705555439, 'loss_2': 0.0111083984375, 'loss_3': -16.0826473236084, 'loss_4': 0.1538572907447815, 'epoch': 5.82}
{'loss': 0.0341, 'grad_norm': 12.888516426086426, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.034063346683979034, 'loss_2': 3.981590270996094e-05, 'loss_3': -15.940234184265137, 'loss_4': 0.047888144850730896, 'epoch': 5.83}
{'loss': 0.0291, 'grad_norm': 8.559818267822266, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.023638583719730377, 'loss_2': 0.00543212890625, 'loss_3': -16.139793395996094, 'loss_4': 0.25354331731796265, 'epoch': 5.83}
{'loss': 0.0455, 'grad_norm': 14.690652847290039, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.04100295156240463, 'loss_2': 0.00444793701171875, 'loss_3': -16.28766441345215, 'loss_4': -0.01610609143972397, 'epoch': 5.84}
{'loss': 0.0192, 'grad_norm': 6.227713108062744, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.017320971935987473, 'loss_2': 0.0018758773803710938, 'loss_3': -15.883319854736328, 'loss_4': 0.4300920367240906, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 15:42:33,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:33,216 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:27<1:11:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:40,555 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04209677875041962, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.078, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03198544681072235, 'eval_loss_2': 0.010111331939697266, 'eval_loss_3': -18.06441307067871, 'eval_loss_4': 0.47826337814331055, 'epoch': 5.84}
{'loss': 0.0602, 'grad_norm': 13.037837028503418, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.04882095009088516, 'loss_2': 0.0113525390625, 'loss_3': -15.975229263305664, 'loss_4': 0.3575172424316406, 'epoch': 5.85}
{'loss': 0.0627, 'grad_norm': 18.7181396484375, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.05700709670782089, 'loss_2': 0.00568389892578125, 'loss_3': -15.815239906311035, 'loss_4': 0.5342864394187927, 'epoch': 5.85}
{'loss': 0.0721, 'grad_norm': 22.323396682739258, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.06950660794973373, 'loss_2': 0.002559661865234375, 'loss_3': -16.012531280517578, 'loss_4': 0.3217149078845978, 'epoch': 5.86}
{'loss': 0.0378, 'grad_norm': 11.785074234008789, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.02892782725393772, 'loss_2': 0.00890350341796875, 'loss_3': -15.823784828186035, 'loss_4': 0.5789900422096252, 'epoch': 5.87}
{'loss': 0.0773, 'grad_norm': 21.147607803344727, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.07094014436006546, 'loss_2': 0.00632476806640625, 'loss_3': -15.797151565551758, 'loss_4': 0.5474623441696167, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 15:42:40,555 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:40,555 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:34<1:11:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:47,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025851912796497345, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.487, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.022627631202340126, 'eval_loss_2': 0.003224283456802368, 'eval_loss_3': -18.1275634765625, 'eval_loss_4': 0.7230822443962097, 'epoch': 5.87}
{'loss': 0.047, 'grad_norm': 10.563472747802734, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.04271703213453293, 'loss_2': 0.004241943359375, 'loss_3': -16.057992935180664, 'loss_4': 0.6305149793624878, 'epoch': 5.88}
{'loss': 0.0285, 'grad_norm': 12.127778053283691, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.026085112243890762, 'loss_2': 0.00246429443359375, 'loss_3': -15.883853912353516, 'loss_4': 0.3518413305282593, 'epoch': 5.88}
{'loss': 0.0483, 'grad_norm': 13.100032806396484, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.040459636598825455, 'loss_2': 0.00783538818359375, 'loss_3': -15.834089279174805, 'loss_4': 0.7413597106933594, 'epoch': 5.89}
{'loss': 0.0323, 'grad_norm': 9.811034202575684, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.026600051671266556, 'loss_2': 0.00568389892578125, 'loss_3': -16.15593910217285, 'loss_4': 0.5952609181404114, 'epoch': 5.9}
{'loss': 0.0522, 'grad_norm': 20.945871353149414, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.05115385353565216, 'loss_2': 0.00106048583984375, 'loss_3': -16.131046295166016, 'loss_4': 0.6380373239517212, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 15:42:47,897 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:47,897 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:41<1:11:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:42:55,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014819145202636719, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.354, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01103165652602911, 'eval_loss_2': 0.003787487745285034, 'eval_loss_3': -18.257835388183594, 'eval_loss_4': 0.588850200176239, 'epoch': 5.9}
{'loss': 0.0719, 'grad_norm': 18.901702880859375, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.07179541140794754, 'loss_2': 0.0001423358917236328, 'loss_3': -15.74842643737793, 'loss_4': 0.5209774374961853, 'epoch': 5.91}
{'loss': 0.095, 'grad_norm': 24.859331130981445, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.09030026942491531, 'loss_2': 0.0046539306640625, 'loss_3': -15.984735488891602, 'loss_4': 0.5999493598937988, 'epoch': 5.91}
{'loss': 0.0375, 'grad_norm': 9.854907035827637, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.03695417568087578, 'loss_2': 0.0005364418029785156, 'loss_3': -16.022754669189453, 'loss_4': 0.11295408010482788, 'epoch': 5.92}
{'loss': 0.0628, 'grad_norm': 18.867406845092773, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.05401728302240372, 'loss_2': 0.0087432861328125, 'loss_3': -16.093978881835938, 'loss_4': 0.041057512164115906, 'epoch': 5.92}
{'loss': 0.0519, 'grad_norm': 13.046605110168457, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.043635979294776917, 'loss_2': 0.0082550048828125, 'loss_3': -15.944008827209473, 'loss_4': 0.2890074849128723, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 15:42:55,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:42:55,247 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:49<1:11:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:02,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02059987559914589, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.512, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011297257617115974, 'eval_loss_2': 0.009302616119384766, 'eval_loss_3': -18.299129486083984, 'eval_loss_4': 0.42608967423439026, 'epoch': 5.93}
{'loss': 0.0566, 'grad_norm': 20.123157501220703, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.04931635037064552, 'loss_2': 0.007297515869140625, 'loss_3': -16.005409240722656, 'loss_4': 0.5566619634628296, 'epoch': 5.94}
{'loss': 0.0796, 'grad_norm': 26.225664138793945, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.06833229959011078, 'loss_2': 0.011260986328125, 'loss_3': -16.040281295776367, 'loss_4': 0.48450765013694763, 'epoch': 5.94}
{'loss': 0.0351, 'grad_norm': 8.72547721862793, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.028479332104325294, 'loss_2': 0.0065765380859375, 'loss_3': -16.062332153320312, 'loss_4': 0.08873675763607025, 'epoch': 5.95}
{'loss': 0.0593, 'grad_norm': 11.912649154663086, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.04801224544644356, 'loss_2': 0.01129913330078125, 'loss_3': -15.948671340942383, 'loss_4': 0.3849947452545166, 'epoch': 5.95}
{'loss': 0.0523, 'grad_norm': 13.97986888885498, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.045065317302942276, 'loss_2': 0.00727081298828125, 'loss_3': -15.871506690979004, 'loss_4': 0.20601817965507507, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 15:43:02,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:02,588 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:52<1:11:29,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:43:06,388 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1025
[INFO|configuration_utils.py:420] 2025-01-21 15:43:06,390 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1025/config.json                                                                            
{'eval_loss': 0.013061771169304848, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.555, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009974012151360512, 'eval_loss_2': 0.003087759017944336, 'eval_loss_3': -18.319499969482422, 'eval_loss_4': 0.32382726669311523, 'epoch': 5.96}
[INFO|modeling_utils.py:2988] 2025-01-21 15:43:06,890 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1025/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:43:06,892 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1025/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:43:06,892 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1025/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:43:07,843 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-980] due to args.save_total_limit
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:58<1:19:04,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:43:11,477 >>
{'loss': 0.0425, 'grad_norm': 14.198627471923828, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.03903096914291382, 'loss_2': 0.003467559814453125, 'loss_3': -15.986724853515625, 'loss_4': 0.3638930320739746, 'epoch': 5.97}
{'loss': 0.0649, 'grad_norm': 23.505762100219727, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.06189022213220596, 'loss_2': 0.003055572509765625, 'loss_3': -16.012868881225586, 'loss_4': 0.25244319438934326, 'epoch': 5.97}
{'loss': 0.0371, 'grad_norm': 12.697279930114746, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.031035002321004868, 'loss_2': 0.006084442138671875, 'loss_3': -16.074298858642578, 'loss_4': 0.742548406124115, 'epoch': 5.98}
{'loss': 0.0355, 'grad_norm': 10.41897201538086, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.03010876476764679, 'loss_2': 0.00534820556640625, 'loss_3': -15.928153991699219, 'loss_4': 0.23074838519096375, 'epoch': 5.98}
{'loss': 0.028, 'grad_norm': 6.355166435241699, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.018145758658647537, 'loss_2': 0.0098724365234375, 'loss_3': -16.00861358642578, 'loss_4': 0.3195565938949585, 'epoch': 5.99}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:43:11,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:11,478 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [26:05<1:10:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:43:18,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017995478585362434, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011214437894523144, 'eval_loss_2': 0.006781041622161865, 'eval_loss_3': -18.29355239868164, 'eval_loss_4': 0.40345367789268494, 'epoch': 5.99}
{'loss': 0.0312, 'grad_norm': 7.7194719314575195, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.025723986327648163, 'loss_2': 0.005466461181640625, 'loss_3': -16.155397415161133, 'loss_4': 0.4572569727897644, 'epoch': 5.99}
{'loss': 0.0658, 'grad_norm': 26.79438591003418, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.0573703870177269, 'loss_2': 0.0084075927734375, 'loss_3': -16.19767189025879, 'loss_4': 0.7889848351478577, 'epoch': 6.0}
{'loss': 0.0496, 'grad_norm': 13.530954360961914, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.0360703244805336, 'loss_2': 0.013519287109375, 'loss_3': -16.072484970092773, 'loss_4': 0.9619507789611816, 'epoch': 6.01}
{'loss': 0.0626, 'grad_norm': 18.95404052734375, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.05088936537504196, 'loss_2': 0.0116729736328125, 'loss_3': -15.962855339050293, 'loss_4': 0.48305651545524597, 'epoch': 6.01}
{'loss': 0.0349, 'grad_norm': 6.8666768074035645, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.020314764231443405, 'loss_2': 0.014617919921875, 'loss_3': -16.10906219482422, 'loss_4': 0.8496556878089905, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 15:43:18,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:18,518 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:12<1:11:00,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:43:25,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013504549860954285, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.787, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011563047766685486, 'eval_loss_2': 0.0019415020942687988, 'eval_loss_3': -18.249370574951172, 'eval_loss_4': 0.4901159405708313, 'epoch': 6.02}
{'loss': 0.0651, 'grad_norm': 15.586344718933105, 'learning_rate': 2.4e-05, 'loss_1': 0.05784573778510094, 'loss_2': 0.007232666015625, 'loss_3': -16.008920669555664, 'loss_4': 0.31151705980300903, 'epoch': 6.02}
{'loss': 0.0325, 'grad_norm': 9.240681648254395, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.030535826459527016, 'loss_2': 0.001979827880859375, 'loss_3': -16.08978271484375, 'loss_4': 0.9652986526489258, 'epoch': 6.03}
{'loss': 0.038, 'grad_norm': 10.724838256835938, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.02997051551938057, 'loss_2': 0.0080718994140625, 'loss_3': -16.084665298461914, 'loss_4': 0.6551633477210999, 'epoch': 6.03}
{'loss': 0.0396, 'grad_norm': 13.779753684997559, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.03027002327144146, 'loss_2': 0.009307861328125, 'loss_3': -16.02065086364746, 'loss_4': 0.6695725917816162, 'epoch': 6.04}
{'loss': 0.0418, 'grad_norm': 9.276388168334961, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.03063480369746685, 'loss_2': 0.01111602783203125, 'loss_3': -15.702617645263672, 'loss_4': 0.03922753036022186, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 15:43:25,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:25,849 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:19<1:11:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:33,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02504793368279934, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.758, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012944375164806843, 'eval_loss_2': 0.012103557586669922, 'eval_loss_3': -18.217426300048828, 'eval_loss_4': 0.510087788105011, 'epoch': 6.05}
{'loss': 0.0795, 'grad_norm': 13.058755874633789, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.0759441927075386, 'loss_2': 0.0035400390625, 'loss_3': -15.850408554077148, 'loss_4': 0.47282856702804565, 'epoch': 6.05}
{'loss': 0.0863, 'grad_norm': 22.176063537597656, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.06865175813436508, 'loss_2': 0.017669677734375, 'loss_3': -16.045974731445312, 'loss_4': 0.7029931545257568, 'epoch': 6.06}
{'loss': 0.0576, 'grad_norm': 14.412217140197754, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.050050999969244, 'loss_2': 0.007534027099609375, 'loss_3': -15.951436996459961, 'loss_4': 0.5994362831115723, 'epoch': 6.06}
{'loss': 0.0353, 'grad_norm': 8.505894660949707, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.02039290778338909, 'loss_2': 0.014892578125, 'loss_3': -16.064125061035156, 'loss_4': 0.07943348586559296, 'epoch': 6.07}
{'loss': 0.0321, 'grad_norm': 10.33719253540039, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.023685047402977943, 'loss_2': 0.0084381103515625, 'loss_3': -16.16400909423828, 'loss_4': 0.7073993682861328, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 15:43:33,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:33,180 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:27<1:11:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:40,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01702272891998291, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.444, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011379899457097054, 'eval_loss_2': 0.005642831325531006, 'eval_loss_3': -18.243188858032227, 'eval_loss_4': 0.3659951984882355, 'epoch': 6.08}
{'loss': 0.0397, 'grad_norm': 12.36987590789795, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.03490854799747467, 'loss_2': 0.004756927490234375, 'loss_3': -16.027854919433594, 'loss_4': 0.1154252141714096, 'epoch': 6.08}
{'loss': 0.0305, 'grad_norm': 10.786391258239746, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.029198240488767624, 'loss_2': 0.0012750625610351562, 'loss_3': -16.074357986450195, 'loss_4': 0.04030916094779968, 'epoch': 6.09}
{'loss': 0.0435, 'grad_norm': 9.440305709838867, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.039727382361888885, 'loss_2': 0.00379180908203125, 'loss_3': -15.895036697387695, 'loss_4': 0.2418692708015442, 'epoch': 6.09}
{'loss': 0.0302, 'grad_norm': 8.568855285644531, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.02513299323618412, 'loss_2': 0.0050506591796875, 'loss_3': -16.074813842773438, 'loss_4': 0.3710201382637024, 'epoch': 6.1}
{'loss': 0.0527, 'grad_norm': 11.320182800292969, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.03829719126224518, 'loss_2': 0.0144195556640625, 'loss_3': -16.013587951660156, 'loss_4': -0.17843285202980042, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 15:43:40,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:40,520 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:34<1:10:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:47,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023242861032485962, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.432, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012079150415956974, 'eval_loss_2': 0.011163711547851562, 'eval_loss_3': -18.27632713317871, 'eval_loss_4': 0.21777814626693726, 'epoch': 6.1}
{'loss': 0.0319, 'grad_norm': 6.337014675140381, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.01958509348332882, 'loss_2': 0.0123138427734375, 'loss_3': -16.050294876098633, 'loss_4': 0.20821166038513184, 'epoch': 6.11}
{'loss': 0.0366, 'grad_norm': 7.120841026306152, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.019820477813482285, 'loss_2': 0.016815185546875, 'loss_3': -16.12215805053711, 'loss_4': -0.18557783961296082, 'epoch': 6.12}
{'loss': 0.0232, 'grad_norm': 6.838988780975342, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.01697555184364319, 'loss_2': 0.00624847412109375, 'loss_3': -15.890337944030762, 'loss_4': 0.17786672711372375, 'epoch': 6.12}
{'loss': 0.034, 'grad_norm': 8.591897010803223, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.02615938149392605, 'loss_2': 0.00783538818359375, 'loss_3': -16.116043090820312, 'loss_4': 0.49967071413993835, 'epoch': 6.13}
{'loss': 0.0537, 'grad_norm': 15.9506254196167, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.04761938378214836, 'loss_2': 0.00612640380859375, 'loss_3': -16.056324005126953, 'loss_4': 0.1926414668560028, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 15:43:47,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:47,858 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:41<1:11:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:43:55,215 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014009475708007812, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010936184786260128, 'eval_loss_2': 0.00307328999042511, 'eval_loss_3': -18.291780471801758, 'eval_loss_4': 0.12446001917123795, 'epoch': 6.13}
{'loss': 0.0155, 'grad_norm': 6.036403179168701, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.01224594097584486, 'loss_2': 0.00321197509765625, 'loss_3': -16.189882278442383, 'loss_4': -0.0761488825082779, 'epoch': 6.14}
{'loss': 0.0474, 'grad_norm': 15.226395606994629, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.039534710347652435, 'loss_2': 0.00787353515625, 'loss_3': -16.08721160888672, 'loss_4': 0.10289466381072998, 'epoch': 6.15}
{'loss': 0.0314, 'grad_norm': 10.889324188232422, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.024571776390075684, 'loss_2': 0.0068359375, 'loss_3': -16.276527404785156, 'loss_4': -0.30242425203323364, 'epoch': 6.15}
{'loss': 0.0292, 'grad_norm': 6.944007873535156, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.01641370914876461, 'loss_2': 0.01275634765625, 'loss_3': -16.45542335510254, 'loss_4': 0.14778685569763184, 'epoch': 6.16}
{'loss': 0.047, 'grad_norm': 7.628589153289795, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.027849413454532623, 'loss_2': 0.0191497802734375, 'loss_3': -16.080020904541016, 'loss_4': -0.228289395570755, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 15:43:55,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:43:55,216 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:49<1:10:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:02,559 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025944381952285767, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.995, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011742260307073593, 'eval_loss_2': 0.014202117919921875, 'eval_loss_3': -18.324941635131836, 'eval_loss_4': -0.10949916392564774, 'epoch': 6.16}
{'loss': 0.0418, 'grad_norm': 12.547524452209473, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.029400130733847618, 'loss_2': 0.01236724853515625, 'loss_3': -16.109466552734375, 'loss_4': 0.29465609788894653, 'epoch': 6.17}
{'loss': 0.0353, 'grad_norm': 8.758585929870605, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.02475743368268013, 'loss_2': 0.01053619384765625, 'loss_3': -16.12082290649414, 'loss_4': -0.5670017600059509, 'epoch': 6.17}
{'loss': 0.0478, 'grad_norm': 11.671135902404785, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.04055830091238022, 'loss_2': 0.007244110107421875, 'loss_3': -16.231792449951172, 'loss_4': -0.34471213817596436, 'epoch': 6.18}
{'loss': 0.042, 'grad_norm': 8.871047973632812, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.028802083805203438, 'loss_2': 0.01323699951171875, 'loss_3': -16.198055267333984, 'loss_4': 0.3360181450843811, 'epoch': 6.19}
{'loss': 0.0174, 'grad_norm': 5.69174861907959, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.011266747489571571, 'loss_2': 0.00611114501953125, 'loss_3': -16.26233673095703, 'loss_4': 0.0660117119550705, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 15:44:02,559 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:02,559 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:56<1:10:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:09,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015382098034024239, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.509, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012571203522384167, 'eval_loss_2': 0.0028108954429626465, 'eval_loss_3': -18.332914352416992, 'eval_loss_4': -0.01791117712855339, 'epoch': 6.19}
{'loss': 0.023, 'grad_norm': 8.89115047454834, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.022675521671772003, 'loss_2': 0.00037217140197753906, 'loss_3': -16.29645347595215, 'loss_4': 0.17232051491737366, 'epoch': 6.2}
{'loss': 0.03, 'grad_norm': 9.09859561920166, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.023141026496887207, 'loss_2': 0.006855010986328125, 'loss_3': -16.241931915283203, 'loss_4': -0.11977849155664444, 'epoch': 6.2}
{'loss': 0.022, 'grad_norm': 5.633098602294922, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.012880620546638966, 'loss_2': 0.00909423828125, 'loss_3': -16.20170783996582, 'loss_4': 0.44924789667129517, 'epoch': 6.21}
{'loss': 0.0261, 'grad_norm': 6.2689666748046875, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.016889149323105812, 'loss_2': 0.009246826171875, 'loss_3': -16.24655532836914, 'loss_4': -0.18254439532756805, 'epoch': 6.22}
{'loss': 0.0742, 'grad_norm': 11.02013874053955, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.06528961658477783, 'loss_2': 0.0089111328125, 'loss_3': -16.384136199951172, 'loss_4': 0.23516780138015747, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 15:44:09,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:09,898 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [27:03<1:10:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:17,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021670758724212646, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.478, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012267527170479298, 'eval_loss_2': 0.009403228759765625, 'eval_loss_3': -18.265897750854492, 'eval_loss_4': -0.09022928774356842, 'epoch': 6.22}
{'loss': 0.033, 'grad_norm': 7.878496170043945, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.023493602871894836, 'loss_2': 0.009521484375, 'loss_3': -16.180570602416992, 'loss_4': -0.21626615524291992, 'epoch': 6.23}
{'loss': 0.0335, 'grad_norm': 15.502152442932129, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.028284966945648193, 'loss_2': 0.0051727294921875, 'loss_3': -16.091737747192383, 'loss_4': -0.3680749237537384, 'epoch': 6.23}
{'loss': 0.0206, 'grad_norm': 7.252092361450195, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.01619582809507847, 'loss_2': 0.00435638427734375, 'loss_3': -16.147171020507812, 'loss_4': -0.3121021091938019, 'epoch': 6.24}
{'loss': 0.0303, 'grad_norm': 11.548866271972656, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.026465928182005882, 'loss_2': 0.00379180908203125, 'loss_3': -16.247791290283203, 'loss_4': -0.22776886820793152, 'epoch': 6.24}
{'loss': 0.0505, 'grad_norm': 10.107914924621582, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.03720884770154953, 'loss_2': 0.0133209228515625, 'loss_3': -16.161386489868164, 'loss_4': -0.4941949248313904, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 15:44:17,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:17,237 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [27:11<1:10:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:24,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017834383994340897, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.345, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01198569219559431, 'eval_loss_2': 0.005848690867424011, 'eval_loss_3': -18.251352310180664, 'eval_loss_4': -0.3041974604129791, 'epoch': 6.25}
{'loss': 0.0706, 'grad_norm': 24.199031829833984, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.06355886161327362, 'loss_2': 0.00699615478515625, 'loss_3': -16.202686309814453, 'loss_4': -0.8518041372299194, 'epoch': 6.26}
{'loss': 0.0335, 'grad_norm': 9.78221321105957, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.022616859525442123, 'loss_2': 0.0108489990234375, 'loss_3': -16.30428695678711, 'loss_4': -0.7310910224914551, 'epoch': 6.26}
{'loss': 0.0307, 'grad_norm': 8.383816719055176, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.022225208580493927, 'loss_2': 0.008453369140625, 'loss_3': -16.326494216918945, 'loss_4': -0.5737448930740356, 'epoch': 6.27}
{'loss': 0.0175, 'grad_norm': 6.98246431350708, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.01351181324571371, 'loss_2': 0.004009246826171875, 'loss_3': -16.139354705810547, 'loss_4': -0.0007241517305374146, 'epoch': 6.27}
{'loss': 0.0426, 'grad_norm': 8.788951873779297, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.03153645992279053, 'loss_2': 0.01102447509765625, 'loss_3': -16.186729431152344, 'loss_4': -0.2599405348300934, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 15:44:24,582 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:24,582 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:18<1:10:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:31,924 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02183896116912365, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.309, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01634722761809826, 'eval_loss_2': 0.005491733551025391, 'eval_loss_3': -18.222497940063477, 'eval_loss_4': -0.031822361052036285, 'epoch': 6.28}
{'loss': 0.0312, 'grad_norm': 12.448372840881348, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.028471633791923523, 'loss_2': 0.00270843505859375, 'loss_3': -16.259349822998047, 'loss_4': -0.20329923927783966, 'epoch': 6.28}
{'loss': 0.0297, 'grad_norm': 9.410970687866211, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.019075021147727966, 'loss_2': 0.010589599609375, 'loss_3': -16.274333953857422, 'loss_4': -0.4836650490760803, 'epoch': 6.29}
{'loss': 0.0181, 'grad_norm': 6.438252925872803, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.013429864309728146, 'loss_2': 0.0046234130859375, 'loss_3': -16.278825759887695, 'loss_4': 0.2682808041572571, 'epoch': 6.3}
{'loss': 0.1651, 'grad_norm': 30.542634963989258, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.162335604429245, 'loss_2': 0.002780914306640625, 'loss_3': -15.955366134643555, 'loss_4': 0.12509199976921082, 'epoch': 6.3}
{'loss': 0.0536, 'grad_norm': 19.675817489624023, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.0495133250951767, 'loss_2': 0.004108428955078125, 'loss_3': -16.21213150024414, 'loss_4': 0.1205470934510231, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 15:44:31,924 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:31,925 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:25<1:10:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:39,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020606543868780136, 'eval_runtime': 3.8194, 'eval_samples_per_second': 268.106, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.012799646705389023, 'eval_loss_2': 0.007806897163391113, 'eval_loss_3': -18.23581314086914, 'eval_loss_4': 0.3087703585624695, 'epoch': 6.31}
{'loss': 0.0998, 'grad_norm': 20.62619972229004, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.08995363861322403, 'loss_2': 0.00983428955078125, 'loss_3': -16.233869552612305, 'loss_4': 0.2653593420982361, 'epoch': 6.31}
{'loss': 0.0415, 'grad_norm': 13.88021183013916, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.037649672478437424, 'loss_2': 0.003871917724609375, 'loss_3': -16.037940979003906, 'loss_4': 0.7335596084594727, 'epoch': 6.32}
{'loss': 0.0535, 'grad_norm': 12.578253746032715, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.04188151657581329, 'loss_2': 0.0116119384765625, 'loss_3': -15.932952880859375, 'loss_4': 0.6596368551254272, 'epoch': 6.33}
{'loss': 0.0814, 'grad_norm': 22.2554874420166, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.06757128983736038, 'loss_2': 0.0138092041015625, 'loss_3': -16.2188663482666, 'loss_4': 0.9899365901947021, 'epoch': 6.33}
{'loss': 0.0368, 'grad_norm': 7.59765100479126, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.024269435554742813, 'loss_2': 0.012542724609375, 'loss_3': -16.139175415039062, 'loss_4': 0.6541938781738281, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 15:44:39,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:39,287 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:33<1:10:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:46,640 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023367349058389664, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.902, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012227659113705158, 'eval_loss_2': 0.01113969087600708, 'eval_loss_3': -18.258678436279297, 'eval_loss_4': 0.7190713882446289, 'epoch': 6.34}
{'loss': 0.0278, 'grad_norm': 5.725132942199707, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.014567446894943714, 'loss_2': 0.0131988525390625, 'loss_3': -16.32292938232422, 'loss_4': 0.6706655025482178, 'epoch': 6.34}
{'loss': 0.0211, 'grad_norm': 5.117610931396484, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.006776353344321251, 'loss_2': 0.0143585205078125, 'loss_3': -16.28633689880371, 'loss_4': 0.8545178771018982, 'epoch': 6.35}
{'loss': 0.0273, 'grad_norm': 9.983513832092285, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.021161597222089767, 'loss_2': 0.0061187744140625, 'loss_3': -16.146455764770508, 'loss_4': 0.4309903383255005, 'epoch': 6.35}
{'loss': 0.013, 'grad_norm': 6.1237568855285645, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.009387667290866375, 'loss_2': 0.0036106109619140625, 'loss_3': -16.16677474975586, 'loss_4': 0.4718649089336395, 'epoch': 6.36}
{'loss': 0.0175, 'grad_norm': 6.929646968841553, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.015820594504475594, 'loss_2': 0.0016574859619140625, 'loss_3': -16.289714813232422, 'loss_4': 0.8922666311264038, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 15:44:46,640 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:46,640 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:40<1:10:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:44:53,999 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020017147064208984, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.191, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013077139854431152, 'eval_loss_2': 0.006940007209777832, 'eval_loss_3': -18.25786781311035, 'eval_loss_4': 0.8268926739692688, 'epoch': 6.37}
{'loss': 0.2292, 'grad_norm': 28.64208221435547, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.22118045389652252, 'loss_2': 0.00799560546875, 'loss_3': -15.83620548248291, 'loss_4': 0.7221732139587402, 'epoch': 6.37}
{'loss': 0.027, 'grad_norm': 121.61575317382812, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.016023388132452965, 'loss_2': 0.01100921630859375, 'loss_3': -16.073532104492188, 'loss_4': 0.9634358882904053, 'epoch': 6.38}
{'loss': 0.0454, 'grad_norm': 15.055559158325195, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.02900967374444008, 'loss_2': 0.016357421875, 'loss_3': -16.15924644470215, 'loss_4': 1.4693706035614014, 'epoch': 6.38}
{'loss': 0.0337, 'grad_norm': 8.291890144348145, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.017199765890836716, 'loss_2': 0.01654052734375, 'loss_3': -16.2344970703125, 'loss_4': 0.7478142976760864, 'epoch': 6.39}
{'loss': 0.066, 'grad_norm': 18.715749740600586, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.0477842316031456, 'loss_2': 0.0181884765625, 'loss_3': -16.074617385864258, 'loss_4': 1.2252899408340454, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 15:44:54,000 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:44:54,000 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:47<1:10:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:01,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.032627932727336884, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.703, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01444946601986885, 'eval_loss_2': 0.018178462982177734, 'eval_loss_3': -18.276256561279297, 'eval_loss_4': 1.2615201473236084, 'epoch': 6.4}
{'loss': 0.0412, 'grad_norm': 8.844897270202637, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.02523934096097946, 'loss_2': 0.0159454345703125, 'loss_3': -16.201099395751953, 'loss_4': 1.3311352729797363, 'epoch': 6.4}
{'loss': 0.0903, 'grad_norm': 27.740386962890625, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.0751035064458847, 'loss_2': 0.01519775390625, 'loss_3': -16.21569061279297, 'loss_4': 1.6131819486618042, 'epoch': 6.41}
{'loss': 0.0495, 'grad_norm': 14.415868759155273, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.030526673421263695, 'loss_2': 0.0189666748046875, 'loss_3': -16.259883880615234, 'loss_4': 1.8558197021484375, 'epoch': 6.41}
{'loss': 0.0176, 'grad_norm': 5.229520320892334, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.012172608636319637, 'loss_2': 0.00537872314453125, 'loss_3': -16.339448928833008, 'loss_4': 2.060664176940918, 'epoch': 6.42}
{'loss': 0.1137, 'grad_norm': 28.952831268310547, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.09906355291604996, 'loss_2': 0.014617919921875, 'loss_3': -16.22309112548828, 'loss_4': 1.8300166130065918, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 15:45:01,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:01,366 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:55<1:10:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:08,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02439172938466072, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01481621339917183, 'eval_loss_2': 0.009575515985488892, 'eval_loss_3': -18.265317916870117, 'eval_loss_4': 1.472833514213562, 'epoch': 6.42}
{'loss': 0.0342, 'grad_norm': 8.534406661987305, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.022790560498833656, 'loss_2': 0.0113983154296875, 'loss_3': -16.087587356567383, 'loss_4': 1.4542043209075928, 'epoch': 6.43}
{'loss': 0.0563, 'grad_norm': 19.91204833984375, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.05122159793972969, 'loss_2': 0.00506591796875, 'loss_3': -16.182247161865234, 'loss_4': 1.7385917901992798, 'epoch': 6.44}
{'loss': 0.0191, 'grad_norm': 7.026870250701904, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.0183156356215477, 'loss_2': 0.0007562637329101562, 'loss_3': -16.045255661010742, 'loss_4': 1.6227166652679443, 'epoch': 6.44}
{'loss': 0.0315, 'grad_norm': 8.808991432189941, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.025087866932153702, 'loss_2': 0.00637054443359375, 'loss_3': -16.207950592041016, 'loss_4': 1.6510722637176514, 'epoch': 6.45}
{'loss': 0.0338, 'grad_norm': 13.227018356323242, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.026817796751856804, 'loss_2': 0.00695037841796875, 'loss_3': -16.374347686767578, 'loss_4': 1.5021584033966064, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 15:45:08,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:08,727 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [28:02<1:10:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:16,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.038062065839767456, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.182, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.02642151713371277, 'eval_loss_2': 0.011640548706054688, 'eval_loss_3': -18.183910369873047, 'eval_loss_4': 1.4167593717575073, 'epoch': 6.45}
{'loss': 0.0465, 'grad_norm': 16.508052825927734, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.040490761399269104, 'loss_2': 0.005977630615234375, 'loss_3': -16.22191047668457, 'loss_4': 0.9608333110809326, 'epoch': 6.46}
{'loss': 0.0308, 'grad_norm': 7.4925336837768555, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.017804544419050217, 'loss_2': 0.01297760009765625, 'loss_3': -15.992823600769043, 'loss_4': 1.2678074836730957, 'epoch': 6.47}
{'loss': 0.044, 'grad_norm': 7.297937393188477, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.02922188490629196, 'loss_2': 0.014801025390625, 'loss_3': -15.964776992797852, 'loss_4': 1.273515224456787, 'epoch': 6.47}
{'loss': 0.0433, 'grad_norm': 9.847785949707031, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.02985910139977932, 'loss_2': 0.01340484619140625, 'loss_3': -16.102336883544922, 'loss_4': 1.1766916513442993, 'epoch': 6.48}
{'loss': 0.1073, 'grad_norm': 24.73556900024414, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.08980782330036163, 'loss_2': 0.0175018310546875, 'loss_3': -15.81511116027832, 'loss_4': 1.2855029106140137, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 15:45:16,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:16,100 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [28:10<1:10:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:23,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06986840814352036, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.05413993448019028, 'eval_loss_2': 0.015728473663330078, 'eval_loss_3': -18.048866271972656, 'eval_loss_4': 1.235370397567749, 'epoch': 6.48}
{'loss': 0.0325, 'grad_norm': 7.59740686416626, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.0159413143992424, 'loss_2': 0.016571044921875, 'loss_3': -16.033462524414062, 'loss_4': 0.862612247467041, 'epoch': 6.49}
{'loss': 0.0724, 'grad_norm': 21.299667358398438, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.061354003846645355, 'loss_2': 0.011016845703125, 'loss_3': -16.306324005126953, 'loss_4': 1.234302282333374, 'epoch': 6.49}
{'loss': 0.0662, 'grad_norm': 17.259037017822266, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.045191120356321335, 'loss_2': 0.02099609375, 'loss_3': -15.783491134643555, 'loss_4': 1.4719263315200806, 'epoch': 6.5}
{'loss': 0.0947, 'grad_norm': 29.328357696533203, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.09233837574720383, 'loss_2': 0.002361297607421875, 'loss_3': -15.85501480102539, 'loss_4': 0.8876523375511169, 'epoch': 6.51}
{'loss': 0.0238, 'grad_norm': 6.219729423522949, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.01988707110285759, 'loss_2': 0.00391387939453125, 'loss_3': -16.17669677734375, 'loss_4': 1.125927209854126, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 15:45:23,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:23,458 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:17<1:09:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:30,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03913168981671333, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.041, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0322546511888504, 'eval_loss_2': 0.006877034902572632, 'eval_loss_3': -18.111845016479492, 'eval_loss_4': 0.9460877180099487, 'epoch': 6.51}
{'loss': 0.0626, 'grad_norm': 20.678491592407227, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.05715252831578255, 'loss_2': 0.00542449951171875, 'loss_3': -16.094600677490234, 'loss_4': 0.9992622137069702, 'epoch': 6.52}
{'loss': 0.0295, 'grad_norm': 21.73170280456543, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.022995151579380035, 'loss_2': 0.006465911865234375, 'loss_3': -16.11861801147461, 'loss_4': 1.113150954246521, 'epoch': 6.52}
{'loss': 0.0187, 'grad_norm': 5.942686557769775, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.013480810448527336, 'loss_2': 0.0052490234375, 'loss_3': -16.118301391601562, 'loss_4': 0.9820111393928528, 'epoch': 6.53}
{'loss': 0.0329, 'grad_norm': 11.004682540893555, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.03222151845693588, 'loss_2': 0.0006856918334960938, 'loss_3': -15.984742164611816, 'loss_4': 0.806840181350708, 'epoch': 6.53}
{'loss': 0.0278, 'grad_norm': 8.410295486450195, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.02002047374844551, 'loss_2': 0.007732391357421875, 'loss_3': -16.164386749267578, 'loss_4': 0.5894395112991333, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 15:45:30,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:30,816 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:24<1:09:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:38,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029942132532596588, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.132, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01976463757455349, 'eval_loss_2': 0.01017749309539795, 'eval_loss_3': -18.15521812438965, 'eval_loss_4': 0.7685457468032837, 'epoch': 6.54}
{'loss': 0.0609, 'grad_norm': 20.45849609375, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.045242857187986374, 'loss_2': 0.015655517578125, 'loss_3': -16.033702850341797, 'loss_4': 1.0167168378829956, 'epoch': 6.55}
{'loss': 0.0467, 'grad_norm': 11.030131340026855, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.037640731781721115, 'loss_2': 0.009033203125, 'loss_3': -16.016450881958008, 'loss_4': 0.7861074209213257, 'epoch': 6.55}
{'loss': 0.0291, 'grad_norm': 7.1674299240112305, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.01806856505572796, 'loss_2': 0.0110015869140625, 'loss_3': -16.145553588867188, 'loss_4': 0.9274346828460693, 'epoch': 6.56}
{'loss': 0.0617, 'grad_norm': 13.067140579223633, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.041637059301137924, 'loss_2': 0.0200958251953125, 'loss_3': -16.0081787109375, 'loss_4': 0.7500516176223755, 'epoch': 6.56}
{'loss': 0.0257, 'grad_norm': 6.5700578689575195, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.014870031736791134, 'loss_2': 0.0108642578125, 'loss_3': -16.330738067626953, 'loss_4': 1.0019632577896118, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 15:45:38,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:38,169 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:32<1:09:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:45,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02479209005832672, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013206856325268745, 'eval_loss_2': 0.011585235595703125, 'eval_loss_3': -18.172391891479492, 'eval_loss_4': 0.6722596883773804, 'epoch': 6.57}
{'loss': 0.0231, 'grad_norm': 8.123612403869629, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.019223008304834366, 'loss_2': 0.003902435302734375, 'loss_3': -16.107810974121094, 'loss_4': 1.002516746520996, 'epoch': 6.58}
{'loss': 0.0355, 'grad_norm': 7.625338554382324, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.02454628422856331, 'loss_2': 0.010986328125, 'loss_3': -16.171585083007812, 'loss_4': 0.8943102359771729, 'epoch': 6.58}
{'loss': 0.0257, 'grad_norm': 8.076172828674316, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.0212552547454834, 'loss_2': 0.00440216064453125, 'loss_3': -16.26742935180664, 'loss_4': 0.4263153076171875, 'epoch': 6.59}
{'loss': 0.0254, 'grad_norm': 7.830334663391113, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.01811346411705017, 'loss_2': 0.00724029541015625, 'loss_3': -16.22513771057129, 'loss_4': 0.17682912945747375, 'epoch': 6.59}
{'loss': 0.0528, 'grad_norm': 20.967838287353516, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.04860570654273033, 'loss_2': 0.004180908203125, 'loss_3': -16.188562393188477, 'loss_4': 0.6728067398071289, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 15:45:45,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:45,527 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:39<1:09:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:45:52,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01587682217359543, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.542, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011803753674030304, 'eval_loss_2': 0.0040730684995651245, 'eval_loss_3': -18.204578399658203, 'eval_loss_4': 0.5190078020095825, 'epoch': 6.6}
{'loss': 0.0196, 'grad_norm': 6.808836936950684, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.0148606076836586, 'loss_2': 0.0047149658203125, 'loss_3': -16.25759506225586, 'loss_4': 0.4312562048435211, 'epoch': 6.6}
{'loss': 0.0244, 'grad_norm': 9.09670639038086, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.018994484096765518, 'loss_2': 0.00537872314453125, 'loss_3': -16.154502868652344, 'loss_4': 0.9195095300674438, 'epoch': 6.61}
{'loss': 0.0391, 'grad_norm': 14.67097282409668, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.034384310245513916, 'loss_2': 0.004673004150390625, 'loss_3': -16.097000122070312, 'loss_4': 0.8928201198577881, 'epoch': 6.62}
{'loss': 0.0245, 'grad_norm': 15.822399139404297, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.020151536911725998, 'loss_2': 0.00432586669921875, 'loss_3': -16.159208297729492, 'loss_4': 0.16123142838478088, 'epoch': 6.62}
{'loss': 0.0315, 'grad_norm': 9.792490005493164, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.030796468257904053, 'loss_2': 0.0006551742553710938, 'loss_3': -16.038467407226562, 'loss_4': 0.33934175968170166, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 15:45:52,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:45:52,890 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:46<1:09:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:00,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014253217726945877, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.765, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008421916514635086, 'eval_loss_2': 0.005831301212310791, 'eval_loss_3': -18.24463653564453, 'eval_loss_4': 0.21345657110214233, 'epoch': 6.63}
{'loss': 0.0447, 'grad_norm': 11.866056442260742, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.033472392708063126, 'loss_2': 0.01126861572265625, 'loss_3': -16.33821678161621, 'loss_4': 0.28384190797805786, 'epoch': 6.63}
{'loss': 0.0163, 'grad_norm': 6.284797668457031, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.011064969934523106, 'loss_2': 0.00519561767578125, 'loss_3': -16.058046340942383, 'loss_4': 0.23020818829536438, 'epoch': 6.64}
{'loss': 0.0183, 'grad_norm': 6.831601619720459, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.014484754763543606, 'loss_2': 0.00377655029296875, 'loss_3': -16.217985153198242, 'loss_4': 0.1831018626689911, 'epoch': 6.65}
{'loss': 0.0837, 'grad_norm': 17.146066665649414, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.08192729949951172, 'loss_2': 0.0017375946044921875, 'loss_3': -16.092880249023438, 'loss_4': -0.11920897662639618, 'epoch': 6.65}
{'loss': 0.0305, 'grad_norm': 10.357332229614258, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.023062150925397873, 'loss_2': 0.00746917724609375, 'loss_3': -16.356258392333984, 'loss_4': 0.060280948877334595, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 15:46:00,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:00,247 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:50<1:09:31,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 15:46:04,059 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1145
[INFO|configuration_utils.py:420] 2025-01-21 15:46:04,060 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1145/config.json                                                                            
{'eval_loss': 0.01173117384314537, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009035911411046982, 'eval_loss_2': 0.0026952624320983887, 'eval_loss_3': -18.25897789001465, 'eval_loss_4': 0.06221162900328636, 'epoch': 6.66}
[INFO|modeling_utils.py:2988] 2025-01-21 15:46:04,546 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1145/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 15:46:04,548 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1145/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 15:46:04,548 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1145/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 15:46:05,478 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1025] due to args.save_total_limit
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:55<1:16:36,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 15:46:09,107 >>
{'loss': 0.0109, 'grad_norm': 5.310038089752197, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.010792688466608524, 'loss_2': 8.52346420288086e-05, 'loss_3': -16.354740142822266, 'loss_4': 0.08644238114356995, 'epoch': 6.66}
{'loss': 0.0115, 'grad_norm': 6.355772972106934, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.011168274097144604, 'loss_2': 0.0003762245178222656, 'loss_3': -16.155227661132812, 'loss_4': -0.3371603190898895, 'epoch': 6.67}
{'loss': 0.0445, 'grad_norm': 15.529382705688477, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.036601994186639786, 'loss_2': 0.0079193115234375, 'loss_3': -16.10050392150879, 'loss_4': 0.1486852914094925, 'epoch': 6.67}
{'loss': 0.1092, 'grad_norm': 17.893310546875, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.10148875415325165, 'loss_2': 0.007686614990234375, 'loss_3': -16.124814987182617, 'loss_4': 0.9273994565010071, 'epoch': 6.68}
{'loss': 0.0553, 'grad_norm': 16.511823654174805, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.049932025372982025, 'loss_2': 0.00539398193359375, 'loss_3': -16.14504051208496, 'loss_4': -0.07435424625873566, 'epoch': 6.69}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 15:46:09,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:09,108 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [29:03<1:10:27,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 15:46:16,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022701352834701538, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.435, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010706515051424503, 'eval_loss_2': 0.01199483871459961, 'eval_loss_3': -18.24985122680664, 'eval_loss_4': 0.08293984085321426, 'epoch': 6.69}
{'loss': 0.0209, 'grad_norm': 5.920673847198486, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.012489017099142075, 'loss_2': 0.0084381103515625, 'loss_3': -16.259035110473633, 'loss_4': 0.8960328102111816, 'epoch': 6.69}
{'loss': 0.0322, 'grad_norm': 7.599832057952881, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.017611851915717125, 'loss_2': 0.0146331787109375, 'loss_3': -16.265708923339844, 'loss_4': 0.588336706161499, 'epoch': 6.7}
{'loss': 0.0346, 'grad_norm': 7.15181303024292, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.02064281888306141, 'loss_2': 0.01392364501953125, 'loss_3': -16.213037490844727, 'loss_4': -0.08902166783809662, 'epoch': 6.7}
{'loss': 0.0331, 'grad_norm': 8.254694938659668, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.023066475987434387, 'loss_2': 0.0099945068359375, 'loss_3': -16.289892196655273, 'loss_4': 0.4732329845428467, 'epoch': 6.71}
{'loss': 0.0644, 'grad_norm': 23.217477798461914, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.06366563588380814, 'loss_2': 0.000728607177734375, 'loss_3': -16.274723052978516, 'loss_4': 0.028600558638572693, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 15:46:16,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:16,450 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [29:10<1:09:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:23,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013832638040184975, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010257015004754066, 'eval_loss_2': 0.003575623035430908, 'eval_loss_3': -18.25078582763672, 'eval_loss_4': 0.044781528413295746, 'epoch': 6.72}
{'loss': 0.0304, 'grad_norm': 8.396869659423828, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.022837717086076736, 'loss_2': 0.00757598876953125, 'loss_3': -16.256427764892578, 'loss_4': -0.2825876474380493, 'epoch': 6.72}
{'loss': 0.0093, 'grad_norm': 6.673430442810059, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.00887900311499834, 'loss_2': 0.00043511390686035156, 'loss_3': -16.33664321899414, 'loss_4': -0.14734181761741638, 'epoch': 6.73}
{'loss': 0.0285, 'grad_norm': 7.8047895431518555, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.018402084708213806, 'loss_2': 0.01013946533203125, 'loss_3': -16.077848434448242, 'loss_4': 0.2665717899799347, 'epoch': 6.73}
{'loss': 0.1955, 'grad_norm': 40.00318145751953, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.18156760931015015, 'loss_2': 0.013916015625, 'loss_3': -16.14142608642578, 'loss_4': 0.34356606006622314, 'epoch': 6.74}
{'loss': 0.0491, 'grad_norm': 13.069201469421387, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.037625502794981, 'loss_2': 0.011505126953125, 'loss_3': -15.923335075378418, 'loss_4': 0.2630287706851959, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 15:46:23,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:23,783 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [29:17<1:09:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:31,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019934818148612976, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.174, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010448980145156384, 'eval_loss_2': 0.009485840797424316, 'eval_loss_3': -18.27589225769043, 'eval_loss_4': -0.0004566013813018799, 'epoch': 6.74}
{'loss': 0.0448, 'grad_norm': 11.840099334716797, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.03002367727458477, 'loss_2': 0.0147552490234375, 'loss_3': -16.27838897705078, 'loss_4': 0.2823029160499573, 'epoch': 6.75}
{'loss': 0.0165, 'grad_norm': 5.604537010192871, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.014419163577258587, 'loss_2': 0.002109527587890625, 'loss_3': -16.166337966918945, 'loss_4': 0.1255323886871338, 'epoch': 6.76}
{'loss': 0.0315, 'grad_norm': 8.812176704406738, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.022711260244250298, 'loss_2': 0.00881195068359375, 'loss_3': -16.17901611328125, 'loss_4': -0.2983952760696411, 'epoch': 6.76}
{'loss': 0.0336, 'grad_norm': 12.446188926696777, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.03211452439427376, 'loss_2': 0.0014629364013671875, 'loss_3': -16.083133697509766, 'loss_4': 0.20252281427383423, 'epoch': 6.77}
{'loss': 0.0239, 'grad_norm': 6.923808574676514, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.015820296481251717, 'loss_2': 0.0080718994140625, 'loss_3': -16.224428176879883, 'loss_4': -0.1812739074230194, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 15:46:31,128 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:31,128 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:25<1:08:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:38,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013507097959518433, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009704262018203735, 'eval_loss_2': 0.0038028359413146973, 'eval_loss_3': -18.27562713623047, 'eval_loss_4': -0.005820378661155701, 'epoch': 6.77}
{'loss': 0.0167, 'grad_norm': 6.574861526489258, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.01606937125325203, 'loss_2': 0.0006775856018066406, 'loss_3': -16.13965606689453, 'loss_4': -0.49807336926460266, 'epoch': 6.78}
{'loss': 0.0123, 'grad_norm': 6.444752216339111, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.011494421400129795, 'loss_2': 0.0008158683776855469, 'loss_3': -16.321901321411133, 'loss_4': 0.1943708062171936, 'epoch': 6.78}
{'loss': 0.0332, 'grad_norm': 12.872673034667969, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.02635408192873001, 'loss_2': 0.00688934326171875, 'loss_3': -16.260841369628906, 'loss_4': 0.2751966118812561, 'epoch': 6.79}
{'loss': 0.0345, 'grad_norm': 12.40119457244873, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.02739097736775875, 'loss_2': 0.00714874267578125, 'loss_3': -16.24758529663086, 'loss_4': 0.11551881581544876, 'epoch': 6.8}
{'loss': 0.021, 'grad_norm': 8.688344955444336, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.018091602250933647, 'loss_2': 0.0029354095458984375, 'loss_3': -16.27754783630371, 'loss_4': 0.6639459729194641, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 15:46:38,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:38,470 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:32<1:08:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:45,802 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016568351536989212, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.834, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009624650701880455, 'eval_loss_2': 0.006943702697753906, 'eval_loss_3': -18.284303665161133, 'eval_loss_4': 0.25715506076812744, 'epoch': 6.8}
{'loss': 0.0491, 'grad_norm': 18.721092224121094, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.041705094277858734, 'loss_2': 0.0073699951171875, 'loss_3': -16.213993072509766, 'loss_4': 0.7083489298820496, 'epoch': 6.81}
{'loss': 0.0248, 'grad_norm': 13.041665077209473, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.018084384500980377, 'loss_2': 0.0066680908203125, 'loss_3': -16.16160011291504, 'loss_4': 0.1583702266216278, 'epoch': 6.81}
{'loss': 0.0205, 'grad_norm': 7.635839939117432, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.018434587866067886, 'loss_2': 0.002094268798828125, 'loss_3': -16.160110473632812, 'loss_4': 0.6597102880477905, 'epoch': 6.82}
{'loss': 0.0272, 'grad_norm': 7.882880687713623, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.02214815467596054, 'loss_2': 0.0050506591796875, 'loss_3': -16.173786163330078, 'loss_4': 0.5785770416259766, 'epoch': 6.83}
{'loss': 0.0386, 'grad_norm': 13.526575088500977, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.03231131285429001, 'loss_2': 0.00628662109375, 'loss_3': -16.330223083496094, 'loss_4': 0.15601158142089844, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 15:46:45,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:45,802 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:39<1:08:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:46:53,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01685785874724388, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.634, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012778745032846928, 'eval_loss_2': 0.004079114645719528, 'eval_loss_3': -18.275293350219727, 'eval_loss_4': 0.29811450839042664, 'epoch': 6.83}
{'loss': 0.0209, 'grad_norm': 7.227962493896484, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.019718755036592484, 'loss_2': 0.00116729736328125, 'loss_3': -16.396080017089844, 'loss_4': 0.2180667370557785, 'epoch': 6.84}
{'loss': 0.0252, 'grad_norm': 6.560810565948486, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.016690418124198914, 'loss_2': 0.00846099853515625, 'loss_3': -16.140079498291016, 'loss_4': 0.41394326090812683, 'epoch': 6.84}
{'loss': 0.0318, 'grad_norm': 10.49687385559082, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.028604399412870407, 'loss_2': 0.0031585693359375, 'loss_3': -16.289108276367188, 'loss_4': 0.77850341796875, 'epoch': 6.85}
{'loss': 0.0318, 'grad_norm': 7.379175186157227, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.02479810081422329, 'loss_2': 0.0070037841796875, 'loss_3': -15.971362113952637, 'loss_4': 0.09166225790977478, 'epoch': 6.85}
{'loss': 0.0284, 'grad_norm': 7.894143581390381, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.020741906017065048, 'loss_2': 0.0076904296875, 'loss_3': -16.250635147094727, 'loss_4': 0.5871857404708862, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 15:46:53,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:46:53,140 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:47<1:08:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:00,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02728743478655815, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.419, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02102346159517765, 'eval_loss_2': 0.0062639713287353516, 'eval_loss_3': -18.217613220214844, 'eval_loss_4': 0.6301082372665405, 'epoch': 6.86}
{'loss': 0.0196, 'grad_norm': 7.656423091888428, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.018070364370942116, 'loss_2': 0.00152587890625, 'loss_3': -16.017494201660156, 'loss_4': 0.5356683731079102, 'epoch': 6.87}
{'loss': 0.1007, 'grad_norm': 20.085180282592773, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.09792863577604294, 'loss_2': 0.00272369384765625, 'loss_3': -16.21587371826172, 'loss_4': 1.1218280792236328, 'epoch': 6.87}
{'loss': 0.0407, 'grad_norm': 20.29644203186035, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.03563627600669861, 'loss_2': 0.005084991455078125, 'loss_3': -16.250526428222656, 'loss_4': 0.7404518127441406, 'epoch': 6.88}
{'loss': 0.0362, 'grad_norm': 14.748455047607422, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.030137043446302414, 'loss_2': 0.00611114501953125, 'loss_3': -16.094497680664062, 'loss_4': 0.5439238548278809, 'epoch': 6.88}
{'loss': 0.0312, 'grad_norm': 9.6539888381958, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.03013496845960617, 'loss_2': 0.0010852813720703125, 'loss_3': -16.235729217529297, 'loss_4': 0.6678652763366699, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 15:47:00,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:00,483 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:54<1:08:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:07,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033430568873882294, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.741, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.02915840968489647, 'eval_loss_2': 0.004272162914276123, 'eval_loss_3': -18.17591094970703, 'eval_loss_4': 0.962497353553772, 'epoch': 6.89}
{'loss': 0.0463, 'grad_norm': 17.348461151123047, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.04373480752110481, 'loss_2': 0.00257110595703125, 'loss_3': -16.146709442138672, 'loss_4': 1.151159405708313, 'epoch': 6.9}
{'loss': 0.0272, 'grad_norm': 7.710484027862549, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.018808387219905853, 'loss_2': 0.00841522216796875, 'loss_3': -16.41983413696289, 'loss_4': 1.2809977531433105, 'epoch': 6.9}
{'loss': 0.0322, 'grad_norm': 7.651766300201416, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.020877206698060036, 'loss_2': 0.0113372802734375, 'loss_3': -16.130054473876953, 'loss_4': 1.0200109481811523, 'epoch': 6.91}
{'loss': 0.0222, 'grad_norm': 6.4687604904174805, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.018287789076566696, 'loss_2': 0.00391387939453125, 'loss_3': -16.30306053161621, 'loss_4': 0.7833735942840576, 'epoch': 6.91}
{'loss': 0.0579, 'grad_norm': 13.097196578979492, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.0495200976729393, 'loss_2': 0.0084075927734375, 'loss_3': -16.18460464477539, 'loss_4': 1.379277229309082, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 15:47:07,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:07,825 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [30:01<1:08:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:15,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042826879769563675, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03974010422825813, 'eval_loss_2': 0.003086775541305542, 'eval_loss_3': -18.130226135253906, 'eval_loss_4': 1.2933015823364258, 'epoch': 6.92}
{'loss': 0.0303, 'grad_norm': 13.08428955078125, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.029311170801520348, 'loss_2': 0.0009584426879882812, 'loss_3': -16.252506256103516, 'loss_4': 0.8632170557975769, 'epoch': 6.92}
{'loss': 0.0416, 'grad_norm': 12.259232521057129, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.04128299653530121, 'loss_2': 0.0002849102020263672, 'loss_3': -15.909581184387207, 'loss_4': 0.9503982067108154, 'epoch': 6.93}
{'loss': 0.0363, 'grad_norm': 10.067523956298828, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.03486137464642525, 'loss_2': 0.0014362335205078125, 'loss_3': -16.174728393554688, 'loss_4': 0.8970564007759094, 'epoch': 6.94}
{'loss': 0.0525, 'grad_norm': 12.262993812561035, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.04338103160262108, 'loss_2': 0.0091400146484375, 'loss_3': -15.97365951538086, 'loss_4': 0.3003571331501007, 'epoch': 6.94}
{'loss': 0.0368, 'grad_norm': 9.14175033569336, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.030319280922412872, 'loss_2': 0.0064849853515625, 'loss_3': -16.15801429748535, 'loss_4': 1.0020692348480225, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 15:47:15,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:15,179 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [30:09<1:08:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:22,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0367623008787632, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.346, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0328085757791996, 'eval_loss_2': 0.003953725099563599, 'eval_loss_3': -18.14659309387207, 'eval_loss_4': 1.0797781944274902, 'epoch': 6.95}
{'loss': 0.0238, 'grad_norm': 7.331490993499756, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.019317835569381714, 'loss_2': 0.004451751708984375, 'loss_3': -16.39965057373047, 'loss_4': 0.9086562991142273, 'epoch': 6.95}
{'loss': 0.0295, 'grad_norm': 10.193666458129883, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.02329852245748043, 'loss_2': 0.0062103271484375, 'loss_3': -16.344858169555664, 'loss_4': 0.5201241374015808, 'epoch': 6.96}
{'loss': 0.027, 'grad_norm': 6.714780807495117, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.020871849730610847, 'loss_2': 0.00611114501953125, 'loss_3': -16.216999053955078, 'loss_4': 0.7809289693832397, 'epoch': 6.97}
{'loss': 0.0367, 'grad_norm': 12.385732650756836, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.03293458744883537, 'loss_2': 0.00380706787109375, 'loss_3': -16.310392379760742, 'loss_4': 0.940544605255127, 'epoch': 6.97}
{'loss': 0.0394, 'grad_norm': 7.074148178100586, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.02397298999130726, 'loss_2': 0.015380859375, 'loss_3': -15.995906829833984, 'loss_4': 0.7031813859939575, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 15:47:22,515 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:22,516 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [30:16<1:04:22,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 15:47:29,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017974477261304855, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.235, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013524811714887619, 'eval_loss_2': 0.004449665546417236, 'eval_loss_3': -18.228546142578125, 'eval_loss_4': 0.9160891771316528, 'epoch': 6.98}
{'loss': 0.0219, 'grad_norm': 8.647582054138184, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.021032417193055153, 'loss_2': 0.0008282661437988281, 'loss_3': -16.178695678710938, 'loss_4': 0.9744763374328613, 'epoch': 6.98}
{'loss': 0.0191, 'grad_norm': 7.056683540344238, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.01790090836584568, 'loss_2': 0.0011730194091796875, 'loss_3': -16.23345184326172, 'loss_4': 0.8231611847877502, 'epoch': 6.99}
{'loss': 0.0301, 'grad_norm': 8.829017639160156, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.026994531974196434, 'loss_2': 0.0031261444091796875, 'loss_3': -16.290088653564453, 'loss_4': 1.1636061668395996, 'epoch': 6.99}
{'loss': 0.0115, 'grad_norm': 7.415939807891846, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.005748164840042591, 'loss_2': 0.00572967529296875, 'loss_3': -16.15851593017578, 'loss_4': 1.5434859991073608, 'epoch': 7.0}
{'loss': 0.048, 'grad_norm': 20.28418731689453, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.04480978101491928, 'loss_2': 0.003238677978515625, 'loss_3': -16.1521053314209, 'loss_4': 0.6879339218139648, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 15:47:29,547 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:29,547 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:23<1:07:35,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:47:36,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014734005555510521, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010303412564098835, 'eval_loss_2': 0.004430592060089111, 'eval_loss_3': -18.27776336669922, 'eval_loss_4': 0.955152153968811, 'epoch': 7.01}
{'loss': 0.0282, 'grad_norm': 7.92207145690918, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.019230540841817856, 'loss_2': 0.008941650390625, 'loss_3': -16.226032257080078, 'loss_4': 1.1649255752563477, 'epoch': 7.01}
{'loss': 0.0303, 'grad_norm': 10.310023307800293, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.02547874115407467, 'loss_2': 0.004863739013671875, 'loss_3': -16.055828094482422, 'loss_4': 1.451782464981079, 'epoch': 7.02}
{'loss': 0.0208, 'grad_norm': 7.777782917022705, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.01870778203010559, 'loss_2': 0.0021152496337890625, 'loss_3': -15.980178833007812, 'loss_4': 0.6101374626159668, 'epoch': 7.02}
{'loss': 0.0369, 'grad_norm': 8.969413757324219, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.028488095849752426, 'loss_2': 0.0084075927734375, 'loss_3': -15.988367080688477, 'loss_4': 0.7435082197189331, 'epoch': 7.03}
{'loss': 0.0275, 'grad_norm': 7.838856220245361, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.02166447415947914, 'loss_2': 0.00579071044921875, 'loss_3': -16.074947357177734, 'loss_4': 0.5900842547416687, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 15:47:36,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:36,890 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:30<1:08:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:44,234 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015592100098729134, 'eval_runtime': 3.7994, 'eval_samples_per_second': 269.513, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011427939869463444, 'eval_loss_2': 0.004164159297943115, 'eval_loss_3': -18.303218841552734, 'eval_loss_4': 1.0215312242507935, 'epoch': 7.03}
{'loss': 0.0257, 'grad_norm': 19.80415916442871, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.025626059621572495, 'loss_2': 0.00011229515075683594, 'loss_3': -15.979536056518555, 'loss_4': 0.8695574998855591, 'epoch': 7.04}
{'loss': 0.0324, 'grad_norm': 20.963340759277344, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.024757981300354004, 'loss_2': 0.00763702392578125, 'loss_3': -16.138565063476562, 'loss_4': 1.0912760496139526, 'epoch': 7.05}
{'loss': 0.0312, 'grad_norm': 9.352460861206055, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.023723052814602852, 'loss_2': 0.00749969482421875, 'loss_3': -16.094249725341797, 'loss_4': 1.2220005989074707, 'epoch': 7.05}
{'loss': 0.0408, 'grad_norm': 9.964004516601562, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.030738387256860733, 'loss_2': 0.01010894775390625, 'loss_3': -16.219051361083984, 'loss_4': 1.4758974313735962, 'epoch': 7.06}
{'loss': 0.0414, 'grad_norm': 12.575230598449707, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.034457117319107056, 'loss_2': 0.006946563720703125, 'loss_3': -16.196619033813477, 'loss_4': 1.3295087814331055, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 15:47:44,234 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:44,234 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:38<1:08:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:51,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013377398252487183, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.921, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01088810060173273, 'eval_loss_2': 0.0024892985820770264, 'eval_loss_3': -18.287696838378906, 'eval_loss_4': 0.9954533576965332, 'epoch': 7.06}
{'loss': 0.015, 'grad_norm': 6.657716751098633, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.014320965856313705, 'loss_2': 0.0006389617919921875, 'loss_3': -15.991945266723633, 'loss_4': 0.9955634474754333, 'epoch': 7.07}
{'loss': 0.0303, 'grad_norm': 8.47450065612793, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.02311858907341957, 'loss_2': 0.00714874267578125, 'loss_3': -16.26856803894043, 'loss_4': 1.495893955230713, 'epoch': 7.08}
{'loss': 0.015, 'grad_norm': 6.233348846435547, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.011972778476774693, 'loss_2': 0.003032684326171875, 'loss_3': -16.14522361755371, 'loss_4': 1.2746162414550781, 'epoch': 7.08}
{'loss': 0.0422, 'grad_norm': 17.055696487426758, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.0397324413061142, 'loss_2': 0.002460479736328125, 'loss_3': -16.360490798950195, 'loss_4': 0.5356323719024658, 'epoch': 7.09}
{'loss': 0.0403, 'grad_norm': 10.665750503540039, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.034196771681308746, 'loss_2': 0.006092071533203125, 'loss_3': -16.165937423706055, 'loss_4': 0.7921220064163208, 'epoch': 7.09}
[INFO|trainer.py:4228] 2025-01-21 15:47:51,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:51,584 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:45<1:07:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:47:58,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012918047606945038, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009334422647953033, 'eval_loss_2': 0.0035836249589920044, 'eval_loss_3': -18.255443572998047, 'eval_loss_4': 0.4755827486515045, 'epoch': 7.09}
{'loss': 0.0186, 'grad_norm': 7.55259895324707, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.01468754094094038, 'loss_2': 0.003955841064453125, 'loss_3': -16.365903854370117, 'loss_4': 0.5073809027671814, 'epoch': 7.1}
{'loss': 0.0182, 'grad_norm': 12.985517501831055, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.017927348613739014, 'loss_2': 0.0002319812774658203, 'loss_3': -16.25740623474121, 'loss_4': 1.0221874713897705, 'epoch': 7.1}
{'loss': 0.0308, 'grad_norm': 11.141277313232422, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.02496495097875595, 'loss_2': 0.005855560302734375, 'loss_3': -16.084930419921875, 'loss_4': 0.34369024634361267, 'epoch': 7.11}
{'loss': 0.0194, 'grad_norm': 5.49565315246582, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.008928398601710796, 'loss_2': 0.01043701171875, 'loss_3': -16.251327514648438, 'loss_4': 0.14897370338439941, 'epoch': 7.12}
{'loss': 0.0246, 'grad_norm': 14.968182563781738, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.022961564362049103, 'loss_2': 0.001613616943359375, 'loss_3': -16.26857566833496, 'loss_4': 0.18853148818016052, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 15:47:58,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:47:58,929 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:52<1:07:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:06,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01581154763698578, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011112868785858154, 'eval_loss_2': 0.0046986788511276245, 'eval_loss_3': -18.234638214111328, 'eval_loss_4': 0.02627091109752655, 'epoch': 7.12}
{'loss': 0.0259, 'grad_norm': 8.815608024597168, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.02160097286105156, 'loss_2': 0.00431060791015625, 'loss_3': -16.16733169555664, 'loss_4': 0.007924914360046387, 'epoch': 7.13}
{'loss': 0.0217, 'grad_norm': 9.744393348693848, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.020446034148335457, 'loss_2': 0.0012063980102539062, 'loss_3': -16.151966094970703, 'loss_4': -0.4015798270702362, 'epoch': 7.13}
{'loss': 0.0453, 'grad_norm': 10.945712089538574, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.035159848630428314, 'loss_2': 0.01018524169921875, 'loss_3': -16.124300003051758, 'loss_4': -0.411894828081131, 'epoch': 7.14}
{'loss': 0.0104, 'grad_norm': 5.463017463684082, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.0074158222414553165, 'loss_2': 0.002948760986328125, 'loss_3': -16.289600372314453, 'loss_4': 0.2735610604286194, 'epoch': 7.15}
{'loss': 0.0294, 'grad_norm': 6.728503227233887, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.023006722331047058, 'loss_2': 0.00641632080078125, 'loss_3': -16.197132110595703, 'loss_4': -0.5990948677062988, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 15:48:06,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:06,262 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [31:00<1:07:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:13,592 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01690094545483589, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.531, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012819815427064896, 'eval_loss_2': 0.004081130027770996, 'eval_loss_3': -18.249666213989258, 'eval_loss_4': -0.1687334030866623, 'epoch': 7.15}
{'loss': 0.0229, 'grad_norm': 7.184927940368652, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.015580017119646072, 'loss_2': 0.0073089599609375, 'loss_3': -16.20741081237793, 'loss_4': -0.10166360437870026, 'epoch': 7.16}
{'loss': 0.0343, 'grad_norm': 11.692688941955566, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.03419794514775276, 'loss_2': 0.00010561943054199219, 'loss_3': -16.22241973876953, 'loss_4': 0.010661130771040916, 'epoch': 7.16}
{'loss': 0.0283, 'grad_norm': 10.763772964477539, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.02662578783929348, 'loss_2': 0.0016622543334960938, 'loss_3': -16.310630798339844, 'loss_4': -0.03391857445240021, 'epoch': 7.17}
{'loss': 0.021, 'grad_norm': 5.634596824645996, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.014322089031338692, 'loss_2': 0.006702423095703125, 'loss_3': -16.12606430053711, 'loss_4': -0.5132073163986206, 'epoch': 7.17}
{'loss': 0.0163, 'grad_norm': 6.480973243713379, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.015251734293997288, 'loss_2': 0.001087188720703125, 'loss_3': -16.191532135009766, 'loss_4': -0.5358165502548218, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 15:48:13,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:13,593 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [31:07<1:07:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:20,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01684759184718132, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012941519729793072, 'eval_loss_2': 0.003906071186065674, 'eval_loss_3': -18.270078659057617, 'eval_loss_4': -0.22120027244091034, 'epoch': 7.18}
{'loss': 0.03, 'grad_norm': 8.840625762939453, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.026654595509171486, 'loss_2': 0.003360748291015625, 'loss_3': -16.23773956298828, 'loss_4': -0.05175027251243591, 'epoch': 7.19}
{'loss': 0.0878, 'grad_norm': 20.651872634887695, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.08253293484449387, 'loss_2': 0.005298614501953125, 'loss_3': -16.160491943359375, 'loss_4': -0.4587315022945404, 'epoch': 7.19}
{'loss': 0.0284, 'grad_norm': 9.62331485748291, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.02503138966858387, 'loss_2': 0.0034160614013671875, 'loss_3': -16.453231811523438, 'loss_4': -0.34830164909362793, 'epoch': 7.2}
{'loss': 0.0145, 'grad_norm': 6.183145999908447, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.013394130393862724, 'loss_2': 0.0010967254638671875, 'loss_3': -16.168010711669922, 'loss_4': 0.11851297318935394, 'epoch': 7.2}
{'loss': 0.0138, 'grad_norm': 5.318493843078613, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.009446324780583382, 'loss_2': 0.00439453125, 'loss_3': -16.179277420043945, 'loss_4': -0.2490386664867401, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 15:48:20,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:20,936 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [31:14<1:07:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:28,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017335383221507072, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012415586039423943, 'eval_loss_2': 0.00491979718208313, 'eval_loss_3': -18.29159927368164, 'eval_loss_4': -0.11445397138595581, 'epoch': 7.21}
{'loss': 0.0192, 'grad_norm': 6.116128921508789, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.014763346873223782, 'loss_2': 0.00446319580078125, 'loss_3': -16.31746482849121, 'loss_4': -0.16804960370063782, 'epoch': 7.22}
{'loss': 0.0338, 'grad_norm': 14.52012825012207, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.03348027169704437, 'loss_2': 0.0003447532653808594, 'loss_3': -16.221546173095703, 'loss_4': -0.38814598321914673, 'epoch': 7.22}
{'loss': 0.0115, 'grad_norm': 5.545501232147217, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.00952121987938881, 'loss_2': 0.002017974853515625, 'loss_3': -16.223987579345703, 'loss_4': -0.042954299598932266, 'epoch': 7.23}
{'loss': 0.0245, 'grad_norm': 8.423843383789062, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.02328319661319256, 'loss_2': 0.001220703125, 'loss_3': -16.28810691833496, 'loss_4': -0.3240964412689209, 'epoch': 7.23}
{'loss': 0.0754, 'grad_norm': 26.79242706298828, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.06328490376472473, 'loss_2': 0.0121002197265625, 'loss_3': -16.279815673828125, 'loss_4': -0.4086781144142151, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 15:48:28,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:28,276 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:22<1:07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:35,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017467506229877472, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.845, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011881297454237938, 'eval_loss_2': 0.005586206912994385, 'eval_loss_3': -18.27283477783203, 'eval_loss_4': -0.10924337804317474, 'epoch': 7.24}
{'loss': 0.0236, 'grad_norm': 6.492868900299072, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.01566888950765133, 'loss_2': 0.0079193115234375, 'loss_3': -16.151153564453125, 'loss_4': -0.12394027411937714, 'epoch': 7.24}
{'loss': 0.0254, 'grad_norm': 9.976753234863281, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.020970581099390984, 'loss_2': 0.00443267822265625, 'loss_3': -16.23190689086914, 'loss_4': 0.2925654649734497, 'epoch': 7.25}
{'loss': 0.0495, 'grad_norm': 13.862018585205078, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.04231937602162361, 'loss_2': 0.00713348388671875, 'loss_3': -16.18954849243164, 'loss_4': 0.061547547578811646, 'epoch': 7.26}
{'loss': 0.0185, 'grad_norm': 5.8168463706970215, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.00962812453508377, 'loss_2': 0.00887298583984375, 'loss_3': -16.280885696411133, 'loss_4': -0.18509113788604736, 'epoch': 7.26}
{'loss': 0.0145, 'grad_norm': 5.680692672729492, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.013552718795835972, 'loss_2': 0.0009622573852539062, 'loss_3': -16.2729549407959, 'loss_4': -0.02590368688106537, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 15:48:35,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:35,625 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:29<1:07:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:42,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014608155936002731, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011878703720867634, 'eval_loss_2': 0.0027294494211673737, 'eval_loss_3': -18.26987075805664, 'eval_loss_4': -0.23588883876800537, 'epoch': 7.27}
{'loss': 0.0173, 'grad_norm': 6.0353684425354, 'learning_rate': 2.275e-05, 'loss_1': 0.013121472671627998, 'loss_2': 0.00414276123046875, 'loss_3': -16.28359031677246, 'loss_4': 0.01901925355195999, 'epoch': 7.27}
{'loss': 0.0166, 'grad_norm': 7.3971381187438965, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.0129050612449646, 'loss_2': 0.0037384033203125, 'loss_3': -16.364782333374023, 'loss_4': -0.5348526835441589, 'epoch': 7.28}
{'loss': 0.0209, 'grad_norm': 6.635271072387695, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.013194168917834759, 'loss_2': 0.0077056884765625, 'loss_3': -16.384601593017578, 'loss_4': -0.3986355662345886, 'epoch': 7.28}
{'loss': 0.0803, 'grad_norm': 16.427812576293945, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.06961092352867126, 'loss_2': 0.0106658935546875, 'loss_3': -16.27814483642578, 'loss_4': -0.13544315099716187, 'epoch': 7.29}
{'loss': 0.0317, 'grad_norm': 11.38601016998291, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.025894587859511375, 'loss_2': 0.0058135986328125, 'loss_3': -16.1591796875, 'loss_4': -0.44100484251976013, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 15:48:42,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:42,964 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:36<1:07:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:50,305 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022329993546009064, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014148183166980743, 'eval_loss_2': 0.00818181037902832, 'eval_loss_3': -18.23941421508789, 'eval_loss_4': -0.2310759425163269, 'epoch': 7.3}
{'loss': 0.0262, 'grad_norm': 8.380754470825195, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.022621963173151016, 'loss_2': 0.003604888916015625, 'loss_3': -16.267030715942383, 'loss_4': -0.3246150016784668, 'epoch': 7.3}
{'loss': 0.0298, 'grad_norm': 7.453047752380371, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.019351718947291374, 'loss_2': 0.01049041748046875, 'loss_3': -16.13921356201172, 'loss_4': -0.6554213166236877, 'epoch': 7.31}
{'loss': 0.0943, 'grad_norm': 16.689769744873047, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.08343043178319931, 'loss_2': 0.0109100341796875, 'loss_3': -16.237751007080078, 'loss_4': -0.17502839863300323, 'epoch': 7.31}
{'loss': 0.0921, 'grad_norm': 7.660272598266602, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.08139565587043762, 'loss_2': 0.01065826416015625, 'loss_3': -16.392589569091797, 'loss_4': 0.2421921193599701, 'epoch': 7.32}
{'loss': 0.0143, 'grad_norm': 5.7104411125183105, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.01366586983203888, 'loss_2': 0.0006818771362304688, 'loss_3': -16.230201721191406, 'loss_4': -0.6086993217468262, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 15:48:50,305 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:50,305 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:44<1:07:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:48:57,643 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019863031804561615, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.579, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015792466700077057, 'eval_loss_2': 0.004070565104484558, 'eval_loss_3': -18.19873809814453, 'eval_loss_4': -0.24080099165439606, 'epoch': 7.33}
{'loss': 0.0636, 'grad_norm': 28.556900024414062, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.06281483918428421, 'loss_2': 0.00077056884765625, 'loss_3': -16.277254104614258, 'loss_4': 0.36646705865859985, 'epoch': 7.33}
{'loss': 0.0986, 'grad_norm': 13.752596855163574, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.09791690111160278, 'loss_2': 0.000701904296875, 'loss_3': -16.13872528076172, 'loss_4': -0.4301815629005432, 'epoch': 7.34}
{'loss': 0.0153, 'grad_norm': 4.9943623542785645, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.012153766117990017, 'loss_2': 0.0031585693359375, 'loss_3': -16.2819766998291, 'loss_4': -0.6158025860786438, 'epoch': 7.34}
{'loss': 0.0363, 'grad_norm': 9.256667137145996, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.03106275573372841, 'loss_2': 0.00521087646484375, 'loss_3': -16.211271286010742, 'loss_4': -0.09949035942554474, 'epoch': 7.35}
{'loss': 0.0392, 'grad_norm': 11.17289924621582, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.0378698855638504, 'loss_2': 0.0013093948364257812, 'loss_3': -16.13831329345703, 'loss_4': 0.18809297680854797, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 15:48:57,643 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:48:57,644 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:51<1:07:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:04,972 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018757309764623642, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.015546925365924835, 'eval_loss_2': 0.0032103843986988068, 'eval_loss_3': -18.205242156982422, 'eval_loss_4': -0.19296357035636902, 'epoch': 7.35}
{'loss': 0.0727, 'grad_norm': 20.947689056396484, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.06962474435567856, 'loss_2': 0.0030994415283203125, 'loss_3': -16.18925666809082, 'loss_4': -0.38398295640945435, 'epoch': 7.36}
{'loss': 0.0119, 'grad_norm': 5.3007426261901855, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.011498287320137024, 'loss_2': 0.0004279613494873047, 'loss_3': -16.1416015625, 'loss_4': -0.5509433746337891, 'epoch': 7.37}
{'loss': 0.0297, 'grad_norm': 8.27004337310791, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.022006167098879814, 'loss_2': 0.007701873779296875, 'loss_3': -16.401519775390625, 'loss_4': -0.14246182143688202, 'epoch': 7.37}
{'loss': 0.0144, 'grad_norm': 5.516489505767822, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.012663504108786583, 'loss_2': 0.001750946044921875, 'loss_3': -16.52322769165039, 'loss_4': -0.529565691947937, 'epoch': 7.38}
{'loss': 0.0423, 'grad_norm': 13.806584358215332, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.0393965058028698, 'loss_2': 0.0028934478759765625, 'loss_3': -16.30440902709961, 'loss_4': -0.17910973727703094, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 15:49:04,973 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:04,973 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:58<1:07:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:12,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020627599209547043, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016663191840052605, 'eval_loss_2': 0.003964405506849289, 'eval_loss_3': -18.199758529663086, 'eval_loss_4': -0.06392525881528854, 'epoch': 7.38}
{'loss': 0.0347, 'grad_norm': 11.647353172302246, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.029816269874572754, 'loss_2': 0.004863739013671875, 'loss_3': -16.182701110839844, 'loss_4': -0.3418336808681488, 'epoch': 7.39}
{'loss': 0.0907, 'grad_norm': 8.698443412780762, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.08833201974630356, 'loss_2': 0.00240325927734375, 'loss_3': -16.314586639404297, 'loss_4': 0.42017605900764465, 'epoch': 7.4}
{'loss': 0.0272, 'grad_norm': 6.198415279388428, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.01477881707251072, 'loss_2': 0.01239013671875, 'loss_3': -16.289993286132812, 'loss_4': -0.1846989393234253, 'epoch': 7.4}
{'loss': 0.042, 'grad_norm': 8.157544136047363, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.028971605002880096, 'loss_2': 0.01300811767578125, 'loss_3': -16.11208152770996, 'loss_4': -0.05519606173038483, 'epoch': 7.41}
{'loss': 0.0217, 'grad_norm': 7.149601459503174, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.01781362108886242, 'loss_2': 0.0039215087890625, 'loss_3': -16.068357467651367, 'loss_4': -0.08793987333774567, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 15:49:12,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:12,310 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [32:06<1:06:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:19,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018986977636814117, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.445, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.015464612282812595, 'eval_loss_2': 0.0035223662853240967, 'eval_loss_3': -18.208250045776367, 'eval_loss_4': 0.350180983543396, 'epoch': 7.41}
{'loss': 0.0561, 'grad_norm': 11.816404342651367, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.04429853707551956, 'loss_2': 0.0117950439453125, 'loss_3': -16.25963020324707, 'loss_4': 0.16264384984970093, 'epoch': 7.42}
{'loss': 0.0284, 'grad_norm': 12.363760948181152, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.02666296809911728, 'loss_2': 0.0017652511596679688, 'loss_3': -16.282421112060547, 'loss_4': 0.1389859914779663, 'epoch': 7.42}
{'loss': 0.0199, 'grad_norm': 6.213895797729492, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.018300950527191162, 'loss_2': 0.0016040802001953125, 'loss_3': -16.275650024414062, 'loss_4': 0.7677747011184692, 'epoch': 7.43}
{'loss': 0.0165, 'grad_norm': 5.723512649536133, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.010708763264119625, 'loss_2': 0.00579071044921875, 'loss_3': -16.330188751220703, 'loss_4': 0.43616509437561035, 'epoch': 7.44}
{'loss': 0.0219, 'grad_norm': 7.476161956787109, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.01889195665717125, 'loss_2': 0.00301361083984375, 'loss_3': -16.141082763671875, 'loss_4': 0.505831241607666, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 15:49:19,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:19,654 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:13<1:06:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:26,988 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0171438567340374, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01367304939776659, 'eval_loss_2': 0.003470808267593384, 'eval_loss_3': -18.228872299194336, 'eval_loss_4': 0.6899540424346924, 'epoch': 7.44}
{'loss': 0.0265, 'grad_norm': 8.741185188293457, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.01973843201994896, 'loss_2': 0.00679779052734375, 'loss_3': -16.050540924072266, 'loss_4': 0.4168824553489685, 'epoch': 7.45}
{'loss': 0.0182, 'grad_norm': 7.617486000061035, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.01776941493153572, 'loss_2': 0.0004172325134277344, 'loss_3': -16.29751205444336, 'loss_4': 0.5645958185195923, 'epoch': 7.45}
{'loss': 0.0194, 'grad_norm': 8.610445022583008, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.01903173141181469, 'loss_2': 0.0003216266632080078, 'loss_3': -16.171279907226562, 'loss_4': 0.3565123975276947, 'epoch': 7.46}
{'loss': 0.015, 'grad_norm': 6.823290824890137, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.015021500177681446, 'loss_2': 1.049041748046875e-05, 'loss_3': -16.30733299255371, 'loss_4': 0.8490265607833862, 'epoch': 7.47}
{'loss': 0.0409, 'grad_norm': 10.387760162353516, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.027781562879681587, 'loss_2': 0.01312255859375, 'loss_3': -16.10120391845703, 'loss_4': 1.082797646522522, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 15:49:26,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:26,988 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:20<1:06:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:34,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02186448499560356, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.577, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011686036363244057, 'eval_loss_2': 0.010178446769714355, 'eval_loss_3': -18.23508644104004, 'eval_loss_4': 0.9060332179069519, 'epoch': 7.47}
{'loss': 0.0664, 'grad_norm': 25.615650177001953, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.042515646666288376, 'loss_2': 0.023895263671875, 'loss_3': -16.064348220825195, 'loss_4': 1.1236484050750732, 'epoch': 7.48}
{'loss': 0.0286, 'grad_norm': 6.404167175292969, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.011917591094970703, 'loss_2': 0.01666259765625, 'loss_3': -16.258686065673828, 'loss_4': 0.7395771741867065, 'epoch': 7.48}
{'loss': 0.0285, 'grad_norm': 10.51563549041748, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.015978647395968437, 'loss_2': 0.0125579833984375, 'loss_3': -16.17167091369629, 'loss_4': 1.1960595846176147, 'epoch': 7.49}
{'loss': 0.0205, 'grad_norm': 6.348613739013672, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.013761983253061771, 'loss_2': 0.00673675537109375, 'loss_3': -16.108600616455078, 'loss_4': 1.0502158403396606, 'epoch': 7.49}
{'loss': 0.0231, 'grad_norm': 7.815724849700928, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.016957903280854225, 'loss_2': 0.0061492919921875, 'loss_3': -16.044322967529297, 'loss_4': 1.0576167106628418, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 15:49:34,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:34,328 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:28<1:06:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:41,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024689791724085808, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.577, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013064265251159668, 'eval_loss_2': 0.011625528335571289, 'eval_loss_3': -18.198463439941406, 'eval_loss_4': 1.1713941097259521, 'epoch': 7.5}
{'loss': 0.0288, 'grad_norm': 6.503063201904297, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.01716327667236328, 'loss_2': 0.01165771484375, 'loss_3': -16.134557723999023, 'loss_4': 0.8189228773117065, 'epoch': 7.51}
{'loss': 0.0135, 'grad_norm': 5.753835201263428, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.00941758044064045, 'loss_2': 0.00408935546875, 'loss_3': -16.448211669921875, 'loss_4': 1.3656251430511475, 'epoch': 7.51}
{'loss': 0.0401, 'grad_norm': 11.998428344726562, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.030645262449979782, 'loss_2': 0.00949859619140625, 'loss_3': -16.114362716674805, 'loss_4': 0.9837837219238281, 'epoch': 7.52}
{'loss': 0.0447, 'grad_norm': 15.066401481628418, 'learning_rate': 2.25e-05, 'loss_1': 0.04212140291929245, 'loss_2': 0.002620697021484375, 'loss_3': -16.047119140625, 'loss_4': 0.953708827495575, 'epoch': 7.52}
{'loss': 0.0615, 'grad_norm': 23.686790466308594, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.06121080368757248, 'loss_2': 0.0002741813659667969, 'loss_3': -16.009294509887695, 'loss_4': 1.5804307460784912, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 15:49:41,665 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:41,665 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:35<1:06:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:49:49,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01587206870317459, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012270575389266014, 'eval_loss_2': 0.0036014914512634277, 'eval_loss_3': -18.213340759277344, 'eval_loss_4': 1.576162576675415, 'epoch': 7.53}
{'loss': 0.0225, 'grad_norm': 7.744076728820801, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.01995549164712429, 'loss_2': 0.002552032470703125, 'loss_3': -16.06846809387207, 'loss_4': 1.114166021347046, 'epoch': 7.53}
{'loss': 0.0305, 'grad_norm': 9.158767700195312, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.022255079820752144, 'loss_2': 0.0082244873046875, 'loss_3': -16.136104583740234, 'loss_4': 1.4204885959625244, 'epoch': 7.54}
{'loss': 0.0695, 'grad_norm': 25.756372451782227, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.06483674794435501, 'loss_2': 0.0046234130859375, 'loss_3': -16.203231811523438, 'loss_4': 2.5302796363830566, 'epoch': 7.55}
{'loss': 0.07, 'grad_norm': 16.742645263671875, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.05893513932824135, 'loss_2': 0.011077880859375, 'loss_3': -16.07143783569336, 'loss_4': 1.871953010559082, 'epoch': 7.55}
{'loss': 0.0363, 'grad_norm': 14.162749290466309, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.02281368151307106, 'loss_2': 0.013458251953125, 'loss_3': -16.173717498779297, 'loss_4': 1.4575868844985962, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 15:49:49,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:49,015 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:43<1:07:32,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:49:56,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0179422777146101, 'eval_runtime': 4.0114, 'eval_samples_per_second': 255.276, 'eval_steps_per_second': 3.989, 'eval_loss_1': 0.01146182231605053, 'eval_loss_2': 0.00648045539855957, 'eval_loss_3': -18.228504180908203, 'eval_loss_4': 1.529406189918518, 'epoch': 7.56}
{'loss': 0.0242, 'grad_norm': 8.241744041442871, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.0195615291595459, 'loss_2': 0.0046844482421875, 'loss_3': -16.1112060546875, 'loss_4': 1.7438498735427856, 'epoch': 7.56}
{'loss': 0.0233, 'grad_norm': 7.44427490234375, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.014866256155073643, 'loss_2': 0.008392333984375, 'loss_3': -16.12537956237793, 'loss_4': 1.5066016912460327, 'epoch': 7.57}
{'loss': 0.0205, 'grad_norm': 13.145297050476074, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.01991119422018528, 'loss_2': 0.0006251335144042969, 'loss_3': -16.10159683227539, 'loss_4': 1.4848222732543945, 'epoch': 7.58}
{'loss': 0.0356, 'grad_norm': 9.198540687561035, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.0344633050262928, 'loss_2': 0.001102447509765625, 'loss_3': -16.180641174316406, 'loss_4': 1.202302098274231, 'epoch': 7.58}
{'loss': 0.032, 'grad_norm': 6.751982688903809, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.019821107387542725, 'loss_2': 0.0121917724609375, 'loss_3': -16.31857681274414, 'loss_4': 1.3539848327636719, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 15:49:56,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:49:56,562 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:50<1:06:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:03,900 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01717318966984749, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.316, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01279558427631855, 'eval_loss_2': 0.004377603530883789, 'eval_loss_3': -18.248584747314453, 'eval_loss_4': 1.3467092514038086, 'epoch': 7.59}
{'loss': 0.0459, 'grad_norm': 11.20650577545166, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.03918135538697243, 'loss_2': 0.006710052490234375, 'loss_3': -16.26089096069336, 'loss_4': 1.5637829303741455, 'epoch': 7.59}
{'loss': 0.0443, 'grad_norm': 16.22562599182129, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.03647136315703392, 'loss_2': 0.0078277587890625, 'loss_3': -16.117881774902344, 'loss_4': 1.1146759986877441, 'epoch': 7.6}
{'loss': 0.0565, 'grad_norm': 19.393346786499023, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.05126015841960907, 'loss_2': 0.00521087646484375, 'loss_3': -16.15896224975586, 'loss_4': 1.4877068996429443, 'epoch': 7.6}
{'loss': 0.0266, 'grad_norm': 10.537124633789062, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.02290072664618492, 'loss_2': 0.0037364959716796875, 'loss_3': -16.314533233642578, 'loss_4': 1.698317289352417, 'epoch': 7.61}
{'loss': 0.0325, 'grad_norm': 7.960963249206543, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.025042222812771797, 'loss_2': 0.00749969482421875, 'loss_3': -16.10242462158203, 'loss_4': 1.5583224296569824, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 15:50:03,900 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:03,900 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:57<1:06:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:11,242 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016694242134690285, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012819701805710793, 'eval_loss_2': 0.003874540328979492, 'eval_loss_3': -18.25743865966797, 'eval_loss_4': 0.9613585472106934, 'epoch': 7.62}
{'loss': 0.0281, 'grad_norm': 8.633710861206055, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.02678055316209793, 'loss_2': 0.0012912750244140625, 'loss_3': -16.24528694152832, 'loss_4': 0.6515874862670898, 'epoch': 7.62}
{'loss': 0.028, 'grad_norm': 8.841131210327148, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.022994166240096092, 'loss_2': 0.00501251220703125, 'loss_3': -16.16518211364746, 'loss_4': 1.038461446762085, 'epoch': 7.63}
{'loss': 0.0251, 'grad_norm': 9.91463851928711, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.0247036125510931, 'loss_2': 0.00041294097900390625, 'loss_3': -16.148534774780273, 'loss_4': 0.18551471829414368, 'epoch': 7.63}
{'loss': 0.0155, 'grad_norm': 5.806515693664551, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.01527221966534853, 'loss_2': 0.0001819133758544922, 'loss_3': -16.43695640563965, 'loss_4': 0.6746102571487427, 'epoch': 7.64}
{'loss': 0.0553, 'grad_norm': 13.96802806854248, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.03972448781132698, 'loss_2': 0.01556396484375, 'loss_3': -16.11614227294922, 'loss_4': 0.7418269515037537, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 15:50:11,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:11,243 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [33:05<1:06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:18,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024889223277568817, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.104, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012902489863336086, 'eval_loss_2': 0.011986732482910156, 'eval_loss_3': -18.257930755615234, 'eval_loss_4': 0.5265498757362366, 'epoch': 7.65}
{'loss': 0.0434, 'grad_norm': 13.754222869873047, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.03743346035480499, 'loss_2': 0.005916595458984375, 'loss_3': -16.199617385864258, 'loss_4': 0.6404982209205627, 'epoch': 7.65}
{'loss': 0.02, 'grad_norm': 5.442487716674805, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.011533033102750778, 'loss_2': 0.00844573974609375, 'loss_3': -16.123977661132812, 'loss_4': 0.48285791277885437, 'epoch': 7.66}
{'loss': 0.0303, 'grad_norm': 7.334095478057861, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.019447816535830498, 'loss_2': 0.010894775390625, 'loss_3': -16.08578872680664, 'loss_4': 0.6884049773216248, 'epoch': 7.66}
{'loss': 0.0411, 'grad_norm': 11.160292625427246, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.02614576928317547, 'loss_2': 0.0149383544921875, 'loss_3': -16.390974044799805, 'loss_4': 0.7898632287979126, 'epoch': 7.67}
{'loss': 0.0218, 'grad_norm': 6.868253231048584, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.013029329478740692, 'loss_2': 0.0087432861328125, 'loss_3': -16.462818145751953, 'loss_4': 0.5035006999969482, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 15:50:18,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:18,591 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [33:12<1:06:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:25,936 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019137002527713776, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014824667945504189, 'eval_loss_2': 0.004312336444854736, 'eval_loss_3': -18.27520751953125, 'eval_loss_4': 0.6324118375778198, 'epoch': 7.67}
{'loss': 0.0481, 'grad_norm': 10.814118385314941, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.03706280142068863, 'loss_2': 0.011016845703125, 'loss_3': -16.207143783569336, 'loss_4': 0.5327404141426086, 'epoch': 7.68}
{'loss': 0.0451, 'grad_norm': 13.118800163269043, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.039460424333810806, 'loss_2': 0.00562286376953125, 'loss_3': -16.25971221923828, 'loss_4': 0.8968098163604736, 'epoch': 7.69}
{'loss': 0.0379, 'grad_norm': 6.919722557067871, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.030915576964616776, 'loss_2': 0.0069580078125, 'loss_3': -16.39022445678711, 'loss_4': 1.3159559965133667, 'epoch': 7.69}
{'loss': 0.0206, 'grad_norm': 7.242652416229248, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.019160771742463112, 'loss_2': 0.0014553070068359375, 'loss_3': -16.2327938079834, 'loss_4': 0.8452507257461548, 'epoch': 7.7}
{'loss': 0.1253, 'grad_norm': 23.419706344604492, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.12166272103786469, 'loss_2': 0.003673553466796875, 'loss_3': -16.18730926513672, 'loss_4': 0.7492579221725464, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 15:50:25,936 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:25,937 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:19<1:06:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:33,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029209060594439507, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.443, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.018239421769976616, 'eval_loss_2': 0.01096963882446289, 'eval_loss_3': -18.274141311645508, 'eval_loss_4': 0.9135379791259766, 'epoch': 7.7}
{'loss': 0.0304, 'grad_norm': 6.92840576171875, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.027447231113910675, 'loss_2': 0.002964019775390625, 'loss_3': -16.235721588134766, 'loss_4': 1.079167366027832, 'epoch': 7.71}
{'loss': 0.0361, 'grad_norm': 7.70540714263916, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.02419830672442913, 'loss_2': 0.0118865966796875, 'loss_3': -16.08230209350586, 'loss_4': 0.9252210855484009, 'epoch': 7.72}
{'loss': 0.0827, 'grad_norm': 16.20178985595703, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.0655135065317154, 'loss_2': 0.0171966552734375, 'loss_3': -16.353641510009766, 'loss_4': 1.5494694709777832, 'epoch': 7.72}
{'loss': 0.0405, 'grad_norm': 9.405745506286621, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.03461095318198204, 'loss_2': 0.00591278076171875, 'loss_3': -16.222484588623047, 'loss_4': 0.8805583715438843, 'epoch': 7.73}
{'loss': 0.0432, 'grad_norm': 10.510374069213867, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.03467409312725067, 'loss_2': 0.00853729248046875, 'loss_3': -16.235857009887695, 'loss_4': 1.2296502590179443, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 15:50:33,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:33,299 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:27<1:06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:40,653 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0258207805454731, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.018160514533519745, 'eval_loss_2': 0.007660269737243652, 'eval_loss_3': -18.24419403076172, 'eval_loss_4': 1.1281890869140625, 'epoch': 7.73}
{'loss': 0.0706, 'grad_norm': 18.288330078125, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.06713133305311203, 'loss_2': 0.00347900390625, 'loss_3': -16.091617584228516, 'loss_4': 0.8102370500564575, 'epoch': 7.74}
{'loss': 0.0263, 'grad_norm': 7.910287380218506, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.024869060143828392, 'loss_2': 0.001384735107421875, 'loss_3': -16.126413345336914, 'loss_4': 1.2686152458190918, 'epoch': 7.74}
{'loss': 0.0169, 'grad_norm': 5.806246757507324, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.013869007118046284, 'loss_2': 0.003032684326171875, 'loss_3': -16.12043571472168, 'loss_4': 0.9862803816795349, 'epoch': 7.75}
{'loss': 0.0491, 'grad_norm': 18.760414123535156, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.04554460197687149, 'loss_2': 0.0035247802734375, 'loss_3': -16.24266815185547, 'loss_4': 1.1657418012619019, 'epoch': 7.76}
{'loss': 0.0296, 'grad_norm': 5.681335926055908, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.01603887788951397, 'loss_2': 0.0135955810546875, 'loss_3': -16.295921325683594, 'loss_4': 1.0525331497192383, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 15:50:40,653 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:40,653 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:34<1:06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:48,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02560858055949211, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.174, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016872331500053406, 'eval_loss_2': 0.008736252784729004, 'eval_loss_3': -18.18225860595703, 'eval_loss_4': 1.2748430967330933, 'epoch': 7.76}
{'loss': 0.1379, 'grad_norm': 45.681888580322266, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.128739595413208, 'loss_2': 0.0091705322265625, 'loss_3': -16.00605583190918, 'loss_4': 1.2052366733551025, 'epoch': 7.77}
{'loss': 0.0491, 'grad_norm': 14.239938735961914, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.03725280612707138, 'loss_2': 0.011810302734375, 'loss_3': -15.99914836883545, 'loss_4': 1.0785809755325317, 'epoch': 7.77}
{'loss': 0.0368, 'grad_norm': 8.628334045410156, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.02721353992819786, 'loss_2': 0.0095977783203125, 'loss_3': -16.050859451293945, 'loss_4': 1.509781837463379, 'epoch': 7.78}
{'loss': 0.0767, 'grad_norm': 18.61856460571289, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.06434308737516403, 'loss_2': 0.012359619140625, 'loss_3': -15.90980339050293, 'loss_4': 1.1847866773605347, 'epoch': 7.78}
{'loss': 0.0232, 'grad_norm': 5.7177414894104, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.013350462540984154, 'loss_2': 0.0098419189453125, 'loss_3': -16.087656021118164, 'loss_4': 0.8940847516059875, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 15:50:48,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:48,004 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:41<1:06:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:50:55,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029278188943862915, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.578, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.019353777170181274, 'eval_loss_2': 0.00992441177368164, 'eval_loss_3': -18.132793426513672, 'eval_loss_4': 1.1945908069610596, 'epoch': 7.79}
{'loss': 0.0224, 'grad_norm': 5.594640731811523, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.012951331213116646, 'loss_2': 0.00942230224609375, 'loss_3': -16.394550323486328, 'loss_4': 1.7184535264968872, 'epoch': 7.8}
{'loss': 0.0289, 'grad_norm': 7.538285255432129, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.020893234759569168, 'loss_2': 0.0080108642578125, 'loss_3': -16.21042251586914, 'loss_4': 1.1207084655761719, 'epoch': 7.8}
{'loss': 0.0251, 'grad_norm': 8.403637886047363, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.02051895298063755, 'loss_2': 0.0045623779296875, 'loss_3': -15.937450408935547, 'loss_4': 0.7411868572235107, 'epoch': 7.81}
{'loss': 0.0132, 'grad_norm': 4.905767440795898, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.013022460043430328, 'loss_2': 0.00022721290588378906, 'loss_3': -16.321826934814453, 'loss_4': 1.236413836479187, 'epoch': 7.81}
{'loss': 0.0162, 'grad_norm': 5.664309501647949, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.00923964288085699, 'loss_2': 0.0069122314453125, 'loss_3': -16.112895965576172, 'loss_4': 0.9189794659614563, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 15:50:55,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:50:55,368 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:49<1:06:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:02,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02272128313779831, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.046, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.020049788057804108, 'eval_loss_2': 0.0026714950799942017, 'eval_loss_3': -18.08188247680664, 'eval_loss_4': 0.9320729970932007, 'epoch': 7.82}
{'loss': 0.0466, 'grad_norm': 11.855990409851074, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.043352480977773666, 'loss_2': 0.003215789794921875, 'loss_3': -16.314422607421875, 'loss_4': 1.122162103652954, 'epoch': 7.83}
{'loss': 0.0222, 'grad_norm': 8.115775108337402, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.019375966861844063, 'loss_2': 0.00279998779296875, 'loss_3': -16.149965286254883, 'loss_4': 0.8752905130386353, 'epoch': 7.83}
{'loss': 0.0611, 'grad_norm': 16.595264434814453, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.0562833771109581, 'loss_2': 0.0048065185546875, 'loss_3': -16.067453384399414, 'loss_4': 0.6998281478881836, 'epoch': 7.84}
{'loss': 0.0173, 'grad_norm': 8.178816795349121, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.014736698009073734, 'loss_2': 0.00252532958984375, 'loss_3': -16.039520263671875, 'loss_4': 0.37347739934921265, 'epoch': 7.84}
{'loss': 0.0235, 'grad_norm': 7.891166687011719, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.013652280904352665, 'loss_2': 0.0098114013671875, 'loss_3': -16.02968978881836, 'loss_4': 0.6909383535385132, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 15:51:02,729 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:02,729 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:56<1:05:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:10,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02210741862654686, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.128, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.0175778828561306, 'eval_loss_2': 0.00452953577041626, 'eval_loss_3': -18.087867736816406, 'eval_loss_4': 0.6626285910606384, 'epoch': 7.85}
{'loss': 0.0639, 'grad_norm': 19.133359909057617, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.05989791452884674, 'loss_2': 0.00397491455078125, 'loss_3': -16.104618072509766, 'loss_4': 0.6438839435577393, 'epoch': 7.85}
{'loss': 0.0154, 'grad_norm': 5.954259872436523, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.011949143372476101, 'loss_2': 0.00345611572265625, 'loss_3': -16.08502197265625, 'loss_4': 0.4133462607860565, 'epoch': 7.86}
{'loss': 0.0238, 'grad_norm': 6.348992824554443, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.02091478742659092, 'loss_2': 0.0029296875, 'loss_3': -16.01296043395996, 'loss_4': 0.7726346850395203, 'epoch': 7.87}
{'loss': 0.0126, 'grad_norm': 5.581923961639404, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.01065479964017868, 'loss_2': 0.0019207000732421875, 'loss_3': -16.0290470123291, 'loss_4': 0.013851441442966461, 'epoch': 7.87}
{'loss': 0.0177, 'grad_norm': 6.21690034866333, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.015198218636214733, 'loss_2': 0.0025157928466796875, 'loss_3': -16.23247528076172, 'loss_4': 0.6254904270172119, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 15:51:10,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:10,084 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [34:04<1:05:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:17,428 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01905098930001259, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.186, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015277599915862083, 'eval_loss_2': 0.0037733912467956543, 'eval_loss_3': -18.11371612548828, 'eval_loss_4': 0.5863969326019287, 'epoch': 7.88}
{'loss': 0.0207, 'grad_norm': 7.186885833740234, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.015671033412218094, 'loss_2': 0.0050201416015625, 'loss_3': -16.23918914794922, 'loss_4': 0.582495391368866, 'epoch': 7.88}
{'loss': 0.0136, 'grad_norm': 5.204444885253906, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.012959836050868034, 'loss_2': 0.0006222724914550781, 'loss_3': -16.069072723388672, 'loss_4': 0.5725104808807373, 'epoch': 7.89}
{'loss': 0.0215, 'grad_norm': 6.690898418426514, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.01414578314870596, 'loss_2': 0.0073699951171875, 'loss_3': -16.330703735351562, 'loss_4': 0.8781089186668396, 'epoch': 7.9}
{'loss': 0.0198, 'grad_norm': 7.136804580688477, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.012992624193429947, 'loss_2': 0.0068511962890625, 'loss_3': -16.368831634521484, 'loss_4': 0.6758146286010742, 'epoch': 7.9}
{'loss': 0.0166, 'grad_norm': 5.686601161956787, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.010703853331506252, 'loss_2': 0.00594329833984375, 'loss_3': -16.242412567138672, 'loss_4': 0.07262085378170013, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 15:51:17,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:17,428 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [34:11<1:05:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:24,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01743388921022415, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.311, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013455711305141449, 'eval_loss_2': 0.003978177905082703, 'eval_loss_3': -18.1509952545166, 'eval_loss_4': 0.7171704769134521, 'epoch': 7.91}
{'loss': 0.0177, 'grad_norm': 5.851555347442627, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.010604617185890675, 'loss_2': 0.00710296630859375, 'loss_3': -16.27855110168457, 'loss_4': 0.5798144340515137, 'epoch': 7.91}
{'loss': 0.0282, 'grad_norm': 12.2748384475708, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.024264778941869736, 'loss_2': 0.0039520263671875, 'loss_3': -16.295204162597656, 'loss_4': 0.5582009553909302, 'epoch': 7.92}
{'loss': 0.0182, 'grad_norm': 6.271394729614258, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.009635727852582932, 'loss_2': 0.00859832763671875, 'loss_3': -16.418581008911133, 'loss_4': 0.8140978813171387, 'epoch': 7.92}
{'loss': 0.0289, 'grad_norm': 9.650391578674316, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.021014109253883362, 'loss_2': 0.00789642333984375, 'loss_3': -16.451549530029297, 'loss_4': 0.9880647659301758, 'epoch': 7.93}
{'loss': 0.0448, 'grad_norm': 35.591400146484375, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.038737401366233826, 'loss_2': 0.0060882568359375, 'loss_3': -16.31078338623047, 'loss_4': 1.1069539785385132, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 15:51:24,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:24,770 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:18<1:05:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:51:32,113 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023425323888659477, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.459, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013766869902610779, 'eval_loss_2': 0.009658455848693848, 'eval_loss_3': -18.178796768188477, 'eval_loss_4': 1.0120062828063965, 'epoch': 7.94}
{'loss': 0.0279, 'grad_norm': 6.399576187133789, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.018817173317074776, 'loss_2': 0.009033203125, 'loss_3': -16.325387954711914, 'loss_4': 1.2993853092193604, 'epoch': 7.94}
{'loss': 0.0385, 'grad_norm': 21.9614315032959, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.030555743724107742, 'loss_2': 0.00794219970703125, 'loss_3': -16.081789016723633, 'loss_4': 0.9568607807159424, 'epoch': 7.95}
{'loss': 0.0429, 'grad_norm': 12.534684181213379, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.03617106378078461, 'loss_2': 0.006683349609375, 'loss_3': -16.227842330932617, 'loss_4': 1.751159429550171, 'epoch': 7.95}
{'loss': 0.0334, 'grad_norm': 11.121692657470703, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.029754620045423508, 'loss_2': 0.003688812255859375, 'loss_3': -16.385173797607422, 'loss_4': 1.0680177211761475, 'epoch': 7.96}
{'loss': 0.0302, 'grad_norm': 13.099677085876465, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.02941308356821537, 'loss_2': 0.0008339881896972656, 'loss_3': -16.378097534179688, 'loss_4': 1.1233553886413574, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 15:51:32,113 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:32,113 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:26<1:05:07,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:51:39,440 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020546797662973404, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.426, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.015469730831682682, 'eval_loss_2': 0.005077064037322998, 'eval_loss_3': -18.221227645874023, 'eval_loss_4': 1.2323130369186401, 'epoch': 7.97}
{'loss': 0.0172, 'grad_norm': 5.9414873123168945, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.016627592965960503, 'loss_2': 0.0005855560302734375, 'loss_3': -16.067527770996094, 'loss_4': 1.080899953842163, 'epoch': 7.97}
{'loss': 0.0442, 'grad_norm': 16.35593605041504, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.039521075785160065, 'loss_2': 0.004673004150390625, 'loss_3': -16.397201538085938, 'loss_4': 1.5083849430084229, 'epoch': 7.98}
{'loss': 0.0317, 'grad_norm': 9.036360740661621, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.031397782266139984, 'loss_2': 0.0002524852752685547, 'loss_3': -16.276763916015625, 'loss_4': 1.6362714767456055, 'epoch': 7.98}
{'loss': 0.0346, 'grad_norm': 9.066136360168457, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.03074396774172783, 'loss_2': 0.0038700103759765625, 'loss_3': -16.219085693359375, 'loss_4': 1.7605797052383423, 'epoch': 7.99}
{'loss': 0.0288, 'grad_norm': 7.225676536560059, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.02156953141093254, 'loss_2': 0.00726318359375, 'loss_3': -16.280588150024414, 'loss_4': 0.7947940826416016, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 15:51:39,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:39,441 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:33<1:04:04,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 15:51:46,496 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018648670986294746, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.297, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.015001119114458561, 'eval_loss_2': 0.003647550940513611, 'eval_loss_3': -18.19869613647461, 'eval_loss_4': 1.1014282703399658, 'epoch': 7.99}
{'loss': 0.0359, 'grad_norm': 12.460821151733398, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.03225228935480118, 'loss_2': 0.003620147705078125, 'loss_3': -16.145959854125977, 'loss_4': 0.39754199981689453, 'epoch': 8.0}
{'loss': 0.0283, 'grad_norm': 7.977271556854248, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.022898299619555473, 'loss_2': 0.005401611328125, 'loss_3': -16.383453369140625, 'loss_4': 0.9058473110198975, 'epoch': 8.01}
{'loss': 0.0165, 'grad_norm': 5.508703231811523, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.01582222804427147, 'loss_2': 0.0006313323974609375, 'loss_3': -16.395076751708984, 'loss_4': 0.5547183156013489, 'epoch': 8.01}
{'loss': 0.015, 'grad_norm': 5.577174663543701, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.011930546723306179, 'loss_2': 0.003078460693359375, 'loss_3': -16.32896614074707, 'loss_4': 0.8292217254638672, 'epoch': 8.02}
{'loss': 0.0139, 'grad_norm': 6.19048547744751, 'learning_rate': 2.2e-05, 'loss_1': 0.01227145828306675, 'loss_2': 0.00157928466796875, 'loss_3': -16.100353240966797, 'loss_4': 0.3836182951927185, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 15:51:46,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:46,496 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:40<1:05:03,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:51:53,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018879707902669907, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.005, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014604474417865276, 'eval_loss_2': 0.004275232553482056, 'eval_loss_3': -18.185565948486328, 'eval_loss_4': 0.5725060701370239, 'epoch': 8.02}
{'loss': 0.0234, 'grad_norm': 6.719988822937012, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.01973770558834076, 'loss_2': 0.003692626953125, 'loss_3': -16.194517135620117, 'loss_4': 1.2046000957489014, 'epoch': 8.03}
{'loss': 0.0243, 'grad_norm': 8.585577011108398, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.024003101512789726, 'loss_2': 0.0002970695495605469, 'loss_3': -16.263446807861328, 'loss_4': 1.2039401531219482, 'epoch': 8.03}
{'loss': 0.0217, 'grad_norm': 7.208080291748047, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.020498473197221756, 'loss_2': 0.0011625289916992188, 'loss_3': -16.311756134033203, 'loss_4': 0.8133857250213623, 'epoch': 8.04}
{'loss': 0.0141, 'grad_norm': 5.8067851066589355, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.013206268660724163, 'loss_2': 0.0009288787841796875, 'loss_3': -16.367969512939453, 'loss_4': 0.5963695049285889, 'epoch': 8.05}
{'loss': 0.0239, 'grad_norm': 6.629999160766602, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.01737481728196144, 'loss_2': 0.00647735595703125, 'loss_3': -16.466331481933594, 'loss_4': 0.6101027727127075, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 15:51:53,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:51:53,843 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:47<1:05:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:01,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019493574276566505, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.547, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.0137858334928751, 'eval_loss_2': 0.005707740783691406, 'eval_loss_3': -18.202730178833008, 'eval_loss_4': 0.2694546580314636, 'epoch': 8.05}
{'loss': 0.0223, 'grad_norm': 6.817313194274902, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.01992781087756157, 'loss_2': 0.002407073974609375, 'loss_3': -16.421478271484375, 'loss_4': 0.7537643909454346, 'epoch': 8.06}
{'loss': 0.0176, 'grad_norm': 5.723854064941406, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.013022475875914097, 'loss_2': 0.004611968994140625, 'loss_3': -16.240501403808594, 'loss_4': 0.30261826515197754, 'epoch': 8.06}
{'loss': 0.0743, 'grad_norm': 19.379228591918945, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.07179487496614456, 'loss_2': 0.00249481201171875, 'loss_3': -16.266416549682617, 'loss_4': 0.7861553430557251, 'epoch': 8.07}
{'loss': 0.0173, 'grad_norm': 5.205513000488281, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.007785553578287363, 'loss_2': 0.009521484375, 'loss_3': -16.543354034423828, 'loss_4': 0.12835188210010529, 'epoch': 8.08}
{'loss': 0.0179, 'grad_norm': 6.276752471923828, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.017801515758037567, 'loss_2': 7.355213165283203e-05, 'loss_3': -16.534378051757812, 'loss_4': 0.29027819633483887, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 15:52:01,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:01,177 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:55<1:04:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:08,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017647987231612206, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014910758472979069, 'eval_loss_2': 0.002737227827310562, 'eval_loss_3': -18.195674896240234, 'eval_loss_4': 0.04333270341157913, 'epoch': 8.08}
{'loss': 0.0657, 'grad_norm': 23.756141662597656, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.0648123174905777, 'loss_2': 0.0009164810180664062, 'loss_3': -16.25432777404785, 'loss_4': -0.0710768774151802, 'epoch': 8.09}
{'loss': 0.038, 'grad_norm': 10.681318283081055, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.03647597134113312, 'loss_2': 0.0015201568603515625, 'loss_3': -16.31774139404297, 'loss_4': -0.21500375866889954, 'epoch': 8.09}
{'loss': 0.0256, 'grad_norm': 6.490808010101318, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.02101391740143299, 'loss_2': 0.00457000732421875, 'loss_3': -16.464765548706055, 'loss_4': 0.0034153014421463013, 'epoch': 8.1}
{'loss': 0.0178, 'grad_norm': 5.514708995819092, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.015117726288735867, 'loss_2': 0.0026950836181640625, 'loss_3': -16.40999984741211, 'loss_4': 0.1805402785539627, 'epoch': 8.1}
{'loss': 0.0261, 'grad_norm': 8.364445686340332, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.02193540148437023, 'loss_2': 0.0041351318359375, 'loss_3': -16.372844696044922, 'loss_4': -0.2603251039981842, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 15:52:08,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:08,511 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [35:02<1:04:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:15,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02343699522316456, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.596, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01862183026969433, 'eval_loss_2': 0.004815161228179932, 'eval_loss_3': -18.1611385345459, 'eval_loss_4': -0.060742054134607315, 'epoch': 8.11}
{'loss': 0.0124, 'grad_norm': 5.07811164855957, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.008724238723516464, 'loss_2': 0.0036411285400390625, 'loss_3': -16.511516571044922, 'loss_4': 0.23316746950149536, 'epoch': 8.12}
{'loss': 0.018, 'grad_norm': 6.439308166503906, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.015240417793393135, 'loss_2': 0.00273895263671875, 'loss_3': -16.513269424438477, 'loss_4': -0.3069782555103302, 'epoch': 8.12}
{'loss': 0.0296, 'grad_norm': 9.260442733764648, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.02384859509766102, 'loss_2': 0.00579071044921875, 'loss_3': -16.310260772705078, 'loss_4': 0.19750766456127167, 'epoch': 8.13}
{'loss': 0.0327, 'grad_norm': 16.41103172302246, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.029484983533620834, 'loss_2': 0.003177642822265625, 'loss_3': -15.988826751708984, 'loss_4': -0.2904953956604004, 'epoch': 8.13}
{'loss': 0.016, 'grad_norm': 5.561598300933838, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.012883027084171772, 'loss_2': 0.003082275390625, 'loss_3': -16.345584869384766, 'loss_4': 0.33273279666900635, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 15:52:15,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:15,845 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [35:09<1:04:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:23,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.031497545540332794, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0254597757011652, 'eval_loss_2': 0.006037771701812744, 'eval_loss_3': -18.11707878112793, 'eval_loss_4': 0.2432149201631546, 'epoch': 8.14}
{'loss': 0.0242, 'grad_norm': 7.863519668579102, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.019643079489469528, 'loss_2': 0.004566192626953125, 'loss_3': -16.430017471313477, 'loss_4': 0.0024752765893936157, 'epoch': 8.15}
{'loss': 0.0183, 'grad_norm': 5.781103610992432, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.016196424141526222, 'loss_2': 0.0021514892578125, 'loss_3': -16.199710845947266, 'loss_4': -0.05215364322066307, 'epoch': 8.15}
{'loss': 0.0394, 'grad_norm': 10.476758003234863, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.03555067628622055, 'loss_2': 0.0038242340087890625, 'loss_3': -16.244550704956055, 'loss_4': -0.37914666533470154, 'epoch': 8.16}
{'loss': 0.0247, 'grad_norm': 7.064990997314453, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.020918885245919228, 'loss_2': 0.0037841796875, 'loss_3': -16.414649963378906, 'loss_4': 0.5792791843414307, 'epoch': 8.16}
{'loss': 0.0175, 'grad_norm': 7.4546074867248535, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.01725975051522255, 'loss_2': 0.0002758502960205078, 'loss_3': -16.39902687072754, 'loss_4': 0.2386738657951355, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 15:52:23,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:23,189 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [35:17<1:04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:30,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03265080600976944, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.755, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02974025532603264, 'eval_loss_2': 0.0029105544090270996, 'eval_loss_3': -18.096721649169922, 'eval_loss_4': 0.4430121183395386, 'epoch': 8.17}
{'loss': 0.0252, 'grad_norm': 6.502392768859863, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.018808096647262573, 'loss_2': 0.0063934326171875, 'loss_3': -16.117565155029297, 'loss_4': 0.4463925361633301, 'epoch': 8.17}
{'loss': 0.0295, 'grad_norm': 8.738492965698242, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.023224152624607086, 'loss_2': 0.0062408447265625, 'loss_3': -16.206756591796875, 'loss_4': 0.4910975992679596, 'epoch': 8.18}
{'loss': 0.0476, 'grad_norm': 15.769340515136719, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.03576693683862686, 'loss_2': 0.01187896728515625, 'loss_3': -16.25373077392578, 'loss_4': 0.1128367930650711, 'epoch': 8.19}
{'loss': 0.0233, 'grad_norm': 6.175248146057129, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.016522515565156937, 'loss_2': 0.00679779052734375, 'loss_3': -16.2941951751709, 'loss_4': 0.6935945153236389, 'epoch': 8.19}
{'loss': 0.0406, 'grad_norm': 23.42203140258789, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.033096108585596085, 'loss_2': 0.00745391845703125, 'loss_3': -16.34418487548828, 'loss_4': 0.2988419234752655, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 15:52:30,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:30,537 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:24<1:04:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:37,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04231412708759308, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.573, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.03238280862569809, 'eval_loss_2': 0.009931325912475586, 'eval_loss_3': -18.06818962097168, 'eval_loss_4': 0.6706660985946655, 'epoch': 8.2}
{'loss': 0.0169, 'grad_norm': 6.059232711791992, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.011186718940734863, 'loss_2': 0.00572967529296875, 'loss_3': -16.28780174255371, 'loss_4': 0.7446762323379517, 'epoch': 8.2}
{'loss': 0.0234, 'grad_norm': 6.395163059234619, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.012954019010066986, 'loss_2': 0.010467529296875, 'loss_3': -16.308156967163086, 'loss_4': 0.7751836776733398, 'epoch': 8.21}
{'loss': 0.0427, 'grad_norm': 16.23450469970703, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.03495091199874878, 'loss_2': 0.007724761962890625, 'loss_3': -16.015819549560547, 'loss_4': 0.47455936670303345, 'epoch': 8.22}
{'loss': 0.0307, 'grad_norm': 5.973543167114258, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.017850074917078018, 'loss_2': 0.0128936767578125, 'loss_3': -16.2939453125, 'loss_4': 0.28960320353507996, 'epoch': 8.22}
{'loss': 0.042, 'grad_norm': 13.279879570007324, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.03119485080242157, 'loss_2': 0.0107879638671875, 'loss_3': -16.10440444946289, 'loss_4': 0.6275192499160767, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 15:52:37,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:37,874 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:31<1:04:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:45,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028822358697652817, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.446, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.025324199348688126, 'eval_loss_2': 0.003498159348964691, 'eval_loss_3': -18.10653305053711, 'eval_loss_4': 0.7542562484741211, 'epoch': 8.23}
{'loss': 0.0892, 'grad_norm': 17.03429412841797, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.07500971108675003, 'loss_2': 0.01416015625, 'loss_3': -16.013158798217773, 'loss_4': 0.8465453386306763, 'epoch': 8.23}
{'loss': 0.0085, 'grad_norm': 5.047169208526611, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.006385293323546648, 'loss_2': 0.00209808349609375, 'loss_3': -16.10883331298828, 'loss_4': 1.072943925857544, 'epoch': 8.24}
{'loss': 0.0142, 'grad_norm': 6.709523677825928, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.01358860358595848, 'loss_2': 0.0005631446838378906, 'loss_3': -16.168302536010742, 'loss_4': 0.8689953088760376, 'epoch': 8.24}
{'loss': 0.0107, 'grad_norm': 5.27392578125, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.009872517548501492, 'loss_2': 0.0008258819580078125, 'loss_3': -16.08866310119629, 'loss_4': 0.16478392481803894, 'epoch': 8.25}
{'loss': 0.0288, 'grad_norm': 6.54547643661499, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.015156229957938194, 'loss_2': 0.0135955810546875, 'loss_3': -16.140037536621094, 'loss_4': 0.7998603582382202, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 15:52:45,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:45,211 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:39<1:04:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:52,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03680163994431496, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.221, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.025536812841892242, 'eval_loss_2': 0.011264830827713013, 'eval_loss_3': -18.08589744567871, 'eval_loss_4': 0.7476462721824646, 'epoch': 8.26}
{'loss': 0.0623, 'grad_norm': 10.723160743713379, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.048789430409669876, 'loss_2': 0.0135345458984375, 'loss_3': -16.225875854492188, 'loss_4': 0.2809693217277527, 'epoch': 8.26}
{'loss': 0.0367, 'grad_norm': 9.31091594696045, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.026556629687547684, 'loss_2': 0.0101470947265625, 'loss_3': -16.080089569091797, 'loss_4': 0.8651482462882996, 'epoch': 8.27}
{'loss': 0.0316, 'grad_norm': 8.451164245605469, 'learning_rate': 2.175e-05, 'loss_1': 0.020827213302254677, 'loss_2': 0.01073455810546875, 'loss_3': -16.316146850585938, 'loss_4': 0.7846626043319702, 'epoch': 8.27}
{'loss': 0.0263, 'grad_norm': 7.562097072601318, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.015548141673207283, 'loss_2': 0.010772705078125, 'loss_3': -16.074121475219727, 'loss_4': 0.6153963804244995, 'epoch': 8.28}
{'loss': 0.0199, 'grad_norm': 9.627545356750488, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.015349642373621464, 'loss_2': 0.00458526611328125, 'loss_3': -16.31108283996582, 'loss_4': 0.6696813106536865, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 15:52:52,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:52,569 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:46<1:04:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:52:59,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03278717026114464, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.02448543719947338, 'eval_loss_2': 0.008301734924316406, 'eval_loss_3': -18.069868087768555, 'eval_loss_4': 0.7211558818817139, 'epoch': 8.28}
{'loss': 0.0338, 'grad_norm': 11.57539176940918, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.027545830234885216, 'loss_2': 0.00627899169921875, 'loss_3': -16.09515953063965, 'loss_4': 0.3303946852684021, 'epoch': 8.29}
{'loss': 0.0115, 'grad_norm': 5.306323051452637, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.011258813552558422, 'loss_2': 0.00019431114196777344, 'loss_3': -16.250669479370117, 'loss_4': 0.2048809677362442, 'epoch': 8.3}
{'loss': 0.0271, 'grad_norm': 15.402963638305664, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.025381319224834442, 'loss_2': 0.00176239013671875, 'loss_3': -16.192142486572266, 'loss_4': 0.7582910656929016, 'epoch': 8.3}
{'loss': 0.0257, 'grad_norm': 13.581010818481445, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.02375122904777527, 'loss_2': 0.001979827880859375, 'loss_3': -16.305397033691406, 'loss_4': 1.0359034538269043, 'epoch': 8.31}
{'loss': 0.1066, 'grad_norm': 28.1295108795166, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.10611589252948761, 'loss_2': 0.000457763671875, 'loss_3': -16.237407684326172, 'loss_4': 1.4338717460632324, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 15:52:59,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:52:59,910 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:53<1:04:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:07,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017359213903546333, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.545, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012879924848675728, 'eval_loss_2': 0.0044792890548706055, 'eval_loss_3': -18.140262603759766, 'eval_loss_4': 0.7673938274383545, 'epoch': 8.31}
{'loss': 0.0173, 'grad_norm': 8.378498077392578, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.015297355130314827, 'loss_2': 0.00197601318359375, 'loss_3': -16.06915855407715, 'loss_4': 0.7123938202857971, 'epoch': 8.32}
{'loss': 0.0189, 'grad_norm': 6.685392379760742, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.015015417709946632, 'loss_2': 0.0038814544677734375, 'loss_3': -16.145145416259766, 'loss_4': 0.7893843650817871, 'epoch': 8.33}
{'loss': 0.0102, 'grad_norm': 5.286551475524902, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.0077773635275661945, 'loss_2': 0.002437591552734375, 'loss_3': -16.17877960205078, 'loss_4': 1.3768417835235596, 'epoch': 8.33}
{'loss': 0.0248, 'grad_norm': 10.242259979248047, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.02468942105770111, 'loss_2': 9.000301361083984e-05, 'loss_3': -16.316471099853516, 'loss_4': 0.56474769115448, 'epoch': 8.34}
{'loss': 0.057, 'grad_norm': 29.713539123535156, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.04894883185625076, 'loss_2': 0.008056640625, 'loss_3': -16.253658294677734, 'loss_4': 1.6353025436401367, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 15:53:07,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:07,273 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [36:01<1:04:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:14,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016564296558499336, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.682, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012891183607280254, 'eval_loss_2': 0.0036731138825416565, 'eval_loss_3': -18.199796676635742, 'eval_loss_4': 1.1115370988845825, 'epoch': 8.34}
{'loss': 0.0207, 'grad_norm': 12.174447059631348, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.020029719918966293, 'loss_2': 0.000667572021484375, 'loss_3': -16.303752899169922, 'loss_4': 0.8809807300567627, 'epoch': 8.35}
{'loss': 0.0174, 'grad_norm': 6.704809188842773, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.015476166270673275, 'loss_2': 0.0018863677978515625, 'loss_3': -16.16897964477539, 'loss_4': 1.2330572605133057, 'epoch': 8.35}
{'loss': 0.0281, 'grad_norm': 12.262558937072754, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.02590598165988922, 'loss_2': 0.002227783203125, 'loss_3': -15.994486808776855, 'loss_4': 1.4305781126022339, 'epoch': 8.36}
{'loss': 0.0346, 'grad_norm': 11.005582809448242, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.028635969385504723, 'loss_2': 0.00592041015625, 'loss_3': -16.076398849487305, 'loss_4': 1.8573176860809326, 'epoch': 8.37}
{'loss': 0.0104, 'grad_norm': 4.7052998542785645, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.00859132967889309, 'loss_2': 0.0018100738525390625, 'loss_3': -16.367069244384766, 'loss_4': 1.278112530708313, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 15:53:14,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:14,633 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [36:08<1:04:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:21,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01681283861398697, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01294806506484747, 'eval_loss_2': 0.003864772617816925, 'eval_loss_3': -18.205066680908203, 'eval_loss_4': 1.3337490558624268, 'epoch': 8.37}
{'loss': 0.027, 'grad_norm': 6.710235118865967, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.014764002524316311, 'loss_2': 0.0121917724609375, 'loss_3': -16.241384506225586, 'loss_4': 1.18757963180542, 'epoch': 8.38}
{'loss': 0.0134, 'grad_norm': 4.793791770935059, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.009681989438831806, 'loss_2': 0.003742218017578125, 'loss_3': -16.415191650390625, 'loss_4': 1.826552152633667, 'epoch': 8.38}
{'loss': 0.0263, 'grad_norm': 15.27664566040039, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.023836733773350716, 'loss_2': 0.0025005340576171875, 'loss_3': -16.33572769165039, 'loss_4': 1.4491338729858398, 'epoch': 8.39}
{'loss': 0.04, 'grad_norm': 9.95728874206543, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.03820327669382095, 'loss_2': 0.0017919540405273438, 'loss_3': -16.08310317993164, 'loss_4': 1.7421245574951172, 'epoch': 8.4}
{'loss': 0.0276, 'grad_norm': 8.800048828125, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.017810974270105362, 'loss_2': 0.0098114013671875, 'loss_3': -16.238651275634766, 'loss_4': 1.8100526332855225, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 15:53:21,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:21,986 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:15<1:04:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:29,340 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01904737949371338, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01359421107918024, 'eval_loss_2': 0.005453169345855713, 'eval_loss_3': -18.17384910583496, 'eval_loss_4': 1.7528443336486816, 'epoch': 8.4}
{'loss': 0.0372, 'grad_norm': 7.8126678466796875, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.020882543176412582, 'loss_2': 0.0163421630859375, 'loss_3': -16.29867172241211, 'loss_4': 1.7575525045394897, 'epoch': 8.41}
{'loss': 0.0452, 'grad_norm': 15.609417915344238, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.029199816286563873, 'loss_2': 0.0159912109375, 'loss_3': -16.202682495117188, 'loss_4': 2.00492000579834, 'epoch': 8.41}
{'loss': 0.0331, 'grad_norm': 10.164201736450195, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.02478022500872612, 'loss_2': 0.00827789306640625, 'loss_3': -16.24838638305664, 'loss_4': 2.001476287841797, 'epoch': 8.42}
{'loss': 0.0354, 'grad_norm': 12.799895286560059, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.03464497625827789, 'loss_2': 0.0007171630859375, 'loss_3': -16.293182373046875, 'loss_4': 1.5340625047683716, 'epoch': 8.42}
{'loss': 0.0236, 'grad_norm': 6.212381839752197, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.018781697377562523, 'loss_2': 0.004817962646484375, 'loss_3': -16.100128173828125, 'loss_4': 2.2029151916503906, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 15:53:29,340 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:29,340 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:23<1:04:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:36,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020096704363822937, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015896735712885857, 'eval_loss_2': 0.004199966788291931, 'eval_loss_3': -18.16391944885254, 'eval_loss_4': 1.904323935508728, 'epoch': 8.43}
{'loss': 0.0177, 'grad_norm': 6.134768009185791, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.015495754778385162, 'loss_2': 0.0021686553955078125, 'loss_3': -16.329011917114258, 'loss_4': 1.922044038772583, 'epoch': 8.44}
{'loss': 0.0461, 'grad_norm': 13.187090873718262, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.04126002639532089, 'loss_2': 0.004863739013671875, 'loss_3': -16.19284439086914, 'loss_4': 1.8650286197662354, 'epoch': 8.44}
{'loss': 0.1122, 'grad_norm': 13.813212394714355, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.10942259430885315, 'loss_2': 0.00275421142578125, 'loss_3': -15.967916488647461, 'loss_4': 1.8881866931915283, 'epoch': 8.45}
{'loss': 0.0992, 'grad_norm': 23.0966739654541, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.094825878739357, 'loss_2': 0.00432586669921875, 'loss_3': -16.183197021484375, 'loss_4': 1.57303786277771, 'epoch': 8.45}
{'loss': 0.025, 'grad_norm': 7.166264533996582, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.023165401071310043, 'loss_2': 0.0018262863159179688, 'loss_3': -16.33620262145996, 'loss_4': 1.9911398887634277, 'epoch': 8.46}
[INFO|trainer.py:4228] 2025-01-21 15:53:36,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:36,693 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:30<1:04:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:44,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0213734470307827, 'eval_runtime': 3.8196, 'eval_samples_per_second': 268.094, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.01785087212920189, 'eval_loss_2': 0.0035225749015808105, 'eval_loss_3': -18.167049407958984, 'eval_loss_4': 1.836022138595581, 'epoch': 8.46}
{'loss': 0.0433, 'grad_norm': 14.392910957336426, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.03444896265864372, 'loss_2': 0.00885009765625, 'loss_3': -15.951395034790039, 'loss_4': 1.8965144157409668, 'epoch': 8.47}
{'loss': 0.0277, 'grad_norm': 15.021658897399902, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.022294005379080772, 'loss_2': 0.00537872314453125, 'loss_3': -16.146900177001953, 'loss_4': 1.860487461090088, 'epoch': 8.47}
{'loss': 0.0264, 'grad_norm': 7.404533863067627, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.022996924817562103, 'loss_2': 0.003387451171875, 'loss_3': -16.450681686401367, 'loss_4': 1.574480414390564, 'epoch': 8.48}
{'loss': 0.0248, 'grad_norm': 6.162671089172363, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.017748761922121048, 'loss_2': 0.007007598876953125, 'loss_3': -16.330215454101562, 'loss_4': 2.1337051391601562, 'epoch': 8.48}
{'loss': 0.0202, 'grad_norm': 7.456142902374268, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.017550552263855934, 'loss_2': 0.0026988983154296875, 'loss_3': -16.244369506835938, 'loss_4': 1.8491244316101074, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 15:53:44,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:44,067 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:38<1:04:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:51,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019980020821094513, 'eval_runtime': 3.8284, 'eval_samples_per_second': 267.475, 'eval_steps_per_second': 4.179, 'eval_loss_1': 0.015564749017357826, 'eval_loss_2': 0.004415273666381836, 'eval_loss_3': -18.1969051361084, 'eval_loss_4': 1.9552279710769653, 'epoch': 8.49}
{'loss': 0.0445, 'grad_norm': 17.159250259399414, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.03500279411673546, 'loss_2': 0.00951385498046875, 'loss_3': -16.332178115844727, 'loss_4': 2.4758358001708984, 'epoch': 8.49}
{'loss': 0.0384, 'grad_norm': 9.16407299041748, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.03566154092550278, 'loss_2': 0.002735137939453125, 'loss_3': -16.38007354736328, 'loss_4': 1.8269069194793701, 'epoch': 8.5}
{'loss': 0.0195, 'grad_norm': 8.488571166992188, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.01622033305466175, 'loss_2': 0.00327301025390625, 'loss_3': -16.308366775512695, 'loss_4': 2.0410985946655273, 'epoch': 8.51}
{'loss': 0.0263, 'grad_norm': 9.636520385742188, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.024343127384781837, 'loss_2': 0.00191497802734375, 'loss_3': -16.229888916015625, 'loss_4': 2.4441022872924805, 'epoch': 8.51}
{'loss': 0.0297, 'grad_norm': 10.002575874328613, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.02874213270843029, 'loss_2': 0.0009660720825195312, 'loss_3': -16.285568237304688, 'loss_4': 2.1954236030578613, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 15:53:51,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:51,446 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:45<1:03:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:53:58,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01890292391180992, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014782692305743694, 'eval_loss_2': 0.004120230674743652, 'eval_loss_3': -18.21578025817871, 'eval_loss_4': 1.964043140411377, 'epoch': 8.52}
{'loss': 0.0195, 'grad_norm': 6.716976642608643, 'learning_rate': 2.15e-05, 'loss_1': 0.014165425673127174, 'loss_2': 0.00533294677734375, 'loss_3': -16.249038696289062, 'loss_4': 2.2509984970092773, 'epoch': 8.52}
{'loss': 0.0296, 'grad_norm': 7.7344746589660645, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.026559779420495033, 'loss_2': 0.00299835205078125, 'loss_3': -16.356861114501953, 'loss_4': 2.2920632362365723, 'epoch': 8.53}
{'loss': 0.016, 'grad_norm': 4.7968974113464355, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.012819833122193813, 'loss_2': 0.003185272216796875, 'loss_3': -16.451276779174805, 'loss_4': 2.1761975288391113, 'epoch': 8.53}
{'loss': 0.0287, 'grad_norm': 9.025360107421875, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.02163689211010933, 'loss_2': 0.00705718994140625, 'loss_3': -16.431650161743164, 'loss_4': 2.3334524631500244, 'epoch': 8.54}
{'loss': 0.0261, 'grad_norm': 6.761246681213379, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.022700676694512367, 'loss_2': 0.00341796875, 'loss_3': -16.201738357543945, 'loss_4': 2.0090110301971436, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 15:53:58,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:53:58,799 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:52<1:03:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:06,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019691545516252518, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01716748997569084, 'eval_loss_2': 0.002524055540561676, 'eval_loss_3': -18.226943969726562, 'eval_loss_4': 1.7921017408370972, 'epoch': 8.55}
{'loss': 0.0171, 'grad_norm': 5.392326831817627, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.01230400986969471, 'loss_2': 0.00478363037109375, 'loss_3': -16.383686065673828, 'loss_4': 2.081094741821289, 'epoch': 8.55}
{'loss': 0.063, 'grad_norm': 21.43582534790039, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.06197335198521614, 'loss_2': 0.0009927749633789062, 'loss_3': -16.0882568359375, 'loss_4': 1.6776037216186523, 'epoch': 8.56}
{'loss': 0.0381, 'grad_norm': 11.967406272888184, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.03776796534657478, 'loss_2': 0.00037097930908203125, 'loss_3': -15.900311470031738, 'loss_4': 1.7518813610076904, 'epoch': 8.56}
{'loss': 0.0217, 'grad_norm': 7.02200174331665, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.021109987050294876, 'loss_2': 0.000614166259765625, 'loss_3': -16.265857696533203, 'loss_4': 1.1053354740142822, 'epoch': 8.57}
{'loss': 0.0509, 'grad_norm': 21.262615203857422, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.04831142723560333, 'loss_2': 0.002597808837890625, 'loss_3': -16.152446746826172, 'loss_4': 2.266183614730835, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 15:54:06,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:06,153 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [37:00<1:03:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:13,513 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019963011145591736, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.815, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.015461131930351257, 'eval_loss_2': 0.0045018792152404785, 'eval_loss_3': -18.231468200683594, 'eval_loss_4': 1.3955830335617065, 'epoch': 8.58}
{'loss': 0.0345, 'grad_norm': 11.103982925415039, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.03314225375652313, 'loss_2': 0.0013790130615234375, 'loss_3': -16.276226043701172, 'loss_4': 1.406095027923584, 'epoch': 8.58}
{'loss': 0.0241, 'grad_norm': 6.860500335693359, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.021817127242684364, 'loss_2': 0.002254486083984375, 'loss_3': -16.24629783630371, 'loss_4': 0.9418569803237915, 'epoch': 8.59}
{'loss': 0.0407, 'grad_norm': 10.09090805053711, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.03629924729466438, 'loss_2': 0.00438690185546875, 'loss_3': -16.204744338989258, 'loss_4': 1.3792309761047363, 'epoch': 8.59}
{'loss': 0.0829, 'grad_norm': 24.009929656982422, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.07861682027578354, 'loss_2': 0.004302978515625, 'loss_3': -16.09870147705078, 'loss_4': 1.6281602382659912, 'epoch': 8.6}
{'loss': 0.0208, 'grad_norm': 6.2116923332214355, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.018922291696071625, 'loss_2': 0.0019016265869140625, 'loss_3': -16.32418441772461, 'loss_4': 1.7011759281158447, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 15:54:13,513 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:13,514 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [37:07<1:03:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:20,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020832624286413193, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.056, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016439178958535194, 'eval_loss_2': 0.004393443465232849, 'eval_loss_3': -18.252914428710938, 'eval_loss_4': 1.1961766481399536, 'epoch': 8.6}
{'loss': 0.0256, 'grad_norm': 8.50191593170166, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.024106519296765327, 'loss_2': 0.00145721435546875, 'loss_3': -16.340927124023438, 'loss_4': 0.8429338932037354, 'epoch': 8.61}
{'loss': 0.0237, 'grad_norm': 7.021481513977051, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.020032130181789398, 'loss_2': 0.003692626953125, 'loss_3': -16.4357967376709, 'loss_4': 1.130425214767456, 'epoch': 8.62}
{'loss': 0.0538, 'grad_norm': 19.80744171142578, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.04520580545067787, 'loss_2': 0.00856781005859375, 'loss_3': -15.87459659576416, 'loss_4': 1.544534683227539, 'epoch': 8.62}
{'loss': 0.0357, 'grad_norm': 11.432472229003906, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.029653102159500122, 'loss_2': 0.0060272216796875, 'loss_3': -16.265071868896484, 'loss_4': 1.301935076713562, 'epoch': 8.63}
{'loss': 0.0163, 'grad_norm': 5.872965335845947, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.0130669130012393, 'loss_2': 0.0032405853271484375, 'loss_3': -16.29549789428711, 'loss_4': 0.7685465812683105, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 15:54:20,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:20,870 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:14<1:03:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:28,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020418107509613037, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.662, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014619589783251286, 'eval_loss_2': 0.005798518657684326, 'eval_loss_3': -18.22382354736328, 'eval_loss_4': 1.2218573093414307, 'epoch': 8.63}
{'loss': 0.0336, 'grad_norm': 10.12350082397461, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.02930544689297676, 'loss_2': 0.00434112548828125, 'loss_3': -16.10495948791504, 'loss_4': 1.5464646816253662, 'epoch': 8.64}
{'loss': 0.0369, 'grad_norm': 15.972763061523438, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.03436332568526268, 'loss_2': 0.002529144287109375, 'loss_3': -16.20410919189453, 'loss_4': 1.6040600538253784, 'epoch': 8.65}
{'loss': 0.029, 'grad_norm': 10.688471794128418, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.02797192521393299, 'loss_2': 0.0010232925415039062, 'loss_3': -15.831932067871094, 'loss_4': 1.762375831604004, 'epoch': 8.65}
{'loss': 0.031, 'grad_norm': 9.76715087890625, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.029171084985136986, 'loss_2': 0.0018491744995117188, 'loss_3': -16.062341690063477, 'loss_4': 1.5582849979400635, 'epoch': 8.66}
{'loss': 0.0973, 'grad_norm': 20.66908073425293, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.09508158266544342, 'loss_2': 0.002246856689453125, 'loss_3': -16.160789489746094, 'loss_4': 1.3817903995513916, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 15:54:28,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:28,238 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:22<1:03:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:35,605 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016338013112545013, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.505, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.012292190454900265, 'eval_loss_2': 0.004045821726322174, 'eval_loss_3': -18.206987380981445, 'eval_loss_4': 1.1657439470291138, 'epoch': 8.66}
{'loss': 0.0239, 'grad_norm': 14.6029052734375, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.020175904035568237, 'loss_2': 0.0037689208984375, 'loss_3': -16.2418212890625, 'loss_4': 1.4971222877502441, 'epoch': 8.67}
{'loss': 0.0152, 'grad_norm': 5.350213527679443, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.014498419128358364, 'loss_2': 0.0007023811340332031, 'loss_3': -16.296667098999023, 'loss_4': 1.3026189804077148, 'epoch': 8.67}
{'loss': 0.0246, 'grad_norm': 10.549586296081543, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.023594558238983154, 'loss_2': 0.0010051727294921875, 'loss_3': -16.06357192993164, 'loss_4': 1.6657452583312988, 'epoch': 8.68}
{'loss': 0.0181, 'grad_norm': 7.322710990905762, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.013384925201535225, 'loss_2': 0.0047607421875, 'loss_3': -16.243932723999023, 'loss_4': 1.7446439266204834, 'epoch': 8.69}
{'loss': 0.0251, 'grad_norm': 9.131179809570312, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.020240386947989464, 'loss_2': 0.00482177734375, 'loss_3': -16.22696304321289, 'loss_4': 1.4071733951568604, 'epoch': 8.69}
[INFO|trainer.py:4228] 2025-01-21 15:54:35,605 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:35,605 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:29<1:03:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:42,966 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01703489013016224, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011773970909416676, 'eval_loss_2': 0.005260918289422989, 'eval_loss_3': -18.1971435546875, 'eval_loss_4': 1.0541644096374512, 'epoch': 8.69}
{'loss': 0.0571, 'grad_norm': 19.36620330810547, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.04744720086455345, 'loss_2': 0.00960540771484375, 'loss_3': -15.983783721923828, 'loss_4': 1.2725813388824463, 'epoch': 8.7}
{'loss': 0.053, 'grad_norm': 13.226598739624023, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.03834666311740875, 'loss_2': 0.0146942138671875, 'loss_3': -16.264888763427734, 'loss_4': 0.7925975322723389, 'epoch': 8.7}
{'loss': 0.0265, 'grad_norm': 11.026469230651855, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.02248399145901203, 'loss_2': 0.004058837890625, 'loss_3': -16.1132869720459, 'loss_4': 1.6271027326583862, 'epoch': 8.71}
{'loss': 0.0098, 'grad_norm': 5.296188831329346, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.009443889372050762, 'loss_2': 0.0003657341003417969, 'loss_3': -16.133155822753906, 'loss_4': 0.6674906611442566, 'epoch': 8.72}
{'loss': 0.042, 'grad_norm': 10.982830047607422, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.039066724479198456, 'loss_2': 0.0029754638671875, 'loss_3': -16.005985260009766, 'loss_4': 0.8058778047561646, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 15:54:42,966 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:42,966 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:36<1:03:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:50,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014483869075775146, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.729, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01084297988563776, 'eval_loss_2': 0.003640890121459961, 'eval_loss_3': -18.21426773071289, 'eval_loss_4': 0.7062503099441528, 'epoch': 8.72}
{'loss': 0.0238, 'grad_norm': 10.963519096374512, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.02374061569571495, 'loss_2': 1.1920928955078125e-05, 'loss_3': -16.277732849121094, 'loss_4': 0.5756406188011169, 'epoch': 8.73}
{'loss': 0.0192, 'grad_norm': 5.404958724975586, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.011626495979726315, 'loss_2': 0.00759124755859375, 'loss_3': -16.131772994995117, 'loss_4': 0.6828454732894897, 'epoch': 8.73}
{'loss': 0.0234, 'grad_norm': 9.954509735107422, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.016439149156212807, 'loss_2': 0.0070037841796875, 'loss_3': -16.147655487060547, 'loss_4': 0.5766538381576538, 'epoch': 8.74}
{'loss': 0.0188, 'grad_norm': 5.702953815460205, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.00934628676623106, 'loss_2': 0.0094451904296875, 'loss_3': -16.254453659057617, 'loss_4': 0.4926294982433319, 'epoch': 8.74}
{'loss': 0.0242, 'grad_norm': 6.823453426361084, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.01474178209900856, 'loss_2': 0.00948333740234375, 'loss_3': -16.20616912841797, 'loss_4': 0.9870924949645996, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 15:54:50,318 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:50,318 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:44<1:03:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:54:57,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01580607332289219, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010286713019013405, 'eval_loss_2': 0.005519360303878784, 'eval_loss_3': -18.19196891784668, 'eval_loss_4': 0.4460831582546234, 'epoch': 8.75}
{'loss': 0.0203, 'grad_norm': 8.540532112121582, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.014466337859630585, 'loss_2': 0.00583648681640625, 'loss_3': -15.89609146118164, 'loss_4': 0.8917025327682495, 'epoch': 8.76}
{'loss': 0.014, 'grad_norm': 6.00295877456665, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.013974086381494999, 'loss_2': 3.933906555175781e-05, 'loss_3': -16.20822525024414, 'loss_4': 0.7386763095855713, 'epoch': 8.76}
{'loss': 0.009, 'grad_norm': 5.046957492828369, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.008563875220716, 'loss_2': 0.00047326087951660156, 'loss_3': -16.318225860595703, 'loss_4': 0.5749713182449341, 'epoch': 8.77}
{'loss': 0.0198, 'grad_norm': 9.030965805053711, 'learning_rate': 2.125e-05, 'loss_1': 0.019244449213147163, 'loss_2': 0.0005702972412109375, 'loss_3': -16.07844352722168, 'loss_4': 0.8072271347045898, 'epoch': 8.77}
{'loss': 0.0312, 'grad_norm': 12.230828285217285, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.029812481254339218, 'loss_2': 0.0013399124145507812, 'loss_3': -16.121957778930664, 'loss_4': 0.29506754875183105, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 15:54:57,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:54:57,671 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:51<1:03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:05,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020044753327965736, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.979, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010151931084692478, 'eval_loss_2': 0.009892821311950684, 'eval_loss_3': -18.144800186157227, 'eval_loss_4': 0.031022826209664345, 'epoch': 8.78}
{'loss': 0.0188, 'grad_norm': 6.101484298706055, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.013429858721792698, 'loss_2': 0.00537872314453125, 'loss_3': -16.180809020996094, 'loss_4': 0.113456591963768, 'epoch': 8.78}
{'loss': 0.0303, 'grad_norm': 5.2455058097839355, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.01089814305305481, 'loss_2': 0.0194244384765625, 'loss_3': -16.271968841552734, 'loss_4': -0.37899574637413025, 'epoch': 8.79}
{'loss': 0.029, 'grad_norm': 7.6444926261901855, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.016748016700148582, 'loss_2': 0.0122833251953125, 'loss_3': -15.972536087036133, 'loss_4': 0.31424373388290405, 'epoch': 8.8}
{'loss': 0.0215, 'grad_norm': 6.683375835418701, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.013941026292741299, 'loss_2': 0.00754547119140625, 'loss_3': -16.267879486083984, 'loss_4': -0.6308894157409668, 'epoch': 8.8}
{'loss': 0.0407, 'grad_norm': 8.107813835144043, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.03344932571053505, 'loss_2': 0.007289886474609375, 'loss_3': -16.101078033447266, 'loss_4': -0.47084152698516846, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 15:55:05,024 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:05,024 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [37:58<1:02:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:12,380 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019043665379285812, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.492, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010643820278346539, 'eval_loss_2': 0.0083998441696167, 'eval_loss_3': -18.161588668823242, 'eval_loss_4': -0.3333124816417694, 'epoch': 8.81}
{'loss': 0.0996, 'grad_norm': 21.36326789855957, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.0919949933886528, 'loss_2': 0.007556915283203125, 'loss_3': -16.416393280029297, 'loss_4': 0.48948487639427185, 'epoch': 8.81}
{'loss': 0.0293, 'grad_norm': 7.394242763519287, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.027517523616552353, 'loss_2': 0.0018224716186523438, 'loss_3': -16.285158157348633, 'loss_4': -0.4782472848892212, 'epoch': 8.82}
{'loss': 0.0604, 'grad_norm': 16.519960403442383, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.05215073749423027, 'loss_2': 0.00824737548828125, 'loss_3': -16.157100677490234, 'loss_4': 0.006454482674598694, 'epoch': 8.83}
{'loss': 0.0132, 'grad_norm': 5.636216163635254, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.012484133243560791, 'loss_2': 0.0007462501525878906, 'loss_3': -16.191425323486328, 'loss_4': 0.14706620573997498, 'epoch': 8.83}
{'loss': 0.0242, 'grad_norm': 7.8683037757873535, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.021680276840925217, 'loss_2': 0.00247955322265625, 'loss_3': -16.141080856323242, 'loss_4': -0.5920983552932739, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 15:55:12,380 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:12,380 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [38:06<1:02:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:19,733 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018363475799560547, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.619, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.012618668377399445, 'eval_loss_2': 0.005744807422161102, 'eval_loss_3': -18.131948471069336, 'eval_loss_4': -0.4404294490814209, 'epoch': 8.84}
{'loss': 0.026, 'grad_norm': 13.410670280456543, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.02178570255637169, 'loss_2': 0.0042572021484375, 'loss_3': -16.250986099243164, 'loss_4': -0.04749740660190582, 'epoch': 8.84}
{'loss': 0.0153, 'grad_norm': 5.486640930175781, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.008752919733524323, 'loss_2': 0.0065460205078125, 'loss_3': -16.341651916503906, 'loss_4': -0.3761520981788635, 'epoch': 8.85}
{'loss': 0.0247, 'grad_norm': 7.763182640075684, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.022215723991394043, 'loss_2': 0.00252532958984375, 'loss_3': -16.031221389770508, 'loss_4': -0.19460222125053406, 'epoch': 8.85}
{'loss': 0.0291, 'grad_norm': 8.07161808013916, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.021636953577399254, 'loss_2': 0.007495880126953125, 'loss_3': -16.155445098876953, 'loss_4': -0.33395683765411377, 'epoch': 8.86}
{'loss': 0.0186, 'grad_norm': 6.10167932510376, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.010974390432238579, 'loss_2': 0.00760650634765625, 'loss_3': -16.27375602722168, 'loss_4': -0.047027915716171265, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 15:55:19,733 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:19,733 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [38:13<1:02:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:27,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020172283053398132, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01679661124944687, 'eval_loss_2': 0.0033756718039512634, 'eval_loss_3': -18.100797653198242, 'eval_loss_4': -0.46161389350891113, 'epoch': 8.87}
{'loss': 0.0229, 'grad_norm': 7.180944919586182, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.020642057061195374, 'loss_2': 0.0022411346435546875, 'loss_3': -16.108047485351562, 'loss_4': -0.37287986278533936, 'epoch': 8.87}
{'loss': 0.0364, 'grad_norm': 12.105212211608887, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.031596552580595016, 'loss_2': 0.0047607421875, 'loss_3': -16.18514633178711, 'loss_4': -0.05034872889518738, 'epoch': 8.88}
{'loss': 0.0785, 'grad_norm': 27.30402183532715, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.07769755274057388, 'loss_2': 0.0007772445678710938, 'loss_3': -16.15395164489746, 'loss_4': -0.32904765009880066, 'epoch': 8.88}
{'loss': 0.0246, 'grad_norm': 6.6501569747924805, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.021788178011775017, 'loss_2': 0.002857208251953125, 'loss_3': -16.070545196533203, 'loss_4': -0.2120901197195053, 'epoch': 8.89}
{'loss': 0.0176, 'grad_norm': 5.716663360595703, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.01397587452083826, 'loss_2': 0.00357818603515625, 'loss_3': -16.217838287353516, 'loss_4': -0.997209906578064, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 15:55:27,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:27,089 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:21<1:02:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:34,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02674507349729538, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.941, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.02111654542386532, 'eval_loss_2': 0.005628526210784912, 'eval_loss_3': -18.07871437072754, 'eval_loss_4': -0.35800039768218994, 'epoch': 8.9}
{'loss': 0.035, 'grad_norm': 8.35216236114502, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.02948678843677044, 'loss_2': 0.005523681640625, 'loss_3': -16.256113052368164, 'loss_4': -0.23593178391456604, 'epoch': 8.9}
{'loss': 0.0598, 'grad_norm': 14.262361526489258, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.05634337291121483, 'loss_2': 0.003498077392578125, 'loss_3': -16.169588088989258, 'loss_4': -0.11413218080997467, 'epoch': 8.91}
{'loss': 0.0292, 'grad_norm': 10.212047576904297, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.02722434140741825, 'loss_2': 0.0019626617431640625, 'loss_3': -16.03081703186035, 'loss_4': -0.09935205429792404, 'epoch': 8.91}
{'loss': 0.0173, 'grad_norm': 6.544282913208008, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.015199295245110989, 'loss_2': 0.0021305084228515625, 'loss_3': -16.140588760375977, 'loss_4': -0.20312291383743286, 'epoch': 8.92}
{'loss': 0.0216, 'grad_norm': 6.785195350646973, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.018558545038104057, 'loss_2': 0.003055572509765625, 'loss_3': -16.24474334716797, 'loss_4': 0.26059165596961975, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 15:55:34,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:34,437 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:28<1:02:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:41,794 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023738645017147064, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.735, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02050659991800785, 'eval_loss_2': 0.003232046961784363, 'eval_loss_3': -18.07054901123047, 'eval_loss_4': -0.12350106239318848, 'epoch': 8.92}
{'loss': 0.0213, 'grad_norm': 5.507160186767578, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.015450879000127316, 'loss_2': 0.0058441162109375, 'loss_3': -16.18960952758789, 'loss_4': -0.3082035779953003, 'epoch': 8.93}
{'loss': 0.0244, 'grad_norm': 10.42849349975586, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.020660629495978355, 'loss_2': 0.0037078857421875, 'loss_3': -16.235990524291992, 'loss_4': 0.4121987819671631, 'epoch': 8.94}
{'loss': 0.0304, 'grad_norm': 8.699556350708008, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.02405613660812378, 'loss_2': 0.0063934326171875, 'loss_3': -16.223125457763672, 'loss_4': 0.09878291189670563, 'epoch': 8.94}
{'loss': 0.0422, 'grad_norm': 8.846152305603027, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.02212168276309967, 'loss_2': 0.020050048828125, 'loss_3': -16.08930015563965, 'loss_4': 0.19276826083660126, 'epoch': 8.95}
{'loss': 0.0167, 'grad_norm': 5.840945720672607, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.014755943790078163, 'loss_2': 0.0019378662109375, 'loss_3': -16.194873809814453, 'loss_4': 0.37270545959472656, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 15:55:41,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:41,795 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:35<1:02:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:55:49,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016205815598368645, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.039, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.01285599172115326, 'eval_loss_2': 0.0033498257398605347, 'eval_loss_3': -18.123376846313477, 'eval_loss_4': 0.2463540881872177, 'epoch': 8.95}
{'loss': 0.0096, 'grad_norm': 5.7332444190979, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.00926214735955, 'loss_2': 0.0003657341003417969, 'loss_3': -16.040546417236328, 'loss_4': 0.7703839540481567, 'epoch': 8.96}
{'loss': 0.1245, 'grad_norm': 34.66427230834961, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.12126625329256058, 'loss_2': 0.003208160400390625, 'loss_3': -15.850959777832031, 'loss_4': 0.22433078289031982, 'epoch': 8.97}
{'loss': 0.0154, 'grad_norm': 5.857479095458984, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.012898903340101242, 'loss_2': 0.0025234222412109375, 'loss_3': -16.296390533447266, 'loss_4': 0.6086856126785278, 'epoch': 8.97}
{'loss': 0.0332, 'grad_norm': 25.898971557617188, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.031097812578082085, 'loss_2': 0.002086639404296875, 'loss_3': -16.167009353637695, 'loss_4': 0.271775484085083, 'epoch': 8.98}
{'loss': 0.0213, 'grad_norm': 6.5965166091918945, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.012498353607952595, 'loss_2': 0.00878143310546875, 'loss_3': -16.233108520507812, 'loss_4': 0.5556278228759766, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 15:55:49,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:49,166 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                          | 1550/5160 [38:42<59:58,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 15:55:56,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01921771839261055, 'eval_runtime': 3.813, 'eval_samples_per_second': 268.558, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.013389992527663708, 'eval_loss_2': 0.005827724933624268, 'eval_loss_3': -18.1525936126709, 'eval_loss_4': 0.5704325437545776, 'epoch': 8.98}
{'loss': 0.0673, 'grad_norm': 18.056461334228516, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.06192637234926224, 'loss_2': 0.00537109375, 'loss_3': -16.252361297607422, 'loss_4': 0.3772578239440918, 'epoch': 8.99}
{'loss': 0.0255, 'grad_norm': 10.719374656677246, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.02054658718407154, 'loss_2': 0.004932403564453125, 'loss_3': -16.055522918701172, 'loss_4': 0.7703356146812439, 'epoch': 8.99}
{'loss': 0.0102, 'grad_norm': 6.320797443389893, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.0033503221347928047, 'loss_2': 0.0068817138671875, 'loss_3': -16.272109985351562, 'loss_4': 0.9881360530853271, 'epoch': 9.0}
{'loss': 0.0418, 'grad_norm': 16.237451553344727, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.026246285066008568, 'loss_2': 0.0155181884765625, 'loss_3': -16.259307861328125, 'loss_4': 0.7536861896514893, 'epoch': 9.01}
{'loss': 0.0315, 'grad_norm': 8.181916236877441, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.02568076364696026, 'loss_2': 0.00582122802734375, 'loss_3': -16.217437744140625, 'loss_4': 0.9863587617874146, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 15:55:56,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:55:56,213 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:50<1:02:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 15:56:03,576 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01426684483885765, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.734, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010205205529928207, 'eval_loss_2': 0.004061639308929443, 'eval_loss_3': -18.156505584716797, 'eval_loss_4': 0.7429682612419128, 'epoch': 9.01}
{'loss': 0.0231, 'grad_norm': 9.438515663146973, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.021768786013126373, 'loss_2': 0.001377105712890625, 'loss_3': -16.025657653808594, 'loss_4': 0.9868611693382263, 'epoch': 9.02}
{'loss': 0.0223, 'grad_norm': 8.4690523147583, 'learning_rate': 2.1e-05, 'loss_1': 0.020043563097715378, 'loss_2': 0.00228118896484375, 'loss_3': -16.161380767822266, 'loss_4': 0.15831784904003143, 'epoch': 9.02}
{'loss': 0.0227, 'grad_norm': 6.926183223724365, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.015240221284329891, 'loss_2': 0.00749969482421875, 'loss_3': -16.19036865234375, 'loss_4': 1.3432698249816895, 'epoch': 9.03}
{'loss': 0.0083, 'grad_norm': 5.141043186187744, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.00633360305801034, 'loss_2': 0.00197601318359375, 'loss_3': -16.045001983642578, 'loss_4': 1.1822090148925781, 'epoch': 9.03}
{'loss': 0.0255, 'grad_norm': 7.648510932922363, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.016516990959644318, 'loss_2': 0.0089874267578125, 'loss_3': -16.2834529876709, 'loss_4': 1.4645771980285645, 'epoch': 9.04}
[INFO|trainer.py:4228] 2025-01-21 15:56:03,576 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:03,576 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [38:57<1:02:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:10,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015678770840168, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008830457925796509, 'eval_loss_2': 0.0068483129143714905, 'eval_loss_3': -18.201065063476562, 'eval_loss_4': 0.837922215461731, 'epoch': 9.04}
{'loss': 0.0312, 'grad_norm': 6.26646089553833, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.02097182907164097, 'loss_2': 0.0102081298828125, 'loss_3': -16.145645141601562, 'loss_4': 0.6631141304969788, 'epoch': 9.05}
{'loss': 0.0282, 'grad_norm': 10.882871627807617, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.019241798669099808, 'loss_2': 0.00899505615234375, 'loss_3': -16.35275650024414, 'loss_4': 0.6320375204086304, 'epoch': 9.05}
{'loss': 0.0228, 'grad_norm': 13.859233856201172, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.021850084885954857, 'loss_2': 0.0009751319885253906, 'loss_3': -16.191240310668945, 'loss_4': 1.084448218345642, 'epoch': 9.06}
{'loss': 0.0175, 'grad_norm': 7.321399688720703, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.014478558674454689, 'loss_2': 0.002979278564453125, 'loss_3': -16.138500213623047, 'loss_4': 1.3030402660369873, 'epoch': 9.06}
{'loss': 0.0116, 'grad_norm': 5.928606033325195, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.010924378409981728, 'loss_2': 0.0006809234619140625, 'loss_3': -16.16566276550293, 'loss_4': 0.5468271970748901, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 15:56:10,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:10,937 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [39:04<1:02:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:18,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011892684735357761, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.968, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007794008124619722, 'eval_loss_2': 0.004098676145076752, 'eval_loss_3': -18.19575309753418, 'eval_loss_4': 0.883531928062439, 'epoch': 9.07}
{'loss': 0.016, 'grad_norm': 10.262928009033203, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.013083926402032375, 'loss_2': 0.0028667449951171875, 'loss_3': -16.404695510864258, 'loss_4': 0.8890972137451172, 'epoch': 9.08}
{'loss': 0.0108, 'grad_norm': 5.826704502105713, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.007934004999697208, 'loss_2': 0.002826690673828125, 'loss_3': -16.120525360107422, 'loss_4': 0.6673020720481873, 'epoch': 9.08}
{'loss': 0.0193, 'grad_norm': 6.462063789367676, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.011009749956429005, 'loss_2': 0.008270263671875, 'loss_3': -16.218364715576172, 'loss_4': 0.5662822127342224, 'epoch': 9.09}
{'loss': 0.0106, 'grad_norm': 5.858652114868164, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.01003581564873457, 'loss_2': 0.0005750656127929688, 'loss_3': -16.247329711914062, 'loss_4': 0.7575069069862366, 'epoch': 9.09}
{'loss': 0.0188, 'grad_norm': 7.409358978271484, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.014638390392065048, 'loss_2': 0.00412750244140625, 'loss_3': -16.038490295410156, 'loss_4': 1.2259644269943237, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 15:56:18,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:18,294 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [39:12<1:02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:25,656 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015075722709298134, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00769070815294981, 'eval_loss_2': 0.0073850154876708984, 'eval_loss_3': -18.20490837097168, 'eval_loss_4': 0.696326732635498, 'epoch': 9.1}
{'loss': 0.0331, 'grad_norm': 10.597395896911621, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.028493890538811684, 'loss_2': 0.00461578369140625, 'loss_3': -16.133352279663086, 'loss_4': 1.064249038696289, 'epoch': 9.1}
{'loss': 0.031, 'grad_norm': 9.80803394317627, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.024619730189442635, 'loss_2': 0.00637054443359375, 'loss_3': -16.09501838684082, 'loss_4': 0.47949257493019104, 'epoch': 9.11}
{'loss': 0.0183, 'grad_norm': 7.219860553741455, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.011013067327439785, 'loss_2': 0.00733184814453125, 'loss_3': -16.137617111206055, 'loss_4': 1.0515451431274414, 'epoch': 9.12}
{'loss': 0.0213, 'grad_norm': 7.761041164398193, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.014282163232564926, 'loss_2': 0.00699615478515625, 'loss_3': -16.06615447998047, 'loss_4': 0.7730388641357422, 'epoch': 9.12}
{'loss': 0.0214, 'grad_norm': 6.097195148468018, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.01116188894957304, 'loss_2': 0.010284423828125, 'loss_3': -15.992093086242676, 'loss_4': 0.3865187168121338, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 15:56:25,656 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:25,656 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:19<1:02:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:33,013 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01298051979392767, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.485, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00848465971648693, 'eval_loss_2': 0.004495859146118164, 'eval_loss_3': -18.21082305908203, 'eval_loss_4': 0.5001920461654663, 'epoch': 9.13}
{'loss': 0.011, 'grad_norm': 4.979440212249756, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.006950075738132, 'loss_2': 0.00400543212890625, 'loss_3': -16.051145553588867, 'loss_4': 0.34002000093460083, 'epoch': 9.13}
{'loss': 0.0224, 'grad_norm': 19.821733474731445, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.019375400617718697, 'loss_2': 0.0030517578125, 'loss_3': -16.048803329467773, 'loss_4': 0.5908515453338623, 'epoch': 9.14}
{'loss': 0.0286, 'grad_norm': 10.434187889099121, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.025499165058135986, 'loss_2': 0.003055572509765625, 'loss_3': -16.22351837158203, 'loss_4': 1.062195897102356, 'epoch': 9.15}
{'loss': 0.0194, 'grad_norm': 9.86731243133545, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.01916377805173397, 'loss_2': 0.00028514862060546875, 'loss_3': -16.17578887939453, 'loss_4': 0.4040353298187256, 'epoch': 9.15}
{'loss': 0.0186, 'grad_norm': 6.176219940185547, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.01450764387845993, 'loss_2': 0.0040740966796875, 'loss_3': -16.278759002685547, 'loss_4': 0.7172285914421082, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 15:56:33,014 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:33,014 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:26<1:02:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:40,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014567118138074875, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.685, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009385953657329082, 'eval_loss_2': 0.005181163549423218, 'eval_loss_3': -18.212356567382812, 'eval_loss_4': 0.3193252980709076, 'epoch': 9.16}
{'loss': 0.02, 'grad_norm': 10.828004837036133, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.01854335516691208, 'loss_2': 0.001461029052734375, 'loss_3': -16.122447967529297, 'loss_4': 0.27251654863357544, 'epoch': 9.16}
{'loss': 0.054, 'grad_norm': 14.763742446899414, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.05262229964137077, 'loss_2': 0.0013523101806640625, 'loss_3': -16.230121612548828, 'loss_4': 0.6946296691894531, 'epoch': 9.17}
{'loss': 0.0217, 'grad_norm': 9.208990097045898, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.01793273352086544, 'loss_2': 0.003814697265625, 'loss_3': -16.104873657226562, 'loss_4': 0.9764256477355957, 'epoch': 9.17}
{'loss': 0.0167, 'grad_norm': 7.599490642547607, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.015747543424367905, 'loss_2': 0.000949859619140625, 'loss_3': -16.213464736938477, 'loss_4': 0.5911611914634705, 'epoch': 9.18}
{'loss': 0.0737, 'grad_norm': 12.927827835083008, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.0716741755604744, 'loss_2': 0.0020294189453125, 'loss_3': -16.303281784057617, 'loss_4': 0.9111409783363342, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 15:56:40,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:40,373 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:34<1:01:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:47,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012906658463180065, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.224, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008171784691512585, 'eval_loss_2': 0.0047348737716674805, 'eval_loss_3': -18.23123550415039, 'eval_loss_4': 0.3301025629043579, 'epoch': 9.19}
{'loss': 0.0229, 'grad_norm': 8.448366165161133, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.020095273852348328, 'loss_2': 0.002834320068359375, 'loss_3': -16.136154174804688, 'loss_4': 0.07516368478536606, 'epoch': 9.19}
{'loss': 0.0521, 'grad_norm': 26.09232521057129, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.05202580615878105, 'loss_2': 6.651878356933594e-05, 'loss_3': -16.15045166015625, 'loss_4': 0.6064445972442627, 'epoch': 9.2}
{'loss': 0.0174, 'grad_norm': 6.855808734893799, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.012978185899555683, 'loss_2': 0.004413604736328125, 'loss_3': -16.10476303100586, 'loss_4': 0.9579508900642395, 'epoch': 9.2}
{'loss': 0.026, 'grad_norm': 15.81949234008789, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.023343149572610855, 'loss_2': 0.00264739990234375, 'loss_3': -16.178071975708008, 'loss_4': 0.2719644606113434, 'epoch': 9.21}
{'loss': 0.0259, 'grad_norm': 10.592893600463867, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.02483210153877735, 'loss_2': 0.0010356903076171875, 'loss_3': -16.255245208740234, 'loss_4': 0.3880133330821991, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 15:56:47,718 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:47,718 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:41<1:01:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:56:55,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012491834349930286, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.148, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008449156768620014, 'eval_loss_2': 0.004042677581310272, 'eval_loss_3': -18.248695373535156, 'eval_loss_4': 0.37371543049812317, 'epoch': 9.22}
{'loss': 0.0262, 'grad_norm': 7.896897792816162, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.025302009657025337, 'loss_2': 0.0009412765502929688, 'loss_3': -16.254074096679688, 'loss_4': 0.7231972813606262, 'epoch': 9.22}
{'loss': 0.0355, 'grad_norm': 16.360803604125977, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.03489996865391731, 'loss_2': 0.0005588531494140625, 'loss_3': -16.21926498413086, 'loss_4': 0.6074999570846558, 'epoch': 9.23}
{'loss': 0.0189, 'grad_norm': 5.22964334487915, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.011454501189291477, 'loss_2': 0.007434844970703125, 'loss_3': -16.46251106262207, 'loss_4': 0.3177769184112549, 'epoch': 9.23}
{'loss': 0.0193, 'grad_norm': 6.31027889251709, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.014596030116081238, 'loss_2': 0.004673004150390625, 'loss_3': -16.313369750976562, 'loss_4': 0.9521353244781494, 'epoch': 9.24}
{'loss': 0.0212, 'grad_norm': 6.04384183883667, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.016127368435263634, 'loss_2': 0.0051116943359375, 'loss_3': -16.31397247314453, 'loss_4': 0.8522287607192993, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 15:56:55,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:56:55,067 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:49<1:01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:02,421 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013090036809444427, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009143956005573273, 'eval_loss_2': 0.003946080803871155, 'eval_loss_3': -18.282913208007812, 'eval_loss_4': 0.18924817442893982, 'epoch': 9.24}
{'loss': 0.0228, 'grad_norm': 8.814408302307129, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.02213991805911064, 'loss_2': 0.0006785392761230469, 'loss_3': -16.526628494262695, 'loss_4': 0.24780549108982086, 'epoch': 9.25}
{'loss': 0.0292, 'grad_norm': 11.483428001403809, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.024135328829288483, 'loss_2': 0.0051116943359375, 'loss_3': -16.395170211791992, 'loss_4': 0.2686878740787506, 'epoch': 9.26}
{'loss': 0.0241, 'grad_norm': 9.212121963500977, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.023013578727841377, 'loss_2': 0.001102447509765625, 'loss_3': -16.151634216308594, 'loss_4': 0.2662994861602783, 'epoch': 9.26}
{'loss': 0.034, 'grad_norm': 11.92076301574707, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.02818206511437893, 'loss_2': 0.00580596923828125, 'loss_3': -16.369182586669922, 'loss_4': 0.38235291838645935, 'epoch': 9.27}
{'loss': 0.0245, 'grad_norm': 5.880491733551025, 'learning_rate': 2.075e-05, 'loss_1': 0.014516989700496197, 'loss_2': 0.01003265380859375, 'loss_3': -16.016979217529297, 'loss_4': -0.27054551243782043, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 15:57:02,421 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:02,421 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:56<1:01:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:09,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017171716317534447, 'eval_runtime': 3.8162, 'eval_samples_per_second': 268.326, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.009025856852531433, 'eval_loss_2': 0.008145861327648163, 'eval_loss_3': -18.253694534301758, 'eval_loss_4': -0.08968418836593628, 'epoch': 9.27}
{'loss': 0.0316, 'grad_norm': 7.037962436676025, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.018120024353265762, 'loss_2': 0.0134429931640625, 'loss_3': -16.10047149658203, 'loss_4': 0.21008849143981934, 'epoch': 9.28}
{'loss': 0.0336, 'grad_norm': 9.644234657287598, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.025870494544506073, 'loss_2': 0.0077667236328125, 'loss_3': -16.116905212402344, 'loss_4': -0.01753269135951996, 'epoch': 9.28}
{'loss': 0.0383, 'grad_norm': 8.81492805480957, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.02969685196876526, 'loss_2': 0.00858306884765625, 'loss_3': -15.974329948425293, 'loss_4': 0.11151036620140076, 'epoch': 9.29}
{'loss': 0.0306, 'grad_norm': 21.70197868347168, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.02879246324300766, 'loss_2': 0.001773834228515625, 'loss_3': -16.201305389404297, 'loss_4': -0.4039367437362671, 'epoch': 9.3}
{'loss': 0.0135, 'grad_norm': 6.1033430099487305, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.008315455168485641, 'loss_2': 0.00522613525390625, 'loss_3': -16.319164276123047, 'loss_4': -0.14115795493125916, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 15:57:09,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:09,789 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [40:03<1:01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:17,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013999060727655888, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.848, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009395092725753784, 'eval_loss_2': 0.004603967070579529, 'eval_loss_3': -18.235620498657227, 'eval_loss_4': -0.4252878725528717, 'epoch': 9.3}
{'loss': 0.0188, 'grad_norm': 5.801954746246338, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.014323174953460693, 'loss_2': 0.00450897216796875, 'loss_3': -16.26243019104004, 'loss_4': -0.38948023319244385, 'epoch': 9.31}
{'loss': 0.044, 'grad_norm': 18.1103515625, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.042691249400377274, 'loss_2': 0.0013523101806640625, 'loss_3': -16.192781448364258, 'loss_4': -0.11569670587778091, 'epoch': 9.31}
{'loss': 0.017, 'grad_norm': 5.217333793640137, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.010527580045163631, 'loss_2': 0.006519317626953125, 'loss_3': -16.352611541748047, 'loss_4': -0.4137924313545227, 'epoch': 9.32}
{'loss': 0.0257, 'grad_norm': 8.10214614868164, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.021420180797576904, 'loss_2': 0.004306793212890625, 'loss_3': -16.244312286376953, 'loss_4': -0.11237841844558716, 'epoch': 9.33}
{'loss': 0.0191, 'grad_norm': 4.944920063018799, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.010027594864368439, 'loss_2': 0.00902557373046875, 'loss_3': -16.248804092407227, 'loss_4': -0.5561531782150269, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 15:57:17,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:17,144 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [40:11<1:01:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:24,497 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020917164161801338, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009496914222836494, 'eval_loss_2': 0.011420249938964844, 'eval_loss_3': -18.214590072631836, 'eval_loss_4': -0.418894499540329, 'epoch': 9.33}
{'loss': 0.0125, 'grad_norm': 6.157036304473877, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.009313809685409069, 'loss_2': 0.003147125244140625, 'loss_3': -16.26102638244629, 'loss_4': -0.2811102271080017, 'epoch': 9.34}
{'loss': 0.0326, 'grad_norm': 6.22431755065918, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.01522830594331026, 'loss_2': 0.0174102783203125, 'loss_3': -16.246421813964844, 'loss_4': 0.3166174292564392, 'epoch': 9.34}
{'loss': 0.0312, 'grad_norm': 8.123473167419434, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.02399211935698986, 'loss_2': 0.00719451904296875, 'loss_3': -16.18475914001465, 'loss_4': -0.3642394244670868, 'epoch': 9.35}
{'loss': 0.0167, 'grad_norm': 5.475691795349121, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.013198651373386383, 'loss_2': 0.0034885406494140625, 'loss_3': -16.069841384887695, 'loss_4': -0.4571375548839569, 'epoch': 9.35}
{'loss': 0.0081, 'grad_norm': 4.821568489074707, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.004988805390894413, 'loss_2': 0.00313568115234375, 'loss_3': -16.4488525390625, 'loss_4': -0.3878985047340393, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 15:57:24,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:24,497 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:18<1:01:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:31,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015817247331142426, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009992414154112339, 'eval_loss_2': 0.005824834108352661, 'eval_loss_3': -18.203001022338867, 'eval_loss_4': -0.42736753821372986, 'epoch': 9.36}
{'loss': 0.0204, 'grad_norm': 8.76179027557373, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.016298944130539894, 'loss_2': 0.0040740966796875, 'loss_3': -16.593727111816406, 'loss_4': -0.6174799203872681, 'epoch': 9.37}
{'loss': 0.0158, 'grad_norm': 6.2660956382751465, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.01371246762573719, 'loss_2': 0.00209808349609375, 'loss_3': -16.19806480407715, 'loss_4': 0.2513861060142517, 'epoch': 9.37}
{'loss': 0.0279, 'grad_norm': 12.61392879486084, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.02230968326330185, 'loss_2': 0.005584716796875, 'loss_3': -16.153226852416992, 'loss_4': -0.3562213182449341, 'epoch': 9.38}
{'loss': 0.0186, 'grad_norm': 7.885892391204834, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.016468197107315063, 'loss_2': 0.0021457672119140625, 'loss_3': -16.199766159057617, 'loss_4': -0.21106138825416565, 'epoch': 9.38}
{'loss': 0.0338, 'grad_norm': 12.217376708984375, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.02817615680396557, 'loss_2': 0.00560760498046875, 'loss_3': -16.193557739257812, 'loss_4': -0.2550087571144104, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 15:57:31,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:31,844 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:25<1:01:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:39,194 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015447668731212616, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.063, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011167741380631924, 'eval_loss_2': 0.004279926419258118, 'eval_loss_3': -18.20561981201172, 'eval_loss_4': -0.47979211807250977, 'epoch': 9.39}
{'loss': 0.03, 'grad_norm': 7.387157440185547, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.020593935623764992, 'loss_2': 0.009368896484375, 'loss_3': -16.196693420410156, 'loss_4': -0.3397636413574219, 'epoch': 9.4}
{'loss': 0.0166, 'grad_norm': 6.772634983062744, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.015012389048933983, 'loss_2': 0.0015850067138671875, 'loss_3': -16.285926818847656, 'loss_4': -0.28750377893447876, 'epoch': 9.4}
{'loss': 0.0222, 'grad_norm': 12.347001075744629, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.018589742481708527, 'loss_2': 0.0035762786865234375, 'loss_3': -16.268896102905273, 'loss_4': -0.05646892637014389, 'epoch': 9.41}
{'loss': 0.0113, 'grad_norm': 6.582337379455566, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.010632828809320927, 'loss_2': 0.0007085800170898438, 'loss_3': -16.270225524902344, 'loss_4': -0.37410488724708557, 'epoch': 9.41}
{'loss': 0.0197, 'grad_norm': 5.372902870178223, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.01087802741676569, 'loss_2': 0.00885009765625, 'loss_3': -16.427696228027344, 'loss_4': -0.5601204037666321, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 15:57:39,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:39,194 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:33<1:01:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:46,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01792004145681858, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.682, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012799346819519997, 'eval_loss_2': 0.005120694637298584, 'eval_loss_3': -18.162282943725586, 'eval_loss_4': -0.14698806405067444, 'epoch': 9.42}
{'loss': 0.0277, 'grad_norm': 10.194771766662598, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.018611624836921692, 'loss_2': 0.0091094970703125, 'loss_3': -16.2102108001709, 'loss_4': -0.31694141030311584, 'epoch': 9.42}
{'loss': 0.0085, 'grad_norm': 5.545507907867432, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.007566436193883419, 'loss_2': 0.000926971435546875, 'loss_3': -16.347335815429688, 'loss_4': -0.20919834077358246, 'epoch': 9.43}
{'loss': 0.0173, 'grad_norm': 5.126800060272217, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.010490559041500092, 'loss_2': 0.006824493408203125, 'loss_3': -16.399818420410156, 'loss_4': 0.18148614466190338, 'epoch': 9.44}
{'loss': 0.0081, 'grad_norm': 4.844901084899902, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.005574203096330166, 'loss_2': 0.002536773681640625, 'loss_3': -16.319957733154297, 'loss_4': -0.25597357749938965, 'epoch': 9.44}
{'loss': 0.0167, 'grad_norm': 5.610248565673828, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.008915637619793415, 'loss_2': 0.00774383544921875, 'loss_3': -16.273086547851562, 'loss_4': 0.01845933496952057, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 15:57:46,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:46,556 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:40<1:01:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:57:53,910 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022523457184433937, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.42, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01718086190521717, 'eval_loss_2': 0.005342595279216766, 'eval_loss_3': -18.123210906982422, 'eval_loss_4': 0.21165607869625092, 'epoch': 9.45}
{'loss': 0.0072, 'grad_norm': 4.483367443084717, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.007007438223809004, 'loss_2': 0.00018072128295898438, 'loss_3': -16.439476013183594, 'loss_4': 0.45177531242370605, 'epoch': 9.45}
{'loss': 0.0335, 'grad_norm': 9.927149772644043, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.024457477033138275, 'loss_2': 0.0090789794921875, 'loss_3': -16.216676712036133, 'loss_4': 0.3442060351371765, 'epoch': 9.46}
{'loss': 0.0144, 'grad_norm': 5.292158126831055, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.008425258100032806, 'loss_2': 0.00594329833984375, 'loss_3': -16.388151168823242, 'loss_4': 0.02465781569480896, 'epoch': 9.47}
{'loss': 0.0262, 'grad_norm': 8.433815956115723, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.017262421548366547, 'loss_2': 0.0089569091796875, 'loss_3': -16.22481918334961, 'loss_4': 0.08161601424217224, 'epoch': 9.47}
{'loss': 0.1083, 'grad_norm': 21.26335334777832, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.10738358646631241, 'loss_2': 0.0008687973022460938, 'loss_3': -16.079864501953125, 'loss_4': 0.21047060191631317, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 15:57:53,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:57:53,910 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:47<1:00:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:01,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02191978693008423, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.213, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017445992678403854, 'eval_loss_2': 0.004473794251680374, 'eval_loss_3': -18.105661392211914, 'eval_loss_4': 0.41414305567741394, 'epoch': 9.48}
{'loss': 0.0269, 'grad_norm': 8.456196784973145, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.023532802239060402, 'loss_2': 0.0033721923828125, 'loss_3': -16.296030044555664, 'loss_4': 0.18009288609027863, 'epoch': 9.48}
{'loss': 0.0136, 'grad_norm': 4.891855239868164, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.007951293140649796, 'loss_2': 0.0056304931640625, 'loss_3': -16.413005828857422, 'loss_4': 0.8220065832138062, 'epoch': 9.49}
{'loss': 0.0215, 'grad_norm': 6.771521091461182, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.012713962234556675, 'loss_2': 0.00879669189453125, 'loss_3': -16.361961364746094, 'loss_4': 0.4553859233856201, 'epoch': 9.49}
{'loss': 0.0237, 'grad_norm': 7.398538112640381, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.01202197652310133, 'loss_2': 0.011688232421875, 'loss_3': -16.32415008544922, 'loss_4': 0.260648250579834, 'epoch': 9.5}
{'loss': 0.0139, 'grad_norm': 7.081930160522461, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.01110566221177578, 'loss_2': 0.0027790069580078125, 'loss_3': -16.32512855529785, 'loss_4': 0.32600611448287964, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 15:58:01,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:01,260 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:55<1:00:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:08,600 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023766759783029556, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.020025987178087234, 'eval_loss_2': 0.0037407726049423218, 'eval_loss_3': -18.03820037841797, 'eval_loss_4': 0.44503796100616455, 'epoch': 9.51}
{'loss': 0.0144, 'grad_norm': 5.3502678871154785, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.007309153210371733, 'loss_2': 0.007110595703125, 'loss_3': -16.335105895996094, 'loss_4': 0.9541829824447632, 'epoch': 9.51}
{'loss': 0.0119, 'grad_norm': 4.896157264709473, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.005772041156888008, 'loss_2': 0.006137847900390625, 'loss_3': -16.355239868164062, 'loss_4': 0.20087981224060059, 'epoch': 9.52}
{'loss': 0.0226, 'grad_norm': 9.612531661987305, 'learning_rate': 2.05e-05, 'loss_1': 0.019498039036989212, 'loss_2': 0.003131866455078125, 'loss_3': -16.120281219482422, 'loss_4': 0.6341964602470398, 'epoch': 9.52}
{'loss': 0.0207, 'grad_norm': 6.153117656707764, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.011203941889107227, 'loss_2': 0.0095367431640625, 'loss_3': -16.398761749267578, 'loss_4': 0.22227075695991516, 'epoch': 9.53}
{'loss': 0.0168, 'grad_norm': 5.62766170501709, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.00974211934953928, 'loss_2': 0.00707244873046875, 'loss_3': -16.252704620361328, 'loss_4': 0.0754280686378479, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 15:58:08,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:08,601 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [41:02<1:00:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:15,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026687312871217728, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.02085118554532528, 'eval_loss_2': 0.005836129188537598, 'eval_loss_3': -18.026514053344727, 'eval_loss_4': 0.4481765031814575, 'epoch': 9.53}
{'loss': 0.0178, 'grad_norm': 6.000230312347412, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.010760053992271423, 'loss_2': 0.00705718994140625, 'loss_3': -16.135461807250977, 'loss_4': 0.11719780415296555, 'epoch': 9.54}
{'loss': 0.0935, 'grad_norm': 23.900943756103516, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.08801253885030746, 'loss_2': 0.00548553466796875, 'loss_3': -16.383146286010742, 'loss_4': 0.13191679120063782, 'epoch': 9.55}
{'loss': 0.0352, 'grad_norm': 15.159988403320312, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.0315101183950901, 'loss_2': 0.003719329833984375, 'loss_3': -16.107173919677734, 'loss_4': 0.719581127166748, 'epoch': 9.55}
{'loss': 0.0247, 'grad_norm': 10.428650856018066, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.024681881070137024, 'loss_2': 6.079673767089844e-06, 'loss_3': -16.352706909179688, 'loss_4': 0.903126060962677, 'epoch': 9.56}
{'loss': 0.0141, 'grad_norm': 6.347537994384766, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.013844557106494904, 'loss_2': 0.0002613067626953125, 'loss_3': -16.188879013061523, 'loss_4': 0.3579292297363281, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 15:58:15,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:15,946 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [41:09<1:00:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:23,295 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020080476999282837, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.138, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015772433951497078, 'eval_loss_2': 0.004308044910430908, 'eval_loss_3': -18.04793357849121, 'eval_loss_4': 0.5441591739654541, 'epoch': 9.56}
{'loss': 0.0226, 'grad_norm': 9.172791481018066, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.0222880020737648, 'loss_2': 0.0003113746643066406, 'loss_3': -16.331192016601562, 'loss_4': 0.3977823853492737, 'epoch': 9.57}
{'loss': 0.0089, 'grad_norm': 6.20224142074585, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.007990757003426552, 'loss_2': 0.000946044921875, 'loss_3': -16.197668075561523, 'loss_4': 0.8684159517288208, 'epoch': 9.58}
{'loss': 0.0281, 'grad_norm': 9.011093139648438, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.023370472714304924, 'loss_2': 0.00476837158203125, 'loss_3': -16.253509521484375, 'loss_4': 0.6733241081237793, 'epoch': 9.58}
{'loss': 0.0306, 'grad_norm': 12.193408966064453, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.026782065629959106, 'loss_2': 0.00384521484375, 'loss_3': -16.373714447021484, 'loss_4': 0.9463314414024353, 'epoch': 9.59}
{'loss': 0.0115, 'grad_norm': 5.423282146453857, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.00602585868909955, 'loss_2': 0.0054473876953125, 'loss_3': -16.405441284179688, 'loss_4': 0.40822941064834595, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 15:58:23,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:23,295 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:17<1:01:31,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 15:58:30,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014781864359974861, 'eval_runtime': 4.0016, 'eval_samples_per_second': 255.899, 'eval_steps_per_second': 3.998, 'eval_loss_1': 0.008803906850516796, 'eval_loss_2': 0.00597795844078064, 'eval_loss_3': -18.166744232177734, 'eval_loss_4': 0.7156080603599548, 'epoch': 9.59}
{'loss': 0.0292, 'grad_norm': 12.556781768798828, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.020389076322317123, 'loss_2': 0.008819580078125, 'loss_3': -16.03881072998047, 'loss_4': 0.9704352617263794, 'epoch': 9.6}
{'loss': 0.0223, 'grad_norm': 6.453920841217041, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.013154106214642525, 'loss_2': 0.00916290283203125, 'loss_3': -16.452110290527344, 'loss_4': 0.6706090569496155, 'epoch': 9.6}
{'loss': 0.0418, 'grad_norm': 19.544198989868164, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.036281995475292206, 'loss_2': 0.005565643310546875, 'loss_3': -16.164640426635742, 'loss_4': 0.5879385471343994, 'epoch': 9.61}
{'loss': 0.0165, 'grad_norm': 5.406030178070068, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.01144458819180727, 'loss_2': 0.005100250244140625, 'loss_3': -16.289236068725586, 'loss_4': 0.7506524324417114, 'epoch': 9.62}
{'loss': 0.0143, 'grad_norm': 6.3517937660217285, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.013167597353458405, 'loss_2': 0.0011692047119140625, 'loss_3': -16.405879974365234, 'loss_4': 0.28669604659080505, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 15:58:30,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:30,846 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:24<1:00:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:38,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012768693268299103, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008694477379322052, 'eval_loss_2': 0.004074215888977051, 'eval_loss_3': -18.189828872680664, 'eval_loss_4': 0.793453574180603, 'epoch': 9.62}
{'loss': 0.0124, 'grad_norm': 5.668388366699219, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.00881114974617958, 'loss_2': 0.00357818603515625, 'loss_3': -16.272872924804688, 'loss_4': 0.4974288046360016, 'epoch': 9.63}
{'loss': 0.0104, 'grad_norm': 5.154064178466797, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.009212641976773739, 'loss_2': 0.001224517822265625, 'loss_3': -16.537208557128906, 'loss_4': 0.41838201880455017, 'epoch': 9.63}
{'loss': 0.0175, 'grad_norm': 5.372499942779541, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.012005208060145378, 'loss_2': 0.0054473876953125, 'loss_3': -16.341611862182617, 'loss_4': 1.1629819869995117, 'epoch': 9.64}
{'loss': 0.0322, 'grad_norm': 7.842005252838135, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.02069992385804653, 'loss_2': 0.01153564453125, 'loss_3': -16.374116897583008, 'loss_4': 0.46379342675209045, 'epoch': 9.65}
{'loss': 0.0165, 'grad_norm': 5.893773555755615, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.010933940298855305, 'loss_2': 0.005519866943359375, 'loss_3': -16.211509704589844, 'loss_4': 0.6048123836517334, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 15:58:38,193 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:38,193 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:32<1:00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:45,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016669228672981262, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009721055626869202, 'eval_loss_2': 0.0069481730461120605, 'eval_loss_3': -18.229625701904297, 'eval_loss_4': 0.6454616189002991, 'epoch': 9.65}
{'loss': 0.0244, 'grad_norm': 7.66849946975708, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.015329847112298012, 'loss_2': 0.0090789794921875, 'loss_3': -16.265811920166016, 'loss_4': 0.9763913154602051, 'epoch': 9.66}
{'loss': 0.0247, 'grad_norm': 8.902154922485352, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.01772286370396614, 'loss_2': 0.0069427490234375, 'loss_3': -16.427095413208008, 'loss_4': 0.603050947189331, 'epoch': 9.66}
{'loss': 0.0193, 'grad_norm': 6.4496941566467285, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.015166408382356167, 'loss_2': 0.0041351318359375, 'loss_3': -16.339332580566406, 'loss_4': 0.7923743724822998, 'epoch': 9.67}
{'loss': 0.0353, 'grad_norm': 9.742405891418457, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.028808526694774628, 'loss_2': 0.006473541259765625, 'loss_3': -16.37728500366211, 'loss_4': 0.5750465393066406, 'epoch': 9.67}
{'loss': 0.0306, 'grad_norm': 11.40942096710205, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.029183609411120415, 'loss_2': 0.00138092041015625, 'loss_3': -16.234891891479492, 'loss_4': 0.9330828785896301, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 15:58:45,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:45,546 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:39<1:00:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:58:52,892 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01390906609594822, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00971832312643528, 'eval_loss_2': 0.0041907429695129395, 'eval_loss_3': -18.24075698852539, 'eval_loss_4': 0.42024606466293335, 'epoch': 9.68}
{'loss': 0.0503, 'grad_norm': 19.228837966918945, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.043898485600948334, 'loss_2': 0.00640869140625, 'loss_3': -16.359535217285156, 'loss_4': 0.29949676990509033, 'epoch': 9.69}
{'loss': 0.0213, 'grad_norm': 5.157290935516357, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.013014682568609715, 'loss_2': 0.0082855224609375, 'loss_3': -16.27859878540039, 'loss_4': 0.4253784716129303, 'epoch': 9.69}
{'loss': 0.0186, 'grad_norm': 6.109605312347412, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.012066224589943886, 'loss_2': 0.006561279296875, 'loss_3': -16.279560089111328, 'loss_4': 0.33682358264923096, 'epoch': 9.7}
{'loss': 0.0333, 'grad_norm': 8.7164945602417, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.029612230136990547, 'loss_2': 0.003726959228515625, 'loss_3': -16.252376556396484, 'loss_4': -0.1157638281583786, 'epoch': 9.7}
{'loss': 0.0273, 'grad_norm': 10.302247047424316, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.026943473145365715, 'loss_2': 0.0003657341003417969, 'loss_3': -16.324142456054688, 'loss_4': 0.2846149206161499, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 15:58:52,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:58:52,892 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:46<1:00:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:00,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012375323101878166, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.675, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009006349369883537, 'eval_loss_2': 0.003368973731994629, 'eval_loss_3': -18.23941421508789, 'eval_loss_4': 0.3089115619659424, 'epoch': 9.71}
{'loss': 0.0162, 'grad_norm': 7.905301094055176, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.014554321765899658, 'loss_2': 0.0016088485717773438, 'loss_3': -16.548561096191406, 'loss_4': 0.5300275683403015, 'epoch': 9.72}
{'loss': 0.0211, 'grad_norm': 6.354865074157715, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.018406227231025696, 'loss_2': 0.002727508544921875, 'loss_3': -16.36360740661621, 'loss_4': 0.9155857563018799, 'epoch': 9.72}
{'loss': 0.0248, 'grad_norm': 8.09218978881836, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.022988062351942062, 'loss_2': 0.0018148422241210938, 'loss_3': -16.26732635498047, 'loss_4': 0.18455183506011963, 'epoch': 9.73}
{'loss': 0.0192, 'grad_norm': 6.819442272186279, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.018409572541713715, 'loss_2': 0.0008053779602050781, 'loss_3': -16.395954132080078, 'loss_4': 0.8459880948066711, 'epoch': 9.73}
{'loss': 0.0144, 'grad_norm': 6.38221549987793, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.012660355307161808, 'loss_2': 0.0016946792602539062, 'loss_3': -16.34093475341797, 'loss_4': 0.49298232793807983, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 15:59:00,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:00,244 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:54<1:00:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:07,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014972967095673084, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.911, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009705762378871441, 'eval_loss_2': 0.005267202854156494, 'eval_loss_3': -18.232540130615234, 'eval_loss_4': 0.259203165769577, 'epoch': 9.74}
{'loss': 0.0178, 'grad_norm': 6.635308742523193, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.013963738456368446, 'loss_2': 0.003814697265625, 'loss_3': -16.348730087280273, 'loss_4': 0.0017265379428863525, 'epoch': 9.74}
{'loss': 0.0177, 'grad_norm': 5.7959794998168945, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.012783505953848362, 'loss_2': 0.00489044189453125, 'loss_3': -16.20309066772461, 'loss_4': 0.38501638174057007, 'epoch': 9.75}
{'loss': 0.017, 'grad_norm': 5.711643695831299, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.013888451270759106, 'loss_2': 0.0030689239501953125, 'loss_3': -16.481170654296875, 'loss_4': -0.29481515288352966, 'epoch': 9.76}
{'loss': 0.0257, 'grad_norm': 8.273219108581543, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.01990860141813755, 'loss_2': 0.005828857421875, 'loss_3': -16.133983612060547, 'loss_4': 0.17054420709609985, 'epoch': 9.76}
{'loss': 0.0226, 'grad_norm': 6.636484146118164, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.014650366269052029, 'loss_2': 0.00798797607421875, 'loss_3': -16.4364013671875, 'loss_4': 0.4352111220359802, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 15:59:07,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:07,595 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [42:01<1:00:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:14,957 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012374617159366608, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.474, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009716368280351162, 'eval_loss_2': 0.002658247947692871, 'eval_loss_3': -18.223024368286133, 'eval_loss_4': 0.14920370280742645, 'epoch': 9.77}
{'loss': 0.029, 'grad_norm': 8.774624824523926, 'learning_rate': 2.025e-05, 'loss_1': 0.021623020991683006, 'loss_2': 0.00736236572265625, 'loss_3': -16.24040985107422, 'loss_4': -0.03102743998169899, 'epoch': 9.77}
{'loss': 0.0266, 'grad_norm': 8.049474716186523, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.02009354718029499, 'loss_2': 0.006458282470703125, 'loss_3': -16.599491119384766, 'loss_4': 0.20541182160377502, 'epoch': 9.78}
{'loss': 0.0265, 'grad_norm': 6.416977882385254, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.022234927862882614, 'loss_2': 0.004302978515625, 'loss_3': -16.36810302734375, 'loss_4': 0.02928779274225235, 'epoch': 9.78}
{'loss': 0.0394, 'grad_norm': 12.460594177246094, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.03447670117020607, 'loss_2': 0.004947662353515625, 'loss_3': -16.147159576416016, 'loss_4': -0.14213818311691284, 'epoch': 9.79}
{'loss': 0.0164, 'grad_norm': 5.028277397155762, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.009692218154668808, 'loss_2': 0.006687164306640625, 'loss_3': -16.381507873535156, 'loss_4': -0.23156729340553284, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 15:59:14,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:14,958 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1690/5160 [42:08<1:00:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:22,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01753687486052513, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.186, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010937598533928394, 'eval_loss_2': 0.0065992772579193115, 'eval_loss_3': -18.216047286987305, 'eval_loss_4': -0.002454545348882675, 'epoch': 9.8}
{'loss': 0.0215, 'grad_norm': 6.702211380004883, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.01584138534963131, 'loss_2': 0.0056304931640625, 'loss_3': -16.33685302734375, 'loss_4': -0.6037862300872803, 'epoch': 9.8}
{'loss': 0.049, 'grad_norm': 22.93950653076172, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.0413050577044487, 'loss_2': 0.00766754150390625, 'loss_3': -16.350261688232422, 'loss_4': 0.4900473356246948, 'epoch': 9.81}
{'loss': 0.0175, 'grad_norm': 8.930523872375488, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.01710515096783638, 'loss_2': 0.0003612041473388672, 'loss_3': -16.2491455078125, 'loss_4': 0.6348958015441895, 'epoch': 9.81}
{'loss': 0.0387, 'grad_norm': 13.327045440673828, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.030826281756162643, 'loss_2': 0.0079193115234375, 'loss_3': -16.509904861450195, 'loss_4': 0.23083020746707916, 'epoch': 9.82}
{'loss': 0.0141, 'grad_norm': 4.784838676452637, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.008176607079803944, 'loss_2': 0.005889892578125, 'loss_3': -16.119556427001953, 'loss_4': -0.097560815513134, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 15:59:22,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:22,302 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                    | 1695/5160 [42:16<59:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:29,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013345031999051571, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.92, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00996513944119215, 'eval_loss_2': 0.0033798925578594208, 'eval_loss_3': -18.212202072143555, 'eval_loss_4': -0.052866388112306595, 'epoch': 9.83}
{'loss': 0.0365, 'grad_norm': 14.176311492919922, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.03039284236729145, 'loss_2': 0.00611114501953125, 'loss_3': -16.027923583984375, 'loss_4': -0.3365148901939392, 'epoch': 9.83}
{'loss': 0.078, 'grad_norm': 10.155107498168945, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.07549665868282318, 'loss_2': 0.00247955322265625, 'loss_3': -16.356611251831055, 'loss_4': -0.0032466650009155273, 'epoch': 9.84}
{'loss': 0.0243, 'grad_norm': 9.22441291809082, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.02393895573914051, 'loss_2': 0.0003833770751953125, 'loss_3': -16.048107147216797, 'loss_4': 0.22310768067836761, 'epoch': 9.84}
{'loss': 0.0278, 'grad_norm': 9.170191764831543, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.02551654353737831, 'loss_2': 0.00223541259765625, 'loss_3': -16.149946212768555, 'loss_4': 0.21257475018501282, 'epoch': 9.85}
{'loss': 0.0358, 'grad_norm': 11.95749282836914, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.02034497633576393, 'loss_2': 0.015472412109375, 'loss_3': -16.377073287963867, 'loss_4': 0.2948083281517029, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 15:59:29,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:29,648 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▊                                                                                                                                                    | 1700/5160 [42:23<59:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:36,998 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014736117795109749, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.15, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010320396162569523, 'eval_loss_2': 0.004415720701217651, 'eval_loss_3': -18.21006202697754, 'eval_loss_4': 0.08237859606742859, 'epoch': 9.85}
{'loss': 0.0092, 'grad_norm': 5.270448207855225, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.008972179144620895, 'loss_2': 0.000263214111328125, 'loss_3': -16.297122955322266, 'loss_4': 0.0246976837515831, 'epoch': 9.86}
{'loss': 0.014, 'grad_norm': 6.530165672302246, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.012999136932194233, 'loss_2': 0.0009813308715820312, 'loss_3': -16.439998626708984, 'loss_4': 0.042348504066467285, 'epoch': 9.87}
{'loss': 0.0126, 'grad_norm': 5.661558151245117, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.011440038681030273, 'loss_2': 0.0011749267578125, 'loss_3': -16.250381469726562, 'loss_4': 0.7214148640632629, 'epoch': 9.87}
{'loss': 0.0232, 'grad_norm': 6.566763401031494, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.0169911477714777, 'loss_2': 0.0062103271484375, 'loss_3': -16.34469223022461, 'loss_4': -0.12610402703285217, 'epoch': 9.88}
{'loss': 0.0223, 'grad_norm': 8.169631004333496, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.01963108777999878, 'loss_2': 0.0026531219482421875, 'loss_3': -16.12879180908203, 'loss_4': 0.3647513687610626, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 15:59:36,998 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:36,998 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1705/5160 [42:30<59:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:44,342 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014927789568901062, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.347, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011433341540396214, 'eval_loss_2': 0.003494448959827423, 'eval_loss_3': -18.203744888305664, 'eval_loss_4': 0.2399243712425232, 'epoch': 9.88}
{'loss': 0.0486, 'grad_norm': 12.089189529418945, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.04677993431687355, 'loss_2': 0.001781463623046875, 'loss_3': -16.155820846557617, 'loss_4': 0.21942612528800964, 'epoch': 9.89}
{'loss': 0.0445, 'grad_norm': 16.833385467529297, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.041001398116350174, 'loss_2': 0.0035305023193359375, 'loss_3': -16.084808349609375, 'loss_4': 0.19154012203216553, 'epoch': 9.9}
{'loss': 0.0349, 'grad_norm': 12.656822204589844, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.027961550280451775, 'loss_2': 0.006984710693359375, 'loss_3': -16.20914077758789, 'loss_4': 0.43831008672714233, 'epoch': 9.9}
{'loss': 0.0191, 'grad_norm': 6.095257759094238, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.01828034594655037, 'loss_2': 0.000850677490234375, 'loss_3': -16.466835021972656, 'loss_4': 0.6648334264755249, 'epoch': 9.91}
{'loss': 0.0198, 'grad_norm': 8.311132431030273, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.016463270410895348, 'loss_2': 0.0033092498779296875, 'loss_3': -16.356407165527344, 'loss_4': 0.4239107370376587, 'epoch': 9.91}
[INFO|trainer.py:4228] 2025-01-21 15:59:44,342 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:44,342 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▏                                                                                                                                                   | 1710/5160 [42:38<59:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:51,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014537295326590538, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.882, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01120763923972845, 'eval_loss_2': 0.003329657018184662, 'eval_loss_3': -18.207176208496094, 'eval_loss_4': 0.43805640935897827, 'epoch': 9.91}
{'loss': 0.0222, 'grad_norm': 7.0959343910217285, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.016254983842372894, 'loss_2': 0.005950927734375, 'loss_3': -16.006013870239258, 'loss_4': 0.26644083857536316, 'epoch': 9.92}
{'loss': 0.0171, 'grad_norm': 6.182186603546143, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.012904117815196514, 'loss_2': 0.004199981689453125, 'loss_3': -16.418777465820312, 'loss_4': 0.44803524017333984, 'epoch': 9.92}
{'loss': 0.0271, 'grad_norm': 7.356937885284424, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.0213142242282629, 'loss_2': 0.005756378173828125, 'loss_3': -16.048816680908203, 'loss_4': 0.8929306268692017, 'epoch': 9.93}
{'loss': 0.0764, 'grad_norm': 16.71702766418457, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.07233914732933044, 'loss_2': 0.0040283203125, 'loss_3': -16.358428955078125, 'loss_4': 1.1279244422912598, 'epoch': 9.94}
{'loss': 0.0283, 'grad_norm': 10.293891906738281, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.025217315182089806, 'loss_2': 0.003047943115234375, 'loss_3': -16.275007247924805, 'loss_4': 0.6327974200248718, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 15:59:51,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:51,693 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:45<59:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 15:59:59,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012449007481336594, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009817369282245636, 'eval_loss_2': 0.0026316381990909576, 'eval_loss_3': -18.216707229614258, 'eval_loss_4': 0.92377108335495, 'epoch': 9.94}
{'loss': 0.011, 'grad_norm': 5.286164283752441, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.010244709439575672, 'loss_2': 0.0007734298706054688, 'loss_3': -16.45413589477539, 'loss_4': 1.513897180557251, 'epoch': 9.95}
{'loss': 0.0482, 'grad_norm': 13.696723937988281, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.043139126151800156, 'loss_2': 0.00502777099609375, 'loss_3': -16.228269577026367, 'loss_4': 1.3617209196090698, 'epoch': 9.95}
{'loss': 0.0175, 'grad_norm': 6.695675373077393, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.01655874028801918, 'loss_2': 0.00093841552734375, 'loss_3': -16.168869018554688, 'loss_4': 0.8277683854103088, 'epoch': 9.96}
{'loss': 0.0376, 'grad_norm': 14.775318145751953, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.03649377077817917, 'loss_2': 0.0010833740234375, 'loss_3': -16.37876319885254, 'loss_4': 0.862369179725647, 'epoch': 9.97}
{'loss': 0.0305, 'grad_norm': 7.200371742248535, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.023720407858490944, 'loss_2': 0.006755828857421875, 'loss_3': -16.40910530090332, 'loss_4': 1.8579413890838623, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 15:59:59,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 15:59:59,043 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:52<53:31,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:00:06,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012557195499539375, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.289, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009951764717698097, 'eval_loss_2': 0.002605430781841278, 'eval_loss_3': -18.204742431640625, 'eval_loss_4': 1.119875431060791, 'epoch': 9.97}
{'loss': 0.0133, 'grad_norm': 6.798370361328125, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.009781674481928349, 'loss_2': 0.003566741943359375, 'loss_3': -16.356218338012695, 'loss_4': 0.642237663269043, 'epoch': 9.98}
{'loss': 0.0099, 'grad_norm': 5.336918830871582, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.009307429194450378, 'loss_2': 0.0005884170532226562, 'loss_3': -16.20317840576172, 'loss_4': 1.1282037496566772, 'epoch': 9.98}
{'loss': 0.0143, 'grad_norm': 5.688309669494629, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.013326459564268589, 'loss_2': 0.000934600830078125, 'loss_3': -16.41822052001953, 'loss_4': 1.4468591213226318, 'epoch': 9.99}
{'loss': 0.0258, 'grad_norm': 11.626808166503906, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.014630138874053955, 'loss_2': 0.011199951171875, 'loss_3': -16.233524322509766, 'loss_4': 1.0841946601867676, 'epoch': 9.99}
{'loss': 0.0048, 'grad_norm': 6.769046783447266, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.004439500626176596, 'loss_2': 0.0003666877746582031, 'loss_3': -16.386272430419922, 'loss_4': 1.4409922361373901, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 16:00:06,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:06,038 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [43:00<58:36,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:00:13,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013229195959866047, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.757, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009981324896216393, 'eval_loss_2': 0.003247871994972229, 'eval_loss_3': -18.21929931640625, 'eval_loss_4': 1.243665337562561, 'epoch': 10.0}
{'loss': 0.0264, 'grad_norm': 14.851313591003418, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.024611204862594604, 'loss_2': 0.001781463623046875, 'loss_3': -16.30188751220703, 'loss_4': 1.0143390893936157, 'epoch': 10.01}
{'loss': 0.0259, 'grad_norm': 8.646157264709473, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.018564091995358467, 'loss_2': 0.0073394775390625, 'loss_3': -16.170360565185547, 'loss_4': 0.9578150510787964, 'epoch': 10.01}
{'loss': 0.0267, 'grad_norm': 6.0860915184021, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.017063185572624207, 'loss_2': 0.0096435546875, 'loss_3': -16.317127227783203, 'loss_4': 1.3957016468048096, 'epoch': 10.02}
{'loss': 0.0186, 'grad_norm': 8.041757583618164, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.014225964434444904, 'loss_2': 0.00432586669921875, 'loss_3': -16.234664916992188, 'loss_4': 1.6435977220535278, 'epoch': 10.02}
{'loss': 0.0154, 'grad_norm': 5.563156604766846, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.009797420352697372, 'loss_2': 0.005615234375, 'loss_3': -16.483644485473633, 'loss_4': 1.2964332103729248, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 16:00:13,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:13,434 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [43:07<59:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:20,791 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012866409495472908, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009271392598748207, 'eval_loss_2': 0.003595016896724701, 'eval_loss_3': -18.251188278198242, 'eval_loss_4': 1.2481690645217896, 'epoch': 10.03}
{'loss': 0.0248, 'grad_norm': 9.642823219299316, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.023856479674577713, 'loss_2': 0.0009746551513671875, 'loss_3': -16.18386459350586, 'loss_4': 1.300990343093872, 'epoch': 10.03}
{'loss': 0.0298, 'grad_norm': 10.540850639343262, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.026685481891036034, 'loss_2': 0.0031337738037109375, 'loss_3': -16.01453971862793, 'loss_4': 1.3226820230484009, 'epoch': 10.04}
{'loss': 0.0165, 'grad_norm': 7.055993556976318, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.015685876831412315, 'loss_2': 0.0008640289306640625, 'loss_3': -16.284467697143555, 'loss_4': 1.9449506998062134, 'epoch': 10.05}
{'loss': 0.0224, 'grad_norm': 8.599698066711426, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.021969489753246307, 'loss_2': 0.0004239082336425781, 'loss_3': -16.52193832397461, 'loss_4': 1.475285530090332, 'epoch': 10.05}
{'loss': 0.026, 'grad_norm': 7.2026801109313965, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.01850724034011364, 'loss_2': 0.007488250732421875, 'loss_3': -16.17253875732422, 'loss_4': 1.028808355331421, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 16:00:20,791 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:20,791 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [43:14<59:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:28,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01693379320204258, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.646, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008995168842375278, 'eval_loss_2': 0.007938623428344727, 'eval_loss_3': -18.201980590820312, 'eval_loss_4': 0.7191052436828613, 'epoch': 10.06}
{'loss': 0.009, 'grad_norm': 5.0261006355285645, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.007179540116339922, 'loss_2': 0.0018491744995117188, 'loss_3': -16.31254005432129, 'loss_4': 1.1254942417144775, 'epoch': 10.06}
{'loss': 0.0189, 'grad_norm': 6.681519985198975, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.013743199408054352, 'loss_2': 0.0052032470703125, 'loss_3': -16.285465240478516, 'loss_4': 0.6559475660324097, 'epoch': 10.07}
{'loss': 0.0285, 'grad_norm': 6.7730607986450195, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.018233485519886017, 'loss_2': 0.01029205322265625, 'loss_3': -16.44366455078125, 'loss_4': 0.31324756145477295, 'epoch': 10.08}
{'loss': 0.0268, 'grad_norm': 9.344217300415039, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.021805107593536377, 'loss_2': 0.0049591064453125, 'loss_3': -16.268733978271484, 'loss_4': 0.298674076795578, 'epoch': 10.08}
{'loss': 0.0151, 'grad_norm': 6.912498950958252, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.014740332961082458, 'loss_2': 0.00034999847412109375, 'loss_3': -16.35771942138672, 'loss_4': 0.031666576862335205, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 16:00:28,154 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:28,154 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:22<59:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:35,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012769239023327827, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.459, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009164633229374886, 'eval_loss_2': 0.003604605793952942, 'eval_loss_3': -18.212175369262695, 'eval_loss_4': -0.16258780658245087, 'epoch': 10.09}
{'loss': 0.0122, 'grad_norm': 5.804278373718262, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.01134429033845663, 'loss_2': 0.000843048095703125, 'loss_3': -16.30382537841797, 'loss_4': -0.28231021761894226, 'epoch': 10.09}
{'loss': 0.0339, 'grad_norm': 13.75181770324707, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.029455654323101044, 'loss_2': 0.00440216064453125, 'loss_3': -16.359806060791016, 'loss_4': -0.20169949531555176, 'epoch': 10.1}
{'loss': 0.014, 'grad_norm': 5.585593223571777, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.008585935458540916, 'loss_2': 0.0054473876953125, 'loss_3': -16.558767318725586, 'loss_4': -0.7689881324768066, 'epoch': 10.1}
{'loss': 0.0372, 'grad_norm': 12.27136516571045, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.03216879814863205, 'loss_2': 0.004993438720703125, 'loss_3': -16.444705963134766, 'loss_4': -0.5586261749267578, 'epoch': 10.11}
{'loss': 0.0234, 'grad_norm': 7.075348377227783, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.019333865493535995, 'loss_2': 0.004108428955078125, 'loss_3': -16.47205352783203, 'loss_4': -0.24118074774742126, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 16:00:35,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:35,517 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:29<59:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:42,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013328881934285164, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009660128504037857, 'eval_loss_2': 0.003668755292892456, 'eval_loss_3': -18.22477912902832, 'eval_loss_4': -0.7848715782165527, 'epoch': 10.12}
{'loss': 0.0176, 'grad_norm': 8.223454475402832, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.012512244284152985, 'loss_2': 0.005062103271484375, 'loss_3': -16.46025276184082, 'loss_4': -0.4500808119773865, 'epoch': 10.12}
{'loss': 0.0383, 'grad_norm': 15.745737075805664, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.03563368692994118, 'loss_2': 0.002620697021484375, 'loss_3': -16.515443801879883, 'loss_4': -0.555604875087738, 'epoch': 10.13}
{'loss': 0.0275, 'grad_norm': 7.531984329223633, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.016679374501109123, 'loss_2': 0.0108184814453125, 'loss_3': -16.28476333618164, 'loss_4': -1.071890115737915, 'epoch': 10.13}
{'loss': 0.015, 'grad_norm': 5.60329008102417, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.011941357515752316, 'loss_2': 0.003009796142578125, 'loss_3': -16.60501480102539, 'loss_4': -0.9490560293197632, 'epoch': 10.14}
{'loss': 0.0153, 'grad_norm': 4.8946027755737305, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.011372452601790428, 'loss_2': 0.00389862060546875, 'loss_3': -16.59654998779297, 'loss_4': -0.9152225255966187, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 16:00:42,859 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:42,859 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:36<58:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:50,214 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017089758068323135, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.623, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011339102871716022, 'eval_loss_2': 0.0057506561279296875, 'eval_loss_3': -18.214303970336914, 'eval_loss_4': -1.052431583404541, 'epoch': 10.15}
{'loss': 0.0223, 'grad_norm': 7.518957138061523, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.01824325881898403, 'loss_2': 0.00402069091796875, 'loss_3': -16.420940399169922, 'loss_4': -0.9764846563339233, 'epoch': 10.15}
{'loss': 0.0116, 'grad_norm': 6.146151542663574, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.011544265784323215, 'loss_2': 1.055002212524414e-05, 'loss_3': -16.44437026977539, 'loss_4': -1.2410215139389038, 'epoch': 10.16}
{'loss': 0.0231, 'grad_norm': 8.708268165588379, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.019649973139166832, 'loss_2': 0.00342559814453125, 'loss_3': -16.4949951171875, 'loss_4': -1.0347628593444824, 'epoch': 10.16}
{'loss': 0.0201, 'grad_norm': 7.783411026000977, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.013567149639129639, 'loss_2': 0.00655364990234375, 'loss_3': -16.39982032775879, 'loss_4': -1.0840468406677246, 'epoch': 10.17}
{'loss': 0.0213, 'grad_norm': 9.168988227844238, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.014713039621710777, 'loss_2': 0.0066070556640625, 'loss_3': -16.464242935180664, 'loss_4': -0.8662813305854797, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 16:00:50,214 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:50,214 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:44<58:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:00:57,554 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01444236934185028, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.105, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010619904845952988, 'eval_loss_2': 0.003822464495897293, 'eval_loss_3': -18.226774215698242, 'eval_loss_4': -0.9554715752601624, 'epoch': 10.17}
{'loss': 0.0179, 'grad_norm': 5.499756336212158, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.015418853610754013, 'loss_2': 0.002460479736328125, 'loss_3': -16.439971923828125, 'loss_4': -0.9455000162124634, 'epoch': 10.18}
{'loss': 0.016, 'grad_norm': 7.53087043762207, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.01240629330277443, 'loss_2': 0.003643035888671875, 'loss_3': -16.502275466918945, 'loss_4': -1.2483108043670654, 'epoch': 10.19}
{'loss': 0.0151, 'grad_norm': 6.723278045654297, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.014658327214419842, 'loss_2': 0.0004420280456542969, 'loss_3': -16.53377914428711, 'loss_4': -1.0172970294952393, 'epoch': 10.19}
{'loss': 0.013, 'grad_norm': 6.040764808654785, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.011191006749868393, 'loss_2': 0.0018558502197265625, 'loss_3': -16.60219955444336, 'loss_4': -0.8613424897193909, 'epoch': 10.2}
{'loss': 0.0281, 'grad_norm': 8.594786643981934, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.023362966254353523, 'loss_2': 0.00478363037109375, 'loss_3': -16.561813354492188, 'loss_4': -0.7972335815429688, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 16:00:57,554 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:00:57,554 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:51<58:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:04,900 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014792848378419876, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.232, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010989922098815441, 'eval_loss_2': 0.0038029253482818604, 'eval_loss_3': -18.22092056274414, 'eval_loss_4': -0.9352962970733643, 'epoch': 10.2}
{'loss': 0.023, 'grad_norm': 8.7567720413208, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.02159438468515873, 'loss_2': 0.0014019012451171875, 'loss_3': -16.357826232910156, 'loss_4': -0.8889083862304688, 'epoch': 10.21}
{'loss': 0.0294, 'grad_norm': 7.119141101837158, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.018019456416368484, 'loss_2': 0.0113372802734375, 'loss_3': -16.41393280029297, 'loss_4': -1.1217068433761597, 'epoch': 10.22}
{'loss': 0.0222, 'grad_norm': 8.34805679321289, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.018243156373500824, 'loss_2': 0.003917694091796875, 'loss_3': -16.30636978149414, 'loss_4': -0.6264362335205078, 'epoch': 10.22}
{'loss': 0.0108, 'grad_norm': 4.915510654449463, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.007635902147740126, 'loss_2': 0.0031147003173828125, 'loss_3': -16.392160415649414, 'loss_4': -1.0344250202178955, 'epoch': 10.23}
{'loss': 0.0412, 'grad_norm': 20.513322830200195, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.03502355143427849, 'loss_2': 0.0061798095703125, 'loss_3': -16.502334594726562, 'loss_4': -1.0421183109283447, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 16:01:04,901 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:04,901 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [43:58<58:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:12,257 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014175765216350555, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.455, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010523967444896698, 'eval_loss_2': 0.0036517977714538574, 'eval_loss_3': -18.22739028930664, 'eval_loss_4': -0.8480508327484131, 'epoch': 10.23}
{'loss': 0.0221, 'grad_norm': 8.421366691589355, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.018282996490597725, 'loss_2': 0.00385284423828125, 'loss_3': -16.331626892089844, 'loss_4': -1.1378355026245117, 'epoch': 10.24}
{'loss': 0.0156, 'grad_norm': 5.148099422454834, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.009190765209496021, 'loss_2': 0.006443023681640625, 'loss_3': -16.391382217407227, 'loss_4': -0.9757585525512695, 'epoch': 10.24}
{'loss': 0.0463, 'grad_norm': 16.256500244140625, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.03912971541285515, 'loss_2': 0.00720977783203125, 'loss_3': -16.260513305664062, 'loss_4': -0.6814367771148682, 'epoch': 10.25}
{'loss': 0.0244, 'grad_norm': 13.8779935836792, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.02422509342432022, 'loss_2': 0.0001342296600341797, 'loss_3': -16.430267333984375, 'loss_4': -0.4885769784450531, 'epoch': 10.26}
{'loss': 0.0219, 'grad_norm': 9.263158798217773, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.02057308703660965, 'loss_2': 0.00133514404296875, 'loss_3': -16.343441009521484, 'loss_4': -0.5287984609603882, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 16:01:12,257 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:12,257 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [44:06<58:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:19,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016112836077809334, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011754067614674568, 'eval_loss_2': 0.004358768463134766, 'eval_loss_3': -18.211544036865234, 'eval_loss_4': -0.558293342590332, 'epoch': 10.26}
{'loss': 0.0232, 'grad_norm': 13.86612319946289, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.01764746755361557, 'loss_2': 0.00554656982421875, 'loss_3': -16.50031089782715, 'loss_4': -0.43394672870635986, 'epoch': 10.27}
{'loss': 0.037, 'grad_norm': 13.052465438842773, 'learning_rate': 1.975e-05, 'loss_1': 0.03369760140776634, 'loss_2': 0.0033321380615234375, 'loss_3': -16.37112045288086, 'loss_4': -0.5995831489562988, 'epoch': 10.27}
{'loss': 0.0222, 'grad_norm': 6.170367240905762, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.014806332066655159, 'loss_2': 0.00734710693359375, 'loss_3': -16.516929626464844, 'loss_4': -0.4309452176094055, 'epoch': 10.28}
{'loss': 0.0545, 'grad_norm': 21.100141525268555, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.05310835689306259, 'loss_2': 0.0014324188232421875, 'loss_3': -16.206043243408203, 'loss_4': -0.1482468992471695, 'epoch': 10.28}
{'loss': 0.0167, 'grad_norm': 5.977516174316406, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.012835996225476265, 'loss_2': 0.00388336181640625, 'loss_3': -16.47416114807129, 'loss_4': -0.449970543384552, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 16:01:19,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:19,609 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [44:13<58:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:26,951 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01462111622095108, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01047582272440195, 'eval_loss_2': 0.004145294427871704, 'eval_loss_3': -18.196691513061523, 'eval_loss_4': -0.215301513671875, 'epoch': 10.29}
{'loss': 0.0133, 'grad_norm': 5.879181385040283, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.010384529829025269, 'loss_2': 0.002918243408203125, 'loss_3': -16.34726333618164, 'loss_4': -0.5121529698371887, 'epoch': 10.3}
{'loss': 0.0273, 'grad_norm': 11.302206039428711, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.027048535645008087, 'loss_2': 0.0002894401550292969, 'loss_3': -16.223934173583984, 'loss_4': 0.07212506234645844, 'epoch': 10.3}
{'loss': 0.0279, 'grad_norm': 12.109952926635742, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.027044348418712616, 'loss_2': 0.0008330345153808594, 'loss_3': -16.362337112426758, 'loss_4': 0.06879238039255142, 'epoch': 10.31}
{'loss': 0.015, 'grad_norm': 5.179696559906006, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.009192507714033127, 'loss_2': 0.00577545166015625, 'loss_3': -16.155044555664062, 'loss_4': -0.3130720853805542, 'epoch': 10.31}
{'loss': 0.0097, 'grad_norm': 5.3291096687316895, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.007932768203318119, 'loss_2': 0.0017185211181640625, 'loss_3': -16.241073608398438, 'loss_4': -0.10871639102697372, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 16:01:26,951 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:26,952 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:20<58:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:34,300 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014224806800484657, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010222404263913631, 'eval_loss_2': 0.0040024034678936005, 'eval_loss_3': -18.17550277709961, 'eval_loss_4': 0.0502903088927269, 'epoch': 10.32}
{'loss': 0.0239, 'grad_norm': 9.34581470489502, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.017809351906180382, 'loss_2': 0.0061187744140625, 'loss_3': -16.318880081176758, 'loss_4': 0.006571926176548004, 'epoch': 10.33}
{'loss': 0.0356, 'grad_norm': 12.031454086303711, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.030915627256035805, 'loss_2': 0.004703521728515625, 'loss_3': -16.350536346435547, 'loss_4': -0.2289009690284729, 'epoch': 10.33}
{'loss': 0.0164, 'grad_norm': 5.951625823974609, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.010182421654462814, 'loss_2': 0.00624847412109375, 'loss_3': -16.241594314575195, 'loss_4': 0.2029714286327362, 'epoch': 10.34}
{'loss': 0.0164, 'grad_norm': 8.469372749328613, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.014758279547095299, 'loss_2': 0.001682281494140625, 'loss_3': -16.483518600463867, 'loss_4': 0.3015064001083374, 'epoch': 10.34}
{'loss': 0.0205, 'grad_norm': 6.933979511260986, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.016537049785256386, 'loss_2': 0.00395965576171875, 'loss_3': -16.246963500976562, 'loss_4': 0.1853235810995102, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 16:01:34,300 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:34,300 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:28<58:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:41,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014207802712917328, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.998, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010699951089918613, 'eval_loss_2': 0.003507852554321289, 'eval_loss_3': -18.178180694580078, 'eval_loss_4': 0.1663154661655426, 'epoch': 10.35}
{'loss': 0.0303, 'grad_norm': 14.361519813537598, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.0290986280888319, 'loss_2': 0.0012226104736328125, 'loss_3': -16.204809188842773, 'loss_4': 0.06029978394508362, 'epoch': 10.35}
{'loss': 0.0246, 'grad_norm': 9.402525901794434, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.01927749440073967, 'loss_2': 0.00531768798828125, 'loss_3': -16.335798263549805, 'loss_4': 0.43279868364334106, 'epoch': 10.36}
{'loss': 0.0213, 'grad_norm': 10.245484352111816, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.01825561374425888, 'loss_2': 0.0030670166015625, 'loss_3': -16.423208236694336, 'loss_4': 0.08643987774848938, 'epoch': 10.37}
{'loss': 0.0177, 'grad_norm': 6.302713871002197, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.010803796350955963, 'loss_2': 0.00685882568359375, 'loss_3': -16.334590911865234, 'loss_4': 0.2295011579990387, 'epoch': 10.37}
{'loss': 0.0206, 'grad_norm': 9.965734481811523, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.02033197320997715, 'loss_2': 0.00022935867309570312, 'loss_3': -16.381023406982422, 'loss_4': 0.40131568908691406, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 16:01:41,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:41,648 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:35<58:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:49,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017416566610336304, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.639, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.014054333791136742, 'eval_loss_2': 0.003362230956554413, 'eval_loss_3': -18.16100311279297, 'eval_loss_4': 0.12562641501426697, 'epoch': 10.38}
{'loss': 0.0146, 'grad_norm': 6.209815979003906, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.011875283904373646, 'loss_2': 0.002685546875, 'loss_3': -16.309799194335938, 'loss_4': 0.6030544638633728, 'epoch': 10.38}
{'loss': 0.0076, 'grad_norm': 5.43294620513916, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.00714007206261158, 'loss_2': 0.00047206878662109375, 'loss_3': -16.541423797607422, 'loss_4': -0.056195687502622604, 'epoch': 10.39}
{'loss': 0.0185, 'grad_norm': 8.773643493652344, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.017500240355730057, 'loss_2': 0.0009613037109375, 'loss_3': -16.502708435058594, 'loss_4': 0.3656751215457916, 'epoch': 10.4}
{'loss': 0.0143, 'grad_norm': 6.1840057373046875, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.011878296732902527, 'loss_2': 0.00240325927734375, 'loss_3': -16.28368377685547, 'loss_4': 0.1027422621846199, 'epoch': 10.4}
{'loss': 0.0238, 'grad_norm': 10.296971321105957, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.020057177171111107, 'loss_2': 0.003704071044921875, 'loss_3': -16.55449104309082, 'loss_4': 0.3936127722263336, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 16:01:49,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:49,009 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:42<58:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:01:56,365 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017805209383368492, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.879, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014452565461397171, 'eval_loss_2': 0.003352642059326172, 'eval_loss_3': -18.149127960205078, 'eval_loss_4': 0.1863793432712555, 'epoch': 10.41}
{'loss': 0.0197, 'grad_norm': 6.403360843658447, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.015572991222143173, 'loss_2': 0.004123687744140625, 'loss_3': -16.57067108154297, 'loss_4': 0.10246464610099792, 'epoch': 10.41}
{'loss': 0.0159, 'grad_norm': 5.83050537109375, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.013399135321378708, 'loss_2': 0.00250244140625, 'loss_3': -16.211441040039062, 'loss_4': -0.2566183805465698, 'epoch': 10.42}
{'loss': 0.0137, 'grad_norm': 6.4126482009887695, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.011742794886231422, 'loss_2': 0.00191497802734375, 'loss_3': -16.323781967163086, 'loss_4': 0.2325424700975418, 'epoch': 10.42}
{'loss': 0.014, 'grad_norm': 5.308506488800049, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.008358641527593136, 'loss_2': 0.00562286376953125, 'loss_3': -16.415624618530273, 'loss_4': 0.35733604431152344, 'epoch': 10.43}
{'loss': 0.0286, 'grad_norm': 11.334907531738281, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.02505319193005562, 'loss_2': 0.0035552978515625, 'loss_3': -16.426612854003906, 'loss_4': 0.1743508130311966, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 16:01:56,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:01:56,365 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:50<58:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:03,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016952890902757645, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.025, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01344116311520338, 'eval_loss_2': 0.0035117268562316895, 'eval_loss_3': -18.14451026916504, 'eval_loss_4': 0.20066910982131958, 'epoch': 10.44}
{'loss': 0.0188, 'grad_norm': 5.489522457122803, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.009799057617783546, 'loss_2': 0.00901031494140625, 'loss_3': -16.137264251708984, 'loss_4': 0.10341429710388184, 'epoch': 10.44}
{'loss': 0.0138, 'grad_norm': 5.051571846008301, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.008888271637260914, 'loss_2': 0.0048828125, 'loss_3': -16.206283569335938, 'loss_4': 0.05095610022544861, 'epoch': 10.45}
{'loss': 0.0291, 'grad_norm': 10.691308975219727, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.026306811720132828, 'loss_2': 0.0027828216552734375, 'loss_3': -16.179670333862305, 'loss_4': -0.07326829433441162, 'epoch': 10.45}
{'loss': 0.0124, 'grad_norm': 5.292222023010254, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.011609421111643314, 'loss_2': 0.000820159912109375, 'loss_3': -16.20580291748047, 'loss_4': 0.01662556827068329, 'epoch': 10.46}
{'loss': 0.0153, 'grad_norm': 5.352136135101318, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.010658717714250088, 'loss_2': 0.004596710205078125, 'loss_3': -16.362510681152344, 'loss_4': 0.254022479057312, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 16:02:03,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:03,711 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [44:57<58:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:11,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01568383350968361, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.159, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011943300254642963, 'eval_loss_2': 0.00374053418636322, 'eval_loss_3': -18.15824317932129, 'eval_loss_4': 0.20087091624736786, 'epoch': 10.47}
{'loss': 0.0163, 'grad_norm': 6.652283191680908, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.015536755323410034, 'loss_2': 0.0007643699645996094, 'loss_3': -16.132720947265625, 'loss_4': 0.28299370408058167, 'epoch': 10.47}
{'loss': 0.0238, 'grad_norm': 11.777287483215332, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.022644493728876114, 'loss_2': 0.001171112060546875, 'loss_3': -16.42412567138672, 'loss_4': 0.10487239062786102, 'epoch': 10.48}
{'loss': 0.0231, 'grad_norm': 6.609735488891602, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.01367489155381918, 'loss_2': 0.0094451904296875, 'loss_3': -16.33450698852539, 'loss_4': 0.3944741487503052, 'epoch': 10.48}
{'loss': 0.0267, 'grad_norm': 11.740150451660156, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.021412884816527367, 'loss_2': 0.0052642822265625, 'loss_3': -16.22024917602539, 'loss_4': 0.3633131980895996, 'epoch': 10.49}
{'loss': 0.024, 'grad_norm': 5.360562801361084, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.008678598329424858, 'loss_2': 0.0153656005859375, 'loss_3': -16.288278579711914, 'loss_4': 0.4563532769680023, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 16:02:11,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:11,060 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [45:05<57:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:18,410 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0211962778121233, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.098, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011685759760439396, 'eval_loss_2': 0.009510517120361328, 'eval_loss_3': -18.18531036376953, 'eval_loss_4': 0.3034731447696686, 'epoch': 10.49}
{'loss': 0.0958, 'grad_norm': 36.090091705322266, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.08020806312561035, 'loss_2': 0.01560211181640625, 'loss_3': -16.11246109008789, 'loss_4': -0.001850523054599762, 'epoch': 10.5}
{'loss': 0.032, 'grad_norm': 8.950531959533691, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.021244501695036888, 'loss_2': 0.01080322265625, 'loss_3': -16.330209732055664, 'loss_4': 0.47807344794273376, 'epoch': 10.51}
{'loss': 0.0242, 'grad_norm': 8.503143310546875, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.021717248484492302, 'loss_2': 0.002437591552734375, 'loss_3': -16.39940643310547, 'loss_4': -0.008765120059251785, 'epoch': 10.51}
{'loss': 0.0225, 'grad_norm': 5.723255634307861, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.009987179189920425, 'loss_2': 0.01250457763671875, 'loss_3': -16.316852569580078, 'loss_4': 0.63139408826828, 'epoch': 10.52}
{'loss': 0.0097, 'grad_norm': 6.320788860321045, 'learning_rate': 1.95e-05, 'loss_1': 0.007654992397874594, 'loss_2': 0.00200653076171875, 'loss_3': -16.29568099975586, 'loss_4': 0.08301487565040588, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 16:02:18,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:18,410 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [45:12<57:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:25,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014690713956952095, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.899, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011605563573539257, 'eval_loss_2': 0.0030851513147354126, 'eval_loss_3': -18.23798370361328, 'eval_loss_4': 0.025144606828689575, 'epoch': 10.52}
{'loss': 0.009, 'grad_norm': 6.819962501525879, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.006747957784682512, 'loss_2': 0.0022125244140625, 'loss_3': -16.28371238708496, 'loss_4': -0.14356355369091034, 'epoch': 10.53}
{'loss': 0.0206, 'grad_norm': 9.300463676452637, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.016622288152575493, 'loss_2': 0.003936767578125, 'loss_3': -16.059295654296875, 'loss_4': -0.0550324022769928, 'epoch': 10.53}
{'loss': 0.011, 'grad_norm': 5.55920934677124, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.010015899315476418, 'loss_2': 0.000995635986328125, 'loss_3': -16.524616241455078, 'loss_4': -0.012779727578163147, 'epoch': 10.54}
{'loss': 0.031, 'grad_norm': 10.767090797424316, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.02733713388442993, 'loss_2': 0.00365447998046875, 'loss_3': -16.212459564208984, 'loss_4': -0.47515642642974854, 'epoch': 10.55}
{'loss': 0.0128, 'grad_norm': 5.323197364807129, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.008126444183290005, 'loss_2': 0.0046844482421875, 'loss_3': -16.186708450317383, 'loss_4': -0.2692050635814667, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 16:02:25,760 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:25,760 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:19<57:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:33,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025464270263910294, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.307, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.013081522658467293, 'eval_loss_2': 0.012382745742797852, 'eval_loss_3': -18.232149124145508, 'eval_loss_4': -0.18711383640766144, 'epoch': 10.55}
{'loss': 0.0252, 'grad_norm': 7.840689182281494, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.01846880465745926, 'loss_2': 0.006717681884765625, 'loss_3': -16.384136199951172, 'loss_4': 0.15372362732887268, 'epoch': 10.56}
{'loss': 0.0319, 'grad_norm': 6.696808338165283, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.016318051144480705, 'loss_2': 0.01558685302734375, 'loss_3': -16.402881622314453, 'loss_4': 0.0833355039358139, 'epoch': 10.56}
{'loss': 0.0252, 'grad_norm': 5.472702503204346, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.009213830344378948, 'loss_2': 0.016021728515625, 'loss_3': -16.500606536865234, 'loss_4': -0.3756486177444458, 'epoch': 10.57}
{'loss': 0.0149, 'grad_norm': 4.963775634765625, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.007476428057998419, 'loss_2': 0.00745391845703125, 'loss_3': -16.42578887939453, 'loss_4': -0.16076448559761047, 'epoch': 10.58}
{'loss': 0.028, 'grad_norm': 6.222903728485107, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.0119168721139431, 'loss_2': 0.0160675048828125, 'loss_3': -16.228023529052734, 'loss_4': -0.44570624828338623, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 16:02:33,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:33,119 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:27<57:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:40,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024824265390634537, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.005, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013662459328770638, 'eval_loss_2': 0.01116180419921875, 'eval_loss_3': -18.225605010986328, 'eval_loss_4': -0.3406107425689697, 'epoch': 10.58}
{'loss': 0.0257, 'grad_norm': 5.811759948730469, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.011721521615982056, 'loss_2': 0.01397705078125, 'loss_3': -16.176408767700195, 'loss_4': -0.36184296011924744, 'epoch': 10.59}
{'loss': 0.0221, 'grad_norm': 5.837645053863525, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.010944153182208538, 'loss_2': 0.011199951171875, 'loss_3': -16.542661666870117, 'loss_4': -0.3393213748931885, 'epoch': 10.59}
{'loss': 0.0182, 'grad_norm': 5.973363399505615, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.010042387060821056, 'loss_2': 0.00812530517578125, 'loss_3': -16.352890014648438, 'loss_4': -0.00756894052028656, 'epoch': 10.6}
{'loss': 0.0211, 'grad_norm': 9.633213996887207, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.01690755970776081, 'loss_2': 0.00418853759765625, 'loss_3': -16.40169906616211, 'loss_4': -0.679210901260376, 'epoch': 10.6}
{'loss': 0.0289, 'grad_norm': 10.788323402404785, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.027491390705108643, 'loss_2': 0.00139617919921875, 'loss_3': -16.168792724609375, 'loss_4': -0.27503931522369385, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 16:02:40,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:40,472 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:34<57:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:47,816 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01949780061841011, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.126, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01550260093063116, 'eval_loss_2': 0.003995202481746674, 'eval_loss_3': -18.210887908935547, 'eval_loss_4': -0.4547213912010193, 'epoch': 10.61}
{'loss': 0.0214, 'grad_norm': 5.782217025756836, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.00818311795592308, 'loss_2': 0.01317596435546875, 'loss_3': -16.45360565185547, 'loss_4': -1.0418041944503784, 'epoch': 10.62}
{'loss': 0.0444, 'grad_norm': 13.8587007522583, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.03637545555830002, 'loss_2': 0.00798797607421875, 'loss_3': -16.149044036865234, 'loss_4': -0.8556258678436279, 'epoch': 10.62}
{'loss': 0.0249, 'grad_norm': 7.358737468719482, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.014805031009018421, 'loss_2': 0.0101318359375, 'loss_3': -16.451400756835938, 'loss_4': -0.45417577028274536, 'epoch': 10.63}
{'loss': 0.0127, 'grad_norm': 4.999229431152344, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.006869905162602663, 'loss_2': 0.00583648681640625, 'loss_3': -16.259052276611328, 'loss_4': -0.383811354637146, 'epoch': 10.63}
{'loss': 0.0268, 'grad_norm': 7.31904411315918, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.018513234332203865, 'loss_2': 0.0083160400390625, 'loss_3': -16.465728759765625, 'loss_4': -0.38539761304855347, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 16:02:47,816 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:47,816 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:41<57:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:02:55,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020219560712575912, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.15, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015081088058650494, 'eval_loss_2': 0.005138471722602844, 'eval_loss_3': -18.246662139892578, 'eval_loss_4': -0.7464956045150757, 'epoch': 10.64}
{'loss': 0.0579, 'grad_norm': 20.078744888305664, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.04906529560685158, 'loss_2': 0.0088043212890625, 'loss_3': -16.431211471557617, 'loss_4': -0.48111146688461304, 'epoch': 10.65}
{'loss': 0.0165, 'grad_norm': 5.338386058807373, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.015030739828944206, 'loss_2': 0.0014286041259765625, 'loss_3': -16.581565856933594, 'loss_4': -0.9808443784713745, 'epoch': 10.65}
{'loss': 0.0976, 'grad_norm': 23.277009963989258, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.09134109318256378, 'loss_2': 0.0062713623046875, 'loss_3': -16.329936981201172, 'loss_4': -0.4335668683052063, 'epoch': 10.66}
{'loss': 0.0155, 'grad_norm': 5.196204662322998, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.010629121214151382, 'loss_2': 0.00485992431640625, 'loss_3': -16.460289001464844, 'loss_4': -0.8272573947906494, 'epoch': 10.66}
{'loss': 0.0173, 'grad_norm': 5.19562292098999, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.012932873331010342, 'loss_2': 0.00432586669921875, 'loss_3': -16.575510025024414, 'loss_4': -0.3192167580127716, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 16:02:55,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:02:55,158 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:49<57:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:02,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020158637315034866, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015626957640051842, 'eval_loss_2': 0.004531681537628174, 'eval_loss_3': -18.25390625, 'eval_loss_4': -0.724408745765686, 'epoch': 10.67}
{'loss': 0.0214, 'grad_norm': 7.618927001953125, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.016897210851311684, 'loss_2': 0.004547119140625, 'loss_3': -16.315153121948242, 'loss_4': -0.8109976053237915, 'epoch': 10.67}
{'loss': 0.0315, 'grad_norm': 9.646921157836914, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.023540353402495384, 'loss_2': 0.00797271728515625, 'loss_3': -16.341182708740234, 'loss_4': -0.41513678431510925, 'epoch': 10.68}
{'loss': 0.0179, 'grad_norm': 6.481868267059326, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.01226111315190792, 'loss_2': 0.0056610107421875, 'loss_3': -16.513004302978516, 'loss_4': -0.3992217481136322, 'epoch': 10.69}
{'loss': 0.0228, 'grad_norm': 8.752569198608398, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.019864238798618317, 'loss_2': 0.002948760986328125, 'loss_3': -16.214712142944336, 'loss_4': -0.7189798355102539, 'epoch': 10.69}
{'loss': 0.0112, 'grad_norm': 5.289848804473877, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.01028074324131012, 'loss_2': 0.0009436607360839844, 'loss_3': -16.44446563720703, 'loss_4': -0.338127076625824, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 16:03:02,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:02,495 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [45:56<57:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:09,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020452149212360382, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.509, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.015204721130430698, 'eval_loss_2': 0.005247429013252258, 'eval_loss_3': -18.223709106445312, 'eval_loss_4': -0.6798763871192932, 'epoch': 10.7}
{'loss': 0.0282, 'grad_norm': 14.824249267578125, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.02487028017640114, 'loss_2': 0.0032958984375, 'loss_3': -16.244291305541992, 'loss_4': -1.030512809753418, 'epoch': 10.7}
{'loss': 0.0163, 'grad_norm': 7.736636161804199, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.015137102454900742, 'loss_2': 0.0011987686157226562, 'loss_3': -16.618358612060547, 'loss_4': -0.7798940539360046, 'epoch': 10.71}
{'loss': 0.0207, 'grad_norm': 10.388899803161621, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.02068418264389038, 'loss_2': 1.8835067749023438e-05, 'loss_3': -16.38141441345215, 'loss_4': -0.6940374374389648, 'epoch': 10.72}
{'loss': 0.0185, 'grad_norm': 7.585417747497559, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.015712503343820572, 'loss_2': 0.002742767333984375, 'loss_3': -16.450740814208984, 'loss_4': -0.9697146415710449, 'epoch': 10.72}
{'loss': 0.0189, 'grad_norm': 7.817478656768799, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.014270883984863758, 'loss_2': 0.004669189453125, 'loss_3': -16.592620849609375, 'loss_4': -0.5821652412414551, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 16:03:09,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:09,853 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [46:03<57:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:17,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019439294934272766, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015389575622975826, 'eval_loss_2': 0.004049718379974365, 'eval_loss_3': -18.22652816772461, 'eval_loss_4': -0.8528218269348145, 'epoch': 10.73}
{'loss': 0.0426, 'grad_norm': 15.581485748291016, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.03985871002078056, 'loss_2': 0.0027446746826171875, 'loss_3': -16.43234634399414, 'loss_4': -0.723090410232544, 'epoch': 10.73}
{'loss': 0.0166, 'grad_norm': 6.195926189422607, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.012767906300723553, 'loss_2': 0.0038089752197265625, 'loss_3': -16.327556610107422, 'loss_4': -0.5399942994117737, 'epoch': 10.74}
{'loss': 0.017, 'grad_norm': 9.681586265563965, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.012544865719974041, 'loss_2': 0.004444122314453125, 'loss_3': -16.406478881835938, 'loss_4': -1.061112642288208, 'epoch': 10.74}
{'loss': 0.0221, 'grad_norm': 9.030221939086914, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.0181175135076046, 'loss_2': 0.0040130615234375, 'loss_3': -16.52004623413086, 'loss_4': -0.4264201819896698, 'epoch': 10.75}
{'loss': 0.0609, 'grad_norm': 18.93992805480957, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.06085968017578125, 'loss_2': 5.525350570678711e-05, 'loss_3': -16.424591064453125, 'loss_4': -0.6759276986122131, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 16:03:17,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:17,194 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [46:11<57:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:24,529 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02052929624915123, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.316, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01489382702857256, 'eval_loss_2': 0.005635470151901245, 'eval_loss_3': -18.253849029541016, 'eval_loss_4': -1.0700278282165527, 'epoch': 10.76}
{'loss': 0.0148, 'grad_norm': 5.210835933685303, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.011053250171244144, 'loss_2': 0.003772735595703125, 'loss_3': -16.43366813659668, 'loss_4': -1.141040325164795, 'epoch': 10.76}
{'loss': 0.0273, 'grad_norm': 9.3878173828125, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.019434012472629547, 'loss_2': 0.0078277587890625, 'loss_3': -16.400653839111328, 'loss_4': -0.9554470181465149, 'epoch': 10.77}
{'loss': 0.0272, 'grad_norm': 14.326908111572266, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.025857169181108475, 'loss_2': 0.0012950897216796875, 'loss_3': -16.372163772583008, 'loss_4': -1.1434506177902222, 'epoch': 10.77}
{'loss': 0.03, 'grad_norm': 12.834972381591797, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.027809880673885345, 'loss_2': 0.002178192138671875, 'loss_3': -16.13367462158203, 'loss_4': -1.0810117721557617, 'epoch': 10.78}
{'loss': 0.0195, 'grad_norm': 6.286525249481201, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.0175457950681448, 'loss_2': 0.001926422119140625, 'loss_3': -16.413732528686523, 'loss_4': -0.9678621888160706, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 16:03:24,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:24,529 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:18<57:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:31,871 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018823867663741112, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.014437682926654816, 'eval_loss_2': 0.004386186599731445, 'eval_loss_3': -18.258258819580078, 'eval_loss_4': -1.1201603412628174, 'epoch': 10.78}
{'loss': 0.0184, 'grad_norm': 5.5551557540893555, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.008669203147292137, 'loss_2': 0.00977325439453125, 'loss_3': -16.388935089111328, 'loss_4': -1.0353418588638306, 'epoch': 10.79}
{'loss': 0.0186, 'grad_norm': 8.328152656555176, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.01743515022099018, 'loss_2': 0.00118255615234375, 'loss_3': -16.57065200805664, 'loss_4': -1.0963900089263916, 'epoch': 10.8}
{'loss': 0.0086, 'grad_norm': 5.365779399871826, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.0070867473259568214, 'loss_2': 0.0015087127685546875, 'loss_3': -16.400012969970703, 'loss_4': -1.0924713611602783, 'epoch': 10.8}
{'loss': 0.0627, 'grad_norm': 15.721880912780762, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.05771811679005623, 'loss_2': 0.0050048828125, 'loss_3': -16.44215202331543, 'loss_4': -1.4357357025146484, 'epoch': 10.81}
{'loss': 0.0171, 'grad_norm': 8.70947551727295, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.01361297257244587, 'loss_2': 0.0034770965576171875, 'loss_3': -16.379138946533203, 'loss_4': -1.1000280380249023, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 16:03:31,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:31,871 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:25<57:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:39,222 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019027601927518845, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.071, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014888961799442768, 'eval_loss_2': 0.004138641059398651, 'eval_loss_3': -18.256622314453125, 'eval_loss_4': -1.2019000053405762, 'epoch': 10.81}
{'loss': 0.0237, 'grad_norm': 9.047173500061035, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.02019430324435234, 'loss_2': 0.00345611572265625, 'loss_3': -16.459625244140625, 'loss_4': -1.0337021350860596, 'epoch': 10.82}
{'loss': 0.0103, 'grad_norm': 4.440220832824707, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.007160579785704613, 'loss_2': 0.0030975341796875, 'loss_3': -16.52598762512207, 'loss_4': -0.8151031732559204, 'epoch': 10.83}
{'loss': 0.0103, 'grad_norm': 4.774593353271484, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.008266856893897057, 'loss_2': 0.0019931793212890625, 'loss_3': -16.28173828125, 'loss_4': -0.8632339239120483, 'epoch': 10.83}
{'loss': 0.0114, 'grad_norm': 5.481632232666016, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.008005984127521515, 'loss_2': 0.0033740997314453125, 'loss_3': -16.361602783203125, 'loss_4': -1.2085437774658203, 'epoch': 10.84}
{'loss': 0.0166, 'grad_norm': 7.559048652648926, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.01383977197110653, 'loss_2': 0.002750396728515625, 'loss_3': -16.462589263916016, 'loss_4': -1.2930947542190552, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 16:03:39,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:39,222 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:33<56:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:46,565 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0193948931992054, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.015154439024627209, 'eval_loss_2': 0.004240453243255615, 'eval_loss_3': -18.212194442749023, 'eval_loss_4': -1.0193935632705688, 'epoch': 10.84}
{'loss': 0.1437, 'grad_norm': 33.91241455078125, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.1398179978132248, 'loss_2': 0.0038433074951171875, 'loss_3': -16.357458114624023, 'loss_4': -1.4456686973571777, 'epoch': 10.85}
{'loss': 0.0123, 'grad_norm': 4.603976726531982, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.007827316410839558, 'loss_2': 0.00450897216796875, 'loss_3': -16.372312545776367, 'loss_4': -0.7807599306106567, 'epoch': 10.85}
{'loss': 0.0155, 'grad_norm': 5.353958606719971, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.010490044951438904, 'loss_2': 0.00504302978515625, 'loss_3': -16.299823760986328, 'loss_4': -1.222908854484558, 'epoch': 10.86}
{'loss': 0.0297, 'grad_norm': 12.533308982849121, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.028186306357383728, 'loss_2': 0.0015621185302734375, 'loss_3': -16.57939910888672, 'loss_4': -0.8779346346855164, 'epoch': 10.87}
{'loss': 0.0408, 'grad_norm': 18.661521911621094, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.0329931303858757, 'loss_2': 0.00780487060546875, 'loss_3': -16.260608673095703, 'loss_4': -1.3653396368026733, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 16:03:46,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:46,565 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:40<56:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:03:53,905 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042318351566791534, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.379, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.03771238774061203, 'eval_loss_2': 0.004605963826179504, 'eval_loss_3': -18.1401424407959, 'eval_loss_4': -1.130086898803711, 'epoch': 10.87}
{'loss': 0.024, 'grad_norm': 8.201828956604004, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.016829248517751694, 'loss_2': 0.00714874267578125, 'loss_3': -16.610904693603516, 'loss_4': -1.691364049911499, 'epoch': 10.88}
{'loss': 0.0462, 'grad_norm': 14.8545560836792, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.04329221695661545, 'loss_2': 0.002941131591796875, 'loss_3': -16.471420288085938, 'loss_4': -1.2995786666870117, 'epoch': 10.88}
{'loss': 0.0846, 'grad_norm': 33.27882766723633, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.07177405059337616, 'loss_2': 0.0128021240234375, 'loss_3': -16.522794723510742, 'loss_4': -0.8795921802520752, 'epoch': 10.89}
{'loss': 0.0238, 'grad_norm': 8.759878158569336, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.018773462623357773, 'loss_2': 0.0049896240234375, 'loss_3': -16.434803009033203, 'loss_4': -1.4216870069503784, 'epoch': 10.9}
{'loss': 0.0345, 'grad_norm': 10.032483100891113, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.025615045800805092, 'loss_2': 0.00884246826171875, 'loss_3': -16.37257957458496, 'loss_4': -1.033902883529663, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 16:03:53,905 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:03:53,905 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:47<56:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:01,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05665066838264465, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.286, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.05351116508245468, 'eval_loss_2': 0.0031394995748996735, 'eval_loss_3': -18.13555908203125, 'eval_loss_4': -1.24763822555542, 'epoch': 10.9}
{'loss': 0.061, 'grad_norm': 16.244911193847656, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.05713387206196785, 'loss_2': 0.003887176513671875, 'loss_3': -16.480941772460938, 'loss_4': -1.8016326427459717, 'epoch': 10.91}
{'loss': 0.0814, 'grad_norm': 37.018619537353516, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.08122647553682327, 'loss_2': 0.0001919269561767578, 'loss_3': -16.46387481689453, 'loss_4': -1.5049488544464111, 'epoch': 10.91}
{'loss': 0.029, 'grad_norm': 7.617798805236816, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.02231898158788681, 'loss_2': 0.0066680908203125, 'loss_3': -16.389678955078125, 'loss_4': -1.6321675777435303, 'epoch': 10.92}
{'loss': 0.0326, 'grad_norm': 9.605110168457031, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.02744600549340248, 'loss_2': 0.00514984130859375, 'loss_3': -16.53976058959961, 'loss_4': -1.3253988027572632, 'epoch': 10.92}
{'loss': 0.0215, 'grad_norm': 6.955083847045898, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.020048080012202263, 'loss_2': 0.0014352798461914062, 'loss_3': -16.739139556884766, 'loss_4': -1.3843897581100464, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 16:04:01,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:01,244 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [46:55<56:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:08,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0218832865357399, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.301, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.017031468451023102, 'eval_loss_2': 0.004851818084716797, 'eval_loss_3': -18.265182495117188, 'eval_loss_4': -1.2269541025161743, 'epoch': 10.93}
{'loss': 0.0329, 'grad_norm': 10.68409252166748, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.025884196162223816, 'loss_2': 0.007061004638671875, 'loss_3': -16.652610778808594, 'loss_4': -1.2361736297607422, 'epoch': 10.94}
{'loss': 0.085, 'grad_norm': 17.37035369873047, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.08080029487609863, 'loss_2': 0.004161834716796875, 'loss_3': -16.5784969329834, 'loss_4': -1.4087809324264526, 'epoch': 10.94}
{'loss': 0.0469, 'grad_norm': 10.962061882019043, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.04058806225657463, 'loss_2': 0.00630950927734375, 'loss_3': -16.575769424438477, 'loss_4': -1.1298134326934814, 'epoch': 10.95}
{'loss': 0.0127, 'grad_norm': 5.765926837921143, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.01244247518479824, 'loss_2': 0.0002505779266357422, 'loss_3': -16.55272674560547, 'loss_4': -1.2917505502700806, 'epoch': 10.95}
{'loss': 0.0369, 'grad_norm': 11.13874340057373, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.03660406544804573, 'loss_2': 0.0003151893615722656, 'loss_3': -16.645355224609375, 'loss_4': -1.414111614227295, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 16:04:08,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:08,585 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [47:02<56:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:15,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015244683250784874, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.428, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011548243463039398, 'eval_loss_2': 0.003696441650390625, 'eval_loss_3': -18.299448013305664, 'eval_loss_4': -1.0455464124679565, 'epoch': 10.96}
{'loss': 0.0284, 'grad_norm': 16.094038009643555, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.026162466034293175, 'loss_2': 0.00218963623046875, 'loss_3': -16.322526931762695, 'loss_4': -1.493472695350647, 'epoch': 10.97}
{'loss': 0.0288, 'grad_norm': 10.816946983337402, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.027514586225152016, 'loss_2': 0.0013027191162109375, 'loss_3': -16.51917266845703, 'loss_4': -1.2208762168884277, 'epoch': 10.97}
{'loss': 0.0712, 'grad_norm': 13.409884452819824, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.06824915111064911, 'loss_2': 0.0029659271240234375, 'loss_3': -16.494491577148438, 'loss_4': -0.7107760906219482, 'epoch': 10.98}
{'loss': 0.0247, 'grad_norm': 7.300343036651611, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.014474854804575443, 'loss_2': 0.0102081298828125, 'loss_3': -16.435192108154297, 'loss_4': -1.012499213218689, 'epoch': 10.98}
{'loss': 0.023, 'grad_norm': 8.229525566101074, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.022960202768445015, 'loss_2': 8.285045623779297e-05, 'loss_3': -16.512563705444336, 'loss_4': -1.1960514783859253, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 16:04:15,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:15,923 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [47:09<54:45,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:04:22,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012837657704949379, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.293, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009036035276949406, 'eval_loss_2': 0.0038016214966773987, 'eval_loss_3': -18.278575897216797, 'eval_loss_4': -0.8165645599365234, 'epoch': 10.99}
{'loss': 0.0121, 'grad_norm': 5.725429534912109, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.009522797539830208, 'loss_2': 0.00258636474609375, 'loss_3': -16.603599548339844, 'loss_4': -0.8657958507537842, 'epoch': 10.99}
{'loss': 0.0067, 'grad_norm': 6.53926944732666, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.003075721673667431, 'loss_2': 0.0036468505859375, 'loss_3': -16.600162506103516, 'loss_4': -0.9769021272659302, 'epoch': 11.0}
{'loss': 0.0417, 'grad_norm': 14.67491340637207, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.039454396814107895, 'loss_2': 0.00225830078125, 'loss_3': -16.475608825683594, 'loss_4': -0.33727511763572693, 'epoch': 11.01}
{'loss': 0.0191, 'grad_norm': 11.008979797363281, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.016723759472370148, 'loss_2': 0.0024089813232421875, 'loss_3': -16.53154945373535, 'loss_4': -0.8347491025924683, 'epoch': 11.01}
{'loss': 0.0105, 'grad_norm': 5.0848388671875, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.009490312077105045, 'loss_2': 0.0010585784912109375, 'loss_3': -16.556745529174805, 'loss_4': -0.7605410814285278, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 16:04:22,950 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:22,950 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:16<56:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:04:30,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013374598696827888, 'eval_runtime': 3.8191, 'eval_samples_per_second': 268.128, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.008998516015708447, 'eval_loss_2': 0.004376083612442017, 'eval_loss_3': -18.291872024536133, 'eval_loss_4': -0.6824147701263428, 'epoch': 11.02}
{'loss': 0.0155, 'grad_norm': 9.938146591186523, 'learning_rate': 1.9e-05, 'loss_1': 0.012523408979177475, 'loss_2': 0.003002166748046875, 'loss_3': -16.425769805908203, 'loss_4': -0.4306541681289673, 'epoch': 11.02}
{'loss': 0.0113, 'grad_norm': 4.87369966506958, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.009799216873943806, 'loss_2': 0.0014820098876953125, 'loss_3': -16.36174774169922, 'loss_4': -0.7213783264160156, 'epoch': 11.03}
{'loss': 0.0159, 'grad_norm': 6.20303201675415, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.008914540521800518, 'loss_2': 0.00698089599609375, 'loss_3': -16.378393173217773, 'loss_4': -1.0100502967834473, 'epoch': 11.03}
{'loss': 0.0156, 'grad_norm': 5.552611827850342, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.00798986665904522, 'loss_2': 0.007602691650390625, 'loss_3': -16.619258880615234, 'loss_4': -0.8329657316207886, 'epoch': 11.04}
{'loss': 0.009, 'grad_norm': 5.117306232452393, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.007282019592821598, 'loss_2': 0.001674652099609375, 'loss_3': -16.24061393737793, 'loss_4': -0.6447515487670898, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 16:04:30,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:30,306 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:24<56:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:37,649 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012515431270003319, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.267, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008979713544249535, 'eval_loss_2': 0.003535717725753784, 'eval_loss_3': -18.278696060180664, 'eval_loss_4': -0.6298325657844543, 'epoch': 11.05}
{'loss': 0.0164, 'grad_norm': 5.4513773918151855, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.010180697776377201, 'loss_2': 0.00621795654296875, 'loss_3': -16.381610870361328, 'loss_4': -0.4632107615470886, 'epoch': 11.05}
{'loss': 0.017, 'grad_norm': 6.677538871765137, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.014921050518751144, 'loss_2': 0.002105712890625, 'loss_3': -16.514793395996094, 'loss_4': -0.13690882921218872, 'epoch': 11.06}
{'loss': 0.017, 'grad_norm': 10.688968658447266, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.015812508761882782, 'loss_2': 0.0011920928955078125, 'loss_3': -16.49022674560547, 'loss_4': -0.5878063440322876, 'epoch': 11.06}
{'loss': 0.0193, 'grad_norm': 5.8138837814331055, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.012416581623256207, 'loss_2': 0.006866455078125, 'loss_3': -16.512523651123047, 'loss_4': -0.4268488585948944, 'epoch': 11.07}
{'loss': 0.0297, 'grad_norm': 9.711023330688477, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.022701436653733253, 'loss_2': 0.00698089599609375, 'loss_3': -16.724517822265625, 'loss_4': -0.3905453681945801, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 16:04:37,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:37,649 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:31<56:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:44,992 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015540753491222858, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.393, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008710717782378197, 'eval_loss_2': 0.006830036640167236, 'eval_loss_3': -18.251035690307617, 'eval_loss_4': -0.3666474223136902, 'epoch': 11.08}
{'loss': 0.0149, 'grad_norm': 5.319562911987305, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.011378450319170952, 'loss_2': 0.0035266876220703125, 'loss_3': -16.213415145874023, 'loss_4': -0.6693665385246277, 'epoch': 11.08}
{'loss': 0.0154, 'grad_norm': 5.148454666137695, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.004787076264619827, 'loss_2': 0.01059722900390625, 'loss_3': -16.435617446899414, 'loss_4': -0.02887216955423355, 'epoch': 11.09}
{'loss': 0.0205, 'grad_norm': 8.582640647888184, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.017912810668349266, 'loss_2': 0.00262451171875, 'loss_3': -16.4196834564209, 'loss_4': -0.18947720527648926, 'epoch': 11.09}
{'loss': 0.0355, 'grad_norm': 14.731931686401367, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.030064702033996582, 'loss_2': 0.00543212890625, 'loss_3': -16.45610809326172, 'loss_4': -0.41743046045303345, 'epoch': 11.1}
{'loss': 0.0312, 'grad_norm': 14.235939025878906, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.02990112639963627, 'loss_2': 0.001270294189453125, 'loss_3': -16.286474227905273, 'loss_4': -0.3330768644809723, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 16:04:44,992 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:44,992 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:38<56:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:52,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015167010948061943, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.171, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011570882983505726, 'eval_loss_2': 0.0035961270332336426, 'eval_loss_3': -18.207916259765625, 'eval_loss_4': -0.16837407648563385, 'epoch': 11.1}
{'loss': 0.0129, 'grad_norm': 5.996979713439941, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.010997992940247059, 'loss_2': 0.001865386962890625, 'loss_3': -16.30703353881836, 'loss_4': -0.5720018148422241, 'epoch': 11.11}
{'loss': 0.019, 'grad_norm': 8.514890670776367, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.017396600916981697, 'loss_2': 0.0016069412231445312, 'loss_3': -16.41677474975586, 'loss_4': -0.1675705909729004, 'epoch': 11.12}
{'loss': 0.0075, 'grad_norm': 5.2917094230651855, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.0073317065834999084, 'loss_2': 0.00013875961303710938, 'loss_3': -16.212858200073242, 'loss_4': -0.31061697006225586, 'epoch': 11.12}
{'loss': 0.0195, 'grad_norm': 13.130845069885254, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.019183630123734474, 'loss_2': 0.0003345012664794922, 'loss_3': -16.442462921142578, 'loss_4': -0.19197890162467957, 'epoch': 11.13}
{'loss': 0.0179, 'grad_norm': 5.7695136070251465, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.015173706226050854, 'loss_2': 0.002758026123046875, 'loss_3': -16.18724250793457, 'loss_4': -0.2638041377067566, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 16:04:52,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:52,335 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:46<55:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:04:59,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018175236880779266, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.444, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014548353850841522, 'eval_loss_2': 0.003626883029937744, 'eval_loss_3': -18.186954498291016, 'eval_loss_4': 0.16050830483436584, 'epoch': 11.13}
{'loss': 0.0136, 'grad_norm': 5.460772514343262, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.009336625225841999, 'loss_2': 0.00429534912109375, 'loss_3': -16.211170196533203, 'loss_4': 0.12274768948554993, 'epoch': 11.14}
{'loss': 0.0177, 'grad_norm': 7.5982465744018555, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.014763152226805687, 'loss_2': 0.0029277801513671875, 'loss_3': -16.370328903198242, 'loss_4': -0.3569753170013428, 'epoch': 11.15}
{'loss': 0.0108, 'grad_norm': 5.4505696296691895, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.005791742820292711, 'loss_2': 0.00498199462890625, 'loss_3': -16.38982582092285, 'loss_4': 0.03726079314947128, 'epoch': 11.15}
{'loss': 0.0119, 'grad_norm': 5.348058700561523, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.008702322840690613, 'loss_2': 0.003246307373046875, 'loss_3': -16.38925552368164, 'loss_4': -0.05218322575092316, 'epoch': 11.16}
{'loss': 0.0248, 'grad_norm': 9.129497528076172, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.020931290462613106, 'loss_2': 0.003849029541015625, 'loss_3': -16.27739143371582, 'loss_4': -0.12190400063991547, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 16:04:59,672 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:04:59,672 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:53<56:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:07,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018636366352438927, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.58, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.014134343713521957, 'eval_loss_2': 0.00450202077627182, 'eval_loss_3': -18.201086044311523, 'eval_loss_4': 0.4156920313835144, 'epoch': 11.16}
{'loss': 0.0106, 'grad_norm': 5.104623794555664, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.008797550573945045, 'loss_2': 0.0018444061279296875, 'loss_3': -16.285139083862305, 'loss_4': 0.10768242180347443, 'epoch': 11.17}
{'loss': 0.0192, 'grad_norm': 6.165713310241699, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.01453294325619936, 'loss_2': 0.0046844482421875, 'loss_3': -16.326404571533203, 'loss_4': 0.3666364252567291, 'epoch': 11.17}
{'loss': 0.0066, 'grad_norm': 5.084888935089111, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.0062005165964365005, 'loss_2': 0.0004189014434814453, 'loss_3': -16.377315521240234, 'loss_4': 0.3212597966194153, 'epoch': 11.18}
{'loss': 0.0307, 'grad_norm': 9.341766357421875, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.026759503409266472, 'loss_2': 0.0039825439453125, 'loss_3': -16.337068557739258, 'loss_4': 0.1064404547214508, 'epoch': 11.19}
{'loss': 0.0424, 'grad_norm': 14.662130355834961, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.04173567146062851, 'loss_2': 0.0006995201110839844, 'loss_3': -16.295177459716797, 'loss_4': 0.36798107624053955, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 16:05:07,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:07,033 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [48:00<55:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:14,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020908042788505554, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.172, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01538817584514618, 'eval_loss_2': 0.005519866943359375, 'eval_loss_3': -18.231529235839844, 'eval_loss_4': 0.4344457983970642, 'epoch': 11.19}
{'loss': 0.0224, 'grad_norm': 6.271732807159424, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.019275957718491554, 'loss_2': 0.003124237060546875, 'loss_3': -16.423009872436523, 'loss_4': -0.15666505694389343, 'epoch': 11.2}
{'loss': 0.0197, 'grad_norm': 7.522646903991699, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.013168130069971085, 'loss_2': 0.006500244140625, 'loss_3': -16.43592071533203, 'loss_4': 0.36482447385787964, 'epoch': 11.2}
{'loss': 0.0198, 'grad_norm': 5.573999881744385, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.01072605513036251, 'loss_2': 0.009033203125, 'loss_3': -16.311861038208008, 'loss_4': 0.5089149475097656, 'epoch': 11.21}
{'loss': 0.0119, 'grad_norm': 6.532873153686523, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.007913772948086262, 'loss_2': 0.0040283203125, 'loss_3': -16.547266006469727, 'loss_4': 0.30623170733451843, 'epoch': 11.22}
{'loss': 0.0266, 'grad_norm': 7.160813331604004, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.018164444714784622, 'loss_2': 0.0084228515625, 'loss_3': -16.23945426940918, 'loss_4': 0.42717164754867554, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 16:05:14,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:14,375 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [48:08<55:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:21,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016751127317547798, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.096, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01237046904861927, 'eval_loss_2': 0.004380658268928528, 'eval_loss_3': -18.23225212097168, 'eval_loss_4': 0.3812783360481262, 'epoch': 11.22}
{'loss': 0.0119, 'grad_norm': 5.699522495269775, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.007784439716488123, 'loss_2': 0.00409698486328125, 'loss_3': -16.29419708251953, 'loss_4': 0.23992064595222473, 'epoch': 11.23}
{'loss': 0.0108, 'grad_norm': 5.393685340881348, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.007060862146317959, 'loss_2': 0.00377655029296875, 'loss_3': -16.2945556640625, 'loss_4': 0.024503514170646667, 'epoch': 11.23}
{'loss': 0.0267, 'grad_norm': 6.5645012855529785, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.02558054029941559, 'loss_2': 0.00112152099609375, 'loss_3': -16.41020965576172, 'loss_4': 0.8769105672836304, 'epoch': 11.24}
{'loss': 0.0095, 'grad_norm': 4.4682416915893555, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.004608524963259697, 'loss_2': 0.004848480224609375, 'loss_3': -16.43244743347168, 'loss_4': 0.23553571105003357, 'epoch': 11.24}
{'loss': 0.0172, 'grad_norm': 5.572714328765869, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.0086744986474514, 'loss_2': 0.008514404296875, 'loss_3': -16.48644256591797, 'loss_4': 0.19579632580280304, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 16:05:21,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:21,726 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [48:15<55:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:29,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01694154366850853, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.298, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010727344080805779, 'eval_loss_2': 0.0062142014503479, 'eval_loss_3': -18.219764709472656, 'eval_loss_4': 0.23010867834091187, 'epoch': 11.25}
{'loss': 0.0219, 'grad_norm': 6.295613765716553, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.012971361167728901, 'loss_2': 0.008941650390625, 'loss_3': -16.369482040405273, 'loss_4': 0.23660218715667725, 'epoch': 11.26}
{'loss': 0.0233, 'grad_norm': 9.380064010620117, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.02099716290831566, 'loss_2': 0.002285003662109375, 'loss_3': -16.39661407470703, 'loss_4': -0.31645646691322327, 'epoch': 11.26}
{'loss': 0.0137, 'grad_norm': 4.907191276550293, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.00466999551281333, 'loss_2': 0.00905609130859375, 'loss_3': -16.196916580200195, 'loss_4': 0.19299811124801636, 'epoch': 11.27}
{'loss': 0.0133, 'grad_norm': 6.354569435119629, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.012048988603055477, 'loss_2': 0.0012502670288085938, 'loss_3': -16.188119888305664, 'loss_4': 0.28120243549346924, 'epoch': 11.27}
{'loss': 0.0226, 'grad_norm': 8.077863693237305, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.015750568360090256, 'loss_2': 0.006885528564453125, 'loss_3': -16.37717056274414, 'loss_4': 0.2531491219997406, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 16:05:29,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:29,063 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:23<55:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:36,406 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015047065913677216, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011325418949127197, 'eval_loss_2': 0.0037216469645500183, 'eval_loss_3': -18.212871551513672, 'eval_loss_4': 0.10177487879991531, 'epoch': 11.28}
{'loss': 0.0253, 'grad_norm': 18.442127227783203, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.021016906946897507, 'loss_2': 0.0042877197265625, 'loss_3': -16.366928100585938, 'loss_4': 0.25842350721359253, 'epoch': 11.28}
{'loss': 0.0359, 'grad_norm': 16.708477020263672, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.03426850587129593, 'loss_2': 0.0016164779663085938, 'loss_3': -16.119251251220703, 'loss_4': -0.14566467702388763, 'epoch': 11.29}
{'loss': 0.0179, 'grad_norm': 12.105042457580566, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.015091209672391415, 'loss_2': 0.002838134765625, 'loss_3': -16.164688110351562, 'loss_4': 0.21249529719352722, 'epoch': 11.3}
{'loss': 0.0176, 'grad_norm': 6.6549201011657715, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.015785759314894676, 'loss_2': 0.0017871856689453125, 'loss_3': -16.31570053100586, 'loss_4': -0.2750924229621887, 'epoch': 11.3}
{'loss': 0.0107, 'grad_norm': 5.297976016998291, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.007707859389483929, 'loss_2': 0.0030307769775390625, 'loss_3': -16.314212799072266, 'loss_4': -0.18605397641658783, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 16:05:36,406 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:36,406 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:30<55:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:43,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016492603346705437, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.087, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011671541258692741, 'eval_loss_2': 0.004821062088012695, 'eval_loss_3': -18.2264347076416, 'eval_loss_4': 0.17183971405029297, 'epoch': 11.31}
{'loss': 0.0733, 'grad_norm': 11.97901439666748, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.0696222111582756, 'loss_2': 0.0036792755126953125, 'loss_3': -16.248777389526367, 'loss_4': 0.11324173212051392, 'epoch': 11.31}
{'loss': 0.018, 'grad_norm': 6.883298397064209, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.013042490929365158, 'loss_2': 0.0050048828125, 'loss_3': -16.489803314208984, 'loss_4': 0.6327509880065918, 'epoch': 11.32}
{'loss': 0.0097, 'grad_norm': 4.74325704574585, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.006122462917119265, 'loss_2': 0.0035572052001953125, 'loss_3': -16.496179580688477, 'loss_4': 0.5291199088096619, 'epoch': 11.33}
{'loss': 0.0266, 'grad_norm': 8.280295372009277, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.01744411326944828, 'loss_2': 0.009124755859375, 'loss_3': -16.135913848876953, 'loss_4': -0.18172478675842285, 'epoch': 11.33}
{'loss': 0.0221, 'grad_norm': 5.975375652313232, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.015981247648596764, 'loss_2': 0.006134033203125, 'loss_3': -16.332304000854492, 'loss_4': 0.3851560354232788, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 16:05:43,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:43,754 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:37<55:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:51,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014812629669904709, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.544, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.010094908066093922, 'eval_loss_2': 0.004717722535133362, 'eval_loss_3': -18.219097137451172, 'eval_loss_4': 0.3462463617324829, 'epoch': 11.34}
{'loss': 0.0714, 'grad_norm': 10.268783569335938, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.0648219883441925, 'loss_2': 0.006595611572265625, 'loss_3': -16.520545959472656, 'loss_4': 0.5588483214378357, 'epoch': 11.34}
{'loss': 0.0273, 'grad_norm': 10.969522476196289, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.020821988582611084, 'loss_2': 0.00652313232421875, 'loss_3': -16.387887954711914, 'loss_4': 0.23331746459007263, 'epoch': 11.35}
{'loss': 0.0105, 'grad_norm': 5.733212947845459, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.010425569489598274, 'loss_2': 4.756450653076172e-05, 'loss_3': -16.132549285888672, 'loss_4': 0.08759389817714691, 'epoch': 11.35}
{'loss': 0.0251, 'grad_norm': 7.725555896759033, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.017194347456097603, 'loss_2': 0.007904052734375, 'loss_3': -16.472352981567383, 'loss_4': 0.23835214972496033, 'epoch': 11.36}
{'loss': 0.0148, 'grad_norm': 6.0436601638793945, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.011427858844399452, 'loss_2': 0.00341033935546875, 'loss_3': -16.335359573364258, 'loss_4': -0.028277326375246048, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 16:05:51,107 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:51,107 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:45<55:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:05:58,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0140610970556736, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010522532276809216, 'eval_loss_2': 0.003538563847541809, 'eval_loss_3': -18.21604347229004, 'eval_loss_4': -0.013460739515721798, 'epoch': 11.37}
{'loss': 0.0149, 'grad_norm': 6.069088935852051, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.010455057956278324, 'loss_2': 0.0044403076171875, 'loss_3': -16.278846740722656, 'loss_4': -0.22872352600097656, 'epoch': 11.37}
{'loss': 0.0124, 'grad_norm': 6.592724800109863, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.009993151761591434, 'loss_2': 0.00237274169921875, 'loss_3': -16.350568771362305, 'loss_4': 0.11639822274446487, 'epoch': 11.38}
{'loss': 0.0121, 'grad_norm': 5.840370178222656, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.011098681017756462, 'loss_2': 0.0009703636169433594, 'loss_3': -16.5236873626709, 'loss_4': -0.28060200810432434, 'epoch': 11.38}
{'loss': 0.0236, 'grad_norm': 9.862768173217773, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.021235685795545578, 'loss_2': 0.002384185791015625, 'loss_3': -16.05145263671875, 'loss_4': -0.2913976311683655, 'epoch': 11.39}
{'loss': 0.0149, 'grad_norm': 6.1449456214904785, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.007058230694383383, 'loss_2': 0.0078582763671875, 'loss_3': -16.108854293823242, 'loss_4': -0.3748423457145691, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 16:05:58,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:05:58,445 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:52<55:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:05,794 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015695761889219284, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01169250626116991, 'eval_loss_2': 0.004003256559371948, 'eval_loss_3': -18.205303192138672, 'eval_loss_4': -0.40510740876197815, 'epoch': 11.4}
{'loss': 0.0084, 'grad_norm': 5.691449165344238, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.008331755176186562, 'loss_2': 0.0001081228256225586, 'loss_3': -16.588062286376953, 'loss_4': -0.2865111827850342, 'epoch': 11.4}
{'loss': 0.0172, 'grad_norm': 8.116816520690918, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.011702331714332104, 'loss_2': 0.00545501708984375, 'loss_3': -16.352596282958984, 'loss_4': 0.3032999634742737, 'epoch': 11.41}
{'loss': 0.021, 'grad_norm': 7.456605911254883, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.018400950357317924, 'loss_2': 0.00264739990234375, 'loss_3': -16.279855728149414, 'loss_4': -0.4945826232433319, 'epoch': 11.41}
{'loss': 0.0203, 'grad_norm': 6.109808921813965, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.011126011610031128, 'loss_2': 0.00913238525390625, 'loss_3': -16.398359298706055, 'loss_4': -0.6827294826507568, 'epoch': 11.42}
{'loss': 0.0135, 'grad_norm': 7.294777870178223, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.012699919752776623, 'loss_2': 0.0008373260498046875, 'loss_3': -16.150188446044922, 'loss_4': -0.5349366068840027, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 16:06:05,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:05,795 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [48:59<55:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:13,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018486110493540764, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011502234265208244, 'eval_loss_2': 0.0069838762283325195, 'eval_loss_3': -18.209381103515625, 'eval_loss_4': -0.6274917721748352, 'epoch': 11.42}
{'loss': 0.0266, 'grad_norm': 9.35783576965332, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.022836793214082718, 'loss_2': 0.003726959228515625, 'loss_3': -16.338232040405273, 'loss_4': -0.29240137338638306, 'epoch': 11.43}
{'loss': 0.0174, 'grad_norm': 6.212622165679932, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.015330232679843903, 'loss_2': 0.0020599365234375, 'loss_3': -16.402523040771484, 'loss_4': -0.5792428255081177, 'epoch': 11.44}
{'loss': 0.0216, 'grad_norm': 6.617457866668701, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.01325845904648304, 'loss_2': 0.0083770751953125, 'loss_3': -16.35899543762207, 'loss_4': -0.6013643145561218, 'epoch': 11.44}
{'loss': 0.0202, 'grad_norm': 10.156623840332031, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.016995055601000786, 'loss_2': 0.0032329559326171875, 'loss_3': -16.34816551208496, 'loss_4': -0.3634943664073944, 'epoch': 11.45}
{'loss': 0.0792, 'grad_norm': 17.739505767822266, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.06840215623378754, 'loss_2': 0.01079559326171875, 'loss_3': -16.327499389648438, 'loss_4': -0.425807923078537, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 16:06:13,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:13,140 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [49:07<55:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:20,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013835948891937733, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.017, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011079510673880577, 'eval_loss_2': 0.0027564391493797302, 'eval_loss_3': -18.242534637451172, 'eval_loss_4': -0.7246189117431641, 'epoch': 11.45}
{'loss': 0.0182, 'grad_norm': 7.5016045570373535, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.013421970419585705, 'loss_2': 0.0047607421875, 'loss_3': -16.304574966430664, 'loss_4': -0.4746246337890625, 'epoch': 11.46}
{'loss': 0.0121, 'grad_norm': 5.478710651397705, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.011429890990257263, 'loss_2': 0.0007076263427734375, 'loss_3': -16.4743709564209, 'loss_4': -0.8371022939682007, 'epoch': 11.47}
{'loss': 0.0282, 'grad_norm': 18.810178756713867, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.02695869468152523, 'loss_2': 0.0012359619140625, 'loss_3': -16.194278717041016, 'loss_4': -1.1234073638916016, 'epoch': 11.47}
{'loss': 0.022, 'grad_norm': 5.769994735717773, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.014743100851774216, 'loss_2': 0.00725555419921875, 'loss_3': -16.43016242980957, 'loss_4': -0.26808130741119385, 'epoch': 11.48}
{'loss': 0.0298, 'grad_norm': 9.825258255004883, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.01597246713936329, 'loss_2': 0.01380157470703125, 'loss_3': -16.35692596435547, 'loss_4': -0.7537811994552612, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 16:06:20,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:20,493 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [49:14<55:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:27,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018588658422231674, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.849, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011730311438441277, 'eval_loss_2': 0.006858348846435547, 'eval_loss_3': -18.237083435058594, 'eval_loss_4': -0.8258206844329834, 'epoch': 11.48}
{'loss': 0.0177, 'grad_norm': 6.472919464111328, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.013878919184207916, 'loss_2': 0.003780364990234375, 'loss_3': -16.23957061767578, 'loss_4': -1.097554087638855, 'epoch': 11.49}
{'loss': 0.0156, 'grad_norm': 5.253349781036377, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.010523317381739616, 'loss_2': 0.0050811767578125, 'loss_3': -16.45996856689453, 'loss_4': -0.6285648345947266, 'epoch': 11.49}
{'loss': 0.0214, 'grad_norm': 6.596435070037842, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.014448966830968857, 'loss_2': 0.00699615478515625, 'loss_3': -16.35131072998047, 'loss_4': -1.1411710977554321, 'epoch': 11.5}
{'loss': 0.0151, 'grad_norm': 7.092294692993164, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.013970034196972847, 'loss_2': 0.0011005401611328125, 'loss_3': -16.10045623779297, 'loss_4': -1.1260154247283936, 'epoch': 11.51}
{'loss': 0.0152, 'grad_norm': 6.037194728851318, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.014734949916601181, 'loss_2': 0.0004241466522216797, 'loss_3': -16.430438995361328, 'loss_4': -0.8887275457382202, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 16:06:27,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:27,845 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:21<54:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:35,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01410743035376072, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010693059302866459, 'eval_loss_2': 0.003414370119571686, 'eval_loss_3': -18.247699737548828, 'eval_loss_4': -0.9614017009735107, 'epoch': 11.51}
{'loss': 0.0153, 'grad_norm': 5.847239971160889, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.010807285085320473, 'loss_2': 0.004474639892578125, 'loss_3': -16.322826385498047, 'loss_4': -0.48390626907348633, 'epoch': 11.52}
{'loss': 0.0175, 'grad_norm': 6.54805326461792, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.01595432683825493, 'loss_2': 0.0014972686767578125, 'loss_3': -16.248794555664062, 'loss_4': -0.9199373722076416, 'epoch': 11.52}
{'loss': 0.0207, 'grad_norm': 6.948834419250488, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.013518257066607475, 'loss_2': 0.0072021484375, 'loss_3': -16.326419830322266, 'loss_4': -1.1784979104995728, 'epoch': 11.53}
{'loss': 0.0157, 'grad_norm': 5.292836666107178, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.010663570836186409, 'loss_2': 0.0049896240234375, 'loss_3': -16.201074600219727, 'loss_4': -1.1385680437088013, 'epoch': 11.53}
{'loss': 0.0188, 'grad_norm': 6.3267436027526855, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.01652647741138935, 'loss_2': 0.002285003662109375, 'loss_3': -16.337629318237305, 'loss_4': -1.02101731300354, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 16:06:35,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:35,185 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:29<54:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:42,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012454063631594181, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.42, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009691783227026463, 'eval_loss_2': 0.0027622804045677185, 'eval_loss_3': -18.253582000732422, 'eval_loss_4': -0.9770357012748718, 'epoch': 11.54}
{'loss': 0.0216, 'grad_norm': 8.168635368347168, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.018777022138237953, 'loss_2': 0.0028285980224609375, 'loss_3': -16.34919548034668, 'loss_4': -0.8028935194015503, 'epoch': 11.55}
{'loss': 0.014, 'grad_norm': 5.909674167633057, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.010772373527288437, 'loss_2': 0.00319671630859375, 'loss_3': -16.508075714111328, 'loss_4': -1.2906707525253296, 'epoch': 11.55}
{'loss': 0.0167, 'grad_norm': 6.733424663543701, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.013089225627481937, 'loss_2': 0.0036067962646484375, 'loss_3': -16.312957763671875, 'loss_4': -0.6239198446273804, 'epoch': 11.56}
{'loss': 0.0169, 'grad_norm': 4.66627311706543, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.010962013155221939, 'loss_2': 0.005908966064453125, 'loss_3': -16.449813842773438, 'loss_4': -1.304254174232483, 'epoch': 11.56}
{'loss': 0.0198, 'grad_norm': 6.260464668273926, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.015332615002989769, 'loss_2': 0.00446319580078125, 'loss_3': -16.184120178222656, 'loss_4': -1.384427547454834, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 16:06:42,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:42,526 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:36<54:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:49,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014218747615814209, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010574732907116413, 'eval_loss_2': 0.0036440156400203705, 'eval_loss_3': -18.24481201171875, 'eval_loss_4': -1.1654285192489624, 'epoch': 11.57}
{'loss': 0.0122, 'grad_norm': 5.740334987640381, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.011452201753854752, 'loss_2': 0.00074005126953125, 'loss_3': -16.45852279663086, 'loss_4': -0.9266625642776489, 'epoch': 11.58}
{'loss': 0.018, 'grad_norm': 6.324553489685059, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.012748110108077526, 'loss_2': 0.00522613525390625, 'loss_3': -16.386695861816406, 'loss_4': -0.33819809556007385, 'epoch': 11.58}
{'loss': 0.0225, 'grad_norm': 8.101101875305176, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.018891556188464165, 'loss_2': 0.003635406494140625, 'loss_3': -16.46004867553711, 'loss_4': -1.185990571975708, 'epoch': 11.59}
{'loss': 0.0183, 'grad_norm': 9.108650207519531, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.018132884055376053, 'loss_2': 0.00011718273162841797, 'loss_3': -16.636219024658203, 'loss_4': -1.6009989976882935, 'epoch': 11.59}
{'loss': 0.013, 'grad_norm': 4.573870658874512, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.00994902290403843, 'loss_2': 0.0030975341796875, 'loss_3': -16.371458053588867, 'loss_4': -1.496347427368164, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 16:06:49,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:49,865 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:43<54:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:06:57,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020285628736019135, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011081240139901638, 'eval_loss_2': 0.009204387664794922, 'eval_loss_3': -18.227224349975586, 'eval_loss_4': -1.2478712797164917, 'epoch': 11.6}
{'loss': 0.0219, 'grad_norm': 6.572145938873291, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.013699708506464958, 'loss_2': 0.008209228515625, 'loss_3': -16.112140655517578, 'loss_4': -1.3383458852767944, 'epoch': 11.6}
{'loss': 0.0213, 'grad_norm': 5.956732273101807, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.00959816388785839, 'loss_2': 0.01166534423828125, 'loss_3': -16.3929443359375, 'loss_4': -1.8652664422988892, 'epoch': 11.61}
{'loss': 0.0347, 'grad_norm': 6.410655975341797, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.02217225730419159, 'loss_2': 0.01256561279296875, 'loss_3': -16.46078109741211, 'loss_4': -1.206642985343933, 'epoch': 11.62}
{'loss': 0.023, 'grad_norm': 7.852088928222656, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.01535160280764103, 'loss_2': 0.00762176513671875, 'loss_3': -16.31109619140625, 'loss_4': -1.3003196716308594, 'epoch': 11.62}
{'loss': 0.0162, 'grad_norm': 6.31977653503418, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.007849284447729588, 'loss_2': 0.00839996337890625, 'loss_3': -16.289216995239258, 'loss_4': -1.1209521293640137, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 16:06:57,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:06:57,205 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:51<55:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:07:04,747 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01365126296877861, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.643, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010672102682292461, 'eval_loss_2': 0.0029791593551635742, 'eval_loss_3': -18.21573257446289, 'eval_loss_4': -1.1361016035079956, 'epoch': 11.63}
{'loss': 0.0201, 'grad_norm': 8.129858016967773, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.019619865342974663, 'loss_2': 0.0004858970642089844, 'loss_3': -16.475433349609375, 'loss_4': -1.2910910844802856, 'epoch': 11.63}
{'loss': 0.017, 'grad_norm': 8.534144401550293, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.015957029536366463, 'loss_2': 0.0010480880737304688, 'loss_3': -16.178726196289062, 'loss_4': -0.9273933172225952, 'epoch': 11.64}
{'loss': 0.0191, 'grad_norm': 8.005749702453613, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.015114708803594112, 'loss_2': 0.0039520263671875, 'loss_3': -16.246044158935547, 'loss_4': -0.6826823353767395, 'epoch': 11.65}
{'loss': 0.0351, 'grad_norm': 8.014395713806152, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.02696280926465988, 'loss_2': 0.008148193359375, 'loss_3': -16.233230590820312, 'loss_4': -1.1287579536437988, 'epoch': 11.65}
{'loss': 0.0197, 'grad_norm': 4.97483491897583, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.008821344934403896, 'loss_2': 0.01088714599609375, 'loss_3': -16.36530113220215, 'loss_4': -0.9989656209945679, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 16:07:04,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:04,748 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [49:58<54:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:12,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015368402004241943, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.853, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010197930037975311, 'eval_loss_2': 0.005170471966266632, 'eval_loss_3': -18.208154678344727, 'eval_loss_4': -0.927467942237854, 'epoch': 11.66}
{'loss': 0.0129, 'grad_norm': 5.270056247711182, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.008992933668196201, 'loss_2': 0.003955841064453125, 'loss_3': -16.39159393310547, 'loss_4': -0.9006131887435913, 'epoch': 11.66}
{'loss': 0.0244, 'grad_norm': 9.522449493408203, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.02225266769528389, 'loss_2': 0.0021305084228515625, 'loss_3': -16.33379364013672, 'loss_4': -0.5790107250213623, 'epoch': 11.67}
{'loss': 0.0176, 'grad_norm': 5.059382915496826, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.01079681608825922, 'loss_2': 0.00684356689453125, 'loss_3': -16.314476013183594, 'loss_4': -1.1171983480453491, 'epoch': 11.67}
{'loss': 0.0182, 'grad_norm': 6.3512983322143555, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.015058362856507301, 'loss_2': 0.0031280517578125, 'loss_3': -16.15599822998047, 'loss_4': -0.6236259937286377, 'epoch': 11.68}
{'loss': 0.0191, 'grad_norm': 5.760200023651123, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.010293327271938324, 'loss_2': 0.0088043212890625, 'loss_3': -16.458139419555664, 'loss_4': -0.7926045656204224, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 16:07:12,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:12,096 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [50:06<54:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:19,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013128782622516155, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.952, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008984710089862347, 'eval_loss_2': 0.004144072532653809, 'eval_loss_3': -18.191856384277344, 'eval_loss_4': -0.675539493560791, 'epoch': 11.69}
{'loss': 0.024, 'grad_norm': 7.75158166885376, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.020881688222289085, 'loss_2': 0.0030727386474609375, 'loss_3': -16.21492576599121, 'loss_4': -0.3691408932209015, 'epoch': 11.69}
{'loss': 0.0315, 'grad_norm': 19.811201095581055, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.02560625970363617, 'loss_2': 0.0058746337890625, 'loss_3': -16.232091903686523, 'loss_4': -0.11575999110937119, 'epoch': 11.7}
{'loss': 0.0344, 'grad_norm': 8.490226745605469, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.01350487396121025, 'loss_2': 0.0208740234375, 'loss_3': -16.30512809753418, 'loss_4': -0.5633196234703064, 'epoch': 11.7}
{'loss': 0.0127, 'grad_norm': 4.819819450378418, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.005422545131295919, 'loss_2': 0.007293701171875, 'loss_3': -16.206958770751953, 'loss_4': -0.689378023147583, 'epoch': 11.71}
{'loss': 0.0178, 'grad_norm': 5.384459018707275, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.010007379576563835, 'loss_2': 0.0078125, 'loss_3': -16.402050018310547, 'loss_4': -0.2676456868648529, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 16:07:19,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:19,445 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [50:13<54:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:26,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019376240670681, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.268, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010170900262892246, 'eval_loss_2': 0.009205341339111328, 'eval_loss_3': -18.173383712768555, 'eval_loss_4': -0.3536662459373474, 'epoch': 11.72}
{'loss': 0.0132, 'grad_norm': 6.703873157501221, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.009867691434919834, 'loss_2': 0.00330352783203125, 'loss_3': -16.175621032714844, 'loss_4': 0.054868824779987335, 'epoch': 11.72}
{'loss': 0.0155, 'grad_norm': 6.333417892456055, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.014001840725541115, 'loss_2': 0.0015153884887695312, 'loss_3': -16.329755783081055, 'loss_4': -0.19966742396354675, 'epoch': 11.73}
{'loss': 0.0504, 'grad_norm': 14.477155685424805, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.042232755571603775, 'loss_2': 0.0081329345703125, 'loss_3': -16.34775161743164, 'loss_4': -0.3469010591506958, 'epoch': 11.73}
{'loss': 0.0216, 'grad_norm': 5.158405303955078, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.011897201649844646, 'loss_2': 0.009674072265625, 'loss_3': -16.273666381835938, 'loss_4': -0.09310086071491241, 'epoch': 11.74}
{'loss': 0.0178, 'grad_norm': 4.999248504638672, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.008915556594729424, 'loss_2': 0.00888824462890625, 'loss_3': -16.23014259338379, 'loss_4': -0.15913523733615875, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 16:07:26,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:26,792 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:20<54:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:34,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014816378243267536, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011263920925557613, 'eval_loss_2': 0.003552459180355072, 'eval_loss_3': -18.149412155151367, 'eval_loss_4': 0.005954260937869549, 'epoch': 11.74}
{'loss': 0.0068, 'grad_norm': 5.131271839141846, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.006691512186080217, 'loss_2': 0.00013315677642822266, 'loss_3': -16.29893684387207, 'loss_4': -0.16755898296833038, 'epoch': 11.75}
{'loss': 0.0129, 'grad_norm': 6.104654788970947, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.009753989987075329, 'loss_2': 0.00312042236328125, 'loss_3': -16.22472381591797, 'loss_4': 0.06677217781543732, 'epoch': 11.76}
{'loss': 0.009, 'grad_norm': 6.028227806091309, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.00895426981151104, 'loss_2': 8.64267349243164e-05, 'loss_3': -16.11960792541504, 'loss_4': -0.3125656247138977, 'epoch': 11.76}
{'loss': 0.016, 'grad_norm': 5.825774669647217, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.010974508710205555, 'loss_2': 0.0050048828125, 'loss_3': -16.23019027709961, 'loss_4': -0.3336000442504883, 'epoch': 11.77}
{'loss': 0.0117, 'grad_norm': 6.700098514556885, 'learning_rate': 1.825e-05, 'loss_1': 0.009890940971672535, 'loss_2': 0.0017633438110351562, 'loss_3': -16.23065948486328, 'loss_4': -0.41368550062179565, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 16:07:34,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:34,139 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:28<54:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:41,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01662936434149742, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.735, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013125408440828323, 'eval_loss_2': 0.003503955900669098, 'eval_loss_3': -18.111360549926758, 'eval_loss_4': 0.1250564008951187, 'epoch': 11.77}
{'loss': 0.0061, 'grad_norm': 4.635297775268555, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.006064567714929581, 'loss_2': 2.5093555450439453e-05, 'loss_3': -16.27336311340332, 'loss_4': 0.3040837049484253, 'epoch': 11.78}
{'loss': 0.0154, 'grad_norm': 5.075923442840576, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.009267915971577168, 'loss_2': 0.00616455078125, 'loss_3': -16.410076141357422, 'loss_4': -0.13903267681598663, 'epoch': 11.78}
{'loss': 0.0117, 'grad_norm': 5.508890628814697, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.00737428804859519, 'loss_2': 0.00437164306640625, 'loss_3': -16.195152282714844, 'loss_4': -0.43645179271698, 'epoch': 11.79}
{'loss': 0.0244, 'grad_norm': 8.146202087402344, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.015299669466912746, 'loss_2': 0.00909423828125, 'loss_3': -16.135746002197266, 'loss_4': 0.04111843556165695, 'epoch': 11.8}
{'loss': 0.0181, 'grad_norm': 4.637468338012695, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.005585263483226299, 'loss_2': 0.01251220703125, 'loss_3': -16.26776885986328, 'loss_4': 0.27152106165885925, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 16:07:41,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:41,501 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:35<54:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:48,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02106267772614956, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.025, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.014507956802845001, 'eval_loss_2': 0.006554722785949707, 'eval_loss_3': -18.091766357421875, 'eval_loss_4': -0.09499356895685196, 'epoch': 11.8}
{'loss': 0.0167, 'grad_norm': 5.216192245483398, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.005869500804692507, 'loss_2': 0.01087188720703125, 'loss_3': -16.14120101928711, 'loss_4': -0.21996638178825378, 'epoch': 11.81}
{'loss': 0.0129, 'grad_norm': 5.118804931640625, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.00787518359720707, 'loss_2': 0.0050048828125, 'loss_3': -16.31966209411621, 'loss_4': -0.07077125459909439, 'epoch': 11.81}
{'loss': 0.0628, 'grad_norm': 16.30289077758789, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.06083984300494194, 'loss_2': 0.001926422119140625, 'loss_3': -16.338157653808594, 'loss_4': -0.14004549384117126, 'epoch': 11.82}
{'loss': 0.0139, 'grad_norm': 7.638050556182861, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.012127392925322056, 'loss_2': 0.0017604827880859375, 'loss_3': -16.146041870117188, 'loss_4': -0.013375889509916306, 'epoch': 11.83}
{'loss': 0.0171, 'grad_norm': 6.764723777770996, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.006974685005843639, 'loss_2': 0.010162353515625, 'loss_3': -16.241649627685547, 'loss_4': -0.6903797388076782, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 16:07:48,856 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:48,856 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:42<53:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:07:56,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01783592253923416, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.16, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01453641802072525, 'eval_loss_2': 0.003299504518508911, 'eval_loss_3': -18.114151000976562, 'eval_loss_4': -0.251489520072937, 'epoch': 11.83}
{'loss': 0.0229, 'grad_norm': 6.914509296417236, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.02032678760588169, 'loss_2': 0.0025730133056640625, 'loss_3': -16.227855682373047, 'loss_4': 0.2170931100845337, 'epoch': 11.84}
{'loss': 0.0161, 'grad_norm': 6.814250946044922, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.01427474059164524, 'loss_2': 0.001827239990234375, 'loss_3': -16.102718353271484, 'loss_4': -0.3517705500125885, 'epoch': 11.84}
{'loss': 0.0067, 'grad_norm': 5.213369846343994, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.005824442021548748, 'loss_2': 0.0008306503295898438, 'loss_3': -16.328250885009766, 'loss_4': -0.5185742974281311, 'epoch': 11.85}
{'loss': 0.0453, 'grad_norm': 17.518888473510742, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.045130327343940735, 'loss_2': 0.00012922286987304688, 'loss_3': -16.318063735961914, 'loss_4': 0.30122053623199463, 'epoch': 11.85}
{'loss': 0.0193, 'grad_norm': 9.56821346282959, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.014653407037258148, 'loss_2': 0.0046234130859375, 'loss_3': -16.26531982421875, 'loss_4': -0.30010610818862915, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 16:07:56,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:07:56,200 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:50<53:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:03,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017312360927462578, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01176525466144085, 'eval_loss_2': 0.0055471062660217285, 'eval_loss_3': -18.125228881835938, 'eval_loss_4': -0.48273101449012756, 'epoch': 11.86}
{'loss': 0.0062, 'grad_norm': 4.889073848724365, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.004450440406799316, 'loss_2': 0.001743316650390625, 'loss_3': -16.353586196899414, 'loss_4': -0.8595714569091797, 'epoch': 11.87}
{'loss': 0.0106, 'grad_norm': 4.640566825866699, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.005827849730849266, 'loss_2': 0.004730224609375, 'loss_3': -16.297183990478516, 'loss_4': -0.4937606155872345, 'epoch': 11.87}
{'loss': 0.016, 'grad_norm': 8.617323875427246, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.01336073037236929, 'loss_2': 0.0026264190673828125, 'loss_3': -16.253063201904297, 'loss_4': -0.4678841233253479, 'epoch': 11.88}
{'loss': 0.0193, 'grad_norm': 6.558935642242432, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.009171292185783386, 'loss_2': 0.0101470947265625, 'loss_3': -16.16736602783203, 'loss_4': -0.6069273352622986, 'epoch': 11.88}
{'loss': 0.011, 'grad_norm': 6.071451187133789, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.00965914223343134, 'loss_2': 0.00136566162109375, 'loss_3': -16.255701065063477, 'loss_4': -0.6068047285079956, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 16:08:03,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:03,541 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [50:57<53:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:10,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018203312531113625, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013092601671814919, 'eval_loss_2': 0.005110710859298706, 'eval_loss_3': -18.11813735961914, 'eval_loss_4': -0.6444718241691589, 'epoch': 11.89}
{'loss': 0.0144, 'grad_norm': 5.669063091278076, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.010466113686561584, 'loss_2': 0.00391387939453125, 'loss_3': -16.218875885009766, 'loss_4': -1.138006329536438, 'epoch': 11.9}
{'loss': 0.0134, 'grad_norm': 5.264518737792969, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.010909422300755978, 'loss_2': 0.0024471282958984375, 'loss_3': -16.265342712402344, 'loss_4': -0.8450092673301697, 'epoch': 11.9}
{'loss': 0.0112, 'grad_norm': 7.001260280609131, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.010800743475556374, 'loss_2': 0.00037288665771484375, 'loss_3': -16.28125762939453, 'loss_4': -1.1120307445526123, 'epoch': 11.91}
{'loss': 0.0236, 'grad_norm': 9.425947189331055, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.021220501512289047, 'loss_2': 0.002361297607421875, 'loss_3': -16.078516006469727, 'loss_4': -0.27643147110939026, 'epoch': 11.91}
{'loss': 0.0315, 'grad_norm': 11.00677490234375, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.025548946112394333, 'loss_2': 0.005992889404296875, 'loss_3': -16.394031524658203, 'loss_4': -0.6741923093795776, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 16:08:10,887 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:10,887 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [51:04<53:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:18,232 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016531318426132202, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.437, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011330785229802132, 'eval_loss_2': 0.00520053505897522, 'eval_loss_3': -18.12811279296875, 'eval_loss_4': -0.7035608291625977, 'epoch': 11.92}
{'loss': 0.0157, 'grad_norm': 5.190848350524902, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.00759462034329772, 'loss_2': 0.008148193359375, 'loss_3': -16.29386329650879, 'loss_4': -0.5006762146949768, 'epoch': 11.92}
{'loss': 0.0264, 'grad_norm': 8.88354778289795, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.014012294821441174, 'loss_2': 0.012359619140625, 'loss_3': -16.313589096069336, 'loss_4': -0.7891307473182678, 'epoch': 11.93}
{'loss': 0.0101, 'grad_norm': 4.691953182220459, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.005247536115348339, 'loss_2': 0.004871368408203125, 'loss_3': -16.3228702545166, 'loss_4': -1.164631724357605, 'epoch': 11.94}
{'loss': 0.0207, 'grad_norm': 11.349513053894043, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.014628558419644833, 'loss_2': 0.006046295166015625, 'loss_3': -16.3544979095459, 'loss_4': -0.38223302364349365, 'epoch': 11.94}
{'loss': 0.014, 'grad_norm': 4.568325042724609, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.00574129493907094, 'loss_2': 0.0082855224609375, 'loss_3': -16.375411987304688, 'loss_4': -0.8668726682662964, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 16:08:18,232 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:18,232 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [51:12<53:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:25,583 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017498649656772614, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.328, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013718217611312866, 'eval_loss_2': 0.0037804320454597473, 'eval_loss_3': -18.110071182250977, 'eval_loss_4': -0.7811148762702942, 'epoch': 11.95}
{'loss': 0.0126, 'grad_norm': 5.191262245178223, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.008765654638409615, 'loss_2': 0.0037860870361328125, 'loss_3': -16.308544158935547, 'loss_4': -0.8930649757385254, 'epoch': 11.95}
{'loss': 0.0082, 'grad_norm': 5.043595314025879, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.006500629708170891, 'loss_2': 0.0016641616821289062, 'loss_3': -16.330093383789062, 'loss_4': -0.42800939083099365, 'epoch': 11.96}
{'loss': 0.0062, 'grad_norm': 5.105197429656982, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.005579973571002483, 'loss_2': 0.0006103515625, 'loss_3': -16.38104820251465, 'loss_4': -0.8812179565429688, 'epoch': 11.97}
{'loss': 0.0136, 'grad_norm': 5.003875732421875, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.006621039938181639, 'loss_2': 0.006988525390625, 'loss_3': -16.263320922851562, 'loss_4': -1.382960557937622, 'epoch': 11.97}
{'loss': 0.0116, 'grad_norm': 5.185759544372559, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.008834251202642918, 'loss_2': 0.002780914306640625, 'loss_3': -16.305339813232422, 'loss_4': -1.0893125534057617, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 16:08:25,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:25,583 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:19<50:23,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:08:32,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022977691143751144, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.872, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01736019179224968, 'eval_loss_2': 0.005617499351501465, 'eval_loss_3': -18.085437774658203, 'eval_loss_4': -0.8709232807159424, 'epoch': 11.98}
{'loss': 0.0363, 'grad_norm': 20.137954711914062, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.03298499807715416, 'loss_2': 0.0033111572265625, 'loss_3': -16.341819763183594, 'loss_4': -0.28709688782691956, 'epoch': 11.98}
{'loss': 0.0331, 'grad_norm': 14.819620132446289, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.021319447085261345, 'loss_2': 0.011749267578125, 'loss_3': -16.393482208251953, 'loss_4': -0.8655221462249756, 'epoch': 11.99}
{'loss': 0.0255, 'grad_norm': 13.341231346130371, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.019600797444581985, 'loss_2': 0.00594329833984375, 'loss_3': -16.231369018554688, 'loss_4': -0.8185499310493469, 'epoch': 11.99}
{'loss': 0.0265, 'grad_norm': 16.874685287475586, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.021496016532182693, 'loss_2': 0.0049591064453125, 'loss_3': -16.389022827148438, 'loss_4': -0.7635331153869629, 'epoch': 12.0}
{'loss': 0.1167, 'grad_norm': 13.963874816894531, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.11032943427562714, 'loss_2': 0.0063323974609375, 'loss_3': -16.26797866821289, 'loss_4': -0.7485396265983582, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 16:08:32,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:32,622 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:26<52:52,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:08:39,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022946037352085114, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.015936054289340973, 'eval_loss_2': 0.007009983062744141, 'eval_loss_3': -18.083419799804688, 'eval_loss_4': -0.9665014147758484, 'epoch': 12.01}
{'loss': 0.0073, 'grad_norm': 5.088708877563477, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.006311841309070587, 'loss_2': 0.0009927749633789062, 'loss_3': -16.297550201416016, 'loss_4': -0.8285670876502991, 'epoch': 12.01}
{'loss': 0.0179, 'grad_norm': 7.927010536193848, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.01560620404779911, 'loss_2': 0.0023021697998046875, 'loss_3': -16.175968170166016, 'loss_4': -0.8588742613792419, 'epoch': 12.02}
{'loss': 0.0073, 'grad_norm': 4.9084014892578125, 'learning_rate': 1.8e-05, 'loss_1': 0.006931225769221783, 'loss_2': 0.0003895759582519531, 'loss_3': -16.328712463378906, 'loss_4': -0.7794066667556763, 'epoch': 12.02}
{'loss': 0.0159, 'grad_norm': 7.085618019104004, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.014093204401433468, 'loss_2': 0.0017938613891601562, 'loss_3': -16.399639129638672, 'loss_4': -1.300096035003662, 'epoch': 12.03}
{'loss': 0.0125, 'grad_norm': 5.276669502258301, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.00783784780651331, 'loss_2': 0.00469207763671875, 'loss_3': -16.304149627685547, 'loss_4': -1.1847400665283203, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 16:08:39,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:39,964 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:33<53:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:47,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015885261818766594, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013125712051987648, 'eval_loss_2': 0.002759549766778946, 'eval_loss_3': -18.12067985534668, 'eval_loss_4': -1.189860463142395, 'epoch': 12.03}
{'loss': 0.0141, 'grad_norm': 7.566406726837158, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.01204102672636509, 'loss_2': 0.0020599365234375, 'loss_3': -16.418006896972656, 'loss_4': -1.2485419511795044, 'epoch': 12.04}
{'loss': 0.0131, 'grad_norm': 4.909160614013672, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.0070238676853477955, 'loss_2': 0.00611114501953125, 'loss_3': -16.2135009765625, 'loss_4': -1.0083985328674316, 'epoch': 12.05}
{'loss': 0.0188, 'grad_norm': 7.2203264236450195, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.016756193712353706, 'loss_2': 0.00202178955078125, 'loss_3': -16.098102569580078, 'loss_4': -0.7095556259155273, 'epoch': 12.05}
{'loss': 0.0139, 'grad_norm': 6.138185501098633, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.011144052259624004, 'loss_2': 0.0027828216552734375, 'loss_3': -16.458742141723633, 'loss_4': -1.1328176259994507, 'epoch': 12.06}
{'loss': 0.011, 'grad_norm': 4.768135070800781, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.006495845504105091, 'loss_2': 0.004486083984375, 'loss_3': -16.470773696899414, 'loss_4': -0.9884983897209167, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 16:08:47,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:47,310 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:41<53:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:08:54,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015230312012135983, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.507, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009513035416603088, 'eval_loss_2': 0.005717277526855469, 'eval_loss_3': -18.16164779663086, 'eval_loss_4': -1.2253894805908203, 'epoch': 12.06}
{'loss': 0.0276, 'grad_norm': 9.064139366149902, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.022228697314858437, 'loss_2': 0.00539398193359375, 'loss_3': -16.216487884521484, 'loss_4': -1.471235752105713, 'epoch': 12.07}
{'loss': 0.0171, 'grad_norm': 5.339196681976318, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.010859676636755466, 'loss_2': 0.00626373291015625, 'loss_3': -16.294902801513672, 'loss_4': -1.4627350568771362, 'epoch': 12.08}
{'loss': 0.0141, 'grad_norm': 6.168708324432373, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.009234375320374966, 'loss_2': 0.00482177734375, 'loss_3': -16.232982635498047, 'loss_4': -0.9768535494804382, 'epoch': 12.08}
{'loss': 0.0384, 'grad_norm': 11.703191757202148, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.03013690561056137, 'loss_2': 0.00827789306640625, 'loss_3': -16.348033905029297, 'loss_4': -0.4080304205417633, 'epoch': 12.09}
{'loss': 0.0228, 'grad_norm': 7.091168403625488, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.012387311086058617, 'loss_2': 0.01044464111328125, 'loss_3': -16.36064338684082, 'loss_4': -1.130065679550171, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 16:08:54,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:08:54,650 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:48<53:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:01,989 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014810536056756973, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008989052847027779, 'eval_loss_2': 0.005821481347084045, 'eval_loss_3': -18.198760986328125, 'eval_loss_4': -1.3057113885879517, 'epoch': 12.09}
{'loss': 0.0173, 'grad_norm': 6.730693817138672, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.014052032493054867, 'loss_2': 0.003253936767578125, 'loss_3': -16.31096839904785, 'loss_4': -1.6566760540008545, 'epoch': 12.1}
{'loss': 0.0153, 'grad_norm': 5.1535115242004395, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.006969733163714409, 'loss_2': 0.0083160400390625, 'loss_3': -16.416706085205078, 'loss_4': -1.107722520828247, 'epoch': 12.1}
{'loss': 0.0089, 'grad_norm': 5.111141204833984, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.007006084080785513, 'loss_2': 0.001903533935546875, 'loss_3': -16.2525577545166, 'loss_4': -1.3904213905334473, 'epoch': 12.11}
{'loss': 0.015, 'grad_norm': 6.230404853820801, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.008197802118957043, 'loss_2': 0.006763458251953125, 'loss_3': -16.343294143676758, 'loss_4': -1.1395926475524902, 'epoch': 12.12}
{'loss': 0.0169, 'grad_norm': 8.951630592346191, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.016867928206920624, 'loss_2': 4.83393669128418e-05, 'loss_3': -16.193849563598633, 'loss_4': -0.8544069528579712, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 16:09:01,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:01,990 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [51:55<53:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:09,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01226146798580885, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.744, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008441704325377941, 'eval_loss_2': 0.003819763660430908, 'eval_loss_3': -18.224058151245117, 'eval_loss_4': -1.2461868524551392, 'epoch': 12.12}
{'loss': 0.0198, 'grad_norm': 7.561330318450928, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.018272340297698975, 'loss_2': 0.001560211181640625, 'loss_3': -16.480472564697266, 'loss_4': -1.467705249786377, 'epoch': 12.13}
{'loss': 0.0212, 'grad_norm': 12.641972541809082, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.018589425832033157, 'loss_2': 0.002643585205078125, 'loss_3': -16.327585220336914, 'loss_4': -1.3750433921813965, 'epoch': 12.13}
{'loss': 0.0129, 'grad_norm': 4.632657051086426, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.0037396536208689213, 'loss_2': 0.00913238525390625, 'loss_3': -16.321269989013672, 'loss_4': -1.2943867444992065, 'epoch': 12.14}
{'loss': 0.0155, 'grad_norm': 6.364948749542236, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.011005998589098454, 'loss_2': 0.004486083984375, 'loss_3': -16.245359420776367, 'loss_4': -0.8458187580108643, 'epoch': 12.15}
{'loss': 0.0234, 'grad_norm': 7.134237766265869, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.013956832699477673, 'loss_2': 0.0094757080078125, 'loss_3': -16.455690383911133, 'loss_4': -0.8442104458808899, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 16:09:09,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:09,344 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [52:03<53:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:16,689 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015334640629589558, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008212600834667683, 'eval_loss_2': 0.007122039794921875, 'eval_loss_3': -18.217771530151367, 'eval_loss_4': -0.9197982549667358, 'epoch': 12.15}
{'loss': 0.0391, 'grad_norm': 10.061634063720703, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.02954540029168129, 'loss_2': 0.0095367431640625, 'loss_3': -16.30668830871582, 'loss_4': -0.9537572264671326, 'epoch': 12.16}
{'loss': 0.011, 'grad_norm': 5.035311222076416, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.00871548242866993, 'loss_2': 0.002262115478515625, 'loss_3': -16.214420318603516, 'loss_4': -1.097848892211914, 'epoch': 12.16}
{'loss': 0.0363, 'grad_norm': 11.844069480895996, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.029232533648610115, 'loss_2': 0.0070343017578125, 'loss_3': -16.230222702026367, 'loss_4': -0.7461177110671997, 'epoch': 12.17}
{'loss': 0.0186, 'grad_norm': 5.379139423370361, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.014029478654265404, 'loss_2': 0.00453948974609375, 'loss_3': -16.322216033935547, 'loss_4': -0.3607049286365509, 'epoch': 12.17}
{'loss': 0.0298, 'grad_norm': 10.403071403503418, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.021028675138950348, 'loss_2': 0.00875091552734375, 'loss_3': -16.29120635986328, 'loss_4': -0.6189111471176147, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 16:09:16,689 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:16,689 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [52:07<53:01,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 16:09:20,495 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2095
[INFO|configuration_utils.py:420] 2025-01-21 16:09:20,497 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2095/config.json                                                                            
{'eval_loss': 0.010706795379519463, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008279039524495602, 'eval_loss_2': 0.0024277567863464355, 'eval_loss_3': -18.200536727905273, 'eval_loss_4': -0.7820035219192505, 'epoch': 12.18}
[INFO|modeling_utils.py:2988] 2025-01-21 16:09:20,989 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2095/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:09:20,990 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2095/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:09:20,991 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2095/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:09:21,958 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-1145] due to args.save_total_limit
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [52:12<58:33,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:09:25,585 >>
{'loss': 0.017, 'grad_norm': 5.941558837890625, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.011928525753319263, 'loss_2': 0.0051116943359375, 'loss_3': -16.424705505371094, 'loss_4': -0.3876258432865143, 'epoch': 12.19}
{'loss': 0.0145, 'grad_norm': 6.323836803436279, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.014376301318407059, 'loss_2': 0.00017070770263671875, 'loss_3': -16.239418029785156, 'loss_4': -0.728737473487854, 'epoch': 12.19}
{'loss': 0.0147, 'grad_norm': 6.072902679443359, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.012103492394089699, 'loss_2': 0.0025806427001953125, 'loss_3': -16.134620666503906, 'loss_4': -0.7040197849273682, 'epoch': 12.2}
{'loss': 0.0265, 'grad_norm': 11.165056228637695, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.023990187793970108, 'loss_2': 0.0025348663330078125, 'loss_3': -16.124942779541016, 'loss_4': -0.42299503087997437, 'epoch': 12.2}
{'loss': 0.0143, 'grad_norm': 6.70315408706665, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.011434938758611679, 'loss_2': 0.0028209686279296875, 'loss_3': -16.047008514404297, 'loss_4': -0.7927008867263794, 'epoch': 12.21}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:09:25,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:25,585 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:19<53:42,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:09:32,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015081226825714111, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.81, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.008922219276428223, 'eval_loss_2': 0.006159007549285889, 'eval_loss_3': -18.19388771057129, 'eval_loss_4': -0.7460281848907471, 'epoch': 12.21}
{'loss': 0.0123, 'grad_norm': 5.757559299468994, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.009409219957888126, 'loss_2': 0.00290679931640625, 'loss_3': -16.15927505493164, 'loss_4': -0.6059682965278625, 'epoch': 12.22}
{'loss': 0.0369, 'grad_norm': 9.846345901489258, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.02521049976348877, 'loss_2': 0.01168060302734375, 'loss_3': -16.392648696899414, 'loss_4': -0.5156117677688599, 'epoch': 12.22}
{'loss': 0.0161, 'grad_norm': 5.117977142333984, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.006951316259801388, 'loss_2': 0.00917816162109375, 'loss_3': -16.31887435913086, 'loss_4': -0.6894333362579346, 'epoch': 12.23}
{'loss': 0.0249, 'grad_norm': 12.288395881652832, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.021587645635008812, 'loss_2': 0.00330352783203125, 'loss_3': -16.149982452392578, 'loss_4': -1.0961179733276367, 'epoch': 12.23}
{'loss': 0.0144, 'grad_norm': 8.871508598327637, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.01015017181634903, 'loss_2': 0.00429534912109375, 'loss_3': -16.381603240966797, 'loss_4': -0.3013764023780823, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 16:09:32,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:32,917 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:26<52:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:40,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011684316210448742, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.791, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008395316079258919, 'eval_loss_2': 0.0032889991998672485, 'eval_loss_3': -18.196178436279297, 'eval_loss_4': -0.8455647230148315, 'epoch': 12.24}
{'loss': 0.0133, 'grad_norm': 5.42396879196167, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.007077603135257959, 'loss_2': 0.00618743896484375, 'loss_3': -16.163095474243164, 'loss_4': -0.4122377038002014, 'epoch': 12.24}
{'loss': 0.0075, 'grad_norm': 5.586549758911133, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.007157032378017902, 'loss_2': 0.00033283233642578125, 'loss_3': -16.257808685302734, 'loss_4': -0.6218100786209106, 'epoch': 12.25}
{'loss': 0.0226, 'grad_norm': 6.83656644821167, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.014921654015779495, 'loss_2': 0.007686614990234375, 'loss_3': -16.199678421020508, 'loss_4': -0.8003251552581787, 'epoch': 12.26}
{'loss': 0.0219, 'grad_norm': 7.243995666503906, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.017508449032902718, 'loss_2': 0.00443267822265625, 'loss_3': -16.219139099121094, 'loss_4': -0.8598878979682922, 'epoch': 12.26}
{'loss': 0.0164, 'grad_norm': 5.608180999755859, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.01074058748781681, 'loss_2': 0.00566864013671875, 'loss_3': -16.139225006103516, 'loss_4': -1.2624046802520752, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 16:09:40,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:40,250 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:34<52:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:47,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012221967801451683, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.495, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008724724873900414, 'eval_loss_2': 0.0034972429275512695, 'eval_loss_3': -18.15012550354004, 'eval_loss_4': -0.9726488590240479, 'epoch': 12.27}
{'loss': 0.0053, 'grad_norm': 4.572013854980469, 'learning_rate': 1.775e-05, 'loss_1': 0.0039365836419165134, 'loss_2': 0.0013704299926757812, 'loss_3': -16.34080696105957, 'loss_4': -0.994498610496521, 'epoch': 12.27}
{'loss': 0.02, 'grad_norm': 5.265164375305176, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.009740722365677357, 'loss_2': 0.01025390625, 'loss_3': -16.450180053710938, 'loss_4': -0.951923668384552, 'epoch': 12.28}
{'loss': 0.0514, 'grad_norm': 17.131074905395508, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.04449694976210594, 'loss_2': 0.00685882568359375, 'loss_3': -16.00078582763672, 'loss_4': -0.6668281555175781, 'epoch': 12.28}
{'loss': 0.0114, 'grad_norm': 5.864551544189453, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.008605954237282276, 'loss_2': 0.0028018951416015625, 'loss_3': -16.320343017578125, 'loss_4': -1.0847716331481934, 'epoch': 12.29}
{'loss': 0.0137, 'grad_norm': 5.498474597930908, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.0096715884283185, 'loss_2': 0.0039825439453125, 'loss_3': -16.409862518310547, 'loss_4': -0.8548974394798279, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 16:09:47,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:47,588 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:41<52:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:09:54,930 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013355442322790623, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008470514789223671, 'eval_loss_2': 0.004884928464889526, 'eval_loss_3': -18.152606964111328, 'eval_loss_4': -0.6674187779426575, 'epoch': 12.3}
{'loss': 0.0108, 'grad_norm': 5.432796955108643, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.007172212935984135, 'loss_2': 0.003620147705078125, 'loss_3': -16.391279220581055, 'loss_4': -0.6324674487113953, 'epoch': 12.3}
{'loss': 0.0221, 'grad_norm': 10.438851356506348, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.021611450240015984, 'loss_2': 0.0005064010620117188, 'loss_3': -16.363555908203125, 'loss_4': -0.408113569021225, 'epoch': 12.31}
{'loss': 0.0121, 'grad_norm': 9.094320297241211, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.011640232056379318, 'loss_2': 0.0004601478576660156, 'loss_3': -16.246322631835938, 'loss_4': -0.6439740657806396, 'epoch': 12.31}
{'loss': 0.0249, 'grad_norm': 10.099979400634766, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.02103862725198269, 'loss_2': 0.003910064697265625, 'loss_3': -16.276260375976562, 'loss_4': -0.6676492691040039, 'epoch': 12.32}
{'loss': 0.0346, 'grad_norm': 6.69705057144165, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.023929022252559662, 'loss_2': 0.01068115234375, 'loss_3': -16.305118560791016, 'loss_4': -0.09316354990005493, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 16:09:54,930 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:09:54,930 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:48<52:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:02,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012258605100214481, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.716, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009106607176363468, 'eval_loss_2': 0.003151997923851013, 'eval_loss_3': -18.18230628967285, 'eval_loss_4': -0.2943304777145386, 'epoch': 12.33}
{'loss': 0.0243, 'grad_norm': 12.555680274963379, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.013998745009303093, 'loss_2': 0.0102996826171875, 'loss_3': -16.2047119140625, 'loss_4': -0.09752781689167023, 'epoch': 12.33}
{'loss': 0.0158, 'grad_norm': 6.412703514099121, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.00946790724992752, 'loss_2': 0.0063629150390625, 'loss_3': -16.342872619628906, 'loss_4': 0.20875217020511627, 'epoch': 12.34}
{'loss': 0.0219, 'grad_norm': 10.441118240356445, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.02027769200503826, 'loss_2': 0.0016012191772460938, 'loss_3': -16.345748901367188, 'loss_4': -0.3682398796081543, 'epoch': 12.34}
{'loss': 0.0255, 'grad_norm': 12.62128734588623, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.025539690628647804, 'loss_2': 1.1920928955078125e-06, 'loss_3': -16.488658905029297, 'loss_4': 0.4760512709617615, 'epoch': 12.35}
{'loss': 0.0152, 'grad_norm': 9.185542106628418, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.014009685255587101, 'loss_2': 0.0011959075927734375, 'loss_3': -16.28412628173828, 'loss_4': 0.1524907648563385, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 16:10:02,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:02,272 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [52:56<52:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:09,615 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01251415815204382, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.711, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009648725390434265, 'eval_loss_2': 0.002865433692932129, 'eval_loss_3': -18.215925216674805, 'eval_loss_4': -0.16454873979091644, 'epoch': 12.35}
{'loss': 0.0185, 'grad_norm': 6.74298620223999, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.01519093569368124, 'loss_2': 0.0033283233642578125, 'loss_3': -16.240440368652344, 'loss_4': 0.22652310132980347, 'epoch': 12.36}
{'loss': 0.009, 'grad_norm': 10.863576889038086, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.007551089860498905, 'loss_2': 0.0014677047729492188, 'loss_3': -16.212421417236328, 'loss_4': -0.017687907442450523, 'epoch': 12.37}
{'loss': 0.018, 'grad_norm': 8.118675231933594, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.013511884026229382, 'loss_2': 0.0044403076171875, 'loss_3': -16.351411819458008, 'loss_4': 0.4576871693134308, 'epoch': 12.37}
{'loss': 0.0167, 'grad_norm': 7.963850975036621, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.013850186951458454, 'loss_2': 0.0028228759765625, 'loss_3': -16.36724090576172, 'loss_4': -0.26875972747802734, 'epoch': 12.38}
{'loss': 0.0241, 'grad_norm': 16.391422271728516, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.0236201174557209, 'loss_2': 0.0004982948303222656, 'loss_3': -16.304227828979492, 'loss_4': -0.13584110140800476, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 16:10:09,616 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:09,616 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [53:03<52:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:16,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013338685035705566, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010508685372769833, 'eval_loss_2': 0.002829998731613159, 'eval_loss_3': -18.242128372192383, 'eval_loss_4': -0.36908257007598877, 'epoch': 12.38}
{'loss': 0.0237, 'grad_norm': 9.697513580322266, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.01703186333179474, 'loss_2': 0.00664520263671875, 'loss_3': -16.518613815307617, 'loss_4': 0.2104702591896057, 'epoch': 12.39}
{'loss': 0.0081, 'grad_norm': 5.297906398773193, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.00676137488335371, 'loss_2': 0.0013790130615234375, 'loss_3': -16.32164764404297, 'loss_4': -0.22273950278759003, 'epoch': 12.4}
{'loss': 0.0222, 'grad_norm': 10.3232421875, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.016319530084729195, 'loss_2': 0.00592803955078125, 'loss_3': -16.33171272277832, 'loss_4': 0.5048482418060303, 'epoch': 12.4}
{'loss': 0.0105, 'grad_norm': 5.299976348876953, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.009335450828075409, 'loss_2': 0.0011730194091796875, 'loss_3': -16.337265014648438, 'loss_4': -0.3024463653564453, 'epoch': 12.41}
{'loss': 0.0169, 'grad_norm': 5.422614097595215, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.009855598211288452, 'loss_2': 0.00708770751953125, 'loss_3': -16.284912109375, 'loss_4': -0.5414877533912659, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 16:10:16,967 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:16,967 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [53:10<52:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:24,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012309612706303596, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008890198543667793, 'eval_loss_2': 0.0034194141626358032, 'eval_loss_3': -18.238540649414062, 'eval_loss_4': -0.7748383283615112, 'epoch': 12.41}
{'loss': 0.0149, 'grad_norm': 5.68252420425415, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.009143057279288769, 'loss_2': 0.005764007568359375, 'loss_3': -16.344947814941406, 'loss_4': -0.7460057139396667, 'epoch': 12.42}
{'loss': 0.0173, 'grad_norm': 5.138067722320557, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.014300640672445297, 'loss_2': 0.002986907958984375, 'loss_3': -16.372882843017578, 'loss_4': -0.930662989616394, 'epoch': 12.42}
{'loss': 0.0183, 'grad_norm': 6.983259201049805, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.013098499737679958, 'loss_2': 0.00522613525390625, 'loss_3': -16.228713989257812, 'loss_4': -0.35547393560409546, 'epoch': 12.43}
{'loss': 0.0257, 'grad_norm': 6.526429176330566, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.01731342449784279, 'loss_2': 0.008392333984375, 'loss_3': -16.40667152404785, 'loss_4': -0.5810421705245972, 'epoch': 12.44}
{'loss': 0.011, 'grad_norm': 5.192838668823242, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.00978260487318039, 'loss_2': 0.0012454986572265625, 'loss_3': -16.252666473388672, 'loss_4': -0.8481631875038147, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 16:10:24,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:24,308 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:18<52:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:31,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012510735541582108, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.371, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00992471445351839, 'eval_loss_2': 0.0025860220193862915, 'eval_loss_3': -18.22303009033203, 'eval_loss_4': -1.0382399559020996, 'epoch': 12.44}
{'loss': 0.0093, 'grad_norm': 6.674192905426025, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.008720003068447113, 'loss_2': 0.0005407333374023438, 'loss_3': -16.4708251953125, 'loss_4': -1.3211901187896729, 'epoch': 12.45}
{'loss': 0.0115, 'grad_norm': 4.265832901000977, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.005652780644595623, 'loss_2': 0.005859375, 'loss_3': -16.46136474609375, 'loss_4': -1.0984042882919312, 'epoch': 12.45}
{'loss': 0.0185, 'grad_norm': 6.484166622161865, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.01722479797899723, 'loss_2': 0.0013246536254882812, 'loss_3': -16.32893943786621, 'loss_4': -1.4947657585144043, 'epoch': 12.46}
{'loss': 0.0131, 'grad_norm': 5.690757751464844, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.012892033904790878, 'loss_2': 0.0001704692840576172, 'loss_3': -16.31015396118164, 'loss_4': -1.7292919158935547, 'epoch': 12.47}
{'loss': 0.0082, 'grad_norm': 5.27869176864624, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.00723574124276638, 'loss_2': 0.0009918212890625, 'loss_3': -16.536266326904297, 'loss_4': -1.3899736404418945, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 16:10:31,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:31,648 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:25<51:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:38,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01139263529330492, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.008885782212018967, 'eval_loss_2': 0.002506852149963379, 'eval_loss_3': -18.208280563354492, 'eval_loss_4': -1.1576590538024902, 'epoch': 12.47}
{'loss': 0.0157, 'grad_norm': 6.337604999542236, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.01420191302895546, 'loss_2': 0.001506805419921875, 'loss_3': -16.33934783935547, 'loss_4': -1.3948748111724854, 'epoch': 12.48}
{'loss': 0.0133, 'grad_norm': 4.878086090087891, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.004951111506670713, 'loss_2': 0.008331298828125, 'loss_3': -16.339021682739258, 'loss_4': -1.3120814561843872, 'epoch': 12.48}
{'loss': 0.0202, 'grad_norm': 5.57841682434082, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.010241962969303131, 'loss_2': 0.009979248046875, 'loss_3': -16.424968719482422, 'loss_4': -1.3146398067474365, 'epoch': 12.49}
{'loss': 0.0339, 'grad_norm': 9.518733978271484, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.02139371819794178, 'loss_2': 0.01251220703125, 'loss_3': -16.221004486083984, 'loss_4': -0.8713677525520325, 'epoch': 12.49}
{'loss': 0.0145, 'grad_norm': 5.601466655731201, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.01050820667296648, 'loss_2': 0.0040283203125, 'loss_3': -16.345701217651367, 'loss_4': -0.8533230423927307, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 16:10:38,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:38,985 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:32<51:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:46,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011697303503751755, 'eval_runtime': 3.8312, 'eval_samples_per_second': 267.278, 'eval_steps_per_second': 4.176, 'eval_loss_1': 0.009392033331096172, 'eval_loss_2': 0.002305269241333008, 'eval_loss_3': -18.179073333740234, 'eval_loss_4': -1.0649155378341675, 'epoch': 12.5}
{'loss': 0.015, 'grad_norm': 6.079877853393555, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.012432015500962734, 'loss_2': 0.0025424957275390625, 'loss_3': -16.31382942199707, 'loss_4': -1.0810712575912476, 'epoch': 12.51}
{'loss': 0.0301, 'grad_norm': 16.43653678894043, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.024640286341309547, 'loss_2': 0.005466461181640625, 'loss_3': -16.436298370361328, 'loss_4': -0.671738862991333, 'epoch': 12.51}
{'loss': 0.0121, 'grad_norm': 5.356747150421143, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.005221339408308268, 'loss_2': 0.00689697265625, 'loss_3': -16.522981643676758, 'loss_4': -1.0444903373718262, 'epoch': 12.52}
{'loss': 0.0132, 'grad_norm': 6.843155384063721, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.0104657132178545, 'loss_2': 0.00270843505859375, 'loss_3': -16.299184799194336, 'loss_4': -1.131998062133789, 'epoch': 12.52}
{'loss': 0.0142, 'grad_norm': 5.806156635284424, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.009161323308944702, 'loss_2': 0.0050048828125, 'loss_3': -16.42521095275879, 'loss_4': -1.157545804977417, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 16:10:46,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:46,353 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:40<51:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:10:53,686 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013559238985180855, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.836, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01078921090811491, 'eval_loss_2': 0.0027700290083885193, 'eval_loss_3': -18.143207550048828, 'eval_loss_4': -0.9289342164993286, 'epoch': 12.53}
{'loss': 0.0306, 'grad_norm': 11.690731048583984, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.02663029357790947, 'loss_2': 0.004016876220703125, 'loss_3': -16.273906707763672, 'loss_4': -0.7019945979118347, 'epoch': 12.53}
{'loss': 0.0331, 'grad_norm': 11.604299545288086, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.03029727190732956, 'loss_2': 0.002777099609375, 'loss_3': -16.404558181762695, 'loss_4': -0.7839089632034302, 'epoch': 12.54}
{'loss': 0.0153, 'grad_norm': 7.32827091217041, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.014793631620705128, 'loss_2': 0.0005154609680175781, 'loss_3': -16.244203567504883, 'loss_4': -0.8101481199264526, 'epoch': 12.55}
{'loss': 0.0134, 'grad_norm': 6.050115585327148, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.010542996227741241, 'loss_2': 0.002864837646484375, 'loss_3': -16.296894073486328, 'loss_4': -1.192884922027588, 'epoch': 12.55}
{'loss': 0.0151, 'grad_norm': 6.355355262756348, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.012586171738803387, 'loss_2': 0.002498626708984375, 'loss_3': -16.32335662841797, 'loss_4': -1.1560230255126953, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 16:10:53,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:10:53,686 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:47<51:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:01,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01834990084171295, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.624, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.014345094561576843, 'eval_loss_2': 0.004004806280136108, 'eval_loss_3': -18.11845588684082, 'eval_loss_4': -0.7327356338500977, 'epoch': 12.56}
{'loss': 0.0167, 'grad_norm': 8.207708358764648, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.01147055346518755, 'loss_2': 0.005260467529296875, 'loss_3': -16.284713745117188, 'loss_4': -0.6723970174789429, 'epoch': 12.56}
{'loss': 0.018, 'grad_norm': 6.194604873657227, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.010839727707207203, 'loss_2': 0.007175445556640625, 'loss_3': -16.325233459472656, 'loss_4': -0.6211113929748535, 'epoch': 12.57}
{'loss': 0.0141, 'grad_norm': 5.207658767700195, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.007929496467113495, 'loss_2': 0.006134033203125, 'loss_3': -16.276493072509766, 'loss_4': -0.6027734279632568, 'epoch': 12.58}
{'loss': 0.0342, 'grad_norm': 15.313580513000488, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.027763405814766884, 'loss_2': 0.0064544677734375, 'loss_3': -16.4686279296875, 'loss_4': -0.6561793684959412, 'epoch': 12.58}
{'loss': 0.0108, 'grad_norm': 5.751818656921387, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.009498382918536663, 'loss_2': 0.0012760162353515625, 'loss_3': -16.333843231201172, 'loss_4': -0.5631527900695801, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 16:11:01,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:01,025 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [53:54<51:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:08,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016430694609880447, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.279, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01398413348942995, 'eval_loss_2': 0.0024465620517730713, 'eval_loss_3': -18.112407684326172, 'eval_loss_4': -0.6684408187866211, 'epoch': 12.59}
{'loss': 0.0393, 'grad_norm': 14.436445236206055, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.033620160073041916, 'loss_2': 0.005706787109375, 'loss_3': -16.276248931884766, 'loss_4': -0.5414301156997681, 'epoch': 12.59}
{'loss': 0.0181, 'grad_norm': 9.100547790527344, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.0136072663590312, 'loss_2': 0.0045013427734375, 'loss_3': -16.35861587524414, 'loss_4': -0.30249619483947754, 'epoch': 12.6}
{'loss': 0.014, 'grad_norm': 4.816251754760742, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.007227859925478697, 'loss_2': 0.00676727294921875, 'loss_3': -16.356834411621094, 'loss_4': -0.7682813405990601, 'epoch': 12.6}
{'loss': 0.0185, 'grad_norm': 11.751574516296387, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.010873181745409966, 'loss_2': 0.00763702392578125, 'loss_3': -16.111255645751953, 'loss_4': -0.7069518566131592, 'epoch': 12.61}
{'loss': 0.019, 'grad_norm': 8.979215621948242, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.015399281866848469, 'loss_2': 0.00357818603515625, 'loss_3': -16.424095153808594, 'loss_4': -0.5992076396942139, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 16:11:08,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:08,366 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [54:02<51:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:15,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018409857526421547, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.014415958896279335, 'eval_loss_2': 0.003993898630142212, 'eval_loss_3': -18.131175994873047, 'eval_loss_4': -0.8049551844596863, 'epoch': 12.62}
{'loss': 0.037, 'grad_norm': 15.269233703613281, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.027178214862942696, 'loss_2': 0.00980377197265625, 'loss_3': -16.313722610473633, 'loss_4': -0.978262722492218, 'epoch': 12.62}
{'loss': 0.0151, 'grad_norm': 7.156373977661133, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.014103218913078308, 'loss_2': 0.00096893310546875, 'loss_3': -16.254091262817383, 'loss_4': -0.5691763162612915, 'epoch': 12.63}
{'loss': 0.0206, 'grad_norm': 7.688241004943848, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.01663987711071968, 'loss_2': 0.00397491455078125, 'loss_3': -16.401538848876953, 'loss_4': -0.9462064504623413, 'epoch': 12.63}
{'loss': 0.0323, 'grad_norm': 20.34632682800293, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.021566689014434814, 'loss_2': 0.010711669921875, 'loss_3': -16.280229568481445, 'loss_4': -1.1588034629821777, 'epoch': 12.64}
{'loss': 0.0255, 'grad_norm': 16.54210090637207, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.02076541818678379, 'loss_2': 0.00469970703125, 'loss_3': -16.418031692504883, 'loss_4': -1.1480425596237183, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 16:11:15,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:15,702 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [54:09<51:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:23,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020755313336849213, 'eval_runtime': 3.8335, 'eval_samples_per_second': 267.119, 'eval_steps_per_second': 4.174, 'eval_loss_1': 0.016161197796463966, 'eval_loss_2': 0.004594113677740097, 'eval_loss_3': -18.14054298400879, 'eval_loss_4': -1.0344995260238647, 'epoch': 12.65}
{'loss': 0.0229, 'grad_norm': 5.679142951965332, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.01682186871767044, 'loss_2': 0.00611114501953125, 'loss_3': -16.38619613647461, 'loss_4': -1.4306260347366333, 'epoch': 12.65}
{'loss': 0.0144, 'grad_norm': 5.418766498565674, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.010277476161718369, 'loss_2': 0.00408935546875, 'loss_3': -16.23046112060547, 'loss_4': -1.1780073642730713, 'epoch': 12.66}
{'loss': 0.0424, 'grad_norm': 11.816850662231445, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.041818201541900635, 'loss_2': 0.0005478858947753906, 'loss_3': -16.296775817871094, 'loss_4': -1.7653863430023193, 'epoch': 12.66}
{'loss': 0.0358, 'grad_norm': 10.344147682189941, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.03288966417312622, 'loss_2': 0.002910614013671875, 'loss_3': -16.144550323486328, 'loss_4': -1.5257306098937988, 'epoch': 12.67}
{'loss': 0.0141, 'grad_norm': 6.384650707244873, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.009148700162768364, 'loss_2': 0.00498199462890625, 'loss_3': -16.36919593811035, 'loss_4': -1.401154637336731, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 16:11:23,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:23,067 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [54:16<51:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:30,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017469679936766624, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.014658105559647083, 'eval_loss_2': 0.0028115734457969666, 'eval_loss_3': -18.16436004638672, 'eval_loss_4': -1.245757818222046, 'epoch': 12.67}
{'loss': 0.0126, 'grad_norm': 5.957367897033691, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.010455729439854622, 'loss_2': 0.0021648406982421875, 'loss_3': -16.624664306640625, 'loss_4': -1.1633315086364746, 'epoch': 12.68}
{'loss': 0.0308, 'grad_norm': 17.84897804260254, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.024289587512612343, 'loss_2': 0.00650787353515625, 'loss_3': -16.28750228881836, 'loss_4': -1.5763225555419922, 'epoch': 12.69}
{'loss': 0.0172, 'grad_norm': 7.4815168380737305, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.013419507071375847, 'loss_2': 0.00382232666015625, 'loss_3': -16.342769622802734, 'loss_4': -1.4501874446868896, 'epoch': 12.69}
{'loss': 0.0157, 'grad_norm': 5.4724860191345215, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.012981347739696503, 'loss_2': 0.002742767333984375, 'loss_3': -16.457752227783203, 'loss_4': -1.6003100872039795, 'epoch': 12.7}
{'loss': 0.0128, 'grad_norm': 5.931712627410889, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.012698530219495296, 'loss_2': 0.00014281272888183594, 'loss_3': -16.442028045654297, 'loss_4': -1.4523077011108398, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 16:11:30,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:30,400 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:24<51:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:37,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01316072978079319, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.706, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010915808379650116, 'eval_loss_2': 0.0022449232637882233, 'eval_loss_3': -18.204151153564453, 'eval_loss_4': -1.1957753896713257, 'epoch': 12.7}
{'loss': 0.0242, 'grad_norm': 11.400520324707031, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.020996347069740295, 'loss_2': 0.003162384033203125, 'loss_3': -16.41964340209961, 'loss_4': -1.5530037879943848, 'epoch': 12.71}
{'loss': 0.0146, 'grad_norm': 5.811387538909912, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.010281705297529697, 'loss_2': 0.004329681396484375, 'loss_3': -16.110071182250977, 'loss_4': -1.430935025215149, 'epoch': 12.72}
{'loss': 0.0141, 'grad_norm': 4.808975696563721, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.007089183200150728, 'loss_2': 0.00698089599609375, 'loss_3': -16.37226104736328, 'loss_4': -1.2233357429504395, 'epoch': 12.72}
{'loss': 0.0192, 'grad_norm': 10.991419792175293, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.01833910308778286, 'loss_2': 0.0008878707885742188, 'loss_3': -16.30254364013672, 'loss_4': -1.4318594932556152, 'epoch': 12.73}
{'loss': 0.025, 'grad_norm': 7.562413215637207, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.008791381493210793, 'loss_2': 0.0162200927734375, 'loss_3': -16.32159996032715, 'loss_4': -0.6490780711174011, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 16:11:37,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:37,728 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:31<51:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:11:45,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011922409757971764, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.506, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009426755830645561, 'eval_loss_2': 0.0024956539273262024, 'eval_loss_3': -18.181968688964844, 'eval_loss_4': -0.8433879017829895, 'epoch': 12.73}
{'loss': 0.0487, 'grad_norm': 19.19306182861328, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.04653260484337807, 'loss_2': 0.0021533966064453125, 'loss_3': -16.34137725830078, 'loss_4': -0.7497773766517639, 'epoch': 12.74}
{'loss': 0.0551, 'grad_norm': 13.993535041809082, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.051277805119752884, 'loss_2': 0.003856658935546875, 'loss_3': -16.23053741455078, 'loss_4': -0.5596382021903992, 'epoch': 12.74}
{'loss': 0.0094, 'grad_norm': 5.084170341491699, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.009219500236213207, 'loss_2': 0.00021719932556152344, 'loss_3': -16.51911735534668, 'loss_4': -0.9496518969535828, 'epoch': 12.75}
{'loss': 0.0149, 'grad_norm': 5.410430908203125, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.011547358706593513, 'loss_2': 0.003314971923828125, 'loss_3': -16.541175842285156, 'loss_4': -1.6046503782272339, 'epoch': 12.76}
{'loss': 0.0272, 'grad_norm': 11.926969528198242, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.02241152711212635, 'loss_2': 0.004756927490234375, 'loss_3': -16.074007034301758, 'loss_4': -0.280720591545105, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 16:11:45,056 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:45,057 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:38<51:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:52,402 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012541655451059341, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.389, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009632165543735027, 'eval_loss_2': 0.0029094889760017395, 'eval_loss_3': -18.20159912109375, 'eval_loss_4': -0.5906459093093872, 'epoch': 12.76}
{'loss': 0.0126, 'grad_norm': 5.506534576416016, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.00656207837164402, 'loss_2': 0.006023406982421875, 'loss_3': -16.337961196899414, 'loss_4': -0.4929179847240448, 'epoch': 12.77}
{'loss': 0.0154, 'grad_norm': 5.471386909484863, 'learning_rate': 1.725e-05, 'loss_1': 0.011380660347640514, 'loss_2': 0.004032135009765625, 'loss_3': -16.453643798828125, 'loss_4': -1.1798815727233887, 'epoch': 12.77}
{'loss': 0.0177, 'grad_norm': 6.104515075683594, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.010136705823242664, 'loss_2': 0.007598876953125, 'loss_3': -16.504554748535156, 'loss_4': -0.6862486600875854, 'epoch': 12.78}
{'loss': 0.0862, 'grad_norm': 19.159303665161133, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.08367492258548737, 'loss_2': 0.00250244140625, 'loss_3': -16.271705627441406, 'loss_4': -0.8918545842170715, 'epoch': 12.78}
{'loss': 0.0239, 'grad_norm': 14.774391174316406, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.017057640478014946, 'loss_2': 0.006885528564453125, 'loss_3': -16.275310516357422, 'loss_4': -0.5096043348312378, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 16:11:52,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:52,403 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:46<51:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:11:59,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01250210590660572, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.441, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009561898186802864, 'eval_loss_2': 0.0029402077198028564, 'eval_loss_3': -18.18011474609375, 'eval_loss_4': -0.6060242652893066, 'epoch': 12.79}
{'loss': 0.0082, 'grad_norm': 5.210088729858398, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.0035219916608184576, 'loss_2': 0.0047149658203125, 'loss_3': -16.243000030517578, 'loss_4': -0.9776355028152466, 'epoch': 12.8}
{'loss': 0.0128, 'grad_norm': 5.837649822235107, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.012731844559311867, 'loss_2': 2.5212764739990234e-05, 'loss_3': -16.348812103271484, 'loss_4': -0.42717403173446655, 'epoch': 12.8}
{'loss': 0.0186, 'grad_norm': 8.626542091369629, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.014345033094286919, 'loss_2': 0.004299163818359375, 'loss_3': -16.19571876525879, 'loss_4': -0.6610237956047058, 'epoch': 12.81}
{'loss': 0.0216, 'grad_norm': 5.513108730316162, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.012715018354356289, 'loss_2': 0.00885009765625, 'loss_3': -16.332380294799805, 'loss_4': -1.1976536512374878, 'epoch': 12.81}
{'loss': 0.0154, 'grad_norm': 6.939833641052246, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.013131050392985344, 'loss_2': 0.002285003662109375, 'loss_3': -16.23565673828125, 'loss_4': -0.5902971029281616, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 16:11:59,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:11:59,745 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:53<50:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:07,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01293936837464571, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.78, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.009420712478458881, 'eval_loss_2': 0.0035186558961868286, 'eval_loss_3': -18.216110229492188, 'eval_loss_4': -0.5453478693962097, 'epoch': 12.82}
{'loss': 0.0124, 'grad_norm': 4.696681499481201, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.004237096756696701, 'loss_2': 0.00820159912109375, 'loss_3': -16.190357208251953, 'loss_4': -0.9271135330200195, 'epoch': 12.83}
{'loss': 0.0129, 'grad_norm': 5.0008544921875, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.008989677764475346, 'loss_2': 0.003887176513671875, 'loss_3': -16.27808380126953, 'loss_4': -0.013677313923835754, 'epoch': 12.83}
{'loss': 0.015, 'grad_norm': 7.162161827087402, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.008216502144932747, 'loss_2': 0.006809234619140625, 'loss_3': -16.389488220214844, 'loss_4': -0.3681271970272064, 'epoch': 12.84}
{'loss': 0.0178, 'grad_norm': 6.190549373626709, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.01213272474706173, 'loss_2': 0.00571441650390625, 'loss_3': -16.296897888183594, 'loss_4': -0.7461239099502563, 'epoch': 12.84}
{'loss': 0.0126, 'grad_norm': 4.38245964050293, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.007107566110789776, 'loss_2': 0.0055389404296875, 'loss_3': -16.479015350341797, 'loss_4': -0.5430676341056824, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 16:12:07,081 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:07,081 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [55:01<50:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:14,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012293308973312378, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.46, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009449287317693233, 'eval_loss_2': 0.00284402072429657, 'eval_loss_3': -18.226736068725586, 'eval_loss_4': -0.42409980297088623, 'epoch': 12.85}
{'loss': 0.0163, 'grad_norm': 5.505160808563232, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.010267546400427818, 'loss_2': 0.006069183349609375, 'loss_3': -16.413015365600586, 'loss_4': -0.6660047173500061, 'epoch': 12.85}
{'loss': 0.0138, 'grad_norm': 7.603822708129883, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.01286975760012865, 'loss_2': 0.0008878707885742188, 'loss_3': -16.361228942871094, 'loss_4': -0.2137727439403534, 'epoch': 12.86}
{'loss': 0.0201, 'grad_norm': 9.296374320983887, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.012531468644738197, 'loss_2': 0.00754547119140625, 'loss_3': -16.26156997680664, 'loss_4': -1.0423622131347656, 'epoch': 12.87}
{'loss': 0.0268, 'grad_norm': 9.504404067993164, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.021994346752762794, 'loss_2': 0.004764556884765625, 'loss_3': -16.44522476196289, 'loss_4': -0.8643389344215393, 'epoch': 12.87}
{'loss': 0.0112, 'grad_norm': 10.15424633026123, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.006677305791527033, 'loss_2': 0.004486083984375, 'loss_3': -16.440223693847656, 'loss_4': -0.3451662063598633, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 16:12:14,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:14,425 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [55:08<50:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:21,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017881423234939575, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008681325241923332, 'eval_loss_2': 0.009200096130371094, 'eval_loss_3': -18.239919662475586, 'eval_loss_4': -0.13710105419158936, 'epoch': 12.88}
{'loss': 0.0222, 'grad_norm': 6.801337718963623, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.012369037605822086, 'loss_2': 0.0098419189453125, 'loss_3': -16.401443481445312, 'loss_4': -0.41625961661338806, 'epoch': 12.88}
{'loss': 0.0274, 'grad_norm': 8.732093811035156, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.019775839522480965, 'loss_2': 0.00763702392578125, 'loss_3': -16.319580078125, 'loss_4': -0.14064355194568634, 'epoch': 12.89}
{'loss': 0.0181, 'grad_norm': 6.539377689361572, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.009933296591043472, 'loss_2': 0.0081787109375, 'loss_3': -16.280494689941406, 'loss_4': -0.40976831316947937, 'epoch': 12.9}
{'loss': 0.0188, 'grad_norm': 5.362288951873779, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.006706210784614086, 'loss_2': 0.01209259033203125, 'loss_3': -16.316043853759766, 'loss_4': -0.05469711124897003, 'epoch': 12.9}
{'loss': 0.0223, 'grad_norm': 14.739627838134766, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.02225925587117672, 'loss_2': 8.308887481689453e-05, 'loss_3': -16.147172927856445, 'loss_4': -0.613169252872467, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 16:12:21,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:21,759 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [55:15<50:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:29,099 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016512520611286163, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.602, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00930393673479557, 'eval_loss_2': 0.007208585739135742, 'eval_loss_3': -18.23389434814453, 'eval_loss_4': 0.1582304984331131, 'epoch': 12.91}
{'loss': 0.0284, 'grad_norm': 9.984819412231445, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.02594836615025997, 'loss_2': 0.00247955322265625, 'loss_3': -16.431682586669922, 'loss_4': -0.21323910355567932, 'epoch': 12.91}
{'loss': 0.0122, 'grad_norm': 5.472747325897217, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.006871859077364206, 'loss_2': 0.0053558349609375, 'loss_3': -16.18169403076172, 'loss_4': -0.2149645835161209, 'epoch': 12.92}
{'loss': 0.0135, 'grad_norm': 5.580298900604248, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.00858369842171669, 'loss_2': 0.00487518310546875, 'loss_3': -16.216693878173828, 'loss_4': -0.26275286078453064, 'epoch': 12.92}
{'loss': 0.0119, 'grad_norm': 13.510699272155762, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.0074750520288944244, 'loss_2': 0.00439453125, 'loss_3': -16.269418716430664, 'loss_4': 0.5926204919815063, 'epoch': 12.93}
{'loss': 0.013, 'grad_norm': 6.631875038146973, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.011673030443489552, 'loss_2': 0.0012798309326171875, 'loss_3': -16.372758865356445, 'loss_4': 0.12302011251449585, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 16:12:29,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:29,099 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:23<50:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:12:36,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011601163074374199, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.074, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008989899419248104, 'eval_loss_2': 0.0026112645864486694, 'eval_loss_3': -18.220523834228516, 'eval_loss_4': 0.20008912682533264, 'epoch': 12.94}
{'loss': 0.0353, 'grad_norm': 15.794269561767578, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.034674473106861115, 'loss_2': 0.0006589889526367188, 'loss_3': -16.256500244140625, 'loss_4': -0.4331088662147522, 'epoch': 12.94}
{'loss': 0.0115, 'grad_norm': 5.562988758087158, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.008949284441769123, 'loss_2': 0.002552032470703125, 'loss_3': -16.313251495361328, 'loss_4': -0.35565564036369324, 'epoch': 12.95}
{'loss': 0.0229, 'grad_norm': 10.902475357055664, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.01999681070446968, 'loss_2': 0.0028591156005859375, 'loss_3': -16.105031967163086, 'loss_4': -0.1378559023141861, 'epoch': 12.95}
{'loss': 0.0281, 'grad_norm': 13.010400772094727, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.02545696496963501, 'loss_2': 0.002655029296875, 'loss_3': -16.197296142578125, 'loss_4': -0.2568325698375702, 'epoch': 12.96}
{'loss': 0.0145, 'grad_norm': 5.506816864013672, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.010114959441125393, 'loss_2': 0.004413604736328125, 'loss_3': -16.181045532226562, 'loss_4': 0.41686517000198364, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 16:12:36,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:36,442 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:30<50:13,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:12:43,752 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013591000810265541, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.871, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008875587955117226, 'eval_loss_2': 0.004715412855148315, 'eval_loss_3': -18.2375545501709, 'eval_loss_4': 0.25203409790992737, 'epoch': 12.97}
{'loss': 0.0255, 'grad_norm': 8.514257431030273, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.02355039492249489, 'loss_2': 0.001964569091796875, 'loss_3': -16.394786834716797, 'loss_4': 0.4092717170715332, 'epoch': 12.97}
{'loss': 0.0101, 'grad_norm': 5.7166876792907715, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.009706084616482258, 'loss_2': 0.000392913818359375, 'loss_3': -16.375404357910156, 'loss_4': 0.3385874629020691, 'epoch': 12.98}
{'loss': 0.0279, 'grad_norm': 6.339244365692139, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.012958177365362644, 'loss_2': 0.0149383544921875, 'loss_3': -16.21637725830078, 'loss_4': 0.5695418119430542, 'epoch': 12.98}
{'loss': 0.03, 'grad_norm': 10.24927806854248, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.025128116831183434, 'loss_2': 0.00482940673828125, 'loss_3': -16.339431762695312, 'loss_4': 0.34146782755851746, 'epoch': 12.99}
{'loss': 0.0202, 'grad_norm': 7.362086296081543, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.013690358027815819, 'loss_2': 0.006500244140625, 'loss_3': -16.17904281616211, 'loss_4': 0.13866831362247467, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 16:12:43,752 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:43,752 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:37<49:25,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:12:50,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012668568640947342, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.372, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00939215812832117, 'eval_loss_2': 0.0032764114439487457, 'eval_loss_3': -18.234846115112305, 'eval_loss_4': 0.07042533159255981, 'epoch': 12.99}
{'loss': 0.0128, 'grad_norm': 6.612689971923828, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.004540831316262484, 'loss_2': 0.00823974609375, 'loss_3': -16.044145584106445, 'loss_4': -0.7842574119567871, 'epoch': 13.0}
{'loss': 0.021, 'grad_norm': 7.180028915405273, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.01936989091336727, 'loss_2': 0.0015964508056640625, 'loss_3': -16.405412673950195, 'loss_4': 0.5485265254974365, 'epoch': 13.01}
{'loss': 0.0274, 'grad_norm': 11.277263641357422, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.024882590398192406, 'loss_2': 0.002552032470703125, 'loss_3': -16.116474151611328, 'loss_4': -0.2500569820404053, 'epoch': 13.01}
{'loss': 0.0056, 'grad_norm': 5.257622718811035, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.004817198030650616, 'loss_2': 0.0007944107055664062, 'loss_3': -16.216289520263672, 'loss_4': -0.3574714958667755, 'epoch': 13.02}
{'loss': 0.0123, 'grad_norm': 5.0359721183776855, 'learning_rate': 1.7e-05, 'loss_1': 0.008596468716859818, 'loss_2': 0.003665924072265625, 'loss_3': -16.29037857055664, 'loss_4': -0.02545943111181259, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 16:12:50,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:50,798 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:44<50:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:12:58,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012667303904891014, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.743, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010549030266702175, 'eval_loss_2': 0.0021182745695114136, 'eval_loss_3': -18.235437393188477, 'eval_loss_4': -0.23678919672966003, 'epoch': 13.02}
{'loss': 0.0229, 'grad_norm': 7.631563186645508, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.01703660748898983, 'loss_2': 0.00588226318359375, 'loss_3': -16.384796142578125, 'loss_4': -0.12175098061561584, 'epoch': 13.03}
{'loss': 0.0121, 'grad_norm': 5.071048259735107, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.007900631986558437, 'loss_2': 0.004161834716796875, 'loss_3': -16.142560958862305, 'loss_4': -0.45468318462371826, 'epoch': 13.03}
{'loss': 0.0094, 'grad_norm': 5.525485038757324, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.004433640744537115, 'loss_2': 0.004974365234375, 'loss_3': -16.368114471435547, 'loss_4': -0.116767019033432, 'epoch': 13.04}
{'loss': 0.013, 'grad_norm': 4.936285495758057, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.007202093955129385, 'loss_2': 0.00579833984375, 'loss_3': -16.35234832763672, 'loss_4': -0.5968589782714844, 'epoch': 13.05}
{'loss': 0.0114, 'grad_norm': 5.706153392791748, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.010854596272110939, 'loss_2': 0.00055694580078125, 'loss_3': -16.223915100097656, 'loss_4': -0.9739645719528198, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 16:12:58,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:12:58,135 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:52<50:11,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:13:05,465 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01229228638112545, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.689, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010139672085642815, 'eval_loss_2': 0.0021526142954826355, 'eval_loss_3': -18.219207763671875, 'eval_loss_4': -0.5859512090682983, 'epoch': 13.05}
{'loss': 0.0124, 'grad_norm': 5.324118614196777, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.008541233837604523, 'loss_2': 0.003826141357421875, 'loss_3': -16.371788024902344, 'loss_4': -0.5206154584884644, 'epoch': 13.06}
{'loss': 0.0157, 'grad_norm': 6.55475378036499, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.009504498913884163, 'loss_2': 0.00616455078125, 'loss_3': -16.301311492919922, 'loss_4': -0.9766910076141357, 'epoch': 13.06}
{'loss': 0.0144, 'grad_norm': 6.400330066680908, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.012599856592714787, 'loss_2': 0.0017709732055664062, 'loss_3': -16.184005737304688, 'loss_4': -1.3271458148956299, 'epoch': 13.07}
{'loss': 0.0127, 'grad_norm': 4.852521896362305, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.008035070262849331, 'loss_2': 0.0046234130859375, 'loss_3': -16.371801376342773, 'loss_4': -0.9779676198959351, 'epoch': 13.08}
{'loss': 0.018, 'grad_norm': 7.484050750732422, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.01266692578792572, 'loss_2': 0.00537109375, 'loss_3': -16.334144592285156, 'loss_4': -0.5339774489402771, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 16:13:05,465 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:05,465 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [55:59<50:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:12,806 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01983765885233879, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010828059166669846, 'eval_loss_2': 0.009009599685668945, 'eval_loss_3': -18.218069076538086, 'eval_loss_4': -0.7699676752090454, 'epoch': 13.08}
{'loss': 0.0185, 'grad_norm': 5.403290748596191, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.010126238688826561, 'loss_2': 0.0083465576171875, 'loss_3': -16.341650009155273, 'loss_4': -0.9259352684020996, 'epoch': 13.09}
{'loss': 0.0184, 'grad_norm': 5.362078666687012, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.01031580101698637, 'loss_2': 0.00811004638671875, 'loss_3': -16.298564910888672, 'loss_4': -0.3642260432243347, 'epoch': 13.09}
{'loss': 0.0237, 'grad_norm': 9.219158172607422, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.014433852396905422, 'loss_2': 0.009307861328125, 'loss_3': -16.118736267089844, 'loss_4': -0.7205530405044556, 'epoch': 13.1}
{'loss': 0.0477, 'grad_norm': 20.564102172851562, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.03878152742981911, 'loss_2': 0.00890350341796875, 'loss_3': -16.236188888549805, 'loss_4': -0.5193407535552979, 'epoch': 13.1}
{'loss': 0.0301, 'grad_norm': 11.788812637329102, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.02038366161286831, 'loss_2': 0.00968170166015625, 'loss_3': -16.40207290649414, 'loss_4': -0.5614297389984131, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 16:13:12,806 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:12,806 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [56:06<50:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:20,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022469105198979378, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.605, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010741057805716991, 'eval_loss_2': 0.011728048324584961, 'eval_loss_3': -18.246986389160156, 'eval_loss_4': -0.8304141163825989, 'epoch': 13.11}
{'loss': 0.0213, 'grad_norm': 5.637393474578857, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.01155248936265707, 'loss_2': 0.00975799560546875, 'loss_3': -16.35575294494629, 'loss_4': -0.39568892121315, 'epoch': 13.12}
{'loss': 0.0338, 'grad_norm': 7.696896076202393, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.017453515902161598, 'loss_2': 0.016357421875, 'loss_3': -16.33025360107422, 'loss_4': -0.666495144367218, 'epoch': 13.12}
{'loss': 0.0293, 'grad_norm': 14.294549942016602, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.020658200606703758, 'loss_2': 0.0086212158203125, 'loss_3': -16.3405704498291, 'loss_4': -1.0508953332901, 'epoch': 13.13}
{'loss': 0.0215, 'grad_norm': 5.723397254943848, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.014759836718440056, 'loss_2': 0.0067596435546875, 'loss_3': -16.19948959350586, 'loss_4': -0.8087169528007507, 'epoch': 13.13}
{'loss': 0.0382, 'grad_norm': 13.190462112426758, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.033937569707632065, 'loss_2': 0.004291534423828125, 'loss_3': -16.369346618652344, 'loss_4': -0.6252859830856323, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 16:13:20,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:20,145 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [56:14<50:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:27,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01734941080212593, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.945, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.012671101838350296, 'eval_loss_2': 0.004678308963775635, 'eval_loss_3': -18.199161529541016, 'eval_loss_4': -0.8230400681495667, 'epoch': 13.14}
{'loss': 0.0172, 'grad_norm': 6.896514892578125, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.014184433966875076, 'loss_2': 0.0029697418212890625, 'loss_3': -16.11925506591797, 'loss_4': -0.7599510550498962, 'epoch': 13.15}
{'loss': 0.0209, 'grad_norm': 8.46670913696289, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.017785608768463135, 'loss_2': 0.003162384033203125, 'loss_3': -16.093671798706055, 'loss_4': -0.5581420063972473, 'epoch': 13.15}
{'loss': 0.0157, 'grad_norm': 8.079011917114258, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.015350067988038063, 'loss_2': 0.000301361083984375, 'loss_3': -16.135723114013672, 'loss_4': -0.795215368270874, 'epoch': 13.16}
{'loss': 0.0178, 'grad_norm': 6.112401962280273, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.00864400528371334, 'loss_2': 0.00916290283203125, 'loss_3': -16.449853897094727, 'loss_4': -1.0063353776931763, 'epoch': 13.16}
{'loss': 0.0139, 'grad_norm': 7.309839725494385, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.013167193159461021, 'loss_2': 0.0007071495056152344, 'loss_3': -16.37152671813965, 'loss_4': -0.9076703786849976, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 16:13:27,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:27,487 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:21<50:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:34,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019623713567852974, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.745, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.016690529882907867, 'eval_loss_2': 0.0029331818222999573, 'eval_loss_3': -18.16411781311035, 'eval_loss_4': -0.6910755634307861, 'epoch': 13.17}
{'loss': 0.0345, 'grad_norm': 11.810675621032715, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.028482962399721146, 'loss_2': 0.00603485107421875, 'loss_3': -16.193096160888672, 'loss_4': -0.7706806063652039, 'epoch': 13.17}
{'loss': 0.0133, 'grad_norm': 6.561149597167969, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.01233510859310627, 'loss_2': 0.000995635986328125, 'loss_3': -16.251728057861328, 'loss_4': -0.8495461940765381, 'epoch': 13.18}
{'loss': 0.0426, 'grad_norm': 16.12847137451172, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.04088994115591049, 'loss_2': 0.0016937255859375, 'loss_3': -16.25385856628418, 'loss_4': -0.5689163208007812, 'epoch': 13.19}
{'loss': 0.0169, 'grad_norm': 8.110957145690918, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.015560953877866268, 'loss_2': 0.001323699951171875, 'loss_3': -16.420669555664062, 'loss_4': -0.7742915153503418, 'epoch': 13.19}
{'loss': 0.0318, 'grad_norm': 9.67833137512207, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.02572859264910221, 'loss_2': 0.00611114501953125, 'loss_3': -16.233278274536133, 'loss_4': 0.107243612408638, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 16:13:34,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:34,836 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:28<49:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:42,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03087451495230198, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.579, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.027021553367376328, 'eval_loss_2': 0.0038529634475708008, 'eval_loss_3': -18.140888214111328, 'eval_loss_4': -0.4827632009983063, 'epoch': 13.2}
{'loss': 0.0291, 'grad_norm': 9.009560585021973, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.018620917573571205, 'loss_2': 0.0104522705078125, 'loss_3': -16.178470611572266, 'loss_4': -0.1818794161081314, 'epoch': 13.2}
{'loss': 0.0303, 'grad_norm': 12.318557739257812, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.02640131488442421, 'loss_2': 0.0038928985595703125, 'loss_3': -16.229766845703125, 'loss_4': -0.4656427502632141, 'epoch': 13.21}
{'loss': 0.0623, 'grad_norm': 11.448344230651855, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.04913442209362984, 'loss_2': 0.01317596435546875, 'loss_3': -16.35576057434082, 'loss_4': -0.16525688767433167, 'epoch': 13.22}
{'loss': 0.016, 'grad_norm': 7.216189861297607, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.014914333820343018, 'loss_2': 0.0010976791381835938, 'loss_3': -16.215282440185547, 'loss_4': -0.327803373336792, 'epoch': 13.22}
{'loss': 0.0464, 'grad_norm': 15.373785972595215, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.03813672065734863, 'loss_2': 0.00823211669921875, 'loss_3': -16.373191833496094, 'loss_4': 0.02048424631357193, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 16:13:42,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:42,185 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:36<49:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:49,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02123495563864708, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.603, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.018297705799341202, 'eval_loss_2': 0.0029372498393058777, 'eval_loss_3': -18.1492977142334, 'eval_loss_4': -0.26741570234298706, 'epoch': 13.23}
{'loss': 0.0201, 'grad_norm': 7.1525774002075195, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.012954814359545708, 'loss_2': 0.00714111328125, 'loss_3': -16.36566925048828, 'loss_4': -0.7351048588752747, 'epoch': 13.23}
{'loss': 0.0288, 'grad_norm': 8.285149574279785, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.018529577180743217, 'loss_2': 0.0102691650390625, 'loss_3': -16.452138900756836, 'loss_4': -0.609969973564148, 'epoch': 13.24}
{'loss': 0.0218, 'grad_norm': 9.129158973693848, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.015825746580958366, 'loss_2': 0.00592803955078125, 'loss_3': -16.275894165039062, 'loss_4': -0.7610718607902527, 'epoch': 13.24}
{'loss': 0.0334, 'grad_norm': 17.606584548950195, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.0325833261013031, 'loss_2': 0.0007967948913574219, 'loss_3': -16.41998863220215, 'loss_4': -0.46383151412010193, 'epoch': 13.25}
{'loss': 0.016, 'grad_norm': 11.72988510131836, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.012329118326306343, 'loss_2': 0.003662109375, 'loss_3': -16.2841854095459, 'loss_4': 0.3589324951171875, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 16:13:49,541 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:49,542 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:43<49:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:13:56,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011654410511255264, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.254, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008815471082925797, 'eval_loss_2': 0.0028389394283294678, 'eval_loss_3': -18.19320297241211, 'eval_loss_4': 0.09039030224084854, 'epoch': 13.26}
{'loss': 0.0143, 'grad_norm': 5.155245304107666, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.010640941560268402, 'loss_2': 0.0036334991455078125, 'loss_3': -16.34638023376465, 'loss_4': 0.21354292333126068, 'epoch': 13.26}
{'loss': 0.0078, 'grad_norm': 4.682388782501221, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.007779610808938742, 'loss_2': 5.84721565246582e-05, 'loss_3': -16.349830627441406, 'loss_4': -0.014478407800197601, 'epoch': 13.27}
{'loss': 0.021, 'grad_norm': 7.893463611602783, 'learning_rate': 1.675e-05, 'loss_1': 0.015493671409785748, 'loss_2': 0.005462646484375, 'loss_3': -16.314197540283203, 'loss_4': 0.4862050414085388, 'epoch': 13.27}
{'loss': 0.0107, 'grad_norm': 4.9466705322265625, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.0071142492815852165, 'loss_2': 0.0035686492919921875, 'loss_3': -16.36722183227539, 'loss_4': -0.1662815809249878, 'epoch': 13.28}
{'loss': 0.0085, 'grad_norm': 5.629019260406494, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.007354073226451874, 'loss_2': 0.00112152099609375, 'loss_3': -16.203813552856445, 'loss_4': 0.5939828753471375, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 16:13:56,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:13:56,880 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:47<49:40,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 16:14:00,681 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2285
[INFO|configuration_utils.py:420] 2025-01-21 16:14:00,683 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2285/config.json                                                                            
{'eval_loss': 0.010171111673116684, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.432, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.007700321730226278, 'eval_loss_2': 0.0024707913398742676, 'eval_loss_3': -18.1973819732666, 'eval_loss_4': 0.30886411666870117, 'epoch': 13.28}
[INFO|modeling_utils.py:2988] 2025-01-21 16:14:01,166 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2285/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:14:01,167 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2285/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:14:01,168 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2285/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:14:02,149 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2095] due to args.save_total_limit
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:52<54:58,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:14:05,784 >>
{'loss': 0.0117, 'grad_norm': 4.86861515045166, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.004771039355546236, 'loss_2': 0.00689697265625, 'loss_3': -16.386016845703125, 'loss_4': 0.13453397154808044, 'epoch': 13.29}
{'loss': 0.0149, 'grad_norm': 4.979490756988525, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.005466126371175051, 'loss_2': 0.009429931640625, 'loss_3': -16.240406036376953, 'loss_4': -0.14955371618270874, 'epoch': 13.3}
{'loss': 0.0232, 'grad_norm': 9.802689552307129, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.018427327275276184, 'loss_2': 0.0047454833984375, 'loss_3': -16.303741455078125, 'loss_4': 0.0006208717823028564, 'epoch': 13.3}
{'loss': 0.0133, 'grad_norm': 6.201610088348389, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.011089849285781384, 'loss_2': 0.002178192138671875, 'loss_3': -16.53848648071289, 'loss_4': 0.13926443457603455, 'epoch': 13.31}
{'loss': 0.013, 'grad_norm': 5.1684651374816895, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.005761208478361368, 'loss_2': 0.007232666015625, 'loss_3': -16.22057342529297, 'loss_4': 0.6108723878860474, 'epoch': 13.31}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:14:05,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:05,784 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [56:59<50:24,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:14:13,120 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010566556826233864, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.558, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00749698793515563, 'eval_loss_2': 0.0030695684254169464, 'eval_loss_3': -18.204450607299805, 'eval_loss_4': 0.5286626219749451, 'epoch': 13.31}
{'loss': 0.0311, 'grad_norm': 14.957768440246582, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.02622232399880886, 'loss_2': 0.0048980712890625, 'loss_3': -16.30217742919922, 'loss_4': 0.20921164751052856, 'epoch': 13.32}
{'loss': 0.0135, 'grad_norm': 5.534099578857422, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.01028408668935299, 'loss_2': 0.003253936767578125, 'loss_3': -16.199012756347656, 'loss_4': 0.5440225601196289, 'epoch': 13.33}
{'loss': 0.0131, 'grad_norm': 6.848704814910889, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.005764621775597334, 'loss_2': 0.0073089599609375, 'loss_3': -16.231979370117188, 'loss_4': 0.6742403507232666, 'epoch': 13.33}
{'loss': 0.0367, 'grad_norm': 27.29416847229004, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.034305550158023834, 'loss_2': 0.002361297607421875, 'loss_3': -16.253952026367188, 'loss_4': 0.6493996381759644, 'epoch': 13.34}
{'loss': 0.0209, 'grad_norm': 13.030608177185059, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.017206324264407158, 'loss_2': 0.003692626953125, 'loss_3': -16.25878143310547, 'loss_4': 0.04545310139656067, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 16:14:13,120 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:13,120 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [57:03<50:24,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 16:14:16,919 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2295
[INFO|configuration_utils.py:420] 2025-01-21 16:14:16,920 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2295/config.json                                                                            
{'eval_loss': 0.010113452561199665, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.651, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.007297074422240257, 'eval_loss_2': 0.0028163790702819824, 'eval_loss_3': -18.2066650390625, 'eval_loss_4': 0.46518656611442566, 'epoch': 13.34}
[INFO|modeling_utils.py:2988] 2025-01-21 16:14:17,421 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2295/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:14:17,422 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2295/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:14:17,423 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2295/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:14:18,424 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2285] due to args.save_total_limit
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [57:08<54:58,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:14:22,041 >>
{'loss': 0.007, 'grad_norm': 5.05589485168457, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.005020644515752792, 'loss_2': 0.0019321441650390625, 'loss_3': -16.29512596130371, 'loss_4': 0.5243773460388184, 'epoch': 13.35}
{'loss': 0.009, 'grad_norm': 5.221433162689209, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.006399311125278473, 'loss_2': 0.002643585205078125, 'loss_3': -16.135353088378906, 'loss_4': 0.41891828179359436, 'epoch': 13.35}
{'loss': 0.0253, 'grad_norm': 8.8638277053833, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.018122313544154167, 'loss_2': 0.00722503662109375, 'loss_3': -16.457487106323242, 'loss_4': 0.02812814712524414, 'epoch': 13.36}
{'loss': 0.0096, 'grad_norm': 5.228095531463623, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.00684390589594841, 'loss_2': 0.002780914306640625, 'loss_3': -16.190673828125, 'loss_4': 0.2609713673591614, 'epoch': 13.37}
{'loss': 0.0367, 'grad_norm': 11.680171966552734, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.03376961126923561, 'loss_2': 0.0029392242431640625, 'loss_3': -16.3533878326416, 'loss_4': 0.4712899327278137, 'epoch': 13.37}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:14:22,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:22,041 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [57:15<50:14,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:14:29,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010249222628772259, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.731, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.007192234043031931, 'eval_loss_2': 0.0030569881200790405, 'eval_loss_3': -18.179222106933594, 'eval_loss_4': 0.36718636751174927, 'epoch': 13.37}
{'loss': 0.006, 'grad_norm': 4.832934856414795, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.005470435135066509, 'loss_2': 0.0005464553833007812, 'loss_3': -16.421958923339844, 'loss_4': 0.4924279451370239, 'epoch': 13.38}
{'loss': 0.0171, 'grad_norm': 10.98714542388916, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.01655532978475094, 'loss_2': 0.0005021095275878906, 'loss_3': -16.133880615234375, 'loss_4': 0.42659297585487366, 'epoch': 13.38}
{'loss': 0.0225, 'grad_norm': 8.051551818847656, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.013892961665987968, 'loss_2': 0.00856781005859375, 'loss_3': -16.20459747314453, 'loss_4': 0.4093453586101532, 'epoch': 13.39}
{'loss': 0.0139, 'grad_norm': 7.17333984375, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.012406363151967525, 'loss_2': 0.0015277862548828125, 'loss_3': -16.14263916015625, 'loss_4': 0.46302393078804016, 'epoch': 13.4}
{'loss': 0.0186, 'grad_norm': 5.84660005569458, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.006505358032882214, 'loss_2': 0.01209259033203125, 'loss_3': -16.36578369140625, 'loss_4': -0.23297882080078125, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 16:14:29,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:29,377 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:23<49:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:36,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016749097034335136, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.626, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009593261405825615, 'eval_loss_2': 0.0071558356285095215, 'eval_loss_3': -18.142791748046875, 'eval_loss_4': 0.15480493009090424, 'epoch': 13.4}
{'loss': 0.0114, 'grad_norm': 4.990668296813965, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.004773234017193317, 'loss_2': 0.006641387939453125, 'loss_3': -16.425199508666992, 'loss_4': 0.4326956570148468, 'epoch': 13.41}
{'loss': 0.0093, 'grad_norm': 4.604913234710693, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.0029923825059086084, 'loss_2': 0.00634765625, 'loss_3': -16.441303253173828, 'loss_4': -0.24208100140094757, 'epoch': 13.41}
{'loss': 0.0114, 'grad_norm': 6.1031365394592285, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.010988042689859867, 'loss_2': 0.0003914833068847656, 'loss_3': -16.304630279541016, 'loss_4': -0.06406518816947937, 'epoch': 13.42}
{'loss': 0.0207, 'grad_norm': 8.947592735290527, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.02028716541826725, 'loss_2': 0.0003719329833984375, 'loss_3': -16.246244430541992, 'loss_4': -0.1607944369316101, 'epoch': 13.42}
{'loss': 0.0205, 'grad_norm': 6.752231597900391, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.011820399202406406, 'loss_2': 0.008697509765625, 'loss_3': -16.271406173706055, 'loss_4': 0.21052122116088867, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 16:14:36,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:36,712 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:30<49:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:44,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01550606545060873, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.988, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011264301836490631, 'eval_loss_2': 0.004241764545440674, 'eval_loss_3': -18.123184204101562, 'eval_loss_4': 0.14162060618400574, 'epoch': 13.43}
{'loss': 0.0173, 'grad_norm': 8.145234107971191, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.012187912128865719, 'loss_2': 0.00507354736328125, 'loss_3': -16.273040771484375, 'loss_4': 0.22695258259773254, 'epoch': 13.44}
{'loss': 0.0111, 'grad_norm': 4.718235969543457, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.0049388534389436245, 'loss_2': 0.006175994873046875, 'loss_3': -16.274761199951172, 'loss_4': 0.28304988145828247, 'epoch': 13.44}
{'loss': 0.0082, 'grad_norm': 4.99256706237793, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.005177847575396299, 'loss_2': 0.00305938720703125, 'loss_3': -16.028480529785156, 'loss_4': 0.10003399848937988, 'epoch': 13.45}
{'loss': 0.0459, 'grad_norm': 11.287104606628418, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.03896980360150337, 'loss_2': 0.0068817138671875, 'loss_3': -16.389434814453125, 'loss_4': 0.3227514922618866, 'epoch': 13.45}
{'loss': 0.0181, 'grad_norm': 4.7093729972839355, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.008688947185873985, 'loss_2': 0.00936126708984375, 'loss_3': -16.111196517944336, 'loss_4': 0.2943173348903656, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 16:14:44,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:44,039 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:37<48:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:14:51,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01668679527938366, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.82, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01247922983020544, 'eval_loss_2': 0.0042075663805007935, 'eval_loss_3': -18.106895446777344, 'eval_loss_4': 0.25454190373420715, 'epoch': 13.46}
{'loss': 0.031, 'grad_norm': 12.312275886535645, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.023261021822690964, 'loss_2': 0.007770538330078125, 'loss_3': -16.29762077331543, 'loss_4': 0.4631989896297455, 'epoch': 13.47}
{'loss': 0.017, 'grad_norm': 7.898629188537598, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.01160107459872961, 'loss_2': 0.00539398193359375, 'loss_3': -16.136829376220703, 'loss_4': 0.6002298593521118, 'epoch': 13.47}
{'loss': 0.0225, 'grad_norm': 10.643050193786621, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.02203788422048092, 'loss_2': 0.00047898292541503906, 'loss_3': -16.154083251953125, 'loss_4': 0.015264451503753662, 'epoch': 13.48}
{'loss': 0.0119, 'grad_norm': 5.7135725021362305, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.005501932464540005, 'loss_2': 0.006378173828125, 'loss_3': -16.348663330078125, 'loss_4': 0.018206316977739334, 'epoch': 13.48}
{'loss': 0.0142, 'grad_norm': 9.515091896057129, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.014089698903262615, 'loss_2': 7.76052474975586e-05, 'loss_3': -16.394197463989258, 'loss_4': 0.7978726029396057, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 16:14:51,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:51,367 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:45<48:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:14:58,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01686558499932289, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013771060854196548, 'eval_loss_2': 0.0030945241451263428, 'eval_loss_3': -18.116296768188477, 'eval_loss_4': 0.21322490274906158, 'epoch': 13.49}
{'loss': 0.0227, 'grad_norm': 10.54870891571045, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.01624804176390171, 'loss_2': 0.0064544677734375, 'loss_3': -16.27998161315918, 'loss_4': 0.46528005599975586, 'epoch': 13.49}
{'loss': 0.0126, 'grad_norm': 5.119516372680664, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.007047637365758419, 'loss_2': 0.00551605224609375, 'loss_3': -16.198110580444336, 'loss_4': -0.016556590795516968, 'epoch': 13.5}
{'loss': 0.0145, 'grad_norm': 6.5033040046691895, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.012108518742024899, 'loss_2': 0.0024051666259765625, 'loss_3': -16.131629943847656, 'loss_4': 0.28087764978408813, 'epoch': 13.51}
{'loss': 0.0212, 'grad_norm': 12.991874694824219, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.020336179062724113, 'loss_2': 0.0009088516235351562, 'loss_3': -16.19482421875, 'loss_4': -0.22310416400432587, 'epoch': 13.51}
{'loss': 0.0146, 'grad_norm': 6.034244537353516, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.008667266927659512, 'loss_2': 0.005889892578125, 'loss_3': -16.35316276550293, 'loss_4': -0.15950624644756317, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 16:14:58,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:14:58,704 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:52<48:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:06,036 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016323307529091835, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.739, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012641326524317265, 'eval_loss_2': 0.003681980073451996, 'eval_loss_3': -18.13111686706543, 'eval_loss_4': 0.1266419142484665, 'epoch': 13.52}
{'loss': 0.0298, 'grad_norm': 28.061471939086914, 'learning_rate': 1.65e-05, 'loss_1': 0.022409770637750626, 'loss_2': 0.007354736328125, 'loss_3': -16.299789428710938, 'loss_4': 0.021492697298526764, 'epoch': 13.52}
{'loss': 0.0149, 'grad_norm': 9.087002754211426, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.014549928717315197, 'loss_2': 0.0003070831298828125, 'loss_3': -15.900979995727539, 'loss_4': -0.4448235332965851, 'epoch': 13.53}
{'loss': 0.0473, 'grad_norm': 21.897722244262695, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.04722284525632858, 'loss_2': 7.724761962890625e-05, 'loss_3': -16.495967864990234, 'loss_4': 0.35184094309806824, 'epoch': 13.53}
{'loss': 0.012, 'grad_norm': 5.626786231994629, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.010026717558503151, 'loss_2': 0.0019369125366210938, 'loss_3': -16.365245819091797, 'loss_4': -0.27219411730766296, 'epoch': 13.54}
{'loss': 0.0113, 'grad_norm': 5.10714864730835, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.008093140088021755, 'loss_2': 0.00316619873046875, 'loss_3': -16.29218292236328, 'loss_4': 0.21883390843868256, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 16:15:06,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:06,036 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [57:59<48:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:13,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01390631403774023, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01031689252704382, 'eval_loss_2': 0.003589421510696411, 'eval_loss_3': -18.159896850585938, 'eval_loss_4': 0.06912067532539368, 'epoch': 13.55}
{'loss': 0.0143, 'grad_norm': 5.272710800170898, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.006451369728893042, 'loss_2': 0.007843017578125, 'loss_3': -16.465312957763672, 'loss_4': -0.28596341609954834, 'epoch': 13.55}
{'loss': 0.0116, 'grad_norm': 4.798801898956299, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.010321239940822124, 'loss_2': 0.0013217926025390625, 'loss_3': -16.24046516418457, 'loss_4': 0.6129928827285767, 'epoch': 13.56}
{'loss': 0.0078, 'grad_norm': 11.089432716369629, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.0057106525637209415, 'loss_2': 0.0021114349365234375, 'loss_3': -16.53162384033203, 'loss_4': 0.17145758867263794, 'epoch': 13.56}
{'loss': 0.0422, 'grad_norm': 15.935937881469727, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.03945052996277809, 'loss_2': 0.002704620361328125, 'loss_3': -16.16849136352539, 'loss_4': -0.12911221385002136, 'epoch': 13.57}
{'loss': 0.0107, 'grad_norm': 5.3048553466796875, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.007398922462016344, 'loss_2': 0.003322601318359375, 'loss_3': -16.49193572998047, 'loss_4': 0.14784017205238342, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 16:15:13,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:13,378 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [58:07<48:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:20,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0119499322026968, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009431686252355576, 'eval_loss_2': 0.0025182440876960754, 'eval_loss_3': -18.166139602661133, 'eval_loss_4': 0.22817391157150269, 'epoch': 13.58}
{'loss': 0.0307, 'grad_norm': 7.450590133666992, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.020170053467154503, 'loss_2': 0.010528564453125, 'loss_3': -16.50338363647461, 'loss_4': 0.4234321117401123, 'epoch': 13.58}
{'loss': 0.0197, 'grad_norm': 6.413660526275635, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.01525032427161932, 'loss_2': 0.00447845458984375, 'loss_3': -16.472719192504883, 'loss_4': 0.531995415687561, 'epoch': 13.59}
{'loss': 0.0102, 'grad_norm': 6.240165710449219, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.008376252837479115, 'loss_2': 0.0018291473388671875, 'loss_3': -16.38261604309082, 'loss_4': 0.19955739378929138, 'epoch': 13.59}
{'loss': 0.0155, 'grad_norm': 8.027576446533203, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.013371328823268414, 'loss_2': 0.002170562744140625, 'loss_3': -16.27515411376953, 'loss_4': 0.3737424612045288, 'epoch': 13.6}
{'loss': 0.0164, 'grad_norm': 5.6647257804870605, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.012325681746006012, 'loss_2': 0.004024505615234375, 'loss_3': -16.301433563232422, 'loss_4': 0.23116686940193176, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 16:15:20,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:20,714 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [58:14<48:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:28,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012958444654941559, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.498, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010626903735101223, 'eval_loss_2': 0.0023315399885177612, 'eval_loss_3': -18.13985824584961, 'eval_loss_4': 0.16350163519382477, 'epoch': 13.6}
{'loss': 0.0109, 'grad_norm': 5.600916385650635, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.01076213177293539, 'loss_2': 0.00018286705017089844, 'loss_3': -16.395431518554688, 'loss_4': 0.005072243511676788, 'epoch': 13.61}
{'loss': 0.0088, 'grad_norm': 6.552506923675537, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.007048069499433041, 'loss_2': 0.0017604827880859375, 'loss_3': -16.46710205078125, 'loss_4': -0.30768072605133057, 'epoch': 13.62}
{'loss': 0.0101, 'grad_norm': 7.018806457519531, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.009269499219954014, 'loss_2': 0.000797271728515625, 'loss_3': -16.09774398803711, 'loss_4': -0.12125769257545471, 'epoch': 13.62}
{'loss': 0.0195, 'grad_norm': 7.783823013305664, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.01934714987874031, 'loss_2': 0.0001850128173828125, 'loss_3': -16.362548828125, 'loss_4': -0.15352284908294678, 'epoch': 13.63}
{'loss': 0.0527, 'grad_norm': 17.570802688598633, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.05243607982993126, 'loss_2': 0.0002846717834472656, 'loss_3': -16.24431800842285, 'loss_4': 0.3216334283351898, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 16:15:28,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:28,045 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:21<48:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:35,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014225062914192677, 'eval_runtime': 3.8246, 'eval_samples_per_second': 267.743, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.011746509931981564, 'eval_loss_2': 0.002478554844856262, 'eval_loss_3': -18.128265380859375, 'eval_loss_4': 0.022065769881010056, 'epoch': 13.63}
{'loss': 0.0101, 'grad_norm': 5.9867401123046875, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.009053527377545834, 'loss_2': 0.0010242462158203125, 'loss_3': -16.452388763427734, 'loss_4': 0.41690826416015625, 'epoch': 13.64}
{'loss': 0.0134, 'grad_norm': 6.183379650115967, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.011780536733567715, 'loss_2': 0.0015716552734375, 'loss_3': -16.248493194580078, 'loss_4': -0.2643999457359314, 'epoch': 13.65}
{'loss': 0.0341, 'grad_norm': 16.618656158447266, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.026529068127274513, 'loss_2': 0.00753021240234375, 'loss_3': -16.31886100769043, 'loss_4': 0.17307962477207184, 'epoch': 13.65}
{'loss': 0.0229, 'grad_norm': 5.8036627769470215, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.01242886297404766, 'loss_2': 0.010498046875, 'loss_3': -16.316059112548828, 'loss_4': -0.13141760230064392, 'epoch': 13.66}
{'loss': 0.0149, 'grad_norm': 6.643316268920898, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.008633413352072239, 'loss_2': 0.006221771240234375, 'loss_3': -16.348440170288086, 'loss_4': -0.24093769490718842, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 16:15:35,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:35,404 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:29<48:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:42,739 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012132665142416954, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.845, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010306168347597122, 'eval_loss_2': 0.0018264949321746826, 'eval_loss_3': -18.129106521606445, 'eval_loss_4': -0.035281404852867126, 'epoch': 13.66}
{'loss': 0.013, 'grad_norm': 5.4717512130737305, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.007685099262744188, 'loss_2': 0.00533294677734375, 'loss_3': -16.366498947143555, 'loss_4': 0.1552550196647644, 'epoch': 13.67}
{'loss': 0.0101, 'grad_norm': 5.811115741729736, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.008068457245826721, 'loss_2': 0.00202178955078125, 'loss_3': -16.39175796508789, 'loss_4': -0.013533562421798706, 'epoch': 13.67}
{'loss': 0.0118, 'grad_norm': 4.687032222747803, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.00563190458342433, 'loss_2': 0.0062103271484375, 'loss_3': -16.428707122802734, 'loss_4': 0.3696821928024292, 'epoch': 13.68}
{'loss': 0.0087, 'grad_norm': 5.178469181060791, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.008195390924811363, 'loss_2': 0.0005469322204589844, 'loss_3': -16.355911254882812, 'loss_4': 0.2060551941394806, 'epoch': 13.69}
{'loss': 0.0104, 'grad_norm': 5.116778373718262, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.005693676415830851, 'loss_2': 0.0047454833984375, 'loss_3': -16.298114776611328, 'loss_4': -0.32390666007995605, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 16:15:42,739 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:42,739 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:36<49:02,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:15:50,272 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014623095281422138, 'eval_runtime': 3.9914, 'eval_samples_per_second': 256.551, 'eval_steps_per_second': 4.009, 'eval_loss_1': 0.009775926358997822, 'eval_loss_2': 0.004847168922424316, 'eval_loss_3': -18.157747268676758, 'eval_loss_4': 0.07134908437728882, 'epoch': 13.69}
{'loss': 0.0186, 'grad_norm': 6.192526340484619, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.01654374599456787, 'loss_2': 0.0020599365234375, 'loss_3': -16.192493438720703, 'loss_4': 0.1896011233329773, 'epoch': 13.7}
{'loss': 0.0181, 'grad_norm': 6.808990955352783, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.01450930256396532, 'loss_2': 0.003589630126953125, 'loss_3': -16.344608306884766, 'loss_4': -0.20785054564476013, 'epoch': 13.7}
{'loss': 0.0162, 'grad_norm': 6.3127007484436035, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.008630339056253433, 'loss_2': 0.00760650634765625, 'loss_3': -16.452381134033203, 'loss_4': 0.05993938446044922, 'epoch': 13.71}
{'loss': 0.0175, 'grad_norm': 7.238734245300293, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.015066605061292648, 'loss_2': 0.0024261474609375, 'loss_3': -16.53732681274414, 'loss_4': -0.42321211099624634, 'epoch': 13.72}
{'loss': 0.0193, 'grad_norm': 6.134152889251709, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.010429863817989826, 'loss_2': 0.0088958740234375, 'loss_3': -16.42190170288086, 'loss_4': -0.034691840410232544, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 16:15:50,272 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:50,272 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:44<48:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:15:57,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012526653707027435, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.099, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009862257167696953, 'eval_loss_2': 0.0026643946766853333, 'eval_loss_3': -18.192913055419922, 'eval_loss_4': -0.008038584142923355, 'epoch': 13.72}
{'loss': 0.0081, 'grad_norm': 4.7042670249938965, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.004617044702172279, 'loss_2': 0.003482818603515625, 'loss_3': -16.24786376953125, 'loss_4': 0.027315258979797363, 'epoch': 13.73}
{'loss': 0.007, 'grad_norm': 5.715491771697998, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.005462516099214554, 'loss_2': 0.001499176025390625, 'loss_3': -16.323034286499023, 'loss_4': 0.48818153142929077, 'epoch': 13.73}
{'loss': 0.0135, 'grad_norm': 5.332015037536621, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.009753995575010777, 'loss_2': 0.003757476806640625, 'loss_3': -16.4136962890625, 'loss_4': -0.00360126793384552, 'epoch': 13.74}
{'loss': 0.0078, 'grad_norm': 4.543095111846924, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.006212389562278986, 'loss_2': 0.001598358154296875, 'loss_3': -16.445390701293945, 'loss_4': -0.1734355092048645, 'epoch': 13.74}
{'loss': 0.0145, 'grad_norm': 5.501403331756592, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.008621694520115852, 'loss_2': 0.0058441162109375, 'loss_3': -16.327342987060547, 'loss_4': -0.17742198705673218, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 16:15:57,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:15:57,621 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:51<48:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:04,968 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01446329616010189, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.303, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010644159279763699, 'eval_loss_2': 0.0038191378116607666, 'eval_loss_3': -18.206615447998047, 'eval_loss_4': -0.1791796088218689, 'epoch': 13.75}
{'loss': 0.0103, 'grad_norm': 5.454838752746582, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.009310164488852024, 'loss_2': 0.0010280609130859375, 'loss_3': -16.396648406982422, 'loss_4': -0.25953319668769836, 'epoch': 13.76}
{'loss': 0.0167, 'grad_norm': 6.169722557067871, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.014189873822033405, 'loss_2': 0.00247955322265625, 'loss_3': -16.427398681640625, 'loss_4': -0.14732225239276886, 'epoch': 13.76}
{'loss': 0.0138, 'grad_norm': 5.170806407928467, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.006311848293989897, 'loss_2': 0.0074462890625, 'loss_3': -16.489124298095703, 'loss_4': 0.36874938011169434, 'epoch': 13.77}
{'loss': 0.091, 'grad_norm': 37.846012115478516, 'learning_rate': 1.625e-05, 'loss_1': 0.08057969063520432, 'loss_2': 0.0104522705078125, 'loss_3': -16.605175018310547, 'loss_4': 0.5165912508964539, 'epoch': 13.77}
{'loss': 0.023, 'grad_norm': 12.608596801757812, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.02119126170873642, 'loss_2': 0.001766204833984375, 'loss_3': -16.47827911376953, 'loss_4': -0.2953447103500366, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 16:16:04,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:04,968 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [58:58<48:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:12,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017633821815252304, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.686, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011140965856611729, 'eval_loss_2': 0.0064928531646728516, 'eval_loss_3': -18.207000732421875, 'eval_loss_4': -0.35214006900787354, 'epoch': 13.78}
{'loss': 0.0176, 'grad_norm': 9.797122955322266, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.013613163493573666, 'loss_2': 0.0039825439453125, 'loss_3': -16.399566650390625, 'loss_4': -0.4775168299674988, 'epoch': 13.78}
{'loss': 0.0216, 'grad_norm': 7.572648525238037, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.01342410035431385, 'loss_2': 0.0081939697265625, 'loss_3': -16.389616012573242, 'loss_4': -0.4197179079055786, 'epoch': 13.79}
{'loss': 0.0187, 'grad_norm': 6.803047180175781, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.00915354210883379, 'loss_2': 0.00951385498046875, 'loss_3': -16.536243438720703, 'loss_4': -0.5037637948989868, 'epoch': 13.8}
{'loss': 0.0106, 'grad_norm': 5.854912281036377, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.010371900163590908, 'loss_2': 0.00027751922607421875, 'loss_3': -16.416954040527344, 'loss_4': -0.2713038921356201, 'epoch': 13.8}
{'loss': 0.0166, 'grad_norm': 5.691539287567139, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.009356717579066753, 'loss_2': 0.00727081298828125, 'loss_3': -16.501916885375977, 'loss_4': -0.5983476638793945, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 16:16:12,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:12,307 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [59:06<48:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:19,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019862964749336243, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.371, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012682036496698856, 'eval_loss_2': 0.007180929183959961, 'eval_loss_3': -18.207563400268555, 'eval_loss_4': -0.49963152408599854, 'epoch': 13.81}
{'loss': 0.0263, 'grad_norm': 8.428560256958008, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.025276167318224907, 'loss_2': 0.001041412353515625, 'loss_3': -16.225767135620117, 'loss_4': -0.04281284660100937, 'epoch': 13.81}
{'loss': 0.0214, 'grad_norm': 11.403615951538086, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.017322193831205368, 'loss_2': 0.004119873046875, 'loss_3': -16.350017547607422, 'loss_4': -0.44202351570129395, 'epoch': 13.82}
{'loss': 0.0242, 'grad_norm': 6.977059841156006, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.01636454276740551, 'loss_2': 0.007843017578125, 'loss_3': -16.332111358642578, 'loss_4': -0.41375815868377686, 'epoch': 13.83}
{'loss': 0.0318, 'grad_norm': 11.724467277526855, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.026546616107225418, 'loss_2': 0.0052642822265625, 'loss_3': -16.422901153564453, 'loss_4': -0.35312384366989136, 'epoch': 13.83}
{'loss': 0.0294, 'grad_norm': 16.215974807739258, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.0280477125197649, 'loss_2': 0.00133514404296875, 'loss_3': -16.395782470703125, 'loss_4': -0.6755645275115967, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 16:16:19,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:19,655 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [59:13<47:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:26,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014922112226486206, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.456, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012698640115559101, 'eval_loss_2': 0.0022234730422496796, 'eval_loss_3': -18.2231388092041, 'eval_loss_4': -0.5755010843276978, 'epoch': 13.84}
{'loss': 0.0229, 'grad_norm': 10.773497581481934, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.02001768723130226, 'loss_2': 0.0029239654541015625, 'loss_3': -16.60061264038086, 'loss_4': -0.42740392684936523, 'epoch': 13.84}
{'loss': 0.0283, 'grad_norm': 13.449335098266602, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.024286527186632156, 'loss_2': 0.00403594970703125, 'loss_3': -16.437946319580078, 'loss_4': -0.19991283118724823, 'epoch': 13.85}
{'loss': 0.0255, 'grad_norm': 5.582440376281738, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.012399732135236263, 'loss_2': 0.0130615234375, 'loss_3': -16.6226749420166, 'loss_4': -0.5049809217453003, 'epoch': 13.85}
{'loss': 0.0391, 'grad_norm': 16.40632438659668, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.037299562245607376, 'loss_2': 0.0017566680908203125, 'loss_3': -16.422504425048828, 'loss_4': -0.5828272104263306, 'epoch': 13.86}
{'loss': 0.0194, 'grad_norm': 9.858622550964355, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.01865171268582344, 'loss_2': 0.00074005126953125, 'loss_3': -16.291528701782227, 'loss_4': -0.5824901461601257, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 16:16:26,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:26,995 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:20<47:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:34,333 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01575392484664917, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.899, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013329311273992062, 'eval_loss_2': 0.0024246126413345337, 'eval_loss_3': -18.216787338256836, 'eval_loss_4': -0.6095308065414429, 'epoch': 13.87}
{'loss': 0.0365, 'grad_norm': 19.33653450012207, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.034474752843379974, 'loss_2': 0.001979827880859375, 'loss_3': -16.288625717163086, 'loss_4': -1.0206365585327148, 'epoch': 13.87}
{'loss': 0.0122, 'grad_norm': 5.6297101974487305, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.0108296237885952, 'loss_2': 0.001331329345703125, 'loss_3': -16.408971786499023, 'loss_4': -0.7389110326766968, 'epoch': 13.88}
{'loss': 0.0122, 'grad_norm': 6.376347541809082, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.01200728677213192, 'loss_2': 0.0001577138900756836, 'loss_3': -16.512374877929688, 'loss_4': -0.3978897035121918, 'epoch': 13.88}
{'loss': 0.0122, 'grad_norm': 5.520424842834473, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.006451508030295372, 'loss_2': 0.005725860595703125, 'loss_3': -16.500036239624023, 'loss_4': -0.9544375538825989, 'epoch': 13.89}
{'loss': 0.0419, 'grad_norm': 18.630966186523438, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.03673473373055458, 'loss_2': 0.005207061767578125, 'loss_3': -16.479354858398438, 'loss_4': -0.8187333345413208, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 16:16:34,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:34,334 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:28<47:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:41,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015501982532441616, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.485, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012762301601469517, 'eval_loss_2': 0.0027396827936172485, 'eval_loss_3': -18.2294921875, 'eval_loss_4': -0.6448029279708862, 'epoch': 13.9}
{'loss': 0.0172, 'grad_norm': 5.2987895011901855, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.012714440934360027, 'loss_2': 0.00445556640625, 'loss_3': -16.399417877197266, 'loss_4': -0.8627858757972717, 'epoch': 13.9}
{'loss': 0.0289, 'grad_norm': 9.731274604797363, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.025989001616835594, 'loss_2': 0.0029010772705078125, 'loss_3': -16.492820739746094, 'loss_4': -0.6850529313087463, 'epoch': 13.91}
{'loss': 0.0125, 'grad_norm': 4.775668621063232, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.005792954470962286, 'loss_2': 0.00670623779296875, 'loss_3': -16.554523468017578, 'loss_4': -0.7230285406112671, 'epoch': 13.91}
{'loss': 0.0178, 'grad_norm': 5.216283798217773, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.012462116777896881, 'loss_2': 0.00531768798828125, 'loss_3': -16.390626907348633, 'loss_4': -0.5662976503372192, 'epoch': 13.92}
{'loss': 0.0152, 'grad_norm': 6.1887969970703125, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.010949448682367802, 'loss_2': 0.004276275634765625, 'loss_3': -16.58295440673828, 'loss_4': -0.679951548576355, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 16:16:41,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:41,670 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:35<47:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:49,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01990463025867939, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.439, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.013999836519360542, 'eval_loss_2': 0.005904793739318848, 'eval_loss_3': -18.212543487548828, 'eval_loss_4': -0.6990450620651245, 'epoch': 13.92}
{'loss': 0.0176, 'grad_norm': 6.798188209533691, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.011049519293010235, 'loss_2': 0.0065765380859375, 'loss_3': -16.74497413635254, 'loss_4': -0.7977246046066284, 'epoch': 13.93}
{'loss': 0.0282, 'grad_norm': 16.771757125854492, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.02791357785463333, 'loss_2': 0.000247955322265625, 'loss_3': -16.481658935546875, 'loss_4': -0.6805999875068665, 'epoch': 13.94}
{'loss': 0.016, 'grad_norm': 5.567342281341553, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.011202379129827023, 'loss_2': 0.00484466552734375, 'loss_3': -16.61126708984375, 'loss_4': -0.9171212911605835, 'epoch': 13.94}
{'loss': 0.0098, 'grad_norm': 5.089578151702881, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.008071397431194782, 'loss_2': 0.00177001953125, 'loss_3': -16.441808700561523, 'loss_4': -0.729579508304596, 'epoch': 13.95}
{'loss': 0.0172, 'grad_norm': 9.523948669433594, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.014062991365790367, 'loss_2': 0.00313568115234375, 'loss_3': -16.547489166259766, 'loss_4': -0.9466696977615356, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 16:16:49,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:49,011 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:42<47:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:16:56,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022710584104061127, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01998373493552208, 'eval_loss_2': 0.0027268528938293457, 'eval_loss_3': -18.141494750976562, 'eval_loss_4': -0.5743170976638794, 'epoch': 13.95}
{'loss': 0.0187, 'grad_norm': 6.133002758026123, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.013904464431107044, 'loss_2': 0.00476837158203125, 'loss_3': -16.51083755493164, 'loss_4': -0.5711998343467712, 'epoch': 13.96}
{'loss': 0.0135, 'grad_norm': 9.191577911376953, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.012389597482979298, 'loss_2': 0.0011205673217773438, 'loss_3': -16.422134399414062, 'loss_4': -0.2919153571128845, 'epoch': 13.97}
{'loss': 0.01, 'grad_norm': 5.335766315460205, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.008528430014848709, 'loss_2': 0.0014600753784179688, 'loss_3': -16.26806640625, 'loss_4': -0.7857593297958374, 'epoch': 13.97}
{'loss': 0.0126, 'grad_norm': 6.988972187042236, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.01011943630874157, 'loss_2': 0.0025177001953125, 'loss_3': -16.47332000732422, 'loss_4': -0.5986433625221252, 'epoch': 13.98}
{'loss': 0.0179, 'grad_norm': 10.620349884033203, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.01498851552605629, 'loss_2': 0.00289154052734375, 'loss_3': -16.448322296142578, 'loss_4': -0.475185751914978, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 16:16:56,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:16:56,353 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:49<45:37,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 16:17:03,387 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0378759428858757, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.492, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.03234230354428291, 'eval_loss_2': 0.00553363561630249, 'eval_loss_3': -18.10231590270996, 'eval_loss_4': -0.3199678659439087, 'epoch': 13.98}
{'loss': 0.0269, 'grad_norm': 7.602156162261963, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.018245751038193703, 'loss_2': 0.00862884521484375, 'loss_3': -16.435606002807617, 'loss_4': 0.06310013681650162, 'epoch': 13.99}
{'loss': 0.0314, 'grad_norm': 7.589181423187256, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.023104440420866013, 'loss_2': 0.008331298828125, 'loss_3': -16.601673126220703, 'loss_4': -0.015921078622341156, 'epoch': 13.99}
{'loss': 0.0124, 'grad_norm': 8.112908363342285, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.009747889824211597, 'loss_2': 0.002655029296875, 'loss_3': -16.71049690246582, 'loss_4': 0.4906468093395233, 'epoch': 14.0}
{'loss': 0.0261, 'grad_norm': 8.167973518371582, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.018602950498461723, 'loss_2': 0.007511138916015625, 'loss_3': -16.54857063293457, 'loss_4': 0.07282455265522003, 'epoch': 14.01}
{'loss': 0.0498, 'grad_norm': 17.879146575927734, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.047167956829071045, 'loss_2': 0.0025844573974609375, 'loss_3': -16.323915481567383, 'loss_4': -0.05127554386854172, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 16:17:03,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:03,388 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 2415/5160 [59:57<47:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:17:10,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04589229077100754, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.042049750685691833, 'eval_loss_2': 0.0038425400853157043, 'eval_loss_3': -18.052854537963867, 'eval_loss_4': -0.011760039255023003, 'epoch': 14.01}
{'loss': 0.0175, 'grad_norm': 5.148460865020752, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.010087722912430763, 'loss_2': 0.0074005126953125, 'loss_3': -16.342689514160156, 'loss_4': -0.31891492009162903, 'epoch': 14.02}
{'loss': 0.0104, 'grad_norm': 5.551097869873047, 'learning_rate': 1.6e-05, 'loss_1': 0.006803393363952637, 'loss_2': 0.003620147705078125, 'loss_3': -16.312217712402344, 'loss_4': 0.16764096915721893, 'epoch': 14.02}
{'loss': 0.025, 'grad_norm': 14.506266593933105, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.024421870708465576, 'loss_2': 0.0006270408630371094, 'loss_3': -16.5664119720459, 'loss_4': -0.07634319365024567, 'epoch': 14.03}
{'loss': 0.0127, 'grad_norm': 4.845911026000977, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.00856371782720089, 'loss_2': 0.00409698486328125, 'loss_3': -16.475215911865234, 'loss_4': 0.49459126591682434, 'epoch': 14.03}
{'loss': 0.0297, 'grad_norm': 12.24283218383789, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.02447461523115635, 'loss_2': 0.00527191162109375, 'loss_3': -16.44951820373535, 'loss_4': 0.179066464304924, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 16:17:10,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:10,727 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                    | 2420/5160 [1:00:04<47:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:18,070 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04329472780227661, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.040192022919654846, 'eval_loss_2': 0.003102704882621765, 'eval_loss_3': -18.02903938293457, 'eval_loss_4': 0.10027321428060532, 'epoch': 14.04}
{'loss': 0.0476, 'grad_norm': 11.513043403625488, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.045089736580848694, 'loss_2': 0.00251007080078125, 'loss_3': -16.361574172973633, 'loss_4': -0.11497750878334045, 'epoch': 14.05}
{'loss': 0.0135, 'grad_norm': 6.623250961303711, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.011296205222606659, 'loss_2': 0.00218963623046875, 'loss_3': -16.422271728515625, 'loss_4': 0.007968708872795105, 'epoch': 14.05}
{'loss': 0.0239, 'grad_norm': 7.101629257202148, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.016701487824320793, 'loss_2': 0.00716400146484375, 'loss_3': -16.43932342529297, 'loss_4': 0.628348171710968, 'epoch': 14.06}
{'loss': 0.0212, 'grad_norm': 7.219736576080322, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.015590347349643707, 'loss_2': 0.00565338134765625, 'loss_3': -16.185855865478516, 'loss_4': -0.33451929688453674, 'epoch': 14.06}
{'loss': 0.0176, 'grad_norm': 13.562336921691895, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.015254686586558819, 'loss_2': 0.00232696533203125, 'loss_3': -16.00752067565918, 'loss_4': 0.04468512535095215, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 16:17:18,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:18,070 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 2425/5160 [1:00:12<47:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:25,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03566669672727585, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.265, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.032378263771533966, 'eval_loss_2': 0.0032884329557418823, 'eval_loss_3': -18.079669952392578, 'eval_loss_4': 0.08764120191335678, 'epoch': 14.07}
{'loss': 0.0113, 'grad_norm': 7.033339977264404, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.010280811227858067, 'loss_2': 0.001010894775390625, 'loss_3': -16.28388214111328, 'loss_4': -0.4135788679122925, 'epoch': 14.08}
{'loss': 0.024, 'grad_norm': 9.30396556854248, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.01904532127082348, 'loss_2': 0.00499725341796875, 'loss_3': -16.428607940673828, 'loss_4': -0.043463945388793945, 'epoch': 14.08}
{'loss': 0.0471, 'grad_norm': 10.887600898742676, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.03468235582113266, 'loss_2': 0.01238250732421875, 'loss_3': -16.45992088317871, 'loss_4': 0.2848275303840637, 'epoch': 14.09}
{'loss': 0.0306, 'grad_norm': 12.920201301574707, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.02026861160993576, 'loss_2': 0.01029205322265625, 'loss_3': -16.619497299194336, 'loss_4': -0.19202573597431183, 'epoch': 14.09}
{'loss': 0.0079, 'grad_norm': 4.629647254943848, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.003878243500366807, 'loss_2': 0.0040130615234375, 'loss_3': -16.500465393066406, 'loss_4': 0.17147895693778992, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 16:17:25,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:25,418 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:19<47:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:32,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015033215284347534, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.229, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011774793267250061, 'eval_loss_2': 0.003258422017097473, 'eval_loss_3': -18.17849349975586, 'eval_loss_4': -0.021965352818369865, 'epoch': 14.1}
{'loss': 0.09, 'grad_norm': 11.936721801757812, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.08336447179317474, 'loss_2': 0.0066375732421875, 'loss_3': -16.461122512817383, 'loss_4': 0.4170510172843933, 'epoch': 14.1}
{'loss': 0.0203, 'grad_norm': 6.069272518157959, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.01296776533126831, 'loss_2': 0.007282257080078125, 'loss_3': -16.33652114868164, 'loss_4': -0.008155934512615204, 'epoch': 14.11}
{'loss': 0.013, 'grad_norm': 6.648913860321045, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.010701688937842846, 'loss_2': 0.00232696533203125, 'loss_3': -16.59641456604004, 'loss_4': 0.007118344306945801, 'epoch': 14.12}
{'loss': 0.0138, 'grad_norm': 5.833074569702148, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.009831249713897705, 'loss_2': 0.0040130615234375, 'loss_3': -16.52419662475586, 'loss_4': -0.37236541509628296, 'epoch': 14.12}
{'loss': 0.0162, 'grad_norm': 9.639031410217285, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.013166566379368305, 'loss_2': 0.0030498504638671875, 'loss_3': -16.310972213745117, 'loss_4': 0.01588054746389389, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 16:17:32,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:32,756 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:26<46:55,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:17:40,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011471877805888653, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.31, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008290055207908154, 'eval_loss_2': 0.0031818225979804993, 'eval_loss_3': -18.20737648010254, 'eval_loss_4': -0.07422024756669998, 'epoch': 14.13}
{'loss': 0.0065, 'grad_norm': 10.349600791931152, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.004088022746145725, 'loss_2': 0.0023899078369140625, 'loss_3': -16.49764060974121, 'loss_4': -0.1568729728460312, 'epoch': 14.13}
{'loss': 0.0084, 'grad_norm': 6.882707595825195, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.008307634852826595, 'loss_2': 4.738569259643555e-05, 'loss_3': -16.446449279785156, 'loss_4': -0.04544396698474884, 'epoch': 14.14}
{'loss': 0.0223, 'grad_norm': inf, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.019925814121961594, 'loss_2': 0.0023345947265625, 'loss_3': -16.428863525390625, 'loss_4': -0.19847917556762695, 'epoch': 14.15}
{'loss': 0.0199, 'grad_norm': 9.612990379333496, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.019061243161559105, 'loss_2': 0.000789642333984375, 'loss_3': -16.46401023864746, 'loss_4': 0.4107586741447449, 'epoch': 14.15}
{'loss': 0.01, 'grad_norm': 5.322305202484131, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.00817329902201891, 'loss_2': 0.0018644332885742188, 'loss_3': -16.313636779785156, 'loss_4': 0.35072651505470276, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 16:17:40,078 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:40,078 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:34<47:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:47,427 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010779233649373055, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.121, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0076359948143363, 'eval_loss_2': 0.0031432397663593292, 'eval_loss_3': -18.20711898803711, 'eval_loss_4': 0.0028687380254268646, 'epoch': 14.16}
{'loss': 0.0142, 'grad_norm': 5.422424793243408, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.01126475352793932, 'loss_2': 0.00289154052734375, 'loss_3': -16.42925262451172, 'loss_4': -0.04815337061882019, 'epoch': 14.16}
{'loss': 0.0135, 'grad_norm': 5.926963806152344, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.012243803590536118, 'loss_2': 0.0012760162353515625, 'loss_3': -16.279203414916992, 'loss_4': -0.08982512354850769, 'epoch': 14.17}
{'loss': 0.0188, 'grad_norm': 9.821953773498535, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.01819288730621338, 'loss_2': 0.0006227493286132812, 'loss_3': -16.609384536743164, 'loss_4': 0.013219743967056274, 'epoch': 14.17}
{'loss': 0.0131, 'grad_norm': 8.10704517364502, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.011844699271023273, 'loss_2': 0.0012121200561523438, 'loss_3': -16.37836265563965, 'loss_4': -0.13971596956253052, 'epoch': 14.18}
{'loss': 0.023, 'grad_norm': 9.431380271911621, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.02049611136317253, 'loss_2': 0.0025157928466796875, 'loss_3': -16.33177947998047, 'loss_4': 0.2682257890701294, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 16:17:47,427 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:47,427 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:41<46:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:17:54,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010713160037994385, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.899, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007269085384905338, 'eval_loss_2': 0.003444075584411621, 'eval_loss_3': -18.225528717041016, 'eval_loss_4': 0.20313379168510437, 'epoch': 14.19}
{'loss': 0.0188, 'grad_norm': 7.805365562438965, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.018241435289382935, 'loss_2': 0.0005960464477539062, 'loss_3': -16.555749893188477, 'loss_4': 0.08293122053146362, 'epoch': 14.19}
{'loss': 0.006, 'grad_norm': 4.567961692810059, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.00563570111989975, 'loss_2': 0.0004031658172607422, 'loss_3': -16.365028381347656, 'loss_4': -0.26625052094459534, 'epoch': 14.2}
{'loss': 0.0131, 'grad_norm': 7.781064987182617, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.010104444809257984, 'loss_2': 0.003025054931640625, 'loss_3': -16.42917823791504, 'loss_4': 0.3050510287284851, 'epoch': 14.2}
{'loss': 0.0139, 'grad_norm': 7.023526668548584, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.013207054696977139, 'loss_2': 0.0006732940673828125, 'loss_3': -16.224239349365234, 'loss_4': 0.6485055685043335, 'epoch': 14.21}
{'loss': 0.0213, 'grad_norm': 8.355826377868652, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.012992204166948795, 'loss_2': 0.00827789306640625, 'loss_3': -16.098026275634766, 'loss_4': 0.465560644865036, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 16:17:54,772 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:17:54,772 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:48<46:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:02,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012724697589874268, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.585, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00750958826392889, 'eval_loss_2': 0.005215108394622803, 'eval_loss_3': -18.22671890258789, 'eval_loss_4': 0.267049640417099, 'epoch': 14.22}
{'loss': 0.0131, 'grad_norm': 5.339461326599121, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.00630920147523284, 'loss_2': 0.006744384765625, 'loss_3': -16.349292755126953, 'loss_4': 0.5900782346725464, 'epoch': 14.22}
{'loss': 0.0211, 'grad_norm': 5.733123302459717, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.00953030027449131, 'loss_2': 0.0115966796875, 'loss_3': -16.188373565673828, 'loss_4': 0.37877827882766724, 'epoch': 14.23}
{'loss': 0.0155, 'grad_norm': 5.771066665649414, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.012837152928113937, 'loss_2': 0.0026702880859375, 'loss_3': -16.143550872802734, 'loss_4': 0.21561941504478455, 'epoch': 14.23}
{'loss': 0.0176, 'grad_norm': 6.925363063812256, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.015157114714384079, 'loss_2': 0.002483367919921875, 'loss_3': -16.356216430664062, 'loss_4': 0.8211949467658997, 'epoch': 14.24}
{'loss': 0.0159, 'grad_norm': 5.33064079284668, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.009788364171981812, 'loss_2': 0.006145477294921875, 'loss_3': -16.46573257446289, 'loss_4': 0.3621363043785095, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 16:18:02,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:02,110 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:56<46:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:09,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012514663860201836, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.376, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007621836848556995, 'eval_loss_2': 0.004892826080322266, 'eval_loss_3': -18.24489974975586, 'eval_loss_4': 0.33632081747055054, 'epoch': 14.24}
{'loss': 0.0175, 'grad_norm': 5.895155906677246, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.01166638731956482, 'loss_2': 0.00579071044921875, 'loss_3': -16.149261474609375, 'loss_4': -0.2770027220249176, 'epoch': 14.25}
{'loss': 0.0076, 'grad_norm': 4.616377830505371, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.005193725228309631, 'loss_2': 0.002414703369140625, 'loss_3': -16.14521026611328, 'loss_4': 0.426932156085968, 'epoch': 14.26}
{'loss': 0.0424, 'grad_norm': 16.016815185546875, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.033808086067438126, 'loss_2': 0.008636474609375, 'loss_3': -16.549196243286133, 'loss_4': 0.2393711507320404, 'epoch': 14.26}
{'loss': 0.0227, 'grad_norm': 8.050553321838379, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.01066025160253048, 'loss_2': 0.01200103759765625, 'loss_3': -16.485334396362305, 'loss_4': 0.6306828260421753, 'epoch': 14.27}
{'loss': 0.01, 'grad_norm': 5.948814868927002, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.007892167195677757, 'loss_2': 0.0020599365234375, 'loss_3': -16.551280975341797, 'loss_4': 0.3450359106063843, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 16:18:09,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:09,449 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:01:03<46:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:16,790 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011000432074069977, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0077758124098181725, 'eval_loss_2': 0.0032246187329292297, 'eval_loss_3': -18.238996505737305, 'eval_loss_4': 0.4187784492969513, 'epoch': 14.27}
{'loss': 0.0239, 'grad_norm': 20.32095718383789, 'learning_rate': 1.575e-05, 'loss_1': 0.022339798510074615, 'loss_2': 0.0015783309936523438, 'loss_3': -16.413110733032227, 'loss_4': 0.7409422397613525, 'epoch': 14.28}
{'loss': 0.0286, 'grad_norm': 12.987462997436523, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.023933351039886475, 'loss_2': 0.004695892333984375, 'loss_3': -16.456863403320312, 'loss_4': 0.1486552655696869, 'epoch': 14.28}
{'loss': 0.0154, 'grad_norm': 7.161509037017822, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.010234643705189228, 'loss_2': 0.005157470703125, 'loss_3': -16.524642944335938, 'loss_4': 0.25361257791519165, 'epoch': 14.29}
{'loss': 0.0177, 'grad_norm': 7.318904876708984, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.017247967422008514, 'loss_2': 0.0004773139953613281, 'loss_3': -16.19890594482422, 'loss_4': 0.10892481356859207, 'epoch': 14.3}
{'loss': 0.0061, 'grad_norm': 4.894841194152832, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.0055896504782140255, 'loss_2': 0.0004851818084716797, 'loss_3': -16.41659927368164, 'loss_4': 0.29662197828292847, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 16:18:16,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:16,790 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:01:10<46:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:24,123 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012878955341875553, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.565, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008678706362843513, 'eval_loss_2': 0.004200249910354614, 'eval_loss_3': -18.22447395324707, 'eval_loss_4': 0.3988626301288605, 'epoch': 14.3}
{'loss': 0.0289, 'grad_norm': 7.9436936378479, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.022841645404696465, 'loss_2': 0.0060882568359375, 'loss_3': -16.499431610107422, 'loss_4': 0.08614464104175568, 'epoch': 14.31}
{'loss': 0.0265, 'grad_norm': 11.447687149047852, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.015234682708978653, 'loss_2': 0.0112457275390625, 'loss_3': -16.576932907104492, 'loss_4': 0.4277365803718567, 'epoch': 14.31}
{'loss': 0.0072, 'grad_norm': 5.156100749969482, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.006890032906085253, 'loss_2': 0.0003027915954589844, 'loss_3': -16.289844512939453, 'loss_4': -0.0921855941414833, 'epoch': 14.32}
{'loss': 0.0148, 'grad_norm': 7.743502140045166, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.012636520899832249, 'loss_2': 0.002117156982421875, 'loss_3': -16.483915328979492, 'loss_4': 0.619134247303009, 'epoch': 14.33}
{'loss': 0.0283, 'grad_norm': 7.7647705078125, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.020228110253810883, 'loss_2': 0.008026123046875, 'loss_3': -16.333759307861328, 'loss_4': 0.4945002496242523, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 16:18:24,123 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:24,123 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:01:18<46:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:31,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011172614060342312, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.344, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008451034314930439, 'eval_loss_2': 0.0027215778827667236, 'eval_loss_3': -18.23501968383789, 'eval_loss_4': 0.2966119647026062, 'epoch': 14.33}
{'loss': 0.0153, 'grad_norm': 6.357232093811035, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.01134671550244093, 'loss_2': 0.0039215087890625, 'loss_3': -16.414501190185547, 'loss_4': 0.017299219965934753, 'epoch': 14.34}
{'loss': 0.0147, 'grad_norm': 9.052294731140137, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.01335623674094677, 'loss_2': 0.00136566162109375, 'loss_3': -16.277725219726562, 'loss_4': 0.28550755977630615, 'epoch': 14.34}
{'loss': 0.0248, 'grad_norm': 7.851767063140869, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.01910717785358429, 'loss_2': 0.00566864013671875, 'loss_3': -16.640268325805664, 'loss_4': 0.40459951758384705, 'epoch': 14.35}
{'loss': 0.0105, 'grad_norm': 4.619790077209473, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.005079314578324556, 'loss_2': 0.005462646484375, 'loss_3': -16.31157684326172, 'loss_4': 0.09957882761955261, 'epoch': 14.35}
{'loss': 0.0069, 'grad_norm': 5.018335342407227, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.005900687072426081, 'loss_2': 0.00098419189453125, 'loss_3': -16.171588897705078, 'loss_4': 0.12846998870372772, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 16:18:31,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:31,469 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:25<46:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:38,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014737425372004509, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00959333498030901, 'eval_loss_2': 0.005144089460372925, 'eval_loss_3': -18.217220306396484, 'eval_loss_4': 0.08833108842372894, 'epoch': 14.36}
{'loss': 0.0205, 'grad_norm': 7.500701427459717, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.016787344589829445, 'loss_2': 0.0036830902099609375, 'loss_3': -16.316497802734375, 'loss_4': -0.11716979742050171, 'epoch': 14.37}
{'loss': 0.0163, 'grad_norm': 5.050293922424316, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.006990103982388973, 'loss_2': 0.00933837890625, 'loss_3': -16.355266571044922, 'loss_4': -0.04381301999092102, 'epoch': 14.37}
{'loss': 0.0221, 'grad_norm': 8.878994941711426, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.017623374238610268, 'loss_2': 0.0045013427734375, 'loss_3': -16.424484252929688, 'loss_4': 0.49153077602386475, 'epoch': 14.38}
{'loss': 0.0048, 'grad_norm': 4.987926483154297, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.0027029458433389664, 'loss_2': 0.00209808349609375, 'loss_3': -16.463855743408203, 'loss_4': 0.06668823212385178, 'epoch': 14.38}
{'loss': 0.0127, 'grad_norm': 5.241800785064697, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.00540476618334651, 'loss_2': 0.00725555419921875, 'loss_3': -16.323823928833008, 'loss_4': -0.018954701721668243, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 16:18:38,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:38,809 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:32<46:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:46,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013203449547290802, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.495, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009122171439230442, 'eval_loss_2': 0.004081279039382935, 'eval_loss_3': -18.203960418701172, 'eval_loss_4': 0.011699922382831573, 'epoch': 14.39}
{'loss': 0.0142, 'grad_norm': 5.711654186248779, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.01111521478742361, 'loss_2': 0.003101348876953125, 'loss_3': -16.32142448425293, 'loss_4': 0.011270135641098022, 'epoch': 14.4}
{'loss': 0.0106, 'grad_norm': 4.522583484649658, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.00950669590383768, 'loss_2': 0.0010576248168945312, 'loss_3': -16.24847412109375, 'loss_4': -0.019156739115715027, 'epoch': 14.4}
{'loss': 0.0093, 'grad_norm': 4.5987396240234375, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.006255284883081913, 'loss_2': 0.0030040740966796875, 'loss_3': -16.339134216308594, 'loss_4': 0.264110803604126, 'epoch': 14.41}
{'loss': 0.0263, 'grad_norm': 8.742714881896973, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.018979793414473534, 'loss_2': 0.00733184814453125, 'loss_3': -16.36746597290039, 'loss_4': -0.19898097217082977, 'epoch': 14.41}
{'loss': 0.0077, 'grad_norm': 4.583528995513916, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.0073562851175665855, 'loss_2': 0.0003304481506347656, 'loss_3': -16.37794303894043, 'loss_4': -0.17469507455825806, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 16:18:46,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:46,146 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:40<46:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:18:53,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014683777466416359, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.38, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010663405992090702, 'eval_loss_2': 0.004020370543003082, 'eval_loss_3': -18.209949493408203, 'eval_loss_4': -0.1277834177017212, 'epoch': 14.42}
{'loss': 0.0216, 'grad_norm': 9.789789199829102, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.01691872999072075, 'loss_2': 0.004673004150390625, 'loss_3': -16.526212692260742, 'loss_4': 0.17439579963684082, 'epoch': 14.42}
{'loss': 0.0235, 'grad_norm': 7.1046342849731445, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.01239754818379879, 'loss_2': 0.0110626220703125, 'loss_3': -16.458110809326172, 'loss_4': -0.0819464847445488, 'epoch': 14.43}
{'loss': 0.0259, 'grad_norm': 6.904325008392334, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.012675575911998749, 'loss_2': 0.013214111328125, 'loss_3': -16.354127883911133, 'loss_4': -0.07986560463905334, 'epoch': 14.44}
{'loss': 0.0366, 'grad_norm': 11.505202293395996, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.0329713299870491, 'loss_2': 0.0035858154296875, 'loss_3': -16.2586669921875, 'loss_4': -0.156002938747406, 'epoch': 14.44}
{'loss': 0.0168, 'grad_norm': 20.11688804626465, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.014158394187688828, 'loss_2': 0.002620697021484375, 'loss_3': -16.458667755126953, 'loss_4': 0.14926090836524963, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 16:18:53,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:18:53,487 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:47<46:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:00,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016981281340122223, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009773768484592438, 'eval_loss_2': 0.007207512855529785, 'eval_loss_3': -18.210941314697266, 'eval_loss_4': -0.07327651977539062, 'epoch': 14.45}
{'loss': 0.0076, 'grad_norm': 4.919018268585205, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.004678707104176283, 'loss_2': 0.0029087066650390625, 'loss_3': -16.342178344726562, 'loss_4': 0.3327922821044922, 'epoch': 14.45}
{'loss': 0.017, 'grad_norm': 5.7925214767456055, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.015946708619594574, 'loss_2': 0.001041412353515625, 'loss_3': -16.30314826965332, 'loss_4': -0.05100741982460022, 'epoch': 14.46}
{'loss': 0.0204, 'grad_norm': 5.440639495849609, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.00790249090641737, 'loss_2': 0.0124664306640625, 'loss_3': -16.44021987915039, 'loss_4': -0.03366422653198242, 'epoch': 14.47}
{'loss': 0.0128, 'grad_norm': 8.4518404006958, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.011510479263961315, 'loss_2': 0.0012950897216796875, 'loss_3': -16.360143661499023, 'loss_4': -0.24444451928138733, 'epoch': 14.47}
{'loss': 0.0352, 'grad_norm': 10.69649600982666, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.030806681141257286, 'loss_2': 0.00439453125, 'loss_3': -16.326425552368164, 'loss_4': 0.40140751004219055, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 16:19:00,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:00,828 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:54<46:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:08,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013338737189769745, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.793, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009709440171718597, 'eval_loss_2': 0.0036292970180511475, 'eval_loss_3': -18.199264526367188, 'eval_loss_4': 0.03945356607437134, 'epoch': 14.48}
{'loss': 0.0163, 'grad_norm': 5.938432216644287, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.014267969876527786, 'loss_2': 0.0020122528076171875, 'loss_3': -16.34549331665039, 'loss_4': 0.1633703112602234, 'epoch': 14.48}
{'loss': 0.032, 'grad_norm': 17.829992294311523, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.028133897110819817, 'loss_2': 0.003833770751953125, 'loss_3': -16.247119903564453, 'loss_4': 0.6213266849517822, 'epoch': 14.49}
{'loss': 0.0143, 'grad_norm': 4.797613620758057, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.007147568743675947, 'loss_2': 0.007106781005859375, 'loss_3': -16.146026611328125, 'loss_4': -0.06757695972919464, 'epoch': 14.49}
{'loss': 0.0074, 'grad_norm': 5.041990756988525, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.0049169594421982765, 'loss_2': 0.00243377685546875, 'loss_3': -16.452085494995117, 'loss_4': 0.31181600689888, 'epoch': 14.5}
{'loss': 0.0112, 'grad_norm': 6.252141952514648, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.010094929486513138, 'loss_2': 0.0011377334594726562, 'loss_3': -16.32509994506836, 'loss_4': -0.016911938786506653, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 16:19:08,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:08,175 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:02:02<45:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:15,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012866058386862278, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.336, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009566105902194977, 'eval_loss_2': 0.0032999515533447266, 'eval_loss_3': -18.20664405822754, 'eval_loss_4': 0.1106421947479248, 'epoch': 14.51}
{'loss': 0.0273, 'grad_norm': 21.004056930541992, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.026809433475136757, 'loss_2': 0.0005087852478027344, 'loss_3': -16.124675750732422, 'loss_4': -0.0737554281949997, 'epoch': 14.51}
{'loss': 0.0139, 'grad_norm': 5.990206241607666, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.012297444976866245, 'loss_2': 0.0015888214111328125, 'loss_3': -16.356639862060547, 'loss_4': 0.14486458897590637, 'epoch': 14.52}
{'loss': 0.0158, 'grad_norm': 5.640012264251709, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.012843608856201172, 'loss_2': 0.0029621124267578125, 'loss_3': -16.173080444335938, 'loss_4': 0.020287618041038513, 'epoch': 14.52}
{'loss': 0.0163, 'grad_norm': 9.9923734664917, 'learning_rate': 1.55e-05, 'loss_1': 0.015137754380702972, 'loss_2': 0.0011320114135742188, 'loss_3': -16.252174377441406, 'loss_4': -0.14837142825126648, 'epoch': 14.53}
{'loss': 0.0065, 'grad_norm': 4.280247688293457, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.004193502012640238, 'loss_2': 0.002315521240234375, 'loss_3': -16.405208587646484, 'loss_4': 0.06429404765367508, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 16:19:15,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:15,517 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:02:09<45:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:22,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012868329882621765, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.761, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.00996418297290802, 'eval_loss_2': 0.002904146909713745, 'eval_loss_3': -18.215381622314453, 'eval_loss_4': 0.10787739604711533, 'epoch': 14.53}
{'loss': 0.0172, 'grad_norm': 8.527688026428223, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.011423933319747448, 'loss_2': 0.00580596923828125, 'loss_3': -16.308002471923828, 'loss_4': -0.2971608340740204, 'epoch': 14.54}
{'loss': 0.0131, 'grad_norm': 4.845732688903809, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.007599796634167433, 'loss_2': 0.0054931640625, 'loss_3': -16.413677215576172, 'loss_4': 0.44439244270324707, 'epoch': 14.55}
{'loss': 0.0161, 'grad_norm': 11.57291316986084, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.014674948528409004, 'loss_2': 0.001377105712890625, 'loss_3': -16.22456169128418, 'loss_4': 0.612185001373291, 'epoch': 14.55}
{'loss': 0.0115, 'grad_norm': 4.79506778717041, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.005838586483150721, 'loss_2': 0.005615234375, 'loss_3': -16.321125030517578, 'loss_4': 0.3413904309272766, 'epoch': 14.56}
{'loss': 0.022, 'grad_norm': 4.876459121704102, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.013820420019328594, 'loss_2': 0.0082244873046875, 'loss_3': -16.235477447509766, 'loss_4': 0.02102040871977806, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 16:19:22,847 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:22,847 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:02:16<45:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:30,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014326710253953934, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.405, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011391940526664257, 'eval_loss_2': 0.002934768795967102, 'eval_loss_3': -18.216035842895508, 'eval_loss_4': 0.19751307368278503, 'epoch': 14.56}
{'loss': 0.0073, 'grad_norm': 4.944070339202881, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.005262960679829121, 'loss_2': 0.002071380615234375, 'loss_3': -16.226350784301758, 'loss_4': 0.28423964977264404, 'epoch': 14.57}
{'loss': 0.0437, 'grad_norm': 20.74176597595215, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.035872019827365875, 'loss_2': 0.0078582763671875, 'loss_3': -16.384563446044922, 'loss_4': 0.3322378396987915, 'epoch': 14.58}
{'loss': 0.0116, 'grad_norm': 4.687359809875488, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.008721563033759594, 'loss_2': 0.00284576416015625, 'loss_3': -16.423742294311523, 'loss_4': 0.4271630048751831, 'epoch': 14.58}
{'loss': 0.0153, 'grad_norm': 5.031151294708252, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.007874243892729282, 'loss_2': 0.007415771484375, 'loss_3': -16.25143814086914, 'loss_4': 0.30872586369514465, 'epoch': 14.59}
{'loss': 0.0122, 'grad_norm': 5.2743072509765625, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.009977204725146294, 'loss_2': 0.0022125244140625, 'loss_3': -16.41278839111328, 'loss_4': 0.37569668889045715, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 16:19:30,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:30,185 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:24<45:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:37,528 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01474294625222683, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012104743160307407, 'eval_loss_2': 0.0026382021605968475, 'eval_loss_3': -18.199323654174805, 'eval_loss_4': 0.2527252733707428, 'epoch': 14.59}
{'loss': 0.0198, 'grad_norm': 8.949344635009766, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.01323652733117342, 'loss_2': 0.00658416748046875, 'loss_3': -16.33515167236328, 'loss_4': 0.5203777551651001, 'epoch': 14.6}
{'loss': 0.0113, 'grad_norm': 5.374316215515137, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.00546777481213212, 'loss_2': 0.005828857421875, 'loss_3': -16.676551818847656, 'loss_4': 0.03825807943940163, 'epoch': 14.6}
{'loss': 0.0217, 'grad_norm': 6.532018661499023, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.013248524628579617, 'loss_2': 0.008453369140625, 'loss_3': -16.493549346923828, 'loss_4': 0.17460958659648895, 'epoch': 14.61}
{'loss': 0.0176, 'grad_norm': 4.747583389282227, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.009750578552484512, 'loss_2': 0.0078582763671875, 'loss_3': -16.36994171142578, 'loss_4': 0.20545852184295654, 'epoch': 14.62}
{'loss': 0.019, 'grad_norm': 5.309639930725098, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.010725529864430428, 'loss_2': 0.00829315185546875, 'loss_3': -16.425857543945312, 'loss_4': 0.12768368422985077, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 16:19:37,528 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:37,528 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:31<45:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:44,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014844462275505066, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.131, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011976958252489567, 'eval_loss_2': 0.0028675049543380737, 'eval_loss_3': -18.212501525878906, 'eval_loss_4': 0.25694411993026733, 'epoch': 14.62}
{'loss': 0.025, 'grad_norm': 8.751228332519531, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.016568530350923538, 'loss_2': 0.0084075927734375, 'loss_3': -16.447105407714844, 'loss_4': 0.42730486392974854, 'epoch': 14.63}
{'loss': 0.0111, 'grad_norm': 5.9703288078308105, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.01106706541031599, 'loss_2': 7.033348083496094e-05, 'loss_3': -16.535655975341797, 'loss_4': 0.2929348945617676, 'epoch': 14.63}
{'loss': 0.0193, 'grad_norm': 4.844875335693359, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.006468973588198423, 'loss_2': 0.01287841796875, 'loss_3': -16.47504997253418, 'loss_4': 0.2502749562263489, 'epoch': 14.64}
{'loss': 0.0095, 'grad_norm': 4.8932600021362305, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.005385547876358032, 'loss_2': 0.004154205322265625, 'loss_3': -16.552101135253906, 'loss_4': -0.04358528554439545, 'epoch': 14.65}
{'loss': 0.0243, 'grad_norm': 8.075751304626465, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.02111709676682949, 'loss_2': 0.00318145751953125, 'loss_3': -16.3834228515625, 'loss_4': 0.2141323685646057, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 16:19:44,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:44,873 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:38<45:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:52,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01519390381872654, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.003, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011495763435959816, 'eval_loss_2': 0.0036981403827667236, 'eval_loss_3': -18.222332000732422, 'eval_loss_4': 0.2559252977371216, 'epoch': 14.65}
{'loss': 0.0152, 'grad_norm': 7.872036457061768, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.012751777656376362, 'loss_2': 0.002490997314453125, 'loss_3': -16.35096549987793, 'loss_4': 0.011747531592845917, 'epoch': 14.66}
{'loss': 0.0318, 'grad_norm': 12.255620002746582, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.027480103075504303, 'loss_2': 0.004302978515625, 'loss_3': -16.665409088134766, 'loss_4': 0.03806053847074509, 'epoch': 14.66}
{'loss': 0.022, 'grad_norm': 12.730761528015137, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.020577315241098404, 'loss_2': 0.0014362335205078125, 'loss_3': -16.40797996520996, 'loss_4': 0.3007931113243103, 'epoch': 14.67}
{'loss': 0.0109, 'grad_norm': 5.40764856338501, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.010267327539622784, 'loss_2': 0.00063323974609375, 'loss_3': -16.625829696655273, 'loss_4': 0.4516488015651703, 'epoch': 14.67}
{'loss': 0.0175, 'grad_norm': 6.3191237449646, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.013020426966249943, 'loss_2': 0.004436492919921875, 'loss_3': -16.2957706451416, 'loss_4': -0.3028831481933594, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 16:19:52,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:52,220 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:46<45:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:19:59,558 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01428619958460331, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.625, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011169948615133762, 'eval_loss_2': 0.0031162500381469727, 'eval_loss_3': -18.200185775756836, 'eval_loss_4': 0.3400706648826599, 'epoch': 14.68}
{'loss': 0.0313, 'grad_norm': 25.51082992553711, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.030827488750219345, 'loss_2': 0.0005054473876953125, 'loss_3': -16.397361755371094, 'loss_4': 0.49920034408569336, 'epoch': 14.69}
{'loss': 0.0107, 'grad_norm': 5.332186222076416, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.007747132796794176, 'loss_2': 0.0029773712158203125, 'loss_3': -16.494020462036133, 'loss_4': 0.8585425615310669, 'epoch': 14.69}
{'loss': 0.0174, 'grad_norm': 6.832417011260986, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.01088554784655571, 'loss_2': 0.006511688232421875, 'loss_3': -16.2701416015625, 'loss_4': 0.352287232875824, 'epoch': 14.7}
{'loss': 0.0182, 'grad_norm': 8.684520721435547, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.015540232881903648, 'loss_2': 0.002704620361328125, 'loss_3': -16.643577575683594, 'loss_4': 0.4385800361633301, 'epoch': 14.7}
{'loss': 0.0099, 'grad_norm': 4.6631059646606445, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.006906162481755018, 'loss_2': 0.002971649169921875, 'loss_3': -16.383743286132812, 'loss_4': 0.6730725169181824, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 16:19:59,558 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:19:59,558 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:53<45:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:06,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016802845522761345, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.602, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012880876660346985, 'eval_loss_2': 0.003921970725059509, 'eval_loss_3': -18.192890167236328, 'eval_loss_4': 0.5134837031364441, 'epoch': 14.71}
{'loss': 0.0108, 'grad_norm': 5.191971778869629, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.00831293873488903, 'loss_2': 0.002536773681640625, 'loss_3': -16.538467407226562, 'loss_4': 0.743048369884491, 'epoch': 14.72}
{'loss': 0.0135, 'grad_norm': 7.75813627243042, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.013372646644711494, 'loss_2': 9.21487808227539e-05, 'loss_3': -16.37343978881836, 'loss_4': 0.5070244669914246, 'epoch': 14.72}
{'loss': 0.0154, 'grad_norm': 6.016557693481445, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.0077973622828722, 'loss_2': 0.00762176513671875, 'loss_3': -16.515138626098633, 'loss_4': 0.5205237865447998, 'epoch': 14.73}
{'loss': 0.0069, 'grad_norm': 4.274878978729248, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.003286750754341483, 'loss_2': 0.003574371337890625, 'loss_3': -16.687496185302734, 'loss_4': 0.7818900346755981, 'epoch': 14.73}
{'loss': 0.0205, 'grad_norm': 8.77536392211914, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.012233210727572441, 'loss_2': 0.00830078125, 'loss_3': -16.408727645874023, 'loss_4': 0.46570491790771484, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 16:20:06,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:06,891 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:03:00<45:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:14,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015635810792446136, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.673, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.012448573485016823, 'eval_loss_2': 0.003187239170074463, 'eval_loss_3': -18.165605545043945, 'eval_loss_4': 0.6748462319374084, 'epoch': 14.74}
{'loss': 0.0248, 'grad_norm': 8.869345664978027, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.02209092490375042, 'loss_2': 0.002750396728515625, 'loss_3': -16.37456703186035, 'loss_4': 0.6205953359603882, 'epoch': 14.74}
{'loss': 0.0183, 'grad_norm': 8.608291625976562, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.016048194840550423, 'loss_2': 0.002277374267578125, 'loss_3': -16.40902328491211, 'loss_4': 0.9270464777946472, 'epoch': 14.75}
{'loss': 0.0157, 'grad_norm': 5.375654220581055, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.010032212361693382, 'loss_2': 0.0056915283203125, 'loss_3': -16.433456420898438, 'loss_4': 0.6607848405838013, 'epoch': 14.76}
{'loss': 0.0164, 'grad_norm': 5.785548686981201, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.011498548090457916, 'loss_2': 0.00487518310546875, 'loss_3': -16.393308639526367, 'loss_4': 1.2815965414047241, 'epoch': 14.76}
{'loss': 0.0084, 'grad_norm': 4.213286876678467, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.005510860588401556, 'loss_2': 0.0028553009033203125, 'loss_3': -16.58424949645996, 'loss_4': 1.0293900966644287, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 16:20:14,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:14,228 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:03:08<45:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:21,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016394492238759995, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.56, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.013078583404421806, 'eval_loss_2': 0.0033159106969833374, 'eval_loss_3': -18.14400863647461, 'eval_loss_4': 0.8460005521774292, 'epoch': 14.77}
{'loss': 0.1104, 'grad_norm': 18.747610092163086, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.1092299297451973, 'loss_2': 0.0012073516845703125, 'loss_3': -16.58869171142578, 'loss_4': 1.6388019323349, 'epoch': 14.77}
{'loss': 0.0084, 'grad_norm': 4.6596598625183105, 'learning_rate': 1.525e-05, 'loss_1': 0.0067628659307956696, 'loss_2': 0.001605987548828125, 'loss_3': -16.24858856201172, 'loss_4': 0.6802047491073608, 'epoch': 14.78}
{'loss': 0.0122, 'grad_norm': 5.0270233154296875, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.00996517762541771, 'loss_2': 0.002246856689453125, 'loss_3': -16.378984451293945, 'loss_4': 0.8255377411842346, 'epoch': 14.78}
{'loss': 0.0308, 'grad_norm': 7.762346267700195, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.026005854830145836, 'loss_2': 0.004825592041015625, 'loss_3': -16.238449096679688, 'loss_4': 1.128331184387207, 'epoch': 14.79}
{'loss': 0.0081, 'grad_norm': 4.55795955657959, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.0062273056246340275, 'loss_2': 0.0019130706787109375, 'loss_3': -16.350852966308594, 'loss_4': 0.5348345041275024, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 16:20:21,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:21,568 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:03:15<45:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:28,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02028261125087738, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.958, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013429448939859867, 'eval_loss_2': 0.006853163242340088, 'eval_loss_3': -18.133010864257812, 'eval_loss_4': 0.926753044128418, 'epoch': 14.8}
{'loss': 0.0152, 'grad_norm': 5.708971977233887, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.00948580726981163, 'loss_2': 0.005733489990234375, 'loss_3': -16.38839340209961, 'loss_4': 0.7967754006385803, 'epoch': 14.8}
{'loss': 0.0191, 'grad_norm': 6.161792278289795, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.013391216285526752, 'loss_2': 0.0057373046875, 'loss_3': -16.53058433532715, 'loss_4': 0.8207046985626221, 'epoch': 14.81}
{'loss': 0.0178, 'grad_norm': 5.858926773071289, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.009091576561331749, 'loss_2': 0.00865936279296875, 'loss_3': -16.529052734375, 'loss_4': 0.9905213117599487, 'epoch': 14.81}
{'loss': 0.0217, 'grad_norm': 5.965424537658691, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.011956460773944855, 'loss_2': 0.00971221923828125, 'loss_3': -16.497833251953125, 'loss_4': 0.7855627536773682, 'epoch': 14.82}
{'loss': 0.0126, 'grad_norm': 4.980710983276367, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.004527946002781391, 'loss_2': 0.0080413818359375, 'loss_3': -16.403392791748047, 'loss_4': 1.1292892694473267, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 16:20:28,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:28,917 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:22<45:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:36,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018856801092624664, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.353, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012862205505371094, 'eval_loss_2': 0.0059945955872535706, 'eval_loss_3': -18.11549186706543, 'eval_loss_4': 0.9467301368713379, 'epoch': 14.83}
{'loss': 0.0213, 'grad_norm': 5.848700046539307, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.013872992247343063, 'loss_2': 0.0074005126953125, 'loss_3': -16.42630386352539, 'loss_4': 1.334563136100769, 'epoch': 14.83}
{'loss': 0.017, 'grad_norm': 7.007919788360596, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.012579141184687614, 'loss_2': 0.00439453125, 'loss_3': -16.428136825561523, 'loss_4': 0.9481483101844788, 'epoch': 14.84}
{'loss': 0.0096, 'grad_norm': 6.361263751983643, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.008467530831694603, 'loss_2': 0.0011157989501953125, 'loss_3': -16.28403091430664, 'loss_4': 0.9900282025337219, 'epoch': 14.84}
{'loss': 0.0199, 'grad_norm': 5.598023414611816, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.010393194854259491, 'loss_2': 0.0094757080078125, 'loss_3': -16.381967544555664, 'loss_4': 1.473253846168518, 'epoch': 14.85}
{'loss': 0.0232, 'grad_norm': 8.683334350585938, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.022094860672950745, 'loss_2': 0.00109100341796875, 'loss_3': -16.328407287597656, 'loss_4': 0.8274563550949097, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 16:20:36,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:36,260 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:30<44:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:43,600 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01489247940480709, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.451, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010044116526842117, 'eval_loss_2': 0.004848361015319824, 'eval_loss_3': -18.112030029296875, 'eval_loss_4': 0.9728116393089294, 'epoch': 14.85}
{'loss': 0.0087, 'grad_norm': 5.780407428741455, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.007348232436925173, 'loss_2': 0.001361846923828125, 'loss_3': -16.460800170898438, 'loss_4': 0.7764937877655029, 'epoch': 14.86}
{'loss': 0.0258, 'grad_norm': 6.256107330322266, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.013822823762893677, 'loss_2': 0.01201629638671875, 'loss_3': -16.28350257873535, 'loss_4': 0.9477062225341797, 'epoch': 14.87}
{'loss': 0.0119, 'grad_norm': 7.913781642913818, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.007048654370009899, 'loss_2': 0.00487518310546875, 'loss_3': -16.347143173217773, 'loss_4': 0.640273928642273, 'epoch': 14.87}
{'loss': 0.0707, 'grad_norm': 17.285158157348633, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.06852295994758606, 'loss_2': 0.00212860107421875, 'loss_3': -16.144941329956055, 'loss_4': 0.889329195022583, 'epoch': 14.88}
{'loss': 0.0237, 'grad_norm': 6.283496856689453, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.01263434998691082, 'loss_2': 0.01103973388671875, 'loss_3': -16.33633041381836, 'loss_4': 1.2008790969848633, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 16:20:43,600 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:43,600 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:37<44:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:50,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01325787790119648, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00941661186516285, 'eval_loss_2': 0.0038412660360336304, 'eval_loss_3': -18.102964401245117, 'eval_loss_4': 0.978139340877533, 'epoch': 14.88}
{'loss': 0.0098, 'grad_norm': 4.892589569091797, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.006114255636930466, 'loss_2': 0.0036468505859375, 'loss_3': -16.45982551574707, 'loss_4': 0.7492918968200684, 'epoch': 14.89}
{'loss': 0.0113, 'grad_norm': 4.50363826751709, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.007818921469151974, 'loss_2': 0.0035228729248046875, 'loss_3': -16.26189613342285, 'loss_4': 0.6346052885055542, 'epoch': 14.9}
{'loss': 0.0174, 'grad_norm': 5.339698791503906, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.01493813842535019, 'loss_2': 0.002498626708984375, 'loss_3': -16.073535919189453, 'loss_4': 1.0381317138671875, 'epoch': 14.9}
{'loss': 0.0188, 'grad_norm': 5.750680446624756, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.013263811357319355, 'loss_2': 0.00557708740234375, 'loss_3': -16.340076446533203, 'loss_4': 1.0734171867370605, 'epoch': 14.91}
{'loss': 0.0154, 'grad_norm': 5.517199516296387, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.008120344020426273, 'loss_2': 0.00727081298828125, 'loss_3': -16.413928985595703, 'loss_4': 1.0061936378479004, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 16:20:50,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:50,938 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:44<44:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:20:58,274 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013983451761305332, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.687, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009177529253065586, 'eval_loss_2': 0.004805922508239746, 'eval_loss_3': -18.11354637145996, 'eval_loss_4': 1.1810542345046997, 'epoch': 14.91}
{'loss': 0.0152, 'grad_norm': 9.333650588989258, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.014775692485272884, 'loss_2': 0.0004105567932128906, 'loss_3': -16.343017578125, 'loss_4': 1.259005069732666, 'epoch': 14.92}
{'loss': 0.0094, 'grad_norm': 5.874354839324951, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.007998748682439327, 'loss_2': 0.0013742446899414062, 'loss_3': -16.346641540527344, 'loss_4': 1.2041560411453247, 'epoch': 14.92}
{'loss': 0.0209, 'grad_norm': 8.984375, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.01817411556839943, 'loss_2': 0.0027332305908203125, 'loss_3': -16.298009872436523, 'loss_4': 0.7501070499420166, 'epoch': 14.93}
{'loss': 0.0343, 'grad_norm': 12.815935134887695, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.032687123864889145, 'loss_2': 0.001598358154296875, 'loss_3': -16.261554718017578, 'loss_4': 1.3999972343444824, 'epoch': 14.94}
{'loss': 0.0258, 'grad_norm': 10.419398307800293, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.023561861366033554, 'loss_2': 0.002254486083984375, 'loss_3': -16.3505859375, 'loss_4': 1.4547487497329712, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 16:20:58,274 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:20:58,274 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:52<44:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:05,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01577383652329445, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.801, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009435014799237251, 'eval_loss_2': 0.006338819861412048, 'eval_loss_3': -18.13650131225586, 'eval_loss_4': 1.171012043952942, 'epoch': 14.94}
{'loss': 0.0333, 'grad_norm': 10.366155624389648, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.02324591763317585, 'loss_2': 0.0100250244140625, 'loss_3': -16.256072998046875, 'loss_4': 0.8712424039840698, 'epoch': 14.95}
{'loss': 0.0235, 'grad_norm': 7.464850425720215, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.010817674919962883, 'loss_2': 0.0126953125, 'loss_3': -16.19322395324707, 'loss_4': 1.781672716140747, 'epoch': 14.95}
{'loss': 0.0128, 'grad_norm': 5.484206199645996, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.008193328976631165, 'loss_2': 0.0046539306640625, 'loss_3': -16.099536895751953, 'loss_4': 1.1585066318511963, 'epoch': 14.96}
{'loss': 0.0181, 'grad_norm': 4.793726444244385, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.009492672048509121, 'loss_2': 0.00858306884765625, 'loss_3': -16.278249740600586, 'loss_4': 1.5505704879760742, 'epoch': 14.97}
{'loss': 0.0171, 'grad_norm': 6.764479160308838, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.012413040734827518, 'loss_2': 0.00466156005859375, 'loss_3': -16.410289764404297, 'loss_4': 1.3449186086654663, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 16:21:05,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:05,624 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:03:59<40:05,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 16:21:12,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013775019906461239, 'eval_runtime': 3.7944, 'eval_samples_per_second': 269.868, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.009466124698519707, 'eval_loss_2': 0.0043088942766189575, 'eval_loss_3': -18.121952056884766, 'eval_loss_4': 1.146702766418457, 'epoch': 14.97}
{'loss': 0.0134, 'grad_norm': 7.479043960571289, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.01259550265967846, 'loss_2': 0.0008230209350585938, 'loss_3': -16.182498931884766, 'loss_4': 1.0565458536148071, 'epoch': 14.98}
{'loss': 0.0425, 'grad_norm': 17.1203556060791, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.03913968801498413, 'loss_2': 0.003360748291015625, 'loss_3': -16.16079330444336, 'loss_4': 1.3740465641021729, 'epoch': 14.98}
{'loss': 0.027, 'grad_norm': 15.51130199432373, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.021997394040226936, 'loss_2': 0.0049591064453125, 'loss_3': -16.36832046508789, 'loss_4': 1.280139446258545, 'epoch': 14.99}
{'loss': 0.0112, 'grad_norm': 4.722203254699707, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.009338418021798134, 'loss_2': 0.0019063949584960938, 'loss_3': -16.356489181518555, 'loss_4': 0.9598230719566345, 'epoch': 14.99}
{'loss': 0.0044, 'grad_norm': 6.958755016326904, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.004387806635349989, 'loss_2': 1.3947486877441406e-05, 'loss_3': -16.02903938293457, 'loss_4': 0.7286442518234253, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 16:21:12,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:12,607 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:04:06<43:51,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:21:19,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014399782754480839, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.018, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010471627116203308, 'eval_loss_2': 0.003928154706954956, 'eval_loss_3': -18.114994049072266, 'eval_loss_4': 1.1012823581695557, 'epoch': 15.0}
{'loss': 0.0076, 'grad_norm': 5.406412601470947, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.007433826569467783, 'loss_2': 0.00020194053649902344, 'loss_3': -16.18899917602539, 'loss_4': 0.9496238231658936, 'epoch': 15.01}
{'loss': 0.026, 'grad_norm': 8.889999389648438, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.025076372548937798, 'loss_2': 0.0009632110595703125, 'loss_3': -16.363292694091797, 'loss_4': 1.4018911123275757, 'epoch': 15.01}
{'loss': 0.0099, 'grad_norm': 4.580650806427002, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.006227944511920214, 'loss_2': 0.003711700439453125, 'loss_3': -16.459671020507812, 'loss_4': 1.572482943534851, 'epoch': 15.02}
{'loss': 0.0269, 'grad_norm': 11.222390174865723, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.021697502583265305, 'loss_2': 0.00522613525390625, 'loss_3': -16.14209747314453, 'loss_4': 0.8261613249778748, 'epoch': 15.02}
{'loss': 0.019, 'grad_norm': 6.104623794555664, 'learning_rate': 1.5e-05, 'loss_1': 0.011202475987374783, 'loss_2': 0.0078125, 'loss_3': -16.243364334106445, 'loss_4': 1.7157750129699707, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 16:21:19,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:19,990 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:04:13<44:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:21:27,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015810677781701088, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.524, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011380779556930065, 'eval_loss_2': 0.004429899156093597, 'eval_loss_3': -18.103731155395508, 'eval_loss_4': 0.8944491147994995, 'epoch': 15.03}
{'loss': 0.0087, 'grad_norm': 4.880221366882324, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.008173597976565361, 'loss_2': 0.0005092620849609375, 'loss_3': -16.270320892333984, 'loss_4': 0.6793097257614136, 'epoch': 15.03}
{'loss': 0.0155, 'grad_norm': 4.90600061416626, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.0068021006882190704, 'loss_2': 0.00870513916015625, 'loss_3': -16.434106826782227, 'loss_4': 0.9577047824859619, 'epoch': 15.04}
{'loss': 0.0288, 'grad_norm': 9.254542350769043, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.022632790729403496, 'loss_2': 0.00614166259765625, 'loss_3': -16.189495086669922, 'loss_4': 1.4516539573669434, 'epoch': 15.05}
{'loss': 0.0263, 'grad_norm': 8.3230619430542, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.018589235842227936, 'loss_2': 0.00774383544921875, 'loss_3': -16.025480270385742, 'loss_4': 1.206108570098877, 'epoch': 15.05}
{'loss': 0.0251, 'grad_norm': 6.971266269683838, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.01061150524765253, 'loss_2': 0.0145111083984375, 'loss_3': -16.22330665588379, 'loss_4': 1.0335041284561157, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 16:21:27,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:27,329 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:21<44:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:34,673 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013507825322449207, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01042474526911974, 'eval_loss_2': 0.0030830800533294678, 'eval_loss_3': -18.112966537475586, 'eval_loss_4': 0.8765925168991089, 'epoch': 15.06}
{'loss': 0.0205, 'grad_norm': 6.525280475616455, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.010647001676261425, 'loss_2': 0.00983428955078125, 'loss_3': -16.18460464477539, 'loss_4': 0.4803144633769989, 'epoch': 15.06}
{'loss': 0.0217, 'grad_norm': 8.390273094177246, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.015583809465169907, 'loss_2': 0.006114959716796875, 'loss_3': -16.14519691467285, 'loss_4': 0.7452523708343506, 'epoch': 15.07}
{'loss': 0.0099, 'grad_norm': 4.68168830871582, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.005185912828892469, 'loss_2': 0.004673004150390625, 'loss_3': -16.340187072753906, 'loss_4': 0.852546215057373, 'epoch': 15.08}
{'loss': 0.0297, 'grad_norm': 8.565542221069336, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.026090599596500397, 'loss_2': 0.003604888916015625, 'loss_3': -16.329845428466797, 'loss_4': 0.8301957249641418, 'epoch': 15.08}
{'loss': 0.0152, 'grad_norm': 9.093320846557617, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.014601651579141617, 'loss_2': 0.0005869865417480469, 'loss_3': -16.409652709960938, 'loss_4': 1.0510706901550293, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 16:21:34,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:34,674 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:28<44:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:42,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014515695162117481, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.653, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01090693287551403, 'eval_loss_2': 0.0036087632179260254, 'eval_loss_3': -18.104782104492188, 'eval_loss_4': 0.9385843276977539, 'epoch': 15.09}
{'loss': 0.0112, 'grad_norm': 5.076197147369385, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.0077349115163087845, 'loss_2': 0.0034770965576171875, 'loss_3': -16.33256721496582, 'loss_4': 1.0408246517181396, 'epoch': 15.09}
{'loss': 0.009, 'grad_norm': 5.499636650085449, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.00795043632388115, 'loss_2': 0.0010833740234375, 'loss_3': -16.182708740234375, 'loss_4': 1.0993154048919678, 'epoch': 15.1}
{'loss': 0.0328, 'grad_norm': 15.237405776977539, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.025911342352628708, 'loss_2': 0.00690460205078125, 'loss_3': -16.440200805664062, 'loss_4': 1.1842602491378784, 'epoch': 15.1}
{'loss': 0.0191, 'grad_norm': 8.359868049621582, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.011193995364010334, 'loss_2': 0.0079345703125, 'loss_3': -16.350683212280273, 'loss_4': 0.8196051716804504, 'epoch': 15.11}
{'loss': 0.0251, 'grad_norm': 10.931108474731445, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.020317187532782555, 'loss_2': 0.0048065185546875, 'loss_3': -16.321313858032227, 'loss_4': 1.109268069267273, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 16:21:42,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:42,018 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:35<44:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:49,370 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01695210114121437, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.26, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.010830585844814777, 'eval_loss_2': 0.006121516227722168, 'eval_loss_3': -18.107276916503906, 'eval_loss_4': 0.888054609298706, 'epoch': 15.12}
{'loss': 0.0202, 'grad_norm': 5.984482765197754, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.017260519787669182, 'loss_2': 0.0029010772705078125, 'loss_3': -16.083145141601562, 'loss_4': 0.7190925478935242, 'epoch': 15.12}
{'loss': 0.0127, 'grad_norm': 8.09501838684082, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.01232992671430111, 'loss_2': 0.00033736228942871094, 'loss_3': -16.120296478271484, 'loss_4': 1.0499954223632812, 'epoch': 15.13}
{'loss': 0.0197, 'grad_norm': 13.999444961547852, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.019515641033649445, 'loss_2': 0.00016820430755615234, 'loss_3': -16.286239624023438, 'loss_4': 0.5005778670310974, 'epoch': 15.13}
{'loss': 0.0152, 'grad_norm': 5.177797317504883, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.01138073205947876, 'loss_2': 0.0037708282470703125, 'loss_3': -16.34036636352539, 'loss_4': 0.9172737002372742, 'epoch': 15.14}
{'loss': 0.0154, 'grad_norm': 6.301499366760254, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.009542714804410934, 'loss_2': 0.005855560302734375, 'loss_3': -16.392528533935547, 'loss_4': 0.47801071405410767, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 16:21:49,370 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:49,370 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:43<44:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:21:56,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015836507081985474, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.583, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010153785347938538, 'eval_loss_2': 0.005682721734046936, 'eval_loss_3': -18.126800537109375, 'eval_loss_4': 0.7099096179008484, 'epoch': 15.15}
{'loss': 0.0079, 'grad_norm': 4.532938480377197, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.005431133788079023, 'loss_2': 0.00243377685546875, 'loss_3': -16.211990356445312, 'loss_4': 0.337492972612381, 'epoch': 15.15}
{'loss': 0.0173, 'grad_norm': 7.0476460456848145, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.014733548276126385, 'loss_2': 0.002559661865234375, 'loss_3': -16.29476547241211, 'loss_4': 0.8607902526855469, 'epoch': 15.16}
{'loss': 0.0418, 'grad_norm': 11.40088176727295, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.04092838987708092, 'loss_2': 0.0009074211120605469, 'loss_3': -16.30066680908203, 'loss_4': 0.8000071048736572, 'epoch': 15.16}
{'loss': 0.0678, 'grad_norm': 16.87618637084961, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.06489529460668564, 'loss_2': 0.002864837646484375, 'loss_3': -16.227985382080078, 'loss_4': 0.5557552576065063, 'epoch': 15.17}
{'loss': 0.0143, 'grad_norm': 7.254060745239258, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.011723565869033337, 'loss_2': 0.0025691986083984375, 'loss_3': -16.40782928466797, 'loss_4': 0.7196799516677856, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 16:21:56,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:21:56,707 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:50<43:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:04,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015009911730885506, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.758, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010687777772545815, 'eval_loss_2': 0.004322133958339691, 'eval_loss_3': -18.14257049560547, 'eval_loss_4': 0.37502020597457886, 'epoch': 15.17}
{'loss': 0.0165, 'grad_norm': 6.183788299560547, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.015413052402436733, 'loss_2': 0.001087188720703125, 'loss_3': -16.4610538482666, 'loss_4': 0.3559452295303345, 'epoch': 15.18}
{'loss': 0.01, 'grad_norm': 5.632768630981445, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.00773877976462245, 'loss_2': 0.002269744873046875, 'loss_3': -16.385295867919922, 'loss_4': 0.43082040548324585, 'epoch': 15.19}
{'loss': 0.01, 'grad_norm': 5.220705986022949, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.006814638618379831, 'loss_2': 0.00319671630859375, 'loss_3': -16.47174644470215, 'loss_4': 0.13207471370697021, 'epoch': 15.19}
{'loss': 0.0201, 'grad_norm': 5.428150653839111, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.007677693851292133, 'loss_2': 0.012420654296875, 'loss_3': -16.323348999023438, 'loss_4': 0.26893213391304016, 'epoch': 15.2}
{'loss': 0.0245, 'grad_norm': 9.807514190673828, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.017730269581079483, 'loss_2': 0.00681304931640625, 'loss_3': -16.16690444946289, 'loss_4': -0.056935034692287445, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 16:22:04,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:04,040 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:04:57<43:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:11,379 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01536967046558857, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.494, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010690674185752869, 'eval_loss_2': 0.004678994417190552, 'eval_loss_3': -18.127817153930664, 'eval_loss_4': 0.18394897878170013, 'epoch': 15.2}
{'loss': 0.0184, 'grad_norm': 6.318361282348633, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.015430652536451817, 'loss_2': 0.003002166748046875, 'loss_3': -16.41213607788086, 'loss_4': 0.17357291281223297, 'epoch': 15.21}
{'loss': 0.0201, 'grad_norm': 7.334053993225098, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.0166271161288023, 'loss_2': 0.003448486328125, 'loss_3': -16.229949951171875, 'loss_4': 0.16432258486747742, 'epoch': 15.22}
{'loss': 0.0284, 'grad_norm': 17.645740509033203, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.028206435963511467, 'loss_2': 0.0001518726348876953, 'loss_3': -16.314817428588867, 'loss_4': 0.2750471234321594, 'epoch': 15.22}
{'loss': 0.0053, 'grad_norm': 4.713383197784424, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.004711703862994909, 'loss_2': 0.0005893707275390625, 'loss_3': -16.325990676879883, 'loss_4': 0.18886244297027588, 'epoch': 15.23}
{'loss': 0.0136, 'grad_norm': 5.734654903411865, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.011921869590878487, 'loss_2': 0.00165557861328125, 'loss_3': -16.250343322753906, 'loss_4': 0.6246622800827026, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 16:22:11,379 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:11,379 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:05:05<43:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:18,722 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013869117945432663, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.598, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010516989976167679, 'eval_loss_2': 0.003352127969264984, 'eval_loss_3': -18.145313262939453, 'eval_loss_4': 0.08247467875480652, 'epoch': 15.23}
{'loss': 0.0987, 'grad_norm': 16.98686408996582, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.09247827529907227, 'loss_2': 0.0062713623046875, 'loss_3': -16.36233139038086, 'loss_4': 0.5952805876731873, 'epoch': 15.24}
{'loss': 0.0183, 'grad_norm': 9.707074165344238, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.016914580017328262, 'loss_2': 0.0014324188232421875, 'loss_3': -16.46543312072754, 'loss_4': -0.20260697603225708, 'epoch': 15.24}
{'loss': 0.0068, 'grad_norm': 4.591466903686523, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.004513009916990995, 'loss_2': 0.0022735595703125, 'loss_3': -16.38079071044922, 'loss_4': 0.3001910448074341, 'epoch': 15.25}
{'loss': 0.0087, 'grad_norm': 4.795175075531006, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.005018456839025021, 'loss_2': 0.003719329833984375, 'loss_3': -16.429553985595703, 'loss_4': 0.3389984369277954, 'epoch': 15.26}
{'loss': 0.0112, 'grad_norm': 5.24032735824585, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.007296587806195021, 'loss_2': 0.003925323486328125, 'loss_3': -16.312000274658203, 'loss_4': 0.1586410254240036, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 16:22:18,722 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:18,722 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:05:12<43:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:26,063 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014943966642022133, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.193, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010777750983834267, 'eval_loss_2': 0.004166215658187866, 'eval_loss_3': -18.15744400024414, 'eval_loss_4': 0.1423686295747757, 'epoch': 15.26}
{'loss': 0.0113, 'grad_norm': 5.3746337890625, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.010450869798660278, 'loss_2': 0.0008568763732910156, 'loss_3': -16.292282104492188, 'loss_4': -0.05099163204431534, 'epoch': 15.27}
{'loss': 0.0079, 'grad_norm': 9.313232421875, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.007220124360173941, 'loss_2': 0.0006723403930664062, 'loss_3': -16.506072998046875, 'loss_4': 0.19137656688690186, 'epoch': 15.27}
{'loss': 0.0085, 'grad_norm': 4.625108242034912, 'learning_rate': 1.475e-05, 'loss_1': 0.006295440718531609, 'loss_2': 0.002231597900390625, 'loss_3': -16.442188262939453, 'loss_4': 0.11616109311580658, 'epoch': 15.28}
{'loss': 0.013, 'grad_norm': 5.88902473449707, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.011173238977789879, 'loss_2': 0.001804351806640625, 'loss_3': -16.373958587646484, 'loss_4': -0.04855507239699364, 'epoch': 15.28}
{'loss': 0.0189, 'grad_norm': 7.365084648132324, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.018385669216513634, 'loss_2': 0.0004687309265136719, 'loss_3': -16.504066467285156, 'loss_4': 0.22135193645954132, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 16:22:26,063 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:26,063 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:19<43:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:33,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013747571036219597, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010094819590449333, 'eval_loss_2': 0.0036527514457702637, 'eval_loss_3': -18.179670333862305, 'eval_loss_4': 0.06667208671569824, 'epoch': 15.29}
{'loss': 0.0157, 'grad_norm': 5.233190059661865, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.01166477333754301, 'loss_2': 0.00402069091796875, 'loss_3': -16.41649055480957, 'loss_4': 0.10637973248958588, 'epoch': 15.3}
{'loss': 0.0288, 'grad_norm': 8.665343284606934, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.02597520686686039, 'loss_2': 0.0027751922607421875, 'loss_3': -16.574310302734375, 'loss_4': 0.012187201529741287, 'epoch': 15.3}
{'loss': 0.0086, 'grad_norm': 4.738528728485107, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.007029032334685326, 'loss_2': 0.0015554428100585938, 'loss_3': -16.345922470092773, 'loss_4': 0.40143516659736633, 'epoch': 15.31}
{'loss': 0.0187, 'grad_norm': 7.210235595703125, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.01409220602363348, 'loss_2': 0.00460052490234375, 'loss_3': -16.4522705078125, 'loss_4': 0.19239644706249237, 'epoch': 15.31}
{'loss': 0.0128, 'grad_norm': 6.033628463745117, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.011704649776220322, 'loss_2': 0.0010938644409179688, 'loss_3': -16.45656967163086, 'loss_4': -0.03479606658220291, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 16:22:33,400 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:33,400 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:27<43:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:40,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014211153611540794, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.468, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009775081649422646, 'eval_loss_2': 0.004436071962118149, 'eval_loss_3': -18.16387939453125, 'eval_loss_4': 0.041556939482688904, 'epoch': 15.32}
{'loss': 0.0077, 'grad_norm': 5.317873001098633, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.006733525078743696, 'loss_2': 0.0009717941284179688, 'loss_3': -16.4735050201416, 'loss_4': 0.06426925212144852, 'epoch': 15.33}
{'loss': 0.0222, 'grad_norm': 7.399362087249756, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.017679423093795776, 'loss_2': 0.00450897216796875, 'loss_3': -16.5167293548584, 'loss_4': 0.5041956305503845, 'epoch': 15.33}
{'loss': 0.0089, 'grad_norm': 5.709798812866211, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.006612368859350681, 'loss_2': 0.00231170654296875, 'loss_3': -16.356441497802734, 'loss_4': 0.282787561416626, 'epoch': 15.34}
{'loss': 0.0104, 'grad_norm': 4.610764503479004, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.006769650150090456, 'loss_2': 0.003620147705078125, 'loss_3': -16.48393440246582, 'loss_4': 0.2526113986968994, 'epoch': 15.34}
{'loss': 0.012, 'grad_norm': 5.261792182922363, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.010044303722679615, 'loss_2': 0.001995086669921875, 'loss_3': -16.27156639099121, 'loss_4': 0.35493186116218567, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 16:22:40,735 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:40,735 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:34<43:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:48,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015414848923683167, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.994, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011574731208384037, 'eval_loss_2': 0.003840118646621704, 'eval_loss_3': -18.12350845336914, 'eval_loss_4': 0.10597539693117142, 'epoch': 15.35}
{'loss': 0.0145, 'grad_norm': 5.229532718658447, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.0062181525863707066, 'loss_2': 0.0082855224609375, 'loss_3': -16.486358642578125, 'loss_4': 0.2962512969970703, 'epoch': 15.35}
{'loss': 0.0202, 'grad_norm': 8.751744270324707, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.018550477921962738, 'loss_2': 0.0016508102416992188, 'loss_3': -16.354177474975586, 'loss_4': -0.23486514389514923, 'epoch': 15.36}
{'loss': 0.015, 'grad_norm': 6.492264270782471, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.012133128941059113, 'loss_2': 0.0028743743896484375, 'loss_3': -16.45862579345703, 'loss_4': 0.24058504402637482, 'epoch': 15.37}
{'loss': 0.0085, 'grad_norm': 4.700404167175293, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.00723221804946661, 'loss_2': 0.0012664794921875, 'loss_3': -16.294403076171875, 'loss_4': -0.197373628616333, 'epoch': 15.37}
{'loss': 0.0118, 'grad_norm': 4.880903720855713, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.005144950468093157, 'loss_2': 0.00669097900390625, 'loss_3': -16.406831741333008, 'loss_4': 0.14413219690322876, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 16:22:48,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:48,089 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:42<43:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:22:55,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012952789664268494, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.389, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010271146893501282, 'eval_loss_2': 0.002681642770767212, 'eval_loss_3': -18.117393493652344, 'eval_loss_4': 0.27684056758880615, 'epoch': 15.38}
{'loss': 0.0144, 'grad_norm': 7.352027416229248, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.012577027082443237, 'loss_2': 0.0017862319946289062, 'loss_3': -16.38412094116211, 'loss_4': 0.14431165158748627, 'epoch': 15.38}
{'loss': 0.0235, 'grad_norm': 10.80094051361084, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.021836629137396812, 'loss_2': 0.0016775131225585938, 'loss_3': -16.565040588378906, 'loss_4': 0.5123271346092224, 'epoch': 15.39}
{'loss': 0.0207, 'grad_norm': 7.004969120025635, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.018472302705049515, 'loss_2': 0.00218963623046875, 'loss_3': -16.477516174316406, 'loss_4': 0.5725349187850952, 'epoch': 15.4}
{'loss': 0.012, 'grad_norm': 4.790970802307129, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.0075888377614319324, 'loss_2': 0.004405975341796875, 'loss_3': -16.3864688873291, 'loss_4': 0.10804355144500732, 'epoch': 15.4}
{'loss': 0.0149, 'grad_norm': 9.892504692077637, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.014864432625472546, 'loss_2': 1.895427703857422e-05, 'loss_3': -16.50485610961914, 'loss_4': 0.5920080542564392, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 16:22:55,440 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:22:55,440 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:49<43:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:02,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01345191802829504, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.606, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010126657783985138, 'eval_loss_2': 0.003325261175632477, 'eval_loss_3': -18.13505744934082, 'eval_loss_4': 0.37807130813598633, 'epoch': 15.41}
{'loss': 0.0215, 'grad_norm': 8.990999221801758, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.019989565014839172, 'loss_2': 0.00154876708984375, 'loss_3': -16.405277252197266, 'loss_4': 0.3032572269439697, 'epoch': 15.41}
{'loss': 0.0141, 'grad_norm': 7.432167053222656, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.009864225052297115, 'loss_2': 0.00418853759765625, 'loss_3': -16.511188507080078, 'loss_4': 0.7216091156005859, 'epoch': 15.42}
{'loss': 0.0149, 'grad_norm': 4.575356960296631, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.012213646434247494, 'loss_2': 0.0026645660400390625, 'loss_3': -16.609878540039062, 'loss_4': 0.5571498870849609, 'epoch': 15.42}
{'loss': 0.0161, 'grad_norm': 6.8594465255737305, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.011559588834643364, 'loss_2': 0.00455474853515625, 'loss_3': -16.251405715942383, 'loss_4': 0.14664269983768463, 'epoch': 15.43}
{'loss': 0.0051, 'grad_norm': 4.861841201782227, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.004437286406755447, 'loss_2': 0.0006427764892578125, 'loss_3': -16.30755615234375, 'loss_4': 0.4386439323425293, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 16:23:02,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:02,798 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:05:56<43:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:10,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01324795838445425, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.825, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009909874759614468, 'eval_loss_2': 0.0033380836248397827, 'eval_loss_3': -18.11968421936035, 'eval_loss_4': 0.4051676392555237, 'epoch': 15.44}
{'loss': 0.0113, 'grad_norm': 6.991816997528076, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.010288852266967297, 'loss_2': 0.0010356903076171875, 'loss_3': -16.246036529541016, 'loss_4': 0.7110595703125, 'epoch': 15.44}
{'loss': 0.0073, 'grad_norm': 4.690093040466309, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.004492177162319422, 'loss_2': 0.002841949462890625, 'loss_3': -16.38828468322754, 'loss_4': 0.3493381142616272, 'epoch': 15.45}
{'loss': 0.0191, 'grad_norm': 7.042736530303955, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.016580210998654366, 'loss_2': 0.002506256103515625, 'loss_3': -16.253143310546875, 'loss_4': 0.6295047402381897, 'epoch': 15.45}
{'loss': 0.0106, 'grad_norm': 5.176977634429932, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.010035539977252483, 'loss_2': 0.0005779266357421875, 'loss_3': -16.42706298828125, 'loss_4': 0.4649403691291809, 'epoch': 15.46}
{'loss': 0.0126, 'grad_norm': 5.749040126800537, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.008334239013493061, 'loss_2': 0.00424957275390625, 'loss_3': -16.35500717163086, 'loss_4': 0.7263404130935669, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 16:23:10,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:10,144 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:06:04<43:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:17,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013308851048350334, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.732, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01004198007285595, 'eval_loss_2': 0.0032668709754943848, 'eval_loss_3': -18.13457489013672, 'eval_loss_4': 0.4246925413608551, 'epoch': 15.47}
{'loss': 0.0295, 'grad_norm': 11.414800643920898, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.023927927017211914, 'loss_2': 0.00554656982421875, 'loss_3': -16.252357482910156, 'loss_4': 0.6811970472335815, 'epoch': 15.47}
{'loss': 0.0119, 'grad_norm': 5.546139717102051, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.01131589524447918, 'loss_2': 0.0006175041198730469, 'loss_3': -16.287620544433594, 'loss_4': 0.510123610496521, 'epoch': 15.48}
{'loss': 0.0163, 'grad_norm': 5.62542724609375, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.009327983483672142, 'loss_2': 0.007015228271484375, 'loss_3': -16.476486206054688, 'loss_4': 0.43111634254455566, 'epoch': 15.48}
{'loss': 0.0282, 'grad_norm': 9.92387866973877, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.021438760682940483, 'loss_2': 0.00673675537109375, 'loss_3': -16.263513565063477, 'loss_4': 0.33133551478385925, 'epoch': 15.49}
{'loss': 0.025, 'grad_norm': 9.240819931030273, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.0219496451318264, 'loss_2': 0.003002166748046875, 'loss_3': -16.46982192993164, 'loss_4': 0.19241705536842346, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 16:23:17,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:17,481 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:06:11<43:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:24,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012171451933681965, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.57, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009042760357260704, 'eval_loss_2': 0.0031286925077438354, 'eval_loss_3': -18.154094696044922, 'eval_loss_4': 0.4943079352378845, 'epoch': 15.49}
{'loss': 0.0071, 'grad_norm': 5.503026485443115, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.006483461707830429, 'loss_2': 0.0006203651428222656, 'loss_3': -16.247446060180664, 'loss_4': 0.71729576587677, 'epoch': 15.5}
{'loss': 0.0163, 'grad_norm': 6.331491947174072, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.014776380732655525, 'loss_2': 0.0015325546264648438, 'loss_3': -16.152687072753906, 'loss_4': 0.8471498489379883, 'epoch': 15.51}
{'loss': 0.0231, 'grad_norm': 8.21235466003418, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.020573757588863373, 'loss_2': 0.0025005340576171875, 'loss_3': -16.316089630126953, 'loss_4': 0.203649640083313, 'epoch': 15.51}
{'loss': 0.0219, 'grad_norm': 7.800192356109619, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.019072240218520164, 'loss_2': 0.002838134765625, 'loss_3': -16.498619079589844, 'loss_4': 0.7512531280517578, 'epoch': 15.52}
{'loss': 0.0074, 'grad_norm': 5.177082538604736, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.006332085933536291, 'loss_2': 0.001033782958984375, 'loss_3': -16.44303321838379, 'loss_4': 0.6174365282058716, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 16:23:24,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:24,821 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:18<43:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:32,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01255604438483715, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008833615109324455, 'eval_loss_2': 0.0037224292755126953, 'eval_loss_3': -18.16181182861328, 'eval_loss_4': 0.7228370904922485, 'epoch': 15.52}
{'loss': 0.0121, 'grad_norm': 5.0829386711120605, 'learning_rate': 1.45e-05, 'loss_1': 0.005805287975817919, 'loss_2': 0.0063018798828125, 'loss_3': -16.35516929626465, 'loss_4': 0.8013770580291748, 'epoch': 15.53}
{'loss': 0.0148, 'grad_norm': 5.494026184082031, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.009553578682243824, 'loss_2': 0.00524139404296875, 'loss_3': -16.31792449951172, 'loss_4': 0.5937021970748901, 'epoch': 15.53}
{'loss': 0.0094, 'grad_norm': 5.165706634521484, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.00823145266622305, 'loss_2': 0.0011873245239257812, 'loss_3': -16.231922149658203, 'loss_4': 1.0021880865097046, 'epoch': 15.54}
{'loss': 0.0303, 'grad_norm': 19.425792694091797, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.027617819607257843, 'loss_2': 0.0026607513427734375, 'loss_3': -16.489904403686523, 'loss_4': 0.9926037192344666, 'epoch': 15.55}
{'loss': 0.0278, 'grad_norm': 12.16872787475586, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.026381423696875572, 'loss_2': 0.0014219284057617188, 'loss_3': -16.164201736450195, 'loss_4': 0.9869126081466675, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 16:23:32,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:32,172 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:26<42:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:39,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011309227906167507, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.465, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008413148112595081, 'eval_loss_2': 0.0028960779309272766, 'eval_loss_3': -18.140771865844727, 'eval_loss_4': 0.8659628629684448, 'epoch': 15.55}
{'loss': 0.0137, 'grad_norm': 7.33180570602417, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.01091129519045353, 'loss_2': 0.002788543701171875, 'loss_3': -16.404497146606445, 'loss_4': 0.6287739276885986, 'epoch': 15.56}
{'loss': 0.0452, 'grad_norm': 26.38551139831543, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.039548344910144806, 'loss_2': 0.0056915283203125, 'loss_3': -16.180805206298828, 'loss_4': 0.9683802127838135, 'epoch': 15.56}
{'loss': 0.0323, 'grad_norm': 7.268162250518799, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.02681232988834381, 'loss_2': 0.005512237548828125, 'loss_3': -16.26447105407715, 'loss_4': 1.4514880180358887, 'epoch': 15.57}
{'loss': 0.0059, 'grad_norm': 5.017709255218506, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.004557864274829626, 'loss_2': 0.0012950897216796875, 'loss_3': -16.486072540283203, 'loss_4': 0.9203187227249146, 'epoch': 15.58}
{'loss': 0.0256, 'grad_norm': 11.990924835205078, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.024609288200736046, 'loss_2': 0.0010385513305664062, 'loss_3': -16.44812774658203, 'loss_4': 0.6400904655456543, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 16:23:39,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:39,518 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:33<42:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:46,868 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013472970575094223, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.04, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009117808192968369, 'eval_loss_2': 0.0043551623821258545, 'eval_loss_3': -18.116016387939453, 'eval_loss_4': 0.8109111189842224, 'epoch': 15.58}
{'loss': 0.0135, 'grad_norm': 5.089567184448242, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.005302919540554285, 'loss_2': 0.0082244873046875, 'loss_3': -16.431983947753906, 'loss_4': 0.7496811747550964, 'epoch': 15.59}
{'loss': 0.0148, 'grad_norm': 6.218817710876465, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.008167402818799019, 'loss_2': 0.0066375732421875, 'loss_3': -16.329235076904297, 'loss_4': 0.9029664993286133, 'epoch': 15.59}
{'loss': 0.0114, 'grad_norm': 4.883761405944824, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.00437001371756196, 'loss_2': 0.00699615478515625, 'loss_3': -16.346139907836914, 'loss_4': 0.8868152499198914, 'epoch': 15.6}
{'loss': 0.025, 'grad_norm': 13.362045288085938, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.02364843524992466, 'loss_2': 0.001369476318359375, 'loss_3': -16.231224060058594, 'loss_4': 0.7908285856246948, 'epoch': 15.6}
{'loss': 0.0345, 'grad_norm': 9.329018592834473, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.030898168683052063, 'loss_2': 0.003597259521484375, 'loss_3': -16.38638687133789, 'loss_4': 0.9196851849555969, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 16:23:46,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:46,869 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:40<42:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:23:54,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017918232828378677, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.451, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01263250783085823, 'eval_loss_2': 0.005285724997520447, 'eval_loss_3': -18.076990127563477, 'eval_loss_4': 0.9741408824920654, 'epoch': 15.61}
{'loss': 0.0075, 'grad_norm': 5.026352405548096, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.005326663143932819, 'loss_2': 0.0021915435791015625, 'loss_3': -16.413061141967773, 'loss_4': 0.9023310542106628, 'epoch': 15.62}
{'loss': 0.0149, 'grad_norm': 6.842677116394043, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.00869106687605381, 'loss_2': 0.006198883056640625, 'loss_3': -16.18659782409668, 'loss_4': 0.7965750098228455, 'epoch': 15.62}
{'loss': 0.0091, 'grad_norm': 5.279484272003174, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.0064290352165699005, 'loss_2': 0.0026836395263671875, 'loss_3': -16.256572723388672, 'loss_4': 1.021843671798706, 'epoch': 15.63}
{'loss': 0.0176, 'grad_norm': 7.863877773284912, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.01500552985817194, 'loss_2': 0.0025634765625, 'loss_3': -16.519760131835938, 'loss_4': 1.4111006259918213, 'epoch': 15.63}
{'loss': 0.0081, 'grad_norm': 4.933806419372559, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.007124817464500666, 'loss_2': 0.0009713172912597656, 'loss_3': -16.332752227783203, 'loss_4': 1.5504388809204102, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 16:23:54,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:23:54,205 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:48<42:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:01,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01905820518732071, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.486, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.015105288475751877, 'eval_loss_2': 0.003952920436859131, 'eval_loss_3': -18.053680419921875, 'eval_loss_4': 1.0789319276809692, 'epoch': 15.64}
{'loss': 0.0235, 'grad_norm': 9.795258522033691, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.02228044532239437, 'loss_2': 0.0012149810791015625, 'loss_3': -16.19769859313965, 'loss_4': 1.1578900814056396, 'epoch': 15.65}
{'loss': 0.0138, 'grad_norm': 6.338173866271973, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.009684373624622822, 'loss_2': 0.00414276123046875, 'loss_3': -16.202829360961914, 'loss_4': 1.3997952938079834, 'epoch': 15.65}
{'loss': 0.0096, 'grad_norm': 5.624355792999268, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.0071355137042701244, 'loss_2': 0.00250244140625, 'loss_3': -16.355485916137695, 'loss_4': 1.1003477573394775, 'epoch': 15.66}
{'loss': 0.0156, 'grad_norm': 10.586337089538574, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.012150990776717663, 'loss_2': 0.003482818603515625, 'loss_3': -16.386882781982422, 'loss_4': 1.3116921186447144, 'epoch': 15.66}
{'loss': 0.0133, 'grad_norm': 5.004526615142822, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.008823336102068424, 'loss_2': 0.004459381103515625, 'loss_3': -16.243236541748047, 'loss_4': 1.5231837034225464, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 16:24:01,545 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:01,545 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:06:55<42:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:08,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01855708658695221, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.46, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.014512153342366219, 'eval_loss_2': 0.004044931381940842, 'eval_loss_3': -18.051393508911133, 'eval_loss_4': 1.2709035873413086, 'epoch': 15.67}
{'loss': 0.0327, 'grad_norm': 9.093706130981445, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.021991943940520287, 'loss_2': 0.01068115234375, 'loss_3': -16.194499969482422, 'loss_4': 1.2008932828903198, 'epoch': 15.67}
{'loss': 0.0059, 'grad_norm': 5.158849239349365, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.005198676139116287, 'loss_2': 0.000743865966796875, 'loss_3': -16.141021728515625, 'loss_4': 1.3556199073791504, 'epoch': 15.68}
{'loss': 0.0107, 'grad_norm': 4.6192193031311035, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.006305060349404812, 'loss_2': 0.004364013671875, 'loss_3': -16.325721740722656, 'loss_4': 1.5039894580841064, 'epoch': 15.69}
{'loss': 0.0083, 'grad_norm': 4.501423358917236, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.007638569921255112, 'loss_2': 0.0006155967712402344, 'loss_3': -16.497543334960938, 'loss_4': 1.2500698566436768, 'epoch': 15.69}
{'loss': 0.0303, 'grad_norm': 11.968533515930176, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.024620305746793747, 'loss_2': 0.005645751953125, 'loss_3': -16.394939422607422, 'loss_4': 1.2192187309265137, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 16:24:08,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:08,888 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:07:02<42:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:16,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015402473509311676, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.356, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011601099744439125, 'eval_loss_2': 0.0038013719022274017, 'eval_loss_3': -18.0765380859375, 'eval_loss_4': 1.390091896057129, 'epoch': 15.7}
{'loss': 0.0116, 'grad_norm': 4.5471391677856445, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.0038846589159220457, 'loss_2': 0.007755279541015625, 'loss_3': -16.41484260559082, 'loss_4': 1.2776137590408325, 'epoch': 15.7}
{'loss': 0.009, 'grad_norm': 5.779993057250977, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.007712379097938538, 'loss_2': 0.0012664794921875, 'loss_3': -16.36005401611328, 'loss_4': 1.625917673110962, 'epoch': 15.71}
{'loss': 0.0069, 'grad_norm': 5.098801612854004, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.005032475106418133, 'loss_2': 0.0018634796142578125, 'loss_3': -16.267581939697266, 'loss_4': 1.3479492664337158, 'epoch': 15.72}
{'loss': 0.0372, 'grad_norm': 12.409667015075684, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.033651676028966904, 'loss_2': 0.00359344482421875, 'loss_3': -16.264392852783203, 'loss_4': 1.2865290641784668, 'epoch': 15.72}
{'loss': 0.0124, 'grad_norm': 4.957012176513672, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.009090986102819443, 'loss_2': 0.0033416748046875, 'loss_3': -16.324932098388672, 'loss_4': 1.655794620513916, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 16:24:16,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:16,233 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:07:10<42:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:23,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014042369090020657, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010678908787667751, 'eval_loss_2': 0.0033634603023529053, 'eval_loss_3': -18.12188148498535, 'eval_loss_4': 1.5659350156784058, 'epoch': 15.73}
{'loss': 0.0139, 'grad_norm': 5.715132236480713, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.009438523091375828, 'loss_2': 0.00446319580078125, 'loss_3': -16.10565185546875, 'loss_4': 1.3017584085464478, 'epoch': 15.73}
{'loss': 0.008, 'grad_norm': 5.096850872039795, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.006481165532022715, 'loss_2': 0.00153350830078125, 'loss_3': -16.23125457763672, 'loss_4': 1.4818302392959595, 'epoch': 15.74}
{'loss': 0.0121, 'grad_norm': 5.428807735443115, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.010086479596793652, 'loss_2': 0.002048492431640625, 'loss_3': -16.28792381286621, 'loss_4': 1.2628357410430908, 'epoch': 15.74}
{'loss': 0.0175, 'grad_norm': 6.366049289703369, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.013926967047154903, 'loss_2': 0.0035457611083984375, 'loss_3': -16.087242126464844, 'loss_4': 1.834172010421753, 'epoch': 15.75}
{'loss': 0.0136, 'grad_norm': 6.117717742919922, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.007496542297303677, 'loss_2': 0.006072998046875, 'loss_3': -16.30756187438965, 'loss_4': 1.6920043230056763, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 16:24:23,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:23,581 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:07:17<42:52,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:24:31,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013498456217348576, 'eval_runtime': 4.0011, 'eval_samples_per_second': 255.929, 'eval_steps_per_second': 3.999, 'eval_loss_1': 0.00959900114685297, 'eval_loss_2': 0.0038994550704956055, 'eval_loss_3': -18.12714958190918, 'eval_loss_4': 1.7364007234573364, 'epoch': 15.76}
{'loss': 0.0197, 'grad_norm': 5.52722692489624, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.015900161117315292, 'loss_2': 0.0038089752197265625, 'loss_3': -16.211402893066406, 'loss_4': 1.6003257036209106, 'epoch': 15.76}
{'loss': 0.0196, 'grad_norm': 7.058438777923584, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.019393740221858025, 'loss_2': 0.00016808509826660156, 'loss_3': -16.148414611816406, 'loss_4': 1.7549200057983398, 'epoch': 15.77}
{'loss': 0.0122, 'grad_norm': 6.136009216308594, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.010579005815088749, 'loss_2': 0.0016040802001953125, 'loss_3': -16.451114654541016, 'loss_4': 1.9222513437271118, 'epoch': 15.77}
{'loss': 0.0153, 'grad_norm': 5.934201717376709, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.012722092680633068, 'loss_2': 0.00255584716796875, 'loss_3': -16.483911514282227, 'loss_4': 1.8649616241455078, 'epoch': 15.78}
{'loss': 0.009, 'grad_norm': 5.745792865753174, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.008438479155302048, 'loss_2': 0.0006055831909179688, 'loss_3': -16.28384017944336, 'loss_4': 1.7610008716583252, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 16:24:31,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:31,124 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:25<42:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:38,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012452729046344757, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.292, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008786119520664215, 'eval_loss_2': 0.003666609525680542, 'eval_loss_3': -18.12413787841797, 'eval_loss_4': 1.5791325569152832, 'epoch': 15.78}
{'loss': 0.0125, 'grad_norm': 5.572762489318848, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.007456130348145962, 'loss_2': 0.00505828857421875, 'loss_3': -16.35934066772461, 'loss_4': 1.2693184614181519, 'epoch': 15.79}
{'loss': 0.0336, 'grad_norm': 10.789933204650879, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.029984092339873314, 'loss_2': 0.003612518310546875, 'loss_3': -16.307193756103516, 'loss_4': 1.7701029777526855, 'epoch': 15.8}
{'loss': 0.0182, 'grad_norm': 6.430993556976318, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.014232905581593513, 'loss_2': 0.003925323486328125, 'loss_3': -16.43756866455078, 'loss_4': 1.5730921030044556, 'epoch': 15.8}
{'loss': 0.0439, 'grad_norm': 19.415618896484375, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.03854282572865486, 'loss_2': 0.0053253173828125, 'loss_3': -16.25918197631836, 'loss_4': 1.5484797954559326, 'epoch': 15.81}
{'loss': 0.0103, 'grad_norm': 6.155999660491943, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.009395325556397438, 'loss_2': 0.0008845329284667969, 'loss_3': -16.478076934814453, 'loss_4': 0.9875524044036865, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 16:24:38,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:38,466 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:32<42:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:45,812 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01203248929232359, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.35, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008621860295534134, 'eval_loss_2': 0.00341062992811203, 'eval_loss_3': -18.12259864807129, 'eval_loss_4': 1.422192931175232, 'epoch': 15.81}
{'loss': 0.0161, 'grad_norm': 6.055362701416016, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.01278744824230671, 'loss_2': 0.003265380859375, 'loss_3': -16.255130767822266, 'loss_4': 1.4818530082702637, 'epoch': 15.82}
{'loss': 0.0258, 'grad_norm': 10.13031005859375, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.022233735769987106, 'loss_2': 0.0035400390625, 'loss_3': -16.447978973388672, 'loss_4': 1.193711757659912, 'epoch': 15.83}
{'loss': 0.0183, 'grad_norm': 7.03994083404541, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.010513745248317719, 'loss_2': 0.0077667236328125, 'loss_3': -16.413177490234375, 'loss_4': 1.196908712387085, 'epoch': 15.83}
{'loss': 0.0141, 'grad_norm': 6.285952091217041, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.01222358550876379, 'loss_2': 0.001857757568359375, 'loss_3': -16.373565673828125, 'loss_4': 1.6963011026382446, 'epoch': 15.84}
{'loss': 0.0147, 'grad_norm': 6.011165618896484, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.01264424342662096, 'loss_2': 0.0021038055419921875, 'loss_3': -16.23508071899414, 'loss_4': 1.0207148790359497, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 16:24:45,812 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:45,812 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:39<41:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:24:53,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012394007295370102, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.403, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008573930710554123, 'eval_loss_2': 0.003820076584815979, 'eval_loss_3': -18.11556625366211, 'eval_loss_4': 1.1902294158935547, 'epoch': 15.84}
{'loss': 0.0114, 'grad_norm': 4.954301834106445, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.009123951196670532, 'loss_2': 0.002300262451171875, 'loss_3': -16.32135009765625, 'loss_4': 1.0132967233657837, 'epoch': 15.85}
{'loss': 0.0148, 'grad_norm': 5.851638317108154, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.011244417168200016, 'loss_2': 0.0035114288330078125, 'loss_3': -16.4415225982666, 'loss_4': 1.5479788780212402, 'epoch': 15.85}
{'loss': 0.0159, 'grad_norm': 5.191931247711182, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.007778402883559465, 'loss_2': 0.00807952880859375, 'loss_3': -16.42627716064453, 'loss_4': 1.0119458436965942, 'epoch': 15.86}
{'loss': 0.0185, 'grad_norm': 8.012722969055176, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.014735287986695766, 'loss_2': 0.0037631988525390625, 'loss_3': -16.34298324584961, 'loss_4': 1.334410548210144, 'epoch': 15.87}
{'loss': 0.0177, 'grad_norm': 5.043257713317871, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.008607455529272556, 'loss_2': 0.0090484619140625, 'loss_3': -16.23523712158203, 'loss_4': 0.8642688989639282, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 16:24:53,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:24:53,145 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:47<41:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:00,486 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011776071041822433, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.445, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008101833052933216, 'eval_loss_2': 0.003674238920211792, 'eval_loss_3': -18.11363983154297, 'eval_loss_4': 1.0373841524124146, 'epoch': 15.87}
{'loss': 0.0412, 'grad_norm': 23.445199966430664, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.04113158583641052, 'loss_2': 3.629922866821289e-05, 'loss_3': -16.433609008789062, 'loss_4': 1.4404594898223877, 'epoch': 15.88}
{'loss': 0.037, 'grad_norm': 17.387584686279297, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.036402586847543716, 'loss_2': 0.000598907470703125, 'loss_3': -16.229835510253906, 'loss_4': 1.2469332218170166, 'epoch': 15.88}
{'loss': 0.1102, 'grad_norm': 23.853437423706055, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.10768581926822662, 'loss_2': 0.002498626708984375, 'loss_3': -16.304792404174805, 'loss_4': 1.5295078754425049, 'epoch': 15.89}
{'loss': 0.009, 'grad_norm': 4.590139865875244, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.006682013161480427, 'loss_2': 0.0022983551025390625, 'loss_3': -16.390623092651367, 'loss_4': 0.9446090459823608, 'epoch': 15.9}
{'loss': 0.0109, 'grad_norm': 5.812685489654541, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.010858239606022835, 'loss_2': 5.614757537841797e-05, 'loss_3': -16.335039138793945, 'loss_4': 0.48846688866615295, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 16:25:00,486 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:00,486 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:54<41:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:07,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011356347240507603, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.733, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00837007351219654, 'eval_loss_2': 0.0029862746596336365, 'eval_loss_3': -18.132564544677734, 'eval_loss_4': 1.0280512571334839, 'epoch': 15.9}
{'loss': 0.0224, 'grad_norm': 6.3944268226623535, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.019919879734516144, 'loss_2': 0.0024662017822265625, 'loss_3': -16.22933006286621, 'loss_4': 0.5734009146690369, 'epoch': 15.91}
{'loss': 0.014, 'grad_norm': 5.442000865936279, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.012145969085395336, 'loss_2': 0.0018310546875, 'loss_3': -16.511688232421875, 'loss_4': 1.0475502014160156, 'epoch': 15.91}
{'loss': 0.0229, 'grad_norm': 13.773025512695312, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.019355375319719315, 'loss_2': 0.00359344482421875, 'loss_3': -16.25006675720215, 'loss_4': 1.26185941696167, 'epoch': 15.92}
{'loss': 0.0235, 'grad_norm': 6.060431480407715, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.013585674576461315, 'loss_2': 0.0098724365234375, 'loss_3': -16.32743263244629, 'loss_4': 1.2424249649047852, 'epoch': 15.92}
{'loss': 0.0156, 'grad_norm': 5.505344867706299, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.012412981130182743, 'loss_2': 0.003162384033203125, 'loss_3': -16.467041015625, 'loss_4': 1.6367084980010986, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 16:25:07,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:07,834 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:08:01<41:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:15,178 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013888468965888023, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008635958656668663, 'eval_loss_2': 0.00525251030921936, 'eval_loss_3': -18.154033660888672, 'eval_loss_4': 1.407906413078308, 'epoch': 15.93}
{'loss': 0.0215, 'grad_norm': 5.283831596374512, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.011352972127497196, 'loss_2': 0.0101470947265625, 'loss_3': -16.32077407836914, 'loss_4': 1.6367847919464111, 'epoch': 15.94}
{'loss': 0.0193, 'grad_norm': 5.267186641693115, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.01212606392800808, 'loss_2': 0.007213592529296875, 'loss_3': -16.42279815673828, 'loss_4': 1.9091852903366089, 'epoch': 15.94}
{'loss': 0.0169, 'grad_norm': 4.755214214324951, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.00940007995814085, 'loss_2': 0.007511138916015625, 'loss_3': -16.43220329284668, 'loss_4': 1.4919158220291138, 'epoch': 15.95}
{'loss': 0.0176, 'grad_norm': 9.011141777038574, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.01612742245197296, 'loss_2': 0.0014781951904296875, 'loss_3': -16.33818244934082, 'loss_4': 1.7751274108886719, 'epoch': 15.95}
{'loss': 0.028, 'grad_norm': 9.186095237731934, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.021575890481472015, 'loss_2': 0.00646209716796875, 'loss_3': -16.548198699951172, 'loss_4': 1.401486873626709, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 16:25:15,178 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:15,178 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:08:09<41:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:22,520 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012031590566039085, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.644, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008800139650702477, 'eval_loss_2': 0.003231450915336609, 'eval_loss_3': -18.178199768066406, 'eval_loss_4': 1.7045197486877441, 'epoch': 15.96}
{'loss': 0.0223, 'grad_norm': 6.1066131591796875, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.015531706623733044, 'loss_2': 0.006805419921875, 'loss_3': -16.29348373413086, 'loss_4': 1.369835376739502, 'epoch': 15.97}
{'loss': 0.0216, 'grad_norm': 6.67160701751709, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.02136528491973877, 'loss_2': 0.0002238750457763672, 'loss_3': -16.34767723083496, 'loss_4': 2.059002637863159, 'epoch': 15.97}
{'loss': 0.0113, 'grad_norm': 6.168188095092773, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.010416017845273018, 'loss_2': 0.00084686279296875, 'loss_3': -16.53903579711914, 'loss_4': 1.8619356155395508, 'epoch': 15.98}
{'loss': 0.0071, 'grad_norm': 5.501884460449219, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.005008508451282978, 'loss_2': 0.002071380615234375, 'loss_3': -16.333248138427734, 'loss_4': 1.8813247680664062, 'epoch': 15.98}
{'loss': 0.0163, 'grad_norm': 5.107663631439209, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.009012389928102493, 'loss_2': 0.00724029541015625, 'loss_3': -16.321975708007812, 'loss_4': 2.096545696258545, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 16:25:22,520 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:22,520 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:08:16<40:22,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:25:29,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012303215451538563, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008958633989095688, 'eval_loss_2': 0.0033445805311203003, 'eval_loss_3': -18.197574615478516, 'eval_loss_4': 1.7811036109924316, 'epoch': 15.99}
{'loss': 0.04, 'grad_norm': 28.04930305480957, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.0398680604994297, 'loss_2': 9.632110595703125e-05, 'loss_3': -16.358638763427734, 'loss_4': 2.318660020828247, 'epoch': 15.99}
{'loss': 0.0044, 'grad_norm': 6.49153995513916, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.002841769251972437, 'loss_2': 0.001556396484375, 'loss_3': -16.631649017333984, 'loss_4': 1.9008722305297852, 'epoch': 16.0}
{'loss': 0.0264, 'grad_norm': 8.295858383178711, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.01988239958882332, 'loss_2': 0.00653076171875, 'loss_3': -16.35687255859375, 'loss_4': 1.6193673610687256, 'epoch': 16.01}
{'loss': 0.0495, 'grad_norm': 17.493696212768555, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.038353294134140015, 'loss_2': 0.011138916015625, 'loss_3': -16.39598846435547, 'loss_4': 1.3330118656158447, 'epoch': 16.01}
{'loss': 0.0165, 'grad_norm': 5.613979339599609, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.009298458695411682, 'loss_2': 0.00724029541015625, 'loss_3': -16.45061492919922, 'loss_4': 1.413102388381958, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 16:25:29,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:29,551 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:23<41:15,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:25:36,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012353554368019104, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009385989047586918, 'eval_loss_2': 0.0029675662517547607, 'eval_loss_3': -18.201255798339844, 'eval_loss_4': 1.7525187730789185, 'epoch': 16.02}
{'loss': 0.0238, 'grad_norm': 8.171671867370605, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.02369522862136364, 'loss_2': 0.00011986494064331055, 'loss_3': -16.361799240112305, 'loss_4': 1.9729262590408325, 'epoch': 16.02}
{'loss': 0.0295, 'grad_norm': 10.427133560180664, 'learning_rate': 1.4e-05, 'loss_1': 0.02239198610186577, 'loss_2': 0.007091522216796875, 'loss_3': -16.300708770751953, 'loss_4': 1.672769546508789, 'epoch': 16.03}
{'loss': 0.0253, 'grad_norm': 6.8224921226501465, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.017913958057761192, 'loss_2': 0.007415771484375, 'loss_3': -16.376819610595703, 'loss_4': 1.6223719120025635, 'epoch': 16.03}
{'loss': 0.0199, 'grad_norm': 8.904692649841309, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.01839381456375122, 'loss_2': 0.0015411376953125, 'loss_3': -16.403610229492188, 'loss_4': 1.8441733121871948, 'epoch': 16.04}
{'loss': 0.0806, 'grad_norm': 16.780546188354492, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.07680446654558182, 'loss_2': 0.0037689208984375, 'loss_3': -16.415504455566406, 'loss_4': 2.2912824153900146, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 16:25:36,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:36,890 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:30<41:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:44,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012924210168421268, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.803, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009835203178226948, 'eval_loss_2': 0.0030890069901943207, 'eval_loss_3': -18.17169952392578, 'eval_loss_4': 1.8369028568267822, 'epoch': 16.05}
{'loss': 0.0261, 'grad_norm': 11.87083625793457, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.02602504938840866, 'loss_2': 5.650520324707031e-05, 'loss_3': -16.279010772705078, 'loss_4': 1.6857433319091797, 'epoch': 16.05}
{'loss': 0.0217, 'grad_norm': 7.2897515296936035, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.018294526264071465, 'loss_2': 0.0033931732177734375, 'loss_3': -16.508211135864258, 'loss_4': 2.0176501274108887, 'epoch': 16.06}
{'loss': 0.0188, 'grad_norm': 8.456770896911621, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.016475044190883636, 'loss_2': 0.0023193359375, 'loss_3': -16.622146606445312, 'loss_4': 1.808464765548706, 'epoch': 16.06}
{'loss': 0.0132, 'grad_norm': 5.328181743621826, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.009509353898465633, 'loss_2': 0.0037136077880859375, 'loss_3': -16.489013671875, 'loss_4': 1.574040412902832, 'epoch': 16.07}
{'loss': 0.0178, 'grad_norm': 6.6374335289001465, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.013403371907770634, 'loss_2': 0.004367828369140625, 'loss_3': -16.515911102294922, 'loss_4': 1.7880874872207642, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 16:25:44,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:44,246 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:38<41:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:51,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011357700452208519, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008373727090656757, 'eval_loss_2': 0.002983972430229187, 'eval_loss_3': -18.16107749938965, 'eval_loss_4': 1.7876479625701904, 'epoch': 16.08}
{'loss': 0.0239, 'grad_norm': 7.385632514953613, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.017922136932611465, 'loss_2': 0.006015777587890625, 'loss_3': -16.564266204833984, 'loss_4': 1.9121860265731812, 'epoch': 16.08}
{'loss': 0.0268, 'grad_norm': 6.8970046043396, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.01743086241185665, 'loss_2': 0.0093536376953125, 'loss_3': -16.273977279663086, 'loss_4': 1.8768641948699951, 'epoch': 16.09}
{'loss': 0.0129, 'grad_norm': 5.113081455230713, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.00901878159493208, 'loss_2': 0.00385284423828125, 'loss_3': -16.43006134033203, 'loss_4': 1.4529218673706055, 'epoch': 16.09}
{'loss': 0.0204, 'grad_norm': 5.899050712585449, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.009032429195940495, 'loss_2': 0.01140594482421875, 'loss_3': -16.513198852539062, 'loss_4': 1.3459482192993164, 'epoch': 16.1}
{'loss': 0.0154, 'grad_norm': 5.329087257385254, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.008758490905165672, 'loss_2': 0.006591796875, 'loss_3': -16.59100341796875, 'loss_4': 1.4281877279281616, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 16:25:51,590 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:51,590 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:45<41:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:25:58,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012446129694581032, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008835310116410255, 'eval_loss_2': 0.0036108195781707764, 'eval_loss_3': -18.134756088256836, 'eval_loss_4': 1.6104650497436523, 'epoch': 16.1}
{'loss': 0.0208, 'grad_norm': 6.884047985076904, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.010772289708256721, 'loss_2': 0.01003265380859375, 'loss_3': -16.419593811035156, 'loss_4': 1.7068309783935547, 'epoch': 16.11}
{'loss': 0.013, 'grad_norm': 4.926334857940674, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.00697416253387928, 'loss_2': 0.006023406982421875, 'loss_3': -16.417091369628906, 'loss_4': 1.9207673072814941, 'epoch': 16.12}
{'loss': 0.0114, 'grad_norm': 5.238266468048096, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.008782655000686646, 'loss_2': 0.00262451171875, 'loss_3': -16.437461853027344, 'loss_4': 1.5473005771636963, 'epoch': 16.12}
{'loss': 0.0093, 'grad_norm': 5.877528667449951, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.008205318823456764, 'loss_2': 0.0011234283447265625, 'loss_3': -16.440845489501953, 'loss_4': 1.619352102279663, 'epoch': 16.13}
{'loss': 0.0097, 'grad_norm': 5.148169994354248, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.0056584603153169155, 'loss_2': 0.004032135009765625, 'loss_3': -16.257457733154297, 'loss_4': 0.9402161836624146, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 16:25:58,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:25:58,923 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:52<41:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:06,265 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013399535790085793, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.53, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009669745340943336, 'eval_loss_2': 0.003729790449142456, 'eval_loss_3': -18.12689208984375, 'eval_loss_4': 1.6305433511734009, 'epoch': 16.13}
{'loss': 0.013, 'grad_norm': 5.215535640716553, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.007647603750228882, 'loss_2': 0.00539398193359375, 'loss_3': -16.452749252319336, 'loss_4': 1.6547799110412598, 'epoch': 16.14}
{'loss': 0.0274, 'grad_norm': 12.860085487365723, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.02660193108022213, 'loss_2': 0.0007576942443847656, 'loss_3': -16.26982879638672, 'loss_4': 1.309844732284546, 'epoch': 16.15}
{'loss': 0.0163, 'grad_norm': 5.845004558563232, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.009322702884674072, 'loss_2': 0.00702667236328125, 'loss_3': -16.505338668823242, 'loss_4': 1.3811686038970947, 'epoch': 16.15}
{'loss': 0.0171, 'grad_norm': 11.479153633117676, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.01134395133703947, 'loss_2': 0.005718231201171875, 'loss_3': -16.35629653930664, 'loss_4': 1.8810484409332275, 'epoch': 16.16}
{'loss': 0.0118, 'grad_norm': 4.847803592681885, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.005717198830097914, 'loss_2': 0.00603485107421875, 'loss_3': -16.630821228027344, 'loss_4': 1.6256022453308105, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 16:26:06,265 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:06,265 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:09:00<41:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:13,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012008635327219963, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.383, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008450835011899471, 'eval_loss_2': 0.0035578012466430664, 'eval_loss_3': -18.148883819580078, 'eval_loss_4': 1.6756162643432617, 'epoch': 16.16}
{'loss': 0.0088, 'grad_norm': 4.795141220092773, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.007307559717446566, 'loss_2': 0.0015058517456054688, 'loss_3': -16.501052856445312, 'loss_4': 1.9361295700073242, 'epoch': 16.17}
{'loss': 0.0511, 'grad_norm': 11.357613563537598, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.0439528152346611, 'loss_2': 0.007190704345703125, 'loss_3': -16.59600830078125, 'loss_4': 2.2603397369384766, 'epoch': 16.17}
{'loss': 0.0093, 'grad_norm': 6.106558799743652, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.007349594961851835, 'loss_2': 0.001987457275390625, 'loss_3': -16.347108840942383, 'loss_4': 1.3490546941757202, 'epoch': 16.18}
{'loss': 0.0376, 'grad_norm': 14.853560447692871, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.033094532787799835, 'loss_2': 0.0044708251953125, 'loss_3': -16.393054962158203, 'loss_4': 1.627761960029602, 'epoch': 16.19}
{'loss': 0.0151, 'grad_norm': 8.890954971313477, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.014154281467199326, 'loss_2': 0.000896453857421875, 'loss_3': -16.28060531616211, 'loss_4': 1.593811273574829, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 16:26:13,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:13,608 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:09:07<41:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:20,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010811420157551765, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007830092683434486, 'eval_loss_2': 0.002981327474117279, 'eval_loss_3': -18.181148529052734, 'eval_loss_4': 1.7689614295959473, 'epoch': 16.19}
{'loss': 0.0177, 'grad_norm': 9.084709167480469, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.011743648909032345, 'loss_2': 0.005985260009765625, 'loss_3': -16.42780113220215, 'loss_4': 1.3278627395629883, 'epoch': 16.2}
{'loss': 0.0167, 'grad_norm': 5.694955825805664, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.009207131341099739, 'loss_2': 0.007495880126953125, 'loss_3': -16.34920883178711, 'loss_4': 1.654203176498413, 'epoch': 16.2}
{'loss': 0.0072, 'grad_norm': 4.800665855407715, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.004956298507750034, 'loss_2': 0.002216339111328125, 'loss_3': -16.435447692871094, 'loss_4': 2.0929501056671143, 'epoch': 16.21}
{'loss': 0.0151, 'grad_norm': 6.620411396026611, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.012889048084616661, 'loss_2': 0.002166748046875, 'loss_3': -16.498184204101562, 'loss_4': 1.7418198585510254, 'epoch': 16.22}
{'loss': 0.0262, 'grad_norm': 11.165169715881348, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.022565554827451706, 'loss_2': 0.0036830902099609375, 'loss_3': -16.37877082824707, 'loss_4': 2.3248820304870605, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 16:26:20,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:20,958 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:09:14<40:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:28,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012286877259612083, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008476382121443748, 'eval_loss_2': 0.003810495138168335, 'eval_loss_3': -18.208166122436523, 'eval_loss_4': 1.747612714767456, 'epoch': 16.22}
{'loss': 0.0105, 'grad_norm': 6.2008137702941895, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.009473270736634731, 'loss_2': 0.001049041748046875, 'loss_3': -16.34857177734375, 'loss_4': 1.7208342552185059, 'epoch': 16.23}
{'loss': 0.038, 'grad_norm': 14.807034492492676, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.029073309153318405, 'loss_2': 0.00896453857421875, 'loss_3': -16.394268035888672, 'loss_4': 2.208244800567627, 'epoch': 16.23}
{'loss': 0.0126, 'grad_norm': 5.037410736083984, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.006833686958998442, 'loss_2': 0.00579833984375, 'loss_3': -16.579994201660156, 'loss_4': 2.020153522491455, 'epoch': 16.24}
{'loss': 0.0223, 'grad_norm': 7.100955963134766, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.013990839943289757, 'loss_2': 0.00833892822265625, 'loss_3': -16.414749145507812, 'loss_4': 1.7040228843688965, 'epoch': 16.24}
{'loss': 0.0193, 'grad_norm': 5.21346378326416, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.008669132366776466, 'loss_2': 0.01058197021484375, 'loss_3': -16.494823455810547, 'loss_4': 1.8750312328338623, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 16:26:28,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:28,307 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:22<40:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:35,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013459351845085621, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.541, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.008969230577349663, 'eval_loss_2': 0.004490122199058533, 'eval_loss_3': -18.207609176635742, 'eval_loss_4': 1.7322325706481934, 'epoch': 16.25}
{'loss': 0.0236, 'grad_norm': 5.9257001876831055, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.017594721168279648, 'loss_2': 0.006046295166015625, 'loss_3': -16.44316864013672, 'loss_4': 1.9387123584747314, 'epoch': 16.26}
{'loss': 0.0412, 'grad_norm': 13.788864135742188, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.03904833644628525, 'loss_2': 0.002185821533203125, 'loss_3': -16.322757720947266, 'loss_4': 1.9671905040740967, 'epoch': 16.26}
{'loss': 0.0118, 'grad_norm': 5.819315433502197, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.007132689002901316, 'loss_2': 0.00463104248046875, 'loss_3': -16.50027084350586, 'loss_4': 1.9219307899475098, 'epoch': 16.27}
{'loss': 0.0123, 'grad_norm': 6.43894100189209, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.0100993188098073, 'loss_2': 0.002166748046875, 'loss_3': -16.49207305908203, 'loss_4': 1.9679638147354126, 'epoch': 16.27}
{'loss': 0.0201, 'grad_norm': 7.78048038482666, 'learning_rate': 1.375e-05, 'loss_1': 0.013396388851106167, 'loss_2': 0.0067138671875, 'loss_3': -16.416889190673828, 'loss_4': 1.8039240837097168, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 16:26:35,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:35,646 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:29<40:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:42,992 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011260251514613628, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008137519471347332, 'eval_loss_2': 0.0031227320432662964, 'eval_loss_3': -18.207786560058594, 'eval_loss_4': 1.697580099105835, 'epoch': 16.28}
{'loss': 0.0148, 'grad_norm': 5.663012504577637, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.013262909837067127, 'loss_2': 0.001544952392578125, 'loss_3': -16.364673614501953, 'loss_4': 1.7711995840072632, 'epoch': 16.28}
{'loss': 0.0151, 'grad_norm': 6.935737609863281, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.014079947024583817, 'loss_2': 0.001026153564453125, 'loss_3': -16.57375717163086, 'loss_4': 1.5512856245040894, 'epoch': 16.29}
{'loss': 0.0091, 'grad_norm': 5.502230644226074, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.005975041538476944, 'loss_2': 0.003147125244140625, 'loss_3': -16.48310089111328, 'loss_4': 1.5662314891815186, 'epoch': 16.3}
{'loss': 0.0082, 'grad_norm': 4.995220184326172, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.006750216707587242, 'loss_2': 0.0014982223510742188, 'loss_3': -16.519777297973633, 'loss_4': 1.0063164234161377, 'epoch': 16.3}
{'loss': 0.0161, 'grad_norm': 5.693230628967285, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.011462857946753502, 'loss_2': 0.004627227783203125, 'loss_3': -16.53945541381836, 'loss_4': 1.694089651107788, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 16:26:42,992 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:42,992 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:36<40:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:50,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01158100739121437, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.688, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007996981032192707, 'eval_loss_2': 0.0035840272903442383, 'eval_loss_3': -18.21291160583496, 'eval_loss_4': 1.5164903402328491, 'epoch': 16.31}
{'loss': 0.0246, 'grad_norm': 6.799604892730713, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.022113628685474396, 'loss_2': 0.0025177001953125, 'loss_3': -16.538288116455078, 'loss_4': 1.824819564819336, 'epoch': 16.31}
{'loss': 0.0247, 'grad_norm': 7.202408790588379, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.01867559552192688, 'loss_2': 0.006008148193359375, 'loss_3': -16.716785430908203, 'loss_4': 1.5704114437103271, 'epoch': 16.32}
{'loss': 0.0234, 'grad_norm': 9.516864776611328, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.02094600722193718, 'loss_2': 0.002422332763671875, 'loss_3': -16.5880069732666, 'loss_4': 1.8685954809188843, 'epoch': 16.33}
{'loss': 0.0299, 'grad_norm': 8.815597534179688, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.024755103513598442, 'loss_2': 0.005138397216796875, 'loss_3': -16.316131591796875, 'loss_4': 1.1915228366851807, 'epoch': 16.33}
{'loss': 0.0175, 'grad_norm': 5.651595592498779, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.01024874858558178, 'loss_2': 0.00725555419921875, 'loss_3': -16.448352813720703, 'loss_4': 1.0588524341583252, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 16:26:50,355 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:50,355 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:44<40:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:26:57,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012963356450200081, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.933, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00822323840111494, 'eval_loss_2': 0.004740118980407715, 'eval_loss_3': -18.212100982666016, 'eval_loss_4': 1.2926429510116577, 'epoch': 16.34}
{'loss': 0.0238, 'grad_norm': 7.082222938537598, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.011090537533164024, 'loss_2': 0.0126953125, 'loss_3': -16.563480377197266, 'loss_4': 1.4602437019348145, 'epoch': 16.34}
{'loss': 0.0173, 'grad_norm': 7.215285301208496, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.011789191514253616, 'loss_2': 0.005558013916015625, 'loss_3': -16.32394027709961, 'loss_4': 1.4217572212219238, 'epoch': 16.35}
{'loss': 0.0078, 'grad_norm': 4.716882228851318, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.0034832425881177187, 'loss_2': 0.0043182373046875, 'loss_3': -16.36569595336914, 'loss_4': 1.2582706212997437, 'epoch': 16.35}
{'loss': 0.0208, 'grad_norm': 6.8411078453063965, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.01677565649151802, 'loss_2': 0.0040130615234375, 'loss_3': -16.613859176635742, 'loss_4': 1.7850192785263062, 'epoch': 16.36}
{'loss': 0.0209, 'grad_norm': 8.836389541625977, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.014162964187562466, 'loss_2': 0.00676727294921875, 'loss_3': -16.46810531616211, 'loss_4': 0.8771246671676636, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 16:26:57,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:26:57,710 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:48<40:35,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 16:27:01,516 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2815
[INFO|configuration_utils.py:420] 2025-01-21 16:27:01,517 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2815/config.json                                                                            
{'eval_loss': 0.00988253764808178, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0074276006780564785, 'eval_loss_2': 0.0024549365043640137, 'eval_loss_3': -18.21697998046875, 'eval_loss_4': 1.1835525035858154, 'epoch': 16.37}
[INFO|modeling_utils.py:2988] 2025-01-21 16:27:02,004 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2815/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 16:27:02,005 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2815/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 16:27:02,005 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2815/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 16:27:02,996 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2295] due to args.save_total_limit
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:53<44:50,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 16:27:06,618 >>
{'loss': 0.0125, 'grad_norm': 5.775866985321045, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.010251104831695557, 'loss_2': 0.002239227294921875, 'loss_3': -16.446765899658203, 'loss_4': 1.0755785703659058, 'epoch': 16.37}
{'loss': 0.0156, 'grad_norm': 5.469836711883545, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.007834585383534431, 'loss_2': 0.00774383544921875, 'loss_3': -16.417945861816406, 'loss_4': 0.9776730537414551, 'epoch': 16.38}
{'loss': 0.0192, 'grad_norm': 7.854265213012695, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.016968436539173126, 'loss_2': 0.00225830078125, 'loss_3': -16.59063720703125, 'loss_4': 1.2120040655136108, 'epoch': 16.38}
{'loss': 0.0133, 'grad_norm': 5.257659912109375, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.0066458843648433685, 'loss_2': 0.0066375732421875, 'loss_3': -16.544967651367188, 'loss_4': 0.8978945016860962, 'epoch': 16.39}
{'loss': 0.0104, 'grad_norm': 5.544567584991455, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.008829686790704727, 'loss_2': 0.0016021728515625, 'loss_3': -16.334796905517578, 'loss_4': 1.2416470050811768, 'epoch': 16.4}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 16:27:06,618 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:06,618 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:10:00<41:03,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 16:27:13,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011117087677121162, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.614, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008348346687853336, 'eval_loss_2': 0.0027687400579452515, 'eval_loss_3': -18.19757652282715, 'eval_loss_4': 1.1750569343566895, 'epoch': 16.4}
{'loss': 0.0236, 'grad_norm': 11.558938980102539, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.020800529047846794, 'loss_2': 0.002780914306640625, 'loss_3': -16.41845703125, 'loss_4': 0.7536514401435852, 'epoch': 16.4}
{'loss': 0.0093, 'grad_norm': 4.981716156005859, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.008583891205489635, 'loss_2': 0.0007390975952148438, 'loss_3': -16.51201629638672, 'loss_4': 1.5547609329223633, 'epoch': 16.41}
{'loss': 0.0539, 'grad_norm': 36.03968048095703, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.04789929836988449, 'loss_2': 0.006038665771484375, 'loss_3': -16.39299774169922, 'loss_4': 1.381194829940796, 'epoch': 16.41}
{'loss': 0.0135, 'grad_norm': 5.4165544509887695, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.011975385248661041, 'loss_2': 0.001491546630859375, 'loss_3': -16.316926956176758, 'loss_4': 1.4230366945266724, 'epoch': 16.42}
{'loss': 0.0067, 'grad_norm': 4.655076026916504, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.004616511985659599, 'loss_2': 0.0021038055419921875, 'loss_3': -16.412527084350586, 'loss_4': 1.2005382776260376, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 16:27:13,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:13,952 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:10:07<40:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:21,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012540335766971111, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.763, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.008522684685885906, 'eval_loss_2': 0.004017651081085205, 'eval_loss_3': -18.18419075012207, 'eval_loss_4': 1.1813580989837646, 'epoch': 16.42}
{'loss': 0.0047, 'grad_norm': 4.457580089569092, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.003994723781943321, 'loss_2': 0.0007171630859375, 'loss_3': -16.459705352783203, 'loss_4': 1.1082592010498047, 'epoch': 16.43}
{'loss': 0.0123, 'grad_norm': 5.82360315322876, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.009995882399380207, 'loss_2': 0.00232696533203125, 'loss_3': -16.377925872802734, 'loss_4': 1.339056372642517, 'epoch': 16.44}
{'loss': 0.0138, 'grad_norm': 8.402791976928711, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.009758472442626953, 'loss_2': 0.0040130615234375, 'loss_3': -16.543643951416016, 'loss_4': 0.9752092361450195, 'epoch': 16.44}
{'loss': 0.0333, 'grad_norm': 6.173408508300781, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.021073149517178535, 'loss_2': 0.0122528076171875, 'loss_3': -16.108610153198242, 'loss_4': 0.8068246841430664, 'epoch': 16.45}
{'loss': 0.0163, 'grad_norm': 4.546855926513672, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.005425152834504843, 'loss_2': 0.0108489990234375, 'loss_3': -16.558528900146484, 'loss_4': 1.4180943965911865, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 16:27:21,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:21,275 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:10:15<40:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:28,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016091056168079376, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.654, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008309610188007355, 'eval_loss_2': 0.0077814459800720215, 'eval_loss_3': -18.164566040039062, 'eval_loss_4': 1.1991312503814697, 'epoch': 16.45}
{'loss': 0.015, 'grad_norm': 5.456833362579346, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.008047552779316902, 'loss_2': 0.00699615478515625, 'loss_3': -16.461334228515625, 'loss_4': 1.1387653350830078, 'epoch': 16.46}
{'loss': 0.0411, 'grad_norm': 13.623617172241211, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.033383775502443314, 'loss_2': 0.00775146484375, 'loss_3': -16.223526000976562, 'loss_4': 0.8614925146102905, 'epoch': 16.47}
{'loss': 0.0179, 'grad_norm': 7.040274620056152, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.014105751179158688, 'loss_2': 0.00379180908203125, 'loss_3': -16.44669532775879, 'loss_4': 1.0463008880615234, 'epoch': 16.47}
{'loss': 0.0286, 'grad_norm': 16.429704666137695, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.02249148115515709, 'loss_2': 0.006134033203125, 'loss_3': -16.44685173034668, 'loss_4': 0.8398998975753784, 'epoch': 16.48}
{'loss': 0.0223, 'grad_norm': 6.878377914428711, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.011692263185977936, 'loss_2': 0.0106048583984375, 'loss_3': -16.37040138244629, 'loss_4': 1.1713619232177734, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 16:27:28,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:28,609 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:22<40:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:35,946 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014369421638548374, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.617, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009168604388833046, 'eval_loss_2': 0.005200818181037903, 'eval_loss_3': -18.162784576416016, 'eval_loss_4': 1.127592921257019, 'epoch': 16.48}
{'loss': 0.0133, 'grad_norm': 4.934404373168945, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.006102669518440962, 'loss_2': 0.0072174072265625, 'loss_3': -16.299150466918945, 'loss_4': 1.197575330734253, 'epoch': 16.49}
{'loss': 0.0282, 'grad_norm': 17.51266860961914, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.02475481480360031, 'loss_2': 0.0034847259521484375, 'loss_3': -16.503589630126953, 'loss_4': 1.0669059753417969, 'epoch': 16.49}
{'loss': 0.0128, 'grad_norm': 5.250492095947266, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.012201483361423016, 'loss_2': 0.0005660057067871094, 'loss_3': -16.508562088012695, 'loss_4': 1.042836308479309, 'epoch': 16.5}
{'loss': 0.0159, 'grad_norm': 6.422280311584473, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.0095231207087636, 'loss_2': 0.0063629150390625, 'loss_3': -16.38860321044922, 'loss_4': 0.8956211805343628, 'epoch': 16.51}
{'loss': 0.0156, 'grad_norm': 5.457687854766846, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.011339502409100533, 'loss_2': 0.004283905029296875, 'loss_3': -16.288997650146484, 'loss_4': 1.121794581413269, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 16:27:35,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:35,946 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:29<40:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:43,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011085644364356995, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.994, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008777372539043427, 'eval_loss_2': 0.002308271825313568, 'eval_loss_3': -18.1674861907959, 'eval_loss_4': 1.221815824508667, 'epoch': 16.51}
{'loss': 0.0144, 'grad_norm': 5.137039661407471, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.009057187475264072, 'loss_2': 0.00531005859375, 'loss_3': -16.40614128112793, 'loss_4': 1.5607430934906006, 'epoch': 16.52}
{'loss': 0.0207, 'grad_norm': 6.42095947265625, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.014518814161419868, 'loss_2': 0.00617218017578125, 'loss_3': -16.412921905517578, 'loss_4': 1.2674143314361572, 'epoch': 16.52}
{'loss': 0.0097, 'grad_norm': 4.650076389312744, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.007336762733757496, 'loss_2': 0.0023193359375, 'loss_3': -16.36745262145996, 'loss_4': 0.9241134524345398, 'epoch': 16.53}
{'loss': 0.012, 'grad_norm': 7.336269855499268, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.011413143016397953, 'loss_2': 0.0006084442138671875, 'loss_3': -16.66757583618164, 'loss_4': 1.4238934516906738, 'epoch': 16.53}
{'loss': 0.0911, 'grad_norm': 32.63750457763672, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.08897361159324646, 'loss_2': 0.002101898193359375, 'loss_3': -16.38434410095215, 'loss_4': 1.8094316720962524, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 16:27:43,295 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:43,295 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:37<39:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:50,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014644969254732132, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.925, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010902319103479385, 'eval_loss_2': 0.0037426501512527466, 'eval_loss_3': -18.13863754272461, 'eval_loss_4': 1.4393478631973267, 'epoch': 16.54}
{'loss': 0.0121, 'grad_norm': 8.756587028503418, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.011541218496859074, 'loss_2': 0.0005545616149902344, 'loss_3': -16.472103118896484, 'loss_4': 1.4823532104492188, 'epoch': 16.55}
{'loss': 0.0166, 'grad_norm': 7.031965732574463, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.01592111587524414, 'loss_2': 0.000701904296875, 'loss_3': -16.426971435546875, 'loss_4': 1.139542818069458, 'epoch': 16.55}
{'loss': 0.0194, 'grad_norm': 6.924954414367676, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.014774986542761326, 'loss_2': 0.004650115966796875, 'loss_3': -16.34319305419922, 'loss_4': 1.531270146369934, 'epoch': 16.56}
{'loss': 0.0123, 'grad_norm': 5.918883800506592, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.0065795364789664745, 'loss_2': 0.005748748779296875, 'loss_3': -16.4626522064209, 'loss_4': 1.5064572095870972, 'epoch': 16.56}
{'loss': 0.0135, 'grad_norm': 6.278866291046143, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.009850801900029182, 'loss_2': 0.0036792755126953125, 'loss_3': -16.426572799682617, 'loss_4': 1.658686637878418, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 16:27:50,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:50,626 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:44<39:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:27:57,954 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013886718079447746, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.981, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010925231501460075, 'eval_loss_2': 0.002961486577987671, 'eval_loss_3': -18.1549072265625, 'eval_loss_4': 1.5727094411849976, 'epoch': 16.57}
{'loss': 0.0105, 'grad_norm': 6.700465202331543, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.009504791349172592, 'loss_2': 0.0009851455688476562, 'loss_3': -16.491575241088867, 'loss_4': 1.4765374660491943, 'epoch': 16.58}
{'loss': 0.0142, 'grad_norm': 6.210105895996094, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.010058515705168247, 'loss_2': 0.004123687744140625, 'loss_3': -16.537641525268555, 'loss_4': 1.491776704788208, 'epoch': 16.58}
{'loss': 0.0328, 'grad_norm': 7.3310651779174805, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.021169092506170273, 'loss_2': 0.01160430908203125, 'loss_3': -16.286069869995117, 'loss_4': 1.6942511796951294, 'epoch': 16.59}
{'loss': 0.0199, 'grad_norm': 6.667326927185059, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.01401340588927269, 'loss_2': 0.00592041015625, 'loss_3': -16.193946838378906, 'loss_4': 1.375891923904419, 'epoch': 16.59}
{'loss': 0.0083, 'grad_norm': 4.6673502922058105, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.008219858631491661, 'loss_2': 0.00010025501251220703, 'loss_3': -16.569124221801758, 'loss_4': 2.280857563018799, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 16:27:57,954 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:27:57,954 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:51<39:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:05,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014157949015498161, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.34, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01016721036285162, 'eval_loss_2': 0.003990739583969116, 'eval_loss_3': -18.14944839477539, 'eval_loss_4': 1.5969548225402832, 'epoch': 16.6}
{'loss': 0.0075, 'grad_norm': 4.702969074249268, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.006533976644277573, 'loss_2': 0.0009641647338867188, 'loss_3': -16.294368743896484, 'loss_4': 1.6024889945983887, 'epoch': 16.6}
{'loss': 0.0182, 'grad_norm': 4.867453575134277, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.009210052900016308, 'loss_2': 0.00896453857421875, 'loss_3': -16.36312484741211, 'loss_4': 1.815241813659668, 'epoch': 16.61}
{'loss': 0.0113, 'grad_norm': 4.944964408874512, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.00648105563595891, 'loss_2': 0.004852294921875, 'loss_3': -16.473800659179688, 'loss_4': 1.8472797870635986, 'epoch': 16.62}
{'loss': 0.0329, 'grad_norm': 12.876038551330566, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.028710275888442993, 'loss_2': 0.004180908203125, 'loss_3': -16.215938568115234, 'loss_4': 1.3988364934921265, 'epoch': 16.62}
{'loss': 0.0193, 'grad_norm': 7.219860553741455, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.01925406977534294, 'loss_2': 5.370378494262695e-05, 'loss_3': -16.484268188476562, 'loss_4': 1.8256313800811768, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 16:28:05,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:05,301 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:10:59<39:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:12,634 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013288693502545357, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.941, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.00936825666576624, 'eval_loss_2': 0.003920435905456543, 'eval_loss_3': -18.16297721862793, 'eval_loss_4': 1.4627023935317993, 'epoch': 16.63}
{'loss': 0.0196, 'grad_norm': 5.760746002197266, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.014377017505466938, 'loss_2': 0.005229949951171875, 'loss_3': -16.304885864257812, 'loss_4': 2.1737680435180664, 'epoch': 16.63}
{'loss': 0.0179, 'grad_norm': 8.943216323852539, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.017083438113331795, 'loss_2': 0.0008645057678222656, 'loss_3': -16.605257034301758, 'loss_4': 1.3390833139419556, 'epoch': 16.64}
{'loss': 0.0089, 'grad_norm': 4.761044979095459, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.008268944919109344, 'loss_2': 0.000659942626953125, 'loss_3': -16.492507934570312, 'loss_4': 1.2327721118927002, 'epoch': 16.65}
{'loss': 0.0106, 'grad_norm': 5.331149101257324, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.009779706597328186, 'loss_2': 0.00080108642578125, 'loss_3': -16.524497985839844, 'loss_4': 1.6073837280273438, 'epoch': 16.65}
{'loss': 0.0194, 'grad_norm': 7.853824615478516, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.018845709040760994, 'loss_2': 0.0005245208740234375, 'loss_3': -16.368534088134766, 'loss_4': 1.3849782943725586, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 16:28:12,634 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:12,634 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:11:06<39:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:19,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01269540749490261, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009400373324751854, 'eval_loss_2': 0.003295034170150757, 'eval_loss_3': -18.15270233154297, 'eval_loss_4': 1.329445719718933, 'epoch': 16.66}
{'loss': 0.0136, 'grad_norm': 5.522933483123779, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.010027197189629078, 'loss_2': 0.00360107421875, 'loss_3': -16.307125091552734, 'loss_4': 0.5907139778137207, 'epoch': 16.66}
{'loss': 0.0151, 'grad_norm': 4.278642654418945, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.0063564591109752655, 'loss_2': 0.0087432861328125, 'loss_3': -16.1591739654541, 'loss_4': 0.8301047086715698, 'epoch': 16.67}
{'loss': 0.0187, 'grad_norm': 6.405111789703369, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.008418602868914604, 'loss_2': 0.01031494140625, 'loss_3': -16.265918731689453, 'loss_4': 1.4680428504943848, 'epoch': 16.67}
{'loss': 0.0183, 'grad_norm': 5.890995502471924, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.012168947607278824, 'loss_2': 0.0061798095703125, 'loss_3': -16.298770904541016, 'loss_4': 0.9882553815841675, 'epoch': 16.68}
{'loss': 0.022, 'grad_norm': 5.65474271774292, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.011453486979007721, 'loss_2': 0.01055908203125, 'loss_3': -16.34495735168457, 'loss_4': 1.3880245685577393, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 16:28:19,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:19,986 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:11:13<39:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:27,330 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01358608715236187, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009183866903185844, 'eval_loss_2': 0.004402220249176025, 'eval_loss_3': -18.15222930908203, 'eval_loss_4': 1.1868304014205933, 'epoch': 16.69}
{'loss': 0.0286, 'grad_norm': 6.40933084487915, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.020371299237012863, 'loss_2': 0.0081939697265625, 'loss_3': -16.278289794921875, 'loss_4': 1.0598691701889038, 'epoch': 16.69}
{'loss': 0.0373, 'grad_norm': 8.45627212524414, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.03375623747706413, 'loss_2': 0.00350189208984375, 'loss_3': -16.548477172851562, 'loss_4': 1.1400249004364014, 'epoch': 16.7}
{'loss': 0.0142, 'grad_norm': 6.278658866882324, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.013989802449941635, 'loss_2': 0.0002378225326538086, 'loss_3': -16.559995651245117, 'loss_4': 1.5686826705932617, 'epoch': 16.7}
{'loss': 0.0151, 'grad_norm': 5.446338653564453, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.009729161858558655, 'loss_2': 0.005329132080078125, 'loss_3': -16.47056770324707, 'loss_4': 1.1943539381027222, 'epoch': 16.71}
{'loss': 0.0198, 'grad_norm': 5.13405704498291, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.01365847047418356, 'loss_2': 0.00614166259765625, 'loss_3': -16.312618255615234, 'loss_4': 1.2281931638717651, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 16:28:27,330 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:27,330 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:21<39:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:34,672 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011543869972229004, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.551, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009018397890031338, 'eval_loss_2': 0.0025254711508750916, 'eval_loss_3': -18.156160354614258, 'eval_loss_4': 1.0635607242584229, 'epoch': 16.72}
{'loss': 0.0127, 'grad_norm': 6.112143039703369, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.007280988153070211, 'loss_2': 0.005458831787109375, 'loss_3': -16.56354331970215, 'loss_4': 1.1686153411865234, 'epoch': 16.72}
{'loss': 0.0113, 'grad_norm': 5.177709102630615, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.01015649363398552, 'loss_2': 0.0011043548583984375, 'loss_3': -16.656692504882812, 'loss_4': 1.227203130722046, 'epoch': 16.73}
{'loss': 0.0124, 'grad_norm': 6.153872966766357, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.010193902999162674, 'loss_2': 0.002185821533203125, 'loss_3': -16.51045799255371, 'loss_4': 0.7234584093093872, 'epoch': 16.73}
{'loss': 0.0063, 'grad_norm': 4.973021030426025, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.006222606170922518, 'loss_2': 0.00011599063873291016, 'loss_3': -16.512117385864258, 'loss_4': 1.3724876642227173, 'epoch': 16.74}
{'loss': 0.0138, 'grad_norm': 5.527669429779053, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.009889209643006325, 'loss_2': 0.003887176513671875, 'loss_3': -16.56770896911621, 'loss_4': 1.2740238904953003, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 16:28:34,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:34,673 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:28<39:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:42,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012305974960327148, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.552, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.00985214114189148, 'eval_loss_2': 0.002453833818435669, 'eval_loss_3': -18.142986297607422, 'eval_loss_4': 1.0849488973617554, 'epoch': 16.74}
{'loss': 0.0125, 'grad_norm': 4.945146083831787, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.008253293111920357, 'loss_2': 0.00424957275390625, 'loss_3': -16.564977645874023, 'loss_4': 1.191589117050171, 'epoch': 16.75}
{'loss': 0.0273, 'grad_norm': 8.020185470581055, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.0218264851719141, 'loss_2': 0.00542449951171875, 'loss_3': -16.22323226928711, 'loss_4': 1.4281593561172485, 'epoch': 16.76}
{'loss': 0.0214, 'grad_norm': 6.940916538238525, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.017426250502467155, 'loss_2': 0.00395965576171875, 'loss_3': -16.521175384521484, 'loss_4': 1.2951340675354004, 'epoch': 16.76}
{'loss': 0.0135, 'grad_norm': 6.704739570617676, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.011378412134945393, 'loss_2': 0.00215911865234375, 'loss_3': -16.404987335205078, 'loss_4': 1.223761796951294, 'epoch': 16.77}
{'loss': 0.0164, 'grad_norm': 5.469686985015869, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.012389566749334335, 'loss_2': 0.0039825439453125, 'loss_3': -16.519054412841797, 'loss_4': 1.175849437713623, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 16:28:42,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:42,007 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:35<39:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:49,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014363348484039307, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.636, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011827276088297367, 'eval_loss_2': 0.002536073327064514, 'eval_loss_3': -18.140615463256836, 'eval_loss_4': 1.1396204233169556, 'epoch': 16.77}
{'loss': 0.0158, 'grad_norm': 6.111190319061279, 'learning_rate': 1.325e-05, 'loss_1': 0.009882214479148388, 'loss_2': 0.00588226318359375, 'loss_3': -16.453386306762695, 'loss_4': 0.9374277591705322, 'epoch': 16.78}
{'loss': 0.0339, 'grad_norm': 12.198858261108398, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.030252808704972267, 'loss_2': 0.003643035888671875, 'loss_3': -16.52233123779297, 'loss_4': 1.3875203132629395, 'epoch': 16.78}
{'loss': 0.0367, 'grad_norm': 19.825183868408203, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.031966887414455414, 'loss_2': 0.00470733642578125, 'loss_3': -16.388925552368164, 'loss_4': 1.1418198347091675, 'epoch': 16.79}
{'loss': 0.017, 'grad_norm': 6.476281642913818, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.012345744296908379, 'loss_2': 0.004638671875, 'loss_3': -16.383617401123047, 'loss_4': 1.1914293766021729, 'epoch': 16.8}
{'loss': 0.0255, 'grad_norm': 9.397497177124023, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.01745489053428173, 'loss_2': 0.00799560546875, 'loss_3': -16.440078735351562, 'loss_4': 1.1993499994277954, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 16:28:49,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:49,346 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:43<39:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:28:56,682 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017400037497282028, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.716, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.014644757844507694, 'eval_loss_2': 0.00275527685880661, 'eval_loss_3': -18.117942810058594, 'eval_loss_4': 1.2482830286026, 'epoch': 16.8}
{'loss': 0.0203, 'grad_norm': 6.3928704261779785, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.015272133983671665, 'loss_2': 0.005069732666015625, 'loss_3': -16.54707908630371, 'loss_4': 1.6741620302200317, 'epoch': 16.81}
{'loss': 0.0208, 'grad_norm': 8.787983894348145, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.019787782803177834, 'loss_2': 0.0010347366333007812, 'loss_3': -16.63235855102539, 'loss_4': 1.2711704969406128, 'epoch': 16.81}
{'loss': 0.0103, 'grad_norm': 6.212653160095215, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.00894182175397873, 'loss_2': 0.0013942718505859375, 'loss_3': -16.56012725830078, 'loss_4': 0.9831256866455078, 'epoch': 16.82}
{'loss': 0.0267, 'grad_norm': 8.559200286865234, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.017746321856975555, 'loss_2': 0.00897979736328125, 'loss_3': -16.406238555908203, 'loss_4': 1.5629184246063232, 'epoch': 16.83}
{'loss': 0.0446, 'grad_norm': 21.835851669311523, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.03771902993321419, 'loss_2': 0.00691986083984375, 'loss_3': -16.463167190551758, 'loss_4': 1.45063316822052, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 16:28:56,682 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:28:56,682 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:50<39:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:04,022 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02076343633234501, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.039, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.017194829881191254, 'eval_loss_2': 0.003568604588508606, 'eval_loss_3': -18.086336135864258, 'eval_loss_4': 1.3731263875961304, 'epoch': 16.83}
{'loss': 0.0174, 'grad_norm': 7.426820755004883, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.01704907976090908, 'loss_2': 0.0003094673156738281, 'loss_3': -16.585126876831055, 'loss_4': 1.31828773021698, 'epoch': 16.84}
{'loss': 0.0264, 'grad_norm': 16.18658447265625, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.022095998749136925, 'loss_2': 0.0043182373046875, 'loss_3': -16.365917205810547, 'loss_4': 1.1277813911437988, 'epoch': 16.84}
{'loss': 0.0182, 'grad_norm': 5.518855571746826, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.007861251011490822, 'loss_2': 0.01031494140625, 'loss_3': -16.198698043823242, 'loss_4': 0.8626095652580261, 'epoch': 16.85}
{'loss': 0.0214, 'grad_norm': 10.45155143737793, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.017686473205685616, 'loss_2': 0.0036792755126953125, 'loss_3': -16.243244171142578, 'loss_4': 1.0608124732971191, 'epoch': 16.85}
{'loss': 0.0854, 'grad_norm': 14.888797760009766, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.0833488255739212, 'loss_2': 0.00209808349609375, 'loss_3': -16.417232513427734, 'loss_4': 1.8628592491149902, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 16:29:04,022 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:04,022 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:11:57<38:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:11,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019842829555273056, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.467, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.016455892473459244, 'eval_loss_2': 0.0033869370818138123, 'eval_loss_3': -18.093732833862305, 'eval_loss_4': 1.414954662322998, 'epoch': 16.86}
{'loss': 0.0097, 'grad_norm': 4.8117804527282715, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.007894371636211872, 'loss_2': 0.0017948150634765625, 'loss_3': -16.411035537719727, 'loss_4': 1.4864985942840576, 'epoch': 16.87}
{'loss': 0.0179, 'grad_norm': 6.857191562652588, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.014092703349888325, 'loss_2': 0.0037975311279296875, 'loss_3': -16.434873580932617, 'loss_4': 1.7348194122314453, 'epoch': 16.87}
{'loss': 0.0488, 'grad_norm': 19.367691040039062, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.048324473202228546, 'loss_2': 0.0004317760467529297, 'loss_3': -16.18389892578125, 'loss_4': 1.5128285884857178, 'epoch': 16.88}
{'loss': 0.0151, 'grad_norm': 5.1996893882751465, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.00902093481272459, 'loss_2': 0.006072998046875, 'loss_3': -16.315868377685547, 'loss_4': 1.4417368173599243, 'epoch': 16.88}
{'loss': 0.0234, 'grad_norm': 5.722349643707275, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.012417145073413849, 'loss_2': 0.01099395751953125, 'loss_3': -16.258092880249023, 'loss_4': 1.3340572118759155, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 16:29:11,361 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:11,361 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:12:05<38:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:18,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021810142323374748, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.733, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01895800232887268, 'eval_loss_2': 0.002852141857147217, 'eval_loss_3': -18.084941864013672, 'eval_loss_4': 1.3630425930023193, 'epoch': 16.89}
{'loss': 0.0119, 'grad_norm': 4.62563943862915, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.008385158143937588, 'loss_2': 0.0035400390625, 'loss_3': -16.35541534423828, 'loss_4': 1.4806337356567383, 'epoch': 16.9}
{'loss': 0.02, 'grad_norm': 10.307146072387695, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.019346287474036217, 'loss_2': 0.000698089599609375, 'loss_3': -16.337251663208008, 'loss_4': 1.469022512435913, 'epoch': 16.9}
{'loss': 0.0122, 'grad_norm': 6.595236778259277, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.010701512917876244, 'loss_2': 0.0014791488647460938, 'loss_3': -16.22223663330078, 'loss_4': 1.4200236797332764, 'epoch': 16.91}
{'loss': 0.025, 'grad_norm': 9.044417381286621, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.02171308360993862, 'loss_2': 0.0033321380615234375, 'loss_3': -16.263187408447266, 'loss_4': 1.4001933336257935, 'epoch': 16.91}
{'loss': 0.0061, 'grad_norm': 4.977445602416992, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.006085504312068224, 'loss_2': 5.125999450683594e-05, 'loss_3': -16.235383987426758, 'loss_4': 1.3080222606658936, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 16:29:18,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:18,694 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:12:12<38:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:26,032 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015718992799520493, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.84, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011728044599294662, 'eval_loss_2': 0.00399094820022583, 'eval_loss_3': -18.106033325195312, 'eval_loss_4': 1.229556679725647, 'epoch': 16.92}
{'loss': 0.0104, 'grad_norm': 5.317145824432373, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.007883928716182709, 'loss_2': 0.002468109130859375, 'loss_3': -16.405227661132812, 'loss_4': 1.5078623294830322, 'epoch': 16.92}
{'loss': 0.0164, 'grad_norm': 12.728899955749512, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.010759669356048107, 'loss_2': 0.00559234619140625, 'loss_3': -16.509796142578125, 'loss_4': 0.7786174416542053, 'epoch': 16.93}
{'loss': 0.0104, 'grad_norm': 4.865314483642578, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.006563838571310043, 'loss_2': 0.00379180908203125, 'loss_3': -16.384668350219727, 'loss_4': 1.1014955043792725, 'epoch': 16.94}
{'loss': 0.0088, 'grad_norm': 4.32742977142334, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.004506770521402359, 'loss_2': 0.00432586669921875, 'loss_3': -16.456804275512695, 'loss_4': 1.2050148248672485, 'epoch': 16.94}
{'loss': 0.0187, 'grad_norm': 7.5104756355285645, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.013927045278251171, 'loss_2': 0.00476837158203125, 'loss_3': -16.463468551635742, 'loss_4': 1.4895737171173096, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 16:29:26,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:26,032 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:19<38:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:29:33,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014639362692832947, 'eval_runtime': 3.7962, 'eval_samples_per_second': 269.744, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010696344077587128, 'eval_loss_2': 0.003943018615245819, 'eval_loss_3': -18.166397094726562, 'eval_loss_4': 1.3085918426513672, 'epoch': 16.95}
{'loss': 0.0083, 'grad_norm': 5.246786117553711, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.006844969000667334, 'loss_2': 0.00148773193359375, 'loss_3': -16.332693099975586, 'loss_4': 1.0719282627105713, 'epoch': 16.95}
{'loss': 0.015, 'grad_norm': 5.092430114746094, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.009836187586188316, 'loss_2': 0.00514984130859375, 'loss_3': -16.413494110107422, 'loss_4': 1.478791356086731, 'epoch': 16.96}
{'loss': 0.0192, 'grad_norm': 8.829541206359863, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.014601949602365494, 'loss_2': 0.00457000732421875, 'loss_3': -16.2080078125, 'loss_4': 1.903139352798462, 'epoch': 16.97}
{'loss': 0.0342, 'grad_norm': 12.701591491699219, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.029689829796552658, 'loss_2': 0.004520416259765625, 'loss_3': -16.31960678100586, 'loss_4': 0.8918819427490234, 'epoch': 16.97}
{'loss': 0.0223, 'grad_norm': 8.668009757995605, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.021737538278102875, 'loss_2': 0.0005617141723632812, 'loss_3': -16.38370132446289, 'loss_4': 1.4340230226516724, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 16:29:33,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:33,369 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:26<36:21,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:29:40,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01292873453348875, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009211945347487926, 'eval_loss_2': 0.003716789186000824, 'eval_loss_3': -18.185754776000977, 'eval_loss_4': 1.4556649923324585, 'epoch': 16.98}
{'loss': 0.031, 'grad_norm': 13.312779426574707, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.03096572309732437, 'loss_2': 2.8371810913085938e-05, 'loss_3': -16.375869750976562, 'loss_4': 1.9692517518997192, 'epoch': 16.98}
{'loss': 0.0105, 'grad_norm': 6.669744968414307, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.008907223120331764, 'loss_2': 0.001575469970703125, 'loss_3': -16.319377899169922, 'loss_4': 1.6986067295074463, 'epoch': 16.99}
{'loss': 0.0211, 'grad_norm': 8.372597694396973, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.020369183272123337, 'loss_2': 0.0007371902465820312, 'loss_3': -16.491687774658203, 'loss_4': 1.9706138372421265, 'epoch': 16.99}
{'loss': 0.0063, 'grad_norm': 7.686400890350342, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.004194436129182577, 'loss_2': 0.002079010009765625, 'loss_3': -16.55855941772461, 'loss_4': 1.9220774173736572, 'epoch': 17.0}
{'loss': 0.017, 'grad_norm': 5.963582992553711, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.013959177769720554, 'loss_2': 0.0029964447021484375, 'loss_3': -16.676603317260742, 'loss_4': 1.2644189596176147, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 16:29:40,397 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:40,397 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:34<38:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:29:47,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013786882162094116, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01014703419059515, 'eval_loss_2': 0.0036398470401763916, 'eval_loss_3': -18.19730567932129, 'eval_loss_4': 1.4749091863632202, 'epoch': 17.01}
{'loss': 0.0217, 'grad_norm': 6.254179000854492, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.015713561326265335, 'loss_2': 0.00603485107421875, 'loss_3': -16.538206100463867, 'loss_4': 1.689814567565918, 'epoch': 17.01}
{'loss': 0.0141, 'grad_norm': 7.374779224395752, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.01381618995219469, 'loss_2': 0.00023436546325683594, 'loss_3': -16.309072494506836, 'loss_4': 1.736348032951355, 'epoch': 17.02}
{'loss': 0.0209, 'grad_norm': 10.839362144470215, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.02065170556306839, 'loss_2': 0.0002810955047607422, 'loss_3': -16.277202606201172, 'loss_4': 1.4163062572479248, 'epoch': 17.02}
{'loss': 0.0256, 'grad_norm': 9.31119441986084, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.019659286364912987, 'loss_2': 0.005954742431640625, 'loss_3': -16.46533966064453, 'loss_4': 0.9394896626472473, 'epoch': 17.03}
{'loss': 0.0166, 'grad_norm': 7.95229959487915, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.015457901172339916, 'loss_2': 0.0011653900146484375, 'loss_3': -16.50755500793457, 'loss_4': 1.3640458583831787, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 16:29:47,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:47,734 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:41<38:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:29:55,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01397207286208868, 'eval_runtime': 3.7936, 'eval_samples_per_second': 269.929, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009976028464734554, 'eval_loss_2': 0.003996044397354126, 'eval_loss_3': -18.207195281982422, 'eval_loss_4': 1.5302155017852783, 'epoch': 17.03}
{'loss': 0.0097, 'grad_norm': 5.3418660163879395, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.008531990461051464, 'loss_2': 0.001171112060546875, 'loss_3': -16.547277450561523, 'loss_4': 1.7353172302246094, 'epoch': 17.04}
{'loss': 0.0115, 'grad_norm': 6.117351055145264, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.00980154424905777, 'loss_2': 0.0017070770263671875, 'loss_3': -16.552825927734375, 'loss_4': 1.3227611780166626, 'epoch': 17.05}
{'loss': 0.0147, 'grad_norm': 8.809435844421387, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.010902894660830498, 'loss_2': 0.0038127899169921875, 'loss_3': -16.19850730895996, 'loss_4': 1.6067850589752197, 'epoch': 17.05}
{'loss': 0.0132, 'grad_norm': 5.246860504150391, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.005630019120872021, 'loss_2': 0.007564544677734375, 'loss_3': -16.398744583129883, 'loss_4': 1.7309424877166748, 'epoch': 17.06}
{'loss': 0.0245, 'grad_norm': 7.17733907699585, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.02303188107907772, 'loss_2': 0.001468658447265625, 'loss_3': -16.57851791381836, 'loss_4': 1.5326523780822754, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 16:29:55,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:29:55,061 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:48<38:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:02,392 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015129972249269485, 'eval_runtime': 3.797, 'eval_samples_per_second': 269.685, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010668860748410225, 'eval_loss_2': 0.004461109638214111, 'eval_loss_3': -18.21520233154297, 'eval_loss_4': 1.556228756904602, 'epoch': 17.06}
{'loss': 0.0076, 'grad_norm': 5.134411334991455, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.006947438698261976, 'loss_2': 0.000698089599609375, 'loss_3': -16.460603713989258, 'loss_4': 1.453346848487854, 'epoch': 17.07}
{'loss': 0.0113, 'grad_norm': 6.234305381774902, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.010602530092000961, 'loss_2': 0.0006761550903320312, 'loss_3': -16.37061309814453, 'loss_4': 1.4454973936080933, 'epoch': 17.08}
{'loss': 0.0422, 'grad_norm': 18.470243453979492, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.03842991217970848, 'loss_2': 0.003795623779296875, 'loss_3': -16.491893768310547, 'loss_4': 1.6376010179519653, 'epoch': 17.08}
{'loss': 0.0109, 'grad_norm': 5.892244815826416, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.010507720522582531, 'loss_2': 0.0003848075866699219, 'loss_3': -16.465118408203125, 'loss_4': 1.4945175647735596, 'epoch': 17.09}
{'loss': 0.0162, 'grad_norm': 9.58894157409668, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.013974734582006931, 'loss_2': 0.0022640228271484375, 'loss_3': -16.63180160522461, 'loss_4': 1.6900720596313477, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 16:30:02,392 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:02,392 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:12:56<38:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:09,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01431348454207182, 'eval_runtime': 3.7923, 'eval_samples_per_second': 270.019, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.011646080762147903, 'eval_loss_2': 0.0026674047112464905, 'eval_loss_3': -18.234838485717773, 'eval_loss_4': 1.5433316230773926, 'epoch': 17.09}
{'loss': 0.0162, 'grad_norm': 7.366150856018066, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.014360861852765083, 'loss_2': 0.0018463134765625, 'loss_3': -16.4697322845459, 'loss_4': 1.7704553604125977, 'epoch': 17.1}
{'loss': 0.0229, 'grad_norm': 6.6295576095581055, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.01525920070707798, 'loss_2': 0.00768280029296875, 'loss_3': -16.4671688079834, 'loss_4': 1.8565293550491333, 'epoch': 17.1}
{'loss': 0.0226, 'grad_norm': 12.940801620483398, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.02251155488193035, 'loss_2': 6.747245788574219e-05, 'loss_3': -16.517147064208984, 'loss_4': 1.669332504272461, 'epoch': 17.11}
{'loss': 0.0321, 'grad_norm': 7.429581165313721, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.01856951415538788, 'loss_2': 0.01351165771484375, 'loss_3': -16.15651512145996, 'loss_4': 1.037258505821228, 'epoch': 17.12}
{'loss': 0.0323, 'grad_norm': 13.953116416931152, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.026600172743201256, 'loss_2': 0.005687713623046875, 'loss_3': -16.53711700439453, 'loss_4': 1.5820832252502441, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 16:30:09,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:09,732 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:13:03<38:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:17,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01490910816937685, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01164370495826006, 'eval_loss_2': 0.0032654032111167908, 'eval_loss_3': -18.224132537841797, 'eval_loss_4': 1.40510892868042, 'epoch': 17.12}
{'loss': 0.0231, 'grad_norm': 8.548637390136719, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.02108466625213623, 'loss_2': 0.002010345458984375, 'loss_3': -16.478378295898438, 'loss_4': 1.4515048265457153, 'epoch': 17.13}
{'loss': 0.0491, 'grad_norm': 13.83253002166748, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.043302424252033234, 'loss_2': 0.00576019287109375, 'loss_3': -16.367511749267578, 'loss_4': 1.3310883045196533, 'epoch': 17.13}
{'loss': 0.012, 'grad_norm': 5.945620059967041, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.009351972490549088, 'loss_2': 0.002635955810546875, 'loss_3': -16.546884536743164, 'loss_4': 1.2320551872253418, 'epoch': 17.14}
{'loss': 0.0076, 'grad_norm': 5.540556907653809, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.007436970714479685, 'loss_2': 0.00015163421630859375, 'loss_3': -16.50394058227539, 'loss_4': 1.1113879680633545, 'epoch': 17.15}
{'loss': 0.0117, 'grad_norm': 5.157007694244385, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.00892371591180563, 'loss_2': 0.002788543701171875, 'loss_3': -16.428119659423828, 'loss_4': 0.8601303696632385, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 16:30:17,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:17,084 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:13:11<38:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:24,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013841523788869381, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010713755153119564, 'eval_loss_2': 0.003127768635749817, 'eval_loss_3': -18.22453498840332, 'eval_loss_4': 1.241134762763977, 'epoch': 17.15}
{'loss': 0.0102, 'grad_norm': 5.346391201019287, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.008703651838004589, 'loss_2': 0.0014934539794921875, 'loss_3': -16.316890716552734, 'loss_4': 1.3537325859069824, 'epoch': 17.16}
{'loss': 0.016, 'grad_norm': 5.232513904571533, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.007721742149442434, 'loss_2': 0.0083160400390625, 'loss_3': -16.234148025512695, 'loss_4': 1.2596747875213623, 'epoch': 17.16}
{'loss': 0.0184, 'grad_norm': 6.575992107391357, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.011965369805693626, 'loss_2': 0.00643157958984375, 'loss_3': -16.53677749633789, 'loss_4': 1.3225970268249512, 'epoch': 17.17}
{'loss': 0.0155, 'grad_norm': 7.136437892913818, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.011465087532997131, 'loss_2': 0.004055023193359375, 'loss_3': -16.552921295166016, 'loss_4': 1.1349915266036987, 'epoch': 17.17}
{'loss': 0.0127, 'grad_norm': 5.344385147094727, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.011859544552862644, 'loss_2': 0.0008058547973632812, 'loss_3': -16.500001907348633, 'loss_4': 1.2421513795852661, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 16:30:24,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:24,433 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:13:18<37:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:31,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01631544902920723, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.512, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009695401415228844, 'eval_loss_2': 0.006620049476623535, 'eval_loss_3': -18.22258949279785, 'eval_loss_4': 1.2004663944244385, 'epoch': 17.18}
{'loss': 0.0184, 'grad_norm': 6.066715240478516, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.014481118880212307, 'loss_2': 0.00396728515625, 'loss_3': -16.516542434692383, 'loss_4': 0.9952250719070435, 'epoch': 17.19}
{'loss': 0.0188, 'grad_norm': 6.594799995422363, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.013947246596217155, 'loss_2': 0.0048675537109375, 'loss_3': -16.414514541625977, 'loss_4': 1.5162131786346436, 'epoch': 17.19}
{'loss': 0.0175, 'grad_norm': 8.673294067382812, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.01659371703863144, 'loss_2': 0.0008649826049804688, 'loss_3': -16.187463760375977, 'loss_4': 1.4074106216430664, 'epoch': 17.2}
{'loss': 0.0149, 'grad_norm': 6.0991291999816895, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.007249501068145037, 'loss_2': 0.0076446533203125, 'loss_3': -16.49774742126465, 'loss_4': 1.2493982315063477, 'epoch': 17.2}
{'loss': 0.019, 'grad_norm': 4.962900161743164, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.009978698566555977, 'loss_2': 0.00897216796875, 'loss_3': -16.520631790161133, 'loss_4': 0.9902284145355225, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 16:30:31,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:31,768 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:25<37:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:39,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015933837741613388, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.649, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009045151993632317, 'eval_loss_2': 0.006888687610626221, 'eval_loss_3': -18.202899932861328, 'eval_loss_4': 1.3806943893432617, 'epoch': 17.21}
{'loss': 0.0187, 'grad_norm': 5.824769496917725, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.010657778941094875, 'loss_2': 0.00803375244140625, 'loss_3': -16.372764587402344, 'loss_4': 1.344049334526062, 'epoch': 17.22}
{'loss': 0.0534, 'grad_norm': 12.059317588806152, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.043911322951316833, 'loss_2': 0.00948333740234375, 'loss_3': -16.372941970825195, 'loss_4': 1.5181324481964111, 'epoch': 17.22}
{'loss': 0.0097, 'grad_norm': 5.066093921661377, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.007112094201147556, 'loss_2': 0.0026187896728515625, 'loss_3': -16.39453887939453, 'loss_4': 1.8798027038574219, 'epoch': 17.23}
{'loss': 0.0267, 'grad_norm': 7.875335693359375, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.020232250913977623, 'loss_2': 0.0064849853515625, 'loss_3': -16.31277084350586, 'loss_4': 1.2190111875534058, 'epoch': 17.23}
{'loss': 0.0216, 'grad_norm': 11.584914207458496, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.018947895616292953, 'loss_2': 0.002674102783203125, 'loss_3': -16.450607299804688, 'loss_4': 1.6319892406463623, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 16:30:39,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:39,103 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:33<37:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:46,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011640744283795357, 'eval_runtime': 3.7971, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.008908465504646301, 'eval_loss_2': 0.0027322769165039062, 'eval_loss_3': -18.191898345947266, 'eval_loss_4': 1.4370241165161133, 'epoch': 17.24}
{'loss': 0.0125, 'grad_norm': 5.767120838165283, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.008896236307919025, 'loss_2': 0.00356292724609375, 'loss_3': -16.426158905029297, 'loss_4': 1.651151418685913, 'epoch': 17.24}
{'loss': 0.0211, 'grad_norm': 9.86082935333252, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.01607416570186615, 'loss_2': 0.0050506591796875, 'loss_3': -16.219829559326172, 'loss_4': 1.8680419921875, 'epoch': 17.25}
{'loss': 0.0087, 'grad_norm': 5.410313129425049, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.007580129895359278, 'loss_2': 0.0011091232299804688, 'loss_3': -16.250471115112305, 'loss_4': 1.841963291168213, 'epoch': 17.26}
{'loss': 0.0119, 'grad_norm': 5.54755163192749, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.006455093622207642, 'loss_2': 0.005462646484375, 'loss_3': -16.303611755371094, 'loss_4': 1.1641875505447388, 'epoch': 17.26}
{'loss': 0.0149, 'grad_norm': 4.775120258331299, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.00624784454703331, 'loss_2': 0.00864410400390625, 'loss_3': -16.409954071044922, 'loss_4': 1.6706066131591797, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 16:30:46,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:46,445 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:40<37:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:30:53,787 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012617351487278938, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00872123334556818, 'eval_loss_2': 0.0038961172103881836, 'eval_loss_3': -18.1947078704834, 'eval_loss_4': 1.6916124820709229, 'epoch': 17.27}
{'loss': 0.0144, 'grad_norm': 6.4006547927856445, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.013648181222379208, 'loss_2': 0.00072479248046875, 'loss_3': -16.342731475830078, 'loss_4': 2.0258495807647705, 'epoch': 17.27}
{'loss': 0.0234, 'grad_norm': 8.798966407775879, 'learning_rate': 1.275e-05, 'loss_1': 0.016087284311652184, 'loss_2': 0.00732421875, 'loss_3': -16.41937255859375, 'loss_4': 1.7831438779830933, 'epoch': 17.28}
{'loss': 0.0282, 'grad_norm': 11.895726203918457, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.026532672345638275, 'loss_2': 0.001682281494140625, 'loss_3': -16.409175872802734, 'loss_4': 1.982462763786316, 'epoch': 17.28}
{'loss': 0.0216, 'grad_norm': 6.620333671569824, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.012725573033094406, 'loss_2': 0.00884246826171875, 'loss_3': -16.389957427978516, 'loss_4': 1.5187280178070068, 'epoch': 17.29}
{'loss': 0.0072, 'grad_norm': 5.003716468811035, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.005744646303355694, 'loss_2': 0.0014705657958984375, 'loss_3': -16.235511779785156, 'loss_4': 1.716992974281311, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 16:30:53,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:30:53,788 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:47<37:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:01,133 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01126618031412363, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.346, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008862861432135105, 'eval_loss_2': 0.0024033188819885254, 'eval_loss_3': -18.189289093017578, 'eval_loss_4': 1.8039271831512451, 'epoch': 17.3}
{'loss': 0.0074, 'grad_norm': 5.078960418701172, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.006301519460976124, 'loss_2': 0.0010881423950195312, 'loss_3': -16.22703742980957, 'loss_4': 1.4379054307937622, 'epoch': 17.3}
{'loss': 0.0103, 'grad_norm': 5.361939907073975, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.009740322828292847, 'loss_2': 0.00058746337890625, 'loss_3': -16.36914825439453, 'loss_4': 1.4821206331253052, 'epoch': 17.31}
{'loss': 0.0276, 'grad_norm': 14.355008125305176, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.025813477113842964, 'loss_2': 0.0018262863159179688, 'loss_3': -16.3593807220459, 'loss_4': 2.0727384090423584, 'epoch': 17.31}
{'loss': 0.0116, 'grad_norm': 5.15309476852417, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.0058287885040044785, 'loss_2': 0.0057525634765625, 'loss_3': -16.193941116333008, 'loss_4': 1.9943031072616577, 'epoch': 17.32}
{'loss': 0.0218, 'grad_norm': 6.369048595428467, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.015651928260922432, 'loss_2': 0.00614166259765625, 'loss_3': -16.2408390045166, 'loss_4': 1.9898898601531982, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 16:31:01,133 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:01,133 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:55<37:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:08,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014681472443044186, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.755, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0088472506031394, 'eval_loss_2': 0.005834221839904785, 'eval_loss_3': -18.197999954223633, 'eval_loss_4': 1.9050348997116089, 'epoch': 17.33}
{'loss': 0.0239, 'grad_norm': 7.83815336227417, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.015434959903359413, 'loss_2': 0.0084228515625, 'loss_3': -16.45502281188965, 'loss_4': 1.8943883180618286, 'epoch': 17.33}
{'loss': 0.0116, 'grad_norm': 4.991573333740234, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.0043532527051866055, 'loss_2': 0.00724029541015625, 'loss_3': -16.531736373901367, 'loss_4': 1.8841493129730225, 'epoch': 17.34}
{'loss': 0.0133, 'grad_norm': 5.44417667388916, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.0050877537578344345, 'loss_2': 0.00823974609375, 'loss_3': -16.407197952270508, 'loss_4': 1.5739926099777222, 'epoch': 17.34}
{'loss': 0.023, 'grad_norm': 6.399017333984375, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.015856193378567696, 'loss_2': 0.007183074951171875, 'loss_3': -16.31121063232422, 'loss_4': 1.6878976821899414, 'epoch': 17.35}
{'loss': 0.0046, 'grad_norm': 5.130456447601318, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.0043179686181247234, 'loss_2': 0.0003216266632080078, 'loss_3': -16.312557220458984, 'loss_4': 2.2759957313537598, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 16:31:08,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:08,471 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:14:02<37:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:15,805 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01104150153696537, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.653, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008277663961052895, 'eval_loss_2': 0.0027638375759124756, 'eval_loss_3': -18.20425033569336, 'eval_loss_4': 1.8537232875823975, 'epoch': 17.35}
{'loss': 0.0139, 'grad_norm': 7.025847434997559, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.012936473824083805, 'loss_2': 0.0009965896606445312, 'loss_3': -16.5398006439209, 'loss_4': 2.1138505935668945, 'epoch': 17.36}
{'loss': 0.0161, 'grad_norm': 9.902263641357422, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.014989026822149754, 'loss_2': 0.00113677978515625, 'loss_3': -16.236602783203125, 'loss_4': 2.199437379837036, 'epoch': 17.37}
{'loss': 0.0063, 'grad_norm': 4.992633819580078, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.00477128941565752, 'loss_2': 0.0015020370483398438, 'loss_3': -16.28427505493164, 'loss_4': 1.3785954713821411, 'epoch': 17.37}
{'loss': 0.0112, 'grad_norm': 4.485290050506592, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.006021630018949509, 'loss_2': 0.0052032470703125, 'loss_3': -16.366371154785156, 'loss_4': 1.7561616897583008, 'epoch': 17.38}
{'loss': 0.0078, 'grad_norm': 4.677511215209961, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.006224020384252071, 'loss_2': 0.001621246337890625, 'loss_3': -16.473770141601562, 'loss_4': 1.7851805686950684, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 16:31:15,805 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:15,805 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:14:09<37:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:23,138 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013157550245523453, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.919, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.008698198944330215, 'eval_loss_2': 0.004459351301193237, 'eval_loss_3': -18.179851531982422, 'eval_loss_4': 1.728585124015808, 'epoch': 17.38}
{'loss': 0.013, 'grad_norm': 4.621068954467773, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.005741199944168329, 'loss_2': 0.00722503662109375, 'loss_3': -16.290382385253906, 'loss_4': 1.8275011777877808, 'epoch': 17.39}
{'loss': 0.0071, 'grad_norm': 5.044051647186279, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.005342391785234213, 'loss_2': 0.001728057861328125, 'loss_3': -16.24336814880371, 'loss_4': 1.574393391609192, 'epoch': 17.4}
{'loss': 0.0116, 'grad_norm': 5.192137241363525, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.0063033862970769405, 'loss_2': 0.005321502685546875, 'loss_3': -16.186298370361328, 'loss_4': 1.4947245121002197, 'epoch': 17.4}
{'loss': 0.0113, 'grad_norm': 6.021603584289551, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.008108913898468018, 'loss_2': 0.003185272216796875, 'loss_3': -16.375205993652344, 'loss_4': 1.481001853942871, 'epoch': 17.41}
{'loss': 0.0167, 'grad_norm': 11.031418800354004, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.015694063156843185, 'loss_2': 0.000965118408203125, 'loss_3': -16.265880584716797, 'loss_4': 1.6458027362823486, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 16:31:23,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:23,138 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:14:17<37:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:30,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012057585641741753, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.415, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008748841471970081, 'eval_loss_2': 0.0033087432384490967, 'eval_loss_3': -18.182453155517578, 'eval_loss_4': 1.5556821823120117, 'epoch': 17.41}
{'loss': 0.0098, 'grad_norm': 5.560080051422119, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.007064622361212969, 'loss_2': 0.002719879150390625, 'loss_3': -16.47024917602539, 'loss_4': 1.171827793121338, 'epoch': 17.42}
{'loss': 0.0084, 'grad_norm': 4.481636047363281, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.00443235132843256, 'loss_2': 0.00392913818359375, 'loss_3': -16.40222930908203, 'loss_4': 1.5785627365112305, 'epoch': 17.42}
{'loss': 0.0118, 'grad_norm': 5.491164207458496, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.008384616114199162, 'loss_2': 0.0034427642822265625, 'loss_3': -16.218521118164062, 'loss_4': 1.8386433124542236, 'epoch': 17.43}
{'loss': 0.0062, 'grad_norm': 4.747038841247559, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.004683294799178839, 'loss_2': 0.00148773193359375, 'loss_3': -16.297344207763672, 'loss_4': 1.3793203830718994, 'epoch': 17.44}
{'loss': 0.0053, 'grad_norm': 4.26068115234375, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.0031165587715804577, 'loss_2': 0.0022182464599609375, 'loss_3': -16.569637298583984, 'loss_4': 1.722392201423645, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 16:31:30,475 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:30,475 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:24<37:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:37,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011884771287441254, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008708580397069454, 'eval_loss_2': 0.003176189959049225, 'eval_loss_3': -18.191972732543945, 'eval_loss_4': 1.3092784881591797, 'epoch': 17.44}
{'loss': 0.0143, 'grad_norm': 5.0716962814331055, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.009838691912591457, 'loss_2': 0.00449371337890625, 'loss_3': -16.385696411132812, 'loss_4': 1.8407036066055298, 'epoch': 17.45}
{'loss': 0.0111, 'grad_norm': 4.563282489776611, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.007395783439278603, 'loss_2': 0.003665924072265625, 'loss_3': -16.364524841308594, 'loss_4': 1.0996791124343872, 'epoch': 17.45}
{'loss': 0.0104, 'grad_norm': 5.601538181304932, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.009784410707652569, 'loss_2': 0.0006203651428222656, 'loss_3': -16.357223510742188, 'loss_4': 0.9727635979652405, 'epoch': 17.46}
{'loss': 0.0128, 'grad_norm': 5.188178539276123, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.0067214458249509335, 'loss_2': 0.00605010986328125, 'loss_3': -16.49378204345703, 'loss_4': 1.4081897735595703, 'epoch': 17.47}
{'loss': 0.0176, 'grad_norm': 8.432147979736328, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.016765261068940163, 'loss_2': 0.0008444786071777344, 'loss_3': -16.39113998413086, 'loss_4': 1.185443639755249, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 16:31:37,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:37,817 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:31<37:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:45,151 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012906419113278389, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.655, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009187864139676094, 'eval_loss_2': 0.003718554973602295, 'eval_loss_3': -18.182815551757812, 'eval_loss_4': 1.0185307264328003, 'epoch': 17.47}
{'loss': 0.0203, 'grad_norm': 8.973111152648926, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.015345347113907337, 'loss_2': 0.0049591064453125, 'loss_3': -16.384658813476562, 'loss_4': 0.8780050873756409, 'epoch': 17.48}
{'loss': 0.0084, 'grad_norm': 5.02305793762207, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.003781188977882266, 'loss_2': 0.004611968994140625, 'loss_3': -16.183610916137695, 'loss_4': 1.1671777963638306, 'epoch': 17.48}
{'loss': 0.0133, 'grad_norm': 4.900559425354004, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.006694862153381109, 'loss_2': 0.00662994384765625, 'loss_3': -16.301767349243164, 'loss_4': 0.9670262336730957, 'epoch': 17.49}
{'loss': 0.0108, 'grad_norm': 5.567190170288086, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.0054302457720041275, 'loss_2': 0.00539398193359375, 'loss_3': -16.353046417236328, 'loss_4': 1.1253435611724854, 'epoch': 17.49}
{'loss': 0.012, 'grad_norm': 5.382552146911621, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.007501300424337387, 'loss_2': 0.0045318603515625, 'loss_3': -16.33257293701172, 'loss_4': 0.6098389625549316, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 16:31:45,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:45,151 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:39<36:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:31:52,475 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012077623046934605, 'eval_runtime': 3.7927, 'eval_samples_per_second': 269.993, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.009331119246780872, 'eval_loss_2': 0.0027465038001537323, 'eval_loss_3': -18.169635772705078, 'eval_loss_4': 0.7845035195350647, 'epoch': 17.5}
{'loss': 0.0094, 'grad_norm': 5.637940883636475, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.00875022541731596, 'loss_2': 0.0006508827209472656, 'loss_3': -16.357437133789062, 'loss_4': 0.5833703875541687, 'epoch': 17.51}
{'loss': 0.011, 'grad_norm': 5.620280742645264, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.004378877580165863, 'loss_2': 0.006641387939453125, 'loss_3': -16.484786987304688, 'loss_4': 0.7218809127807617, 'epoch': 17.51}
{'loss': 0.0885, 'grad_norm': 18.057933807373047, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.0860351100564003, 'loss_2': 0.002460479736328125, 'loss_3': -16.55438995361328, 'loss_4': 1.1475344896316528, 'epoch': 17.52}
{'loss': 0.0078, 'grad_norm': 4.611424446105957, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.004637446720153093, 'loss_2': 0.00319671630859375, 'loss_3': -16.325332641601562, 'loss_4': 0.49452564120292664, 'epoch': 17.52}
{'loss': 0.011, 'grad_norm': 5.227661609649658, 'learning_rate': 1.25e-05, 'loss_1': 0.008791324682533741, 'loss_2': 0.002254486083984375, 'loss_3': -16.40620994567871, 'loss_4': 0.7116905450820923, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 16:31:52,475 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:52,475 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:46<36:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:31:59,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012734845280647278, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.762, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01014186441898346, 'eval_loss_2': 0.0025929808616638184, 'eval_loss_3': -18.145498275756836, 'eval_loss_4': 0.7271900177001953, 'epoch': 17.53}
{'loss': 0.0093, 'grad_norm': 5.563024520874023, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.006775942165404558, 'loss_2': 0.002498626708984375, 'loss_3': -16.404644012451172, 'loss_4': 1.2931418418884277, 'epoch': 17.53}
{'loss': 0.0053, 'grad_norm': 4.7656941413879395, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.00506199337542057, 'loss_2': 0.00023937225341796875, 'loss_3': -16.547714233398438, 'loss_4': -0.001219191588461399, 'epoch': 17.54}
{'loss': 0.0094, 'grad_norm': 5.066474437713623, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.0053812419064342976, 'loss_2': 0.0039825439453125, 'loss_3': -16.328693389892578, 'loss_4': 0.8131827712059021, 'epoch': 17.55}
{'loss': 0.0094, 'grad_norm': 5.115148544311523, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.0059000649489462376, 'loss_2': 0.003528594970703125, 'loss_3': -16.435821533203125, 'loss_4': 0.6086992025375366, 'epoch': 17.55}
{'loss': 0.012, 'grad_norm': 4.954796314239502, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.007558153476566076, 'loss_2': 0.00444793701171875, 'loss_3': -16.408214569091797, 'loss_4': 0.8132030963897705, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 16:31:59,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:31:59,807 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:53<36:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:07,145 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013789620250463486, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.716, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011275531724095345, 'eval_loss_2': 0.002514086663722992, 'eval_loss_3': -18.14536476135254, 'eval_loss_4': 0.7794901132583618, 'epoch': 17.56}
{'loss': 0.0074, 'grad_norm': 5.046035289764404, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.006313986144959927, 'loss_2': 0.0011186599731445312, 'loss_3': -16.411914825439453, 'loss_4': 0.9105856418609619, 'epoch': 17.56}
{'loss': 0.0139, 'grad_norm': 5.665144920349121, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.010022753849625587, 'loss_2': 0.0038604736328125, 'loss_3': -16.20669937133789, 'loss_4': 0.7284698486328125, 'epoch': 17.57}
{'loss': 0.01, 'grad_norm': 5.590653896331787, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.005267216358333826, 'loss_2': 0.00470733642578125, 'loss_3': -16.42605209350586, 'loss_4': 0.7157870531082153, 'epoch': 17.58}
{'loss': 0.025, 'grad_norm': 8.692939758300781, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.015323883853852749, 'loss_2': 0.009674072265625, 'loss_3': -16.10463523864746, 'loss_4': 0.9662870764732361, 'epoch': 17.58}
{'loss': 0.0135, 'grad_norm': 6.601418495178223, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.012356464751064777, 'loss_2': 0.0011281967163085938, 'loss_3': -16.328336715698242, 'loss_4': 1.1091759204864502, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 16:32:07,145 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:07,145 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:15:01<36:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:14,477 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01802928000688553, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.802, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011789267882704735, 'eval_loss_2': 0.0062400102615356445, 'eval_loss_3': -18.169418334960938, 'eval_loss_4': 0.8310378789901733, 'epoch': 17.59}
{'loss': 0.0179, 'grad_norm': 6.282285213470459, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.01671290583908558, 'loss_2': 0.0011844635009765625, 'loss_3': -16.577062606811523, 'loss_4': 1.094008445739746, 'epoch': 17.59}
{'loss': 0.0123, 'grad_norm': 5.570024490356445, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.006446031387895346, 'loss_2': 0.00588226318359375, 'loss_3': -16.30582046508789, 'loss_4': 0.6365265846252441, 'epoch': 17.6}
{'loss': 0.0244, 'grad_norm': 4.9280171394348145, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.007419367786496878, 'loss_2': 0.016998291015625, 'loss_3': -16.538063049316406, 'loss_4': 1.1723978519439697, 'epoch': 17.6}
{'loss': 0.0174, 'grad_norm': 8.956829071044922, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.013692942447960377, 'loss_2': 0.003673553466796875, 'loss_3': -16.31763458251953, 'loss_4': 0.7412950396537781, 'epoch': 17.61}
{'loss': 0.0282, 'grad_norm': 9.31006908416748, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.01365919504314661, 'loss_2': 0.0145263671875, 'loss_3': -16.512287139892578, 'loss_4': 0.9729576706886292, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 16:32:14,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:14,478 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:15:08<36:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:21,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01687557063996792, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01186192687600851, 'eval_loss_2': 0.005013644695281982, 'eval_loss_3': -18.173898696899414, 'eval_loss_4': 0.8021056652069092, 'epoch': 17.62}
{'loss': 0.0154, 'grad_norm': 4.783963203430176, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.0068916212767362595, 'loss_2': 0.00855255126953125, 'loss_3': -16.423419952392578, 'loss_4': 0.8032506108283997, 'epoch': 17.62}
{'loss': 0.0116, 'grad_norm': 6.230308532714844, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.008964737877249718, 'loss_2': 0.002651214599609375, 'loss_3': -16.393566131591797, 'loss_4': 0.8143337965011597, 'epoch': 17.63}
{'loss': 0.012, 'grad_norm': 5.485224723815918, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.008840130642056465, 'loss_2': 0.003143310546875, 'loss_3': -16.606548309326172, 'loss_4': 0.997470498085022, 'epoch': 17.63}
{'loss': 0.0139, 'grad_norm': 5.106462478637695, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.008078907616436481, 'loss_2': 0.0057830810546875, 'loss_3': -16.48849105834961, 'loss_4': 0.6938498616218567, 'epoch': 17.64}
{'loss': 0.0788, 'grad_norm': 19.28960609436035, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.07708809524774551, 'loss_2': 0.0016689300537109375, 'loss_3': -16.541622161865234, 'loss_4': 1.2662478685379028, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 16:32:21,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:21,825 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:15:15<36:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:29,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015592379495501518, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.663, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01220606081187725, 'eval_loss_2': 0.0033863186836242676, 'eval_loss_3': -18.144800186157227, 'eval_loss_4': 0.7672192454338074, 'epoch': 17.65}
{'loss': 0.0098, 'grad_norm': 4.912905693054199, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.006996648386120796, 'loss_2': 0.0028228759765625, 'loss_3': -16.329696655273438, 'loss_4': 0.6457481384277344, 'epoch': 17.65}
{'loss': 0.006, 'grad_norm': 4.510912895202637, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.0043766372837126255, 'loss_2': 0.0015878677368164062, 'loss_3': -16.289098739624023, 'loss_4': 0.9142705202102661, 'epoch': 17.66}
{'loss': 0.0159, 'grad_norm': 6.110023498535156, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.010822265408933163, 'loss_2': 0.005096435546875, 'loss_3': -16.444438934326172, 'loss_4': 1.1134614944458008, 'epoch': 17.66}
{'loss': 0.0239, 'grad_norm': 7.976057529449463, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.016186809167265892, 'loss_2': 0.007694244384765625, 'loss_3': -16.357078552246094, 'loss_4': 0.5868415832519531, 'epoch': 17.67}
{'loss': 0.0144, 'grad_norm': 5.317829132080078, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.009086950682103634, 'loss_2': 0.00527191162109375, 'loss_3': -16.232921600341797, 'loss_4': 0.7806757092475891, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 16:32:29,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:29,155 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:23<36:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:36,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01547863706946373, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.644, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010494191199541092, 'eval_loss_2': 0.004984445869922638, 'eval_loss_3': -18.172584533691406, 'eval_loss_4': 0.7742017507553101, 'epoch': 17.67}
{'loss': 0.0104, 'grad_norm': 5.055064678192139, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.006295751314610243, 'loss_2': 0.0040740966796875, 'loss_3': -16.22323226928711, 'loss_4': 0.8254104256629944, 'epoch': 17.68}
{'loss': 0.0314, 'grad_norm': 8.582409858703613, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.02062251605093479, 'loss_2': 0.01078033447265625, 'loss_3': -16.59978485107422, 'loss_4': 0.632361650466919, 'epoch': 17.69}
{'loss': 0.0071, 'grad_norm': 7.836922645568848, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.006988905370235443, 'loss_2': 0.00015926361083984375, 'loss_3': -16.44196891784668, 'loss_4': 0.627098560333252, 'epoch': 17.69}
{'loss': 0.031, 'grad_norm': 8.402518272399902, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.02221514843404293, 'loss_2': 0.0088348388671875, 'loss_3': -16.364673614501953, 'loss_4': 1.1178414821624756, 'epoch': 17.7}
{'loss': 0.0079, 'grad_norm': 4.4302825927734375, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.0043060509487986565, 'loss_2': 0.0036144256591796875, 'loss_3': -16.46173858642578, 'loss_4': 0.9700806140899658, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 16:32:36,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:36,493 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:30<36:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:43,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013003893196582794, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009938215836882591, 'eval_loss_2': 0.0030656754970550537, 'eval_loss_3': -18.191587448120117, 'eval_loss_4': 0.8993997573852539, 'epoch': 17.7}
{'loss': 0.0176, 'grad_norm': 5.826859474182129, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.009431400336325169, 'loss_2': 0.008148193359375, 'loss_3': -16.21810531616211, 'loss_4': 0.6468007564544678, 'epoch': 17.71}
{'loss': 0.0153, 'grad_norm': 5.1765313148498535, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.006596540566533804, 'loss_2': 0.0086822509765625, 'loss_3': -16.526216506958008, 'loss_4': 0.9753761887550354, 'epoch': 17.72}
{'loss': 0.0202, 'grad_norm': 9.895978927612305, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.017853708937764168, 'loss_2': 0.0023899078369140625, 'loss_3': -16.385711669921875, 'loss_4': 1.2253543138504028, 'epoch': 17.72}
{'loss': 0.0086, 'grad_norm': 5.273351192474365, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.0070707714185118675, 'loss_2': 0.0015192031860351562, 'loss_3': -16.283681869506836, 'loss_4': 1.5466697216033936, 'epoch': 17.73}
{'loss': 0.0182, 'grad_norm': 8.266034126281738, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.015178864821791649, 'loss_2': 0.0029926300048828125, 'loss_3': -16.3837890625, 'loss_4': 1.356313705444336, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 16:32:43,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:43,828 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:37<36:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:51,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014877011999487877, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.431, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009599766694009304, 'eval_loss_2': 0.0052772462368011475, 'eval_loss_3': -18.196853637695312, 'eval_loss_4': 0.9630810022354126, 'epoch': 17.73}
{'loss': 0.0228, 'grad_norm': 8.598176956176758, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.019641272723674774, 'loss_2': 0.0031299591064453125, 'loss_3': -16.430644989013672, 'loss_4': 1.5092477798461914, 'epoch': 17.74}
{'loss': 0.0167, 'grad_norm': 4.922239780426025, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.006775473244488239, 'loss_2': 0.00994873046875, 'loss_3': -16.570178985595703, 'loss_4': 1.1267434358596802, 'epoch': 17.74}
{'loss': 0.015, 'grad_norm': 5.06657600402832, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.0068092080764472485, 'loss_2': 0.00817108154296875, 'loss_3': -16.48379898071289, 'loss_4': 1.3402528762817383, 'epoch': 17.75}
{'loss': 0.0289, 'grad_norm': 10.191868782043457, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.022459980100393295, 'loss_2': 0.006397247314453125, 'loss_3': -16.20027732849121, 'loss_4': 1.461474061012268, 'epoch': 17.76}
{'loss': 0.0139, 'grad_norm': 6.054942607879639, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.009443454444408417, 'loss_2': 0.004489898681640625, 'loss_3': -16.4144344329834, 'loss_4': 1.360102653503418, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 16:32:51,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:51,163 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:45<36:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:32:58,504 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01779729314148426, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.353, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009757579304277897, 'eval_loss_2': 0.008039712905883789, 'eval_loss_3': -18.200410842895508, 'eval_loss_4': 0.9511619806289673, 'epoch': 17.76}
{'loss': 0.0244, 'grad_norm': 6.891139507293701, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.018920553848147392, 'loss_2': 0.005523681640625, 'loss_3': -16.277610778808594, 'loss_4': 1.257413387298584, 'epoch': 17.77}
{'loss': 0.0238, 'grad_norm': 8.750873565673828, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.016798852011561394, 'loss_2': 0.0070037841796875, 'loss_3': -16.545272827148438, 'loss_4': 1.5606752634048462, 'epoch': 17.77}
{'loss': 0.0167, 'grad_norm': 4.59940767288208, 'learning_rate': 1.225e-05, 'loss_1': 0.005211228970438242, 'loss_2': 0.0114593505859375, 'loss_3': -16.392419815063477, 'loss_4': 1.1919777393341064, 'epoch': 17.78}
{'loss': 0.014, 'grad_norm': 5.1269989013671875, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.0066556003876030445, 'loss_2': 0.007335662841796875, 'loss_3': -16.27637481689453, 'loss_4': 1.0427345037460327, 'epoch': 17.78}
{'loss': 0.0178, 'grad_norm': 6.150789260864258, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.009672097861766815, 'loss_2': 0.00817108154296875, 'loss_3': -16.242950439453125, 'loss_4': 1.3646316528320312, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 16:32:58,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:32:58,505 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:52<36:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:05,849 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012971561402082443, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.093, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00966573879122734, 'eval_loss_2': 0.0033058226108551025, 'eval_loss_3': -18.18806266784668, 'eval_loss_4': 0.9497119188308716, 'epoch': 17.79}
{'loss': 0.0137, 'grad_norm': 4.984004974365234, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.0059549626894295216, 'loss_2': 0.007778167724609375, 'loss_3': -16.270923614501953, 'loss_4': 0.9339813590049744, 'epoch': 17.8}
{'loss': 0.0113, 'grad_norm': 5.823599815368652, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.008971667848527431, 'loss_2': 0.0022792816162109375, 'loss_3': -16.51032257080078, 'loss_4': 0.9706858396530151, 'epoch': 17.8}
{'loss': 0.0114, 'grad_norm': 4.49443244934082, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.0065711745992302895, 'loss_2': 0.004852294921875, 'loss_3': -16.337989807128906, 'loss_4': 1.2389717102050781, 'epoch': 17.81}
{'loss': 0.0097, 'grad_norm': 5.302371978759766, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.009005499072372913, 'loss_2': 0.0006623268127441406, 'loss_3': -16.493953704833984, 'loss_4': 1.0980745553970337, 'epoch': 17.81}
{'loss': 0.0077, 'grad_norm': 5.467167377471924, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.007130031008273363, 'loss_2': 0.0005350112915039062, 'loss_3': -16.49375343322754, 'loss_4': 0.9657572507858276, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 16:33:05,849 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:05,849 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:15:59<36:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:13,185 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014999862760305405, 'eval_runtime': 3.7964, 'eval_samples_per_second': 269.726, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009288604371249676, 'eval_loss_2': 0.005711257457733154, 'eval_loss_3': -18.19965934753418, 'eval_loss_4': 1.1466457843780518, 'epoch': 17.82}
{'loss': 0.0243, 'grad_norm': 5.531344413757324, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.009001268073916435, 'loss_2': 0.0152740478515625, 'loss_3': -16.417377471923828, 'loss_4': 1.2389793395996094, 'epoch': 17.83}
{'loss': 0.0239, 'grad_norm': 6.776627540588379, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.01178857684135437, 'loss_2': 0.0121002197265625, 'loss_3': -16.439197540283203, 'loss_4': 1.0161961317062378, 'epoch': 17.83}
{'loss': 0.0475, 'grad_norm': 14.678964614868164, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.04196769371628761, 'loss_2': 0.00553131103515625, 'loss_3': -16.372669219970703, 'loss_4': 1.4666457176208496, 'epoch': 17.84}
{'loss': 0.0169, 'grad_norm': 5.088629245758057, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.006258992478251457, 'loss_2': 0.01068115234375, 'loss_3': -16.403831481933594, 'loss_4': 1.6137468814849854, 'epoch': 17.84}
{'loss': 0.0125, 'grad_norm': 5.455714702606201, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.005933189764618874, 'loss_2': 0.00653839111328125, 'loss_3': -16.54074478149414, 'loss_4': 1.2443994283676147, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 16:33:13,185 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:13,185 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:16:07<36:28,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:33:20,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017771083861589432, 'eval_runtime': 3.9921, 'eval_samples_per_second': 256.503, 'eval_steps_per_second': 4.008, 'eval_loss_1': 0.008737524971365929, 'eval_loss_2': 0.009033560752868652, 'eval_loss_3': -18.201215744018555, 'eval_loss_4': 1.3193910121917725, 'epoch': 17.85}
{'loss': 0.0116, 'grad_norm': 4.711607933044434, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.0040146480314433575, 'loss_2': 0.00762176513671875, 'loss_3': -16.363353729248047, 'loss_4': 0.9580888152122498, 'epoch': 17.85}
{'loss': 0.0195, 'grad_norm': 4.559044361114502, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.004982274957001209, 'loss_2': 0.0144805908203125, 'loss_3': -16.390003204345703, 'loss_4': 1.1481674909591675, 'epoch': 17.86}
{'loss': 0.0156, 'grad_norm': 4.78243350982666, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.00716937892138958, 'loss_2': 0.00846099853515625, 'loss_3': -16.409038543701172, 'loss_4': 1.0131351947784424, 'epoch': 17.87}
{'loss': 0.0163, 'grad_norm': 5.192144870758057, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.008646641857922077, 'loss_2': 0.00762176513671875, 'loss_3': -16.378936767578125, 'loss_4': 1.552887201309204, 'epoch': 17.87}
{'loss': 0.0089, 'grad_norm': 5.242956161499023, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.006671092007309198, 'loss_2': 0.0022430419921875, 'loss_3': -16.366859436035156, 'loss_4': 1.600316047668457, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 16:33:20,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:20,713 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:16:14<36:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:28,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013704667799174786, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.553, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009714307263493538, 'eval_loss_2': 0.003990359604358673, 'eval_loss_3': -18.203189849853516, 'eval_loss_4': 1.3492932319641113, 'epoch': 17.88}
{'loss': 0.0148, 'grad_norm': 6.6170759201049805, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.009403596632182598, 'loss_2': 0.00537872314453125, 'loss_3': -16.422767639160156, 'loss_4': 1.484724760055542, 'epoch': 17.88}
{'loss': 0.008, 'grad_norm': 5.27397346496582, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.00655233021825552, 'loss_2': 0.0014009475708007812, 'loss_3': -16.59136962890625, 'loss_4': 1.5398871898651123, 'epoch': 17.89}
{'loss': 0.0066, 'grad_norm': 4.670625686645508, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.005358363036066294, 'loss_2': 0.0011997222900390625, 'loss_3': -16.245948791503906, 'loss_4': 1.6567023992538452, 'epoch': 17.9}
{'loss': 0.0127, 'grad_norm': 4.837161540985107, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.0038268195930868387, 'loss_2': 0.0088653564453125, 'loss_3': -16.255477905273438, 'loss_4': 1.3007103204727173, 'epoch': 17.9}
{'loss': 0.0255, 'grad_norm': 12.193562507629395, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.024241117760539055, 'loss_2': 0.001216888427734375, 'loss_3': -16.30881118774414, 'loss_4': 1.661569595336914, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 16:33:28,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:28,055 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:21<35:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:35,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013083402998745441, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.366, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010375902988016605, 'eval_loss_2': 0.002707500010728836, 'eval_loss_3': -18.213987350463867, 'eval_loss_4': 1.3279590606689453, 'epoch': 17.91}
{'loss': 0.008, 'grad_norm': 4.505708694458008, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.0052258847281336784, 'loss_2': 0.0027561187744140625, 'loss_3': -16.391725540161133, 'loss_4': 0.9866859316825867, 'epoch': 17.91}
{'loss': 0.094, 'grad_norm': 11.410238265991211, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.09113810211420059, 'loss_2': 0.002841949462890625, 'loss_3': -16.685176849365234, 'loss_4': 1.8529026508331299, 'epoch': 17.92}
{'loss': 0.0219, 'grad_norm': 6.452210426330566, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.01648903265595436, 'loss_2': 0.005374908447265625, 'loss_3': -16.438823699951172, 'loss_4': 1.094007968902588, 'epoch': 17.92}
{'loss': 0.0131, 'grad_norm': 6.589587688446045, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.009850653819739819, 'loss_2': 0.003269195556640625, 'loss_3': -16.49687957763672, 'loss_4': 1.3802971839904785, 'epoch': 17.93}
{'loss': 0.014, 'grad_norm': 5.1710896492004395, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.008831661194562912, 'loss_2': 0.00521087646484375, 'loss_3': -16.254310607910156, 'loss_4': 1.1368865966796875, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 16:33:35,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:35,401 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:29<35:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:33:42,759 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013337591663002968, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.68, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010358192026615143, 'eval_loss_2': 0.0029793977737426758, 'eval_loss_3': -18.22618293762207, 'eval_loss_4': 1.2855565547943115, 'epoch': 17.94}
{'loss': 0.0143, 'grad_norm': 5.6499857902526855, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.008382756263017654, 'loss_2': 0.00588226318359375, 'loss_3': -16.382537841796875, 'loss_4': 1.3345673084259033, 'epoch': 17.94}
{'loss': 0.0143, 'grad_norm': 6.004002094268799, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.01016833633184433, 'loss_2': 0.0041656494140625, 'loss_3': -16.34676742553711, 'loss_4': 0.982298731803894, 'epoch': 17.95}
{'loss': 0.0077, 'grad_norm': 5.028332233428955, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.007315837312489748, 'loss_2': 0.0004086494445800781, 'loss_3': -16.324718475341797, 'loss_4': 1.2845722436904907, 'epoch': 17.95}
{'loss': 0.0112, 'grad_norm': 5.642966270446777, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.010394280776381493, 'loss_2': 0.0007829666137695312, 'loss_3': -16.368972778320312, 'loss_4': 1.3911951780319214, 'epoch': 17.96}
{'loss': 0.0065, 'grad_norm': 4.789422035217285, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.005808210000395775, 'loss_2': 0.0007123947143554688, 'loss_3': -16.448780059814453, 'loss_4': 0.9387925863265991, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 16:33:42,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:42,759 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:36<35:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:33:50,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014186672866344452, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.487, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010530517436563969, 'eval_loss_2': 0.003656156361103058, 'eval_loss_3': -18.228403091430664, 'eval_loss_4': 1.0901793241500854, 'epoch': 17.97}
{'loss': 0.0132, 'grad_norm': 5.873160362243652, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.012251807376742363, 'loss_2': 0.0009713172912597656, 'loss_3': -16.47641372680664, 'loss_4': 1.6462891101837158, 'epoch': 17.97}
{'loss': 0.0162, 'grad_norm': 5.621725082397461, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.009752009995281696, 'loss_2': 0.00643157958984375, 'loss_3': -16.43465232849121, 'loss_4': 0.8204010128974915, 'epoch': 17.98}
{'loss': 0.0219, 'grad_norm': 7.530871868133545, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.019251298159360886, 'loss_2': 0.0026092529296875, 'loss_3': -16.437381744384766, 'loss_4': 1.2080166339874268, 'epoch': 17.98}
{'loss': 0.0156, 'grad_norm': 5.039173126220703, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.007185858208686113, 'loss_2': 0.00841522216796875, 'loss_3': -16.259910583496094, 'loss_4': 0.7298269271850586, 'epoch': 17.99}
{'loss': 0.0148, 'grad_norm': 8.315457344055176, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.009378118440508842, 'loss_2': 0.00542449951171875, 'loss_3': -16.429149627685547, 'loss_4': 1.579377293586731, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 16:33:50,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:50,092 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:43<34:53,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:33:57,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013632332906126976, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010127102956175804, 'eval_loss_2': 0.003505229949951172, 'eval_loss_3': -18.23401641845703, 'eval_loss_4': 0.8902522325515747, 'epoch': 17.99}
{'loss': 0.0069, 'grad_norm': 6.143665790557861, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.002443973207846284, 'loss_2': 0.0045013427734375, 'loss_3': -16.34521484375, 'loss_4': 0.7474243640899658, 'epoch': 18.0}
{'loss': 0.0127, 'grad_norm': 6.469227313995361, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.012270488776266575, 'loss_2': 0.0004773139953613281, 'loss_3': -16.369312286376953, 'loss_4': 1.087622046470642, 'epoch': 18.01}
{'loss': 0.01, 'grad_norm': 7.472572326660156, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.007891589775681496, 'loss_2': 0.0020961761474609375, 'loss_3': -16.494096755981445, 'loss_4': 1.0755364894866943, 'epoch': 18.01}
{'loss': 0.0053, 'grad_norm': 4.763685703277588, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.005197540856897831, 'loss_2': 0.00012290477752685547, 'loss_3': -16.426862716674805, 'loss_4': 0.7682410478591919, 'epoch': 18.02}
{'loss': 0.0146, 'grad_norm': 5.9913482666015625, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.010251877829432487, 'loss_2': 0.004364013671875, 'loss_3': -16.569133758544922, 'loss_4': 0.9622319340705872, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 16:33:57,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:33:57,144 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:51<35:23,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:34:04,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01436365582048893, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.652, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010690786875784397, 'eval_loss_2': 0.003672868013381958, 'eval_loss_3': -18.228757858276367, 'eval_loss_4': 0.8676612973213196, 'epoch': 18.02}
{'loss': 0.0117, 'grad_norm': 4.30734920501709, 'learning_rate': 1.2e-05, 'loss_1': 0.004938650876283646, 'loss_2': 0.006744384765625, 'loss_3': -16.461355209350586, 'loss_4': 0.8253923654556274, 'epoch': 18.03}
{'loss': 0.0122, 'grad_norm': 5.806107044219971, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.008158043026924133, 'loss_2': 0.00408935546875, 'loss_3': -16.456462860107422, 'loss_4': 0.9174668192863464, 'epoch': 18.03}
{'loss': 0.0144, 'grad_norm': 5.843282699584961, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.004818303976207972, 'loss_2': 0.009613037109375, 'loss_3': -16.427906036376953, 'loss_4': 0.7604186534881592, 'epoch': 18.04}
{'loss': 0.0125, 'grad_norm': 5.362757205963135, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.008195258677005768, 'loss_2': 0.004268646240234375, 'loss_3': -16.23862075805664, 'loss_4': 0.7651956081390381, 'epoch': 18.05}
{'loss': 0.0116, 'grad_norm': 6.306091785430908, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.008654303848743439, 'loss_2': 0.002925872802734375, 'loss_3': -16.350055694580078, 'loss_4': 1.0066596269607544, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 16:34:04,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:04,483 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:16:58<35:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:11,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01482089702039957, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.693, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011218304745852947, 'eval_loss_2': 0.0036025941371917725, 'eval_loss_3': -18.238859176635742, 'eval_loss_4': 0.896830677986145, 'epoch': 18.05}
{'loss': 0.0072, 'grad_norm': 5.144477844238281, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.004175855778157711, 'loss_2': 0.003063201904296875, 'loss_3': -16.56029510498047, 'loss_4': 1.3509413003921509, 'epoch': 18.06}
{'loss': 0.0131, 'grad_norm': 8.130845069885254, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.012079650536179543, 'loss_2': 0.0010700225830078125, 'loss_3': -16.309572219848633, 'loss_4': 1.0606658458709717, 'epoch': 18.06}
{'loss': 0.0122, 'grad_norm': 4.981642723083496, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.00580322090536356, 'loss_2': 0.0063934326171875, 'loss_3': -16.382509231567383, 'loss_4': 0.8080559968948364, 'epoch': 18.07}
{'loss': 0.0165, 'grad_norm': 6.6499457359313965, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.014748244546353817, 'loss_2': 0.0017633438110351562, 'loss_3': -16.240524291992188, 'loss_4': 0.7874180674552917, 'epoch': 18.08}
{'loss': 0.0147, 'grad_norm': 5.43787956237793, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.01231465395539999, 'loss_2': 0.00234222412109375, 'loss_3': -16.41622543334961, 'loss_4': 1.193105697631836, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 16:34:11,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:11,821 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:17:05<35:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:19,168 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01418883353471756, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.38, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011436931788921356, 'eval_loss_2': 0.0027519017457962036, 'eval_loss_3': -18.237062454223633, 'eval_loss_4': 0.9016969203948975, 'epoch': 18.08}
{'loss': 0.0103, 'grad_norm': 5.925964832305908, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.008567296899855137, 'loss_2': 0.0017061233520507812, 'loss_3': -16.446495056152344, 'loss_4': 1.0946550369262695, 'epoch': 18.09}
{'loss': 0.0311, 'grad_norm': 16.556201934814453, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.022689539939165115, 'loss_2': 0.0084228515625, 'loss_3': -16.452144622802734, 'loss_4': 0.859386146068573, 'epoch': 18.09}
{'loss': 0.0129, 'grad_norm': 7.050740718841553, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.009943816810846329, 'loss_2': 0.002960205078125, 'loss_3': -16.457420349121094, 'loss_4': 1.2415159940719604, 'epoch': 18.1}
{'loss': 0.0185, 'grad_norm': 6.872682571411133, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.017716115340590477, 'loss_2': 0.0008144378662109375, 'loss_3': -16.493741989135742, 'loss_4': 0.9172713160514832, 'epoch': 18.1}
{'loss': 0.0694, 'grad_norm': 18.353422164916992, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.06493082642555237, 'loss_2': 0.004421234130859375, 'loss_3': -16.519433975219727, 'loss_4': 0.9126374125480652, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 16:34:19,168 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:19,168 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:17:13<35:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:26,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014118391089141369, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011314647272229195, 'eval_loss_2': 0.0028037428855895996, 'eval_loss_3': -18.239662170410156, 'eval_loss_4': 0.8498165607452393, 'epoch': 18.11}
{'loss': 0.0118, 'grad_norm': 5.649122714996338, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.009450707584619522, 'loss_2': 0.0023956298828125, 'loss_3': -16.266910552978516, 'loss_4': 0.43799394369125366, 'epoch': 18.12}
{'loss': 0.0136, 'grad_norm': 4.456338882446289, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.00577579578384757, 'loss_2': 0.00777435302734375, 'loss_3': -16.329328536987305, 'loss_4': 0.8248268365859985, 'epoch': 18.12}
{'loss': 0.0069, 'grad_norm': 4.4523444175720215, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.004392128903418779, 'loss_2': 0.002471923828125, 'loss_3': -16.665481567382812, 'loss_4': 0.6661262512207031, 'epoch': 18.13}
{'loss': 0.0066, 'grad_norm': 5.143379211425781, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.006189779378473759, 'loss_2': 0.0004572868347167969, 'loss_3': -16.353595733642578, 'loss_4': 0.8715121746063232, 'epoch': 18.13}
{'loss': 0.0145, 'grad_norm': 6.617351055145264, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.01192888431251049, 'loss_2': 0.0026187896728515625, 'loss_3': -16.296470642089844, 'loss_4': 1.0267162322998047, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 16:34:26,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:26,507 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:20<35:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:33,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013886906206607819, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.532, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011191733181476593, 'eval_loss_2': 0.0026951730251312256, 'eval_loss_3': -18.24466896057129, 'eval_loss_4': 0.8251997232437134, 'epoch': 18.14}
{'loss': 0.008, 'grad_norm': 4.966597080230713, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.005070200655609369, 'loss_2': 0.0029430389404296875, 'loss_3': -16.344375610351562, 'loss_4': 0.8370132446289062, 'epoch': 18.15}
{'loss': 0.0201, 'grad_norm': 10.204227447509766, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.0173016469925642, 'loss_2': 0.002777099609375, 'loss_3': -16.44838523864746, 'loss_4': 0.4257083237171173, 'epoch': 18.15}
{'loss': 0.0202, 'grad_norm': 5.855583190917969, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.013066490180790424, 'loss_2': 0.007167816162109375, 'loss_3': -16.38640022277832, 'loss_4': 0.8855211734771729, 'epoch': 18.16}
{'loss': 0.009, 'grad_norm': 4.9306182861328125, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.005516041535884142, 'loss_2': 0.003505706787109375, 'loss_3': -16.573421478271484, 'loss_4': 1.103306770324707, 'epoch': 18.16}
{'loss': 0.0193, 'grad_norm': 6.58634090423584, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.015949338674545288, 'loss_2': 0.00333404541015625, 'loss_3': -16.296283721923828, 'loss_4': 0.5031523704528809, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 16:34:33,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:33,848 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:27<35:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:41,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015361248515546322, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.827, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01144164614379406, 'eval_loss_2': 0.0039196014404296875, 'eval_loss_3': -18.26323699951172, 'eval_loss_4': 0.7043225765228271, 'epoch': 18.17}
{'loss': 0.0204, 'grad_norm': 7.529303073883057, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.015884000808000565, 'loss_2': 0.0045013427734375, 'loss_3': -16.238109588623047, 'loss_4': 1.023483157157898, 'epoch': 18.17}
{'loss': 0.0317, 'grad_norm': 10.056763648986816, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.02361983060836792, 'loss_2': 0.0081024169921875, 'loss_3': -16.448280334472656, 'loss_4': 1.205430507659912, 'epoch': 18.18}
{'loss': 0.0095, 'grad_norm': 5.723998069763184, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.00663787079975009, 'loss_2': 0.0028228759765625, 'loss_3': -16.352951049804688, 'loss_4': 0.3889941871166229, 'epoch': 18.19}
{'loss': 0.0197, 'grad_norm': 5.039057731628418, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.01002846285700798, 'loss_2': 0.0097198486328125, 'loss_3': -16.399696350097656, 'loss_4': 0.8832207322120667, 'epoch': 18.19}
{'loss': 0.0107, 'grad_norm': 5.149291038513184, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.005327208433300257, 'loss_2': 0.005413055419921875, 'loss_3': -16.534408569335938, 'loss_4': 0.58109450340271, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 16:34:41,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:41,182 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:35<35:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:48,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01708650402724743, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.646, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011199026368558407, 'eval_loss_2': 0.005887478590011597, 'eval_loss_3': -18.24494743347168, 'eval_loss_4': 0.6052564382553101, 'epoch': 18.2}
{'loss': 0.0166, 'grad_norm': 6.575340747833252, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.010745811276137829, 'loss_2': 0.00583648681640625, 'loss_3': -16.470956802368164, 'loss_4': 1.190652847290039, 'epoch': 18.2}
{'loss': 0.0071, 'grad_norm': 4.579890727996826, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.005511712282896042, 'loss_2': 0.0015697479248046875, 'loss_3': -16.343303680419922, 'loss_4': 0.6662493944168091, 'epoch': 18.21}
{'loss': 0.0054, 'grad_norm': 4.443680763244629, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.005035415757447481, 'loss_2': 0.0003771781921386719, 'loss_3': -16.35915756225586, 'loss_4': 0.5050613284111023, 'epoch': 18.22}
{'loss': 0.0073, 'grad_norm': 4.899580955505371, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.006148422136902809, 'loss_2': 0.001171112060546875, 'loss_3': -16.342609405517578, 'loss_4': 0.5756009817123413, 'epoch': 18.22}
{'loss': 0.0311, 'grad_norm': 10.964378356933594, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.019307728856801987, 'loss_2': 0.01178741455078125, 'loss_3': -16.48796272277832, 'loss_4': 0.7744666934013367, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 16:34:48,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:48,521 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:42<34:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:34:55,854 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019124068319797516, 'eval_runtime': 3.7943, 'eval_samples_per_second': 269.881, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01070479303598404, 'eval_loss_2': 0.008419275283813477, 'eval_loss_3': -18.238536834716797, 'eval_loss_4': 0.4906378984451294, 'epoch': 18.23}
{'loss': 0.0214, 'grad_norm': 6.906905174255371, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.010671710595488548, 'loss_2': 0.0107269287109375, 'loss_3': -16.419960021972656, 'loss_4': 0.8534864187240601, 'epoch': 18.23}
{'loss': 0.0291, 'grad_norm': 9.244894981384277, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.022723671048879623, 'loss_2': 0.00635528564453125, 'loss_3': -16.348936080932617, 'loss_4': 0.6534614562988281, 'epoch': 18.24}
{'loss': 0.0172, 'grad_norm': 5.057868480682373, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.006193904206156731, 'loss_2': 0.0110321044921875, 'loss_3': -16.460054397583008, 'loss_4': 0.5910595059394836, 'epoch': 18.24}
{'loss': 0.0367, 'grad_norm': 9.580512046813965, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.03231380134820938, 'loss_2': 0.00438690185546875, 'loss_3': -16.562580108642578, 'loss_4': 0.3787215054035187, 'epoch': 18.25}
{'loss': 0.0126, 'grad_norm': 4.911816120147705, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.003346192417666316, 'loss_2': 0.009246826171875, 'loss_3': -16.348102569580078, 'loss_4': 0.6812423467636108, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 16:34:55,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:34:55,854 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:49<34:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:03,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017342178151011467, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.397, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010429560206830502, 'eval_loss_2': 0.00691261887550354, 'eval_loss_3': -18.228351593017578, 'eval_loss_4': 0.39967405796051025, 'epoch': 18.26}
{'loss': 0.0181, 'grad_norm': 6.653337001800537, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.009873458184301853, 'loss_2': 0.00826263427734375, 'loss_3': -16.333375930786133, 'loss_4': 0.9012376070022583, 'epoch': 18.26}
{'loss': 0.015, 'grad_norm': 6.34602689743042, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.009112908504903316, 'loss_2': 0.00585174560546875, 'loss_3': -16.333251953125, 'loss_4': 0.23773500323295593, 'epoch': 18.27}
{'loss': 0.0796, 'grad_norm': 17.46381950378418, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.07830987125635147, 'loss_2': 0.0013303756713867188, 'loss_3': -16.494831085205078, 'loss_4': 0.7201165556907654, 'epoch': 18.27}
{'loss': 0.0124, 'grad_norm': 4.571863651275635, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.0069786859676241875, 'loss_2': 0.00543212890625, 'loss_3': -16.365692138671875, 'loss_4': 0.44983959197998047, 'epoch': 18.28}
{'loss': 0.0089, 'grad_norm': 5.958891868591309, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.007750357501208782, 'loss_2': 0.0011072158813476562, 'loss_3': -16.537771224975586, 'loss_4': -0.05406896024942398, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 16:35:03,199 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:03,199 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:17:57<34:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:10,561 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013428924605250359, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.798, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009877203032374382, 'eval_loss_2': 0.0035517215728759766, 'eval_loss_3': -18.205209732055664, 'eval_loss_4': 0.3002265393733978, 'epoch': 18.28}
{'loss': 0.0052, 'grad_norm': 4.80778169631958, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.003369175596162677, 'loss_2': 0.0017833709716796875, 'loss_3': -16.6396541595459, 'loss_4': 0.1890038251876831, 'epoch': 18.29}
{'loss': 0.0063, 'grad_norm': 4.760605335235596, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.005352264270186424, 'loss_2': 0.0009379386901855469, 'loss_3': -16.39598274230957, 'loss_4': 0.20573508739471436, 'epoch': 18.3}
{'loss': 0.0168, 'grad_norm': 7.314363956451416, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.014956362545490265, 'loss_2': 0.0018739700317382812, 'loss_3': -16.414583206176758, 'loss_4': 0.32664617896080017, 'epoch': 18.3}
{'loss': 0.0085, 'grad_norm': 4.616509437561035, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.004442794714123011, 'loss_2': 0.004062652587890625, 'loss_3': -16.4832820892334, 'loss_4': 0.24660171568393707, 'epoch': 18.31}
{'loss': 0.0194, 'grad_norm': 4.718508720397949, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.017033610492944717, 'loss_2': 0.002346038818359375, 'loss_3': -16.562789916992188, 'loss_4': 0.12338382750749588, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 16:35:10,561 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:10,562 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:18:04<34:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:17,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013400349766016006, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.629, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009609010070562363, 'eval_loss_2': 0.003791339695453644, 'eval_loss_3': -18.214248657226562, 'eval_loss_4': 0.25777125358581543, 'epoch': 18.31}
{'loss': 0.0109, 'grad_norm': 5.240182876586914, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.004136121831834316, 'loss_2': 0.006744384765625, 'loss_3': -16.57569122314453, 'loss_4': 0.08331523090600967, 'epoch': 18.32}
{'loss': 0.0085, 'grad_norm': 4.715244770050049, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.005086574703454971, 'loss_2': 0.00339508056640625, 'loss_3': -16.458412170410156, 'loss_4': 0.06759551167488098, 'epoch': 18.33}
{'loss': 0.0076, 'grad_norm': 4.4267425537109375, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.00523855397477746, 'loss_2': 0.0023345947265625, 'loss_3': -16.321361541748047, 'loss_4': 0.45092564821243286, 'epoch': 18.33}
{'loss': 0.0241, 'grad_norm': 12.913620948791504, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.021995995193719864, 'loss_2': 0.0021266937255859375, 'loss_3': -16.312328338623047, 'loss_4': 0.38112568855285645, 'epoch': 18.34}
{'loss': 0.0112, 'grad_norm': 5.628912925720215, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.007508278824388981, 'loss_2': 0.0036563873291015625, 'loss_3': -16.635677337646484, 'loss_4': 0.07209087908267975, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 16:35:17,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:17,904 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:18:11<34:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:25,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012551502324640751, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.538, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009953810833394527, 'eval_loss_2': 0.0025976896286010742, 'eval_loss_3': -18.203227996826172, 'eval_loss_4': 0.19252805411815643, 'epoch': 18.34}
{'loss': 0.0163, 'grad_norm': 7.117603302001953, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.014807148836553097, 'loss_2': 0.0014781951904296875, 'loss_3': -16.271732330322266, 'loss_4': 0.17430521547794342, 'epoch': 18.35}
{'loss': 0.0085, 'grad_norm': 5.052860736846924, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.006174883805215359, 'loss_2': 0.0023708343505859375, 'loss_3': -16.414512634277344, 'loss_4': -0.12979227304458618, 'epoch': 18.35}
{'loss': 0.0247, 'grad_norm': 17.85597801208496, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.021868914365768433, 'loss_2': 0.002788543701171875, 'loss_3': -16.322399139404297, 'loss_4': 0.07503969967365265, 'epoch': 18.36}
{'loss': 0.0138, 'grad_norm': 5.6734185218811035, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.011135922744870186, 'loss_2': 0.0026950836181640625, 'loss_3': -16.251026153564453, 'loss_4': -0.2369433343410492, 'epoch': 18.37}
{'loss': 0.0213, 'grad_norm': 7.616245269775391, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.018824249505996704, 'loss_2': 0.00244903564453125, 'loss_3': -16.170936584472656, 'loss_4': 0.2652676999568939, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 16:35:25,254 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:25,254 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:19<34:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:32,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014013545587658882, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.424, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010715099051594734, 'eval_loss_2': 0.003298446536064148, 'eval_loss_3': -18.2119083404541, 'eval_loss_4': 0.13045480847358704, 'epoch': 18.37}
{'loss': 0.006, 'grad_norm': 4.787236213684082, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.004821757320314646, 'loss_2': 0.0011425018310546875, 'loss_3': -16.51902961730957, 'loss_4': 0.27645689249038696, 'epoch': 18.38}
{'loss': 0.0087, 'grad_norm': 4.637280464172363, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.0055155581794679165, 'loss_2': 0.0031890869140625, 'loss_3': -16.354936599731445, 'loss_4': 0.510962724685669, 'epoch': 18.38}
{'loss': 0.0139, 'grad_norm': 6.136524677276611, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.009820627048611641, 'loss_2': 0.00408172607421875, 'loss_3': -16.346736907958984, 'loss_4': 0.3483678102493286, 'epoch': 18.39}
{'loss': 0.0077, 'grad_norm': 4.686949253082275, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.0047211493365466595, 'loss_2': 0.002971649169921875, 'loss_3': -16.432785034179688, 'loss_4': 0.13885828852653503, 'epoch': 18.4}
{'loss': 0.0162, 'grad_norm': 4.480149269104004, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.006819179281592369, 'loss_2': 0.0093841552734375, 'loss_3': -16.413314819335938, 'loss_4': 0.17180031538009644, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 16:35:32,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:32,603 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:26<34:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:39,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014650318771600723, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011017446406185627, 'eval_loss_2': 0.003632873296737671, 'eval_loss_3': -18.200597763061523, 'eval_loss_4': 0.10491494089365005, 'epoch': 18.4}
{'loss': 0.0131, 'grad_norm': 6.138763427734375, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.008882904425263405, 'loss_2': 0.00421142578125, 'loss_3': -16.573375701904297, 'loss_4': -0.09499247372150421, 'epoch': 18.41}
{'loss': 0.0266, 'grad_norm': 10.861087799072266, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.026204023510217667, 'loss_2': 0.00037097930908203125, 'loss_3': -16.236635208129883, 'loss_4': -0.2824214696884155, 'epoch': 18.41}
{'loss': 0.016, 'grad_norm': 7.126008033752441, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.01038146112114191, 'loss_2': 0.005664825439453125, 'loss_3': -16.374534606933594, 'loss_4': -0.07012540102005005, 'epoch': 18.42}
{'loss': 0.0115, 'grad_norm': 5.8586530685424805, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.007644839119166136, 'loss_2': 0.0038509368896484375, 'loss_3': -16.39344596862793, 'loss_4': -0.00885242223739624, 'epoch': 18.42}
{'loss': 0.0205, 'grad_norm': 8.32534122467041, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.014629487879574299, 'loss_2': 0.005825042724609375, 'loss_3': -16.425342559814453, 'loss_4': -0.04000061750411987, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 16:35:39,953 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:39,953 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:33<34:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:47,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015206461772322655, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.467, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011905048973858356, 'eval_loss_2': 0.0033014118671417236, 'eval_loss_3': -18.20831871032715, 'eval_loss_4': 0.0377572700381279, 'epoch': 18.43}
{'loss': 0.0115, 'grad_norm': 5.506839275360107, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.007364118471741676, 'loss_2': 0.004154205322265625, 'loss_3': -16.41884994506836, 'loss_4': -0.16574223339557648, 'epoch': 18.44}
{'loss': 0.0088, 'grad_norm': 5.737096309661865, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.007539481855928898, 'loss_2': 0.0012788772583007812, 'loss_3': -16.38869285583496, 'loss_4': -0.452662855386734, 'epoch': 18.44}
{'loss': 0.0177, 'grad_norm': 5.306324481964111, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.008415496908128262, 'loss_2': 0.00927734375, 'loss_3': -16.231956481933594, 'loss_4': 0.13442392647266388, 'epoch': 18.45}
{'loss': 0.0088, 'grad_norm': 5.547374725341797, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.008557049557566643, 'loss_2': 0.00020956993103027344, 'loss_3': -16.412084579467773, 'loss_4': 0.3924727141857147, 'epoch': 18.45}
{'loss': 0.0175, 'grad_norm': 9.540760040283203, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.014914460480213165, 'loss_2': 0.00262451171875, 'loss_3': -16.49453353881836, 'loss_4': -0.026384063065052032, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 16:35:47,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:47,307 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:41<34:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:35:54,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014829663559794426, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.962, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011836310848593712, 'eval_loss_2': 0.002993352711200714, 'eval_loss_3': -18.22235870361328, 'eval_loss_4': -0.13175149261951447, 'epoch': 18.46}
{'loss': 0.0113, 'grad_norm': 6.084753513336182, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.011136634275317192, 'loss_2': 0.00013065338134765625, 'loss_3': -16.408811569213867, 'loss_4': -0.15647196769714355, 'epoch': 18.47}
{'loss': 0.0076, 'grad_norm': 4.551090240478516, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.0044904728420078754, 'loss_2': 0.00313568115234375, 'loss_3': -16.41218376159668, 'loss_4': -0.050958871841430664, 'epoch': 18.47}
{'loss': 0.0174, 'grad_norm': 10.116311073303223, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.014133146032691002, 'loss_2': 0.003299713134765625, 'loss_3': -16.432655334472656, 'loss_4': -0.3936742842197418, 'epoch': 18.48}
{'loss': 0.0206, 'grad_norm': 6.0448503494262695, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.010866345837712288, 'loss_2': 0.00974273681640625, 'loss_3': -16.42263412475586, 'loss_4': 0.3912777900695801, 'epoch': 18.48}
{'loss': 0.0099, 'grad_norm': 5.719263553619385, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.008788071572780609, 'loss_2': 0.0011081695556640625, 'loss_3': -16.413902282714844, 'loss_4': -0.3035629987716675, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 16:35:54,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:35:54,647 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:48<34:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:01,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014758315868675709, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.554, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011293013580143452, 'eval_loss_2': 0.003465302288532257, 'eval_loss_3': -18.2128963470459, 'eval_loss_4': -0.13728973269462585, 'epoch': 18.49}
{'loss': 0.0081, 'grad_norm': 5.384583473205566, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.007588173728436232, 'loss_2': 0.0005035400390625, 'loss_3': -16.485607147216797, 'loss_4': 0.3312130272388458, 'epoch': 18.49}
{'loss': 0.0144, 'grad_norm': 4.7878217697143555, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.005457886029034853, 'loss_2': 0.0089569091796875, 'loss_3': -16.403844833374023, 'loss_4': 0.43322813510894775, 'epoch': 18.5}
{'loss': 0.0182, 'grad_norm': 9.519514083862305, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.015921520069241524, 'loss_2': 0.002323150634765625, 'loss_3': -16.448184967041016, 'loss_4': -0.33350515365600586, 'epoch': 18.51}
{'loss': 0.0236, 'grad_norm': 14.622649192810059, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.02269543707370758, 'loss_2': 0.0009145736694335938, 'loss_3': -16.199825286865234, 'loss_4': 0.2518309950828552, 'epoch': 18.51}
{'loss': 0.0068, 'grad_norm': 5.227901458740234, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.005140517372637987, 'loss_2': 0.001708984375, 'loss_3': -16.404321670532227, 'loss_4': 0.14103174209594727, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 16:36:01,980 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:01,980 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:18:55<34:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:09,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015051314607262611, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.302, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011539267376065254, 'eval_loss_2': 0.003512047231197357, 'eval_loss_3': -18.206958770751953, 'eval_loss_4': -0.09022420644760132, 'epoch': 18.52}
{'loss': 0.0081, 'grad_norm': 4.8629560470581055, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.0049303374253213406, 'loss_2': 0.0031585693359375, 'loss_3': -16.42622947692871, 'loss_4': 0.2734909951686859, 'epoch': 18.52}
{'loss': 0.016, 'grad_norm': 5.663148403167725, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.012854175642132759, 'loss_2': 0.00311279296875, 'loss_3': -16.2482852935791, 'loss_4': 0.016299322247505188, 'epoch': 18.53}
{'loss': 0.0114, 'grad_norm': 4.709880352020264, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.008587769232690334, 'loss_2': 0.002841949462890625, 'loss_3': -16.26299285888672, 'loss_4': 0.08154353499412537, 'epoch': 18.53}
{'loss': 0.0401, 'grad_norm': 14.70543384552002, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.03518642857670784, 'loss_2': 0.0048675537109375, 'loss_3': -16.25402069091797, 'loss_4': -0.14651168882846832, 'epoch': 18.54}
{'loss': 0.0158, 'grad_norm': 7.011459827423096, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.01455864030867815, 'loss_2': 0.0012111663818359375, 'loss_3': -16.591142654418945, 'loss_4': -0.19128835201263428, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 16:36:09,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:09,319 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:19:03<33:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:16,663 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017722848802804947, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.413, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010914776474237442, 'eval_loss_2': 0.006808072328567505, 'eval_loss_3': -18.198965072631836, 'eval_loss_4': 0.010334905236959457, 'epoch': 18.55}
{'loss': 0.013, 'grad_norm': 4.710489273071289, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.007247408386319876, 'loss_2': 0.005786895751953125, 'loss_3': -16.483856201171875, 'loss_4': 0.26831191778182983, 'epoch': 18.55}
{'loss': 0.0042, 'grad_norm': 4.792032718658447, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.003879773896187544, 'loss_2': 0.0003018379211425781, 'loss_3': -16.456615447998047, 'loss_4': 0.07178551703691483, 'epoch': 18.56}
{'loss': 0.0068, 'grad_norm': 5.456766605377197, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.005757481325417757, 'loss_2': 0.001041412353515625, 'loss_3': -16.302440643310547, 'loss_4': -0.4984433948993683, 'epoch': 18.56}
{'loss': 0.0124, 'grad_norm': 7.187586307525635, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.01135322917252779, 'loss_2': 0.0010833740234375, 'loss_3': -16.371183395385742, 'loss_4': 0.22256678342819214, 'epoch': 18.57}
{'loss': 0.0121, 'grad_norm': 6.415693759918213, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.0065636709332466125, 'loss_2': 0.0055389404296875, 'loss_3': -16.31890106201172, 'loss_4': 0.29213646054267883, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 16:36:16,663 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:16,663 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:19:10<33:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:24,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014161407947540283, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.283, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010620025917887688, 'eval_loss_2': 0.0035413801670074463, 'eval_loss_3': -18.198688507080078, 'eval_loss_4': 0.004130268469452858, 'epoch': 18.58}
{'loss': 0.0109, 'grad_norm': 5.221558094024658, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.0038177783135324717, 'loss_2': 0.0070953369140625, 'loss_3': -16.281951904296875, 'loss_4': 0.15782678127288818, 'epoch': 18.58}
{'loss': 0.0208, 'grad_norm': 8.267044067382812, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.01446215994656086, 'loss_2': 0.0063629150390625, 'loss_3': -16.28567886352539, 'loss_4': -0.052555203437805176, 'epoch': 18.59}
{'loss': 0.0138, 'grad_norm': 7.032278060913086, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.009347796440124512, 'loss_2': 0.0044097900390625, 'loss_3': -16.40736198425293, 'loss_4': 0.1530941128730774, 'epoch': 18.59}
{'loss': 0.0117, 'grad_norm': 6.244419574737549, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.011677826754748821, 'loss_2': 3.0159950256347656e-05, 'loss_3': -16.450889587402344, 'loss_4': 0.2283925712108612, 'epoch': 18.6}
{'loss': 0.01, 'grad_norm': 5.30873441696167, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.00813407264649868, 'loss_2': 0.0018243789672851562, 'loss_3': -16.371559143066406, 'loss_4': 0.15308848023414612, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 16:36:24,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:24,004 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:17<33:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:31,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013746807351708412, 'eval_runtime': 3.7958, 'eval_samples_per_second': 269.774, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010256880894303322, 'eval_loss_2': 0.0034899264574050903, 'eval_loss_3': -18.182546615600586, 'eval_loss_4': 0.08794549107551575, 'epoch': 18.6}
{'loss': 0.0947, 'grad_norm': 22.554861068725586, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.09359732270240784, 'loss_2': 0.0010728836059570312, 'loss_3': -16.41309928894043, 'loss_4': 0.27999186515808105, 'epoch': 18.61}
{'loss': 0.0098, 'grad_norm': 4.872992038726807, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.0048530627973377705, 'loss_2': 0.00493621826171875, 'loss_3': -16.253520965576172, 'loss_4': 0.025263667106628418, 'epoch': 18.62}
{'loss': 0.0241, 'grad_norm': 9.05534553527832, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.017205344513058662, 'loss_2': 0.00685882568359375, 'loss_3': -16.22701644897461, 'loss_4': 0.04319752752780914, 'epoch': 18.62}
{'loss': 0.0137, 'grad_norm': 6.675375938415527, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.012811376713216305, 'loss_2': 0.0008649826049804688, 'loss_3': -16.620059967041016, 'loss_4': -0.27264508605003357, 'epoch': 18.63}
{'loss': 0.0097, 'grad_norm': 5.341301918029785, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.007318929769098759, 'loss_2': 0.00238800048828125, 'loss_3': -16.610687255859375, 'loss_4': -0.14594951272010803, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 16:36:31,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:31,336 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:25<33:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:38,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01266091875731945, 'eval_runtime': 3.7981, 'eval_samples_per_second': 269.611, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.009324741549789906, 'eval_loss_2': 0.00333617627620697, 'eval_loss_3': -18.17108154296875, 'eval_loss_4': 0.193367600440979, 'epoch': 18.63}
{'loss': 0.0072, 'grad_norm': 5.141124725341797, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.005281325429677963, 'loss_2': 0.0019397735595703125, 'loss_3': -16.5477294921875, 'loss_4': 0.45138004422187805, 'epoch': 18.64}
{'loss': 0.0066, 'grad_norm': 5.275585174560547, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.005874286405742168, 'loss_2': 0.0007467269897460938, 'loss_3': -16.528501510620117, 'loss_4': -0.0997358113527298, 'epoch': 18.65}
{'loss': 0.0047, 'grad_norm': 5.003309726715088, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.004226227756589651, 'loss_2': 0.00047588348388671875, 'loss_3': -16.448402404785156, 'loss_4': -0.05342646688222885, 'epoch': 18.65}
{'loss': 0.0085, 'grad_norm': 5.4281392097473145, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.005896059330552816, 'loss_2': 0.0025691986083984375, 'loss_3': -16.376468658447266, 'loss_4': -0.02612399309873581, 'epoch': 18.66}
{'loss': 0.0088, 'grad_norm': 5.721884727478027, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.006836289074271917, 'loss_2': 0.001941680908203125, 'loss_3': -16.440813064575195, 'loss_4': 0.0030696317553520203, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 16:36:38,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:38,668 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:32<33:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:46,001 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011842936277389526, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.652, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.00794214103370905, 'eval_loss_2': 0.0039007961750030518, 'eval_loss_3': -18.169288635253906, 'eval_loss_4': 0.30984821915626526, 'epoch': 18.66}
{'loss': 0.0143, 'grad_norm': 9.05670166015625, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.01304270513355732, 'loss_2': 0.0012683868408203125, 'loss_3': -16.29414939880371, 'loss_4': 0.2798132002353668, 'epoch': 18.67}
{'loss': 0.0085, 'grad_norm': 5.06810998916626, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.006905259098857641, 'loss_2': 0.001598358154296875, 'loss_3': -16.288475036621094, 'loss_4': 0.4576430320739746, 'epoch': 18.67}
{'loss': 0.0087, 'grad_norm': 5.009676933288574, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.005585042759776115, 'loss_2': 0.0031452178955078125, 'loss_3': -16.42359161376953, 'loss_4': 0.17102618515491486, 'epoch': 18.68}
{'loss': 0.0137, 'grad_norm': 5.352086067199707, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.008757825009524822, 'loss_2': 0.004932403564453125, 'loss_3': -16.541881561279297, 'loss_4': 0.9344891309738159, 'epoch': 18.69}
{'loss': 0.0057, 'grad_norm': 4.59231424331665, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.004296963103115559, 'loss_2': 0.0013751983642578125, 'loss_3': -16.269624710083008, 'loss_4': 0.39768922328948975, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 16:36:46,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:46,002 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:39<33:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:36:53,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012823410332202911, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.625, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.008867569267749786, 'eval_loss_2': 0.003955841064453125, 'eval_loss_3': -18.167503356933594, 'eval_loss_4': 0.3724578320980072, 'epoch': 18.69}
{'loss': 0.0135, 'grad_norm': 5.416184902191162, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.00617558928206563, 'loss_2': 0.00730133056640625, 'loss_3': -16.333215713500977, 'loss_4': 0.28427696228027344, 'epoch': 18.7}
{'loss': 0.0237, 'grad_norm': 10.477428436279297, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.02082803286612034, 'loss_2': 0.002910614013671875, 'loss_3': -16.476139068603516, 'loss_4': 0.41841456294059753, 'epoch': 18.7}
{'loss': 0.0089, 'grad_norm': 5.585300445556641, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.004130660090595484, 'loss_2': 0.00476837158203125, 'loss_3': -16.39739418029785, 'loss_4': 0.35890549421310425, 'epoch': 18.71}
{'loss': 0.0133, 'grad_norm': 7.353442668914795, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.010472370311617851, 'loss_2': 0.002872467041015625, 'loss_3': -16.50700569152832, 'loss_4': 0.3617658317089081, 'epoch': 18.72}
{'loss': 0.0093, 'grad_norm': 5.801568984985352, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.006925585679709911, 'loss_2': 0.00237274169921875, 'loss_3': -16.332441329956055, 'loss_4': 0.14348265528678894, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 16:36:53,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:36:53,338 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:47<33:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:00,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013060162775218487, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.195, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009432564489543438, 'eval_loss_2': 0.003627598285675049, 'eval_loss_3': -18.16611671447754, 'eval_loss_4': 0.2837120294570923, 'epoch': 18.72}
{'loss': 0.0106, 'grad_norm': 5.594528675079346, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.007222363259643316, 'loss_2': 0.003398895263671875, 'loss_3': -16.310049057006836, 'loss_4': 0.5445832014083862, 'epoch': 18.73}
{'loss': 0.0247, 'grad_norm': 10.881854057312012, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.024515891447663307, 'loss_2': 0.00016570091247558594, 'loss_3': -16.287673950195312, 'loss_4': 0.3620903491973877, 'epoch': 18.73}
{'loss': 0.0092, 'grad_norm': 4.943328380584717, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.0048381914384663105, 'loss_2': 0.004383087158203125, 'loss_3': -16.424880981445312, 'loss_4': 0.2302376925945282, 'epoch': 18.74}
{'loss': 0.0171, 'grad_norm': 7.361225605010986, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.013598399236798286, 'loss_2': 0.003475189208984375, 'loss_3': -16.345897674560547, 'loss_4': 0.33407342433929443, 'epoch': 18.74}
{'loss': 0.0061, 'grad_norm': 4.953234672546387, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.002449051709845662, 'loss_2': 0.003650665283203125, 'loss_3': -16.44850730895996, 'loss_4': -0.31539294123649597, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 16:37:00,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:00,679 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:54<33:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:08,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013435597531497478, 'eval_runtime': 3.7995, 'eval_samples_per_second': 269.508, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009600545279681683, 'eval_loss_2': 0.003835052251815796, 'eval_loss_3': -18.156112670898438, 'eval_loss_4': 0.2179296314716339, 'epoch': 18.75}
{'loss': 0.012, 'grad_norm': 4.965548515319824, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.0035982916597276926, 'loss_2': 0.008392333984375, 'loss_3': -16.454954147338867, 'loss_4': 0.7969210147857666, 'epoch': 18.76}
{'loss': 0.0212, 'grad_norm': 10.792226791381836, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.01522661093622446, 'loss_2': 0.0059814453125, 'loss_3': -16.34033203125, 'loss_4': 0.381290465593338, 'epoch': 18.76}
{'loss': 0.006, 'grad_norm': 4.668832778930664, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.00284598208963871, 'loss_2': 0.0031414031982421875, 'loss_3': -16.478363037109375, 'loss_4': -0.12817955017089844, 'epoch': 18.77}
{'loss': 0.0127, 'grad_norm': 5.675951957702637, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.009277633391320705, 'loss_2': 0.0034637451171875, 'loss_3': -16.246105194091797, 'loss_4': 0.19852587580680847, 'epoch': 18.77}
{'loss': 0.0105, 'grad_norm': 5.373846530914307, 'learning_rate': 1.125e-05, 'loss_1': 0.006191524211317301, 'loss_2': 0.00433349609375, 'loss_3': -16.46432876586914, 'loss_4': -0.0236387699842453, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 16:37:08,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:08,015 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:20:01<33:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:15,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013905355706810951, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.805, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.009619751013815403, 'eval_loss_2': 0.004285603761672974, 'eval_loss_3': -18.158693313598633, 'eval_loss_4': 0.12098415195941925, 'epoch': 18.78}
{'loss': 0.0194, 'grad_norm': 8.935201644897461, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.01655229739844799, 'loss_2': 0.0028781890869140625, 'loss_3': -16.471664428710938, 'loss_4': 0.14243647456169128, 'epoch': 18.78}
{'loss': 0.013, 'grad_norm': 5.087499618530273, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.00838490854948759, 'loss_2': 0.004638671875, 'loss_3': -16.375640869140625, 'loss_4': 0.41585129499435425, 'epoch': 18.79}
{'loss': 0.0105, 'grad_norm': 5.269773960113525, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.006675946060568094, 'loss_2': 0.003849029541015625, 'loss_3': -16.24822998046875, 'loss_4': 0.07317844033241272, 'epoch': 18.8}
{'loss': 0.0103, 'grad_norm': 5.827497482299805, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.009615221992135048, 'loss_2': 0.0007305145263671875, 'loss_3': -16.4818058013916, 'loss_4': 0.11114197969436646, 'epoch': 18.8}
{'loss': 0.019, 'grad_norm': 6.506518840789795, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.010060641914606094, 'loss_2': 0.008941650390625, 'loss_3': -16.31428337097168, 'loss_4': -0.3787810802459717, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 16:37:15,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:15,349 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:20:09<33:06,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:37:22,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013822149485349655, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.691, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009155035950243473, 'eval_loss_2': 0.004667114466428757, 'eval_loss_3': -18.15117835998535, 'eval_loss_4': 0.07424252480268478, 'epoch': 18.81}
{'loss': 0.019, 'grad_norm': 5.118004322052002, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.007828413508832455, 'loss_2': 0.0111846923828125, 'loss_3': -16.456825256347656, 'loss_4': 0.15501588582992554, 'epoch': 18.81}
{'loss': 0.0072, 'grad_norm': 5.058901786804199, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.005510731600224972, 'loss_2': 0.00167083740234375, 'loss_3': -16.417335510253906, 'loss_4': 0.3106212615966797, 'epoch': 18.82}
{'loss': 0.009, 'grad_norm': 5.453152179718018, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.004896063357591629, 'loss_2': 0.00409698486328125, 'loss_3': -16.488445281982422, 'loss_4': -0.05662544071674347, 'epoch': 18.83}
{'loss': 0.0065, 'grad_norm': 4.791403293609619, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.0041020652279257774, 'loss_2': 0.0023708343505859375, 'loss_3': -16.542299270629883, 'loss_4': 0.22501063346862793, 'epoch': 18.83}
{'loss': 0.0066, 'grad_norm': 4.911756992340088, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.0035076781641691923, 'loss_2': 0.003093719482421875, 'loss_3': -16.363603591918945, 'loss_4': 0.1562185287475586, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 16:37:22,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:22,678 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:20:16<33:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:30,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013318553566932678, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009798973798751831, 'eval_loss_2': 0.003519579768180847, 'eval_loss_3': -18.128957748413086, 'eval_loss_4': 0.09692268073558807, 'epoch': 18.84}
{'loss': 0.0048, 'grad_norm': 4.088747978210449, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.0039256904274225235, 'loss_2': 0.0008516311645507812, 'loss_3': -16.404199600219727, 'loss_4': 0.4148905277252197, 'epoch': 18.84}
{'loss': 0.0066, 'grad_norm': 4.62691068649292, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.005060757510364056, 'loss_2': 0.0014905929565429688, 'loss_3': -16.379690170288086, 'loss_4': 0.07118979096412659, 'epoch': 18.85}
{'loss': 0.0154, 'grad_norm': 7.657688140869141, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.013128806836903095, 'loss_2': 0.0022430419921875, 'loss_3': -16.42184829711914, 'loss_4': -0.12666070461273193, 'epoch': 18.85}
{'loss': 0.024, 'grad_norm': 12.668270111083984, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.021524703130126, 'loss_2': 0.002498626708984375, 'loss_3': -16.45037841796875, 'loss_4': 0.3076171278953552, 'epoch': 18.86}
{'loss': 0.0138, 'grad_norm': 5.4498772621154785, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.009056487120687962, 'loss_2': 0.00470733642578125, 'loss_3': -16.408519744873047, 'loss_4': 0.018633343279361725, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 16:37:30,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:30,015 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:23<32:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:37,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013623910024762154, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010209531523287296, 'eval_loss_2': 0.0034143775701522827, 'eval_loss_3': -18.10503387451172, 'eval_loss_4': 0.1285603791475296, 'epoch': 18.87}
{'loss': 0.0077, 'grad_norm': 4.963475704193115, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.004350020084530115, 'loss_2': 0.00336456298828125, 'loss_3': -16.43167495727539, 'loss_4': 0.36186856031417847, 'epoch': 18.87}
{'loss': 0.0084, 'grad_norm': 4.550384044647217, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.008160280995070934, 'loss_2': 0.00019407272338867188, 'loss_3': -16.599536895751953, 'loss_4': 0.06904870271682739, 'epoch': 18.88}
{'loss': 0.0152, 'grad_norm': 5.885250568389893, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.011868531815707684, 'loss_2': 0.003322601318359375, 'loss_3': -16.357131958007812, 'loss_4': 0.42044228315353394, 'epoch': 18.88}
{'loss': 0.0109, 'grad_norm': 4.665811538696289, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.004197207745164633, 'loss_2': 0.00667572021484375, 'loss_3': -16.444988250732422, 'loss_4': 0.19712844491004944, 'epoch': 18.89}
{'loss': 0.0051, 'grad_norm': 4.881664752960205, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.0048944950103759766, 'loss_2': 0.0002455711364746094, 'loss_3': -16.725025177001953, 'loss_4': 0.2582355737686157, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 16:37:37,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:37,348 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:31<32:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:44,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012595199048519135, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009952446445822716, 'eval_loss_2': 0.0026427507400512695, 'eval_loss_3': -18.101953506469727, 'eval_loss_4': 0.16578646004199982, 'epoch': 18.9}
{'loss': 0.0186, 'grad_norm': 6.346593379974365, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.012643638998270035, 'loss_2': 0.0059967041015625, 'loss_3': -16.450223922729492, 'loss_4': 0.21891041100025177, 'epoch': 18.9}
{'loss': 0.0099, 'grad_norm': 4.795628070831299, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.006329662166535854, 'loss_2': 0.003543853759765625, 'loss_3': -16.58650779724121, 'loss_4': 0.08038440346717834, 'epoch': 18.91}
{'loss': 0.0137, 'grad_norm': 5.760178089141846, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.007555259857326746, 'loss_2': 0.0061798095703125, 'loss_3': -16.44922637939453, 'loss_4': -0.10363801568746567, 'epoch': 18.91}
{'loss': 0.0147, 'grad_norm': 4.9753737449646, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.004797283560037613, 'loss_2': 0.0099029541015625, 'loss_3': -16.679908752441406, 'loss_4': -0.10888324677944183, 'epoch': 18.92}
{'loss': 0.0089, 'grad_norm': 4.7920403480529785, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.006314825266599655, 'loss_2': 0.0025920867919921875, 'loss_3': -16.3347110748291, 'loss_4': 0.10341259092092514, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 16:37:44,683 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:44,683 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:38<32:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:52,012 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017052246257662773, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.942, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010662331245839596, 'eval_loss_2': 0.006389915943145752, 'eval_loss_3': -18.125091552734375, 'eval_loss_4': 0.1637851744890213, 'epoch': 18.92}
{'loss': 0.0206, 'grad_norm': 4.943305969238281, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.006588350981473923, 'loss_2': 0.01396942138671875, 'loss_3': -16.36089515686035, 'loss_4': -0.12134718894958496, 'epoch': 18.93}
{'loss': 0.0171, 'grad_norm': 5.596796035766602, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.00782557763159275, 'loss_2': 0.0092315673828125, 'loss_3': -16.388771057128906, 'loss_4': 0.2465200275182724, 'epoch': 18.94}
{'loss': 0.0266, 'grad_norm': 17.843997955322266, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.019490227103233337, 'loss_2': 0.007061004638671875, 'loss_3': -16.43478775024414, 'loss_4': 0.2443217933177948, 'epoch': 18.94}
{'loss': 0.0141, 'grad_norm': 4.624995231628418, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.006254531443119049, 'loss_2': 0.00787353515625, 'loss_3': -16.587142944335938, 'loss_4': -0.44059762358665466, 'epoch': 18.95}
{'loss': 0.011, 'grad_norm': 5.562900543212891, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.007917161099612713, 'loss_2': 0.00308990478515625, 'loss_3': -16.660062789916992, 'loss_4': 0.37571823596954346, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 16:37:52,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:52,012 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:45<32:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:37:59,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01611548662185669, 'eval_runtime': 3.7947, 'eval_samples_per_second': 269.849, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01077626645565033, 'eval_loss_2': 0.00533922016620636, 'eval_loss_3': -18.128223419189453, 'eval_loss_4': 0.18450656533241272, 'epoch': 18.95}
{'loss': 0.0243, 'grad_norm': 14.40544319152832, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.019636444747447968, 'loss_2': 0.00464630126953125, 'loss_3': -16.472713470458984, 'loss_4': 0.40825605392456055, 'epoch': 18.96}
{'loss': 0.0281, 'grad_norm': 14.803122520446777, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.021642208099365234, 'loss_2': 0.0064849853515625, 'loss_3': -16.482498168945312, 'loss_4': 0.49905532598495483, 'epoch': 18.97}
{'loss': 0.0125, 'grad_norm': 5.463403224945068, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.009141400456428528, 'loss_2': 0.003360748291015625, 'loss_3': -16.586376190185547, 'loss_4': 0.38369059562683105, 'epoch': 18.97}
{'loss': 0.0186, 'grad_norm': 5.788783073425293, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.0130929471924901, 'loss_2': 0.00554656982421875, 'loss_3': -16.73598289489746, 'loss_4': 0.14971937239170074, 'epoch': 18.98}
{'loss': 0.0216, 'grad_norm': 7.916177749633789, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.01400831900537014, 'loss_2': 0.00759124755859375, 'loss_3': -16.474855422973633, 'loss_4': 0.2930606007575989, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 16:37:59,342 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:37:59,342 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:52<31:18,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 16:38:06,365 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01361087430268526, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.898, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01061673928052187, 'eval_loss_2': 0.002994135022163391, 'eval_loss_3': -18.125640869140625, 'eval_loss_4': 0.3256071209907532, 'epoch': 18.98}
{'loss': 0.0084, 'grad_norm': 5.004977226257324, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.006937121506780386, 'loss_2': 0.00146484375, 'loss_3': -16.371591567993164, 'loss_4': 0.29128342866897583, 'epoch': 18.99}
{'loss': 0.0226, 'grad_norm': 8.302520751953125, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.018116561695933342, 'loss_2': 0.00445556640625, 'loss_3': -16.571147918701172, 'loss_4': 1.083270788192749, 'epoch': 18.99}
{'loss': 0.0187, 'grad_norm': 10.73666763305664, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.016465432941913605, 'loss_2': 0.0022830963134765625, 'loss_3': -16.42812156677246, 'loss_4': 0.5247359871864319, 'epoch': 19.0}
{'loss': 0.013, 'grad_norm': 5.899641990661621, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.00939580425620079, 'loss_2': 0.003574371337890625, 'loss_3': -16.626148223876953, 'loss_4': 0.4645897150039673, 'epoch': 19.01}
{'loss': 0.0938, 'grad_norm': 21.146808624267578, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.09168294817209244, 'loss_2': 0.00209808349609375, 'loss_3': -16.535465240478516, 'loss_4': 0.5606669187545776, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 16:38:06,365 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:06,365 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:21:00<32:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:38:13,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013480067253112793, 'eval_runtime': 3.7986, 'eval_samples_per_second': 269.575, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010236050002276897, 'eval_loss_2': 0.003244016319513321, 'eval_loss_3': -18.12510871887207, 'eval_loss_4': 0.44931554794311523, 'epoch': 19.01}
{'loss': 0.0113, 'grad_norm': 5.061513900756836, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.00976532232016325, 'loss_2': 0.0015659332275390625, 'loss_3': -16.63692283630371, 'loss_4': 0.02824024111032486, 'epoch': 19.02}
{'loss': 0.0122, 'grad_norm': 5.481016159057617, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.009216919541358948, 'loss_2': 0.00295257568359375, 'loss_3': -16.421070098876953, 'loss_4': 0.8861858248710632, 'epoch': 19.02}
{'loss': 0.0135, 'grad_norm': 5.434309005737305, 'learning_rate': 1.1e-05, 'loss_1': 0.009918823838233948, 'loss_2': 0.003574371337890625, 'loss_3': -16.50888442993164, 'loss_4': 0.8153606653213501, 'epoch': 19.03}
{'loss': 0.0171, 'grad_norm': 5.724393367767334, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.01034142728894949, 'loss_2': 0.0067901611328125, 'loss_3': -16.460416793823242, 'loss_4': 0.378170907497406, 'epoch': 19.03}
{'loss': 0.0163, 'grad_norm': 10.626017570495605, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.015935128554701805, 'loss_2': 0.0003349781036376953, 'loss_3': -16.586978912353516, 'loss_4': 0.6213382482528687, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 16:38:13,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:13,704 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:21:07<32:25,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:38:21,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015049159526824951, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.025, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010413824580609798, 'eval_loss_2': 0.004635334014892578, 'eval_loss_3': -18.13616943359375, 'eval_loss_4': 0.4885839819908142, 'epoch': 19.04}
{'loss': 0.0139, 'grad_norm': 4.851141929626465, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.009106112644076347, 'loss_2': 0.004749298095703125, 'loss_3': -16.588010787963867, 'loss_4': 0.41561806201934814, 'epoch': 19.05}
{'loss': 0.0114, 'grad_norm': 5.285676956176758, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.007009741850197315, 'loss_2': 0.004375457763671875, 'loss_3': -16.525901794433594, 'loss_4': 0.5659934282302856, 'epoch': 19.05}
{'loss': 0.0814, 'grad_norm': 14.812813758850098, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.07434976100921631, 'loss_2': 0.0070953369140625, 'loss_3': -16.57559585571289, 'loss_4': 0.6441206932067871, 'epoch': 19.06}
{'loss': 0.0258, 'grad_norm': 14.047096252441406, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.02523065358400345, 'loss_2': 0.0005235671997070312, 'loss_3': -16.404247283935547, 'loss_4': 0.7251254320144653, 'epoch': 19.06}
{'loss': 0.0133, 'grad_norm': 4.672262191772461, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.0045599364675581455, 'loss_2': 0.00872039794921875, 'loss_3': -16.400394439697266, 'loss_4': 0.5096216797828674, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 16:38:21,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:21,043 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:21:14<32:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:28,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015738289803266525, 'eval_runtime': 3.7948, 'eval_samples_per_second': 269.845, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011099396273493767, 'eval_loss_2': 0.004638895392417908, 'eval_loss_3': -18.120319366455078, 'eval_loss_4': 0.3862116038799286, 'epoch': 19.07}
{'loss': 0.0309, 'grad_norm': 9.262737274169922, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.0214789230376482, 'loss_2': 0.00946807861328125, 'loss_3': -16.506240844726562, 'loss_4': 0.8220052719116211, 'epoch': 19.08}
{'loss': 0.0138, 'grad_norm': 5.14830207824707, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.007525759749114513, 'loss_2': 0.006256103515625, 'loss_3': -16.525489807128906, 'loss_4': 0.5621762275695801, 'epoch': 19.08}
{'loss': 0.0083, 'grad_norm': 5.513250350952148, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.0062761250883340836, 'loss_2': 0.0020580291748046875, 'loss_3': -16.620738983154297, 'loss_4': 0.23273669183254242, 'epoch': 19.09}
{'loss': 0.0097, 'grad_norm': 5.312594890594482, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.007755211088806391, 'loss_2': 0.001956939697265625, 'loss_3': -16.383516311645508, 'loss_4': 0.7630610466003418, 'epoch': 19.09}
{'loss': 0.0098, 'grad_norm': 6.476692199707031, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.008173635229468346, 'loss_2': 0.0016345977783203125, 'loss_3': -16.3922119140625, 'loss_4': -0.03356514871120453, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 16:38:28,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:28,384 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:22<32:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:35,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01680028811097145, 'eval_runtime': 3.7916, 'eval_samples_per_second': 270.069, 'eval_steps_per_second': 4.22, 'eval_loss_1': 0.013006036169826984, 'eval_loss_2': 0.003794252872467041, 'eval_loss_3': -18.123403549194336, 'eval_loss_4': 0.24895550310611725, 'epoch': 19.1}
{'loss': 0.0175, 'grad_norm': 9.167937278747559, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.012379340827465057, 'loss_2': 0.00513458251953125, 'loss_3': -16.420820236206055, 'loss_4': 0.42628243565559387, 'epoch': 19.1}
{'loss': 0.0169, 'grad_norm': 9.521739959716797, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.01094419602304697, 'loss_2': 0.00597381591796875, 'loss_3': -16.720321655273438, 'loss_4': 0.4901580214500427, 'epoch': 19.11}
{'loss': 0.0109, 'grad_norm': 5.553882122039795, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.008637281134724617, 'loss_2': 0.002307891845703125, 'loss_3': -16.58523941040039, 'loss_4': 0.19952896237373352, 'epoch': 19.12}
{'loss': 0.0105, 'grad_norm': 5.116112232208252, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.008756270632147789, 'loss_2': 0.00177764892578125, 'loss_3': -16.63287925720215, 'loss_4': 0.7514238953590393, 'epoch': 19.12}
{'loss': 0.0099, 'grad_norm': 6.375775337219238, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.00983947329223156, 'loss_2': 2.396106719970703e-05, 'loss_3': -16.59602928161621, 'loss_4': 0.5826199650764465, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 16:38:35,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:35,713 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:29<32:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:43,040 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01523330993950367, 'eval_runtime': 3.7909, 'eval_samples_per_second': 270.12, 'eval_steps_per_second': 4.221, 'eval_loss_1': 0.012476623989641666, 'eval_loss_2': 0.0027566850185394287, 'eval_loss_3': -18.124570846557617, 'eval_loss_4': 0.3982897996902466, 'epoch': 19.13}
{'loss': 0.0126, 'grad_norm': 7.272099018096924, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.01149420440196991, 'loss_2': 0.0010614395141601562, 'loss_3': -16.33890151977539, 'loss_4': 0.48958879709243774, 'epoch': 19.13}
{'loss': 0.0073, 'grad_norm': 4.627094745635986, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.0047608367167413235, 'loss_2': 0.002544403076171875, 'loss_3': -16.482315063476562, 'loss_4': 0.6038771867752075, 'epoch': 19.14}
{'loss': 0.0095, 'grad_norm': 5.0359086990356445, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.006831009406596422, 'loss_2': 0.002643585205078125, 'loss_3': -16.565113067626953, 'loss_4': 1.0450150966644287, 'epoch': 19.15}
{'loss': 0.0157, 'grad_norm': 5.012477874755859, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.0074698468670248985, 'loss_2': 0.00827789306640625, 'loss_3': -16.42878532409668, 'loss_4': 0.8083344101905823, 'epoch': 19.15}
{'loss': 0.0217, 'grad_norm': 4.991055488586426, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.010546266101300716, 'loss_2': 0.0111236572265625, 'loss_3': -16.62489891052246, 'loss_4': 0.8676542043685913, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 16:38:43,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:43,040 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:36<32:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:50,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0154269989579916, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.647, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01261327974498272, 'eval_loss_2': 0.0028137192130088806, 'eval_loss_3': -18.14019775390625, 'eval_loss_4': 0.5847348570823669, 'epoch': 19.16}
{'loss': 0.0178, 'grad_norm': 6.402414798736572, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.013139834627509117, 'loss_2': 0.00464630126953125, 'loss_3': -16.4229793548584, 'loss_4': 0.23268365859985352, 'epoch': 19.16}
{'loss': 0.0257, 'grad_norm': 6.924409866333008, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.022182229906320572, 'loss_2': 0.0034999847412109375, 'loss_3': -16.588882446289062, 'loss_4': 1.3394429683685303, 'epoch': 19.17}
{'loss': 0.0081, 'grad_norm': 5.537304401397705, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.006768368184566498, 'loss_2': 0.0013380050659179688, 'loss_3': -16.407278060913086, 'loss_4': 0.2443348467350006, 'epoch': 19.17}
{'loss': 0.0191, 'grad_norm': 7.953732490539551, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.015405658632516861, 'loss_2': 0.003704071044921875, 'loss_3': -16.412675857543945, 'loss_4': 0.8595559597015381, 'epoch': 19.18}
{'loss': 0.0163, 'grad_norm': 6.339044570922852, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.010407211259007454, 'loss_2': 0.005908966064453125, 'loss_3': -16.503646850585938, 'loss_4': 1.0210323333740234, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 16:38:50,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:50,375 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:44<32:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:38:57,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01647084765136242, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.106, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013580319471657276, 'eval_loss_2': 0.0028905272483825684, 'eval_loss_3': -18.158815383911133, 'eval_loss_4': 0.7046869993209839, 'epoch': 19.19}
{'loss': 0.0063, 'grad_norm': 4.643726348876953, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.005395004991441965, 'loss_2': 0.0009245872497558594, 'loss_3': -16.54137420654297, 'loss_4': 0.8684478998184204, 'epoch': 19.19}
{'loss': 0.0159, 'grad_norm': 9.248449325561523, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.014876464381814003, 'loss_2': 0.001049041748046875, 'loss_3': -16.42101287841797, 'loss_4': 0.9698057174682617, 'epoch': 19.2}
{'loss': 0.0119, 'grad_norm': 5.021092414855957, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.009928129613399506, 'loss_2': 0.00200653076171875, 'loss_3': -16.126510620117188, 'loss_4': 0.6631348133087158, 'epoch': 19.2}
{'loss': 0.0187, 'grad_norm': 5.535035610198975, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.011880983598530293, 'loss_2': 0.006771087646484375, 'loss_3': -16.270416259765625, 'loss_4': 1.1743745803833008, 'epoch': 19.21}
{'loss': 0.0103, 'grad_norm': 5.053514003753662, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.004443034529685974, 'loss_2': 0.00583648681640625, 'loss_3': -16.577741622924805, 'loss_4': 1.1476664543151855, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 16:38:57,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:38:57,715 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:51<31:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:05,053 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02036784030497074, 'eval_runtime': 3.8001, 'eval_samples_per_second': 269.464, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01760735549032688, 'eval_loss_2': 0.00276048481464386, 'eval_loss_3': -18.150737762451172, 'eval_loss_4': 0.849077582359314, 'epoch': 19.22}
{'loss': 0.0066, 'grad_norm': 5.074879169464111, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.006271150894463062, 'loss_2': 0.000354766845703125, 'loss_3': -16.267425537109375, 'loss_4': 1.1393921375274658, 'epoch': 19.22}
{'loss': 0.0111, 'grad_norm': 4.830380916595459, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.008389108814299107, 'loss_2': 0.002685546875, 'loss_3': -16.53174591064453, 'loss_4': 1.1600656509399414, 'epoch': 19.23}
{'loss': 0.0167, 'grad_norm': 6.029264450073242, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.014437087811529636, 'loss_2': 0.00228118896484375, 'loss_3': -16.38497543334961, 'loss_4': 1.4070411920547485, 'epoch': 19.23}
{'loss': 0.0085, 'grad_norm': 4.868077278137207, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.008002826012670994, 'loss_2': 0.0005369186401367188, 'loss_3': -16.597675323486328, 'loss_4': 1.3407458066940308, 'epoch': 19.24}
{'loss': 0.011, 'grad_norm': 6.683705806732178, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.01010963600128889, 'loss_2': 0.0008411407470703125, 'loss_3': -16.407962799072266, 'loss_4': 1.5418099164962769, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 16:39:05,053 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:05,053 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:21:58<31:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:12,385 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020070474594831467, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.698, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.017059188336133957, 'eval_loss_2': 0.0030112862586975098, 'eval_loss_3': -18.140958786010742, 'eval_loss_4': 1.0072435140609741, 'epoch': 19.24}
{'loss': 0.0218, 'grad_norm': 5.6964592933654785, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.011287788860499859, 'loss_2': 0.01053619384765625, 'loss_3': -16.40401840209961, 'loss_4': 0.9878879189491272, 'epoch': 19.25}
{'loss': 0.0086, 'grad_norm': 5.5413689613342285, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.005770224146544933, 'loss_2': 0.0028362274169921875, 'loss_3': -16.550304412841797, 'loss_4': 1.3187808990478516, 'epoch': 19.26}
{'loss': 0.0153, 'grad_norm': 5.47853422164917, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.008954716846346855, 'loss_2': 0.00632476806640625, 'loss_3': -16.25121307373047, 'loss_4': 1.208775520324707, 'epoch': 19.26}
{'loss': 0.0112, 'grad_norm': 5.488682270050049, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.00841935258358717, 'loss_2': 0.002811431884765625, 'loss_3': -16.279939651489258, 'loss_4': 1.0675121545791626, 'epoch': 19.27}
{'loss': 0.0063, 'grad_norm': 4.602601051330566, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.004955632146447897, 'loss_2': 0.0013828277587890625, 'loss_3': -16.493526458740234, 'loss_4': 1.4340410232543945, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 16:39:12,385 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:12,385 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:22:06<31:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:19,720 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017938842996954918, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.643, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01423855684697628, 'eval_loss_2': 0.0037002861499786377, 'eval_loss_3': -18.1451416015625, 'eval_loss_4': 1.1233254671096802, 'epoch': 19.27}
{'loss': 0.0116, 'grad_norm': 4.7893853187561035, 'learning_rate': 1.075e-05, 'loss_1': 0.0058492147363722324, 'loss_2': 0.00572967529296875, 'loss_3': -16.39236068725586, 'loss_4': 1.2888492345809937, 'epoch': 19.28}
{'loss': 0.0156, 'grad_norm': 6.217496871948242, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.011025846935808659, 'loss_2': 0.004528045654296875, 'loss_3': -16.31804847717285, 'loss_4': 0.6304584741592407, 'epoch': 19.28}
{'loss': 0.0111, 'grad_norm': 5.381493091583252, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.010862885043025017, 'loss_2': 0.0002722740173339844, 'loss_3': -16.254497528076172, 'loss_4': 1.4551408290863037, 'epoch': 19.29}
{'loss': 0.0104, 'grad_norm': 4.59105110168457, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.0074563841335475445, 'loss_2': 0.0029754638671875, 'loss_3': -16.56097984313965, 'loss_4': 1.4930593967437744, 'epoch': 19.3}
{'loss': 0.0253, 'grad_norm': 8.813720703125, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.020029177889227867, 'loss_2': 0.00527191162109375, 'loss_3': -16.482040405273438, 'loss_4': 0.9340705871582031, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 16:39:19,720 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:19,720 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:22:13<31:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:27,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014486247673630714, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.805, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0121894720941782, 'eval_loss_2': 0.0022967755794525146, 'eval_loss_3': -18.149497985839844, 'eval_loss_4': 1.2200769186019897, 'epoch': 19.3}
{'loss': 0.0073, 'grad_norm': 4.110270023345947, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.006049336865544319, 'loss_2': 0.0012445449829101562, 'loss_3': -16.41106414794922, 'loss_4': 1.043914794921875, 'epoch': 19.31}
{'loss': 0.0177, 'grad_norm': 6.129799842834473, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.016305936500430107, 'loss_2': 0.001377105712890625, 'loss_3': -16.294818878173828, 'loss_4': 1.0798598527908325, 'epoch': 19.31}
{'loss': 0.0139, 'grad_norm': 5.227776527404785, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.007972140796482563, 'loss_2': 0.005970001220703125, 'loss_3': -16.392484664916992, 'loss_4': 1.4500738382339478, 'epoch': 19.32}
{'loss': 0.0379, 'grad_norm': 10.305752754211426, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.03390148654580116, 'loss_2': 0.003955841064453125, 'loss_3': -16.240039825439453, 'loss_4': 1.8726928234100342, 'epoch': 19.33}
{'loss': 0.0077, 'grad_norm': 4.578269004821777, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.005935207009315491, 'loss_2': 0.001735687255859375, 'loss_3': -16.287940979003906, 'loss_4': 1.4940671920776367, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 16:39:27,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:27,055 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:20<31:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:34,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013578786514699459, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.985, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.010821663774549961, 'eval_loss_2': 0.002757124602794647, 'eval_loss_3': -18.165435791015625, 'eval_loss_4': 1.409828782081604, 'epoch': 19.33}
{'loss': 0.0175, 'grad_norm': 7.259143829345703, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.013632895424962044, 'loss_2': 0.0038604736328125, 'loss_3': -16.26388168334961, 'loss_4': 1.152724266052246, 'epoch': 19.34}
{'loss': 0.0116, 'grad_norm': 4.5398030281066895, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.005718996748328209, 'loss_2': 0.005859375, 'loss_3': -16.500900268554688, 'loss_4': 1.2995164394378662, 'epoch': 19.34}
{'loss': 0.0074, 'grad_norm': 4.982266426086426, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.006497811991721392, 'loss_2': 0.000904083251953125, 'loss_3': -16.347984313964844, 'loss_4': 1.8643747568130493, 'epoch': 19.35}
{'loss': 0.0131, 'grad_norm': 6.471051216125488, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.010547817684710026, 'loss_2': 0.00258636474609375, 'loss_3': -16.370014190673828, 'loss_4': 1.792566180229187, 'epoch': 19.35}
{'loss': 0.009, 'grad_norm': 5.912752151489258, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.007941365242004395, 'loss_2': 0.00104522705078125, 'loss_3': -16.353107452392578, 'loss_4': 1.4740642309188843, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 16:39:34,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:34,388 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:28<31:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:41,731 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012870976701378822, 'eval_runtime': 3.8014, 'eval_samples_per_second': 269.375, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010310479439795017, 'eval_loss_2': 0.0025604963302612305, 'eval_loss_3': -18.177915573120117, 'eval_loss_4': 1.681139588356018, 'epoch': 19.36}
{'loss': 0.0188, 'grad_norm': 7.964834690093994, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.018314095214009285, 'loss_2': 0.0005316734313964844, 'loss_3': -16.509109497070312, 'loss_4': 1.4931938648223877, 'epoch': 19.37}
{'loss': 0.0153, 'grad_norm': 6.375572204589844, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.013284056447446346, 'loss_2': 0.002044677734375, 'loss_3': -16.358379364013672, 'loss_4': 1.7880384922027588, 'epoch': 19.37}
{'loss': 0.0082, 'grad_norm': 4.8678998947143555, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.005839627236127853, 'loss_2': 0.00232696533203125, 'loss_3': -16.50861358642578, 'loss_4': 1.7126200199127197, 'epoch': 19.38}
{'loss': 0.0098, 'grad_norm': 4.634450912475586, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.007772265933454037, 'loss_2': 0.001987457275390625, 'loss_3': -16.55123519897461, 'loss_4': 2.130674123764038, 'epoch': 19.38}
{'loss': 0.0313, 'grad_norm': 18.6241455078125, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.030295342206954956, 'loss_2': 0.0010156631469726562, 'loss_3': -16.591960906982422, 'loss_4': 1.8384783267974854, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 16:39:41,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:41,732 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:35<31:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:49,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013133788481354713, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.657, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01059582456946373, 'eval_loss_2': 0.002537965774536133, 'eval_loss_3': -18.164945602416992, 'eval_loss_4': 1.8416862487792969, 'epoch': 19.39}
{'loss': 0.0188, 'grad_norm': 4.713291645050049, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.007748560514301062, 'loss_2': 0.011016845703125, 'loss_3': -16.388057708740234, 'loss_4': 2.5620203018188477, 'epoch': 19.4}
{'loss': 0.0127, 'grad_norm': 4.918363571166992, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.010446174070239067, 'loss_2': 0.00228118896484375, 'loss_3': -16.364946365356445, 'loss_4': 1.8898799419403076, 'epoch': 19.4}
{'loss': 0.018, 'grad_norm': 9.836691856384277, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.01540061179548502, 'loss_2': 0.002582550048828125, 'loss_3': -16.277767181396484, 'loss_4': 2.021092653274536, 'epoch': 19.41}
{'loss': 0.0154, 'grad_norm': 5.516495704650879, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.011543430387973785, 'loss_2': 0.00385284423828125, 'loss_3': -16.531291961669922, 'loss_4': 2.088773727416992, 'epoch': 19.41}
{'loss': 0.0135, 'grad_norm': 5.2866692543029785, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.010662551037967205, 'loss_2': 0.002826690673828125, 'loss_3': -16.423555374145508, 'loss_4': 1.6998727321624756, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 16:39:49,069 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:49,069 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:42<31:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:39:56,400 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0149095319211483, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.887, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010828820988535881, 'eval_loss_2': 0.004080712795257568, 'eval_loss_3': -18.173175811767578, 'eval_loss_4': 1.9017616510391235, 'epoch': 19.42}
{'loss': 0.0152, 'grad_norm': 6.638894557952881, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.015084030106663704, 'loss_2': 7.033348083496094e-05, 'loss_3': -16.449674606323242, 'loss_4': 1.9788166284561157, 'epoch': 19.42}
{'loss': 0.0258, 'grad_norm': 10.338235855102539, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.024949008598923683, 'loss_2': 0.0008716583251953125, 'loss_3': -16.425655364990234, 'loss_4': 2.230797290802002, 'epoch': 19.43}
{'loss': 0.0652, 'grad_norm': 13.247182846069336, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.06252388656139374, 'loss_2': 0.002712249755859375, 'loss_3': -16.47953224182129, 'loss_4': 1.4587353467941284, 'epoch': 19.44}
{'loss': 0.0151, 'grad_norm': 11.252047538757324, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.009802645072340965, 'loss_2': 0.0052490234375, 'loss_3': -16.20050811767578, 'loss_4': 1.9233404397964478, 'epoch': 19.44}
{'loss': 0.0255, 'grad_norm': 7.484735012054443, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.020193984732031822, 'loss_2': 0.005329132080078125, 'loss_3': -16.291980743408203, 'loss_4': 2.226475715637207, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 16:39:56,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:39:56,401 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:50<31:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:03,735 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014903461560606956, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.962, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010792930610477924, 'eval_loss_2': 0.0041105300188064575, 'eval_loss_3': -18.175762176513672, 'eval_loss_4': 1.8238885402679443, 'epoch': 19.45}
{'loss': 0.0111, 'grad_norm': 5.127135276794434, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.008586271665990353, 'loss_2': 0.00252532958984375, 'loss_3': -16.41977310180664, 'loss_4': 2.4266772270202637, 'epoch': 19.45}
{'loss': 0.0101, 'grad_norm': 4.741430282592773, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.007199807092547417, 'loss_2': 0.002933502197265625, 'loss_3': -16.41338348388672, 'loss_4': 2.214369297027588, 'epoch': 19.46}
{'loss': 0.0109, 'grad_norm': 5.315989017486572, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.006475221831351519, 'loss_2': 0.004390716552734375, 'loss_3': -16.497533798217773, 'loss_4': 1.8247720003128052, 'epoch': 19.47}
{'loss': 0.012, 'grad_norm': 9.65219497680664, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.011532507836818695, 'loss_2': 0.00047588348388671875, 'loss_3': -16.429981231689453, 'loss_4': 1.542197346687317, 'epoch': 19.47}
{'loss': 0.0089, 'grad_norm': 4.598678112030029, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.007523080334067345, 'loss_2': 0.0014066696166992188, 'loss_3': -16.25555419921875, 'loss_4': 2.2353570461273193, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 16:40:03,735 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:03,735 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:22:57<31:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:11,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014649588614702225, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.75, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.012301426380872726, 'eval_loss_2': 0.0023481622338294983, 'eval_loss_3': -18.173200607299805, 'eval_loss_4': 1.66143798828125, 'epoch': 19.48}
{'loss': 0.0209, 'grad_norm': 5.874837875366211, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.010385755449533463, 'loss_2': 0.01055145263671875, 'loss_3': -16.511281967163086, 'loss_4': 1.7479794025421143, 'epoch': 19.48}
{'loss': 0.0234, 'grad_norm': 7.3035736083984375, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.01689576730132103, 'loss_2': 0.00646209716796875, 'loss_3': -16.402603149414062, 'loss_4': 1.6858646869659424, 'epoch': 19.49}
{'loss': 0.0158, 'grad_norm': 7.0511016845703125, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.013273118063807487, 'loss_2': 0.0025177001953125, 'loss_3': -16.31159019470215, 'loss_4': 1.2873213291168213, 'epoch': 19.49}
{'loss': 0.0246, 'grad_norm': 5.825698375701904, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.01659899577498436, 'loss_2': 0.007965087890625, 'loss_3': -16.409809112548828, 'loss_4': 1.6430716514587402, 'epoch': 19.5}
{'loss': 0.0265, 'grad_norm': 8.662110328674316, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.01790725439786911, 'loss_2': 0.00858306884765625, 'loss_3': -16.307415008544922, 'loss_4': 1.8281306028366089, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 16:40:11,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:11,067 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:23:04<31:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:18,405 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015314338728785515, 'eval_runtime': 3.7977, 'eval_samples_per_second': 269.635, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011130271479487419, 'eval_loss_2': 0.004184067249298096, 'eval_loss_3': -18.189315795898438, 'eval_loss_4': 1.5969955921173096, 'epoch': 19.51}
{'loss': 0.0146, 'grad_norm': 6.033391952514648, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.01333724893629551, 'loss_2': 0.00130462646484375, 'loss_3': -16.19930648803711, 'loss_4': 1.4410476684570312, 'epoch': 19.51}
{'loss': 0.0165, 'grad_norm': 5.272166728973389, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.007370223756879568, 'loss_2': 0.0091400146484375, 'loss_3': -16.354084014892578, 'loss_4': 1.9139612913131714, 'epoch': 19.52}
{'loss': 0.0201, 'grad_norm': 16.62013816833496, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.005182715132832527, 'loss_2': 0.01486968994140625, 'loss_3': -16.123306274414062, 'loss_4': 1.377450942993164, 'epoch': 19.52}
{'loss': 0.0143, 'grad_norm': 4.474428653717041, 'learning_rate': 1.05e-05, 'loss_1': 0.006465761456638575, 'loss_2': 0.007843017578125, 'loss_3': -16.430034637451172, 'loss_4': 2.0847859382629395, 'epoch': 19.53}
{'loss': 0.0187, 'grad_norm': 4.615124225616455, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.006519378162920475, 'loss_2': 0.01218414306640625, 'loss_3': -16.327646255493164, 'loss_4': 1.5520634651184082, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 16:40:18,405 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:18,405 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:23:12<31:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:25,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012490221299231052, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.49, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010427907109260559, 'eval_loss_2': 0.0020623132586479187, 'eval_loss_3': -18.1732177734375, 'eval_loss_4': 1.5276786088943481, 'epoch': 19.53}
{'loss': 0.0108, 'grad_norm': 5.454310417175293, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.008188734762370586, 'loss_2': 0.002620697021484375, 'loss_3': -16.518871307373047, 'loss_4': 1.920703649520874, 'epoch': 19.54}
{'loss': 0.0114, 'grad_norm': 5.69721794128418, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.008759175427258015, 'loss_2': 0.002620697021484375, 'loss_3': -16.461469650268555, 'loss_4': 1.5926331281661987, 'epoch': 19.55}
{'loss': 0.0143, 'grad_norm': 6.267215251922607, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.011258278973400593, 'loss_2': 0.00301361083984375, 'loss_3': -16.34663963317871, 'loss_4': 1.2171579599380493, 'epoch': 19.55}
{'loss': 0.0177, 'grad_norm': 4.551395893096924, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.005006388295441866, 'loss_2': 0.0126800537109375, 'loss_3': -16.163257598876953, 'loss_4': 1.858161211013794, 'epoch': 19.56}
{'loss': 0.0104, 'grad_norm': 4.940169334411621, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.006080469582229853, 'loss_2': 0.00431060791015625, 'loss_3': -16.365371704101562, 'loss_4': 1.2235229015350342, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 16:40:25,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:25,750 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:19<30:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:33,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016037816181778908, 'eval_runtime': 3.7934, 'eval_samples_per_second': 269.944, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010710175149142742, 'eval_loss_2': 0.00532764196395874, 'eval_loss_3': -18.155075073242188, 'eval_loss_4': 1.4472286701202393, 'epoch': 19.56}
{'loss': 0.0061, 'grad_norm': 4.539346218109131, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.005389412399381399, 'loss_2': 0.0006885528564453125, 'loss_3': -16.363994598388672, 'loss_4': 1.5173592567443848, 'epoch': 19.57}
{'loss': 0.0045, 'grad_norm': 4.657244682312012, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.003748281393200159, 'loss_2': 0.0007190704345703125, 'loss_3': -16.345321655273438, 'loss_4': 1.699782371520996, 'epoch': 19.58}
{'loss': 0.0101, 'grad_norm': 7.3403239250183105, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.006540979258716106, 'loss_2': 0.003570556640625, 'loss_3': -16.351688385009766, 'loss_4': 1.2574596405029297, 'epoch': 19.58}
{'loss': 0.0143, 'grad_norm': 4.588560104370117, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.005805011838674545, 'loss_2': 0.008544921875, 'loss_3': -16.37677764892578, 'loss_4': 1.8374656438827515, 'epoch': 19.59}
{'loss': 0.0117, 'grad_norm': 6.434093475341797, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.010687456466257572, 'loss_2': 0.0010004043579101562, 'loss_3': -16.27433967590332, 'loss_4': 1.7122085094451904, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 16:40:33,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:33,079 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:27<30:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:40,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014713466167449951, 'eval_runtime': 3.7969, 'eval_samples_per_second': 269.691, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.00962966587394476, 'eval_loss_2': 0.005083799362182617, 'eval_loss_3': -18.183565139770508, 'eval_loss_4': 1.3723629713058472, 'epoch': 19.59}
{'loss': 0.0139, 'grad_norm': 5.415806770324707, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.007256398908793926, 'loss_2': 0.006683349609375, 'loss_3': -16.186325073242188, 'loss_4': 1.4120044708251953, 'epoch': 19.6}
{'loss': 0.0109, 'grad_norm': 5.653754234313965, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.006185478996485472, 'loss_2': 0.00475311279296875, 'loss_3': -16.38589859008789, 'loss_4': 1.6206796169281006, 'epoch': 19.6}
{'loss': 0.0147, 'grad_norm': 7.826213836669922, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.0067101032473146915, 'loss_2': 0.0079803466796875, 'loss_3': -16.38636016845703, 'loss_4': 1.291830062866211, 'epoch': 19.61}
{'loss': 0.0106, 'grad_norm': 6.333383560180664, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.008092341013252735, 'loss_2': 0.0024967193603515625, 'loss_3': -16.571361541748047, 'loss_4': 1.238231897354126, 'epoch': 19.62}
{'loss': 0.0069, 'grad_norm': 4.7268781661987305, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.00431453064084053, 'loss_2': 0.002605438232421875, 'loss_3': -16.41763687133789, 'loss_4': 1.6307456493377686, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 16:40:40,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:40,418 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:34<30:41,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:40:47,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011995555832982063, 'eval_runtime': 3.7929, 'eval_samples_per_second': 269.975, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.009333767928183079, 'eval_loss_2': 0.00266178697347641, 'eval_loss_3': -18.18743133544922, 'eval_loss_4': 1.2525181770324707, 'epoch': 19.62}
{'loss': 0.008, 'grad_norm': 5.673176288604736, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.007992198690772057, 'loss_2': 3.445148468017578e-05, 'loss_3': -16.261661529541016, 'loss_4': 1.3796825408935547, 'epoch': 19.63}
{'loss': 0.0153, 'grad_norm': 5.004297256469727, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.007655752822756767, 'loss_2': 0.00763702392578125, 'loss_3': -16.23214340209961, 'loss_4': 1.489208698272705, 'epoch': 19.63}
{'loss': 0.0126, 'grad_norm': 4.888942241668701, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.008444841019809246, 'loss_2': 0.0041351318359375, 'loss_3': -16.305166244506836, 'loss_4': 1.3560338020324707, 'epoch': 19.64}
{'loss': 0.0335, 'grad_norm': 11.48672103881836, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.02897045575082302, 'loss_2': 0.00455474853515625, 'loss_3': -16.233177185058594, 'loss_4': 0.9883518218994141, 'epoch': 19.65}
{'loss': 0.0144, 'grad_norm': 6.112403392791748, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.011422784999012947, 'loss_2': 0.002948760986328125, 'loss_3': -16.20638084411621, 'loss_4': 1.2924888134002686, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 16:40:47,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:47,745 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:41<30:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:40:55,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012605943717062473, 'eval_runtime': 3.7939, 'eval_samples_per_second': 269.903, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010410287417471409, 'eval_loss_2': 0.0021956562995910645, 'eval_loss_3': -18.17357063293457, 'eval_loss_4': 1.1704870462417603, 'epoch': 19.65}
{'loss': 0.0078, 'grad_norm': 4.819320201873779, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.005317418370395899, 'loss_2': 0.00247955322265625, 'loss_3': -16.434219360351562, 'loss_4': 1.5042424201965332, 'epoch': 19.66}
{'loss': 0.0074, 'grad_norm': 4.857119560241699, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.007065189070999622, 'loss_2': 0.00034236907958984375, 'loss_3': -16.192209243774414, 'loss_4': 1.5810320377349854, 'epoch': 19.66}
{'loss': 0.0111, 'grad_norm': 6.007349491119385, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.009465119801461697, 'loss_2': 0.0016565322875976562, 'loss_3': -16.351810455322266, 'loss_4': 1.0552159547805786, 'epoch': 19.67}
{'loss': 0.0293, 'grad_norm': 8.13448429107666, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.025108229368925095, 'loss_2': 0.00420379638671875, 'loss_3': -16.447595596313477, 'loss_4': 0.7497506141662598, 'epoch': 19.67}
{'loss': 0.0124, 'grad_norm': 4.753951072692871, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.005625276826322079, 'loss_2': 0.00676727294921875, 'loss_3': -16.34444808959961, 'loss_4': 1.0984216928482056, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 16:40:55,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:40:55,079 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:49<30:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:02,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013187034986913204, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.528, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010729356668889523, 'eval_loss_2': 0.0024576783180236816, 'eval_loss_3': -18.150226593017578, 'eval_loss_4': 1.0152876377105713, 'epoch': 19.68}
{'loss': 0.0073, 'grad_norm': 4.817382335662842, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.006212067324668169, 'loss_2': 0.0010395050048828125, 'loss_3': -16.362478256225586, 'loss_4': 1.3850153684616089, 'epoch': 19.69}
{'loss': 0.0196, 'grad_norm': 10.410067558288574, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.01738874986767769, 'loss_2': 0.002197265625, 'loss_3': -16.281494140625, 'loss_4': 1.2741594314575195, 'epoch': 19.69}
{'loss': 0.0069, 'grad_norm': 5.054534912109375, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.005835577379912138, 'loss_2': 0.001110076904296875, 'loss_3': -16.361392974853516, 'loss_4': 1.2789311408996582, 'epoch': 19.7}
{'loss': 0.0112, 'grad_norm': 5.696906089782715, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.008877109736204147, 'loss_2': 0.002368927001953125, 'loss_3': -16.598175048828125, 'loss_4': 0.9099389314651489, 'epoch': 19.7}
{'loss': 0.0061, 'grad_norm': 4.544088363647461, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.004729762673377991, 'loss_2': 0.0013790130615234375, 'loss_3': -16.308950424194336, 'loss_4': 1.3220171928405762, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 16:41:02,416 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:02,417 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:23:56<30:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:09,751 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016206184402108192, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.835, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011434772051870823, 'eval_loss_2': 0.004771411418914795, 'eval_loss_3': -18.141963958740234, 'eval_loss_4': 0.9016867280006409, 'epoch': 19.71}
{'loss': 0.0222, 'grad_norm': 8.02071762084961, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.013031955808401108, 'loss_2': 0.00920867919921875, 'loss_3': -16.092124938964844, 'loss_4': 1.5483441352844238, 'epoch': 19.72}
{'loss': 0.0103, 'grad_norm': 4.5243964195251465, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.005081800743937492, 'loss_2': 0.005237579345703125, 'loss_3': -16.43863296508789, 'loss_4': 0.9729890823364258, 'epoch': 19.72}
{'loss': 0.023, 'grad_norm': 5.632789611816406, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.007679075468331575, 'loss_2': 0.01531982421875, 'loss_3': -16.350122451782227, 'loss_4': 1.0880482196807861, 'epoch': 19.73}
{'loss': 0.02, 'grad_norm': 7.465341091156006, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.019255513325333595, 'loss_2': 0.00078582763671875, 'loss_3': -16.204158782958984, 'loss_4': 1.3746860027313232, 'epoch': 19.73}
{'loss': 0.0101, 'grad_norm': 5.16194486618042, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.008251779712736607, 'loss_2': 0.0018720626831054688, 'loss_3': -16.324480056762695, 'loss_4': 1.0530247688293457, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 16:41:09,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:09,751 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:24:03<30:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:17,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01613028720021248, 'eval_runtime': 3.7949, 'eval_samples_per_second': 269.839, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012665036134421825, 'eval_loss_2': 0.0034652501344680786, 'eval_loss_3': -18.137847900390625, 'eval_loss_4': 0.8951380252838135, 'epoch': 19.74}
{'loss': 0.0149, 'grad_norm': 8.443151473999023, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.01490554679185152, 'loss_2': 1.5676021575927734e-05, 'loss_3': -16.53489875793457, 'loss_4': 0.6682754158973694, 'epoch': 19.74}
{'loss': 0.0187, 'grad_norm': 9.530195236206055, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.017110422253608704, 'loss_2': 0.0016021728515625, 'loss_3': -16.418806076049805, 'loss_4': 0.9473786950111389, 'epoch': 19.75}
{'loss': 0.0094, 'grad_norm': 6.517565727233887, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.006369342096149921, 'loss_2': 0.003063201904296875, 'loss_3': -16.271564483642578, 'loss_4': 1.4504764080047607, 'epoch': 19.76}
{'loss': 0.0096, 'grad_norm': 4.80372428894043, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.008126464672386646, 'loss_2': 0.001453399658203125, 'loss_3': -16.229286193847656, 'loss_4': 1.078230619430542, 'epoch': 19.76}
{'loss': 0.013, 'grad_norm': 7.131229877471924, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.008913048543035984, 'loss_2': 0.004058837890625, 'loss_3': -16.268417358398438, 'loss_4': 0.8569887280464172, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 16:41:17,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:17,090 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:24:11<30:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:24,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015793338418006897, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.818, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012796864844858646, 'eval_loss_2': 0.002996474504470825, 'eval_loss_3': -18.156343460083008, 'eval_loss_4': 0.9125537872314453, 'epoch': 19.77}
{'loss': 0.014, 'grad_norm': 6.478461742401123, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.009405992925167084, 'loss_2': 0.004638671875, 'loss_3': -16.287586212158203, 'loss_4': 0.8652542233467102, 'epoch': 19.77}
{'loss': 0.0089, 'grad_norm': 4.976830005645752, 'learning_rate': 1.025e-05, 'loss_1': 0.0036068412009626627, 'loss_2': 0.00533294677734375, 'loss_3': -16.154460906982422, 'loss_4': 0.7239437103271484, 'epoch': 19.78}
{'loss': 0.0229, 'grad_norm': 12.773454666137695, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.020474400371313095, 'loss_2': 0.002399444580078125, 'loss_3': -16.247560501098633, 'loss_4': 1.186577320098877, 'epoch': 19.78}
{'loss': 0.0096, 'grad_norm': 7.740080833435059, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.007138427346944809, 'loss_2': 0.002437591552734375, 'loss_3': -16.53801155090332, 'loss_4': 1.0541719198226929, 'epoch': 19.79}
{'loss': 0.0154, 'grad_norm': 7.007498264312744, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.01013905555009842, 'loss_2': 0.005283355712890625, 'loss_3': -16.355066299438477, 'loss_4': 0.6722677946090698, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 16:41:24,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:24,424 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:18<30:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:31,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01592973619699478, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.455, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012611158192157745, 'eval_loss_2': 0.003318578004837036, 'eval_loss_3': -18.147024154663086, 'eval_loss_4': 0.8504793047904968, 'epoch': 19.8}
{'loss': 0.0084, 'grad_norm': 5.593585968017578, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.007350386120378971, 'loss_2': 0.0010852813720703125, 'loss_3': -16.257213592529297, 'loss_4': 1.2670478820800781, 'epoch': 19.8}
{'loss': 0.0126, 'grad_norm': 4.844486236572266, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.004435146227478981, 'loss_2': 0.008209228515625, 'loss_3': -16.365903854370117, 'loss_4': 0.9025460481643677, 'epoch': 19.81}
{'loss': 0.0107, 'grad_norm': 5.292680263519287, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.004514901898801327, 'loss_2': 0.006145477294921875, 'loss_3': -16.588394165039062, 'loss_4': 0.6696983575820923, 'epoch': 19.81}
{'loss': 0.0154, 'grad_norm': 4.505302906036377, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.006639113184064627, 'loss_2': 0.0088043212890625, 'loss_3': -16.20411491394043, 'loss_4': 0.7294337749481201, 'epoch': 19.82}
{'loss': 0.0222, 'grad_norm': 51.53122329711914, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.014783683232963085, 'loss_2': 0.007381439208984375, 'loss_3': -16.285297393798828, 'loss_4': 0.8386400938034058, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 16:41:31,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:31,768 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:25<30:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:39,104 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015681583434343338, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.56, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012300658971071243, 'eval_loss_2': 0.0033809244632720947, 'eval_loss_3': -18.164934158325195, 'eval_loss_4': 0.8134039044380188, 'epoch': 19.83}
{'loss': 0.0153, 'grad_norm': 6.25870418548584, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.009057543240487576, 'loss_2': 0.00628662109375, 'loss_3': -16.081157684326172, 'loss_4': 0.8856996893882751, 'epoch': 19.83}
{'loss': 0.0082, 'grad_norm': 4.476653575897217, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.002802629955112934, 'loss_2': 0.00542449951171875, 'loss_3': -16.44487190246582, 'loss_4': 0.8852800130844116, 'epoch': 19.84}
{'loss': 0.0084, 'grad_norm': 4.444308757781982, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.005229600705206394, 'loss_2': 0.0031299591064453125, 'loss_3': -16.668912887573242, 'loss_4': 1.0408169031143188, 'epoch': 19.84}
{'loss': 0.0067, 'grad_norm': 5.418996810913086, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.006227406673133373, 'loss_2': 0.0004730224609375, 'loss_3': -16.411090850830078, 'loss_4': 0.7703880071640015, 'epoch': 19.85}
{'loss': 0.01, 'grad_norm': 4.523748874664307, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.0027333975303918123, 'loss_2': 0.00731658935546875, 'loss_3': -16.425315856933594, 'loss_4': 0.6881933212280273, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 16:41:39,104 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:39,104 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:33<30:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:46,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016152221709489822, 'eval_runtime': 3.7928, 'eval_samples_per_second': 269.983, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.013219702988862991, 'eval_loss_2': 0.002932518720626831, 'eval_loss_3': -18.154951095581055, 'eval_loss_4': 0.8242689967155457, 'epoch': 19.85}
{'loss': 0.0154, 'grad_norm': 5.840828895568848, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.014481930993497372, 'loss_2': 0.0009188652038574219, 'loss_3': -16.244869232177734, 'loss_4': 0.903864860534668, 'epoch': 19.86}
{'loss': 0.0121, 'grad_norm': 10.883139610290527, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.011815909296274185, 'loss_2': 0.0003218650817871094, 'loss_3': -16.275287628173828, 'loss_4': 0.7727158069610596, 'epoch': 19.87}
{'loss': 0.0106, 'grad_norm': 5.005714416503906, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.007206834852695465, 'loss_2': 0.00341796875, 'loss_3': -16.427013397216797, 'loss_4': 0.6743348240852356, 'epoch': 19.87}
{'loss': 0.0053, 'grad_norm': 4.540049076080322, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.004953464958816767, 'loss_2': 0.00039505958557128906, 'loss_3': -16.384380340576172, 'loss_4': 1.3185220956802368, 'epoch': 19.88}
{'loss': 0.0127, 'grad_norm': 4.634219646453857, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.006814529187977314, 'loss_2': 0.0058746337890625, 'loss_3': -16.407733917236328, 'loss_4': 0.7298740744590759, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 16:41:46,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:46,437 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:40<29:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:41:53,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01750100404024124, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.924, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.013825572095811367, 'eval_loss_2': 0.0036754310131073, 'eval_loss_3': -18.153898239135742, 'eval_loss_4': 0.8473533987998962, 'epoch': 19.88}
{'loss': 0.0065, 'grad_norm': 5.127563953399658, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.00490872235968709, 'loss_2': 0.0016117095947265625, 'loss_3': -16.486047744750977, 'loss_4': 0.9262152314186096, 'epoch': 19.89}
{'loss': 0.0126, 'grad_norm': 4.600344181060791, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.005340230651199818, 'loss_2': 0.007305145263671875, 'loss_3': -16.329627990722656, 'loss_4': 0.9659379124641418, 'epoch': 19.9}
{'loss': 0.0158, 'grad_norm': 7.8947014808654785, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.014167746528983116, 'loss_2': 0.0015926361083984375, 'loss_3': -16.392974853515625, 'loss_4': 0.585810124874115, 'epoch': 19.9}
{'loss': 0.0086, 'grad_norm': 4.977474212646484, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.0051970710046589375, 'loss_2': 0.003421783447265625, 'loss_3': -16.44388771057129, 'loss_4': 0.3473625183105469, 'epoch': 19.91}
{'loss': 0.007, 'grad_norm': 4.876245498657227, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.004807326477020979, 'loss_2': 0.0022182464599609375, 'loss_3': -16.3707218170166, 'loss_4': 0.6332417726516724, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 16:41:53,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:41:53,766 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:47<29:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:01,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018781594932079315, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.818, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.015826327726244926, 'eval_loss_2': 0.0029552653431892395, 'eval_loss_3': -18.1466064453125, 'eval_loss_4': 0.7743301391601562, 'epoch': 19.91}
{'loss': 0.0118, 'grad_norm': 4.845231056213379, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.007517393212765455, 'loss_2': 0.004291534423828125, 'loss_3': -16.29537010192871, 'loss_4': 0.7139183282852173, 'epoch': 19.92}
{'loss': 0.0224, 'grad_norm': 10.272636413574219, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.014252069406211376, 'loss_2': 0.00811767578125, 'loss_3': -16.337364196777344, 'loss_4': 0.6618119478225708, 'epoch': 19.92}
{'loss': 0.0093, 'grad_norm': 5.321125507354736, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.006844605319201946, 'loss_2': 0.0024356842041015625, 'loss_3': -16.221553802490234, 'loss_4': 1.0301861763000488, 'epoch': 19.93}
{'loss': 0.0169, 'grad_norm': 5.579983234405518, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.011676638387143612, 'loss_2': 0.00527191162109375, 'loss_3': -16.31039810180664, 'loss_4': 0.6881542205810547, 'epoch': 19.94}
{'loss': 0.008, 'grad_norm': 5.205172538757324, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.006892610806971788, 'loss_2': 0.001064300537109375, 'loss_3': -16.53411865234375, 'loss_4': 1.0230965614318848, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 16:42:01,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:01,096 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:24:55<29:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:08,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01887635886669159, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.888, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01641242206096649, 'eval_loss_2': 0.0024639368057250977, 'eval_loss_3': -18.144243240356445, 'eval_loss_4': 0.718719482421875, 'epoch': 19.94}
{'loss': 0.0119, 'grad_norm': 6.018463611602783, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.011023730970919132, 'loss_2': 0.0008707046508789062, 'loss_3': -16.232650756835938, 'loss_4': 0.7486567497253418, 'epoch': 19.95}
{'loss': 0.0148, 'grad_norm': 5.82997465133667, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.010537784546613693, 'loss_2': 0.004302978515625, 'loss_3': -16.366943359375, 'loss_4': 1.105809211730957, 'epoch': 19.95}
{'loss': 0.0241, 'grad_norm': 9.336199760437012, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.021501872688531876, 'loss_2': 0.002593994140625, 'loss_3': -16.226619720458984, 'loss_4': 0.71239173412323, 'epoch': 19.96}
{'loss': 0.0125, 'grad_norm': 10.238873481750488, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.01175820641219616, 'loss_2': 0.0007696151733398438, 'loss_3': -16.28156089782715, 'loss_4': 0.7578850388526917, 'epoch': 19.97}
{'loss': 0.0718, 'grad_norm': 24.00511932373047, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.06325259804725647, 'loss_2': 0.00852203369140625, 'loss_3': -16.356910705566406, 'loss_4': 0.6277689337730408, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 16:42:08,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:08,425 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:25:02<27:07,  1.06it/s][INFO|trainer.py:4226] 2025-01-21 16:42:15,609 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01926650106906891, 'eval_runtime': 3.9977, 'eval_samples_per_second': 256.145, 'eval_steps_per_second': 4.002, 'eval_loss_1': 0.016699954867362976, 'eval_loss_2': 0.0025665462017059326, 'eval_loss_3': -18.13669204711914, 'eval_loss_4': 0.6840077042579651, 'epoch': 19.97}
{'loss': 0.0077, 'grad_norm': 4.609928607940674, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.005477949511259794, 'loss_2': 0.002231597900390625, 'loss_3': -16.307769775390625, 'loss_4': 0.6248053312301636, 'epoch': 19.98}
{'loss': 0.0112, 'grad_norm': 5.005200386047363, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.008435036987066269, 'loss_2': 0.002742767333984375, 'loss_3': -16.45537757873535, 'loss_4': 0.9014331102371216, 'epoch': 19.98}
{'loss': 0.0174, 'grad_norm': 6.446334362030029, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.014724252745509148, 'loss_2': 0.002716064453125, 'loss_3': -16.11095428466797, 'loss_4': 0.4846033453941345, 'epoch': 19.99}
{'loss': 0.0115, 'grad_norm': 5.590104579925537, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.009183886460959911, 'loss_2': 0.002277374267578125, 'loss_3': -16.35924530029297, 'loss_4': 0.5369970798492432, 'epoch': 19.99}
{'loss': 0.0056, 'grad_norm': 6.143229007720947, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.003522805869579315, 'loss_2': 0.0021114349365234375, 'loss_3': -16.390974044799805, 'loss_4': 0.5604429841041565, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 16:42:15,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:15,609 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:25:09<29:15,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:42:22,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018511073663830757, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.127, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01567651331424713, 'eval_loss_2': 0.0028345584869384766, 'eval_loss_3': -18.15864372253418, 'eval_loss_4': 0.5073392987251282, 'epoch': 20.0}
{'loss': 0.0108, 'grad_norm': 4.971993446350098, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.005786811467260122, 'loss_2': 0.00498199462890625, 'loss_3': -16.373390197753906, 'loss_4': 0.4439411759376526, 'epoch': 20.01}
{'loss': 0.0125, 'grad_norm': 6.124622344970703, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.006041473243385553, 'loss_2': 0.006439208984375, 'loss_3': -16.407054901123047, 'loss_4': 0.3205506205558777, 'epoch': 20.01}
{'loss': 0.0056, 'grad_norm': 4.0973687171936035, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.003151687327772379, 'loss_2': 0.0024662017822265625, 'loss_3': -16.49622344970703, 'loss_4': 0.4176991581916809, 'epoch': 20.02}
{'loss': 0.0084, 'grad_norm': 5.598620414733887, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.008231514133512974, 'loss_2': 0.00020694732666015625, 'loss_3': -16.349285125732422, 'loss_4': 0.4783397912979126, 'epoch': 20.02}
{'loss': 0.0139, 'grad_norm': 6.361503601074219, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.011131981387734413, 'loss_2': 0.0027980804443359375, 'loss_3': -16.369443893432617, 'loss_4': 0.259053498506546, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 16:42:22,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:22,987 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:25:16<29:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:42:30,326 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01738208532333374, 'eval_runtime': 3.8002, 'eval_samples_per_second': 269.458, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.01357781607657671, 'eval_loss_2': 0.003804270178079605, 'eval_loss_3': -18.15923500061035, 'eval_loss_4': 0.3254857361316681, 'epoch': 20.03}
{'loss': 0.0222, 'grad_norm': 6.979415416717529, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.015587225556373596, 'loss_2': 0.00656890869140625, 'loss_3': -16.48110008239746, 'loss_4': 0.22967097163200378, 'epoch': 20.03}
{'loss': 0.0122, 'grad_norm': 4.861419677734375, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.007631924003362656, 'loss_2': 0.00460052490234375, 'loss_3': -16.271060943603516, 'loss_4': 0.31377270817756653, 'epoch': 20.04}
{'loss': 0.0092, 'grad_norm': 5.495913505554199, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.005368481390178204, 'loss_2': 0.003841400146484375, 'loss_3': -16.35413360595703, 'loss_4': 0.4081937074661255, 'epoch': 20.05}
{'loss': 0.0111, 'grad_norm': 4.572497844696045, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.0060835350304841995, 'loss_2': 0.0050201416015625, 'loss_3': -16.39406394958496, 'loss_4': 0.6373084783554077, 'epoch': 20.05}
{'loss': 0.0089, 'grad_norm': 4.857769012451172, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.004384529776871204, 'loss_2': 0.00450897216796875, 'loss_3': -16.38072395324707, 'loss_4': 0.20176666975021362, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 16:42:30,326 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:30,327 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:24<29:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:37,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01599702052772045, 'eval_runtime': 3.7974, 'eval_samples_per_second': 269.661, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012609807774424553, 'eval_loss_2': 0.0033872127532958984, 'eval_loss_3': -18.151817321777344, 'eval_loss_4': 0.14506079256534576, 'epoch': 20.06}
{'loss': 0.009, 'grad_norm': 4.799233913421631, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.0057541122660040855, 'loss_2': 0.0032024383544921875, 'loss_3': -16.436880111694336, 'loss_4': -0.04441987723112106, 'epoch': 20.06}
{'loss': 0.0099, 'grad_norm': 4.283331394195557, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.003144504502415657, 'loss_2': 0.00679779052734375, 'loss_3': -16.35088348388672, 'loss_4': -0.00181647390127182, 'epoch': 20.07}
{'loss': 0.011, 'grad_norm': 4.797698974609375, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.0068940226919949055, 'loss_2': 0.004150390625, 'loss_3': -16.3601131439209, 'loss_4': 0.12740512192249298, 'epoch': 20.08}
{'loss': 0.0124, 'grad_norm': 5.408898830413818, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.008535326458513737, 'loss_2': 0.0038928985595703125, 'loss_3': -16.537872314453125, 'loss_4': -0.0049130916595458984, 'epoch': 20.08}
{'loss': 0.0069, 'grad_norm': 5.107054233551025, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.00573508208617568, 'loss_2': 0.001171112060546875, 'loss_3': -16.37762451171875, 'loss_4': -0.14835834503173828, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 16:42:37,658 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:37,658 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:31<29:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:44,992 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014971571043133736, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.562, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012176173739135265, 'eval_loss_2': 0.002795398235321045, 'eval_loss_3': -18.148771286010742, 'eval_loss_4': 0.01129576750099659, 'epoch': 20.09}
{'loss': 0.0241, 'grad_norm': 9.06195068359375, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.01959848403930664, 'loss_2': 0.00447845458984375, 'loss_3': -16.593772888183594, 'loss_4': 0.1373915672302246, 'epoch': 20.09}
{'loss': 0.0923, 'grad_norm': 15.493926048278809, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.08534687757492065, 'loss_2': 0.006946563720703125, 'loss_3': -16.221099853515625, 'loss_4': 0.7995288968086243, 'epoch': 20.1}
{'loss': 0.0085, 'grad_norm': 5.731196403503418, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.008429591543972492, 'loss_2': 2.5391578674316406e-05, 'loss_3': -16.449352264404297, 'loss_4': 0.04393799602985382, 'epoch': 20.1}
{'loss': 0.0071, 'grad_norm': 4.8551106452941895, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.00396589282900095, 'loss_2': 0.003143310546875, 'loss_3': -16.160266876220703, 'loss_4': -0.1753121167421341, 'epoch': 20.11}
{'loss': 0.0131, 'grad_norm': 5.061346054077148, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.006199524272233248, 'loss_2': 0.0068817138671875, 'loss_3': -16.35003662109375, 'loss_4': 0.2289474457502365, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 16:42:44,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:44,993 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:38<29:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:52,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01615104265511036, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.806, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.012793006375432014, 'eval_loss_2': 0.0033580362796783447, 'eval_loss_3': -18.169891357421875, 'eval_loss_4': -0.10512682795524597, 'epoch': 20.12}
{'loss': 0.0078, 'grad_norm': 4.65143346786499, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.003922001458704472, 'loss_2': 0.0038394927978515625, 'loss_3': -16.54057502746582, 'loss_4': 0.1103687435388565, 'epoch': 20.12}
{'loss': 0.0178, 'grad_norm': 5.670764446258545, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.011245088651776314, 'loss_2': 0.006603240966796875, 'loss_3': -16.29702377319336, 'loss_4': -0.1566351056098938, 'epoch': 20.13}
{'loss': 0.0105, 'grad_norm': 5.324522018432617, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.009418242610991001, 'loss_2': 0.0011272430419921875, 'loss_3': -16.205673217773438, 'loss_4': -0.13425830006599426, 'epoch': 20.13}
{'loss': 0.0126, 'grad_norm': 6.934939861297607, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.012235158123075962, 'loss_2': 0.00034999847412109375, 'loss_3': -16.23781394958496, 'loss_4': -0.028791721910238266, 'epoch': 20.14}
{'loss': 0.0183, 'grad_norm': 7.5695366859436035, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.01604345627129078, 'loss_2': 0.00226593017578125, 'loss_3': -16.27007484436035, 'loss_4': 0.15337198972702026, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 16:42:52,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:52,321 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:46<29:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:42:59,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014946596696972847, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012310290709137917, 'eval_loss_2': 0.0026363059878349304, 'eval_loss_3': -18.159038543701172, 'eval_loss_4': -0.11403503268957138, 'epoch': 20.15}
{'loss': 0.009, 'grad_norm': 4.177929878234863, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.0034160620998591185, 'loss_2': 0.0056304931640625, 'loss_3': -16.576313018798828, 'loss_4': -0.49459320306777954, 'epoch': 20.15}
{'loss': 0.007, 'grad_norm': 5.307131767272949, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.006094856187701225, 'loss_2': 0.0008802413940429688, 'loss_3': -16.451366424560547, 'loss_4': -0.20701777935028076, 'epoch': 20.16}
{'loss': 0.0077, 'grad_norm': 4.5715718269348145, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.0030274526216089725, 'loss_2': 0.00467681884765625, 'loss_3': -16.510711669921875, 'loss_4': 0.04268017038702965, 'epoch': 20.16}
{'loss': 0.012, 'grad_norm': 5.634387016296387, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.010080146603286266, 'loss_2': 0.001941680908203125, 'loss_3': -16.27542495727539, 'loss_4': -0.16387346386909485, 'epoch': 20.17}
{'loss': 0.0153, 'grad_norm': 8.03658676147461, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.011438777670264244, 'loss_2': 0.0038471221923828125, 'loss_3': -16.23876953125, 'loss_4': -0.5509130954742432, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 16:42:59,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:42:59,662 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:25:53<29:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:07,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014925885945558548, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.43, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011653382331132889, 'eval_loss_2': 0.003272503614425659, 'eval_loss_3': -18.17085838317871, 'eval_loss_4': -0.09543521702289581, 'epoch': 20.17}
{'loss': 0.0248, 'grad_norm': 9.298843383789062, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.018367204815149307, 'loss_2': 0.00641632080078125, 'loss_3': -16.5527400970459, 'loss_4': 0.27401676774024963, 'epoch': 20.18}
{'loss': 0.0065, 'grad_norm': 6.110147476196289, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.005588635336607695, 'loss_2': 0.0009484291076660156, 'loss_3': -16.54789161682129, 'loss_4': -0.18642368912696838, 'epoch': 20.19}
{'loss': 0.0279, 'grad_norm': 8.611310005187988, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.020229943096637726, 'loss_2': 0.00766754150390625, 'loss_3': -16.318193435668945, 'loss_4': 0.10294651985168457, 'epoch': 20.19}
{'loss': 0.0347, 'grad_norm': 21.84109115600586, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.03110191784799099, 'loss_2': 0.003559112548828125, 'loss_3': -16.261083602905273, 'loss_4': -0.18279403448104858, 'epoch': 20.2}
{'loss': 0.0077, 'grad_norm': 4.52125358581543, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.004257249645888805, 'loss_2': 0.003444671630859375, 'loss_3': -16.635540008544922, 'loss_4': 0.5857025980949402, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 16:43:07,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:07,009 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:26:00<29:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:14,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015714529901742935, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.546, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010943891480565071, 'eval_loss_2': 0.004770636558532715, 'eval_loss_3': -18.178882598876953, 'eval_loss_4': 0.04445790871977806, 'epoch': 20.2}
{'loss': 0.0164, 'grad_norm': 5.860927104949951, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.008026649244129658, 'loss_2': 0.008331298828125, 'loss_3': -16.294315338134766, 'loss_4': -0.03221255540847778, 'epoch': 20.21}
{'loss': 0.0096, 'grad_norm': 4.9963860511779785, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.007107940036803484, 'loss_2': 0.002521514892578125, 'loss_3': -16.469139099121094, 'loss_4': 0.21180161833763123, 'epoch': 20.22}
{'loss': 0.0227, 'grad_norm': 12.509145736694336, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.02058882638812065, 'loss_2': 0.00209808349609375, 'loss_3': -16.496543884277344, 'loss_4': 0.30862462520599365, 'epoch': 20.22}
{'loss': 0.0065, 'grad_norm': 5.123810768127441, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.005768585950136185, 'loss_2': 0.0007290840148925781, 'loss_3': -16.20482635498047, 'loss_4': -0.11482711136341095, 'epoch': 20.23}
{'loss': 0.008, 'grad_norm': 4.492644786834717, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.0029621021822094917, 'loss_2': 0.00505828857421875, 'loss_3': -16.348955154418945, 'loss_4': 0.7718393206596375, 'epoch': 20.23}
[INFO|trainer.py:4228] 2025-01-21 16:43:14,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:14,349 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:26:08<28:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:21,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013146493583917618, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010580379515886307, 'eval_loss_2': 0.002566114068031311, 'eval_loss_3': -18.184486389160156, 'eval_loss_4': 0.34232020378112793, 'epoch': 20.23}
{'loss': 0.0328, 'grad_norm': 13.459896087646484, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.029455136507749557, 'loss_2': 0.0033130645751953125, 'loss_3': -16.2679443359375, 'loss_4': 0.4460158944129944, 'epoch': 20.24}
{'loss': 0.0105, 'grad_norm': 7.076852798461914, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.009273843839764595, 'loss_2': 0.0012111663818359375, 'loss_3': -16.27627182006836, 'loss_4': 0.5815263390541077, 'epoch': 20.24}
{'loss': 0.0065, 'grad_norm': 4.865021705627441, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.004144588485360146, 'loss_2': 0.0023784637451171875, 'loss_3': -16.391742706298828, 'loss_4': 0.6574862003326416, 'epoch': 20.25}
{'loss': 0.0089, 'grad_norm': 5.108882904052734, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.006849245633929968, 'loss_2': 0.002017974853515625, 'loss_3': -16.28832244873047, 'loss_4': 0.1200517788529396, 'epoch': 20.26}
{'loss': 0.0165, 'grad_norm': 10.231022834777832, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.013135560788214207, 'loss_2': 0.003368377685546875, 'loss_3': -16.620365142822266, 'loss_4': 0.6000899076461792, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 16:43:21,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:21,691 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:26:15<28:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:29,028 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012812310829758644, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.676, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010224706493318081, 'eval_loss_2': 0.002587605267763138, 'eval_loss_3': -18.186386108398438, 'eval_loss_4': 0.40036144852638245, 'epoch': 20.26}
{'loss': 0.0105, 'grad_norm': 4.540126800537109, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.006118420977145433, 'loss_2': 0.00434112548828125, 'loss_3': -16.157255172729492, 'loss_4': 0.3794061839580536, 'epoch': 20.27}
{'loss': 0.016, 'grad_norm': 9.68086051940918, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.015024066902697086, 'loss_2': 0.000995635986328125, 'loss_3': -16.23595428466797, 'loss_4': 0.018498748540878296, 'epoch': 20.27}
{'loss': 0.0075, 'grad_norm': 5.253695487976074, 'learning_rate': 9.75e-06, 'loss_1': 0.006159981247037649, 'loss_2': 0.0013036727905273438, 'loss_3': -16.35085678100586, 'loss_4': 0.3963603079319, 'epoch': 20.28}
{'loss': 0.0085, 'grad_norm': 4.653958320617676, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.005462216213345528, 'loss_2': 0.00305938720703125, 'loss_3': -16.167024612426758, 'loss_4': 0.45883622765541077, 'epoch': 20.28}
{'loss': 0.012, 'grad_norm': 5.182960033416748, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.007167459465563297, 'loss_2': 0.004833221435546875, 'loss_3': -16.335262298583984, 'loss_4': 0.4561094641685486, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 16:43:29,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:29,028 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:22<28:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:36,376 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013055462390184402, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.25, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009969476610422134, 'eval_loss_2': 0.003085985779762268, 'eval_loss_3': -18.176162719726562, 'eval_loss_4': 0.2474527806043625, 'epoch': 20.29}
{'loss': 0.0115, 'grad_norm': 4.799829006195068, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.0069037266075611115, 'loss_2': 0.00458526611328125, 'loss_3': -16.27432632446289, 'loss_4': -0.03507019206881523, 'epoch': 20.3}
{'loss': 0.0171, 'grad_norm': 6.316742420196533, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.013664638623595238, 'loss_2': 0.0034008026123046875, 'loss_3': -16.434528350830078, 'loss_4': -0.033479928970336914, 'epoch': 20.3}
{'loss': 0.0106, 'grad_norm': 4.678004264831543, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.0033754112664610147, 'loss_2': 0.00725555419921875, 'loss_3': -16.555919647216797, 'loss_4': 0.2204589992761612, 'epoch': 20.31}
{'loss': 0.0106, 'grad_norm': 5.032435417175293, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.009183741174638271, 'loss_2': 0.0013904571533203125, 'loss_3': -16.366453170776367, 'loss_4': 0.34788012504577637, 'epoch': 20.31}
{'loss': 0.0058, 'grad_norm': 4.314275741577148, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.0026391209103167057, 'loss_2': 0.00319671630859375, 'loss_3': -16.436382293701172, 'loss_4': 0.46150532364845276, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 16:43:36,376 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:36,376 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:30<28:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:43,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014246240258216858, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011129126884043217, 'eval_loss_2': 0.003117114305496216, 'eval_loss_3': -18.16712188720703, 'eval_loss_4': 0.21970628201961517, 'epoch': 20.32}
{'loss': 0.0164, 'grad_norm': 6.228508472442627, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.012844512239098549, 'loss_2': 0.003597259521484375, 'loss_3': -16.48373794555664, 'loss_4': 0.022351980209350586, 'epoch': 20.33}
{'loss': 0.005, 'grad_norm': 5.104055404663086, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.003959584049880505, 'loss_2': 0.001068115234375, 'loss_3': -16.30591583251953, 'loss_4': 0.08180052042007446, 'epoch': 20.33}
{'loss': 0.0172, 'grad_norm': 10.45667552947998, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.015897691249847412, 'loss_2': 0.00130462646484375, 'loss_3': -16.45819091796875, 'loss_4': -0.03074955940246582, 'epoch': 20.34}
{'loss': 0.0141, 'grad_norm': 5.79840612411499, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.008439161814749241, 'loss_2': 0.00565338134765625, 'loss_3': -16.36285400390625, 'loss_4': 0.5092353224754333, 'epoch': 20.34}
{'loss': 0.0136, 'grad_norm': 4.5352654457092285, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.0054920571856200695, 'loss_2': 0.00806427001953125, 'loss_3': -16.22303009033203, 'loss_4': -0.32692959904670715, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 16:43:43,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:43,717 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:37<28:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:51,056 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015207771211862564, 'eval_runtime': 3.7989, 'eval_samples_per_second': 269.549, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012559418566524982, 'eval_loss_2': 0.0026483535766601562, 'eval_loss_3': -18.146900177001953, 'eval_loss_4': 0.1203957349061966, 'epoch': 20.35}
{'loss': 0.0213, 'grad_norm': 5.684110641479492, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.01386233326047659, 'loss_2': 0.00748443603515625, 'loss_3': -16.473896026611328, 'loss_4': 0.031435996294021606, 'epoch': 20.35}
{'loss': 0.0162, 'grad_norm': 6.75131893157959, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.015337327495217323, 'loss_2': 0.0008249282836914062, 'loss_3': -16.333438873291016, 'loss_4': -0.07433046400547028, 'epoch': 20.36}
{'loss': 0.0048, 'grad_norm': 4.88670015335083, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.0038850069977343082, 'loss_2': 0.0009622573852539062, 'loss_3': -16.47678565979004, 'loss_4': 0.19259919226169586, 'epoch': 20.37}
{'loss': 0.0091, 'grad_norm': 6.324645042419434, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.007017279975116253, 'loss_2': 0.002040863037109375, 'loss_3': -16.355640411376953, 'loss_4': 0.14033780992031097, 'epoch': 20.37}
{'loss': 0.0162, 'grad_norm': 5.661978721618652, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.009839195758104324, 'loss_2': 0.006336212158203125, 'loss_3': -16.445514678955078, 'loss_4': -0.33940041065216064, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 16:43:51,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:51,057 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:44<28:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:43:58,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016160547733306885, 'eval_runtime': 3.7968, 'eval_samples_per_second': 269.702, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.013096727430820465, 'eval_loss_2': 0.0030638203024864197, 'eval_loss_3': -18.1342716217041, 'eval_loss_4': -0.006577261723577976, 'epoch': 20.38}
{'loss': 0.0083, 'grad_norm': 5.018804550170898, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.0057991305366158485, 'loss_2': 0.0024852752685546875, 'loss_3': -16.249908447265625, 'loss_4': -0.11249452084302902, 'epoch': 20.38}
{'loss': 0.0114, 'grad_norm': 5.237276554107666, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.00465083634480834, 'loss_2': 0.00679779052734375, 'loss_3': -16.467580795288086, 'loss_4': -0.47613316774368286, 'epoch': 20.39}
{'loss': 0.0089, 'grad_norm': 4.983276844024658, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.005488413851708174, 'loss_2': 0.003414154052734375, 'loss_3': -16.476890563964844, 'loss_4': 0.3397306799888611, 'epoch': 20.4}
{'loss': 0.0084, 'grad_norm': 5.214142799377441, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.005896325223147869, 'loss_2': 0.00249481201171875, 'loss_3': -16.16098976135254, 'loss_4': 0.2530175745487213, 'epoch': 20.4}
{'loss': 0.0106, 'grad_norm': 5.414684295654297, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.004295336082577705, 'loss_2': 0.00627899169921875, 'loss_3': -16.570999145507812, 'loss_4': 0.30230849981307983, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 16:43:58,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:43:58,390 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:26:52<28:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:05,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014799963682889938, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.477, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011803487315773964, 'eval_loss_2': 0.002996474504470825, 'eval_loss_3': -18.140207290649414, 'eval_loss_4': -0.038699205964803696, 'epoch': 20.41}
{'loss': 0.0092, 'grad_norm': 5.018436431884766, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.005000935401767492, 'loss_2': 0.004150390625, 'loss_3': -16.28238296508789, 'loss_4': 0.04663090407848358, 'epoch': 20.41}
{'loss': 0.008, 'grad_norm': 5.560445785522461, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.007226737681776285, 'loss_2': 0.0007829666137695312, 'loss_3': -16.327617645263672, 'loss_4': -0.3634129762649536, 'epoch': 20.42}
{'loss': 0.0049, 'grad_norm': 4.935901641845703, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.0040946840308606625, 'loss_2': 0.000797271728515625, 'loss_3': -16.37533950805664, 'loss_4': -0.3180059492588043, 'epoch': 20.42}
{'loss': 0.0086, 'grad_norm': 4.973495006561279, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.0042583998292684555, 'loss_2': 0.0043792724609375, 'loss_3': -16.369556427001953, 'loss_4': 0.23318105936050415, 'epoch': 20.43}
{'loss': 0.0141, 'grad_norm': 7.555858612060547, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.012316941283643246, 'loss_2': 0.0018100738525390625, 'loss_3': -16.35483169555664, 'loss_4': -0.19516046345233917, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 16:44:05,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:05,726 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:26:59<28:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:13,071 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015590250492095947, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012017040513455868, 'eval_loss_2': 0.003573209047317505, 'eval_loss_3': -18.141849517822266, 'eval_loss_4': -0.019297728314995766, 'epoch': 20.44}
{'loss': 0.0108, 'grad_norm': 5.377218723297119, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.00897209532558918, 'loss_2': 0.00182342529296875, 'loss_3': -16.426212310791016, 'loss_4': 0.23155146837234497, 'epoch': 20.44}
{'loss': 0.0096, 'grad_norm': 5.670273303985596, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.0076865386217832565, 'loss_2': 0.0019054412841796875, 'loss_3': -16.439237594604492, 'loss_4': -0.460030198097229, 'epoch': 20.45}
{'loss': 0.0057, 'grad_norm': 5.071657180786133, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.0034561704378575087, 'loss_2': 0.002227783203125, 'loss_3': -16.50578498840332, 'loss_4': 0.2653452157974243, 'epoch': 20.45}
{'loss': 0.0108, 'grad_norm': 5.692258358001709, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.010297195054590702, 'loss_2': 0.0005002021789550781, 'loss_3': -16.629804611206055, 'loss_4': -0.2405252754688263, 'epoch': 20.46}
{'loss': 0.0109, 'grad_norm': 6.681768417358398, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.01022429671138525, 'loss_2': 0.000713348388671875, 'loss_3': -16.454261779785156, 'loss_4': -0.2373788207769394, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 16:44:13,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:13,072 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:27:07<28:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:20,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0157258752733469, 'eval_runtime': 3.7988, 'eval_samples_per_second': 269.559, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.012442434206604958, 'eval_loss_2': 0.0032834410667419434, 'eval_loss_3': -18.15386962890625, 'eval_loss_4': 0.05302656069397926, 'epoch': 20.47}
{'loss': 0.0113, 'grad_norm': 6.729926109313965, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.009706034325063229, 'loss_2': 0.00154876708984375, 'loss_3': -16.187664031982422, 'loss_4': 0.6669963598251343, 'epoch': 20.47}
{'loss': 0.0109, 'grad_norm': 4.992568016052246, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.00851011835038662, 'loss_2': 0.00235748291015625, 'loss_3': -16.337261199951172, 'loss_4': 0.3786379098892212, 'epoch': 20.48}
{'loss': 0.068, 'grad_norm': 12.454773902893066, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.06672675907611847, 'loss_2': 0.0012683868408203125, 'loss_3': -16.21883773803711, 'loss_4': 0.46235114336013794, 'epoch': 20.48}
{'loss': 0.0092, 'grad_norm': 5.175014495849609, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.006699942518025637, 'loss_2': 0.002468109130859375, 'loss_3': -16.192340850830078, 'loss_4': 0.18398816883563995, 'epoch': 20.49}
{'loss': 0.0201, 'grad_norm': 5.677854537963867, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.013118808157742023, 'loss_2': 0.00698089599609375, 'loss_3': -16.330860137939453, 'loss_4': 0.5232044458389282, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 16:44:20,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:20,409 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:27:14<28:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:27,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017806272953748703, 'eval_runtime': 3.7999, 'eval_samples_per_second': 269.482, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.0118510527536273, 'eval_loss_2': 0.005955219268798828, 'eval_loss_3': -18.156740188598633, 'eval_loss_4': 0.12849943339824677, 'epoch': 20.49}
{'loss': 0.0212, 'grad_norm': 5.404072284698486, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.008860296569764614, 'loss_2': 0.0123748779296875, 'loss_3': -16.3089599609375, 'loss_4': 0.24419738352298737, 'epoch': 20.5}
{'loss': 0.014, 'grad_norm': 5.2956414222717285, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.005453410558402538, 'loss_2': 0.008544921875, 'loss_3': -16.353275299072266, 'loss_4': -0.23405101895332336, 'epoch': 20.51}
{'loss': 0.0098, 'grad_norm': 6.134334564208984, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.008804052136838436, 'loss_2': 0.0010242462158203125, 'loss_3': -16.263090133666992, 'loss_4': 0.2631281912326813, 'epoch': 20.51}
{'loss': 0.0168, 'grad_norm': 5.086014270782471, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.005650703329592943, 'loss_2': 0.01116943359375, 'loss_3': -16.371036529541016, 'loss_4': 0.2897784113883972, 'epoch': 20.52}
{'loss': 0.0201, 'grad_norm': 4.879797458648682, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.01126926764845848, 'loss_2': 0.00884246826171875, 'loss_3': -16.135570526123047, 'loss_4': 0.8628340363502502, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 16:44:27,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:27,749 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:21<28:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:35,088 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016655655577778816, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.145, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012156161479651928, 'eval_loss_2': 0.004499495029449463, 'eval_loss_3': -18.15838050842285, 'eval_loss_4': 0.2618907392024994, 'epoch': 20.52}
{'loss': 0.0122, 'grad_norm': 4.618581295013428, 'learning_rate': 9.5e-06, 'loss_1': 0.0029848767444491386, 'loss_2': 0.009185791015625, 'loss_3': -16.485273361206055, 'loss_4': 0.22929495573043823, 'epoch': 20.53}
{'loss': 0.0083, 'grad_norm': 5.202126502990723, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.004442394711077213, 'loss_2': 0.0038604736328125, 'loss_3': -16.311500549316406, 'loss_4': 0.6209176778793335, 'epoch': 20.53}
{'loss': 0.0125, 'grad_norm': 4.579612731933594, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.005243054125458002, 'loss_2': 0.007266998291015625, 'loss_3': -16.345046997070312, 'loss_4': 0.3563627600669861, 'epoch': 20.54}
{'loss': 0.0253, 'grad_norm': 11.982584953308105, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.02239285036921501, 'loss_2': 0.002956390380859375, 'loss_3': -16.121967315673828, 'loss_4': 0.24864423274993896, 'epoch': 20.55}
{'loss': 0.0089, 'grad_norm': 5.260549068450928, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.008537424728274345, 'loss_2': 0.000316619873046875, 'loss_3': -16.423784255981445, 'loss_4': 0.6094377040863037, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 16:44:35,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:35,088 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:29<28:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:42,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015534148551523685, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.505, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01207214780151844, 'eval_loss_2': 0.00346200168132782, 'eval_loss_3': -18.15591812133789, 'eval_loss_4': 0.37156233191490173, 'epoch': 20.55}
{'loss': 0.0047, 'grad_norm': 4.959115505218506, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.0035158058162778616, 'loss_2': 0.0011386871337890625, 'loss_3': -16.400352478027344, 'loss_4': 0.34389954805374146, 'epoch': 20.56}
{'loss': 0.0079, 'grad_norm': 4.794125080108643, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.004477002192288637, 'loss_2': 0.003383636474609375, 'loss_3': -16.48865509033203, 'loss_4': -0.21309924125671387, 'epoch': 20.56}
{'loss': 0.0073, 'grad_norm': 5.3352203369140625, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.0037687737494707108, 'loss_2': 0.003498077392578125, 'loss_3': -16.579999923706055, 'loss_4': 0.2404111623764038, 'epoch': 20.57}
{'loss': 0.0047, 'grad_norm': 4.988669395446777, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.004088239278644323, 'loss_2': 0.0006589889526367188, 'loss_3': -16.35869789123535, 'loss_4': 0.19684745371341705, 'epoch': 20.58}
{'loss': 0.0071, 'grad_norm': 4.511429786682129, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.004226479679346085, 'loss_2': 0.00286865234375, 'loss_3': -16.21040916442871, 'loss_4': 0.3124062120914459, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 16:44:42,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:42,431 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:36<27:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:49,780 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015401900745928288, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.967, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011328005231916904, 'eval_loss_2': 0.004073895514011383, 'eval_loss_3': -18.166406631469727, 'eval_loss_4': 0.4621981382369995, 'epoch': 20.58}
{'loss': 0.0073, 'grad_norm': 5.199326038360596, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.004768819082528353, 'loss_2': 0.00257110595703125, 'loss_3': -16.399898529052734, 'loss_4': 0.22910410165786743, 'epoch': 20.59}
{'loss': 0.0066, 'grad_norm': 5.015137672424316, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.006221745163202286, 'loss_2': 0.0004277229309082031, 'loss_3': -16.261991500854492, 'loss_4': 0.3577730059623718, 'epoch': 20.59}
{'loss': 0.011, 'grad_norm': 7.051865577697754, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.010138691402971745, 'loss_2': 0.0008544921875, 'loss_3': -16.353395462036133, 'loss_4': 0.9103858470916748, 'epoch': 20.6}
{'loss': 0.0164, 'grad_norm': 9.036864280700684, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.014355398714542389, 'loss_2': 0.00202178955078125, 'loss_3': -16.33049774169922, 'loss_4': 0.32907596230506897, 'epoch': 20.6}
{'loss': 0.0685, 'grad_norm': 11.482463836669922, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.06790032237768173, 'loss_2': 0.0005497932434082031, 'loss_3': -16.55499267578125, 'loss_4': 1.057917833328247, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 16:44:49,780 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:49,780 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:43<27:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:44:57,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014891032129526138, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011198649182915688, 'eval_loss_2': 0.0036923848092556, 'eval_loss_3': -18.150976181030273, 'eval_loss_4': 0.4630008041858673, 'epoch': 20.61}
{'loss': 0.0043, 'grad_norm': 4.431769847869873, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.002700981916859746, 'loss_2': 0.0016345977783203125, 'loss_3': -16.542268753051758, 'loss_4': 0.7047415971755981, 'epoch': 20.62}
{'loss': 0.0052, 'grad_norm': 4.478060245513916, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.004554389044642448, 'loss_2': 0.0006923675537109375, 'loss_3': -16.340435028076172, 'loss_4': 0.40260472893714905, 'epoch': 20.62}
{'loss': 0.0084, 'grad_norm': 5.091816425323486, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.003763125278055668, 'loss_2': 0.004608154296875, 'loss_3': -16.15506362915039, 'loss_4': 0.11197914183139801, 'epoch': 20.63}
{'loss': 0.0178, 'grad_norm': 8.242875099182129, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.017570028081536293, 'loss_2': 0.00026988983154296875, 'loss_3': -16.253190994262695, 'loss_4': 0.49619603157043457, 'epoch': 20.63}
{'loss': 0.0057, 'grad_norm': 4.5060319900512695, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.005151413381099701, 'loss_2': 0.0005006790161132812, 'loss_3': -16.4178524017334, 'loss_4': 0.26620566844940186, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 16:44:57,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:44:57,122 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:51<27:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:04,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014885986223816872, 'eval_runtime': 3.7997, 'eval_samples_per_second': 269.496, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011271961033344269, 'eval_loss_2': 0.0036140233278274536, 'eval_loss_3': -18.13822364807129, 'eval_loss_4': 0.5590943694114685, 'epoch': 20.64}
{'loss': 0.0053, 'grad_norm': 5.100114822387695, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.0047478461638092995, 'loss_2': 0.00055694580078125, 'loss_3': -16.152591705322266, 'loss_4': 0.81980961561203, 'epoch': 20.65}
{'loss': 0.0081, 'grad_norm': 5.632021427154541, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.006221360992640257, 'loss_2': 0.001922607421875, 'loss_3': -16.397005081176758, 'loss_4': 1.2481815814971924, 'epoch': 20.65}
{'loss': 0.0063, 'grad_norm': 4.692480087280273, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.0047890967689454556, 'loss_2': 0.0014781951904296875, 'loss_3': -16.365694046020508, 'loss_4': 0.5121840238571167, 'epoch': 20.66}
{'loss': 0.0138, 'grad_norm': 5.147763729095459, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.006206027697771788, 'loss_2': 0.00759124755859375, 'loss_3': -16.388591766357422, 'loss_4': 0.4693470001220703, 'epoch': 20.66}
{'loss': 0.0071, 'grad_norm': 4.52131462097168, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.002830165671184659, 'loss_2': 0.004314422607421875, 'loss_3': -16.49115753173828, 'loss_4': 1.20392906665802, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 16:45:04,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:04,461 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:27:58<27:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:11,797 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01612596958875656, 'eval_runtime': 3.7987, 'eval_samples_per_second': 269.568, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011141381226480007, 'eval_loss_2': 0.0049845874309539795, 'eval_loss_3': -18.150314331054688, 'eval_loss_4': 0.5977581739425659, 'epoch': 20.67}
{'loss': 0.0092, 'grad_norm': 4.900728702545166, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.003475880017504096, 'loss_2': 0.005767822265625, 'loss_3': -16.498153686523438, 'loss_4': 0.4278983175754547, 'epoch': 20.67}
{'loss': 0.0152, 'grad_norm': 7.501925468444824, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.012862536124885082, 'loss_2': 0.0023651123046875, 'loss_3': -16.418167114257812, 'loss_4': 0.4937034845352173, 'epoch': 20.68}
{'loss': 0.0147, 'grad_norm': 4.855658531188965, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.0062975529581308365, 'loss_2': 0.0084228515625, 'loss_3': -16.490623474121094, 'loss_4': 0.6009780168533325, 'epoch': 20.69}
{'loss': 0.0144, 'grad_norm': 4.751091957092285, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.0057565998286008835, 'loss_2': 0.0086822509765625, 'loss_3': -16.19908905029297, 'loss_4': 0.12873032689094543, 'epoch': 20.69}
{'loss': 0.0251, 'grad_norm': 8.677774429321289, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.021430686116218567, 'loss_2': 0.00366973876953125, 'loss_3': -16.63443374633789, 'loss_4': 0.9413043260574341, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 16:45:11,797 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:11,797 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:28:05<27:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:19,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014980483800172806, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.585, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.011028561741113663, 'eval_loss_2': 0.003951922059059143, 'eval_loss_3': -18.16042709350586, 'eval_loss_4': 0.47457176446914673, 'epoch': 20.7}
{'loss': 0.0132, 'grad_norm': 5.305647373199463, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.00710616260766983, 'loss_2': 0.006072998046875, 'loss_3': -16.428913116455078, 'loss_4': 0.7841392755508423, 'epoch': 20.7}
{'loss': 0.0086, 'grad_norm': 4.313548564910889, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.005117373540997505, 'loss_2': 0.003509521484375, 'loss_3': -16.539867401123047, 'loss_4': 0.6539002656936646, 'epoch': 20.71}
{'loss': 0.0176, 'grad_norm': 6.8214287757873535, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.013742205686867237, 'loss_2': 0.003849029541015625, 'loss_3': -16.345857620239258, 'loss_4': 0.7531368732452393, 'epoch': 20.72}
{'loss': 0.0046, 'grad_norm': 4.259264945983887, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.003131992882117629, 'loss_2': 0.0015048980712890625, 'loss_3': -16.387649536132812, 'loss_4': 0.1953921616077423, 'epoch': 20.72}
{'loss': 0.0102, 'grad_norm': 5.360901355743408, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.00604940066114068, 'loss_2': 0.00414276123046875, 'loss_3': -16.239978790283203, 'loss_4': 0.4554997980594635, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 16:45:19,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:19,132 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:28:13<27:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:26,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01275310292840004, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.588, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.009781543165445328, 'eval_loss_2': 0.002971559762954712, 'eval_loss_3': -18.17561149597168, 'eval_loss_4': 0.39593005180358887, 'epoch': 20.73}
{'loss': 0.0093, 'grad_norm': 5.23899507522583, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.008434532210230827, 'loss_2': 0.0008630752563476562, 'loss_3': -16.55260467529297, 'loss_4': 0.502042829990387, 'epoch': 20.73}
{'loss': 0.0046, 'grad_norm': 4.4293107986450195, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.0033813912887126207, 'loss_2': 0.0011806488037109375, 'loss_3': -16.474382400512695, 'loss_4': 0.4520702064037323, 'epoch': 20.74}
{'loss': 0.012, 'grad_norm': 6.057382106781006, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.010201165452599525, 'loss_2': 0.0017547607421875, 'loss_3': -16.237762451171875, 'loss_4': 0.214610755443573, 'epoch': 20.74}
{'loss': 0.0077, 'grad_norm': 5.088502883911133, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.006331031676381826, 'loss_2': 0.0014047622680664062, 'loss_3': -16.365734100341797, 'loss_4': 0.33698520064353943, 'epoch': 20.75}
{'loss': 0.009, 'grad_norm': 5.3952717781066895, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.005837106145918369, 'loss_2': 0.0031452178955078125, 'loss_3': -16.365325927734375, 'loss_4': 0.6767333745956421, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 16:45:26,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:26,472 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:20<27:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:33,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01300064381211996, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.908, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010163819417357445, 'eval_loss_2': 0.0028368234634399414, 'eval_loss_3': -18.17506217956543, 'eval_loss_4': 0.3416392505168915, 'epoch': 20.76}
{'loss': 0.0104, 'grad_norm': 5.0516462326049805, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.007040537428110838, 'loss_2': 0.003391265869140625, 'loss_3': -16.264314651489258, 'loss_4': 0.5761551260948181, 'epoch': 20.76}
{'loss': 0.0113, 'grad_norm': 6.310013771057129, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.007154784630984068, 'loss_2': 0.0041656494140625, 'loss_3': -16.31658363342285, 'loss_4': 0.7607489228248596, 'epoch': 20.77}
{'loss': 0.0096, 'grad_norm': 6.638871669769287, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.007543954532593489, 'loss_2': 0.002079010009765625, 'loss_3': -16.537673950195312, 'loss_4': 0.0885482132434845, 'epoch': 20.77}
{'loss': 0.0117, 'grad_norm': 4.7075419425964355, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.005078120622783899, 'loss_2': 0.0066375732421875, 'loss_3': -16.533241271972656, 'loss_4': -0.14813217520713806, 'epoch': 20.78}
{'loss': 0.0078, 'grad_norm': 4.04669189453125, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.0034415079280734062, 'loss_2': 0.0043182373046875, 'loss_3': -16.61267852783203, 'loss_4': 0.6621729135513306, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 16:45:33,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:33,819 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:27<27:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:45:41,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014511765912175179, 'eval_runtime': 3.7932, 'eval_samples_per_second': 269.956, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010460645891726017, 'eval_loss_2': 0.004051119089126587, 'eval_loss_3': -18.17316246032715, 'eval_loss_4': 0.28607192635536194, 'epoch': 20.78}
{'loss': 0.0085, 'grad_norm': 4.954720973968506, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.006429995410144329, 'loss_2': 0.002040863037109375, 'loss_3': -16.40408706665039, 'loss_4': 0.43403831124305725, 'epoch': 20.79}
{'loss': 0.0117, 'grad_norm': 5.091691493988037, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.006933972239494324, 'loss_2': 0.0047760009765625, 'loss_3': -16.5961856842041, 'loss_4': 0.12602180242538452, 'epoch': 20.8}
{'loss': 0.0121, 'grad_norm': 6.213003158569336, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.0099887540563941, 'loss_2': 0.00215911865234375, 'loss_3': -16.336074829101562, 'loss_4': 0.27970296144485474, 'epoch': 20.8}
{'loss': 0.0204, 'grad_norm': 6.290192127227783, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.016317235305905342, 'loss_2': 0.0041046142578125, 'loss_3': -16.417606353759766, 'loss_4': 0.13668954372406006, 'epoch': 20.81}
{'loss': 0.013, 'grad_norm': 5.11868143081665, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.005450033582746983, 'loss_2': 0.0075531005859375, 'loss_3': -16.539592742919922, 'loss_4': 0.27719756960868835, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 16:45:41,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:41,146 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:35<27:08,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:45:48,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01621914841234684, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.756, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011008452624082565, 'eval_loss_2': 0.005210697650909424, 'eval_loss_3': -18.173036575317383, 'eval_loss_4': 0.2326866239309311, 'epoch': 20.81}
{'loss': 0.0091, 'grad_norm': 4.811601638793945, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.004713601432740688, 'loss_2': 0.004425048828125, 'loss_3': -16.38681411743164, 'loss_4': 0.352461576461792, 'epoch': 20.82}
{'loss': 0.0153, 'grad_norm': 8.958925247192383, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.013717514462769032, 'loss_2': 0.0015497207641601562, 'loss_3': -16.373104095458984, 'loss_4': 0.49964046478271484, 'epoch': 20.83}
{'loss': 0.0059, 'grad_norm': 4.771234512329102, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.004620020277798176, 'loss_2': 0.0012969970703125, 'loss_3': -16.652359008789062, 'loss_4': 0.4315603971481323, 'epoch': 20.83}
{'loss': 0.0124, 'grad_norm': 4.951399803161621, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.00371364364400506, 'loss_2': 0.00873565673828125, 'loss_3': -16.47765350341797, 'loss_4': 0.0360981822013855, 'epoch': 20.84}
{'loss': 0.0099, 'grad_norm': 4.709972858428955, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.002765946090221405, 'loss_2': 0.0070953369140625, 'loss_3': -16.563129425048828, 'loss_4': 0.4928392171859741, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 16:45:48,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:48,470 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:42<27:04,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:45:55,798 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0155031718313694, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.796, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010841662995517254, 'eval_loss_2': 0.0046615079045295715, 'eval_loss_3': -18.1668701171875, 'eval_loss_4': 0.1897570788860321, 'epoch': 20.84}
{'loss': 0.0103, 'grad_norm': 4.559213161468506, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.0035036318004131317, 'loss_2': 0.00679779052734375, 'loss_3': -16.5501651763916, 'loss_4': 0.6630121469497681, 'epoch': 20.85}
{'loss': 0.0164, 'grad_norm': 6.791472911834717, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.014836311340332031, 'loss_2': 0.001575469970703125, 'loss_3': -16.170063018798828, 'loss_4': -0.2082429826259613, 'epoch': 20.85}
{'loss': 0.0098, 'grad_norm': 4.932114601135254, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.004331973381340504, 'loss_2': 0.005435943603515625, 'loss_3': -16.602340698242188, 'loss_4': 0.28628313541412354, 'epoch': 20.86}
{'loss': 0.0048, 'grad_norm': 4.443671226501465, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.0032216517720371485, 'loss_2': 0.00156402587890625, 'loss_3': -16.220293045043945, 'loss_4': 0.406821608543396, 'epoch': 20.87}
{'loss': 0.0113, 'grad_norm': 5.670526504516602, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.006184383761137724, 'loss_2': 0.00516510009765625, 'loss_3': -16.381078720092773, 'loss_4': 0.323738694190979, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 16:45:55,798 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:45:55,798 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:49<26:59,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:46:03,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014057253487408161, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.808, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011260063387453556, 'eval_loss_2': 0.002797190099954605, 'eval_loss_3': -18.164962768554688, 'eval_loss_4': 0.16349481046199799, 'epoch': 20.87}
{'loss': 0.0078, 'grad_norm': 4.730258941650391, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.007188100833445787, 'loss_2': 0.0006165504455566406, 'loss_3': -16.389110565185547, 'loss_4': 0.0887589231133461, 'epoch': 20.88}
{'loss': 0.0067, 'grad_norm': 7.403364181518555, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.005664221942424774, 'loss_2': 0.0010690689086914062, 'loss_3': -16.463808059692383, 'loss_4': 0.5222217440605164, 'epoch': 20.88}
{'loss': 0.0096, 'grad_norm': 5.038267612457275, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.006442435085773468, 'loss_2': 0.003200531005859375, 'loss_3': -16.278228759765625, 'loss_4': 0.2530803978443146, 'epoch': 20.89}
{'loss': 0.0105, 'grad_norm': 5.3875298500061035, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.008510159328579903, 'loss_2': 0.0020236968994140625, 'loss_3': -16.342004776000977, 'loss_4': -0.31444230675697327, 'epoch': 20.9}
{'loss': 0.0081, 'grad_norm': 4.33821439743042, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.0041276817210018635, 'loss_2': 0.003997802734375, 'loss_3': -16.564128875732422, 'loss_4': 0.42642712593078613, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 16:46:03,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:03,125 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:28:57<26:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:10,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013709800317883492, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.072, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011032799258828163, 'eval_loss_2': 0.0026770010590553284, 'eval_loss_3': -18.172555923461914, 'eval_loss_4': 0.19763831794261932, 'epoch': 20.9}
{'loss': 0.0145, 'grad_norm': 5.665322303771973, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.006934863980859518, 'loss_2': 0.00754547119140625, 'loss_3': -16.354999542236328, 'loss_4': -0.06305250525474548, 'epoch': 20.91}
{'loss': 0.0093, 'grad_norm': 5.2119059562683105, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.0038762036710977554, 'loss_2': 0.00540924072265625, 'loss_3': -16.555479049682617, 'loss_4': 0.15013179183006287, 'epoch': 20.91}
{'loss': 0.0106, 'grad_norm': 4.2221832275390625, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.008353437297046185, 'loss_2': 0.0022869110107421875, 'loss_3': -16.501262664794922, 'loss_4': 0.48711735010147095, 'epoch': 20.92}
{'loss': 0.0094, 'grad_norm': 4.122965335845947, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.003306874306872487, 'loss_2': 0.006103515625, 'loss_3': -16.438310623168945, 'loss_4': 0.3237617015838623, 'epoch': 20.92}
{'loss': 0.0087, 'grad_norm': 5.641026973724365, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.006303566973656416, 'loss_2': 0.0023860931396484375, 'loss_3': -16.347532272338867, 'loss_4': 0.7504874467849731, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 16:46:10,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:10,470 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:29:04<26:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:17,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014196538366377354, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.522, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011537844315171242, 'eval_loss_2': 0.0026586949825286865, 'eval_loss_3': -18.174427032470703, 'eval_loss_4': 0.19062559306621552, 'epoch': 20.93}
{'loss': 0.0085, 'grad_norm': 4.93426513671875, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.005151708144694567, 'loss_2': 0.0033740997314453125, 'loss_3': -16.275611877441406, 'loss_4': 0.0743057131767273, 'epoch': 20.94}
{'loss': 0.0046, 'grad_norm': 4.781134605407715, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.00453623291105032, 'loss_2': 7.176399230957031e-05, 'loss_3': -16.635608673095703, 'loss_4': 0.1080518290400505, 'epoch': 20.94}
{'loss': 0.0067, 'grad_norm': 4.623341083526611, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.003551359288394451, 'loss_2': 0.0031280517578125, 'loss_3': -16.34421157836914, 'loss_4': 0.04893834888935089, 'epoch': 20.95}
{'loss': 0.0264, 'grad_norm': 11.677112579345703, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.020153332501649857, 'loss_2': 0.006252288818359375, 'loss_3': -16.40925407409668, 'loss_4': 0.43730372190475464, 'epoch': 20.95}
{'loss': 0.0159, 'grad_norm': 5.044229030609131, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.00733296200633049, 'loss_2': 0.00853729248046875, 'loss_3': -16.412235260009766, 'loss_4': 0.31299054622650146, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 16:46:17,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:17,804 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:29:11<26:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:25,135 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014291231520473957, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.644, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.011368046514689922, 'eval_loss_2': 0.0029231831431388855, 'eval_loss_3': -18.17361068725586, 'eval_loss_4': 0.24459248781204224, 'epoch': 20.96}
{'loss': 0.0072, 'grad_norm': 4.713172912597656, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.005087446887046099, 'loss_2': 0.0021209716796875, 'loss_3': -16.45945167541504, 'loss_4': 0.4879686236381531, 'epoch': 20.97}
{'loss': 0.0132, 'grad_norm': 6.646243095397949, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.010870187543332577, 'loss_2': 0.002338409423828125, 'loss_3': -16.18698501586914, 'loss_4': 0.30428946018218994, 'epoch': 20.97}
{'loss': 0.0106, 'grad_norm': 5.700328826904297, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.009406505152583122, 'loss_2': 0.0011854171752929688, 'loss_3': -16.306283950805664, 'loss_4': -0.2125493437051773, 'epoch': 20.98}
{'loss': 0.0076, 'grad_norm': 4.528784275054932, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.006584446877241135, 'loss_2': 0.0010166168212890625, 'loss_3': -16.394752502441406, 'loss_4': 0.420378178358078, 'epoch': 20.98}
{'loss': 0.0173, 'grad_norm': 9.594746589660645, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.014098437502980232, 'loss_2': 0.00321197509765625, 'loss_3': -16.312271118164062, 'loss_4': 0.3003954589366913, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 16:46:25,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:25,135 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:18<25:53,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 16:46:32,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015061384066939354, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.671, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011838280595839024, 'eval_loss_2': 0.003223106265068054, 'eval_loss_3': -18.164913177490234, 'eval_loss_4': 0.39427003264427185, 'epoch': 20.99}
{'loss': 0.0056, 'grad_norm': 4.836444854736328, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.005235862918198109, 'loss_2': 0.00038170814514160156, 'loss_3': -16.538631439208984, 'loss_4': 0.6257601976394653, 'epoch': 20.99}
{'loss': 0.0044, 'grad_norm': 6.544709205627441, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.001486484194174409, 'loss_2': 0.002887725830078125, 'loss_3': -16.51508331298828, 'loss_4': 0.3102029263973236, 'epoch': 21.0}
{'loss': 0.0242, 'grad_norm': 9.839420318603516, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.013465773314237595, 'loss_2': 0.0107421875, 'loss_3': -16.450035095214844, 'loss_4': 0.432914674282074, 'epoch': 21.01}
{'loss': 0.009, 'grad_norm': 5.077341079711914, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.0069670891389250755, 'loss_2': 0.00203704833984375, 'loss_3': -16.367591857910156, 'loss_4': 0.6009494066238403, 'epoch': 21.01}
{'loss': 0.0182, 'grad_norm': 11.129242897033691, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.017054647207260132, 'loss_2': 0.0011072158813476562, 'loss_3': -16.544689178466797, 'loss_4': 0.45376157760620117, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 16:46:32,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:32,156 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:26<26:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:46:39,491 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01577698066830635, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.452, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012249919585883617, 'eval_loss_2': 0.0035270601511001587, 'eval_loss_3': -18.16033935546875, 'eval_loss_4': 0.5251609086990356, 'epoch': 21.02}
{'loss': 0.0091, 'grad_norm': 5.7307658195495605, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.007993637584149837, 'loss_2': 0.001117706298828125, 'loss_3': -16.353904724121094, 'loss_4': 0.6897336840629578, 'epoch': 21.02}
{'loss': 0.0141, 'grad_norm': 5.260685920715332, 'learning_rate': 9e-06, 'loss_1': 0.006325943861156702, 'loss_2': 0.00780487060546875, 'loss_3': -16.49774169921875, 'loss_4': 0.26630520820617676, 'epoch': 21.03}
{'loss': 0.0098, 'grad_norm': 5.2803497314453125, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.007267572917044163, 'loss_2': 0.002574920654296875, 'loss_3': -16.29991912841797, 'loss_4': 0.7787078022956848, 'epoch': 21.03}
{'loss': 0.0176, 'grad_norm': 6.7867560386657715, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.011553602293133736, 'loss_2': 0.006069183349609375, 'loss_3': -16.219541549682617, 'loss_4': 0.5686071515083313, 'epoch': 21.04}
{'loss': 0.0152, 'grad_norm': 6.146003723144531, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.011891212314367294, 'loss_2': 0.003292083740234375, 'loss_3': -16.23925018310547, 'loss_4': 0.3061993718147278, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 16:46:39,491 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:39,491 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:33<26:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:46,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014444956555962563, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.293, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012092102319002151, 'eval_loss_2': 0.002352852374315262, 'eval_loss_3': -18.16256332397461, 'eval_loss_4': 0.7153586149215698, 'epoch': 21.05}
{'loss': 0.0089, 'grad_norm': 5.265598773956299, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.00483252527192235, 'loss_2': 0.00409698486328125, 'loss_3': -16.32257843017578, 'loss_4': 0.5467588901519775, 'epoch': 21.05}
{'loss': 0.0117, 'grad_norm': 5.9896111488342285, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.010835333727300167, 'loss_2': 0.0008864402770996094, 'loss_3': -16.505882263183594, 'loss_4': 0.4101783037185669, 'epoch': 21.06}
{'loss': 0.0079, 'grad_norm': 4.459381103515625, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.005107133649289608, 'loss_2': 0.0027446746826171875, 'loss_3': -16.531240463256836, 'loss_4': 1.2320442199707031, 'epoch': 21.06}
{'loss': 0.0095, 'grad_norm': 4.297205448150635, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.004532535094767809, 'loss_2': 0.00492095947265625, 'loss_3': -16.4028263092041, 'loss_4': 0.9322716593742371, 'epoch': 21.07}
{'loss': 0.0123, 'grad_norm': 4.638688087463379, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.004561212379485369, 'loss_2': 0.0077362060546875, 'loss_3': -16.453523635864258, 'loss_4': 1.0373611450195312, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 16:46:46,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:46,836 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:40<26:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:46:54,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014325866475701332, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.272, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011101462878286839, 'eval_loss_2': 0.003224402666091919, 'eval_loss_3': -18.166595458984375, 'eval_loss_4': 0.8121713995933533, 'epoch': 21.08}
{'loss': 0.0136, 'grad_norm': 5.827627658843994, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.008539123460650444, 'loss_2': 0.00510406494140625, 'loss_3': -16.46694564819336, 'loss_4': 0.7562520503997803, 'epoch': 21.08}
{'loss': 0.0094, 'grad_norm': 4.953952312469482, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.00533166341483593, 'loss_2': 0.0040435791015625, 'loss_3': -16.297231674194336, 'loss_4': 0.6117403507232666, 'epoch': 21.09}
{'loss': 0.0097, 'grad_norm': 4.744235515594482, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.0036965846084058285, 'loss_2': 0.00603485107421875, 'loss_3': -16.33089828491211, 'loss_4': 0.8742622137069702, 'epoch': 21.09}
{'loss': 0.0172, 'grad_norm': 5.197912216186523, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.0056879641488194466, 'loss_2': 0.01153564453125, 'loss_3': -16.493637084960938, 'loss_4': 0.48459017276763916, 'epoch': 21.1}
{'loss': 0.0054, 'grad_norm': 4.917531490325928, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.005266986321657896, 'loss_2': 0.00013637542724609375, 'loss_3': -16.392908096313477, 'loss_4': 0.8666120171546936, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 16:46:54,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:46:54,177 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:48<26:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:01,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014179132878780365, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.918, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010690473951399326, 'eval_loss_2': 0.0034886598587036133, 'eval_loss_3': -18.16853141784668, 'eval_loss_4': 0.8627480268478394, 'epoch': 21.1}
{'loss': 0.0753, 'grad_norm': 11.092793464660645, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.07287991046905518, 'loss_2': 0.0023746490478515625, 'loss_3': -16.3244686126709, 'loss_4': 1.2862770557403564, 'epoch': 21.11}
{'loss': 0.0254, 'grad_norm': 7.460923671722412, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.01711006462574005, 'loss_2': 0.00826263427734375, 'loss_3': -16.448911666870117, 'loss_4': 0.501741349697113, 'epoch': 21.12}
{'loss': 0.0208, 'grad_norm': 6.277007102966309, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.014822568744421005, 'loss_2': 0.006011962890625, 'loss_3': -16.367141723632812, 'loss_4': 0.8942582607269287, 'epoch': 21.12}
{'loss': 0.0066, 'grad_norm': 4.8526930809021, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.005228770896792412, 'loss_2': 0.0013446807861328125, 'loss_3': -16.39942741394043, 'loss_4': 1.0894436836242676, 'epoch': 21.13}
{'loss': 0.0109, 'grad_norm': 5.0319132804870605, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.0076179346069693565, 'loss_2': 0.0032711029052734375, 'loss_3': -16.463848114013672, 'loss_4': 0.6836336255073547, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 16:47:01,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:01,512 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:29:55<26:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:08,844 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013875309377908707, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.821, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.011308345012366772, 'eval_loss_2': 0.0025669634342193604, 'eval_loss_3': -18.169862747192383, 'eval_loss_4': 0.8465926051139832, 'epoch': 21.13}
{'loss': 0.0087, 'grad_norm': 5.167603492736816, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.004865953233093023, 'loss_2': 0.003833770751953125, 'loss_3': -16.34052276611328, 'loss_4': 0.6464974880218506, 'epoch': 21.14}
{'loss': 0.0155, 'grad_norm': 6.141042232513428, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.012202050536870956, 'loss_2': 0.0033416748046875, 'loss_3': -16.377408981323242, 'loss_4': 1.0298744440078735, 'epoch': 21.15}
{'loss': 0.0077, 'grad_norm': 4.973838806152344, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.005393668077886105, 'loss_2': 0.002315521240234375, 'loss_3': -16.269601821899414, 'loss_4': 0.8705248832702637, 'epoch': 21.15}
{'loss': 0.0068, 'grad_norm': 4.397614479064941, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.005163584835827351, 'loss_2': 0.0016164779663085938, 'loss_3': -16.2517147064209, 'loss_4': 1.0928237438201904, 'epoch': 21.16}
{'loss': 0.0233, 'grad_norm': 12.343042373657227, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.021862251684069633, 'loss_2': 0.0014181137084960938, 'loss_3': -16.389751434326172, 'loss_4': 0.6265416741371155, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 16:47:08,844 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:08,844 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:30:02<26:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:16,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015202632173895836, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.889, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.01167579460889101, 'eval_loss_2': 0.003526836633682251, 'eval_loss_3': -18.164894104003906, 'eval_loss_4': 0.8361373543739319, 'epoch': 21.16}
{'loss': 0.0072, 'grad_norm': 4.877601146697998, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.005510724615305662, 'loss_2': 0.0016603469848632812, 'loss_3': -16.344154357910156, 'loss_4': 0.9470040798187256, 'epoch': 21.17}
{'loss': 0.0137, 'grad_norm': 6.091727256774902, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.008765915408730507, 'loss_2': 0.00490570068359375, 'loss_3': -16.493770599365234, 'loss_4': 0.7305375337600708, 'epoch': 21.17}
{'loss': 0.0055, 'grad_norm': 4.865512847900391, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.003722523106262088, 'loss_2': 0.0017910003662109375, 'loss_3': -16.432897567749023, 'loss_4': 0.8364719152450562, 'epoch': 21.18}
{'loss': 0.0052, 'grad_norm': 5.57297420501709, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.004485661629587412, 'loss_2': 0.000682830810546875, 'loss_3': -16.51708221435547, 'loss_4': 1.1578764915466309, 'epoch': 21.19}
{'loss': 0.0062, 'grad_norm': 4.575493335723877, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.005712202284485102, 'loss_2': 0.0005178451538085938, 'loss_3': -16.439062118530273, 'loss_4': 0.884990930557251, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 16:47:16,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:16,182 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:10<26:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:23,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015839803963899612, 'eval_runtime': 3.7979, 'eval_samples_per_second': 269.622, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.012492622248828411, 'eval_loss_2': 0.0033471807837486267, 'eval_loss_3': -18.15337371826172, 'eval_loss_4': 0.9265496134757996, 'epoch': 21.19}
{'loss': 0.0111, 'grad_norm': 6.720231533050537, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.008516914211213589, 'loss_2': 0.0025844573974609375, 'loss_3': -16.398822784423828, 'loss_4': 1.180159330368042, 'epoch': 21.2}
{'loss': 0.007, 'grad_norm': 4.43442964553833, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.0046202209778130054, 'loss_2': 0.0023956298828125, 'loss_3': -16.282211303710938, 'loss_4': 1.290532112121582, 'epoch': 21.2}
{'loss': 0.0306, 'grad_norm': 11.925334930419922, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.02821221947669983, 'loss_2': 0.0023937225341796875, 'loss_3': -16.282060623168945, 'loss_4': 1.269824504852295, 'epoch': 21.21}
{'loss': 0.0116, 'grad_norm': 5.755216598510742, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.006019920110702515, 'loss_2': 0.005596160888671875, 'loss_3': -16.35110855102539, 'loss_4': 0.8796665668487549, 'epoch': 21.22}
{'loss': 0.0205, 'grad_norm': 9.286144256591797, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.01793481595814228, 'loss_2': 0.002567291259765625, 'loss_3': -16.593032836914062, 'loss_4': 0.6088281869888306, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 16:47:23,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:23,517 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:17<26:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:30,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01625746861100197, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.616, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.013495462015271187, 'eval_loss_2': 0.0027620047330856323, 'eval_loss_3': -18.151952743530273, 'eval_loss_4': 1.0419515371322632, 'epoch': 21.22}
{'loss': 0.006, 'grad_norm': 4.928344249725342, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.005252823233604431, 'loss_2': 0.0007224082946777344, 'loss_3': -16.401899337768555, 'loss_4': 1.0452213287353516, 'epoch': 21.23}
{'loss': 0.0163, 'grad_norm': 6.547703742980957, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.01247931644320488, 'loss_2': 0.0037784576416015625, 'loss_3': -16.237926483154297, 'loss_4': 1.1153008937835693, 'epoch': 21.23}
{'loss': 0.0069, 'grad_norm': 5.210922718048096, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.005793319083750248, 'loss_2': 0.0011453628540039062, 'loss_3': -16.29758644104004, 'loss_4': 0.8945661783218384, 'epoch': 21.24}
{'loss': 0.0164, 'grad_norm': 5.980165481567383, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.009937877766788006, 'loss_2': 0.00643157958984375, 'loss_3': -16.21768569946289, 'loss_4': 0.5438207387924194, 'epoch': 21.24}
{'loss': 0.0176, 'grad_norm': 10.023467063903809, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.01491969171911478, 'loss_2': 0.002727508544921875, 'loss_3': -16.32621192932129, 'loss_4': 1.1557462215423584, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 16:47:30,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:30,862 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:24<25:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:38,199 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015821615234017372, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.446, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.012826942838728428, 'eval_loss_2': 0.0029946714639663696, 'eval_loss_3': -18.140369415283203, 'eval_loss_4': 1.0831146240234375, 'epoch': 21.25}
{'loss': 0.0087, 'grad_norm': 4.6104960441589355, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.0068153077736496925, 'loss_2': 0.0018901824951171875, 'loss_3': -16.437068939208984, 'loss_4': 1.3147587776184082, 'epoch': 21.26}
{'loss': 0.013, 'grad_norm': 5.554964065551758, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.007035847753286362, 'loss_2': 0.005916595458984375, 'loss_3': -16.270885467529297, 'loss_4': 0.7226595878601074, 'epoch': 21.26}
{'loss': 0.02, 'grad_norm': 6.564993858337402, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.012226843275129795, 'loss_2': 0.00782012939453125, 'loss_3': -16.353012084960938, 'loss_4': 1.2261826992034912, 'epoch': 21.27}
{'loss': 0.0055, 'grad_norm': 5.153902530670166, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.00507368054240942, 'loss_2': 0.00043487548828125, 'loss_3': -16.201763153076172, 'loss_4': 0.42253756523132324, 'epoch': 21.27}
{'loss': 0.0075, 'grad_norm': 5.197914123535156, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.006932408083230257, 'loss_2': 0.000560760498046875, 'loss_3': -16.384639739990234, 'loss_4': 1.1612753868103027, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 16:47:38,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:38,200 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:32<25:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:45,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01662478782236576, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.777, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.013599315658211708, 'eval_loss_2': 0.0030254721641540527, 'eval_loss_3': -18.125633239746094, 'eval_loss_4': 1.1098496913909912, 'epoch': 21.28}
{'loss': 0.0096, 'grad_norm': 5.468790054321289, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.00875706784427166, 'loss_2': 0.0008144378662109375, 'loss_3': -16.405216217041016, 'loss_4': 1.1884645223617554, 'epoch': 21.28}
{'loss': 0.0281, 'grad_norm': 22.348648071289062, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.02626904845237732, 'loss_2': 0.0018253326416015625, 'loss_3': -16.201297760009766, 'loss_4': 0.9760220050811768, 'epoch': 21.29}
{'loss': 0.0065, 'grad_norm': 4.157205104827881, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.00322411279194057, 'loss_2': 0.00327301025390625, 'loss_3': -16.25922393798828, 'loss_4': 0.8379820585250854, 'epoch': 21.3}
{'loss': 0.012, 'grad_norm': 5.122777462005615, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.00767354853451252, 'loss_2': 0.004364013671875, 'loss_3': -16.3006591796875, 'loss_4': 0.8619546890258789, 'epoch': 21.3}
{'loss': 0.0072, 'grad_norm': 4.864152431488037, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.004702051170170307, 'loss_2': 0.0025348663330078125, 'loss_3': -16.60614776611328, 'loss_4': 0.9568815231323242, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 16:47:45,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:45,532 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:39<25:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:47:52,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01729239523410797, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.798, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.014813465997576714, 'eval_loss_2': 0.0024789273738861084, 'eval_loss_3': -18.128150939941406, 'eval_loss_4': 0.9441983699798584, 'epoch': 21.31}
{'loss': 0.0092, 'grad_norm': 5.083385944366455, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.0075840516947209835, 'loss_2': 0.00164031982421875, 'loss_3': -16.367483139038086, 'loss_4': 0.8785132765769958, 'epoch': 21.31}
{'loss': 0.0253, 'grad_norm': 15.508801460266113, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.015823321416974068, 'loss_2': 0.0094757080078125, 'loss_3': -16.585636138916016, 'loss_4': 1.1512372493743896, 'epoch': 21.32}
{'loss': 0.0101, 'grad_norm': 5.238963603973389, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.00733812153339386, 'loss_2': 0.002712249755859375, 'loss_3': -16.357908248901367, 'loss_4': 0.9412986040115356, 'epoch': 21.33}
{'loss': 0.0104, 'grad_norm': 5.331493377685547, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.00854093674570322, 'loss_2': 0.0018138885498046875, 'loss_3': -16.13187599182129, 'loss_4': 0.7383782863616943, 'epoch': 21.33}
{'loss': 0.0141, 'grad_norm': 4.9737138748168945, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.006825359538197517, 'loss_2': 0.0072784423828125, 'loss_3': -16.309528350830078, 'loss_4': 0.7287728786468506, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 16:47:52,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:47:52,865 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:46<25:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:00,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017936652526259422, 'eval_runtime': 3.796, 'eval_samples_per_second': 269.758, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.016024326905608177, 'eval_loss_2': 0.0019123256206512451, 'eval_loss_3': -18.124248504638672, 'eval_loss_4': 0.7757499814033508, 'epoch': 21.34}
{'loss': 0.0112, 'grad_norm': 5.642327785491943, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.007871278561651707, 'loss_2': 0.0033245086669921875, 'loss_3': -16.351871490478516, 'loss_4': 0.7129321098327637, 'epoch': 21.34}
{'loss': 0.0119, 'grad_norm': 5.878586292266846, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.01070006936788559, 'loss_2': 0.0011806488037109375, 'loss_3': -16.47028160095215, 'loss_4': 0.5683633089065552, 'epoch': 21.35}
{'loss': 0.0104, 'grad_norm': 5.281385898590088, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.007703823037445545, 'loss_2': 0.0026493072509765625, 'loss_3': -16.253671646118164, 'loss_4': 0.7082874774932861, 'epoch': 21.35}
{'loss': 0.0168, 'grad_norm': 4.515142917633057, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.0035609693732112646, 'loss_2': 0.0132293701171875, 'loss_3': -16.511741638183594, 'loss_4': 0.7641119956970215, 'epoch': 21.36}
{'loss': 0.0071, 'grad_norm': 4.314891815185547, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.0037969411350786686, 'loss_2': 0.00331878662109375, 'loss_3': -16.57835578918457, 'loss_4': 0.4994748830795288, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 16:48:00,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:00,195 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:30:54<25:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:07,526 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020831339061260223, 'eval_runtime': 3.7956, 'eval_samples_per_second': 269.788, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.017541848123073578, 'eval_loss_2': 0.0032894909381866455, 'eval_loss_3': -18.1064395904541, 'eval_loss_4': 0.7504220008850098, 'epoch': 21.37}
{'loss': 0.0075, 'grad_norm': 17.32846450805664, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.005645317956805229, 'loss_2': 0.0018367767333984375, 'loss_3': -16.495927810668945, 'loss_4': 0.7138381004333496, 'epoch': 21.37}
{'loss': 0.0084, 'grad_norm': 4.181748867034912, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.0029599680565297604, 'loss_2': 0.005401611328125, 'loss_3': -16.323211669921875, 'loss_4': 0.550849437713623, 'epoch': 21.38}
{'loss': 0.02, 'grad_norm': 7.894070625305176, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.014052025973796844, 'loss_2': 0.005950927734375, 'loss_3': -16.40540313720703, 'loss_4': 0.6396149396896362, 'epoch': 21.38}
{'loss': 0.0131, 'grad_norm': 7.101655006408691, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.009333797730505466, 'loss_2': 0.0037841796875, 'loss_3': -16.327455520629883, 'loss_4': 0.9077745079994202, 'epoch': 21.39}
{'loss': 0.0183, 'grad_norm': 4.821287155151367, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.008790259249508381, 'loss_2': 0.00952911376953125, 'loss_3': -16.281347274780273, 'loss_4': 0.3069033920764923, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 16:48:07,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:07,526 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:31:01<25:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:14,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023292209953069687, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.116, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020530758425593376, 'eval_loss_2': 0.00276145339012146, 'eval_loss_3': -18.086776733398438, 'eval_loss_4': 0.8132723569869995, 'epoch': 21.4}
{'loss': 0.0075, 'grad_norm': 4.963454246520996, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.0055808196775615215, 'loss_2': 0.001949310302734375, 'loss_3': -16.456371307373047, 'loss_4': 0.7196351289749146, 'epoch': 21.4}
{'loss': 0.0097, 'grad_norm': 4.676088809967041, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.007968561723828316, 'loss_2': 0.0016984939575195312, 'loss_3': -16.22777557373047, 'loss_4': 0.7003139853477478, 'epoch': 21.41}
{'loss': 0.0205, 'grad_norm': 8.477578163146973, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.013135253451764584, 'loss_2': 0.007343292236328125, 'loss_3': -16.257408142089844, 'loss_4': 1.2205445766448975, 'epoch': 21.41}
{'loss': 0.0113, 'grad_norm': 8.067184448242188, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.010620747692883015, 'loss_2': 0.0007143020629882812, 'loss_3': -16.417198181152344, 'loss_4': 0.8260143399238586, 'epoch': 21.42}
{'loss': 0.0133, 'grad_norm': 8.557808876037598, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.012482864782214165, 'loss_2': 0.0008554458618164062, 'loss_3': -16.473556518554688, 'loss_4': 0.9417963027954102, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 16:48:14,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:14,872 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:31:08<25:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:22,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023675329983234406, 'eval_runtime': 3.7946, 'eval_samples_per_second': 269.854, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0209944024682045, 'eval_loss_2': 0.0026809275150299072, 'eval_loss_3': -18.09619140625, 'eval_loss_4': 0.9047046899795532, 'epoch': 21.42}
{'loss': 0.0119, 'grad_norm': 4.795023441314697, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.010110403411090374, 'loss_2': 0.0017490386962890625, 'loss_3': -16.43839454650879, 'loss_4': 0.8787515163421631, 'epoch': 21.43}
{'loss': 0.01, 'grad_norm': 5.232508659362793, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.007036664057523012, 'loss_2': 0.0029449462890625, 'loss_3': -16.315166473388672, 'loss_4': 0.844292402267456, 'epoch': 21.44}
{'loss': 0.0031, 'grad_norm': 4.817257404327393, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.0023385747335851192, 'loss_2': 0.0007877349853515625, 'loss_3': -16.378517150878906, 'loss_4': 0.8820980191230774, 'epoch': 21.44}
{'loss': 0.007, 'grad_norm': 4.765883445739746, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.0051332153379917145, 'loss_2': 0.0018463134765625, 'loss_3': -16.142499923706055, 'loss_4': 0.9070705771446228, 'epoch': 21.45}
{'loss': 0.013, 'grad_norm': 6.0311431884765625, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.009325959719717503, 'loss_2': 0.0037021636962890625, 'loss_3': -16.38207244873047, 'loss_4': 1.2638254165649414, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 16:48:22,205 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:22,205 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:31:16<25:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:29,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026779530569911003, 'eval_runtime': 3.7951, 'eval_samples_per_second': 269.819, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.022449729964137077, 'eval_loss_2': 0.004329800605773926, 'eval_loss_3': -18.083452224731445, 'eval_loss_4': 0.8553845882415771, 'epoch': 21.45}
{'loss': 0.02, 'grad_norm': 7.371757984161377, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.010333161801099777, 'loss_2': 0.00965118408203125, 'loss_3': -16.372814178466797, 'loss_4': 0.8571885824203491, 'epoch': 21.46}
{'loss': 0.019, 'grad_norm': 6.415572166442871, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.013274000026285648, 'loss_2': 0.0057525634765625, 'loss_3': -16.277376174926758, 'loss_4': 1.1571528911590576, 'epoch': 21.47}
{'loss': 0.0066, 'grad_norm': 4.460299491882324, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.0030954445246607065, 'loss_2': 0.003513336181640625, 'loss_3': -16.377044677734375, 'loss_4': 0.7296890020370483, 'epoch': 21.47}
{'loss': 0.0078, 'grad_norm': 5.020358562469482, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.005367810372263193, 'loss_2': 0.002437591552734375, 'loss_3': -16.26488494873047, 'loss_4': 0.7449641227722168, 'epoch': 21.48}
{'loss': 0.009, 'grad_norm': 4.468156814575195, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.005936068948358297, 'loss_2': 0.00310516357421875, 'loss_3': -16.498287200927734, 'loss_4': 1.147175669670105, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 16:48:29,540 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:29,540 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:23<25:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:36,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027115581557154655, 'eval_runtime': 3.794, 'eval_samples_per_second': 269.898, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.023670023307204247, 'eval_loss_2': 0.003445558249950409, 'eval_loss_3': -18.082962036132812, 'eval_loss_4': 0.8647536039352417, 'epoch': 21.48}
{'loss': 0.0085, 'grad_norm': 4.655842304229736, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.0036752205342054367, 'loss_2': 0.00482177734375, 'loss_3': -16.3389892578125, 'loss_4': 0.45597195625305176, 'epoch': 21.49}
{'loss': 0.02, 'grad_norm': 9.049726486206055, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.019840441644191742, 'loss_2': 0.00011038780212402344, 'loss_3': -16.361230850219727, 'loss_4': 1.0531835556030273, 'epoch': 21.49}
{'loss': 0.0075, 'grad_norm': 5.676008224487305, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.0057547129690647125, 'loss_2': 0.0017490386962890625, 'loss_3': -16.17303466796875, 'loss_4': 0.7760529518127441, 'epoch': 21.5}
{'loss': 0.0061, 'grad_norm': 5.08031702041626, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0042009856551885605, 'loss_2': 0.0019073486328125, 'loss_3': -16.186717987060547, 'loss_4': 1.0736398696899414, 'epoch': 21.51}
{'loss': 0.0103, 'grad_norm': 4.6680169105529785, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.0059426045045256615, 'loss_2': 0.004405975341796875, 'loss_3': -16.38214111328125, 'loss_4': 0.7998104691505432, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 16:48:36,866 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:36,866 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:30<25:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:44,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028179720044136047, 'eval_runtime': 3.7959, 'eval_samples_per_second': 269.766, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0251753106713295, 'eval_loss_2': 0.003004409372806549, 'eval_loss_3': -18.078428268432617, 'eval_loss_4': 0.8562827706336975, 'epoch': 21.51}
{'loss': 0.0165, 'grad_norm': 6.234268665313721, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.01158109586685896, 'loss_2': 0.004917144775390625, 'loss_3': -16.23208236694336, 'loss_4': 1.0837676525115967, 'epoch': 21.52}
{'loss': 0.0218, 'grad_norm': 6.081623554229736, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.013338013552129269, 'loss_2': 0.00847625732421875, 'loss_3': -16.245738983154297, 'loss_4': 1.477264165878296, 'epoch': 21.52}
{'loss': 0.0177, 'grad_norm': 5.760355472564697, 'learning_rate': 8.5e-06, 'loss_1': 0.008802887983620167, 'loss_2': 0.0088653564453125, 'loss_3': -16.209871292114258, 'loss_4': 0.5972741842269897, 'epoch': 21.53}
{'loss': 0.0124, 'grad_norm': 5.045964241027832, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.006412146147340536, 'loss_2': 0.00594329833984375, 'loss_3': -16.383089065551758, 'loss_4': 0.8796491622924805, 'epoch': 21.53}
{'loss': 0.0074, 'grad_norm': 4.687689781188965, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.005179510917514563, 'loss_2': 0.00220489501953125, 'loss_3': -16.496549606323242, 'loss_4': 1.2883778810501099, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 16:48:44,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:44,204 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:38<25:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:51,546 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025412917137145996, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.022763922810554504, 'eval_loss_2': 0.0026489943265914917, 'eval_loss_3': -18.088943481445312, 'eval_loss_4': 0.9010888934135437, 'epoch': 21.54}
{'loss': 0.0056, 'grad_norm': 4.795774459838867, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.005127682816237211, 'loss_2': 0.0004489421844482422, 'loss_3': -16.238649368286133, 'loss_4': 0.9416121244430542, 'epoch': 21.55}
{'loss': 0.0246, 'grad_norm': 9.313231468200684, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.014262346550822258, 'loss_2': 0.01029205322265625, 'loss_3': -16.310230255126953, 'loss_4': 0.9235012531280518, 'epoch': 21.55}
{'loss': 0.0126, 'grad_norm': 6.168278694152832, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.008869953453540802, 'loss_2': 0.003688812255859375, 'loss_3': -16.477977752685547, 'loss_4': 0.9483502507209778, 'epoch': 21.56}
{'loss': 0.006, 'grad_norm': 4.7485151290893555, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.005344696342945099, 'loss_2': 0.0006818771362304688, 'loss_3': -16.320106506347656, 'loss_4': 1.0994287729263306, 'epoch': 21.56}
{'loss': 0.0066, 'grad_norm': 4.8559746742248535, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.004259677603840828, 'loss_2': 0.0023174285888671875, 'loss_3': -16.505355834960938, 'loss_4': 0.7221022248268127, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 16:48:51,546 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:51,546 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:45<24:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:48:58,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024737391620874405, 'eval_runtime': 3.7984, 'eval_samples_per_second': 269.587, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.021120501682162285, 'eval_loss_2': 0.0036168918013572693, 'eval_loss_3': -18.079174041748047, 'eval_loss_4': 0.9825555682182312, 'epoch': 21.57}
{'loss': 0.025, 'grad_norm': 9.96069049835205, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.024858549237251282, 'loss_2': 0.00017118453979492188, 'loss_3': -16.230743408203125, 'loss_4': 0.838428795337677, 'epoch': 21.58}
{'loss': 0.0154, 'grad_norm': 4.961121559143066, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.00695099588483572, 'loss_2': 0.008453369140625, 'loss_3': -16.48007583618164, 'loss_4': 0.5901713371276855, 'epoch': 21.58}
{'loss': 0.0113, 'grad_norm': 4.664909362792969, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.005600155331194401, 'loss_2': 0.005672454833984375, 'loss_3': -16.652362823486328, 'loss_4': 1.0283069610595703, 'epoch': 21.59}
{'loss': 0.0133, 'grad_norm': 6.25152587890625, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.011263708584010601, 'loss_2': 0.0020751953125, 'loss_3': -16.328975677490234, 'loss_4': 0.740744948387146, 'epoch': 21.59}
{'loss': 0.0749, 'grad_norm': 9.728045463562012, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.07362294942140579, 'loss_2': 0.0012912750244140625, 'loss_3': -16.27667999267578, 'loss_4': 1.316286325454712, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 16:48:58,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:48:58,877 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:31:52<24:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:49:06,205 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022522268816828728, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.816, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01837480068206787, 'eval_loss_2': 0.004147469997406006, 'eval_loss_3': -18.093976974487305, 'eval_loss_4': 1.0040303468704224, 'epoch': 21.6}
{'loss': 0.0105, 'grad_norm': 4.451458930969238, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.004316628444939852, 'loss_2': 0.00623321533203125, 'loss_3': -16.5960693359375, 'loss_4': 0.8469430208206177, 'epoch': 21.6}
{'loss': 0.0081, 'grad_norm': 4.820408821105957, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.007153918966650963, 'loss_2': 0.000896453857421875, 'loss_3': -16.21808433532715, 'loss_4': 1.4617488384246826, 'epoch': 21.61}
{'loss': 0.0096, 'grad_norm': 5.127554893493652, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.008104492910206318, 'loss_2': 0.001514434814453125, 'loss_3': -16.357704162597656, 'loss_4': 1.224927544593811, 'epoch': 21.62}
{'loss': 0.0121, 'grad_norm': 5.362888336181641, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.0061597926542162895, 'loss_2': 0.00597381591796875, 'loss_3': -16.426898956298828, 'loss_4': 1.1636903285980225, 'epoch': 21.62}
{'loss': 0.0111, 'grad_norm': 4.134683132171631, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.005638923496007919, 'loss_2': 0.0054779052734375, 'loss_3': -16.562175750732422, 'loss_4': 1.2193613052368164, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 16:49:06,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:06,206 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:32:00<24:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:49:13,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01939818635582924, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.799, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0169081874191761, 'eval_loss_2': 0.002489998936653137, 'eval_loss_3': -18.108381271362305, 'eval_loss_4': 0.9720921516418457, 'epoch': 21.63}
{'loss': 0.0134, 'grad_norm': 6.131381034851074, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.01321219839155674, 'loss_2': 0.00014019012451171875, 'loss_3': -16.45705223083496, 'loss_4': 1.0916988849639893, 'epoch': 21.63}
{'loss': 0.0072, 'grad_norm': 4.809504985809326, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.005656924564391375, 'loss_2': 0.00156402587890625, 'loss_3': -16.397464752197266, 'loss_4': 1.2839573621749878, 'epoch': 21.64}
{'loss': 0.0175, 'grad_norm': 5.236954212188721, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.008399930782616138, 'loss_2': 0.009124755859375, 'loss_3': -16.3444766998291, 'loss_4': 0.7577797174453735, 'epoch': 21.65}
{'loss': 0.0154, 'grad_norm': 4.68539571762085, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.006059007253497839, 'loss_2': 0.00931549072265625, 'loss_3': -16.209693908691406, 'loss_4': 1.2153334617614746, 'epoch': 21.65}
{'loss': 0.0076, 'grad_norm': 5.05576753616333, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.006881301756948233, 'loss_2': 0.0007381439208984375, 'loss_3': -16.306076049804688, 'loss_4': 1.064338207244873, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 16:49:13,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:13,534 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:32:07<24:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:20,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018950745463371277, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.321, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01613532193005085, 'eval_loss_2': 0.002815425395965576, 'eval_loss_3': -18.107559204101562, 'eval_loss_4': 0.9246841073036194, 'epoch': 21.66}
{'loss': 0.0158, 'grad_norm': 5.811808109283447, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.01284103561192751, 'loss_2': 0.002933502197265625, 'loss_3': -16.283615112304688, 'loss_4': 0.8927933573722839, 'epoch': 21.66}
{'loss': 0.0313, 'grad_norm': 8.157557487487793, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.026946278288960457, 'loss_2': 0.00438690185546875, 'loss_3': -16.224048614501953, 'loss_4': 1.147470235824585, 'epoch': 21.67}
{'loss': 0.0107, 'grad_norm': 4.909039497375488, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.009465503506362438, 'loss_2': 0.0012836456298828125, 'loss_3': -16.292573928833008, 'loss_4': 0.6236985325813293, 'epoch': 21.67}
{'loss': 0.0107, 'grad_norm': 4.511332988739014, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.006089168135076761, 'loss_2': 0.0046234130859375, 'loss_3': -16.476638793945312, 'loss_4': 1.0754097700119019, 'epoch': 21.68}
{'loss': 0.0136, 'grad_norm': 5.060605049133301, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.008252937346696854, 'loss_2': 0.00533294677734375, 'loss_3': -16.469276428222656, 'loss_4': 0.8539881110191345, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 16:49:20,880 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:20,880 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:32:14<24:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:28,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018558010458946228, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.211, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.016180530190467834, 'eval_loss_2': 0.0023774802684783936, 'eval_loss_3': -18.10726547241211, 'eval_loss_4': 0.913338303565979, 'epoch': 21.69}
{'loss': 0.0055, 'grad_norm': 5.544246196746826, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.005505122244358063, 'loss_2': 1.1622905731201172e-05, 'loss_3': -16.46723175048828, 'loss_4': 1.0361666679382324, 'epoch': 21.69}
{'loss': 0.008, 'grad_norm': 5.261297702789307, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.006412584334611893, 'loss_2': 0.0015735626220703125, 'loss_3': -16.419342041015625, 'loss_4': 0.6500376462936401, 'epoch': 21.7}
{'loss': 0.0136, 'grad_norm': 6.14101505279541, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.01134475413709879, 'loss_2': 0.0023040771484375, 'loss_3': -16.10505485534668, 'loss_4': 0.9154331684112549, 'epoch': 21.7}
{'loss': 0.0109, 'grad_norm': 5.009127140045166, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.007066688500344753, 'loss_2': 0.0037841796875, 'loss_3': -16.152015686035156, 'loss_4': 1.3003500699996948, 'epoch': 21.71}
{'loss': 0.011, 'grad_norm': 4.5953474044799805, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.005015391856431961, 'loss_2': 0.00594329833984375, 'loss_3': -16.214553833007812, 'loss_4': 0.952243983745575, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 16:49:28,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:28,231 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:22<24:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:35,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019178444519639015, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.393, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01654268428683281, 'eval_loss_2': 0.002635762095451355, 'eval_loss_3': -18.107059478759766, 'eval_loss_4': 0.9293198585510254, 'epoch': 21.72}
{'loss': 0.0088, 'grad_norm': 4.224672317504883, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.006601504981517792, 'loss_2': 0.00217437744140625, 'loss_3': -16.287818908691406, 'loss_4': 0.9605187177658081, 'epoch': 21.72}
{'loss': 0.0139, 'grad_norm': 6.131308078765869, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.007370007690042257, 'loss_2': 0.00656890869140625, 'loss_3': -16.26891326904297, 'loss_4': 0.4959985613822937, 'epoch': 21.73}
{'loss': 0.0052, 'grad_norm': 4.730095386505127, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.0048316591419279575, 'loss_2': 0.0003566741943359375, 'loss_3': -16.508834838867188, 'loss_4': 0.9202574491500854, 'epoch': 21.73}
{'loss': 0.018, 'grad_norm': 7.360666751861572, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.017503101378679276, 'loss_2': 0.00049591064453125, 'loss_3': -16.522258758544922, 'loss_4': 0.6829472780227661, 'epoch': 21.74}
{'loss': 0.0058, 'grad_norm': 4.424487113952637, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.004802222363650799, 'loss_2': 0.0009613037109375, 'loss_3': -16.45582389831543, 'loss_4': 0.8769199252128601, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 16:49:35,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:35,601 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:29<24:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:42,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020634129643440247, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016839371994137764, 'eval_loss_2': 0.003794759511947632, 'eval_loss_3': -18.08738899230957, 'eval_loss_4': 0.8187724947929382, 'epoch': 21.74}
{'loss': 0.0147, 'grad_norm': 7.087182998657227, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.012531334534287453, 'loss_2': 0.00214385986328125, 'loss_3': -16.257780075073242, 'loss_4': 0.8205241560935974, 'epoch': 21.75}
{'loss': 0.0146, 'grad_norm': 7.563353538513184, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.012819189578294754, 'loss_2': 0.0017566680908203125, 'loss_3': -16.44472885131836, 'loss_4': 0.2838156819343567, 'epoch': 21.76}
{'loss': 0.0115, 'grad_norm': 6.1145548820495605, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.008814627304673195, 'loss_2': 0.002704620361328125, 'loss_3': -16.42218017578125, 'loss_4': 0.9492709040641785, 'epoch': 21.76}
{'loss': 0.0137, 'grad_norm': 6.006124973297119, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.0074305543676018715, 'loss_2': 0.006275177001953125, 'loss_3': -16.214847564697266, 'loss_4': 0.30253323912620544, 'epoch': 21.77}
{'loss': 0.0084, 'grad_norm': 5.353147029876709, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.008034052327275276, 'loss_2': 0.00034618377685546875, 'loss_3': -16.361637115478516, 'loss_4': 0.40028882026672363, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 16:49:42,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:42,959 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:36<24:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:50,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021154923364520073, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.974, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.017221365123987198, 'eval_loss_2': 0.003933560103178024, 'eval_loss_3': -18.06647491455078, 'eval_loss_4': 0.6934598684310913, 'epoch': 21.77}
{'loss': 0.0102, 'grad_norm': 5.407748222351074, 'learning_rate': 8.25e-06, 'loss_1': 0.007306803949177265, 'loss_2': 0.0029048919677734375, 'loss_3': -16.445152282714844, 'loss_4': 0.852918803691864, 'epoch': 21.78}
{'loss': 0.0243, 'grad_norm': 9.131921768188477, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.022122777998447418, 'loss_2': 0.0022068023681640625, 'loss_3': -16.301799774169922, 'loss_4': 0.7466148734092712, 'epoch': 21.78}
{'loss': 0.0061, 'grad_norm': 4.32012939453125, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.005099061876535416, 'loss_2': 0.0010204315185546875, 'loss_3': -16.295503616333008, 'loss_4': 0.9413981437683105, 'epoch': 21.79}
{'loss': 0.0129, 'grad_norm': 7.776186466217041, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.011807559058070183, 'loss_2': 0.0010852813720703125, 'loss_3': -16.126747131347656, 'loss_4': 0.7928265333175659, 'epoch': 21.8}
{'loss': 0.0128, 'grad_norm': 5.26699686050415, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.00837718416005373, 'loss_2': 0.00440216064453125, 'loss_3': -16.479948043823242, 'loss_4': 0.7674763798713684, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 16:49:50,309 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:50,309 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:44<24:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:49:57,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01960466429591179, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.359, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.016909342259168625, 'eval_loss_2': 0.002695322036743164, 'eval_loss_3': -18.068971633911133, 'eval_loss_4': 0.5966405272483826, 'epoch': 21.8}
{'loss': 0.0062, 'grad_norm': 5.245814323425293, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.006086403504014015, 'loss_2': 6.663799285888672e-05, 'loss_3': -16.353347778320312, 'loss_4': 0.9156464338302612, 'epoch': 21.81}
{'loss': 0.006, 'grad_norm': 4.467406272888184, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.0032273002434521914, 'loss_2': 0.002803802490234375, 'loss_3': -16.33034896850586, 'loss_4': 0.37237533926963806, 'epoch': 21.81}
{'loss': 0.0075, 'grad_norm': 4.421561241149902, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.005412275902926922, 'loss_2': 0.00212860107421875, 'loss_3': -16.4619140625, 'loss_4': 0.5468883514404297, 'epoch': 21.82}
{'loss': 0.0137, 'grad_norm': 6.1562676429748535, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.012684741988778114, 'loss_2': 0.0010194778442382812, 'loss_3': -16.429367065429688, 'loss_4': 0.5839263200759888, 'epoch': 21.83}
{'loss': 0.0087, 'grad_norm': 5.392997741699219, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.00666354363784194, 'loss_2': 0.0020599365234375, 'loss_3': -16.17761993408203, 'loss_4': 0.5461328029632568, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 16:49:57,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:49:57,655 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:32:51<24:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:05,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01968158222734928, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.033, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.016185054555535316, 'eval_loss_2': 0.003496527671813965, 'eval_loss_3': -18.079830169677734, 'eval_loss_4': 0.4408275783061981, 'epoch': 21.83}
{'loss': 0.0083, 'grad_norm': 5.01175594329834, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.004652444738894701, 'loss_2': 0.0036067962646484375, 'loss_3': -16.126811981201172, 'loss_4': 0.5533856153488159, 'epoch': 21.84}
{'loss': 0.0132, 'grad_norm': 9.468252182006836, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.011849245056509972, 'loss_2': 0.0013828277587890625, 'loss_3': -16.568115234375, 'loss_4': 0.2680182456970215, 'epoch': 21.84}
{'loss': 0.0183, 'grad_norm': 5.899023532867432, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.010306429117918015, 'loss_2': 0.00800323486328125, 'loss_3': -16.49285125732422, 'loss_4': 0.22484351694583893, 'epoch': 21.85}
{'loss': 0.0136, 'grad_norm': 4.967708110809326, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.009869224391877651, 'loss_2': 0.003704071044921875, 'loss_3': -16.353893280029297, 'loss_4': 0.10242272913455963, 'epoch': 21.85}
{'loss': 0.0297, 'grad_norm': 16.254133224487305, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.028888648375868797, 'loss_2': 0.0008287429809570312, 'loss_3': -16.37253189086914, 'loss_4': 0.4509153366088867, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 16:50:05,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:05,003 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:32:58<24:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:12,342 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02051817625761032, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.27, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01595943421125412, 'eval_loss_2': 0.004558742046356201, 'eval_loss_3': -18.092533111572266, 'eval_loss_4': 0.25538182258605957, 'epoch': 21.86}
{'loss': 0.0176, 'grad_norm': 9.234709739685059, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.012599596753716469, 'loss_2': 0.005046844482421875, 'loss_3': -16.38519859313965, 'loss_4': 0.22062963247299194, 'epoch': 21.87}
{'loss': 0.0189, 'grad_norm': 6.146975994110107, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.01621023751795292, 'loss_2': 0.0026569366455078125, 'loss_3': -16.296092987060547, 'loss_4': 0.3047596216201782, 'epoch': 21.87}
{'loss': 0.0096, 'grad_norm': 5.555404186248779, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.009185357950627804, 'loss_2': 0.00041365623474121094, 'loss_3': -16.376251220703125, 'loss_4': 0.13868170976638794, 'epoch': 21.88}
{'loss': 0.0099, 'grad_norm': 5.523116588592529, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.006721946876496077, 'loss_2': 0.00319671630859375, 'loss_3': -16.16868019104004, 'loss_4': 0.39826133847236633, 'epoch': 21.88}
{'loss': 0.0194, 'grad_norm': 5.406082630157471, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.009219203144311905, 'loss_2': 0.010223388671875, 'loss_3': -16.098522186279297, 'loss_4': 0.15837766230106354, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 16:50:12,342 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:12,342 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:33:06<24:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:19,696 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018471812829375267, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014867667108774185, 'eval_loss_2': 0.0036041438579559326, 'eval_loss_3': -18.090486526489258, 'eval_loss_4': 0.17006278038024902, 'epoch': 21.89}
{'loss': 0.0116, 'grad_norm': 5.224254131317139, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.007456653751432896, 'loss_2': 0.0041351318359375, 'loss_3': -16.33331871032715, 'loss_4': 0.27474454045295715, 'epoch': 21.9}
{'loss': 0.0085, 'grad_norm': 5.207908630371094, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.00392660079523921, 'loss_2': 0.00455474853515625, 'loss_3': -16.452695846557617, 'loss_4': 0.20384864509105682, 'epoch': 21.9}
{'loss': 0.0113, 'grad_norm': 6.406723976135254, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.008708124049007893, 'loss_2': 0.0026035308837890625, 'loss_3': -16.341081619262695, 'loss_4': 0.3693975806236267, 'epoch': 21.91}
{'loss': 0.0316, 'grad_norm': 14.678812026977539, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.030487162992358208, 'loss_2': 0.001102447509765625, 'loss_3': -16.368797302246094, 'loss_4': 0.04258889704942703, 'epoch': 21.91}
{'loss': 0.0113, 'grad_norm': 4.338591575622559, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.008099174126982689, 'loss_2': 0.003154754638671875, 'loss_3': -16.440780639648438, 'loss_4': 0.3571881651878357, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 16:50:19,696 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:19,696 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:33:13<23:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:27,045 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018248824402689934, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.36, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01354625541716814, 'eval_loss_2': 0.004702568054199219, 'eval_loss_3': -18.122257232666016, 'eval_loss_4': 0.2008661925792694, 'epoch': 21.92}
{'loss': 0.0157, 'grad_norm': 5.340092658996582, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.00852653943002224, 'loss_2': 0.00719451904296875, 'loss_3': -16.356107711791992, 'loss_4': 0.04581180214881897, 'epoch': 21.92}
{'loss': 0.0171, 'grad_norm': 8.525242805480957, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.01045698206871748, 'loss_2': 0.006687164306640625, 'loss_3': -16.422208786010742, 'loss_4': 0.2835586667060852, 'epoch': 21.93}
{'loss': 0.0092, 'grad_norm': 4.797754287719727, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.004086303990334272, 'loss_2': 0.00508880615234375, 'loss_3': -16.544227600097656, 'loss_4': 0.2720849812030792, 'epoch': 21.94}
{'loss': 0.0251, 'grad_norm': 12.316628456115723, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.014391684904694557, 'loss_2': 0.01067352294921875, 'loss_3': -16.493541717529297, 'loss_4': 0.45437386631965637, 'epoch': 21.94}
{'loss': 0.011, 'grad_norm': 6.163768768310547, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.007959668524563313, 'loss_2': 0.00304412841796875, 'loss_3': -16.28093910217285, 'loss_4': 0.08871962875127792, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 16:50:27,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:27,045 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:20<23:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:34,390 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01705285720527172, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.367, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010668424889445305, 'eval_loss_2': 0.006384432315826416, 'eval_loss_3': -18.147396087646484, 'eval_loss_4': 0.25973665714263916, 'epoch': 21.95}
{'loss': 0.0231, 'grad_norm': 15.065605163574219, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.020312724635004997, 'loss_2': 0.002773284912109375, 'loss_3': -16.501075744628906, 'loss_4': -0.08358215540647507, 'epoch': 21.95}
{'loss': 0.0256, 'grad_norm': 12.76427173614502, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.022507676854729652, 'loss_2': 0.003124237060546875, 'loss_3': -16.44866943359375, 'loss_4': 0.15735703706741333, 'epoch': 21.96}
{'loss': 0.0064, 'grad_norm': 4.688777923583984, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.004517211113125086, 'loss_2': 0.0019159317016601562, 'loss_3': -16.406980514526367, 'loss_4': 0.23830558359622955, 'epoch': 21.97}
{'loss': 0.0746, 'grad_norm': 17.768352508544922, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.07452256232500076, 'loss_2': 7.05718994140625e-05, 'loss_3': -16.32780647277832, 'loss_4': 0.06504300236701965, 'epoch': 21.97}
{'loss': 0.0141, 'grad_norm': 4.818612575531006, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.0031924231443554163, 'loss_2': 0.01087188720703125, 'loss_3': -16.515161514282227, 'loss_4': 0.2671358585357666, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 16:50:34,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:34,390 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:28<22:25,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 16:50:41,431 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014711606316268444, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009414153173565865, 'eval_loss_2': 0.005297452211380005, 'eval_loss_3': -18.166015625, 'eval_loss_4': 0.35918423533439636, 'epoch': 21.98}
{'loss': 0.0132, 'grad_norm': 5.6736578941345215, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.008097358979284763, 'loss_2': 0.005077362060546875, 'loss_3': -16.311176300048828, 'loss_4': 0.5556632280349731, 'epoch': 21.98}
{'loss': 0.0116, 'grad_norm': 6.197452545166016, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.009276501834392548, 'loss_2': 0.0023593902587890625, 'loss_3': -16.475826263427734, 'loss_4': 0.34227728843688965, 'epoch': 21.99}
{'loss': 0.0064, 'grad_norm': 4.712347030639648, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.004022912587970495, 'loss_2': 0.0023670196533203125, 'loss_3': -16.348533630371094, 'loss_4': 0.2591835856437683, 'epoch': 21.99}
{'loss': 0.0054, 'grad_norm': 6.265349388122559, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.004741608165204525, 'loss_2': 0.0006260871887207031, 'loss_3': -16.64148712158203, 'loss_4': 0.6301047801971436, 'epoch': 22.0}
{'loss': 0.0059, 'grad_norm': 5.415103912353516, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.005803871899843216, 'loss_2': 4.649162292480469e-05, 'loss_3': -16.613231658935547, 'loss_4': 1.015774130821228, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 16:50:41,431 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:41,431 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:35<23:28,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:50:48,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01286876667290926, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009434466250240803, 'eval_loss_2': 0.003434300422668457, 'eval_loss_3': -18.15110969543457, 'eval_loss_4': 0.4481710195541382, 'epoch': 22.01}
{'loss': 0.0342, 'grad_norm': 13.680837631225586, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.03152887895703316, 'loss_2': 0.002689361572265625, 'loss_3': -16.26698875427246, 'loss_4': -0.0702611431479454, 'epoch': 22.01}
{'loss': 0.0063, 'grad_norm': 4.964271545410156, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.00512770377099514, 'loss_2': 0.0011224746704101562, 'loss_3': -16.430618286132812, 'loss_4': 0.7091677188873291, 'epoch': 22.02}
{'loss': 0.008, 'grad_norm': 4.767744064331055, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.005527250003069639, 'loss_2': 0.0024776458740234375, 'loss_3': -16.61206817626953, 'loss_4': 0.2919238209724426, 'epoch': 22.02}
{'loss': 0.0062, 'grad_norm': 4.453372955322266, 'learning_rate': 8e-06, 'loss_1': 0.005160692613571882, 'loss_2': 0.0010881423950195312, 'loss_3': -16.326663970947266, 'loss_4': 0.6493793725967407, 'epoch': 22.03}
{'loss': 0.0063, 'grad_norm': 4.952679634094238, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.005297486204653978, 'loss_2': 0.0009870529174804688, 'loss_3': -16.075122833251953, 'loss_4': 0.2491392195224762, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 16:50:48,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:48,779 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:42<23:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:50:56,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012583088129758835, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.588, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008993815630674362, 'eval_loss_2': 0.0035892724990844727, 'eval_loss_3': -18.153911590576172, 'eval_loss_4': 0.4125363826751709, 'epoch': 22.03}
{'loss': 0.0106, 'grad_norm': 8.50631332397461, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.0062407683581113815, 'loss_2': 0.0043792724609375, 'loss_3': -16.418537139892578, 'loss_4': 0.24361392855644226, 'epoch': 22.04}
{'loss': 0.0121, 'grad_norm': 12.30953311920166, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.010315329767763615, 'loss_2': 0.0017824172973632812, 'loss_3': -16.466978073120117, 'loss_4': 0.2999018132686615, 'epoch': 22.05}
{'loss': 0.0049, 'grad_norm': 4.774450302124023, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.0047737299464643, 'loss_2': 0.0001537799835205078, 'loss_3': -16.320632934570312, 'loss_4': 0.6508893966674805, 'epoch': 22.05}
{'loss': 0.0113, 'grad_norm': 7.288977146148682, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.010130040347576141, 'loss_2': 0.0011959075927734375, 'loss_3': -16.514894485473633, 'loss_4': 0.3330684006214142, 'epoch': 22.06}
{'loss': 0.0088, 'grad_norm': 5.211445331573486, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.007773315999656916, 'loss_2': 0.001007080078125, 'loss_3': -16.43185043334961, 'loss_4': 0.3537362515926361, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 16:50:56,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:50:56,136 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:50<23:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:03,479 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01216665655374527, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008758921176195145, 'eval_loss_2': 0.003407735377550125, 'eval_loss_3': -18.172637939453125, 'eval_loss_4': 0.38358092308044434, 'epoch': 22.06}
{'loss': 0.0173, 'grad_norm': 8.380603790283203, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.015352499671280384, 'loss_2': 0.00197601318359375, 'loss_3': -16.234111785888672, 'loss_4': 0.20406660437583923, 'epoch': 22.07}
{'loss': 0.0111, 'grad_norm': 5.022517204284668, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.009183268062770367, 'loss_2': 0.00196075439453125, 'loss_3': -16.60393524169922, 'loss_4': 0.5541927814483643, 'epoch': 22.08}
{'loss': 0.0312, 'grad_norm': 9.712517738342285, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.02210446447134018, 'loss_2': 0.0090789794921875, 'loss_3': -16.369834899902344, 'loss_4': 0.7858380079269409, 'epoch': 22.08}
{'loss': 0.0209, 'grad_norm': 14.080859184265137, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.01966751553118229, 'loss_2': 0.0011920928955078125, 'loss_3': -16.58041000366211, 'loss_4': 0.6430343389511108, 'epoch': 22.09}
{'loss': 0.0318, 'grad_norm': 6.459660053253174, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.024803563952445984, 'loss_2': 0.00702667236328125, 'loss_3': -16.35027503967285, 'loss_4': -0.023897916078567505, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 16:51:03,479 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:03,479 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:33:57<23:44,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 16:51:11,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013181895948946476, 'eval_runtime': 3.9966, 'eval_samples_per_second': 256.216, 'eval_steps_per_second': 4.003, 'eval_loss_1': 0.009806731715798378, 'eval_loss_2': 0.0033751651644706726, 'eval_loss_3': -18.169334411621094, 'eval_loss_4': 0.2941555678844452, 'epoch': 22.09}
{'loss': 0.0082, 'grad_norm': 5.374234199523926, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.006628662813454866, 'loss_2': 0.0015468597412109375, 'loss_3': -16.550718307495117, 'loss_4': 0.28891557455062866, 'epoch': 22.1}
{'loss': 0.0138, 'grad_norm': 6.398240089416504, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.0072689601220190525, 'loss_2': 0.0065460205078125, 'loss_3': -16.474803924560547, 'loss_4': 0.0785842314362526, 'epoch': 22.1}
{'loss': 0.0119, 'grad_norm': 4.876834392547607, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.0091865174472332, 'loss_2': 0.0027618408203125, 'loss_3': -16.33333396911621, 'loss_4': 0.639471173286438, 'epoch': 22.11}
{'loss': 0.014, 'grad_norm': 4.825344085693359, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.005398150999099016, 'loss_2': 0.0085906982421875, 'loss_3': -16.371322631835938, 'loss_4': -0.35128718614578247, 'epoch': 22.12}
{'loss': 0.0044, 'grad_norm': 5.8695549964904785, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.00346739892847836, 'loss_2': 0.0009632110595703125, 'loss_3': -16.566251754760742, 'loss_4': 0.26636502146720886, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 16:51:11,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:11,018 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:34:04<23:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:18,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0127244358882308, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009517436847090721, 'eval_loss_2': 0.003206998109817505, 'eval_loss_3': -18.163631439208984, 'eval_loss_4': 0.2641432583332062, 'epoch': 22.12}
{'loss': 0.0081, 'grad_norm': 5.113253116607666, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.00629074964672327, 'loss_2': 0.0017948150634765625, 'loss_3': -16.26739501953125, 'loss_4': 0.6863095760345459, 'epoch': 22.13}
{'loss': 0.0112, 'grad_norm': 5.693685531616211, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.009868292137980461, 'loss_2': 0.0012912750244140625, 'loss_3': -16.37166976928711, 'loss_4': 0.9656981229782104, 'epoch': 22.13}
{'loss': 0.0124, 'grad_norm': 5.939812660217285, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.00781954638659954, 'loss_2': 0.00460052490234375, 'loss_3': -16.420814514160156, 'loss_4': 0.3886956572532654, 'epoch': 22.14}
{'loss': 0.015, 'grad_norm': 5.030942916870117, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.006958479061722755, 'loss_2': 0.0080413818359375, 'loss_3': -16.4862060546875, 'loss_4': 0.14453290402889252, 'epoch': 22.15}
{'loss': 0.0972, 'grad_norm': 21.974512100219727, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.09489700198173523, 'loss_2': 0.0022830963134765625, 'loss_3': -16.609081268310547, 'loss_4': 0.7154139876365662, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 16:51:18,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:18,371 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:34:12<23:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:25,716 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01374082826077938, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.882, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010198227129876614, 'eval_loss_2': 0.003542602062225342, 'eval_loss_3': -18.148345947265625, 'eval_loss_4': 0.2920936346054077, 'epoch': 22.15}
{'loss': 0.0135, 'grad_norm': 5.773754119873047, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.01184803806245327, 'loss_2': 0.001674652099609375, 'loss_3': -16.266122817993164, 'loss_4': -0.01241670548915863, 'epoch': 22.16}
{'loss': 0.0101, 'grad_norm': 8.705780982971191, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.007858113385736942, 'loss_2': 0.002227783203125, 'loss_3': -16.405012130737305, 'loss_4': 0.2692529857158661, 'epoch': 22.16}
{'loss': 0.0111, 'grad_norm': 5.225045680999756, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.006889552343636751, 'loss_2': 0.004222869873046875, 'loss_3': -16.40793228149414, 'loss_4': 0.24598157405853271, 'epoch': 22.17}
{'loss': 0.0097, 'grad_norm': 5.5011115074157715, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.006226519122719765, 'loss_2': 0.003467559814453125, 'loss_3': -16.41208267211914, 'loss_4': 0.18487611413002014, 'epoch': 22.17}
{'loss': 0.0073, 'grad_norm': 4.803471088409424, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.005976511165499687, 'loss_2': 0.0013427734375, 'loss_3': -16.510570526123047, 'loss_4': -0.11101439595222473, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 16:51:25,716 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:25,716 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:19<23:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:33,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014302609488368034, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.59, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011282815597951412, 'eval_loss_2': 0.0030197948217391968, 'eval_loss_3': -18.15728759765625, 'eval_loss_4': 0.348625510931015, 'epoch': 22.18}
{'loss': 0.0167, 'grad_norm': 6.607637405395508, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.009901410900056362, 'loss_2': 0.00675201416015625, 'loss_3': -16.272693634033203, 'loss_4': 0.7314542531967163, 'epoch': 22.19}
{'loss': 0.0098, 'grad_norm': 10.905723571777344, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.005166639108210802, 'loss_2': 0.004638671875, 'loss_3': -16.36846160888672, 'loss_4': 0.45316755771636963, 'epoch': 22.19}
{'loss': 0.0101, 'grad_norm': 4.934229373931885, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.005808042362332344, 'loss_2': 0.004322052001953125, 'loss_3': -16.419612884521484, 'loss_4': -0.12340021133422852, 'epoch': 22.2}
{'loss': 0.1073, 'grad_norm': 21.831575393676758, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.10634148865938187, 'loss_2': 0.0009126663208007812, 'loss_3': -16.276214599609375, 'loss_4': 0.6157525181770325, 'epoch': 22.2}
{'loss': 0.0072, 'grad_norm': 4.862398147583008, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.005924660246819258, 'loss_2': 0.0012340545654296875, 'loss_3': -16.343414306640625, 'loss_4': 0.37698596715927124, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 16:51:33,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:33,076 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:27<23:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:40,436 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015884988009929657, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.697, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01229263935238123, 'eval_loss_2': 0.003592349588871002, 'eval_loss_3': -18.16047477722168, 'eval_loss_4': 0.4215228259563446, 'epoch': 22.21}
{'loss': 0.0153, 'grad_norm': 8.748931884765625, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.013784974813461304, 'loss_2': 0.001514434814453125, 'loss_3': -16.544044494628906, 'loss_4': 0.5827869772911072, 'epoch': 22.22}
{'loss': 0.0094, 'grad_norm': 5.266332626342773, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.008877989836037159, 'loss_2': 0.0005712509155273438, 'loss_3': -16.283966064453125, 'loss_4': 0.318143755197525, 'epoch': 22.22}
{'loss': 0.006, 'grad_norm': 4.101958751678467, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.0037762203719466925, 'loss_2': 0.002216339111328125, 'loss_3': -16.585979461669922, 'loss_4': 0.7691479921340942, 'epoch': 22.23}
{'loss': 0.006, 'grad_norm': 4.553371906280518, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.0033973646350204945, 'loss_2': 0.002643585205078125, 'loss_3': -16.438156127929688, 'loss_4': 0.7310769557952881, 'epoch': 22.23}
{'loss': 0.0279, 'grad_norm': 9.011238098144531, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.022417815402150154, 'loss_2': 0.0054931640625, 'loss_3': -16.281085968017578, 'loss_4': 0.4464300274848938, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 16:51:40,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:40,437 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:34<23:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:47,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01683446764945984, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.096, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012219099327921867, 'eval_loss_2': 0.004615366458892822, 'eval_loss_3': -18.156822204589844, 'eval_loss_4': 0.5182104706764221, 'epoch': 22.24}
{'loss': 0.0107, 'grad_norm': 4.803082466125488, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.008463599719107151, 'loss_2': 0.002201080322265625, 'loss_3': -16.321975708007812, 'loss_4': 0.5855957269668579, 'epoch': 22.24}
{'loss': 0.004, 'grad_norm': 5.226589202880859, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.0030738827772438526, 'loss_2': 0.0009098052978515625, 'loss_3': -16.48345947265625, 'loss_4': 0.31200170516967773, 'epoch': 22.25}
{'loss': 0.0141, 'grad_norm': 7.4244794845581055, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.011093172244727612, 'loss_2': 0.003002166748046875, 'loss_3': -16.266952514648438, 'loss_4': 0.5427882075309753, 'epoch': 22.26}
{'loss': 0.0268, 'grad_norm': 12.627397537231445, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.021864939481019974, 'loss_2': 0.004947662353515625, 'loss_3': -16.205440521240234, 'loss_4': 0.35607653856277466, 'epoch': 22.26}
{'loss': 0.0127, 'grad_norm': 5.995977878570557, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.00906738918274641, 'loss_2': 0.00363922119140625, 'loss_3': -16.48895263671875, 'loss_4': -0.15371018648147583, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 16:51:47,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:47,783 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:41<22:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:51:55,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018119074404239655, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.149, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013359075412154198, 'eval_loss_2': 0.004759997129440308, 'eval_loss_3': -18.15424346923828, 'eval_loss_4': 0.5687981843948364, 'epoch': 22.27}
{'loss': 0.0107, 'grad_norm': 6.109863758087158, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.010525813326239586, 'loss_2': 0.0001289844512939453, 'loss_3': -16.372228622436523, 'loss_4': 0.42480847239494324, 'epoch': 22.27}
{'loss': 0.0163, 'grad_norm': 4.873022556304932, 'learning_rate': 7.75e-06, 'loss_1': 0.008059447631239891, 'loss_2': 0.00823974609375, 'loss_3': -16.379793167114258, 'loss_4': 0.6072341203689575, 'epoch': 22.28}
{'loss': 0.0134, 'grad_norm': 6.425638198852539, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.009176493622362614, 'loss_2': 0.00423431396484375, 'loss_3': -16.410533905029297, 'loss_4': 0.6213866472244263, 'epoch': 22.28}
{'loss': 0.0176, 'grad_norm': 8.416033744812012, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.012956539168953896, 'loss_2': 0.00460052490234375, 'loss_3': -16.322187423706055, 'loss_4': 0.29160094261169434, 'epoch': 22.29}
{'loss': 0.0051, 'grad_norm': 4.46328592300415, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.004011822864413261, 'loss_2': 0.00109100341796875, 'loss_3': -16.551549911499023, 'loss_4': 0.7296870946884155, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 16:51:55,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:51:55,130 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:49<22:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:02,482 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01752937026321888, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013453425839543343, 'eval_loss_2': 0.004075944423675537, 'eval_loss_3': -18.14966583251953, 'eval_loss_4': 0.5240198969841003, 'epoch': 22.3}
{'loss': 0.0063, 'grad_norm': 4.9261651039123535, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.004923523403704166, 'loss_2': 0.0013561248779296875, 'loss_3': -16.404788970947266, 'loss_4': 0.40826550126075745, 'epoch': 22.3}
{'loss': 0.0138, 'grad_norm': 6.258543491363525, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.012244727462530136, 'loss_2': 0.0015230178833007812, 'loss_3': -16.398468017578125, 'loss_4': -0.09306911379098892, 'epoch': 22.31}
{'loss': 0.0142, 'grad_norm': 5.420294761657715, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.009403870441019535, 'loss_2': 0.0048370361328125, 'loss_3': -16.324626922607422, 'loss_4': -0.003589719533920288, 'epoch': 22.31}
{'loss': 0.0082, 'grad_norm': 4.655815124511719, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.006490200757980347, 'loss_2': 0.0017023086547851562, 'loss_3': -16.37441635131836, 'loss_4': 0.5045152902603149, 'epoch': 22.32}
{'loss': 0.0319, 'grad_norm': 9.492680549621582, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.031103065237402916, 'loss_2': 0.0008120536804199219, 'loss_3': -16.537691116333008, 'loss_4': 0.5113507509231567, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 16:52:02,482 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:02,482 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:34:56<22:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:09,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017505593597888947, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014786863699555397, 'eval_loss_2': 0.0027187317609786987, 'eval_loss_3': -18.128488540649414, 'eval_loss_4': 0.5091963410377502, 'epoch': 22.33}
{'loss': 0.0114, 'grad_norm': 5.3976569175720215, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.006709648761898279, 'loss_2': 0.00470733642578125, 'loss_3': -16.56048583984375, 'loss_4': 0.025178536772727966, 'epoch': 22.33}
{'loss': 0.004, 'grad_norm': 21.747983932495117, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.00289862509816885, 'loss_2': 0.0010786056518554688, 'loss_3': -16.455039978027344, 'loss_4': 0.2562216818332672, 'epoch': 22.34}
{'loss': 0.0124, 'grad_norm': 4.974457263946533, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.008700835518538952, 'loss_2': 0.003734588623046875, 'loss_3': -16.433956146240234, 'loss_4': 0.38330480456352234, 'epoch': 22.34}
{'loss': 0.0156, 'grad_norm': 5.290807247161865, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.004744215402752161, 'loss_2': 0.0108642578125, 'loss_3': -16.398900985717773, 'loss_4': 0.07677356153726578, 'epoch': 22.35}
{'loss': 0.0114, 'grad_norm': 4.615520000457764, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.005109610967338085, 'loss_2': 0.0063323974609375, 'loss_3': -16.557334899902344, 'loss_4': 0.2571529746055603, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 16:52:09,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:09,838 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:35:03<22:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:17,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019502824172377586, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.743, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.016366906464099884, 'eval_loss_2': 0.0031359195709228516, 'eval_loss_3': -18.119709014892578, 'eval_loss_4': 0.5220998525619507, 'epoch': 22.35}
{'loss': 0.0097, 'grad_norm': 5.928685188293457, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.009276222437620163, 'loss_2': 0.0003771781921386719, 'loss_3': -16.442453384399414, 'loss_4': 0.270246297121048, 'epoch': 22.36}
{'loss': 0.02, 'grad_norm': 6.591976642608643, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.00890148151665926, 'loss_2': 0.01108551025390625, 'loss_3': -16.196533203125, 'loss_4': 0.11256752908229828, 'epoch': 22.37}
{'loss': 0.0105, 'grad_norm': 5.846068382263184, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.005861038342118263, 'loss_2': 0.00461578369140625, 'loss_3': -16.52280044555664, 'loss_4': 0.7949167490005493, 'epoch': 22.37}
{'loss': 0.0078, 'grad_norm': 4.585930347442627, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.004807217977941036, 'loss_2': 0.00296783447265625, 'loss_3': -16.38315200805664, 'loss_4': 0.58277428150177, 'epoch': 22.38}
{'loss': 0.0088, 'grad_norm': 5.967413902282715, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.006446931045502424, 'loss_2': 0.002376556396484375, 'loss_3': -16.327899932861328, 'loss_4': 0.5084510445594788, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 16:52:17,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:17,190 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:35:11<22:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:24,537 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019578218460083008, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.32, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.017153047025203705, 'eval_loss_2': 0.002425171434879303, 'eval_loss_3': -18.10226058959961, 'eval_loss_4': 0.6016095876693726, 'epoch': 22.38}
{'loss': 0.0143, 'grad_norm': 6.339457035064697, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.010569831356406212, 'loss_2': 0.003688812255859375, 'loss_3': -16.480106353759766, 'loss_4': 0.6399317979812622, 'epoch': 22.39}
{'loss': 0.0112, 'grad_norm': 4.939296245574951, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.005881892051547766, 'loss_2': 0.005279541015625, 'loss_3': -16.215084075927734, 'loss_4': 0.5697600245475769, 'epoch': 22.4}
{'loss': 0.017, 'grad_norm': 6.296759128570557, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.013941088691353798, 'loss_2': 0.003101348876953125, 'loss_3': -16.335594177246094, 'loss_4': 0.4967159032821655, 'epoch': 22.4}
{'loss': 0.0112, 'grad_norm': 4.408333778381348, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.00480297114700079, 'loss_2': 0.00643157958984375, 'loss_3': -16.339309692382812, 'loss_4': 0.4660544991493225, 'epoch': 22.41}
{'loss': 0.0184, 'grad_norm': 8.587739944458008, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.015294105745851994, 'loss_2': 0.0031261444091796875, 'loss_3': -16.2477970123291, 'loss_4': 0.4592430591583252, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 16:52:24,537 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:24,537 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:18<22:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:31,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02071199379861355, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.338, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01639120653271675, 'eval_loss_2': 0.004320785403251648, 'eval_loss_3': -18.102392196655273, 'eval_loss_4': 0.7376682162284851, 'epoch': 22.41}
{'loss': 0.0117, 'grad_norm': 4.80966854095459, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.007919954136013985, 'loss_2': 0.0037364959716796875, 'loss_3': -16.267486572265625, 'loss_4': 1.0365674495697021, 'epoch': 22.42}
{'loss': 0.0138, 'grad_norm': 12.953048706054688, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.009976515546441078, 'loss_2': 0.003787994384765625, 'loss_3': -16.444992065429688, 'loss_4': 0.03026439994573593, 'epoch': 22.42}
{'loss': 0.0066, 'grad_norm': 5.059721946716309, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.005941653158515692, 'loss_2': 0.0006437301635742188, 'loss_3': -16.39255714416504, 'loss_4': 0.47069472074508667, 'epoch': 22.43}
{'loss': 0.0063, 'grad_norm': 4.695425987243652, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.004645420238375664, 'loss_2': 0.0016803741455078125, 'loss_3': -16.466989517211914, 'loss_4': 1.0656455755233765, 'epoch': 22.44}
{'loss': 0.0085, 'grad_norm': 9.066973686218262, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.005623191129416227, 'loss_2': 0.002925872802734375, 'loss_3': -16.355558395385742, 'loss_4': 1.4789059162139893, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 16:52:31,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:31,877 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:25<22:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:39,219 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022625233978033066, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.307, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01725044474005699, 'eval_loss_2': 0.005374789237976074, 'eval_loss_3': -18.099443435668945, 'eval_loss_4': 0.8361732959747314, 'epoch': 22.44}
{'loss': 0.006, 'grad_norm': 6.230522155761719, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.004938714671880007, 'loss_2': 0.0010166168212890625, 'loss_3': -16.32377815246582, 'loss_4': 0.9220825433731079, 'epoch': 22.45}
{'loss': 0.0106, 'grad_norm': 4.472842693328857, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.0077703301794826984, 'loss_2': 0.00278472900390625, 'loss_3': -16.414592742919922, 'loss_4': 1.005138874053955, 'epoch': 22.45}
{'loss': 0.0118, 'grad_norm': 4.455216407775879, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.004334046505391598, 'loss_2': 0.00745391845703125, 'loss_3': -16.427703857421875, 'loss_4': 0.43656837940216064, 'epoch': 22.46}
{'loss': 0.0089, 'grad_norm': 5.786160469055176, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.00829071830958128, 'loss_2': 0.0006437301635742188, 'loss_3': -16.57315444946289, 'loss_4': 0.5203280448913574, 'epoch': 22.47}
{'loss': 0.0172, 'grad_norm': 6.7143378257751465, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.011249633505940437, 'loss_2': 0.00592041015625, 'loss_3': -16.473949432373047, 'loss_4': 0.8601130247116089, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 16:52:39,219 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:39,219 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:33<22:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:46,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02150302566587925, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.016760341823101044, 'eval_loss_2': 0.004742681980133057, 'eval_loss_3': -18.106149673461914, 'eval_loss_4': 0.9776836633682251, 'epoch': 22.47}
{'loss': 0.0088, 'grad_norm': 5.757495880126953, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.007862409576773643, 'loss_2': 0.0009398460388183594, 'loss_3': -16.44619369506836, 'loss_4': 1.1492865085601807, 'epoch': 22.48}
{'loss': 0.0141, 'grad_norm': 7.7983856201171875, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.010248681530356407, 'loss_2': 0.0038928985595703125, 'loss_3': -16.63178253173828, 'loss_4': 0.7678345441818237, 'epoch': 22.48}
{'loss': 0.0151, 'grad_norm': 6.51880407333374, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.0112635912373662, 'loss_2': 0.0038280487060546875, 'loss_3': -16.410104751586914, 'loss_4': 0.8691206574440002, 'epoch': 22.49}
{'loss': 0.008, 'grad_norm': 5.178079605102539, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.0073160952888429165, 'loss_2': 0.0006842613220214844, 'loss_3': -16.361217498779297, 'loss_4': 1.070845127105713, 'epoch': 22.49}
{'loss': 0.0115, 'grad_norm': 4.027949810028076, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.0048640817403793335, 'loss_2': 0.00667572021484375, 'loss_3': -16.45922088623047, 'loss_4': 1.1560243368148804, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 16:52:46,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:46,566 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:40<22:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:52:53,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021988119930028915, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.517, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.016876129433512688, 'eval_loss_2': 0.005111992359161377, 'eval_loss_3': -18.099924087524414, 'eval_loss_4': 1.0976438522338867, 'epoch': 22.5}
{'loss': 0.0303, 'grad_norm': 10.07452392578125, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.0239125844091177, 'loss_2': 0.00643157958984375, 'loss_3': -16.367652893066406, 'loss_4': 1.2175540924072266, 'epoch': 22.51}
{'loss': 0.0062, 'grad_norm': 4.622877597808838, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.004283389076590538, 'loss_2': 0.0019626617431640625, 'loss_3': -16.337627410888672, 'loss_4': 0.6559382677078247, 'epoch': 22.51}
{'loss': 0.0108, 'grad_norm': 4.6507039070129395, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.008884994313120842, 'loss_2': 0.0019140243530273438, 'loss_3': -16.547395706176758, 'loss_4': 1.5709826946258545, 'epoch': 22.52}
{'loss': 0.0268, 'grad_norm': 8.310635566711426, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.02173374593257904, 'loss_2': 0.00508880615234375, 'loss_3': -16.37013053894043, 'loss_4': 0.7967381477355957, 'epoch': 22.52}
{'loss': 0.0067, 'grad_norm': 4.524519443511963, 'learning_rate': 7.5e-06, 'loss_1': 0.005362209398299456, 'loss_2': 0.0013751983642578125, 'loss_3': -16.48579216003418, 'loss_4': 1.3628531694412231, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 16:52:53,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:52:53,924 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:47<22:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:01,274 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020970698446035385, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.149, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01597404107451439, 'eval_loss_2': 0.004996657371520996, 'eval_loss_3': -18.106340408325195, 'eval_loss_4': 1.0570967197418213, 'epoch': 22.53}
{'loss': 0.0267, 'grad_norm': 12.2227783203125, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.024158939719200134, 'loss_2': 0.0025787353515625, 'loss_3': -16.669788360595703, 'loss_4': 0.9319980144500732, 'epoch': 22.53}
{'loss': 0.0097, 'grad_norm': 38.2653694152832, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.0038531653117388487, 'loss_2': 0.005828857421875, 'loss_3': -16.410877227783203, 'loss_4': 0.5644201636314392, 'epoch': 22.54}
{'loss': 0.0259, 'grad_norm': 11.34959602355957, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.022076187655329704, 'loss_2': 0.0037746429443359375, 'loss_3': -16.546009063720703, 'loss_4': 1.1806464195251465, 'epoch': 22.55}
{'loss': 0.013, 'grad_norm': 5.286472320556641, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.006985059939324856, 'loss_2': 0.00600433349609375, 'loss_3': -16.22454833984375, 'loss_4': 0.9918879866600037, 'epoch': 22.55}
{'loss': 0.013, 'grad_norm': 7.69686222076416, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.012892639264464378, 'loss_2': 7.343292236328125e-05, 'loss_3': -16.244590759277344, 'loss_4': 1.3173701763153076, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 16:53:01,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:01,275 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:35:55<22:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:08,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018742620944976807, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.145, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014679147861897945, 'eval_loss_2': 0.004063472151756287, 'eval_loss_3': -18.128355026245117, 'eval_loss_4': 0.9650155305862427, 'epoch': 22.56}
{'loss': 0.0111, 'grad_norm': 4.548056602478027, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.0072985622100532055, 'loss_2': 0.0037937164306640625, 'loss_3': -16.445009231567383, 'loss_4': 1.1977250576019287, 'epoch': 22.56}
{'loss': 0.0055, 'grad_norm': 4.779666423797607, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.004766814410686493, 'loss_2': 0.0007648468017578125, 'loss_3': -16.308107376098633, 'loss_4': 0.835010290145874, 'epoch': 22.57}
{'loss': 0.0064, 'grad_norm': 4.918413162231445, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.006152153015136719, 'loss_2': 0.00027060508728027344, 'loss_3': -16.456695556640625, 'loss_4': 1.0419849157333374, 'epoch': 22.58}
{'loss': 0.0051, 'grad_norm': 4.28653621673584, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.004287196788936853, 'loss_2': 0.00086212158203125, 'loss_3': -16.529827117919922, 'loss_4': 1.0417653322219849, 'epoch': 22.58}
{'loss': 0.0092, 'grad_norm': 4.647890090942383, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.005752388387918472, 'loss_2': 0.0034694671630859375, 'loss_3': -16.158235549926758, 'loss_4': 0.7660164833068848, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 16:53:08,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:08,626 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:36:02<21:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:15,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017081845551729202, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.283, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013041886501014233, 'eval_loss_2': 0.004039958119392395, 'eval_loss_3': -18.139028549194336, 'eval_loss_4': 0.9313690662384033, 'epoch': 22.59}
{'loss': 0.0068, 'grad_norm': 5.047775745391846, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.004633254837244749, 'loss_2': 0.002117156982421875, 'loss_3': -16.330528259277344, 'loss_4': 0.8805499076843262, 'epoch': 22.59}
{'loss': 0.0066, 'grad_norm': 4.4873552322387695, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.0043496023863554, 'loss_2': 0.0022144317626953125, 'loss_3': -16.329328536987305, 'loss_4': 1.01381516456604, 'epoch': 22.6}
{'loss': 0.0118, 'grad_norm': 4.844363689422607, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.00520526384934783, 'loss_2': 0.0065460205078125, 'loss_3': -16.214855194091797, 'loss_4': 0.6882867813110352, 'epoch': 22.6}
{'loss': 0.0079, 'grad_norm': 4.309966564178467, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.0038107214495539665, 'loss_2': 0.0040435791015625, 'loss_3': -16.42701530456543, 'loss_4': 0.8988710641860962, 'epoch': 22.61}
{'loss': 0.0132, 'grad_norm': 4.260538101196289, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.005992609541863203, 'loss_2': 0.007175445556640625, 'loss_3': -16.41583251953125, 'loss_4': 0.7696970701217651, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 16:53:15,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:15,975 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:36:09<21:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:23,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015521597117185593, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011782629415392876, 'eval_loss_2': 0.003738969564437866, 'eval_loss_3': -18.144193649291992, 'eval_loss_4': 0.9052276015281677, 'epoch': 22.62}
{'loss': 0.0114, 'grad_norm': 8.505599975585938, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.011069471016526222, 'loss_2': 0.0003707408905029297, 'loss_3': -16.501338958740234, 'loss_4': 0.6787087917327881, 'epoch': 22.62}
{'loss': 0.0191, 'grad_norm': 6.358478546142578, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.013366655446588993, 'loss_2': 0.005733489990234375, 'loss_3': -16.40483856201172, 'loss_4': 0.7452216148376465, 'epoch': 22.63}
{'loss': 0.0231, 'grad_norm': 13.816069602966309, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.018241791054606438, 'loss_2': 0.00490570068359375, 'loss_3': -16.62129020690918, 'loss_4': 0.7952074408531189, 'epoch': 22.63}
{'loss': 0.0161, 'grad_norm': 5.0431084632873535, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.007929785177111626, 'loss_2': 0.0081329345703125, 'loss_3': -16.345767974853516, 'loss_4': 0.8217864036560059, 'epoch': 22.64}
{'loss': 0.01, 'grad_norm': 5.39072322845459, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.0056545790284872055, 'loss_2': 0.0043792724609375, 'loss_3': -16.266756057739258, 'loss_4': 1.0964395999908447, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 16:53:23,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:23,329 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:17<21:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:30,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014138517901301384, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.777, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011352193541824818, 'eval_loss_2': 0.0027863234281539917, 'eval_loss_3': -18.13205337524414, 'eval_loss_4': 0.8508766889572144, 'epoch': 22.65}
{'loss': 0.0083, 'grad_norm': 4.813294410705566, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.005094821564853191, 'loss_2': 0.0032367706298828125, 'loss_3': -16.492143630981445, 'loss_4': 0.9872121214866638, 'epoch': 22.65}
{'loss': 0.0098, 'grad_norm': 5.490721225738525, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.007494490593671799, 'loss_2': 0.00226593017578125, 'loss_3': -16.3043212890625, 'loss_4': 1.3315685987472534, 'epoch': 22.66}
{'loss': 0.0371, 'grad_norm': 20.965648651123047, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.030587894842028618, 'loss_2': 0.00653076171875, 'loss_3': -16.169275283813477, 'loss_4': 0.569757878780365, 'epoch': 22.66}
{'loss': 0.0092, 'grad_norm': 5.164006233215332, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.004946729633957148, 'loss_2': 0.00428009033203125, 'loss_3': -16.41656494140625, 'loss_4': 0.8055656552314758, 'epoch': 22.67}
{'loss': 0.0127, 'grad_norm': 5.4514641761779785, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.007994658313691616, 'loss_2': 0.00475311279296875, 'loss_3': -16.225269317626953, 'loss_4': 0.9473461508750916, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 16:53:30,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:30,688 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:24<21:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:38,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0140946414321661, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.815, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011401447467505932, 'eval_loss_2': 0.002693191170692444, 'eval_loss_3': -18.13397789001465, 'eval_loss_4': 0.8528167009353638, 'epoch': 22.67}
{'loss': 0.0081, 'grad_norm': 4.887535572052002, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.0032288699876517057, 'loss_2': 0.00492095947265625, 'loss_3': -16.460758209228516, 'loss_4': 1.2234582901000977, 'epoch': 22.68}
{'loss': 0.0158, 'grad_norm': 10.216619491577148, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.014804688282310963, 'loss_2': 0.0010433197021484375, 'loss_3': -16.197463989257812, 'loss_4': 0.889035701751709, 'epoch': 22.69}
{'loss': 0.0159, 'grad_norm': 4.6976189613342285, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.007468131370842457, 'loss_2': 0.00839996337890625, 'loss_3': -16.48565101623535, 'loss_4': 0.8147501945495605, 'epoch': 22.69}
{'loss': 0.0183, 'grad_norm': 9.18117904663086, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.01755186915397644, 'loss_2': 0.00070953369140625, 'loss_3': -16.343904495239258, 'loss_4': 1.104922890663147, 'epoch': 22.7}
{'loss': 0.009, 'grad_norm': 4.7560811042785645, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.004905922804027796, 'loss_2': 0.0041046142578125, 'loss_3': -16.502315521240234, 'loss_4': 0.8824484348297119, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 16:53:38,036 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:38,036 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:31<21:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:45,382 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014086248353123665, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.061, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011205190792679787, 'eval_loss_2': 0.002881057560443878, 'eval_loss_3': -18.1400146484375, 'eval_loss_4': 0.9008810520172119, 'epoch': 22.7}
{'loss': 0.0205, 'grad_norm': 4.998206615447998, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.007493071258068085, 'loss_2': 0.01300048828125, 'loss_3': -16.41542625427246, 'loss_4': 0.7789785861968994, 'epoch': 22.71}
{'loss': 0.0107, 'grad_norm': 5.338613033294678, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.00786737073212862, 'loss_2': 0.002864837646484375, 'loss_3': -16.384963989257812, 'loss_4': 1.0507228374481201, 'epoch': 22.72}
{'loss': 0.0161, 'grad_norm': 9.389947891235352, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.012664129957556725, 'loss_2': 0.0034122467041015625, 'loss_3': -16.373008728027344, 'loss_4': 0.9776318073272705, 'epoch': 22.72}
{'loss': 0.005, 'grad_norm': 4.667880535125732, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.004960702732205391, 'loss_2': 7.82012939453125e-05, 'loss_3': -16.316162109375, 'loss_4': 1.2464241981506348, 'epoch': 22.73}
{'loss': 0.0119, 'grad_norm': 5.469027996063232, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.007937351241707802, 'loss_2': 0.003978729248046875, 'loss_3': -16.5783634185791, 'loss_4': 1.022053837776184, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 16:53:45,383 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:45,383 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:39<21:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:53:52,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014640815556049347, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.352, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.011718734167516232, 'eval_loss_2': 0.0029220804572105408, 'eval_loss_3': -18.148452758789062, 'eval_loss_4': 0.9934932589530945, 'epoch': 22.73}
{'loss': 0.019, 'grad_norm': 12.974449157714844, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.015873976051807404, 'loss_2': 0.0031280517578125, 'loss_3': -16.353055953979492, 'loss_4': 1.167158603668213, 'epoch': 22.74}
{'loss': 0.0127, 'grad_norm': 5.120159149169922, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.007994312793016434, 'loss_2': 0.0047149658203125, 'loss_3': -16.577245712280273, 'loss_4': 1.4243278503417969, 'epoch': 22.74}
{'loss': 0.0135, 'grad_norm': 5.8775200843811035, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.009473348967730999, 'loss_2': 0.003978729248046875, 'loss_3': -16.364971160888672, 'loss_4': 1.0530160665512085, 'epoch': 22.75}
{'loss': 0.0134, 'grad_norm': 5.967521667480469, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.011851651594042778, 'loss_2': 0.0015201568603515625, 'loss_3': -16.41962242126465, 'loss_4': 1.0572929382324219, 'epoch': 22.76}
{'loss': 0.0132, 'grad_norm': 5.14579963684082, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.008214153349399567, 'loss_2': 0.0050048828125, 'loss_3': -16.433629989624023, 'loss_4': 0.9736157059669495, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 16:53:52,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:53:52,728 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:46<21:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:00,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01609126105904579, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.51, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.012351666577160358, 'eval_loss_2': 0.003739595413208008, 'eval_loss_3': -18.14771270751953, 'eval_loss_4': 1.0399227142333984, 'epoch': 22.76}
{'loss': 0.0108, 'grad_norm': 4.999949932098389, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.006990485358983278, 'loss_2': 0.0037670135498046875, 'loss_3': -16.256568908691406, 'loss_4': 0.7515158653259277, 'epoch': 22.77}
{'loss': 0.0088, 'grad_norm': 5.047299861907959, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.007640199735760689, 'loss_2': 0.001194000244140625, 'loss_3': -16.365795135498047, 'loss_4': 1.1433429718017578, 'epoch': 22.77}
{'loss': 0.0056, 'grad_norm': 4.667666435241699, 'learning_rate': 7.25e-06, 'loss_1': 0.0031006226781755686, 'loss_2': 0.002468109130859375, 'loss_3': -16.385940551757812, 'loss_4': 0.9897724390029907, 'epoch': 22.78}
{'loss': 0.0104, 'grad_norm': 7.076632976531982, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.00702535267919302, 'loss_2': 0.0033359527587890625, 'loss_3': -16.311386108398438, 'loss_4': 0.9781462550163269, 'epoch': 22.78}
{'loss': 0.0053, 'grad_norm': 4.651028156280518, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.005141852423548698, 'loss_2': 0.00015687942504882812, 'loss_3': -16.33357048034668, 'loss_4': 0.5377116203308105, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 16:54:00,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:00,093 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:36:54<21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:07,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01568691059947014, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.179, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01192025188356638, 'eval_loss_2': 0.0037666596472263336, 'eval_loss_3': -18.144521713256836, 'eval_loss_4': 1.105858325958252, 'epoch': 22.79}
{'loss': 0.0788, 'grad_norm': 16.163000106811523, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.07541704922914505, 'loss_2': 0.003383636474609375, 'loss_3': -16.483407974243164, 'loss_4': 1.406628131866455, 'epoch': 22.8}
{'loss': 0.0059, 'grad_norm': 5.001101970672607, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.003699443070217967, 'loss_2': 0.002223968505859375, 'loss_3': -16.527976989746094, 'loss_4': 1.1772741079330444, 'epoch': 22.8}
{'loss': 0.0111, 'grad_norm': 5.046257019042969, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.007550390437245369, 'loss_2': 0.003570556640625, 'loss_3': -16.31435775756836, 'loss_4': 1.102092981338501, 'epoch': 22.81}
{'loss': 0.0087, 'grad_norm': 5.3735032081604, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.006000985857099295, 'loss_2': 0.002712249755859375, 'loss_3': -16.548717498779297, 'loss_4': 1.3784854412078857, 'epoch': 22.81}
{'loss': 0.0139, 'grad_norm': 5.396339416503906, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.005692537408322096, 'loss_2': 0.00820159912109375, 'loss_3': -16.379335403442383, 'loss_4': 1.2495607137680054, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 16:54:07,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:07,446 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:37:01<21:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:14,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013213072903454304, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.56, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01027483120560646, 'eval_loss_2': 0.0029382407665252686, 'eval_loss_3': -18.157485961914062, 'eval_loss_4': 1.1495012044906616, 'epoch': 22.82}
{'loss': 0.0062, 'grad_norm': 4.727260589599609, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.005035913549363613, 'loss_2': 0.0011730194091796875, 'loss_3': -16.40593147277832, 'loss_4': 1.2015345096588135, 'epoch': 22.83}
{'loss': 0.0084, 'grad_norm': 5.197113513946533, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.005908787250518799, 'loss_2': 0.002529144287109375, 'loss_3': -16.126163482666016, 'loss_4': 0.9542524814605713, 'epoch': 22.83}
{'loss': 0.0067, 'grad_norm': 4.552728176116943, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.005972891114652157, 'loss_2': 0.0007457733154296875, 'loss_3': -16.41851234436035, 'loss_4': 1.2013094425201416, 'epoch': 22.84}
{'loss': 0.0083, 'grad_norm': 4.830563068389893, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.006368980742990971, 'loss_2': 0.00196075439453125, 'loss_3': -16.388906478881836, 'loss_4': 0.9799134135246277, 'epoch': 22.84}
{'loss': 0.0046, 'grad_norm': 4.340949058532715, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.0034128352999687195, 'loss_2': 0.00116729736328125, 'loss_3': -16.459341049194336, 'loss_4': 1.1682569980621338, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 16:54:14,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:14,808 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:37:08<21:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:22,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013229956850409508, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00973085593432188, 'eval_loss_2': 0.003499101847410202, 'eval_loss_3': -18.166078567504883, 'eval_loss_4': 1.2520428895950317, 'epoch': 22.85}
{'loss': 0.0074, 'grad_norm': 5.719245433807373, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.006196634378284216, 'loss_2': 0.0011987686157226562, 'loss_3': -16.3841552734375, 'loss_4': 0.9005765914916992, 'epoch': 22.85}
{'loss': 0.0109, 'grad_norm': 7.209011554718018, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.009137570858001709, 'loss_2': 0.0017452239990234375, 'loss_3': -16.289794921875, 'loss_4': 1.0919091701507568, 'epoch': 22.86}
{'loss': 0.0144, 'grad_norm': 5.7415080070495605, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.00951933953911066, 'loss_2': 0.0048370361328125, 'loss_3': -16.31243896484375, 'loss_4': 1.1535298824310303, 'epoch': 22.87}
{'loss': 0.015, 'grad_norm': 6.345771789550781, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.009124178439378738, 'loss_2': 0.0058441162109375, 'loss_3': -16.579492568969727, 'loss_4': 1.0655674934387207, 'epoch': 22.87}
{'loss': 0.0097, 'grad_norm': 4.528979301452637, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.0030228872783482075, 'loss_2': 0.0066680908203125, 'loss_3': -16.299779891967773, 'loss_4': 1.375659704208374, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 16:54:22,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:22,155 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:37:16<21:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:29,502 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014902298338711262, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.255, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009629731997847557, 'eval_loss_2': 0.005272567272186279, 'eval_loss_3': -18.168365478515625, 'eval_loss_4': 1.3734469413757324, 'epoch': 22.88}
{'loss': 0.0083, 'grad_norm': 4.896002292633057, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.0065512629225850105, 'loss_2': 0.0017480850219726562, 'loss_3': -16.472919464111328, 'loss_4': 1.2994372844696045, 'epoch': 22.88}
{'loss': 0.0156, 'grad_norm': 6.731487274169922, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.011069174855947495, 'loss_2': 0.00450897216796875, 'loss_3': -16.154647827148438, 'loss_4': 1.3305271863937378, 'epoch': 22.89}
{'loss': 0.0077, 'grad_norm': 4.6387410163879395, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.0047471486032009125, 'loss_2': 0.002956390380859375, 'loss_3': -16.42375373840332, 'loss_4': 1.6217976808547974, 'epoch': 22.9}
{'loss': 0.0154, 'grad_norm': 9.739038467407227, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.015254882164299488, 'loss_2': 0.00014662742614746094, 'loss_3': -16.26195526123047, 'loss_4': 0.9878972768783569, 'epoch': 22.9}
{'loss': 0.0102, 'grad_norm': 5.776384353637695, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.008714983239769936, 'loss_2': 0.001476287841796875, 'loss_3': -16.243358612060547, 'loss_4': 1.5950381755828857, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 16:54:29,502 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:29,502 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:23<21:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:36,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014175919815897942, 'eval_runtime': 3.8042, 'eval_samples_per_second': 269.177, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009834211319684982, 'eval_loss_2': 0.00434170663356781, 'eval_loss_3': -18.15384292602539, 'eval_loss_4': 1.3455995321273804, 'epoch': 22.91}
{'loss': 0.0122, 'grad_norm': 10.091586112976074, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.008880702778697014, 'loss_2': 0.0032978057861328125, 'loss_3': -16.291717529296875, 'loss_4': 1.4655482769012451, 'epoch': 22.91}
{'loss': 0.0078, 'grad_norm': 6.804590702056885, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.007307552732527256, 'loss_2': 0.0005168914794921875, 'loss_3': -16.36276626586914, 'loss_4': 1.259867787361145, 'epoch': 22.92}
{'loss': 0.0071, 'grad_norm': 4.859621047973633, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.003946254495531321, 'loss_2': 0.00319671630859375, 'loss_3': -16.585981369018555, 'loss_4': 1.449718952178955, 'epoch': 22.92}
{'loss': 0.016, 'grad_norm': 13.909174919128418, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.01529567502439022, 'loss_2': 0.0007443428039550781, 'loss_3': -16.230201721191406, 'loss_4': 1.3208153247833252, 'epoch': 22.93}
{'loss': 0.0068, 'grad_norm': 4.760228157043457, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.003977264277637005, 'loss_2': 0.0028076171875, 'loss_3': -16.31396484375, 'loss_4': 1.2882412672042847, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 16:54:36,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:36,845 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:30<20:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:54:44,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013490267097949982, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009746678173542023, 'eval_loss_2': 0.003743588924407959, 'eval_loss_3': -18.145429611206055, 'eval_loss_4': 1.3099908828735352, 'epoch': 22.94}
{'loss': 0.009, 'grad_norm': 4.313354015350342, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.002855685306712985, 'loss_2': 0.006122589111328125, 'loss_3': -16.481477737426758, 'loss_4': 1.5635206699371338, 'epoch': 22.94}
{'loss': 0.0143, 'grad_norm': 6.496608734130859, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.004782641772180796, 'loss_2': 0.0095062255859375, 'loss_3': -16.356582641601562, 'loss_4': 1.407287836074829, 'epoch': 22.95}
{'loss': 0.0138, 'grad_norm': 5.443742752075195, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.00649246433749795, 'loss_2': 0.00727081298828125, 'loss_3': -16.410654067993164, 'loss_4': 1.3008193969726562, 'epoch': 22.95}
{'loss': 0.0118, 'grad_norm': 6.717169284820557, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.009743318893015385, 'loss_2': 0.002101898193359375, 'loss_3': -16.319156646728516, 'loss_4': 1.0624685287475586, 'epoch': 22.96}
{'loss': 0.0103, 'grad_norm': 6.151307106018066, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.0065276301465928555, 'loss_2': 0.00374603271484375, 'loss_3': -16.44582748413086, 'loss_4': 1.5515708923339844, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 16:54:44,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:44,189 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:38<20:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:54:51,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014352655969560146, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.596, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010284146293997765, 'eval_loss_2': 0.004068508744239807, 'eval_loss_3': -18.136310577392578, 'eval_loss_4': 1.2412782907485962, 'epoch': 22.97}
{'loss': 0.014, 'grad_norm': 5.639220237731934, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.012823098339140415, 'loss_2': 0.0011663436889648438, 'loss_3': -16.446186065673828, 'loss_4': 1.4096729755401611, 'epoch': 22.97}
{'loss': 0.014, 'grad_norm': 8.634664535522461, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.013155080378055573, 'loss_2': 0.0008702278137207031, 'loss_3': -16.386009216308594, 'loss_4': 1.060519814491272, 'epoch': 22.98}
{'loss': 0.0163, 'grad_norm': 6.700924396514893, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.01407853327691555, 'loss_2': 0.0021820068359375, 'loss_3': -16.461074829101562, 'loss_4': 0.9931032657623291, 'epoch': 22.98}
{'loss': 0.0205, 'grad_norm': 5.415213584899902, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.009926983155310154, 'loss_2': 0.0105743408203125, 'loss_3': -16.242111206054688, 'loss_4': 1.111285924911499, 'epoch': 22.99}
{'loss': 0.0149, 'grad_norm': 8.144237518310547, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.010279066860675812, 'loss_2': 0.004638671875, 'loss_3': -16.315793991088867, 'loss_4': 1.2595292329788208, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 16:54:51,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:51,530 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:45<20:22,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 16:54:58,600 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014777963049709797, 'eval_runtime': 3.8175, 'eval_samples_per_second': 268.238, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.010985259898006916, 'eval_loss_2': 0.003792703151702881, 'eval_loss_3': -18.12839126586914, 'eval_loss_4': 1.2564557790756226, 'epoch': 22.99}
{'loss': 0.0152, 'grad_norm': 23.124637603759766, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.0018131127581000328, 'loss_2': 0.0134124755859375, 'loss_3': -16.238985061645508, 'loss_4': 0.8278661966323853, 'epoch': 23.0}
{'loss': 0.017, 'grad_norm': 5.469422817230225, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.009220840409398079, 'loss_2': 0.007732391357421875, 'loss_3': -16.195798873901367, 'loss_4': 1.1808832883834839, 'epoch': 23.01}
{'loss': 0.0119, 'grad_norm': 4.980462074279785, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.01110227219760418, 'loss_2': 0.0007991790771484375, 'loss_3': -16.24226188659668, 'loss_4': 1.715954065322876, 'epoch': 23.01}
{'loss': 0.0131, 'grad_norm': 5.567485809326172, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.006935220677405596, 'loss_2': 0.006206512451171875, 'loss_3': -16.1799373626709, 'loss_4': 1.2135653495788574, 'epoch': 23.02}
{'loss': 0.0051, 'grad_norm': 4.733582973480225, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.004484103061258793, 'loss_2': 0.0005960464477539062, 'loss_3': -16.448348999023438, 'loss_4': 1.3143539428710938, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 16:54:58,600 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:54:58,600 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:37:52<20:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:55:05,947 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015122373588383198, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.242, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01094718836247921, 'eval_loss_2': 0.0041751861572265625, 'eval_loss_3': -18.13646125793457, 'eval_loss_4': 1.178240180015564, 'epoch': 23.02}
{'loss': 0.0148, 'grad_norm': 6.678497314453125, 'learning_rate': 7e-06, 'loss_1': 0.013482172973453999, 'loss_2': 0.001300811767578125, 'loss_3': -16.500791549682617, 'loss_4': 1.2687411308288574, 'epoch': 23.03}
{'loss': 0.0485, 'grad_norm': 20.266508102416992, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.04266402870416641, 'loss_2': 0.005863189697265625, 'loss_3': -16.180225372314453, 'loss_4': 1.2137295007705688, 'epoch': 23.03}
{'loss': 0.0091, 'grad_norm': 6.493614196777344, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.007663224823772907, 'loss_2': 0.001445770263671875, 'loss_3': -16.527183532714844, 'loss_4': 0.9581604599952698, 'epoch': 23.04}
{'loss': 0.0074, 'grad_norm': 5.976593971252441, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.006595800630748272, 'loss_2': 0.00079345703125, 'loss_3': -16.155433654785156, 'loss_4': 1.3066885471343994, 'epoch': 23.05}
{'loss': 0.0065, 'grad_norm': 4.924113750457764, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.004422895610332489, 'loss_2': 0.0020351409912109375, 'loss_3': -16.476451873779297, 'loss_4': 1.3201792240142822, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 16:55:05,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:05,948 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:37:59<20:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:13,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017928538843989372, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.312, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01052249688655138, 'eval_loss_2': 0.0074060410261154175, 'eval_loss_3': -18.13145637512207, 'eval_loss_4': 1.1426184177398682, 'epoch': 23.05}
{'loss': 0.0181, 'grad_norm': 4.737215995788574, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.004660589154809713, 'loss_2': 0.013397216796875, 'loss_3': -16.33728790283203, 'loss_4': 1.4624900817871094, 'epoch': 23.06}
{'loss': 0.0239, 'grad_norm': 8.539066314697266, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.015397646464407444, 'loss_2': 0.0084686279296875, 'loss_3': -16.3775577545166, 'loss_4': 1.38913893699646, 'epoch': 23.06}
{'loss': 0.0139, 'grad_norm': 4.889149188995361, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.005531927105039358, 'loss_2': 0.0084075927734375, 'loss_3': -16.521141052246094, 'loss_4': 1.578567385673523, 'epoch': 23.07}
{'loss': 0.0134, 'grad_norm': 5.330557823181152, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.006999874021857977, 'loss_2': 0.00640869140625, 'loss_3': -16.202770233154297, 'loss_4': 1.1265445947647095, 'epoch': 23.08}
{'loss': 0.0166, 'grad_norm': 5.773362636566162, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.010086624883115292, 'loss_2': 0.00653839111328125, 'loss_3': -16.089754104614258, 'loss_4': 1.4025436639785767, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 16:55:13,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:13,297 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:38:07<20:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:20,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017922688275575638, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.231, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010369050316512585, 'eval_loss_2': 0.0075536370277404785, 'eval_loss_3': -18.121543884277344, 'eval_loss_4': 1.152610421180725, 'epoch': 23.08}
{'loss': 0.0094, 'grad_norm': 4.425442695617676, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.0031276806257665157, 'loss_2': 0.0063018798828125, 'loss_3': -16.335628509521484, 'loss_4': 0.6393274664878845, 'epoch': 23.09}
{'loss': 0.0156, 'grad_norm': 5.970590591430664, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.007919855415821075, 'loss_2': 0.00768280029296875, 'loss_3': -16.32916831970215, 'loss_4': 1.4666345119476318, 'epoch': 23.09}
{'loss': 0.0148, 'grad_norm': 4.956182479858398, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.006189321167767048, 'loss_2': 0.0086517333984375, 'loss_3': -16.34557342529297, 'loss_4': 1.1818201541900635, 'epoch': 23.1}
{'loss': 0.0089, 'grad_norm': 5.157090663909912, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.006384539417922497, 'loss_2': 0.0025157928466796875, 'loss_3': -16.31293487548828, 'loss_4': 1.1507598161697388, 'epoch': 23.1}
{'loss': 0.0142, 'grad_norm': 8.969944953918457, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.009852378629148006, 'loss_2': 0.00434112548828125, 'loss_3': -16.325786590576172, 'loss_4': 1.0959422588348389, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 16:55:20,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:20,650 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:38:14<20:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:28,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01587480679154396, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.146, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01078819204121828, 'eval_loss_2': 0.005086615681648254, 'eval_loss_3': -18.124462127685547, 'eval_loss_4': 1.1438302993774414, 'epoch': 23.11}
{'loss': 0.0091, 'grad_norm': 5.180068492889404, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.0063346377573907375, 'loss_2': 0.002719879150390625, 'loss_3': -16.12710952758789, 'loss_4': 1.0395870208740234, 'epoch': 23.12}
{'loss': 0.0088, 'grad_norm': 4.748559951782227, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.004813284147530794, 'loss_2': 0.004009246826171875, 'loss_3': -16.5262451171875, 'loss_4': 1.4225777387619019, 'epoch': 23.12}
{'loss': 0.0059, 'grad_norm': 4.5711870193481445, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.00406994391232729, 'loss_2': 0.0018320083618164062, 'loss_3': -16.345809936523438, 'loss_4': 1.0552095174789429, 'epoch': 23.13}
{'loss': 0.014, 'grad_norm': 7.450830936431885, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.012041093781590462, 'loss_2': 0.0019683837890625, 'loss_3': -16.16715431213379, 'loss_4': 1.1784896850585938, 'epoch': 23.13}
{'loss': 0.0876, 'grad_norm': 9.391250610351562, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.08662483096122742, 'loss_2': 0.00096893310546875, 'loss_3': -16.15343475341797, 'loss_4': 0.6973490118980408, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 16:55:28,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:28,004 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:21<20:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:35,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015887971967458725, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.672, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.01130658108741045, 'eval_loss_2': 0.00458139181137085, 'eval_loss_3': -18.113792419433594, 'eval_loss_4': 0.9979773163795471, 'epoch': 23.14}
{'loss': 0.048, 'grad_norm': 12.018675804138184, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.04295656830072403, 'loss_2': 0.0050506591796875, 'loss_3': -16.27535629272461, 'loss_4': 1.118159294128418, 'epoch': 23.15}
{'loss': 0.0056, 'grad_norm': 5.034382343292236, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.004457436967641115, 'loss_2': 0.0011463165283203125, 'loss_3': -16.297103881835938, 'loss_4': 1.2275869846343994, 'epoch': 23.15}
{'loss': 0.0104, 'grad_norm': 7.371856689453125, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.008067281916737556, 'loss_2': 0.00232696533203125, 'loss_3': -16.53924560546875, 'loss_4': 0.8836251497268677, 'epoch': 23.16}
{'loss': 0.0142, 'grad_norm': 5.569772243499756, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.006492821499705315, 'loss_2': 0.00768280029296875, 'loss_3': -16.32371711730957, 'loss_4': 0.8272713422775269, 'epoch': 23.16}
{'loss': 0.0137, 'grad_norm': 7.4901580810546875, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.012667961418628693, 'loss_2': 0.001018524169921875, 'loss_3': -16.35124969482422, 'loss_4': 1.0177507400512695, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 16:55:35,366 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:35,366 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:29<20:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:42,715 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014448631554841995, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.244, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01099421363323927, 'eval_loss_2': 0.0034544169902801514, 'eval_loss_3': -18.116350173950195, 'eval_loss_4': 0.9006742238998413, 'epoch': 23.17}
{'loss': 0.0077, 'grad_norm': 4.279184341430664, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.004197848029434681, 'loss_2': 0.0034618377685546875, 'loss_3': -16.358261108398438, 'loss_4': 0.8199257850646973, 'epoch': 23.17}
{'loss': 0.0114, 'grad_norm': 5.010526180267334, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.0067231119610369205, 'loss_2': 0.00469970703125, 'loss_3': -16.395366668701172, 'loss_4': 0.8499394059181213, 'epoch': 23.18}
{'loss': 0.0206, 'grad_norm': 6.17466926574707, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.013193942606449127, 'loss_2': 0.00739288330078125, 'loss_3': -16.425498962402344, 'loss_4': 0.36808061599731445, 'epoch': 23.19}
{'loss': 0.0058, 'grad_norm': 4.590625286102295, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.0036221479531377554, 'loss_2': 0.002185821533203125, 'loss_3': -16.32276153564453, 'loss_4': 0.5793576240539551, 'epoch': 23.19}
{'loss': 0.0122, 'grad_norm': 4.899448871612549, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.005697477143257856, 'loss_2': 0.0065460205078125, 'loss_3': -16.307769775390625, 'loss_4': 0.9883283376693726, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 16:55:42,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:42,715 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:36<20:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:50,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014655867591500282, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.959, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010701739229261875, 'eval_loss_2': 0.0039541274309158325, 'eval_loss_3': -18.122905731201172, 'eval_loss_4': 0.8537631630897522, 'epoch': 23.2}
{'loss': 0.0147, 'grad_norm': 5.142448425292969, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.005644326563924551, 'loss_2': 0.00901031494140625, 'loss_3': -16.30850601196289, 'loss_4': 0.7847362756729126, 'epoch': 23.2}
{'loss': 0.0133, 'grad_norm': 5.2412872314453125, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.008741965517401695, 'loss_2': 0.004547119140625, 'loss_3': -16.250118255615234, 'loss_4': 0.9674694538116455, 'epoch': 23.21}
{'loss': 0.0181, 'grad_norm': 9.395822525024414, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.013238683342933655, 'loss_2': 0.00484466552734375, 'loss_3': -16.418500900268555, 'loss_4': 0.8610780835151672, 'epoch': 23.22}
{'loss': 0.007, 'grad_norm': 4.583768844604492, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.005855204537510872, 'loss_2': 0.001194000244140625, 'loss_3': -16.315845489501953, 'loss_4': 1.1458295583724976, 'epoch': 23.22}
{'loss': 0.0071, 'grad_norm': 4.558503150939941, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.003291922155767679, 'loss_2': 0.0038204193115234375, 'loss_3': -16.345075607299805, 'loss_4': 0.8545290231704712, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 16:55:50,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:50,079 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:44<20:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:55:57,432 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013703885488212109, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.169, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01015802938491106, 'eval_loss_2': 0.0035458579659461975, 'eval_loss_3': -18.129249572753906, 'eval_loss_4': 0.8182662725448608, 'epoch': 23.23}
{'loss': 0.0095, 'grad_norm': 5.810746192932129, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.0058850920759141445, 'loss_2': 0.0036525726318359375, 'loss_3': -16.298107147216797, 'loss_4': 0.6872750520706177, 'epoch': 23.23}
{'loss': 0.0055, 'grad_norm': 4.190969944000244, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.0037061539478600025, 'loss_2': 0.001800537109375, 'loss_3': -16.477935791015625, 'loss_4': 1.022942304611206, 'epoch': 23.24}
{'loss': 0.0079, 'grad_norm': 5.089585781097412, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.005094008985906839, 'loss_2': 0.0027923583984375, 'loss_3': -16.381114959716797, 'loss_4': 1.0788778066635132, 'epoch': 23.24}
{'loss': 0.0113, 'grad_norm': 4.67632532119751, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.005316775292158127, 'loss_2': 0.00595855712890625, 'loss_3': -16.52396583557129, 'loss_4': 0.624908447265625, 'epoch': 23.25}
{'loss': 0.0047, 'grad_norm': 5.461167812347412, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.0029464971739798784, 'loss_2': 0.001796722412109375, 'loss_3': -16.482593536376953, 'loss_4': 0.8738155364990234, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 16:55:57,432 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:55:57,432 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:38:51<19:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:04,787 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014829320833086967, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.053, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010728349909186363, 'eval_loss_2': 0.004100970923900604, 'eval_loss_3': -18.120946884155273, 'eval_loss_4': 0.762102484703064, 'epoch': 23.26}
{'loss': 0.0078, 'grad_norm': 4.646564960479736, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.005697421729564667, 'loss_2': 0.00213623046875, 'loss_3': -16.260807037353516, 'loss_4': 0.7781978845596313, 'epoch': 23.26}
{'loss': 0.0058, 'grad_norm': 5.427073001861572, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.0056257061660289764, 'loss_2': 0.0001678466796875, 'loss_3': -16.315271377563477, 'loss_4': 0.9667733907699585, 'epoch': 23.27}
{'loss': 0.0196, 'grad_norm': 6.573950290679932, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.011429650709033012, 'loss_2': 0.0081634521484375, 'loss_3': -16.215103149414062, 'loss_4': 0.6405227780342102, 'epoch': 23.27}
{'loss': 0.0036, 'grad_norm': 4.368189334869385, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.002747411374002695, 'loss_2': 0.0008187294006347656, 'loss_3': -16.484670639038086, 'loss_4': 0.5324094891548157, 'epoch': 23.28}
{'loss': 0.0146, 'grad_norm': 4.904364585876465, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.010172829031944275, 'loss_2': 0.00438690185546875, 'loss_3': -16.394418716430664, 'loss_4': 0.6701275110244751, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 16:56:04,787 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:04,788 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:38:58<19:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:12,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017020005732774734, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011509415693581104, 'eval_loss_2': 0.005510590970516205, 'eval_loss_3': -18.094820022583008, 'eval_loss_4': 0.7263807058334351, 'epoch': 23.28}
{'loss': 0.0101, 'grad_norm': 5.580819129943848, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.007484102621674538, 'loss_2': 0.0026416778564453125, 'loss_3': -16.307857513427734, 'loss_4': 0.8392202854156494, 'epoch': 23.29}
{'loss': 0.0252, 'grad_norm': 7.678170680999756, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.016081131994724274, 'loss_2': 0.0091094970703125, 'loss_3': -16.249073028564453, 'loss_4': 0.8807405233383179, 'epoch': 23.3}
{'loss': 0.0097, 'grad_norm': 5.24144983291626, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.006183964665979147, 'loss_2': 0.003536224365234375, 'loss_3': -16.449323654174805, 'loss_4': 0.7607648372650146, 'epoch': 23.3}
{'loss': 0.0232, 'grad_norm': 11.12336254119873, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.018984047695994377, 'loss_2': 0.004184722900390625, 'loss_3': -16.19070053100586, 'loss_4': 1.2142000198364258, 'epoch': 23.31}
{'loss': 0.0088, 'grad_norm': 4.6088666915893555, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.005128904245793819, 'loss_2': 0.003673553466796875, 'loss_3': -16.397869110107422, 'loss_4': 0.5326451659202576, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 16:56:12,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:12,140 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:39:06<19:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:19,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016278475522994995, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0113315898925066, 'eval_loss_2': 0.004946887493133545, 'eval_loss_3': -18.097692489624023, 'eval_loss_4': 0.6647762060165405, 'epoch': 23.31}
{'loss': 0.0076, 'grad_norm': 4.495403289794922, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.004947452340275049, 'loss_2': 0.002685546875, 'loss_3': -16.249492645263672, 'loss_4': 0.3335062563419342, 'epoch': 23.32}
{'loss': 0.0127, 'grad_norm': 6.239197254180908, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.008163032121956348, 'loss_2': 0.0045013427734375, 'loss_3': -16.2772216796875, 'loss_4': 0.6438610553741455, 'epoch': 23.33}
{'loss': 0.007, 'grad_norm': 4.684080600738525, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.002891730749979615, 'loss_2': 0.004100799560546875, 'loss_3': -16.365386962890625, 'loss_4': 0.5413984656333923, 'epoch': 23.33}
{'loss': 0.0122, 'grad_norm': 4.511891841888428, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.007452545687556267, 'loss_2': 0.004703521728515625, 'loss_3': -16.35689926147461, 'loss_4': 0.18505480885505676, 'epoch': 23.34}
{'loss': 0.0128, 'grad_norm': 7.093844890594482, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.011244099587202072, 'loss_2': 0.0015497207641601562, 'loss_3': -16.108163833618164, 'loss_4': 0.3816899061203003, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 16:56:19,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:19,488 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:39:13<19:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:26,837 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01544268149882555, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.011805934831500053, 'eval_loss_2': 0.0036367475986480713, 'eval_loss_3': -18.103031158447266, 'eval_loss_4': 0.65291827917099, 'epoch': 23.34}
{'loss': 0.0049, 'grad_norm': 5.04666805267334, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.004383489489555359, 'loss_2': 0.000553131103515625, 'loss_3': -16.337318420410156, 'loss_4': 0.5346015691757202, 'epoch': 23.35}
{'loss': 0.0085, 'grad_norm': 5.015104293823242, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.004944871179759502, 'loss_2': 0.0035400390625, 'loss_3': -16.642498016357422, 'loss_4': -0.05224305018782616, 'epoch': 23.35}
{'loss': 0.0166, 'grad_norm': 5.458015441894531, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.0073605310171842575, 'loss_2': 0.00921630859375, 'loss_3': -16.385902404785156, 'loss_4': 0.5885448455810547, 'epoch': 23.36}
{'loss': 0.0193, 'grad_norm': 5.614497184753418, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.011094939894974232, 'loss_2': 0.0082550048828125, 'loss_3': -16.250442504882812, 'loss_4': 0.7644957304000854, 'epoch': 23.37}
{'loss': 0.0076, 'grad_norm': 5.514097213745117, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.0072248890064656734, 'loss_2': 0.0003848075866699219, 'loss_3': -16.33314323425293, 'loss_4': 0.5841357707977295, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 16:56:26,837 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:26,837 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:20<19:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:34,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016293883323669434, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.28, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.012278796173632145, 'eval_loss_2': 0.004015088081359863, 'eval_loss_3': -18.085771560668945, 'eval_loss_4': 0.6163238883018494, 'epoch': 23.37}
{'loss': 0.0064, 'grad_norm': 4.928575038909912, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.003497120225802064, 'loss_2': 0.0028820037841796875, 'loss_3': -16.56222915649414, 'loss_4': 1.1210479736328125, 'epoch': 23.38}
{'loss': 0.0102, 'grad_norm': 5.25201416015625, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.007360531948506832, 'loss_2': 0.002880096435546875, 'loss_3': -16.315872192382812, 'loss_4': 0.367024302482605, 'epoch': 23.38}
{'loss': 0.0062, 'grad_norm': 4.816813945770264, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.004554894287139177, 'loss_2': 0.0016307830810546875, 'loss_3': -16.420238494873047, 'loss_4': 1.0857256650924683, 'epoch': 23.39}
{'loss': 0.0145, 'grad_norm': 5.831982135772705, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.009419651702046394, 'loss_2': 0.005123138427734375, 'loss_3': -16.214736938476562, 'loss_4': 0.3142399489879608, 'epoch': 23.4}
{'loss': 0.0159, 'grad_norm': 10.360355377197266, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.013502190820872784, 'loss_2': 0.002437591552734375, 'loss_3': -16.25245475769043, 'loss_4': 0.15461860597133636, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 16:56:34,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:34,179 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:28<19:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:41,531 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017080126330256462, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.05, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012591846287250519, 'eval_loss_2': 0.0044882819056510925, 'eval_loss_3': -18.08360481262207, 'eval_loss_4': 0.5787702202796936, 'epoch': 23.4}
{'loss': 0.0118, 'grad_norm': 5.46497917175293, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.007586333900690079, 'loss_2': 0.004169464111328125, 'loss_3': -16.298484802246094, 'loss_4': 0.7020409107208252, 'epoch': 23.41}
{'loss': 0.011, 'grad_norm': 38.59991455078125, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.004825551062822342, 'loss_2': 0.006175994873046875, 'loss_3': -16.522554397583008, 'loss_4': 0.5279296636581421, 'epoch': 23.41}
{'loss': 0.0104, 'grad_norm': 4.740025520324707, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.005564095918089151, 'loss_2': 0.00482940673828125, 'loss_3': -16.214797973632812, 'loss_4': 0.5249795317649841, 'epoch': 23.42}
{'loss': 0.01, 'grad_norm': 4.70925235748291, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.004099862650036812, 'loss_2': 0.00586700439453125, 'loss_3': -16.383132934570312, 'loss_4': 0.9049443006515503, 'epoch': 23.42}
{'loss': 0.0097, 'grad_norm': 4.994593143463135, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.006515482906252146, 'loss_2': 0.00313568115234375, 'loss_3': -16.304527282714844, 'loss_4': 0.06459735333919525, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 16:56:41,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:41,531 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:35<19:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:48,882 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018497362732887268, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.963, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01322929561138153, 'eval_loss_2': 0.005268067121505737, 'eval_loss_3': -18.093948364257812, 'eval_loss_4': 0.5740611553192139, 'epoch': 23.43}
{'loss': 0.0116, 'grad_norm': 4.27362585067749, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.0028726886957883835, 'loss_2': 0.00868988037109375, 'loss_3': -16.389991760253906, 'loss_4': 0.6364042162895203, 'epoch': 23.44}
{'loss': 0.0096, 'grad_norm': 4.588862895965576, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.004611165728420019, 'loss_2': 0.004978179931640625, 'loss_3': -16.245607376098633, 'loss_4': 0.3356590270996094, 'epoch': 23.44}
{'loss': 0.0041, 'grad_norm': 5.248374938964844, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.0040686726570129395, 'loss_2': 9.298324584960938e-06, 'loss_3': -16.330455780029297, 'loss_4': 0.9561231732368469, 'epoch': 23.45}
{'loss': 0.0075, 'grad_norm': 4.615654945373535, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.005113264545798302, 'loss_2': 0.002384185791015625, 'loss_3': -16.42674446105957, 'loss_4': 0.8909859657287598, 'epoch': 23.45}
{'loss': 0.0068, 'grad_norm': 4.256916046142578, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.004094796255230904, 'loss_2': 0.002742767333984375, 'loss_3': -16.327823638916016, 'loss_4': 0.7473856210708618, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 16:56:48,882 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:48,882 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:42<19:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:56:56,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017564287409186363, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.666, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012779883109033108, 'eval_loss_2': 0.00478440523147583, 'eval_loss_3': -18.097698211669922, 'eval_loss_4': 0.6256101131439209, 'epoch': 23.46}
{'loss': 0.0108, 'grad_norm': 5.51704740524292, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.008528454229235649, 'loss_2': 0.00225830078125, 'loss_3': -16.336917877197266, 'loss_4': 0.913776159286499, 'epoch': 23.47}
{'loss': 0.0698, 'grad_norm': 15.896852493286133, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.06893884390592575, 'loss_2': 0.0009021759033203125, 'loss_3': -16.29456901550293, 'loss_4': 0.7859432697296143, 'epoch': 23.47}
{'loss': 0.0109, 'grad_norm': 5.131561756134033, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.003945746459066868, 'loss_2': 0.00691986083984375, 'loss_3': -16.309349060058594, 'loss_4': 0.5720422863960266, 'epoch': 23.48}
{'loss': 0.0108, 'grad_norm': 7.197443008422852, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.010509701445698738, 'loss_2': 0.00027298927307128906, 'loss_3': -16.402637481689453, 'loss_4': 0.38850581645965576, 'epoch': 23.48}
{'loss': 0.014, 'grad_norm': 4.8008713722229, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.004030251409858465, 'loss_2': 0.00995635986328125, 'loss_3': -16.16897964477539, 'loss_4': 0.8201450705528259, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 16:56:56,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:56:56,239 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:39:50<19:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:03,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016940876841545105, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.012900994159281254, 'eval_loss_2': 0.004039883613586426, 'eval_loss_3': -18.085426330566406, 'eval_loss_4': 0.6671977639198303, 'epoch': 23.49}
{'loss': 0.0056, 'grad_norm': 4.439847946166992, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.004322662949562073, 'loss_2': 0.0012884140014648438, 'loss_3': -16.302227020263672, 'loss_4': 1.0063197612762451, 'epoch': 23.49}
{'loss': 0.0078, 'grad_norm': 4.400557994842529, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.005173880606889725, 'loss_2': 0.002628326416015625, 'loss_3': -16.4031982421875, 'loss_4': 0.8444685339927673, 'epoch': 23.5}
{'loss': 0.0107, 'grad_norm': 8.121329307556152, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.009343627840280533, 'loss_2': 0.0013170242309570312, 'loss_3': -16.35400390625, 'loss_4': 0.8244078159332275, 'epoch': 23.51}
{'loss': 0.0092, 'grad_norm': 5.295926570892334, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.005373336374759674, 'loss_2': 0.003875732421875, 'loss_3': -16.348073959350586, 'loss_4': 0.8334095478057861, 'epoch': 23.51}
{'loss': 0.0082, 'grad_norm': 4.628712177276611, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.004580608103424311, 'loss_2': 0.0035724639892578125, 'loss_3': -16.489789962768555, 'loss_4': 0.7129601836204529, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 16:57:03,586 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:03,586 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:39:57<19:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:10,958 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016077272593975067, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.218, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.012533210217952728, 'eval_loss_2': 0.003544062376022339, 'eval_loss_3': -18.092777252197266, 'eval_loss_4': 0.6515646576881409, 'epoch': 23.52}
{'loss': 0.0081, 'grad_norm': 5.271936416625977, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.0069201174192130566, 'loss_2': 0.001171112060546875, 'loss_3': -16.33846664428711, 'loss_4': 0.6919534206390381, 'epoch': 23.52}
{'loss': 0.009, 'grad_norm': 4.6762614250183105, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.004213555715978146, 'loss_2': 0.00476837158203125, 'loss_3': -16.437305450439453, 'loss_4': 0.5776553153991699, 'epoch': 23.53}
{'loss': 0.0087, 'grad_norm': 5.929426670074463, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.008360587060451508, 'loss_2': 0.0003848075866699219, 'loss_3': -16.204980850219727, 'loss_4': 0.41155827045440674, 'epoch': 23.53}
{'loss': 0.0122, 'grad_norm': 7.124929428100586, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.009710496291518211, 'loss_2': 0.0025043487548828125, 'loss_3': -16.18492317199707, 'loss_4': 0.6804081201553345, 'epoch': 23.54}
{'loss': 0.0079, 'grad_norm': 5.1301727294921875, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.007018387317657471, 'loss_2': 0.0008373260498046875, 'loss_3': -16.341527938842773, 'loss_4': 0.04554031044244766, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 16:57:10,958 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:10,958 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:40:04<19:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:18,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01666298322379589, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013037716038525105, 'eval_loss_2': 0.0036252662539482117, 'eval_loss_3': -18.09160614013672, 'eval_loss_4': 0.5769414901733398, 'epoch': 23.55}
{'loss': 0.0247, 'grad_norm': 15.518611907958984, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.021550647914409637, 'loss_2': 0.003139495849609375, 'loss_3': -16.390933990478516, 'loss_4': 0.5678972601890564, 'epoch': 23.55}
{'loss': 0.0052, 'grad_norm': 4.97606897354126, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.004524560645222664, 'loss_2': 0.0006580352783203125, 'loss_3': -16.36063003540039, 'loss_4': 0.7374423742294312, 'epoch': 23.56}
{'loss': 0.0097, 'grad_norm': 4.859185218811035, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.004510003142058849, 'loss_2': 0.00522613525390625, 'loss_3': -16.28173828125, 'loss_4': 0.754802942276001, 'epoch': 23.56}
{'loss': 0.0058, 'grad_norm': 4.785005569458008, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.00513596273958683, 'loss_2': 0.0006432533264160156, 'loss_3': -16.152236938476562, 'loss_4': 0.7530674338340759, 'epoch': 23.57}
{'loss': 0.008, 'grad_norm': 4.461828231811523, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.006409210152924061, 'loss_2': 0.001613616943359375, 'loss_3': -16.292924880981445, 'loss_4': 0.6725698709487915, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 16:57:18,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:18,308 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:40:12<19:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:25,658 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016522206366062164, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.316, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013212009333074093, 'eval_loss_2': 0.003310196101665497, 'eval_loss_3': -18.10340690612793, 'eval_loss_4': 0.4695925712585449, 'epoch': 23.58}
{'loss': 0.0402, 'grad_norm': 15.591845512390137, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.030731650069355965, 'loss_2': 0.0095062255859375, 'loss_3': -16.126754760742188, 'loss_4': 0.5234696865081787, 'epoch': 23.58}
{'loss': 0.0083, 'grad_norm': 5.409339904785156, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.00599300442263484, 'loss_2': 0.002315521240234375, 'loss_3': -16.442644119262695, 'loss_4': -0.033055998384952545, 'epoch': 23.59}
{'loss': 0.0053, 'grad_norm': 4.8326592445373535, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.004600686952471733, 'loss_2': 0.0006561279296875, 'loss_3': -16.515262603759766, 'loss_4': 0.3346029222011566, 'epoch': 23.59}
{'loss': 0.0226, 'grad_norm': 7.311171531677246, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.020496930927038193, 'loss_2': 0.002105712890625, 'loss_3': -16.391685485839844, 'loss_4': 0.44542258977890015, 'epoch': 23.6}
{'loss': 0.0051, 'grad_norm': 5.358285427093506, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.00367522519081831, 'loss_2': 0.001434326171875, 'loss_3': -16.39887046813965, 'loss_4': 0.48546406626701355, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 16:57:25,659 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:25,659 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:19<18:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:33,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01727072149515152, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.858, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013756937347352505, 'eval_loss_2': 0.0035137832164764404, 'eval_loss_3': -18.10540771484375, 'eval_loss_4': 0.41406556963920593, 'epoch': 23.6}
{'loss': 0.0093, 'grad_norm': 5.538216590881348, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.00850822776556015, 'loss_2': 0.0007758140563964844, 'loss_3': -16.316726684570312, 'loss_4': 1.1529659032821655, 'epoch': 23.61}
{'loss': 0.0103, 'grad_norm': 5.559849739074707, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.006074653938412666, 'loss_2': 0.00421905517578125, 'loss_3': -16.48200035095215, 'loss_4': 0.6138719320297241, 'epoch': 23.62}
{'loss': 0.0138, 'grad_norm': 6.265299320220947, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.007773489225655794, 'loss_2': 0.006011962890625, 'loss_3': -16.340837478637695, 'loss_4': 0.601872444152832, 'epoch': 23.62}
{'loss': 0.0061, 'grad_norm': 5.603340148925781, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.005044936202466488, 'loss_2': 0.00101470947265625, 'loss_3': -16.427169799804688, 'loss_4': 0.4617961645126343, 'epoch': 23.63}
{'loss': 0.0176, 'grad_norm': 5.550745487213135, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.007546863052994013, 'loss_2': 0.0100555419921875, 'loss_3': -16.2644100189209, 'loss_4': 0.4651660621166229, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 16:57:33,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:33,009 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:26<18:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:40,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017146456986665726, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.5, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.013401790522038937, 'eval_loss_2': 0.003744669258594513, 'eval_loss_3': -18.105037689208984, 'eval_loss_4': 0.40705984830856323, 'epoch': 23.63}
{'loss': 0.0086, 'grad_norm': 5.524515628814697, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.006500291172415018, 'loss_2': 0.002056121826171875, 'loss_3': -16.261396408081055, 'loss_4': 0.2127893716096878, 'epoch': 23.64}
{'loss': 0.0121, 'grad_norm': 6.168664932250977, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.009347665123641491, 'loss_2': 0.002777099609375, 'loss_3': -16.472455978393555, 'loss_4': 0.468349426984787, 'epoch': 23.65}
{'loss': 0.0098, 'grad_norm': 8.219744682312012, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.009526155889034271, 'loss_2': 0.00023293495178222656, 'loss_3': -16.43189811706543, 'loss_4': 0.6246627569198608, 'epoch': 23.65}
{'loss': 0.0042, 'grad_norm': 4.733025550842285, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.0037328454200178385, 'loss_2': 0.0004260540008544922, 'loss_3': -16.516693115234375, 'loss_4': 0.37113064527511597, 'epoch': 23.66}
{'loss': 0.0081, 'grad_norm': 4.656390190124512, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.003551231697201729, 'loss_2': 0.00458526611328125, 'loss_3': -16.534494400024414, 'loss_4': 0.4499766528606415, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 16:57:40,372 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:40,373 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:34<18:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:47,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017557943239808083, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013349944725632668, 'eval_loss_2': 0.004207998514175415, 'eval_loss_3': -18.094972610473633, 'eval_loss_4': 0.39956414699554443, 'epoch': 23.66}
{'loss': 0.0068, 'grad_norm': 6.754499912261963, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.0067924321629107, 'loss_2': 5.1856040954589844e-05, 'loss_3': -16.428058624267578, 'loss_4': -0.15602947771549225, 'epoch': 23.67}
{'loss': 0.0051, 'grad_norm': 4.7342848777771, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.0042656888253986835, 'loss_2': 0.000881195068359375, 'loss_3': -16.496761322021484, 'loss_4': 0.8816218376159668, 'epoch': 23.67}
{'loss': 0.0086, 'grad_norm': 4.963282108306885, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.008306962437927723, 'loss_2': 0.00028395652770996094, 'loss_3': -16.299047470092773, 'loss_4': 0.015431620180606842, 'epoch': 23.68}
{'loss': 0.0086, 'grad_norm': 7.267332553863525, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.004662353079766035, 'loss_2': 0.00396728515625, 'loss_3': -16.33865737915039, 'loss_4': 0.41320762038230896, 'epoch': 23.69}
{'loss': 0.0126, 'grad_norm': 4.241235256195068, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.0032336439471691847, 'loss_2': 0.00933837890625, 'loss_3': -16.483564376831055, 'loss_4': 0.1750996708869934, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 16:57:47,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:47,719 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:41<18:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:57:55,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017924662679433823, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.307, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013040023855865002, 'eval_loss_2': 0.004884637892246246, 'eval_loss_3': -18.095239639282227, 'eval_loss_4': 0.381294846534729, 'epoch': 23.69}
{'loss': 0.0063, 'grad_norm': 4.887574672698975, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.004013183061033487, 'loss_2': 0.002277374267578125, 'loss_3': -16.38368034362793, 'loss_4': 0.29149115085601807, 'epoch': 23.7}
{'loss': 0.0048, 'grad_norm': 4.8529438972473145, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.004149423912167549, 'loss_2': 0.0006122589111328125, 'loss_3': -16.50754165649414, 'loss_4': 0.27188342809677124, 'epoch': 23.7}
{'loss': 0.0554, 'grad_norm': 15.445451736450195, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.04789073392748833, 'loss_2': 0.007476806640625, 'loss_3': -16.37579917907715, 'loss_4': 0.56587153673172, 'epoch': 23.71}
{'loss': 0.0086, 'grad_norm': 4.9087300300598145, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.005206362809985876, 'loss_2': 0.00337982177734375, 'loss_3': -16.340429306030273, 'loss_4': 0.4574386179447174, 'epoch': 23.72}
{'loss': 0.0102, 'grad_norm': 4.747180461883545, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.004673995543271303, 'loss_2': 0.00550079345703125, 'loss_3': -16.338422775268555, 'loss_4': 0.35096266865730286, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 16:57:55,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:57:55,066 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:49<18:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:02,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0172526054084301, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.534, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.012600843794643879, 'eval_loss_2': 0.004651762545108795, 'eval_loss_3': -18.10049057006836, 'eval_loss_4': 0.34759703278541565, 'epoch': 23.72}
{'loss': 0.0072, 'grad_norm': 6.577467918395996, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.00540225300937891, 'loss_2': 0.0018177032470703125, 'loss_3': -16.405935287475586, 'loss_4': 0.31913262605667114, 'epoch': 23.73}
{'loss': 0.0046, 'grad_norm': 4.76862096786499, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.003324915189296007, 'loss_2': 0.0013036727905273438, 'loss_3': -16.22677230834961, 'loss_4': 0.2839500606060028, 'epoch': 23.73}
{'loss': 0.0141, 'grad_norm': 11.281171798706055, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.013429418206214905, 'loss_2': 0.0006780624389648438, 'loss_3': -16.287242889404297, 'loss_4': 0.03843732923269272, 'epoch': 23.74}
{'loss': 0.0125, 'grad_norm': 5.804612636566162, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.006507095880806446, 'loss_2': 0.0059814453125, 'loss_3': -16.555768966674805, 'loss_4': 0.014877993613481522, 'epoch': 23.74}
{'loss': 0.0102, 'grad_norm': 6.173140048980713, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.007103872485458851, 'loss_2': 0.0030765533447265625, 'loss_3': -16.4666690826416, 'loss_4': -0.019480843096971512, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 16:58:02,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:02,407 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:40:56<18:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:09,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0169732253998518, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.221, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.012642493471503258, 'eval_loss_2': 0.004330731928348541, 'eval_loss_3': -18.091064453125, 'eval_loss_4': 0.3228171467781067, 'epoch': 23.75}
{'loss': 0.0145, 'grad_norm': 11.479046821594238, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.012672468088567257, 'loss_2': 0.0018558502197265625, 'loss_3': -16.281415939331055, 'loss_4': 0.08487263321876526, 'epoch': 23.76}
{'loss': 0.0055, 'grad_norm': 4.760921001434326, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.00498391967266798, 'loss_2': 0.0005369186401367188, 'loss_3': -16.164852142333984, 'loss_4': 0.3199734389781952, 'epoch': 23.76}
{'loss': 0.0063, 'grad_norm': 5.656055927276611, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.0056099542416632175, 'loss_2': 0.0006585121154785156, 'loss_3': -16.37674331665039, 'loss_4': 0.4037255346775055, 'epoch': 23.77}
{'loss': 0.0072, 'grad_norm': 4.12429141998291, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.003930507227778435, 'loss_2': 0.00327301025390625, 'loss_3': -16.268600463867188, 'loss_4': 0.3794096112251282, 'epoch': 23.77}
{'loss': 0.0066, 'grad_norm': 7.586434841156006, 'learning_rate': 6.25e-06, 'loss_1': 0.005551810376346111, 'loss_2': 0.0010852813720703125, 'loss_3': -16.468168258666992, 'loss_4': 0.0038839690387248993, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 16:58:09,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:09,768 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:41:03<18:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:17,130 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017090801149606705, 'eval_runtime': 3.8222, 'eval_samples_per_second': 267.907, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.013165927492082119, 'eval_loss_2': 0.00392487645149231, 'eval_loss_3': -18.09323501586914, 'eval_loss_4': 0.27625328302383423, 'epoch': 23.78}
{'loss': 0.0067, 'grad_norm': 4.891664505004883, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.006164216902107, 'loss_2': 0.0005502700805664062, 'loss_3': -16.377174377441406, 'loss_4': 0.05700983852148056, 'epoch': 23.78}
{'loss': 0.0057, 'grad_norm': 4.426660537719727, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.004361406434327364, 'loss_2': 0.001316070556640625, 'loss_3': -16.353910446166992, 'loss_4': 0.14477846026420593, 'epoch': 23.79}
{'loss': 0.0096, 'grad_norm': 4.238940715789795, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.0029792217537760735, 'loss_2': 0.006656646728515625, 'loss_3': -16.398366928100586, 'loss_4': 0.4992417097091675, 'epoch': 23.8}
{'loss': 0.0093, 'grad_norm': 4.785280227661133, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.0051203081384301186, 'loss_2': 0.00415802001953125, 'loss_3': -16.356582641601562, 'loss_4': 0.2622547447681427, 'epoch': 23.8}
{'loss': 0.0224, 'grad_norm': 4.665317535400391, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.004228925798088312, 'loss_2': 0.0181884765625, 'loss_3': -16.530590057373047, 'loss_4': -0.01585763692855835, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 16:58:17,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:17,131 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:41:11<18:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:24,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017964696511626244, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013729546219110489, 'eval_loss_2': 0.0042351484298706055, 'eval_loss_3': -18.089675903320312, 'eval_loss_4': 0.22311457991600037, 'epoch': 23.81}
{'loss': 0.007, 'grad_norm': 4.885985851287842, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.005489981267601252, 'loss_2': 0.00153350830078125, 'loss_3': -16.331687927246094, 'loss_4': 0.43486469984054565, 'epoch': 23.81}
{'loss': 0.0161, 'grad_norm': 9.174837112426758, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.013758987188339233, 'loss_2': 0.0023555755615234375, 'loss_3': -16.41278839111328, 'loss_4': 0.20989161729812622, 'epoch': 23.82}
{'loss': 0.0051, 'grad_norm': 5.019516944885254, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.0022537189070135355, 'loss_2': 0.002887725830078125, 'loss_3': -16.441020965576172, 'loss_4': 0.016502156853675842, 'epoch': 23.83}
{'loss': 0.0131, 'grad_norm': 8.561699867248535, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.009900880046188831, 'loss_2': 0.00324249267578125, 'loss_3': -16.324739456176758, 'loss_4': 0.09459060430526733, 'epoch': 23.83}
{'loss': 0.0079, 'grad_norm': 5.844500541687012, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.006501535885035992, 'loss_2': 0.0014448165893554688, 'loss_3': -16.407123565673828, 'loss_4': 0.14862389862537384, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 16:58:24,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:24,478 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:18<18:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:31,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017582004889845848, 'eval_runtime': 3.801, 'eval_samples_per_second': 269.404, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013511811383068562, 'eval_loss_2': 0.004070192575454712, 'eval_loss_3': -18.09515953063965, 'eval_loss_4': 0.21673382818698883, 'epoch': 23.84}
{'loss': 0.0098, 'grad_norm': 4.527082443237305, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.0029262083116918802, 'loss_2': 0.00685882568359375, 'loss_3': -16.452285766601562, 'loss_4': 0.31894397735595703, 'epoch': 23.84}
{'loss': 0.0102, 'grad_norm': 5.833835601806641, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.004598987754434347, 'loss_2': 0.00557708740234375, 'loss_3': -16.464879989624023, 'loss_4': 0.18960560858249664, 'epoch': 23.85}
{'loss': 0.0181, 'grad_norm': 8.731322288513184, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.017693307250738144, 'loss_2': 0.00036907196044921875, 'loss_3': -16.228408813476562, 'loss_4': 0.6672395467758179, 'epoch': 23.85}
{'loss': 0.006, 'grad_norm': 4.647377967834473, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.005587216001003981, 'loss_2': 0.00041031837463378906, 'loss_3': -16.72162628173828, 'loss_4': 0.16930890083312988, 'epoch': 23.86}
{'loss': 0.0083, 'grad_norm': 5.42301082611084, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.0032570206094533205, 'loss_2': 0.00506591796875, 'loss_3': -16.4330997467041, 'loss_4': 0.14349131286144257, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 16:58:31,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:31,822 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:25<18:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:39,170 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01707778126001358, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.16, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013191916048526764, 'eval_loss_2': 0.0038858652114868164, 'eval_loss_3': -18.08504867553711, 'eval_loss_4': 0.30553320050239563, 'epoch': 23.87}
{'loss': 0.0114, 'grad_norm': 5.100232124328613, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.006316652521491051, 'loss_2': 0.00504302978515625, 'loss_3': -16.390827178955078, 'loss_4': -0.12902860343456268, 'epoch': 23.87}
{'loss': 0.0151, 'grad_norm': 8.771106719970703, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.01380355004221201, 'loss_2': 0.0012969970703125, 'loss_3': -16.507177352905273, 'loss_4': -0.06544404476881027, 'epoch': 23.88}
{'loss': 0.0107, 'grad_norm': 5.929676532745361, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.008287312462925911, 'loss_2': 0.0023651123046875, 'loss_3': -16.346086502075195, 'loss_4': 0.07273934036493301, 'epoch': 23.88}
{'loss': 0.01, 'grad_norm': 6.663756370544434, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.003778984537348151, 'loss_2': 0.0061798095703125, 'loss_3': -16.360595703125, 'loss_4': 0.49871212244033813, 'epoch': 23.89}
{'loss': 0.0105, 'grad_norm': 6.545542240142822, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.00879625603556633, 'loss_2': 0.001739501953125, 'loss_3': -16.409440994262695, 'loss_4': 0.6849257946014404, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 16:58:39,170 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:39,170 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:33<18:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:46,521 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01737039163708687, 'eval_runtime': 3.8023, 'eval_samples_per_second': 269.309, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01361011527478695, 'eval_loss_2': 0.0037602782249450684, 'eval_loss_3': -18.082447052001953, 'eval_loss_4': 0.436273455619812, 'epoch': 23.9}
{'loss': 0.0117, 'grad_norm': 5.2895708084106445, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.00898691639304161, 'loss_2': 0.0027313232421875, 'loss_3': -16.6849308013916, 'loss_4': 0.3813272714614868, 'epoch': 23.9}
{'loss': 0.0141, 'grad_norm': 5.705337047576904, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.006310304161161184, 'loss_2': 0.00775909423828125, 'loss_3': -16.31436538696289, 'loss_4': 0.32923170924186707, 'epoch': 23.91}
{'loss': 0.0037, 'grad_norm': 4.977539539337158, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.0029570520855486393, 'loss_2': 0.0007886886596679688, 'loss_3': -16.29762840270996, 'loss_4': 0.3975440561771393, 'epoch': 23.91}
{'loss': 0.0083, 'grad_norm': 4.595217704772949, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.00478698592633009, 'loss_2': 0.0035247802734375, 'loss_3': -16.396045684814453, 'loss_4': 0.5929003357887268, 'epoch': 23.92}
{'loss': 0.0117, 'grad_norm': 9.168457984924316, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.010161658748984337, 'loss_2': 0.0015735626220703125, 'loss_3': -16.25899887084961, 'loss_4': 0.42195218801498413, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 16:58:46,521 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:46,521 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:40<18:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:58:53,875 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017452392727136612, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013591917231678963, 'eval_loss_2': 0.0038604736328125, 'eval_loss_3': -18.094167709350586, 'eval_loss_4': 0.5135706067085266, 'epoch': 23.92}
{'loss': 0.0049, 'grad_norm': 5.2050676345825195, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.00476103788241744, 'loss_2': 0.0001747608184814453, 'loss_3': -16.371196746826172, 'loss_4': 0.321111261844635, 'epoch': 23.93}
{'loss': 0.0079, 'grad_norm': 4.854655742645264, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.004020975902676582, 'loss_2': 0.003864288330078125, 'loss_3': -16.472986221313477, 'loss_4': 0.0047185346484184265, 'epoch': 23.94}
{'loss': 0.0091, 'grad_norm': 4.513570785522461, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.003644324606284499, 'loss_2': 0.00543975830078125, 'loss_3': -16.242616653442383, 'loss_4': 0.8523966670036316, 'epoch': 23.94}
{'loss': 0.0083, 'grad_norm': 4.648722171783447, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.006015518680214882, 'loss_2': 0.002288818359375, 'loss_3': -16.434371948242188, 'loss_4': 0.3293408751487732, 'epoch': 23.95}
{'loss': 0.0071, 'grad_norm': 5.64777135848999, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.002649608999490738, 'loss_2': 0.004467010498046875, 'loss_3': -16.332443237304688, 'loss_4': 0.28175193071365356, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 16:58:53,875 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:58:53,875 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:47<17:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:01,227 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01735079288482666, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013653025031089783, 'eval_loss_2': 0.0036977678537368774, 'eval_loss_3': -18.105918884277344, 'eval_loss_4': 0.586959958076477, 'epoch': 23.95}
{'loss': 0.0107, 'grad_norm': 5.113181114196777, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.007897591218352318, 'loss_2': 0.0028133392333984375, 'loss_3': -16.422672271728516, 'loss_4': 0.5937749147415161, 'epoch': 23.96}
{'loss': 0.0091, 'grad_norm': 5.544330596923828, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.008667745627462864, 'loss_2': 0.0004515647888183594, 'loss_3': -16.491167068481445, 'loss_4': 0.431148499250412, 'epoch': 23.97}
{'loss': 0.0144, 'grad_norm': 6.137713432312012, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.010054820217192173, 'loss_2': 0.00431060791015625, 'loss_3': -16.454269409179688, 'loss_4': 0.971576988697052, 'epoch': 23.97}
{'loss': 0.007, 'grad_norm': 5.86100959777832, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.00580066442489624, 'loss_2': 0.0011844635009765625, 'loss_3': -16.519176483154297, 'loss_4': 0.5787022113800049, 'epoch': 23.98}
{'loss': 0.0075, 'grad_norm': 5.3668389320373535, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.005202212370932102, 'loss_2': 0.0022754669189453125, 'loss_3': -16.353008270263672, 'loss_4': 0.2511632442474365, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 16:59:01,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:01,227 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:41:54<17:03,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 16:59:08,256 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0171348974108696, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.272, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013421304523944855, 'eval_loss_2': 0.0037135928869247437, 'eval_loss_3': -18.11080551147461, 'eval_loss_4': 0.6403740048408508, 'epoch': 23.98}
{'loss': 0.0052, 'grad_norm': 5.11043119430542, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.004165757913142443, 'loss_2': 0.0010051727294921875, 'loss_3': -16.33553695678711, 'loss_4': 0.8849903345108032, 'epoch': 23.99}
{'loss': 0.0106, 'grad_norm': 5.141217231750488, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.007939862087368965, 'loss_2': 0.0026607513427734375, 'loss_3': -16.470035552978516, 'loss_4': 0.8553975820541382, 'epoch': 23.99}
{'loss': 0.008, 'grad_norm': 6.085229873657227, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.002476984169334173, 'loss_2': 0.00548553466796875, 'loss_3': -16.435701370239258, 'loss_4': 0.03723395615816116, 'epoch': 24.0}
{'loss': 0.0114, 'grad_norm': 7.213879108428955, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.010365285910665989, 'loss_2': 0.0010166168212890625, 'loss_3': -16.498992919921875, 'loss_4': 0.548236608505249, 'epoch': 24.01}
{'loss': 0.0063, 'grad_norm': 4.775991439819336, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.004448374267667532, 'loss_2': 0.0018758773803710938, 'loss_3': -16.346662521362305, 'loss_4': 0.4489158093929291, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 16:59:08,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:08,256 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:42:02<17:37,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 16:59:15,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017935702577233315, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013517477549612522, 'eval_loss_2': 0.004418224096298218, 'eval_loss_3': -18.110536575317383, 'eval_loss_4': 0.6496551036834717, 'epoch': 24.01}
{'loss': 0.0172, 'grad_norm': 5.230744361877441, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.005077878013253212, 'loss_2': 0.01215362548828125, 'loss_3': -16.530651092529297, 'loss_4': 0.634917676448822, 'epoch': 24.02}
{'loss': 0.0089, 'grad_norm': 5.167726516723633, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.006477286107838154, 'loss_2': 0.002429962158203125, 'loss_3': -16.467302322387695, 'loss_4': 0.5722813010215759, 'epoch': 24.02}
{'loss': 0.0084, 'grad_norm': 5.076464653015137, 'learning_rate': 6e-06, 'loss_1': 0.007540915161371231, 'loss_2': 0.0008726119995117188, 'loss_3': -16.549636840820312, 'loss_4': 0.12690794467926025, 'epoch': 24.03}
{'loss': 0.018, 'grad_norm': 5.991181373596191, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.012745856307446957, 'loss_2': 0.0052490234375, 'loss_3': -16.38090705871582, 'loss_4': 0.8215112686157227, 'epoch': 24.03}
{'loss': 0.0119, 'grad_norm': 4.722085952758789, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.004660975653678179, 'loss_2': 0.0072479248046875, 'loss_3': -16.28495979309082, 'loss_4': 0.8861321210861206, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 16:59:15,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:15,608 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:42:09<17:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:22,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019370850175619125, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.318, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.013946007937192917, 'eval_loss_2': 0.0054248422384262085, 'eval_loss_3': -18.125993728637695, 'eval_loss_4': 0.7143258452415466, 'epoch': 24.04}
{'loss': 0.0121, 'grad_norm': 5.175443649291992, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.004918579012155533, 'loss_2': 0.0072174072265625, 'loss_3': -16.446197509765625, 'loss_4': 0.7040454149246216, 'epoch': 24.05}
{'loss': 0.0249, 'grad_norm': 9.75145435333252, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.018531812354922295, 'loss_2': 0.00635528564453125, 'loss_3': -16.413837432861328, 'loss_4': 0.7093693017959595, 'epoch': 24.05}
{'loss': 0.0045, 'grad_norm': 4.498943328857422, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.004239872097969055, 'loss_2': 0.00029087066650390625, 'loss_3': -16.391294479370117, 'loss_4': 1.131993293762207, 'epoch': 24.06}
{'loss': 0.0235, 'grad_norm': 7.937102317810059, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.017052236944437027, 'loss_2': 0.00640106201171875, 'loss_3': -16.375545501708984, 'loss_4': 0.9204154014587402, 'epoch': 24.06}
{'loss': 0.006, 'grad_norm': 5.056921005249023, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.005151690915226936, 'loss_2': 0.0007987022399902344, 'loss_3': -16.38939666748047, 'loss_4': 0.3635736405849457, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 16:59:22,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:22,956 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:16<17:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:30,311 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01720547489821911, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012970670126378536, 'eval_loss_2': 0.004234805703163147, 'eval_loss_3': -18.12140464782715, 'eval_loss_4': 0.7696709036827087, 'epoch': 24.07}
{'loss': 0.0099, 'grad_norm': 5.230180740356445, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.00640130415558815, 'loss_2': 0.0034923553466796875, 'loss_3': -16.418563842773438, 'loss_4': 0.5707951784133911, 'epoch': 24.08}
{'loss': 0.0079, 'grad_norm': 4.361269950866699, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.00658482126891613, 'loss_2': 0.0013189315795898438, 'loss_3': -16.43206787109375, 'loss_4': 0.635036051273346, 'epoch': 24.08}
{'loss': 0.0139, 'grad_norm': 5.765861988067627, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.007308605592697859, 'loss_2': 0.006565093994140625, 'loss_3': -16.50102996826172, 'loss_4': 0.6017364263534546, 'epoch': 24.09}
{'loss': 0.0058, 'grad_norm': 4.872610569000244, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.003492046846076846, 'loss_2': 0.00234222412109375, 'loss_3': -16.420391082763672, 'loss_4': 0.9768660068511963, 'epoch': 24.09}
{'loss': 0.0105, 'grad_norm': 4.334306716918945, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.0037527538370341063, 'loss_2': 0.0067596435546875, 'loss_3': -16.364723205566406, 'loss_4': 0.704524576663971, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 16:59:30,311 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:30,311 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:24<17:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:37,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016916580498218536, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.715, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.012379990890622139, 'eval_loss_2': 0.004536591470241547, 'eval_loss_3': -18.126617431640625, 'eval_loss_4': 0.7804434299468994, 'epoch': 24.1}
{'loss': 0.0101, 'grad_norm': 5.662252426147461, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.005973035003989935, 'loss_2': 0.00408935546875, 'loss_3': -16.49782371520996, 'loss_4': 0.864700973033905, 'epoch': 24.1}
{'loss': 0.0075, 'grad_norm': 5.272613525390625, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.0063812765292823315, 'loss_2': 0.0011444091796875, 'loss_3': -16.350486755371094, 'loss_4': 0.7445542216300964, 'epoch': 24.11}
{'loss': 0.0126, 'grad_norm': 4.674403667449951, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.00464125769212842, 'loss_2': 0.00798797607421875, 'loss_3': -16.362483978271484, 'loss_4': 0.06334134936332703, 'epoch': 24.12}
{'loss': 0.007, 'grad_norm': 5.095414161682129, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.004478118382394314, 'loss_2': 0.002506256103515625, 'loss_3': -16.22764015197754, 'loss_4': 0.9740852117538452, 'epoch': 24.12}
{'loss': 0.0084, 'grad_norm': 5.060726642608643, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.0045698597095906734, 'loss_2': 0.003810882568359375, 'loss_3': -16.368072509765625, 'loss_4': 0.6141319274902344, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 16:59:37,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:37,677 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:31<17:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:45,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016711533069610596, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.088, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012856007553637028, 'eval_loss_2': 0.0038555264472961426, 'eval_loss_3': -18.116619110107422, 'eval_loss_4': 0.7777183651924133, 'epoch': 24.13}
{'loss': 0.0097, 'grad_norm': 5.320868492126465, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.008394294418394566, 'loss_2': 0.0012950897216796875, 'loss_3': -16.309499740600586, 'loss_4': 1.1082316637039185, 'epoch': 24.13}
{'loss': 0.0091, 'grad_norm': 5.6503753662109375, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.00821615569293499, 'loss_2': 0.000843048095703125, 'loss_3': -16.276119232177734, 'loss_4': 0.6487499475479126, 'epoch': 24.14}
{'loss': 0.0118, 'grad_norm': 4.69473123550415, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.0039767855778336525, 'loss_2': 0.007801055908203125, 'loss_3': -16.27096176147461, 'loss_4': 0.47406482696533203, 'epoch': 24.15}
{'loss': 0.0105, 'grad_norm': 5.643670558929443, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.004748343024402857, 'loss_2': 0.00576019287109375, 'loss_3': -16.519800186157227, 'loss_4': 0.9457058906555176, 'epoch': 24.15}
{'loss': 0.0178, 'grad_norm': 4.623115539550781, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.005488668568432331, 'loss_2': 0.01226806640625, 'loss_3': -16.477603912353516, 'loss_4': 1.2613030672073364, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 16:59:45,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:45,039 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:39<17:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:52,411 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016887549310922623, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.786, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013611960224807262, 'eval_loss_2': 0.0032755881547927856, 'eval_loss_3': -18.111515045166016, 'eval_loss_4': 0.8238310813903809, 'epoch': 24.16}
{'loss': 0.0124, 'grad_norm': 4.6779890060424805, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.0041639599949121475, 'loss_2': 0.0082244873046875, 'loss_3': -16.267322540283203, 'loss_4': 0.6107123494148254, 'epoch': 24.16}
{'loss': 0.0083, 'grad_norm': 4.160512924194336, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.0032225947361439466, 'loss_2': 0.00505828857421875, 'loss_3': -16.612442016601562, 'loss_4': 1.1743042469024658, 'epoch': 24.17}
{'loss': 0.0204, 'grad_norm': 8.737366676330566, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.01495621632784605, 'loss_2': 0.0054168701171875, 'loss_3': -16.631967544555664, 'loss_4': 0.5982138514518738, 'epoch': 24.17}
{'loss': 0.0139, 'grad_norm': 7.916757106781006, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.006507035810500383, 'loss_2': 0.007389068603515625, 'loss_3': -16.388275146484375, 'loss_4': 1.2572283744812012, 'epoch': 24.18}
{'loss': 0.0086, 'grad_norm': 9.915631294250488, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.003958551213145256, 'loss_2': 0.0045928955078125, 'loss_3': -16.451757431030273, 'loss_4': 0.9014785289764404, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 16:59:52,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:52,411 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:46<17:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 16:59:59,773 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017846502363681793, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.912, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013773120008409023, 'eval_loss_2': 0.004073381423950195, 'eval_loss_3': -18.109167098999023, 'eval_loss_4': 0.9071236848831177, 'epoch': 24.19}
{'loss': 0.0088, 'grad_norm': 4.696126937866211, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.004063575994223356, 'loss_2': 0.004734039306640625, 'loss_3': -16.322113037109375, 'loss_4': 1.044826626777649, 'epoch': 24.19}
{'loss': 0.0926, 'grad_norm': 15.627653121948242, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.08527420461177826, 'loss_2': 0.0073089599609375, 'loss_3': -16.494626998901367, 'loss_4': 1.5446401834487915, 'epoch': 24.2}
{'loss': 0.0058, 'grad_norm': 5.640307903289795, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.005591557361185551, 'loss_2': 0.00022280216217041016, 'loss_3': -16.07425880432129, 'loss_4': 0.8409064412117004, 'epoch': 24.2}
{'loss': 0.0083, 'grad_norm': 4.686933517456055, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.0036887943278998137, 'loss_2': 0.004611968994140625, 'loss_3': -16.447059631347656, 'loss_4': 0.9678826928138733, 'epoch': 24.21}
{'loss': 0.015, 'grad_norm': 6.884456157684326, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.01202393602579832, 'loss_2': 0.0029926300048828125, 'loss_3': -16.307018280029297, 'loss_4': 0.6770118474960327, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 16:59:59,773 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 16:59:59,773 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:42:53<17:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:07,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018886573612689972, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.633, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.014203762635588646, 'eval_loss_2': 0.004682809114456177, 'eval_loss_3': -18.12363052368164, 'eval_loss_4': 0.931199312210083, 'epoch': 24.22}
{'loss': 0.0131, 'grad_norm': 5.881483554840088, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.009776335209608078, 'loss_2': 0.00331878662109375, 'loss_3': -16.192684173583984, 'loss_4': 0.9503389000892639, 'epoch': 24.22}
{'loss': 0.0176, 'grad_norm': 5.296477794647217, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.007692602928727865, 'loss_2': 0.00989532470703125, 'loss_3': -16.37038803100586, 'loss_4': 1.0537323951721191, 'epoch': 24.23}
{'loss': 0.0078, 'grad_norm': 4.769780158996582, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.0026508443988859653, 'loss_2': 0.0051422119140625, 'loss_3': -16.43675422668457, 'loss_4': 0.9222485423088074, 'epoch': 24.23}
{'loss': 0.0199, 'grad_norm': 8.238007545471191, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.01118395570665598, 'loss_2': 0.008697509765625, 'loss_3': -16.364852905273438, 'loss_4': 1.26088547706604, 'epoch': 24.24}
{'loss': 0.0105, 'grad_norm': 4.6705098152160645, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.0032615161035209894, 'loss_2': 0.0072479248046875, 'loss_3': -16.523927688598633, 'loss_4': 0.866712749004364, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 17:00:07,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:07,144 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:43:01<17:21,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 17:00:14,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01877707988023758, 'eval_runtime': 4.0233, 'eval_samples_per_second': 254.52, 'eval_steps_per_second': 3.977, 'eval_loss_1': 0.014178255572915077, 'eval_loss_2': 0.004598826169967651, 'eval_loss_3': -18.128360748291016, 'eval_loss_4': 0.9292011857032776, 'epoch': 24.24}
{'loss': 0.0069, 'grad_norm': 5.043557167053223, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.006219456437975168, 'loss_2': 0.00069427490234375, 'loss_3': -16.278541564941406, 'loss_4': 1.019761562347412, 'epoch': 24.25}
{'loss': 0.009, 'grad_norm': 4.795252799987793, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.0018010953208431602, 'loss_2': 0.0071563720703125, 'loss_3': -16.23179054260254, 'loss_4': 0.7770068645477295, 'epoch': 24.26}
{'loss': 0.0053, 'grad_norm': 5.186565399169922, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.00468078488484025, 'loss_2': 0.000606536865234375, 'loss_3': -16.395397186279297, 'loss_4': 1.0847554206848145, 'epoch': 24.26}
{'loss': 0.0027, 'grad_norm': 4.511547088623047, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.0022199605591595173, 'loss_2': 0.00048613548278808594, 'loss_3': -16.27438735961914, 'loss_4': 0.8429765701293945, 'epoch': 24.27}
{'loss': 0.0068, 'grad_norm': 4.9403300285339355, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.006545912008732557, 'loss_2': 0.0002111196517944336, 'loss_3': -16.242664337158203, 'loss_4': 0.7348296642303467, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 17:00:14,727 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:14,727 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:43:08<17:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:22,097 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018425269052386284, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.2, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.014434002339839935, 'eval_loss_2': 0.003991264849901199, 'eval_loss_3': -18.12519645690918, 'eval_loss_4': 0.9383776187896729, 'epoch': 24.27}
{'loss': 0.0155, 'grad_norm': 5.969847202301025, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.00786572601646185, 'loss_2': 0.0076141357421875, 'loss_3': -16.31209945678711, 'loss_4': 0.6428989768028259, 'epoch': 24.28}
{'loss': 0.0093, 'grad_norm': 7.4554901123046875, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.0033375013154000044, 'loss_2': 0.00597381591796875, 'loss_3': -16.516868591308594, 'loss_4': 0.7224718332290649, 'epoch': 24.28}
{'loss': 0.0043, 'grad_norm': 4.8959150314331055, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.002962664468213916, 'loss_2': 0.0013275146484375, 'loss_3': -16.580036163330078, 'loss_4': 1.3072125911712646, 'epoch': 24.29}
{'loss': 0.0151, 'grad_norm': 9.113113403320312, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.012816721573472023, 'loss_2': 0.002239227294921875, 'loss_3': -16.265113830566406, 'loss_4': 0.9851306080818176, 'epoch': 24.3}
{'loss': 0.0091, 'grad_norm': 5.614355564117432, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.003883443074300885, 'loss_2': 0.00518035888671875, 'loss_3': -16.585784912109375, 'loss_4': 1.3008427619934082, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 17:00:22,097 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:22,097 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:43:16<16:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:29,460 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017455626279115677, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.633, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01421417761594057, 'eval_loss_2': 0.0032414495944976807, 'eval_loss_3': -18.1187686920166, 'eval_loss_4': 0.9127188920974731, 'epoch': 24.3}
{'loss': 0.0077, 'grad_norm': 4.762596130371094, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.005214938893914223, 'loss_2': 0.00244140625, 'loss_3': -16.260150909423828, 'loss_4': 0.9145570993423462, 'epoch': 24.31}
{'loss': 0.0087, 'grad_norm': 4.416543960571289, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.007073254324495792, 'loss_2': 0.00164031982421875, 'loss_3': -16.496376037597656, 'loss_4': 1.3016349077224731, 'epoch': 24.31}
{'loss': 0.0128, 'grad_norm': 12.272881507873535, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.011802231892943382, 'loss_2': 0.0010128021240234375, 'loss_3': -16.351205825805664, 'loss_4': 0.8350074887275696, 'epoch': 24.32}
{'loss': 0.0046, 'grad_norm': 5.129242420196533, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.002715201349928975, 'loss_2': 0.0019330978393554688, 'loss_3': -16.351991653442383, 'loss_4': 0.46682751178741455, 'epoch': 24.33}
{'loss': 0.0053, 'grad_norm': 4.632319450378418, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.005128012504428625, 'loss_2': 0.0001857280731201172, 'loss_3': -16.369657516479492, 'loss_4': 0.8321682810783386, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 17:00:29,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:29,460 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:23<16:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:36,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016452522948384285, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.694, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013129059225320816, 'eval_loss_2': 0.003323465585708618, 'eval_loss_3': -18.12343978881836, 'eval_loss_4': 0.9216665029525757, 'epoch': 24.33}
{'loss': 0.0037, 'grad_norm': 4.72881555557251, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.00318988342769444, 'loss_2': 0.0005168914794921875, 'loss_3': -16.567041397094727, 'loss_4': 0.9655088186264038, 'epoch': 24.34}
{'loss': 0.0065, 'grad_norm': 4.153693675994873, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.0034805748146027327, 'loss_2': 0.0030364990234375, 'loss_3': -16.478939056396484, 'loss_4': 0.4919082522392273, 'epoch': 24.34}
{'loss': 0.0116, 'grad_norm': 5.313503265380859, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.004690852016210556, 'loss_2': 0.00695037841796875, 'loss_3': -16.389373779296875, 'loss_4': 0.8051270246505737, 'epoch': 24.35}
{'loss': 0.0062, 'grad_norm': 4.393308639526367, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.0035913013853132725, 'loss_2': 0.0026187896728515625, 'loss_3': -16.261594772338867, 'loss_4': 1.066298484802246, 'epoch': 24.35}
{'loss': 0.0232, 'grad_norm': 13.828807830810547, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.016935620456933975, 'loss_2': 0.006244659423828125, 'loss_3': -16.281837463378906, 'loss_4': 1.1097819805145264, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 17:00:36,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:36,827 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:30<16:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:44,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016116391867399216, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.863, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012892257422208786, 'eval_loss_2': 0.0032241344451904297, 'eval_loss_3': -18.131237030029297, 'eval_loss_4': 0.986139714717865, 'epoch': 24.36}
{'loss': 0.0046, 'grad_norm': 5.395358562469482, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.004476452711969614, 'loss_2': 9.655952453613281e-05, 'loss_3': -16.499631881713867, 'loss_4': 1.1453227996826172, 'epoch': 24.37}
{'loss': 0.0074, 'grad_norm': 4.369172096252441, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.004243189934641123, 'loss_2': 0.0031299591064453125, 'loss_3': -16.249004364013672, 'loss_4': 0.8405442833900452, 'epoch': 24.37}
{'loss': 0.065, 'grad_norm': 12.827783584594727, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.062861368060112, 'loss_2': 0.0021533966064453125, 'loss_3': -16.439006805419922, 'loss_4': 1.2188054323196411, 'epoch': 24.38}
{'loss': 0.0194, 'grad_norm': 7.381530284881592, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.012296847999095917, 'loss_2': 0.007080078125, 'loss_3': -16.410537719726562, 'loss_4': 1.0875300168991089, 'epoch': 24.38}
{'loss': 0.0056, 'grad_norm': 5.065059661865234, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.004211725201457739, 'loss_2': 0.0014276504516601562, 'loss_3': -16.41440773010254, 'loss_4': 0.9873014092445374, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 17:00:44,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:44,188 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:38<16:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:51,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01665600575506687, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.625, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01340788509696722, 'eval_loss_2': 0.0032481178641319275, 'eval_loss_3': -18.132368087768555, 'eval_loss_4': 1.0278509855270386, 'epoch': 24.39}
{'loss': 0.0042, 'grad_norm': 4.569399356842041, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.0035983191337436438, 'loss_2': 0.000591278076171875, 'loss_3': -16.59987449645996, 'loss_4': 1.288745403289795, 'epoch': 24.4}
{'loss': 0.0093, 'grad_norm': 4.990878105163574, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.005942027550190687, 'loss_2': 0.003326416015625, 'loss_3': -16.450115203857422, 'loss_4': 1.0131628513336182, 'epoch': 24.4}
{'loss': 0.0133, 'grad_norm': 5.008121967315674, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.004769492894411087, 'loss_2': 0.008575439453125, 'loss_3': -16.404613494873047, 'loss_4': 1.1204118728637695, 'epoch': 24.41}
{'loss': 0.0128, 'grad_norm': 5.409700393676758, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.006055736914277077, 'loss_2': 0.00678253173828125, 'loss_3': -16.33370590209961, 'loss_4': 0.9748741388320923, 'epoch': 24.41}
{'loss': 0.0157, 'grad_norm': 7.986133098602295, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.009067011997103691, 'loss_2': 0.00664520263671875, 'loss_3': -16.464624404907227, 'loss_4': 0.5989693403244019, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 17:00:51,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:51,552 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:45<16:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:00:58,919 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01743296906352043, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.232, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.01334113348275423, 'eval_loss_2': 0.004091836512088776, 'eval_loss_3': -18.13768196105957, 'eval_loss_4': 1.021304726600647, 'epoch': 24.42}
{'loss': 0.0057, 'grad_norm': 4.946009159088135, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.005585567560046911, 'loss_2': 0.00010097026824951172, 'loss_3': -16.515735626220703, 'loss_4': 1.2374154329299927, 'epoch': 24.42}
{'loss': 0.0051, 'grad_norm': 4.807456970214844, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.0046312264166772366, 'loss_2': 0.0004911422729492188, 'loss_3': -16.58487319946289, 'loss_4': 0.8666636943817139, 'epoch': 24.43}
{'loss': 0.0038, 'grad_norm': 4.464375972747803, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.00362731353379786, 'loss_2': 0.00019800662994384766, 'loss_3': -16.34330940246582, 'loss_4': 1.122269630432129, 'epoch': 24.44}
{'loss': 0.008, 'grad_norm': 4.537144184112549, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.004102007020264864, 'loss_2': 0.00386810302734375, 'loss_3': -16.31808090209961, 'loss_4': 1.3965349197387695, 'epoch': 24.44}
{'loss': 0.0065, 'grad_norm': 4.831451892852783, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.005466313101351261, 'loss_2': 0.001026153564453125, 'loss_3': -16.26358985900879, 'loss_4': 0.8658174872398376, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 17:00:58,919 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:00:58,919 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:43:52<16:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:06,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018666572868824005, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.015, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012702652253210545, 'eval_loss_2': 0.005963921546936035, 'eval_loss_3': -18.133769989013672, 'eval_loss_4': 0.9652377367019653, 'epoch': 24.45}
{'loss': 0.009, 'grad_norm': 4.899448871612549, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.002842162037268281, 'loss_2': 0.00612640380859375, 'loss_3': -16.600187301635742, 'loss_4': 1.0214664936065674, 'epoch': 24.45}
{'loss': 0.0089, 'grad_norm': 4.9945502281188965, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.003018229268491268, 'loss_2': 0.00592803955078125, 'loss_3': -16.456979751586914, 'loss_4': 0.667055606842041, 'epoch': 24.46}
{'loss': 0.0124, 'grad_norm': 4.6280670166015625, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.003386284224689007, 'loss_2': 0.0090179443359375, 'loss_3': -16.4818115234375, 'loss_4': 0.7191880345344543, 'epoch': 24.47}
{'loss': 0.0075, 'grad_norm': 5.731819152832031, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.006622325628995895, 'loss_2': 0.0008563995361328125, 'loss_3': -16.304933547973633, 'loss_4': 0.9327667951583862, 'epoch': 24.47}
{'loss': 0.0064, 'grad_norm': 4.500061511993408, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.0052603622898459435, 'loss_2': 0.001178741455078125, 'loss_3': -16.647674560546875, 'loss_4': 0.6634027361869812, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 17:01:06,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:06,276 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:44:00<16:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:13,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0187608040869236, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.049, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013360681012272835, 'eval_loss_2': 0.005400121212005615, 'eval_loss_3': -18.127655029296875, 'eval_loss_4': 0.9660778641700745, 'epoch': 24.48}
{'loss': 0.0211, 'grad_norm': 10.795829772949219, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.016774006187915802, 'loss_2': 0.0043487548828125, 'loss_3': -16.479476928710938, 'loss_4': 0.8172115683555603, 'epoch': 24.48}
{'loss': 0.0045, 'grad_norm': 4.974539279937744, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.00337459659203887, 'loss_2': 0.0010929107666015625, 'loss_3': -16.534698486328125, 'loss_4': 0.7395244240760803, 'epoch': 24.49}
{'loss': 0.0031, 'grad_norm': 5.955479145050049, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.0024658527690917253, 'loss_2': 0.0006818771362304688, 'loss_3': -16.376571655273438, 'loss_4': 1.3221664428710938, 'epoch': 24.49}
{'loss': 0.0102, 'grad_norm': 5.04341459274292, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.009906898252665997, 'loss_2': 0.00034046173095703125, 'loss_3': -16.519527435302734, 'loss_4': 1.0740880966186523, 'epoch': 24.5}
{'loss': 0.004, 'grad_norm': 4.748533248901367, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.0022837831638753414, 'loss_2': 0.0017566680908203125, 'loss_3': -16.295455932617188, 'loss_4': 1.416146993637085, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 17:01:13,630 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:13,630 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:44:07<16:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:20,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01727270521223545, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.886, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013481141068041325, 'eval_loss_2': 0.0037915632128715515, 'eval_loss_3': -18.12042236328125, 'eval_loss_4': 0.9791022539138794, 'epoch': 24.51}
{'loss': 0.0038, 'grad_norm': 6.7290120124816895, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.002558051375672221, 'loss_2': 0.0012102127075195312, 'loss_3': -16.49819564819336, 'loss_4': 1.1623609066009521, 'epoch': 24.51}
{'loss': 0.0129, 'grad_norm': 5.933760166168213, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.006269591394811869, 'loss_2': 0.00664520263671875, 'loss_3': -16.445152282714844, 'loss_4': 1.231789231300354, 'epoch': 24.52}
{'loss': 0.0153, 'grad_norm': 6.359444618225098, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.011300730518996716, 'loss_2': 0.004047393798828125, 'loss_3': -16.27481460571289, 'loss_4': 1.365800142288208, 'epoch': 24.52}
{'loss': 0.047, 'grad_norm': 24.565004348754883, 'learning_rate': 5.5e-06, 'loss_1': 0.04311203584074974, 'loss_2': 0.0038623809814453125, 'loss_3': -16.52646827697754, 'loss_4': 0.4357735514640808, 'epoch': 24.53}
{'loss': 0.0086, 'grad_norm': 6.74971342086792, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.007037688512355089, 'loss_2': 0.001575469970703125, 'loss_3': -16.420883178710938, 'loss_4': 1.0799319744110107, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 17:01:20,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:20,985 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:44:14<16:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:28,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016603674739599228, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013367529958486557, 'eval_loss_2': 0.003236144781112671, 'eval_loss_3': -18.11956214904785, 'eval_loss_4': 0.9587833285331726, 'epoch': 24.53}
{'loss': 0.0106, 'grad_norm': 6.162267208099365, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.010237397626042366, 'loss_2': 0.0003948211669921875, 'loss_3': -16.49636459350586, 'loss_4': 1.11148202419281, 'epoch': 24.54}
{'loss': 0.0084, 'grad_norm': 4.6832990646362305, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.004375477787107229, 'loss_2': 0.0040435791015625, 'loss_3': -16.49479866027832, 'loss_4': 1.1137752532958984, 'epoch': 24.55}
{'loss': 0.018, 'grad_norm': 10.24163818359375, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.015429088845849037, 'loss_2': 0.0025272369384765625, 'loss_3': -16.357751846313477, 'loss_4': 0.9896541237831116, 'epoch': 24.55}
{'loss': 0.0075, 'grad_norm': 5.006691932678223, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.004402617923915386, 'loss_2': 0.0031280517578125, 'loss_3': -16.30624008178711, 'loss_4': 0.8090087175369263, 'epoch': 24.56}
{'loss': 0.0058, 'grad_norm': 5.258824348449707, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.005385597702115774, 'loss_2': 0.0004019737243652344, 'loss_3': -16.468027114868164, 'loss_4': 1.3821465969085693, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 17:01:28,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:28,337 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:22<16:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:35,707 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017029879614710808, 'eval_runtime': 3.8195, 'eval_samples_per_second': 268.096, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.013644916005432606, 'eval_loss_2': 0.0033849626779556274, 'eval_loss_3': -18.110965728759766, 'eval_loss_4': 0.8756093382835388, 'epoch': 24.56}
{'loss': 0.0123, 'grad_norm': 6.430593490600586, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.00730210542678833, 'loss_2': 0.004974365234375, 'loss_3': -16.317785263061523, 'loss_4': 0.6643402576446533, 'epoch': 24.57}
{'loss': 0.0108, 'grad_norm': 5.675913333892822, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.009723525494337082, 'loss_2': 0.0010890960693359375, 'loss_3': -16.28083038330078, 'loss_4': 0.8545770645141602, 'epoch': 24.58}
{'loss': 0.0033, 'grad_norm': 4.771841049194336, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.00307648116722703, 'loss_2': 0.00021529197692871094, 'loss_3': -16.377212524414062, 'loss_4': 0.7705439329147339, 'epoch': 24.58}
{'loss': 0.009, 'grad_norm': 5.027200222015381, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.003474984085187316, 'loss_2': 0.00554656982421875, 'loss_3': -16.32516098022461, 'loss_4': 0.9856739044189453, 'epoch': 24.59}
{'loss': 0.0048, 'grad_norm': 6.092829704284668, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.004400931298732758, 'loss_2': 0.0004248619079589844, 'loss_3': -16.39598846435547, 'loss_4': 0.6475305557250977, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 17:01:35,708 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:35,708 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:29<16:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:43,067 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017768865451216698, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.145, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013881077989935875, 'eval_loss_2': 0.0038877874612808228, 'eval_loss_3': -18.11155128479004, 'eval_loss_4': 0.7641605734825134, 'epoch': 24.59}
{'loss': 0.0084, 'grad_norm': 4.971828937530518, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.00544701935723424, 'loss_2': 0.002964019775390625, 'loss_3': -16.366558074951172, 'loss_4': 0.7673133015632629, 'epoch': 24.6}
{'loss': 0.0076, 'grad_norm': 5.385143280029297, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.005997052416205406, 'loss_2': 0.0015659332275390625, 'loss_3': -16.40018081665039, 'loss_4': 1.157100796699524, 'epoch': 24.6}
{'loss': 0.0186, 'grad_norm': 8.611990928649902, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.013165163807570934, 'loss_2': 0.00542449951171875, 'loss_3': -16.222442626953125, 'loss_4': 0.579591691493988, 'epoch': 24.61}
{'loss': 0.0107, 'grad_norm': 5.785956859588623, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.007266185246407986, 'loss_2': 0.00347900390625, 'loss_3': -16.296092987060547, 'loss_4': 0.6375619769096375, 'epoch': 24.62}
{'loss': 0.0098, 'grad_norm': 5.70436954498291, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.0062053389847278595, 'loss_2': 0.0035552978515625, 'loss_3': -16.256534576416016, 'loss_4': 0.8260502219200134, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 17:01:43,067 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:43,068 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:37<15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:50,430 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018167629837989807, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.852, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014372214674949646, 'eval_loss_2': 0.003795415163040161, 'eval_loss_3': -18.114788055419922, 'eval_loss_4': 0.6814852952957153, 'epoch': 24.62}
{'loss': 0.0149, 'grad_norm': 5.129554271697998, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.0048885652795434, 'loss_2': 0.0100250244140625, 'loss_3': -16.41045379638672, 'loss_4': 0.5561881065368652, 'epoch': 24.63}
{'loss': 0.0029, 'grad_norm': 4.32585334777832, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.00285374210216105, 'loss_2': 6.312131881713867e-05, 'loss_3': -16.5013484954834, 'loss_4': 0.46236827969551086, 'epoch': 24.63}
{'loss': 0.0057, 'grad_norm': 5.013559341430664, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.0037139947526156902, 'loss_2': 0.002010345458984375, 'loss_3': -16.2684268951416, 'loss_4': 0.557969331741333, 'epoch': 24.64}
{'loss': 0.0644, 'grad_norm': 16.956279754638672, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.060982171446084976, 'loss_2': 0.003448486328125, 'loss_3': -16.594663619995117, 'loss_4': 0.8023266792297363, 'epoch': 24.65}
{'loss': 0.0095, 'grad_norm': 4.7729949951171875, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.0043812706135213375, 'loss_2': 0.00507354736328125, 'loss_3': -16.262401580810547, 'loss_4': 0.40590038895606995, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 17:01:50,430 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:50,430 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:44<15:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:01:57,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019395722076296806, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.156, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01570245437324047, 'eval_loss_2': 0.0036932677030563354, 'eval_loss_3': -18.088241577148438, 'eval_loss_4': 0.6006179451942444, 'epoch': 24.65}
{'loss': 0.0093, 'grad_norm': 5.29541540145874, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.0053353700786828995, 'loss_2': 0.00394439697265625, 'loss_3': -16.45335578918457, 'loss_4': 0.806022047996521, 'epoch': 24.66}
{'loss': 0.0097, 'grad_norm': 4.404150009155273, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.0034005516208708286, 'loss_2': 0.00630950927734375, 'loss_3': -16.330162048339844, 'loss_4': 0.513820469379425, 'epoch': 24.66}
{'loss': 0.0048, 'grad_norm': 4.691434860229492, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.003831203794106841, 'loss_2': 0.001018524169921875, 'loss_3': -16.39548110961914, 'loss_4': 0.8116652965545654, 'epoch': 24.67}
{'loss': 0.0141, 'grad_norm': 8.551130294799805, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.012356527149677277, 'loss_2': 0.001708984375, 'loss_3': -16.451988220214844, 'loss_4': 0.4209931194782257, 'epoch': 24.67}
{'loss': 0.0103, 'grad_norm': 5.374084949493408, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.0025883133057504892, 'loss_2': 0.0076751708984375, 'loss_3': -16.37173843383789, 'loss_4': 0.864300012588501, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 17:01:57,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:01:57,783 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:44:51<15:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:05,138 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01855592057108879, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.052, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.015296298079192638, 'eval_loss_2': 0.003259621560573578, 'eval_loss_3': -18.091415405273438, 'eval_loss_4': 0.5732865929603577, 'epoch': 24.68}
{'loss': 0.0106, 'grad_norm': 5.305529594421387, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.006045390851795673, 'loss_2': 0.0045166015625, 'loss_3': -16.353004455566406, 'loss_4': 0.9336320161819458, 'epoch': 24.69}
{'loss': 0.0255, 'grad_norm': 15.836372375488281, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.024160509929060936, 'loss_2': 0.001354217529296875, 'loss_3': -16.30965232849121, 'loss_4': 0.3562239408493042, 'epoch': 24.69}
{'loss': 0.0104, 'grad_norm': 6.357226371765137, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.008796559646725655, 'loss_2': 0.001556396484375, 'loss_3': -16.180322647094727, 'loss_4': 0.42641574144363403, 'epoch': 24.7}
{'loss': 0.0103, 'grad_norm': 5.777244567871094, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.004601755179464817, 'loss_2': 0.00571441650390625, 'loss_3': -16.350494384765625, 'loss_4': 0.47180843353271484, 'epoch': 24.7}
{'loss': 0.0079, 'grad_norm': 4.766440391540527, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.0044016106985509396, 'loss_2': 0.003459930419921875, 'loss_3': -16.395681381225586, 'loss_4': 0.5002539157867432, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 17:02:05,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:05,138 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:44:59<15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:12,501 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018764739856123924, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.015574044547975063, 'eval_loss_2': 0.0031906962394714355, 'eval_loss_3': -18.096899032592773, 'eval_loss_4': 0.5716190338134766, 'epoch': 24.71}
{'loss': 0.0078, 'grad_norm': 4.543901443481445, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.0037334796506911516, 'loss_2': 0.0040435791015625, 'loss_3': -16.35142707824707, 'loss_4': 0.5198907852172852, 'epoch': 24.72}
{'loss': 0.0058, 'grad_norm': 4.858725547790527, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.004363677930086851, 'loss_2': 0.0014438629150390625, 'loss_3': -16.53278160095215, 'loss_4': 0.5050594210624695, 'epoch': 24.72}
{'loss': 0.0115, 'grad_norm': 5.30010986328125, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.006339683197438717, 'loss_2': 0.0051422119140625, 'loss_3': -16.18914794921875, 'loss_4': 0.4561016261577606, 'epoch': 24.73}
{'loss': 0.0051, 'grad_norm': 5.813896656036377, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.004406365100294352, 'loss_2': 0.0007262229919433594, 'loss_3': -16.347553253173828, 'loss_4': 0.6837002038955688, 'epoch': 24.73}
{'loss': 0.0046, 'grad_norm': 4.635391712188721, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.0038429887499660254, 'loss_2': 0.0007996559143066406, 'loss_3': -16.30964469909668, 'loss_4': 0.5682339072227478, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 17:02:12,501 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:12,501 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:45:06<15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:19,854 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020618725568056107, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.132, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01698642037808895, 'eval_loss_2': 0.0036323070526123047, 'eval_loss_3': -18.08802032470703, 'eval_loss_4': 0.5965946316719055, 'epoch': 24.74}
{'loss': 0.0092, 'grad_norm': 4.770064353942871, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.00447551254183054, 'loss_2': 0.0047149658203125, 'loss_3': -16.278671264648438, 'loss_4': 0.4513159990310669, 'epoch': 24.74}
{'loss': 0.0048, 'grad_norm': 4.693464279174805, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.004295434337109327, 'loss_2': 0.0004811286926269531, 'loss_3': -16.343793869018555, 'loss_4': 0.593737781047821, 'epoch': 24.75}
{'loss': 0.0058, 'grad_norm': 5.130472183227539, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.0047019002959132195, 'loss_2': 0.001068115234375, 'loss_3': -16.44308090209961, 'loss_4': 0.9626593589782715, 'epoch': 24.76}
{'loss': 0.0091, 'grad_norm': 5.110354900360107, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.0036096873227506876, 'loss_2': 0.0054473876953125, 'loss_3': -16.430450439453125, 'loss_4': 0.7415561676025391, 'epoch': 24.76}
{'loss': 0.0113, 'grad_norm': 4.597653865814209, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.006058956496417522, 'loss_2': 0.005207061767578125, 'loss_3': -16.37849998474121, 'loss_4': 0.5678827166557312, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 17:02:19,854 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:19,854 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:45:13<15:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:27,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020921267569065094, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.183, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.017234930768609047, 'eval_loss_2': 0.0036863386631011963, 'eval_loss_3': -18.080142974853516, 'eval_loss_4': 0.6959198713302612, 'epoch': 24.77}
{'loss': 0.006, 'grad_norm': 5.111522197723389, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.004731663968414068, 'loss_2': 0.001312255859375, 'loss_3': -16.389305114746094, 'loss_4': 0.17780330777168274, 'epoch': 24.77}
{'loss': 0.0044, 'grad_norm': 4.8688883781433105, 'learning_rate': 5.25e-06, 'loss_1': 0.0032230939250439405, 'loss_2': 0.0011920928955078125, 'loss_3': -16.428524017333984, 'loss_4': 0.9736841320991516, 'epoch': 24.78}
{'loss': 0.004, 'grad_norm': 4.607363700866699, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.003362120594829321, 'loss_2': 0.0006771087646484375, 'loss_3': -16.574642181396484, 'loss_4': 0.8685407638549805, 'epoch': 24.78}
{'loss': 0.0055, 'grad_norm': 4.561301231384277, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.004620765335857868, 'loss_2': 0.0009102821350097656, 'loss_3': -16.381145477294922, 'loss_4': 0.2867636978626251, 'epoch': 24.79}
{'loss': 0.0097, 'grad_norm': 4.953416347503662, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.0018779597012326121, 'loss_2': 0.007778167724609375, 'loss_3': -16.418977737426758, 'loss_4': 0.8399685621261597, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 17:02:27,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:27,206 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:21<15:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:34,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020989488810300827, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.102, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01753915473818779, 'eval_loss_2': 0.003450334072113037, 'eval_loss_3': -18.08139419555664, 'eval_loss_4': 0.771458625793457, 'epoch': 24.8}
{'loss': 0.0103, 'grad_norm': 6.208556652069092, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.009837747551500797, 'loss_2': 0.0004448890686035156, 'loss_3': -16.55743408203125, 'loss_4': 0.5875054597854614, 'epoch': 24.8}
{'loss': 0.0031, 'grad_norm': 5.021175384521484, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.002820044755935669, 'loss_2': 0.0002760887145996094, 'loss_3': -16.47403335571289, 'loss_4': 1.0432476997375488, 'epoch': 24.81}
{'loss': 0.0066, 'grad_norm': 12.13411808013916, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.003928277641534805, 'loss_2': 0.002651214599609375, 'loss_3': -16.368480682373047, 'loss_4': 0.9848756790161133, 'epoch': 24.81}
{'loss': 0.0129, 'grad_norm': 4.448638916015625, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.004456172697246075, 'loss_2': 0.008453369140625, 'loss_3': -16.28217887878418, 'loss_4': 0.8591787815093994, 'epoch': 24.82}
{'loss': 0.0045, 'grad_norm': 4.741574287414551, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.004478808026760817, 'loss_2': 5.3882598876953125e-05, 'loss_3': -16.429035186767578, 'loss_4': 1.042769432067871, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 17:02:34,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:34,565 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:28<15:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:41,927 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022571276873350143, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.018814219161868095, 'eval_loss_2': 0.0037570521235466003, 'eval_loss_3': -18.068622589111328, 'eval_loss_4': 0.8104451298713684, 'epoch': 24.83}
{'loss': 0.009, 'grad_norm': 4.906148910522461, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.004194127861410379, 'loss_2': 0.00478363037109375, 'loss_3': -16.283100128173828, 'loss_4': 0.7600216865539551, 'epoch': 24.83}
{'loss': 0.0096, 'grad_norm': 5.011110305786133, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.004647325724363327, 'loss_2': 0.004913330078125, 'loss_3': -16.563234329223633, 'loss_4': 0.5870353579521179, 'epoch': 24.84}
{'loss': 0.0069, 'grad_norm': 5.0198445320129395, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.006497904658317566, 'loss_2': 0.00037169456481933594, 'loss_3': -16.41255760192871, 'loss_4': 0.8174203038215637, 'epoch': 24.84}
{'loss': 0.0094, 'grad_norm': 7.019552230834961, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.004660659469664097, 'loss_2': 0.00469970703125, 'loss_3': -16.608980178833008, 'loss_4': 0.7577948570251465, 'epoch': 24.85}
{'loss': 0.0148, 'grad_norm': 6.613038539886475, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.01131883729249239, 'loss_2': 0.0034351348876953125, 'loss_3': -16.463096618652344, 'loss_4': 0.647986888885498, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 17:02:41,927 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:41,927 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:35<15:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:49,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021532412618398666, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.864, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.018118958920240402, 'eval_loss_2': 0.003413453698158264, 'eval_loss_3': -18.076614379882812, 'eval_loss_4': 0.8721160888671875, 'epoch': 24.85}
{'loss': 0.0072, 'grad_norm': 4.920890808105469, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.004778693430125713, 'loss_2': 0.002384185791015625, 'loss_3': -16.33056640625, 'loss_4': 1.2939891815185547, 'epoch': 24.86}
{'loss': 0.0089, 'grad_norm': 4.640368938446045, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.003557033371180296, 'loss_2': 0.00534820556640625, 'loss_3': -16.349960327148438, 'loss_4': 1.155726671218872, 'epoch': 24.87}
{'loss': 0.009, 'grad_norm': 4.767117977142334, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.004453438334167004, 'loss_2': 0.00450897216796875, 'loss_3': -16.387971878051758, 'loss_4': 0.932114839553833, 'epoch': 24.87}
{'loss': 0.0067, 'grad_norm': 5.019049644470215, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.0032506282441318035, 'loss_2': 0.00342559814453125, 'loss_3': -16.44341278076172, 'loss_4': 0.801429033279419, 'epoch': 24.88}
{'loss': 0.0144, 'grad_norm': 4.712146759033203, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.004513258580118418, 'loss_2': 0.0099334716796875, 'loss_3': -16.26900863647461, 'loss_4': 0.8828603625297546, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 17:02:49,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:49,284 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:43<15:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:02:56,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02097940258681774, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.875, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.017574919387698174, 'eval_loss_2': 0.003404483199119568, 'eval_loss_3': -18.066377639770508, 'eval_loss_4': 0.930382490158081, 'epoch': 24.88}
{'loss': 0.0097, 'grad_norm': 5.496343612670898, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.008275993168354034, 'loss_2': 0.0013980865478515625, 'loss_3': -16.396276473999023, 'loss_4': 1.258615493774414, 'epoch': 24.89}
{'loss': 0.0096, 'grad_norm': 5.915312767028809, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.008449883200228214, 'loss_2': 0.00116729736328125, 'loss_3': -16.21941375732422, 'loss_4': 1.3525495529174805, 'epoch': 24.9}
{'loss': 0.0191, 'grad_norm': 7.299800872802734, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.013774232007563114, 'loss_2': 0.005340576171875, 'loss_3': -16.192609786987305, 'loss_4': 1.1546025276184082, 'epoch': 24.9}
{'loss': 0.005, 'grad_norm': 4.6322245597839355, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.0024814200587570667, 'loss_2': 0.00254058837890625, 'loss_3': -16.37347412109375, 'loss_4': 0.8539105653762817, 'epoch': 24.91}
{'loss': 0.0089, 'grad_norm': 5.374039173126221, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.007917340844869614, 'loss_2': 0.0010089874267578125, 'loss_3': -16.4161376953125, 'loss_4': 0.7490214109420776, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 17:02:56,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:02:56,647 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:45:50<15:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:04,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021714385598897934, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.168, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.018135707825422287, 'eval_loss_2': 0.003578677773475647, 'eval_loss_3': -18.063453674316406, 'eval_loss_4': 0.986396849155426, 'epoch': 24.91}
{'loss': 0.0105, 'grad_norm': 8.184525489807129, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.010342237539589405, 'loss_2': 0.00015544891357421875, 'loss_3': -16.26943588256836, 'loss_4': 0.7907321453094482, 'epoch': 24.92}
{'loss': 0.0129, 'grad_norm': 5.384510517120361, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.007851747795939445, 'loss_2': 0.00502777099609375, 'loss_3': -16.43179702758789, 'loss_4': 1.0955216884613037, 'epoch': 24.92}
{'loss': 0.0078, 'grad_norm': 4.9187331199646, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.006176296155899763, 'loss_2': 0.0015773773193359375, 'loss_3': -16.284000396728516, 'loss_4': 0.9430834650993347, 'epoch': 24.93}
{'loss': 0.0078, 'grad_norm': 5.1967549324035645, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.0044082580134272575, 'loss_2': 0.003429412841796875, 'loss_3': -16.479904174804688, 'loss_4': 1.0623128414154053, 'epoch': 24.94}
{'loss': 0.0107, 'grad_norm': 4.6255693435668945, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.006453679408878088, 'loss_2': 0.004207611083984375, 'loss_3': -16.36639404296875, 'loss_4': 0.5695413947105408, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 17:03:04,004 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:04,004 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:45:57<14:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:11,358 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021949829533696175, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.137, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.018179360777139664, 'eval_loss_2': 0.00377047061920166, 'eval_loss_3': -18.076751708984375, 'eval_loss_4': 1.0290391445159912, 'epoch': 24.94}
{'loss': 0.0065, 'grad_norm': 4.454216480255127, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.003189703682437539, 'loss_2': 0.0033283233642578125, 'loss_3': -16.397972106933594, 'loss_4': 1.0984647274017334, 'epoch': 24.95}
{'loss': 0.016, 'grad_norm': 5.267756462097168, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.010276630520820618, 'loss_2': 0.005687713623046875, 'loss_3': -16.429588317871094, 'loss_4': 1.5112723112106323, 'epoch': 24.95}
{'loss': 0.0088, 'grad_norm': 4.506049156188965, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.003178834915161133, 'loss_2': 0.0056304931640625, 'loss_3': -16.23442840576172, 'loss_4': 0.9748520851135254, 'epoch': 24.96}
{'loss': 0.0052, 'grad_norm': 4.925174236297607, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.0038830891717225313, 'loss_2': 0.0013637542724609375, 'loss_3': -16.378299713134766, 'loss_4': 0.9364000558853149, 'epoch': 24.97}
{'loss': 0.0116, 'grad_norm': 6.589227199554443, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.006644656416028738, 'loss_2': 0.0049896240234375, 'loss_3': -16.25547218322754, 'loss_4': 0.7684134244918823, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 17:03:11,358 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:11,358 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:46:04<13:24,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 17:03:18,364 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021358732134103775, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01761779561638832, 'eval_loss_2': 0.003740936517715454, 'eval_loss_3': -18.08403968811035, 'eval_loss_4': 1.0190609693527222, 'epoch': 24.97}
{'loss': 0.0065, 'grad_norm': 4.78903341293335, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.0054824925027787685, 'loss_2': 0.0009822845458984375, 'loss_3': -16.426219940185547, 'loss_4': 0.6594060659408569, 'epoch': 24.98}
{'loss': 0.0076, 'grad_norm': 4.781116962432861, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.003948859870433807, 'loss_2': 0.0036029815673828125, 'loss_3': -16.422983169555664, 'loss_4': 1.1634259223937988, 'epoch': 24.98}
{'loss': 0.01, 'grad_norm': 5.769704341888428, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.005362445954233408, 'loss_2': 0.004608154296875, 'loss_3': -16.350133895874023, 'loss_4': 1.1670928001403809, 'epoch': 24.99}
{'loss': 0.0075, 'grad_norm': 4.336688995361328, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.003307400969788432, 'loss_2': 0.0041961669921875, 'loss_3': -16.43347930908203, 'loss_4': 0.8380563259124756, 'epoch': 24.99}
{'loss': 0.0065, 'grad_norm': 5.934995651245117, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.0008610359509475529, 'loss_2': 0.005611419677734375, 'loss_3': -16.444021224975586, 'loss_4': 0.656606137752533, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 17:03:18,364 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:18,364 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:46:12<14:35,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 17:03:25,760 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02092265710234642, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.928, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.017193060368299484, 'eval_loss_2': 0.003729596734046936, 'eval_loss_3': -18.07650375366211, 'eval_loss_4': 1.0294559001922607, 'epoch': 25.0}
{'loss': 0.0107, 'grad_norm': 5.15458869934082, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.003875996684655547, 'loss_2': 0.00684356689453125, 'loss_3': -16.26628303527832, 'loss_4': 1.0465331077575684, 'epoch': 25.01}
{'loss': 0.0036, 'grad_norm': 4.896590709686279, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.003555398201569915, 'loss_2': 4.5180320739746094e-05, 'loss_3': -16.300779342651367, 'loss_4': 1.1287307739257812, 'epoch': 25.01}
{'loss': 0.012, 'grad_norm': 5.529718399047852, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.011663590557873249, 'loss_2': 0.0003485679626464844, 'loss_3': -16.354429244995117, 'loss_4': 0.9668084383010864, 'epoch': 25.02}
{'loss': 0.0083, 'grad_norm': 5.381451606750488, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.006437723990529776, 'loss_2': 0.0018405914306640625, 'loss_3': -16.416706085205078, 'loss_4': 1.0922985076904297, 'epoch': 25.02}
{'loss': 0.1229, 'grad_norm': 11.72109603881836, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.12287814170122147, 'loss_2': 3.421306610107422e-05, 'loss_3': -16.22154426574707, 'loss_4': 1.4241365194320679, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 17:03:25,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:25,761 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:19<14:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:33,127 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020409196615219116, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.459, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.016891933977603912, 'eval_loss_2': 0.003517262637615204, 'eval_loss_3': -18.07565689086914, 'eval_loss_4': 0.980254590511322, 'epoch': 25.03}
{'loss': 0.0157, 'grad_norm': 6.52736759185791, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.013317628763616085, 'loss_2': 0.0023326873779296875, 'loss_3': -16.513517379760742, 'loss_4': 1.0638107061386108, 'epoch': 25.03}
{'loss': 0.006, 'grad_norm': 4.8132643699646, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.005465036723762751, 'loss_2': 0.0005750656127929688, 'loss_3': -16.48021125793457, 'loss_4': 0.668331503868103, 'epoch': 25.04}
{'loss': 0.0071, 'grad_norm': 5.015892505645752, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.004296278581023216, 'loss_2': 0.002796173095703125, 'loss_3': -16.289833068847656, 'loss_4': 0.6799905300140381, 'epoch': 25.05}
{'loss': 0.0089, 'grad_norm': 5.060029983520508, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.004187045618891716, 'loss_2': 0.00475311279296875, 'loss_3': -16.147850036621094, 'loss_4': 0.8831214904785156, 'epoch': 25.05}
{'loss': 0.0122, 'grad_norm': 4.704891681671143, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.004818858113139868, 'loss_2': 0.00738525390625, 'loss_3': -16.2186279296875, 'loss_4': 0.8429735898971558, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 17:03:33,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:33,127 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:27<14:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:40,483 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019802918657660484, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01608886383473873, 'eval_loss_2': 0.003714054822921753, 'eval_loss_3': -18.08066749572754, 'eval_loss_4': 0.8739840984344482, 'epoch': 25.06}
{'loss': 0.01, 'grad_norm': 13.558127403259277, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.007155820727348328, 'loss_2': 0.0028209686279296875, 'loss_3': -16.321069717407227, 'loss_4': 0.9214417934417725, 'epoch': 25.06}
{'loss': 0.0046, 'grad_norm': 4.421067237854004, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.0038458178751170635, 'loss_2': 0.0007338523864746094, 'loss_3': -16.465198516845703, 'loss_4': 1.1025433540344238, 'epoch': 25.07}
{'loss': 0.0054, 'grad_norm': 6.177285671234131, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.004059495870023966, 'loss_2': 0.0013561248779296875, 'loss_3': -16.229341506958008, 'loss_4': 1.1179029941558838, 'epoch': 25.08}
{'loss': 0.0053, 'grad_norm': 4.961458683013916, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.0023415882606059313, 'loss_2': 0.0029754638671875, 'loss_3': -16.505462646484375, 'loss_4': 0.5833919644355774, 'epoch': 25.08}
{'loss': 0.0148, 'grad_norm': 7.1697306632995605, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.011381376534700394, 'loss_2': 0.0034637451171875, 'loss_3': -16.418228149414062, 'loss_4': 0.9848421812057495, 'epoch': 25.09}
[INFO|trainer.py:4228] 2025-01-21 17:03:40,483 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:40,483 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:34<14:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:47,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0197493564337492, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.959, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015719186514616013, 'eval_loss_2': 0.004030168056488037, 'eval_loss_3': -18.087182998657227, 'eval_loss_4': 0.7986374497413635, 'epoch': 25.09}
{'loss': 0.0057, 'grad_norm': 5.287250995635986, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.003104988718405366, 'loss_2': 0.00257110595703125, 'loss_3': -16.50309944152832, 'loss_4': 0.9358847141265869, 'epoch': 25.09}
{'loss': 0.0054, 'grad_norm': 4.503940105438232, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.0029748971574008465, 'loss_2': 0.00244140625, 'loss_3': -16.287729263305664, 'loss_4': 0.9560093879699707, 'epoch': 25.1}
{'loss': 0.0068, 'grad_norm': 4.838368892669678, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.003580481978133321, 'loss_2': 0.003223419189453125, 'loss_3': -16.465328216552734, 'loss_4': 0.5825575590133667, 'epoch': 25.1}
{'loss': 0.0102, 'grad_norm': 5.285229682922363, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.004996421746909618, 'loss_2': 0.0052032470703125, 'loss_3': -16.298118591308594, 'loss_4': 0.6088504791259766, 'epoch': 25.11}
{'loss': 0.0075, 'grad_norm': 4.810382843017578, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.005211831070482731, 'loss_2': 0.0023193359375, 'loss_3': -16.529041290283203, 'loss_4': 1.1253957748413086, 'epoch': 25.12}
[INFO|trainer.py:4228] 2025-01-21 17:03:47,842 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:47,842 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:41<14:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:03:55,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01922641508281231, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.064, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.015460385009646416, 'eval_loss_2': 0.0037660300731658936, 'eval_loss_3': -18.08907699584961, 'eval_loss_4': 0.7820329666137695, 'epoch': 25.12}
{'loss': 0.0053, 'grad_norm': 4.702968120574951, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.004861088003963232, 'loss_2': 0.0004200935363769531, 'loss_3': -16.26605796813965, 'loss_4': 0.8744758367538452, 'epoch': 25.12}
{'loss': 0.0052, 'grad_norm': 4.683042526245117, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.0028972008731216192, 'loss_2': 0.0023250579833984375, 'loss_3': -16.305072784423828, 'loss_4': 0.7563835382461548, 'epoch': 25.13}
{'loss': 0.0124, 'grad_norm': 5.628981590270996, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.009089269675314426, 'loss_2': 0.003322601318359375, 'loss_3': -16.475099563598633, 'loss_4': 1.153646469116211, 'epoch': 25.13}
{'loss': 0.0095, 'grad_norm': 5.67721700668335, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.008797204121947289, 'loss_2': 0.0006957054138183594, 'loss_3': -16.16687774658203, 'loss_4': 1.0749592781066895, 'epoch': 25.14}
{'loss': 0.0065, 'grad_norm': 4.944922924041748, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.005657408386468887, 'loss_2': 0.0008783340454101562, 'loss_3': -16.50308609008789, 'loss_4': 0.49694132804870605, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 17:03:55,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:03:55,203 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:46:49<14:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:02,560 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018917299807071686, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.009, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01530677080154419, 'eval_loss_2': 0.0036105290055274963, 'eval_loss_3': -18.093788146972656, 'eval_loss_4': 0.780450701713562, 'epoch': 25.15}
{'loss': 0.0033, 'grad_norm': 5.031968593597412, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.002256199484691024, 'loss_2': 0.0010890960693359375, 'loss_3': -16.494726181030273, 'loss_4': 0.8331930637359619, 'epoch': 25.15}
{'loss': 0.0073, 'grad_norm': 4.777525424957275, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.0025989331770688295, 'loss_2': 0.004703521728515625, 'loss_3': -16.385433197021484, 'loss_4': 1.1144921779632568, 'epoch': 25.16}
{'loss': 0.0219, 'grad_norm': 5.502954959869385, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.009595927782356739, 'loss_2': 0.01226043701171875, 'loss_3': -16.309234619140625, 'loss_4': 0.9554076790809631, 'epoch': 25.16}
{'loss': 0.007, 'grad_norm': 4.7395195960998535, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.0028025468345731497, 'loss_2': 0.0041656494140625, 'loss_3': -16.309955596923828, 'loss_4': 0.6834364533424377, 'epoch': 25.17}
{'loss': 0.0075, 'grad_norm': 4.557713985443115, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.004156919661909342, 'loss_2': 0.00337982177734375, 'loss_3': -16.33422088623047, 'loss_4': 1.0870084762573242, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 17:04:02,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:02,560 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:46:56<14:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:09,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018496396020054817, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.588, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.015053557232022285, 'eval_loss_2': 0.0034428387880325317, 'eval_loss_3': -18.089731216430664, 'eval_loss_4': 0.7722277641296387, 'epoch': 25.17}
{'loss': 0.0078, 'grad_norm': 5.254629611968994, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.0038334012497216463, 'loss_2': 0.0039825439453125, 'loss_3': -16.236820220947266, 'loss_4': 0.6978651285171509, 'epoch': 25.18}
{'loss': 0.0197, 'grad_norm': 7.156399726867676, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.011220905929803848, 'loss_2': 0.0084686279296875, 'loss_3': -16.335203170776367, 'loss_4': 0.5994314551353455, 'epoch': 25.19}
{'loss': 0.0073, 'grad_norm': 4.7863311767578125, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.004033899866044521, 'loss_2': 0.0032405853271484375, 'loss_3': -16.267803192138672, 'loss_4': 0.5879806280136108, 'epoch': 25.19}
{'loss': 0.012, 'grad_norm': 5.3273444175720215, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.009114837273955345, 'loss_2': 0.00286865234375, 'loss_3': -16.24973487854004, 'loss_4': 1.1379029750823975, 'epoch': 25.2}
{'loss': 0.0179, 'grad_norm': 5.4985671043396, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.016853036358952522, 'loss_2': 0.0010814666748046875, 'loss_3': -16.271121978759766, 'loss_4': 0.8547405004501343, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 17:04:09,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:09,923 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:47:03<14:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:17,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01837741956114769, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.014594567008316517, 'eval_loss_2': 0.0037828534841537476, 'eval_loss_3': -18.089143753051758, 'eval_loss_4': 0.7808764576911926, 'epoch': 25.2}
{'loss': 0.0083, 'grad_norm': 5.0283355712890625, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.0035721538588404655, 'loss_2': 0.00475311279296875, 'loss_3': -16.385786056518555, 'loss_4': 0.8795820474624634, 'epoch': 25.21}
{'loss': 0.0043, 'grad_norm': 4.532430171966553, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.003333775792270899, 'loss_2': 0.0009465217590332031, 'loss_3': -16.465761184692383, 'loss_4': 0.37514984607696533, 'epoch': 25.22}
{'loss': 0.0164, 'grad_norm': 5.9294915199279785, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.016144514083862305, 'loss_2': 0.00025963783264160156, 'loss_3': -16.30548095703125, 'loss_4': 0.7212395071983337, 'epoch': 25.22}
{'loss': 0.0085, 'grad_norm': 4.894515037536621, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.002990570617839694, 'loss_2': 0.00548553466796875, 'loss_3': -16.3980712890625, 'loss_4': 0.6495262384414673, 'epoch': 25.23}
{'loss': 0.011, 'grad_norm': 5.395455837249756, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.010020324029028416, 'loss_2': 0.000934600830078125, 'loss_3': -16.344928741455078, 'loss_4': 0.4742262661457062, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 17:04:17,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:17,277 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:47:11<14:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:24,646 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01900721713900566, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.94, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.014800496399402618, 'eval_loss_2': 0.004206720739603043, 'eval_loss_3': -18.089481353759766, 'eval_loss_4': 0.7788559198379517, 'epoch': 25.23}
{'loss': 0.0129, 'grad_norm': 4.813338756561279, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.007120158988982439, 'loss_2': 0.0057525634765625, 'loss_3': -16.522624969482422, 'loss_4': 0.9664919972419739, 'epoch': 25.24}
{'loss': 0.0105, 'grad_norm': 4.7200117111206055, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.0037379926070570946, 'loss_2': 0.0067901611328125, 'loss_3': -16.42772102355957, 'loss_4': 0.9320129156112671, 'epoch': 25.24}
{'loss': 0.0164, 'grad_norm': 5.906732559204102, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.011222993023693562, 'loss_2': 0.00521087646484375, 'loss_3': -16.418853759765625, 'loss_4': 0.7462324500083923, 'epoch': 25.25}
{'loss': 0.0678, 'grad_norm': 6.626712799072266, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.05868302285671234, 'loss_2': 0.0090789794921875, 'loss_3': -16.500267028808594, 'loss_4': 1.004469633102417, 'epoch': 25.26}
{'loss': 0.0128, 'grad_norm': 5.640635967254639, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.007784182205796242, 'loss_2': 0.00498199462890625, 'loss_3': -16.481801986694336, 'loss_4': 1.244414210319519, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 17:04:24,646 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:24,646 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:18<14:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:32,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01886899769306183, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.003, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014913782477378845, 'eval_loss_2': 0.003955215215682983, 'eval_loss_3': -18.083066940307617, 'eval_loss_4': 0.802207350730896, 'epoch': 25.26}
{'loss': 0.0208, 'grad_norm': 12.913566589355469, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.013243156485259533, 'loss_2': 0.007568359375, 'loss_3': -16.281707763671875, 'loss_4': 1.0046279430389404, 'epoch': 25.27}
{'loss': 0.0154, 'grad_norm': 5.744697570800781, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.006776958703994751, 'loss_2': 0.00864410400390625, 'loss_3': -16.341354370117188, 'loss_4': 1.302527904510498, 'epoch': 25.27}
{'loss': 0.0094, 'grad_norm': 4.283701419830322, 'learning_rate': 4.75e-06, 'loss_1': 0.0036757364869117737, 'loss_2': 0.00568389892578125, 'loss_3': -16.439943313598633, 'loss_4': 1.269606113433838, 'epoch': 25.28}
{'loss': 0.0051, 'grad_norm': 4.476675033569336, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.004307613708078861, 'loss_2': 0.0007615089416503906, 'loss_3': -16.301841735839844, 'loss_4': 0.7156240344047546, 'epoch': 25.28}
{'loss': 0.0894, 'grad_norm': 10.552882194519043, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.08523677289485931, 'loss_2': 0.004169464111328125, 'loss_3': -16.07941246032715, 'loss_4': 1.3309980630874634, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 17:04:32,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:32,007 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:25<13:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:39,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01858486235141754, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.689, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.015238331630825996, 'eval_loss_2': 0.0033465325832366943, 'eval_loss_3': -18.074806213378906, 'eval_loss_4': 0.7934609651565552, 'epoch': 25.29}
{'loss': 0.0134, 'grad_norm': 5.345773220062256, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.004217326175421476, 'loss_2': 0.0092315673828125, 'loss_3': -16.396495819091797, 'loss_4': 0.775090217590332, 'epoch': 25.3}
{'loss': 0.0071, 'grad_norm': 6.331823825836182, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.00689936988055706, 'loss_2': 0.00019741058349609375, 'loss_3': -16.393814086914062, 'loss_4': 0.9697147607803345, 'epoch': 25.3}
{'loss': 0.0085, 'grad_norm': 5.063907623291016, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.008166136220097542, 'loss_2': 0.00034809112548828125, 'loss_3': -16.315601348876953, 'loss_4': 0.6379338502883911, 'epoch': 25.31}
{'loss': 0.0255, 'grad_norm': 15.106056213378906, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.023671526461839676, 'loss_2': 0.0018157958984375, 'loss_3': -16.449291229248047, 'loss_4': 1.0987528562545776, 'epoch': 25.31}
{'loss': 0.0187, 'grad_norm': 8.961607933044434, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.014529645442962646, 'loss_2': 0.004180908203125, 'loss_3': -16.40644073486328, 'loss_4': 0.46066683530807495, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 17:04:39,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:39,374 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:33<13:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:46,734 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02021687477827072, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.591, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.016103796660900116, 'eval_loss_2': 0.0041130781173706055, 'eval_loss_3': -18.06158447265625, 'eval_loss_4': 0.780448317527771, 'epoch': 25.32}
{'loss': 0.0068, 'grad_norm': 4.828227519989014, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.0042351605370640755, 'loss_2': 0.0025234222412109375, 'loss_3': -16.33785629272461, 'loss_4': 0.7148357629776001, 'epoch': 25.33}
{'loss': 0.0102, 'grad_norm': 5.445064067840576, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.007689964026212692, 'loss_2': 0.00255584716796875, 'loss_3': -16.35279083251953, 'loss_4': 1.1620135307312012, 'epoch': 25.33}
{'loss': 0.0058, 'grad_norm': 4.913186073303223, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.004497738089412451, 'loss_2': 0.0012836456298828125, 'loss_3': -16.17962646484375, 'loss_4': 1.2009117603302002, 'epoch': 25.34}
{'loss': 0.0095, 'grad_norm': 5.351280689239502, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.006597850937396288, 'loss_2': 0.002872467041015625, 'loss_3': -16.409671783447266, 'loss_4': 0.7037633061408997, 'epoch': 25.34}
{'loss': 0.0188, 'grad_norm': 5.384391784667969, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.007315013092011213, 'loss_2': 0.0114898681640625, 'loss_3': -16.355016708374023, 'loss_4': 0.7868205308914185, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 17:04:46,734 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:46,734 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:40<13:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:04:54,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02033640444278717, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.015705376863479614, 'eval_loss_2': 0.004631027579307556, 'eval_loss_3': -18.084468841552734, 'eval_loss_4': 0.7628180384635925, 'epoch': 25.35}
{'loss': 0.0099, 'grad_norm': 5.157325744628906, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.006790192797780037, 'loss_2': 0.0031108856201171875, 'loss_3': -16.23684310913086, 'loss_4': 0.8213326930999756, 'epoch': 25.35}
{'loss': 0.0093, 'grad_norm': 5.49769926071167, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.009198516607284546, 'loss_2': 8.398294448852539e-05, 'loss_3': -16.508296966552734, 'loss_4': 0.998384952545166, 'epoch': 25.36}
{'loss': 0.0138, 'grad_norm': 4.858626842498779, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.00416208291426301, 'loss_2': 0.0096588134765625, 'loss_3': -16.40242576599121, 'loss_4': 1.3128173351287842, 'epoch': 25.37}
{'loss': 0.0209, 'grad_norm': 6.307881832122803, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.015752378851175308, 'loss_2': 0.005161285400390625, 'loss_3': -16.376644134521484, 'loss_4': 0.9683000445365906, 'epoch': 25.37}
{'loss': 0.018, 'grad_norm': 6.23173713684082, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.008867033757269382, 'loss_2': 0.00916290283203125, 'loss_3': -16.35308837890625, 'loss_4': 0.5055996179580688, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 17:04:54,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:04:54,090 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:47:48<13:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:01,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017611004412174225, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.388, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.013397029601037502, 'eval_loss_2': 0.004213973879814148, 'eval_loss_3': -18.10672950744629, 'eval_loss_4': 0.7480290532112122, 'epoch': 25.38}
{'loss': 0.01, 'grad_norm': 4.896106243133545, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.006618115119636059, 'loss_2': 0.00341033935546875, 'loss_3': -16.519874572753906, 'loss_4': 1.089115858078003, 'epoch': 25.38}
{'loss': 0.0149, 'grad_norm': 5.682783603668213, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.010160146281123161, 'loss_2': 0.00469207763671875, 'loss_3': -16.420913696289062, 'loss_4': 0.6887843012809753, 'epoch': 25.39}
{'loss': 0.0081, 'grad_norm': 4.499538421630859, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.0035370751284062862, 'loss_2': 0.00458526611328125, 'loss_3': -16.545795440673828, 'loss_4': 0.5725879669189453, 'epoch': 25.4}
{'loss': 0.0051, 'grad_norm': 4.686487674713135, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.004212824162095785, 'loss_2': 0.0009002685546875, 'loss_3': -16.578227996826172, 'loss_4': 0.5251978635787964, 'epoch': 25.4}
{'loss': 0.0045, 'grad_norm': 4.977123260498047, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.003608493134379387, 'loss_2': 0.0008730888366699219, 'loss_3': -16.42089080810547, 'loss_4': 0.9632330536842346, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 17:05:01,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:01,439 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:47:55<13:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:08,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015747535973787308, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.069, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01236055139452219, 'eval_loss_2': 0.0033869855105876923, 'eval_loss_3': -18.11992645263672, 'eval_loss_4': 0.7390097379684448, 'epoch': 25.41}
{'loss': 0.0088, 'grad_norm': 6.258782863616943, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.006674264091998339, 'loss_2': 0.00213623046875, 'loss_3': -16.472721099853516, 'loss_4': 0.9864296913146973, 'epoch': 25.41}
{'loss': 0.0053, 'grad_norm': 4.502955436706543, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.002787430305033922, 'loss_2': 0.002521514892578125, 'loss_3': -16.35599708557129, 'loss_4': 0.832130491733551, 'epoch': 25.42}
{'loss': 0.0112, 'grad_norm': 4.594809055328369, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.004912140313535929, 'loss_2': 0.006252288818359375, 'loss_3': -16.406700134277344, 'loss_4': 0.5642975568771362, 'epoch': 25.42}
{'loss': 0.0093, 'grad_norm': 5.814794063568115, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.006389394868165255, 'loss_2': 0.0029449462890625, 'loss_3': -16.339818954467773, 'loss_4': 1.2375078201293945, 'epoch': 25.43}
{'loss': 0.0226, 'grad_norm': 12.265634536743164, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.019788827747106552, 'loss_2': 0.00279998779296875, 'loss_3': -16.463104248046875, 'loss_4': 0.4482036530971527, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 17:05:08,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:08,801 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:48:02<13:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:16,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015541956759989262, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012285037897527218, 'eval_loss_2': 0.0032569169998168945, 'eval_loss_3': -18.121845245361328, 'eval_loss_4': 0.707324206829071, 'epoch': 25.44}
{'loss': 0.0167, 'grad_norm': 9.166290283203125, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.01620786264538765, 'loss_2': 0.0004475116729736328, 'loss_3': -16.361478805541992, 'loss_4': 0.6766093969345093, 'epoch': 25.44}
{'loss': 0.0094, 'grad_norm': 5.520137310028076, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.008677559904754162, 'loss_2': 0.0007596015930175781, 'loss_3': -16.531490325927734, 'loss_4': 0.3693923056125641, 'epoch': 25.45}
{'loss': 0.0148, 'grad_norm': 5.6405229568481445, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.010185678489506245, 'loss_2': 0.00457763671875, 'loss_3': -16.41794204711914, 'loss_4': 0.7335872650146484, 'epoch': 25.45}
{'loss': 0.0039, 'grad_norm': 4.6423540115356445, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.0034356946125626564, 'loss_2': 0.00048828125, 'loss_3': -16.561033248901367, 'loss_4': 0.7730209827423096, 'epoch': 25.46}
{'loss': 0.0115, 'grad_norm': 4.504120349884033, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.004974368494004011, 'loss_2': 0.00655364990234375, 'loss_3': -16.54205322265625, 'loss_4': 0.3947831988334656, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 17:05:16,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:16,163 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:48:10<13:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:23,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01535421796143055, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.884, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012222821824252605, 'eval_loss_2': 0.003131397068500519, 'eval_loss_3': -18.119892120361328, 'eval_loss_4': 0.673663318157196, 'epoch': 25.47}
{'loss': 0.0082, 'grad_norm': 5.013939380645752, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.0033104047179222107, 'loss_2': 0.00487518310546875, 'loss_3': -16.441205978393555, 'loss_4': 0.7973595261573792, 'epoch': 25.47}
{'loss': 0.0095, 'grad_norm': 9.025153160095215, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.009522617794573307, 'loss_2': 2.2530555725097656e-05, 'loss_3': -16.308698654174805, 'loss_4': 0.7806211709976196, 'epoch': 25.48}
{'loss': 0.0263, 'grad_norm': 11.217952728271484, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.020115546882152557, 'loss_2': 0.006206512451171875, 'loss_3': -16.49252700805664, 'loss_4': 0.5035226345062256, 'epoch': 25.48}
{'loss': 0.0131, 'grad_norm': 4.571505069732666, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.004065992310643196, 'loss_2': 0.0090484619140625, 'loss_3': -16.454099655151367, 'loss_4': 0.9406808018684387, 'epoch': 25.49}
{'loss': 0.011, 'grad_norm': 4.530025959014893, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.004264522343873978, 'loss_2': 0.006687164306640625, 'loss_3': -16.374588012695312, 'loss_4': 0.9091744422912598, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 17:05:23,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:23,512 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:17<13:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:30,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014712700620293617, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.689, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011515926569700241, 'eval_loss_2': 0.0031967759132385254, 'eval_loss_3': -18.140520095825195, 'eval_loss_4': 0.6479690074920654, 'epoch': 25.49}
{'loss': 0.0099, 'grad_norm': 5.1768798828125, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.0068015288561582565, 'loss_2': 0.003143310546875, 'loss_3': -16.10875129699707, 'loss_4': 1.1601918935775757, 'epoch': 25.5}
{'loss': 0.0059, 'grad_norm': 5.071967601776123, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.00453895004466176, 'loss_2': 0.0013227462768554688, 'loss_3': -16.326984405517578, 'loss_4': 0.662265419960022, 'epoch': 25.51}
{'loss': 0.0061, 'grad_norm': 6.152683734893799, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.0056281364522874355, 'loss_2': 0.00045561790466308594, 'loss_3': -16.360172271728516, 'loss_4': 0.7419540882110596, 'epoch': 25.51}
{'loss': 0.0085, 'grad_norm': 5.2835001945495605, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.008346235379576683, 'loss_2': 0.000186920166015625, 'loss_3': -16.39441680908203, 'loss_4': 0.5576112866401672, 'epoch': 25.52}
{'loss': 0.0095, 'grad_norm': 4.661440849304199, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.0024306941777467728, 'loss_2': 0.007110595703125, 'loss_3': -16.395368576049805, 'loss_4': 0.5766686797142029, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 17:05:30,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:30,878 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:24<13:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:38,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015155713073909283, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.023, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011079574935138226, 'eval_loss_2': 0.004076138138771057, 'eval_loss_3': -18.15353012084961, 'eval_loss_4': 0.6007221341133118, 'epoch': 25.52}
{'loss': 0.0065, 'grad_norm': 4.90347146987915, 'learning_rate': 4.5e-06, 'loss_1': 0.005231641232967377, 'loss_2': 0.0012331008911132812, 'loss_3': -16.36642074584961, 'loss_4': 1.0192914009094238, 'epoch': 25.53}
{'loss': 0.0089, 'grad_norm': 4.778321743011475, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.0040611764416098595, 'loss_2': 0.0048065185546875, 'loss_3': -16.58159828186035, 'loss_4': 0.37067320942878723, 'epoch': 25.53}
{'loss': 0.0031, 'grad_norm': 5.036348819732666, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.002467227168381214, 'loss_2': 0.0006437301635742188, 'loss_3': -16.27294921875, 'loss_4': 0.6784398555755615, 'epoch': 25.54}
{'loss': 0.0104, 'grad_norm': 4.395511627197266, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.0028616467025130987, 'loss_2': 0.0075225830078125, 'loss_3': -16.507144927978516, 'loss_4': 0.3008776903152466, 'epoch': 25.55}
{'loss': 0.0111, 'grad_norm': 5.103097438812256, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.005973869934678078, 'loss_2': 0.0051727294921875, 'loss_3': -16.39852523803711, 'loss_4': 0.6003612875938416, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 17:05:38,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:38,236 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:32<13:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:45,593 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016384664922952652, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.08, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011717593297362328, 'eval_loss_2': 0.004667073488235474, 'eval_loss_3': -18.134578704833984, 'eval_loss_4': 0.5476415157318115, 'epoch': 25.55}
{'loss': 0.0091, 'grad_norm': 5.223325729370117, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.006277403328567743, 'loss_2': 0.0028076171875, 'loss_3': -16.396045684814453, 'loss_4': 0.8445191979408264, 'epoch': 25.56}
{'loss': 0.0124, 'grad_norm': 4.751499176025391, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.0050150370225310326, 'loss_2': 0.00740814208984375, 'loss_3': -16.134065628051758, 'loss_4': 0.654449462890625, 'epoch': 25.56}
{'loss': 0.01, 'grad_norm': 10.02983570098877, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.009268132038414478, 'loss_2': 0.0007090568542480469, 'loss_3': -16.422992706298828, 'loss_4': 0.43985405564308167, 'epoch': 25.57}
{'loss': 0.007, 'grad_norm': 6.960936069488525, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.004720981232821941, 'loss_2': 0.0022792816162109375, 'loss_3': -16.237632751464844, 'loss_4': 0.670245349407196, 'epoch': 25.58}
{'loss': 0.0149, 'grad_norm': 8.570941925048828, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.007468187250196934, 'loss_2': 0.00745391845703125, 'loss_3': -16.34290313720703, 'loss_4': 0.5391823649406433, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 17:05:45,593 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:45,593 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:39<13:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:05:52,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016096852719783783, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01166129857301712, 'eval_loss_2': 0.004435554146766663, 'eval_loss_3': -18.134624481201172, 'eval_loss_4': 0.4957525432109833, 'epoch': 25.58}
{'loss': 0.0069, 'grad_norm': 5.152645111083984, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.00394079415127635, 'loss_2': 0.0029296875, 'loss_3': -16.39404296875, 'loss_4': 0.4030827581882477, 'epoch': 25.59}
{'loss': 0.0074, 'grad_norm': 4.816493034362793, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.004419662524014711, 'loss_2': 0.0029468536376953125, 'loss_3': -16.5783634185791, 'loss_4': -0.09643225371837616, 'epoch': 25.59}
{'loss': 0.0121, 'grad_norm': 5.831630706787109, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.009181821718811989, 'loss_2': 0.002887725830078125, 'loss_3': -16.545120239257812, 'loss_4': 0.5725640058517456, 'epoch': 25.6}
{'loss': 0.0064, 'grad_norm': 5.294479846954346, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.003820955054834485, 'loss_2': 0.0025615692138671875, 'loss_3': -16.4285888671875, 'loss_4': 0.45841091871261597, 'epoch': 25.6}
{'loss': 0.0138, 'grad_norm': 6.377233028411865, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.013360710814595222, 'loss_2': 0.00042247772216796875, 'loss_3': -16.373022079467773, 'loss_4': 0.7121704816818237, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 17:05:52,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:05:52,940 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:48:46<12:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:00,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014688687399029732, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.058, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011021362617611885, 'eval_loss_2': 0.0036673247814178467, 'eval_loss_3': -18.13327407836914, 'eval_loss_4': 0.45288899540901184, 'epoch': 25.61}
{'loss': 0.0085, 'grad_norm': 4.932026386260986, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.004583212547004223, 'loss_2': 0.0038909912109375, 'loss_3': -16.32624053955078, 'loss_4': 0.8096194267272949, 'epoch': 25.62}
{'loss': 0.0027, 'grad_norm': 6.574243068695068, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.0023023574613034725, 'loss_2': 0.0003600120544433594, 'loss_3': -16.408836364746094, 'loss_4': 0.6557021737098694, 'epoch': 25.62}
{'loss': 0.0032, 'grad_norm': 4.778807163238525, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.003040693700313568, 'loss_2': 0.00011205673217773438, 'loss_3': -16.3289794921875, 'loss_4': 1.0033513307571411, 'epoch': 25.63}
{'loss': 0.0043, 'grad_norm': 4.8499436378479, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.003096860833466053, 'loss_2': 0.0012264251708984375, 'loss_3': -16.430892944335938, 'loss_4': 0.5827819108963013, 'epoch': 25.63}
{'loss': 0.0085, 'grad_norm': 5.0233354568481445, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.007810184732079506, 'loss_2': 0.000698089599609375, 'loss_3': -16.52225112915039, 'loss_4': 0.8647856712341309, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 17:06:00,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:00,298 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:48:54<12:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:07,670 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013929069973528385, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.377, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.010758660733699799, 'eval_loss_2': 0.003170408308506012, 'eval_loss_3': -18.133136749267578, 'eval_loss_4': 0.4312891364097595, 'epoch': 25.64}
{'loss': 0.006, 'grad_norm': 4.638497352600098, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.002859348664060235, 'loss_2': 0.0031719207763671875, 'loss_3': -16.117992401123047, 'loss_4': 0.4608529806137085, 'epoch': 25.65}
{'loss': 0.0097, 'grad_norm': 4.226302146911621, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.00619834428653121, 'loss_2': 0.003528594970703125, 'loss_3': -16.335025787353516, 'loss_4': 0.17989684641361237, 'epoch': 25.65}
{'loss': 0.0113, 'grad_norm': 4.908885478973389, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.004492760170251131, 'loss_2': 0.0067901611328125, 'loss_3': -16.41550064086914, 'loss_4': 0.6903206706047058, 'epoch': 25.66}
{'loss': 0.0051, 'grad_norm': 5.208647727966309, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.0030039409175515175, 'loss_2': 0.00211334228515625, 'loss_3': -16.4151668548584, 'loss_4': 0.7032073736190796, 'epoch': 25.66}
{'loss': 0.007, 'grad_norm': 4.9676289558410645, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.003930144477635622, 'loss_2': 0.00304412841796875, 'loss_3': -16.38138198852539, 'loss_4': 0.9358240962028503, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 17:06:07,670 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:07,670 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:49:01<12:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:15,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013549445196986198, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010170221328735352, 'eval_loss_2': 0.003379225730895996, 'eval_loss_3': -18.139511108398438, 'eval_loss_4': 0.4685712456703186, 'epoch': 25.67}
{'loss': 0.009, 'grad_norm': 4.977898120880127, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.0043363627046346664, 'loss_2': 0.00469207763671875, 'loss_3': -16.214359283447266, 'loss_4': 0.605167031288147, 'epoch': 25.67}
{'loss': 0.0146, 'grad_norm': 4.981712818145752, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.0057733491994440556, 'loss_2': 0.0088348388671875, 'loss_3': -16.34520721435547, 'loss_4': 0.6335976123809814, 'epoch': 25.68}
{'loss': 0.0133, 'grad_norm': 4.706338882446289, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.006042929831892252, 'loss_2': 0.00726318359375, 'loss_3': -16.35881805419922, 'loss_4': 0.5211374163627625, 'epoch': 25.69}
{'loss': 0.011, 'grad_norm': 4.997755527496338, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.003916547633707523, 'loss_2': 0.0070343017578125, 'loss_3': -16.239219665527344, 'loss_4': 0.007603827863931656, 'epoch': 25.69}
{'loss': 0.024, 'grad_norm': 5.2582621574401855, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.0112411854788661, 'loss_2': 0.0127716064453125, 'loss_3': -16.302207946777344, 'loss_4': 0.5361517071723938, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 17:06:15,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:15,020 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:49:08<12:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:22,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013689171522855759, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01044253259897232, 'eval_loss_2': 0.003246638923883438, 'eval_loss_3': -18.128034591674805, 'eval_loss_4': 0.5403671860694885, 'epoch': 25.7}
{'loss': 0.0083, 'grad_norm': 6.518261432647705, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.007402459159493446, 'loss_2': 0.0009064674377441406, 'loss_3': -16.248958587646484, 'loss_4': 0.13165035843849182, 'epoch': 25.7}
{'loss': 0.0135, 'grad_norm': 4.851738929748535, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.006011591292917728, 'loss_2': 0.0075225830078125, 'loss_3': -16.26980209350586, 'loss_4': 0.6451471447944641, 'epoch': 25.71}
{'loss': 0.0076, 'grad_norm': 4.826539993286133, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.0029313145205378532, 'loss_2': 0.0047149658203125, 'loss_3': -16.308612823486328, 'loss_4': 0.7324960231781006, 'epoch': 25.72}
{'loss': 0.0055, 'grad_norm': 4.625451564788818, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.004232970532029867, 'loss_2': 0.0013170242309570312, 'loss_3': -16.398468017578125, 'loss_4': 0.4170851707458496, 'epoch': 25.72}
{'loss': 0.0106, 'grad_norm': 5.049119472503662, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.00735613564029336, 'loss_2': 0.0032711029052734375, 'loss_3': -16.413341522216797, 'loss_4': 0.5186910033226013, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 17:06:22,377 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:22,377 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:49:16<12:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:29,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015476648695766926, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.224, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011276429519057274, 'eval_loss_2': 0.0042002201080322266, 'eval_loss_3': -18.12736701965332, 'eval_loss_4': 0.5943500995635986, 'epoch': 25.73}
{'loss': 0.0115, 'grad_norm': 5.004636764526367, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.003368422854691744, 'loss_2': 0.00812530517578125, 'loss_3': -16.422164916992188, 'loss_4': 0.17206522822380066, 'epoch': 25.73}
{'loss': 0.0182, 'grad_norm': 12.870951652526855, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.01578805036842823, 'loss_2': 0.002460479736328125, 'loss_3': -16.31949234008789, 'loss_4': 0.31414875388145447, 'epoch': 25.74}
{'loss': 0.0046, 'grad_norm': 4.853800296783447, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.0034055612049996853, 'loss_2': 0.00121307373046875, 'loss_3': -16.22486114501953, 'loss_4': 0.694789707660675, 'epoch': 25.74}
{'loss': 0.0144, 'grad_norm': 5.614787578582764, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.005992645863443613, 'loss_2': 0.00839996337890625, 'loss_3': -16.2469482421875, 'loss_4': 0.7818102836608887, 'epoch': 25.75}
{'loss': 0.0083, 'grad_norm': 4.810570240020752, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.0021880462300032377, 'loss_2': 0.006103515625, 'loss_3': -16.20687484741211, 'loss_4': 0.3292449712753296, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 17:06:29,733 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:29,733 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:23<12:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:37,093 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01584506779909134, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011437601409852505, 'eval_loss_2': 0.00440746545791626, 'eval_loss_3': -18.12126350402832, 'eval_loss_4': 0.5961112976074219, 'epoch': 25.76}
{'loss': 0.0081, 'grad_norm': 4.956969738006592, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.004488279577344656, 'loss_2': 0.0035686492919921875, 'loss_3': -16.157459259033203, 'loss_4': 0.25632646679878235, 'epoch': 25.76}
{'loss': 0.0105, 'grad_norm': 5.289076328277588, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.005258513614535332, 'loss_2': 0.005214691162109375, 'loss_3': -16.396129608154297, 'loss_4': 0.5227874517440796, 'epoch': 25.77}
{'loss': 0.0097, 'grad_norm': 6.120110034942627, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.006422527600079775, 'loss_2': 0.0032978057861328125, 'loss_3': -16.227184295654297, 'loss_4': 0.09548404812812805, 'epoch': 25.77}
{'loss': 0.0126, 'grad_norm': 4.719313621520996, 'learning_rate': 4.25e-06, 'loss_1': 0.004055594094097614, 'loss_2': 0.0085296630859375, 'loss_3': -16.25491714477539, 'loss_4': 0.6148715615272522, 'epoch': 25.78}
{'loss': 0.0043, 'grad_norm': 5.033900737762451, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.002338568912819028, 'loss_2': 0.002010345458984375, 'loss_3': -16.339231491088867, 'loss_4': 0.6266669631004333, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 17:06:37,093 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:37,093 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:31<12:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:44,451 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0148042356595397, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010662726126611233, 'eval_loss_2': 0.004141509532928467, 'eval_loss_3': -18.131349563598633, 'eval_loss_4': 0.5881876349449158, 'epoch': 25.78}
{'loss': 0.0069, 'grad_norm': 5.024385452270508, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.004620754159986973, 'loss_2': 0.0022983551025390625, 'loss_3': -16.336267471313477, 'loss_4': 0.2866423726081848, 'epoch': 25.79}
{'loss': 0.0157, 'grad_norm': 7.659307956695557, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.011882124468684196, 'loss_2': 0.0038623809814453125, 'loss_3': -16.464744567871094, 'loss_4': 0.3475775718688965, 'epoch': 25.8}
{'loss': 0.005, 'grad_norm': 4.890887260437012, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.003999846521764994, 'loss_2': 0.00095367431640625, 'loss_3': -16.46738052368164, 'loss_4': 0.3423803448677063, 'epoch': 25.8}
{'loss': 0.009, 'grad_norm': 5.762187480926514, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.007743573281913996, 'loss_2': 0.001239776611328125, 'loss_3': -16.277645111083984, 'loss_4': 0.7459021806716919, 'epoch': 25.81}
{'loss': 0.0088, 'grad_norm': 4.509670257568359, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.0031622147653251886, 'loss_2': 0.005603790283203125, 'loss_3': -16.32807159423828, 'loss_4': 0.6276893615722656, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 17:06:44,451 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:44,451 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:38<12:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:51,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01545567438006401, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.129, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010377597995102406, 'eval_loss_2': 0.00507807731628418, 'eval_loss_3': -18.13045883178711, 'eval_loss_4': 0.600191593170166, 'epoch': 25.81}
{'loss': 0.0043, 'grad_norm': 4.5656418800354, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.00264279218390584, 'loss_2': 0.00165557861328125, 'loss_3': -16.447372436523438, 'loss_4': 0.397136390209198, 'epoch': 25.82}
{'loss': 0.0119, 'grad_norm': 5.411054611206055, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.007577534765005112, 'loss_2': 0.0042877197265625, 'loss_3': -16.172388076782227, 'loss_4': 0.9087133407592773, 'epoch': 25.83}
{'loss': 0.0205, 'grad_norm': 11.433883666992188, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.01349399983882904, 'loss_2': 0.0070037841796875, 'loss_3': -16.273151397705078, 'loss_4': 0.17913344502449036, 'epoch': 25.83}
{'loss': 0.0079, 'grad_norm': 4.858556747436523, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.006016521714627743, 'loss_2': 0.0018596649169921875, 'loss_3': -16.25725555419922, 'loss_4': 0.6140660643577576, 'epoch': 25.84}
{'loss': 0.0103, 'grad_norm': 4.794047832489014, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.003952099476009607, 'loss_2': 0.006366729736328125, 'loss_3': -16.241317749023438, 'loss_4': 0.6770610809326172, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 17:06:51,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:51,815 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:45<12:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:06:59,172 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014962386339902878, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.243, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010362844914197922, 'eval_loss_2': 0.004599541425704956, 'eval_loss_3': -18.131370544433594, 'eval_loss_4': 0.5816138386726379, 'epoch': 25.84}
{'loss': 0.0051, 'grad_norm': 4.200735569000244, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.003127082483842969, 'loss_2': 0.0019989013671875, 'loss_3': -16.25815773010254, 'loss_4': 0.6359139680862427, 'epoch': 25.85}
{'loss': 0.0038, 'grad_norm': 4.796020030975342, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.0016972145531326532, 'loss_2': 0.002105712890625, 'loss_3': -16.443920135498047, 'loss_4': 0.49695175886154175, 'epoch': 25.85}
{'loss': 0.0094, 'grad_norm': 4.641157627105713, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.006467074155807495, 'loss_2': 0.002941131591796875, 'loss_3': -16.197105407714844, 'loss_4': 0.8270520567893982, 'epoch': 25.86}
{'loss': 0.012, 'grad_norm': 5.845175266265869, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.0070048002526164055, 'loss_2': 0.005008697509765625, 'loss_3': -16.459381103515625, 'loss_4': 0.4142684042453766, 'epoch': 25.87}
{'loss': 0.0074, 'grad_norm': 4.9920854568481445, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.005957741755992174, 'loss_2': 0.0014820098876953125, 'loss_3': -16.301321029663086, 'loss_4': 0.8912639021873474, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 17:06:59,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:06:59,172 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:49:53<12:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:06,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01418368797749281, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.155, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010240409523248672, 'eval_loss_2': 0.003943279385566711, 'eval_loss_3': -18.136058807373047, 'eval_loss_4': 0.5542126297950745, 'epoch': 25.87}
{'loss': 0.0102, 'grad_norm': 4.542031764984131, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.0035679631400853395, 'loss_2': 0.0066375732421875, 'loss_3': -16.275390625, 'loss_4': 0.6174160242080688, 'epoch': 25.88}
{'loss': 0.0054, 'grad_norm': 4.9790568351745605, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.004223370924592018, 'loss_2': 0.0011806488037109375, 'loss_3': -16.298234939575195, 'loss_4': 0.24553273618221283, 'epoch': 25.88}
{'loss': 0.011, 'grad_norm': 5.264559268951416, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.00412207655608654, 'loss_2': 0.00690460205078125, 'loss_3': -16.294321060180664, 'loss_4': 0.1339842826128006, 'epoch': 25.89}
{'loss': 0.0094, 'grad_norm': 5.780543804168701, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.005974635016173124, 'loss_2': 0.0034427642822265625, 'loss_3': -16.41425132751465, 'loss_4': 0.4208754897117615, 'epoch': 25.9}
{'loss': 0.0076, 'grad_norm': 4.764333724975586, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.004536240827292204, 'loss_2': 0.0030670166015625, 'loss_3': -16.38361167907715, 'loss_4': 0.6697224974632263, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 17:07:06,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:06,534 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:50:00<12:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:13,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013970322906970978, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.234, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010231532156467438, 'eval_loss_2': 0.00373879075050354, 'eval_loss_3': -18.135356903076172, 'eval_loss_4': 0.5178237557411194, 'epoch': 25.9}
{'loss': 0.005, 'grad_norm': 4.689391613006592, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.00465952605009079, 'loss_2': 0.00030231475830078125, 'loss_3': -16.400211334228516, 'loss_4': 0.202095165848732, 'epoch': 25.91}
{'loss': 0.0066, 'grad_norm': 4.969168663024902, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.0052634840831160545, 'loss_2': 0.0013370513916015625, 'loss_3': -16.25067138671875, 'loss_4': 0.08457928895950317, 'epoch': 25.91}
{'loss': 0.0134, 'grad_norm': 5.541953086853027, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.011720817536115646, 'loss_2': 0.0016498565673828125, 'loss_3': -16.174800872802734, 'loss_4': 0.6363518238067627, 'epoch': 25.92}
{'loss': 0.014, 'grad_norm': 5.2580156326293945, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.007927746511995792, 'loss_2': 0.006103515625, 'loss_3': -16.261333465576172, 'loss_4': 0.49166160821914673, 'epoch': 25.92}
{'loss': 0.015, 'grad_norm': 6.097053050994873, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.006681223399937153, 'loss_2': 0.00835418701171875, 'loss_3': -16.264751434326172, 'loss_4': 0.4780665338039398, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 17:07:13,892 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:13,892 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:50:07<12:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:21,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01315727923065424, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.841, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009484407491981983, 'eval_loss_2': 0.0036728717386722565, 'eval_loss_3': -18.125539779663086, 'eval_loss_4': 0.4910335838794708, 'epoch': 25.93}
{'loss': 0.0046, 'grad_norm': 5.152647495269775, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.004312078468501568, 'loss_2': 0.0002646446228027344, 'loss_3': -16.29015350341797, 'loss_4': 0.8639097809791565, 'epoch': 25.94}
{'loss': 0.0044, 'grad_norm': 4.973504543304443, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.004083759151399136, 'loss_2': 0.0002970695495605469, 'loss_3': -16.430429458618164, 'loss_4': 0.5256626605987549, 'epoch': 25.94}
{'loss': 0.0104, 'grad_norm': 4.356052875518799, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.005857735872268677, 'loss_2': 0.0045623779296875, 'loss_3': -16.577003479003906, 'loss_4': 0.20991197228431702, 'epoch': 25.95}
{'loss': 0.0082, 'grad_norm': 5.583602428436279, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.00662388326600194, 'loss_2': 0.001617431640625, 'loss_3': -16.425724029541016, 'loss_4': 0.3123549520969391, 'epoch': 25.95}
{'loss': 0.0067, 'grad_norm': 4.710180759429932, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.0032104363199323416, 'loss_2': 0.0034637451171875, 'loss_3': -16.32879638671875, 'loss_4': 0.2505757808685303, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 17:07:21,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:21,240 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:50:15<11:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:28,596 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0136837437748909, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.876, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009559637866914272, 'eval_loss_2': 0.004124104976654053, 'eval_loss_3': -18.134342193603516, 'eval_loss_4': 0.4493788778781891, 'epoch': 25.96}
{'loss': 0.0092, 'grad_norm': 5.214720726013184, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.003331834450364113, 'loss_2': 0.00588226318359375, 'loss_3': -16.36005973815918, 'loss_4': 0.5757401585578918, 'epoch': 25.97}
{'loss': 0.0098, 'grad_norm': 6.903883934020996, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.008185003884136677, 'loss_2': 0.0015773773193359375, 'loss_3': -16.198162078857422, 'loss_4': 0.09056207537651062, 'epoch': 25.97}
{'loss': 0.006, 'grad_norm': 5.5656657218933105, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.0048036230728030205, 'loss_2': 0.0012235641479492188, 'loss_3': -16.352401733398438, 'loss_4': 0.43184688687324524, 'epoch': 25.98}
{'loss': 0.0066, 'grad_norm': 5.398992538452148, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.005345357581973076, 'loss_2': 0.0012073516845703125, 'loss_3': -16.378883361816406, 'loss_4': 0.5484128594398499, 'epoch': 25.98}
{'loss': 0.0062, 'grad_norm': 4.73502779006958, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.002423337195068598, 'loss_2': 0.003780364990234375, 'loss_3': -16.45345687866211, 'loss_4': 0.5218346118927002, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 17:07:28,597 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:28,597 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:22<11:30,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 17:07:35,628 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01339095551520586, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.226, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009389756247401237, 'eval_loss_2': 0.004001200199127197, 'eval_loss_3': -18.136829376220703, 'eval_loss_4': 0.3922344148159027, 'epoch': 25.99}
{'loss': 0.0055, 'grad_norm': inf, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.0032863044179975986, 'loss_2': 0.002193450927734375, 'loss_3': -16.356555938720703, 'loss_4': 0.7042214870452881, 'epoch': 25.99}
{'loss': 0.0066, 'grad_norm': 5.618758201599121, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.001698178704828024, 'loss_2': 0.0048980712890625, 'loss_3': -16.396129608154297, 'loss_4': 0.3422747850418091, 'epoch': 26.0}
{'loss': 0.0093, 'grad_norm': 4.302523612976074, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.002989862347021699, 'loss_2': 0.00629425048828125, 'loss_3': -16.535350799560547, 'loss_4': 0.6395435333251953, 'epoch': 26.01}
{'loss': 0.0048, 'grad_norm': 4.174360275268555, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.004255888517946005, 'loss_2': 0.0005192756652832031, 'loss_3': -16.562454223632812, 'loss_4': 0.865240216255188, 'epoch': 26.01}
{'loss': 0.0746, 'grad_norm': 12.21560287475586, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.06804965436458588, 'loss_2': 0.0065765380859375, 'loss_3': -16.541805267333984, 'loss_4': 0.39038997888565063, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 17:07:35,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:35,629 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:29<11:43,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:07:42,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013130491599440575, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.322, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009383266791701317, 'eval_loss_2': 0.003747224807739258, 'eval_loss_3': -18.126819610595703, 'eval_loss_4': 0.3788480758666992, 'epoch': 26.02}
{'loss': 0.0129, 'grad_norm': 4.7644453048706055, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.004982182290405035, 'loss_2': 0.0078887939453125, 'loss_3': -16.293724060058594, 'loss_4': 0.3752659559249878, 'epoch': 26.02}
{'loss': 0.0065, 'grad_norm': 4.98634672164917, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.004205791745334864, 'loss_2': 0.00234222412109375, 'loss_3': -16.364559173583984, 'loss_4': 0.15081356465816498, 'epoch': 26.03}
{'loss': 0.007, 'grad_norm': 28.7833309173584, 'learning_rate': 4e-06, 'loss_1': 0.00401450926437974, 'loss_2': 0.002971649169921875, 'loss_3': -16.400924682617188, 'loss_4': 0.6026893854141235, 'epoch': 26.03}
{'loss': 0.0047, 'grad_norm': 4.866289138793945, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.00279523734934628, 'loss_2': 0.0019016265869140625, 'loss_3': -16.374732971191406, 'loss_4': 0.6109687089920044, 'epoch': 26.04}
{'loss': 0.008, 'grad_norm': 4.616970062255859, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.004913679789751768, 'loss_2': 0.003124237060546875, 'loss_3': -16.456552505493164, 'loss_4': 0.032687872648239136, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 17:07:42,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:42,986 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:36<11:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:50,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01233287900686264, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009444653987884521, 'eval_loss_2': 0.002888225018978119, 'eval_loss_3': -18.135435104370117, 'eval_loss_4': 0.34168750047683716, 'epoch': 26.05}
{'loss': 0.0112, 'grad_norm': 6.659111022949219, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.009391246363520622, 'loss_2': 0.001842498779296875, 'loss_3': -16.399946212768555, 'loss_4': 0.133816659450531, 'epoch': 26.05}
{'loss': 0.0711, 'grad_norm': 12.916579246520996, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.06738901138305664, 'loss_2': 0.0037479400634765625, 'loss_3': -16.386293411254883, 'loss_4': 0.7114812135696411, 'epoch': 26.06}
{'loss': 0.0245, 'grad_norm': 15.181869506835938, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.02198043279349804, 'loss_2': 0.0025177001953125, 'loss_3': -16.315174102783203, 'loss_4': 0.7191330790519714, 'epoch': 26.06}
{'loss': 0.0092, 'grad_norm': 5.2264509201049805, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.003337508300319314, 'loss_2': 0.005840301513671875, 'loss_3': -16.240509033203125, 'loss_4': -0.04867221415042877, 'epoch': 26.07}
{'loss': 0.0066, 'grad_norm': 4.578958988189697, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.004010708536952734, 'loss_2': 0.0026226043701171875, 'loss_3': -16.334144592285156, 'loss_4': 0.26504507660865784, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 17:07:50,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:50,339 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:44<11:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:07:57,692 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01233688835054636, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.08, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009319831617176533, 'eval_loss_2': 0.0030170567333698273, 'eval_loss_3': -18.136430740356445, 'eval_loss_4': 0.2781391441822052, 'epoch': 26.08}
{'loss': 0.0083, 'grad_norm': 4.936818599700928, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.003788381814956665, 'loss_2': 0.0044708251953125, 'loss_3': -16.410823822021484, 'loss_4': 0.06585462391376495, 'epoch': 26.08}
{'loss': 0.0044, 'grad_norm': 4.933879375457764, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.0037361967843025923, 'loss_2': 0.0006666183471679688, 'loss_3': -16.296171188354492, 'loss_4': 0.48901504278182983, 'epoch': 26.09}
{'loss': 0.0074, 'grad_norm': 5.000457763671875, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.005613937042653561, 'loss_2': 0.001766204833984375, 'loss_3': -16.475004196166992, 'loss_4': 0.38759350776672363, 'epoch': 26.09}
{'loss': 0.011, 'grad_norm': 6.550586700439453, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.010438179597258568, 'loss_2': 0.0005922317504882812, 'loss_3': -16.445415496826172, 'loss_4': 0.050030119717121124, 'epoch': 26.1}
{'loss': 0.0063, 'grad_norm': 4.382593154907227, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.00393180176615715, 'loss_2': 0.00240325927734375, 'loss_3': -16.321762084960938, 'loss_4': 0.3811999261379242, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 17:07:57,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:07:57,693 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:50:51<11:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:05,058 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012126714922487736, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.496, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009300805628299713, 'eval_loss_2': 0.002825908362865448, 'eval_loss_3': -18.13561248779297, 'eval_loss_4': 0.2161397933959961, 'epoch': 26.1}
{'loss': 0.0032, 'grad_norm': 4.66749906539917, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.003187594935297966, 'loss_2': 1.6927719116210938e-05, 'loss_3': -16.378860473632812, 'loss_4': 0.1521158665418625, 'epoch': 26.11}
{'loss': 0.0055, 'grad_norm': 5.006309509277344, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.003430587239563465, 'loss_2': 0.0020198822021484375, 'loss_3': -16.37902069091797, 'loss_4': 0.2628777027130127, 'epoch': 26.12}
{'loss': 0.0045, 'grad_norm': 4.678347587585449, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.003024744102731347, 'loss_2': 0.001430511474609375, 'loss_3': -16.470149993896484, 'loss_4': 0.3678550720214844, 'epoch': 26.12}
{'loss': 0.0079, 'grad_norm': 4.881417274475098, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.005893125664442778, 'loss_2': 0.002048492431640625, 'loss_3': -16.38142967224121, 'loss_4': -0.08038352429866791, 'epoch': 26.13}
{'loss': 0.0099, 'grad_norm': 4.633781433105469, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.004015269689261913, 'loss_2': 0.00591278076171875, 'loss_3': -16.475927352905273, 'loss_4': 0.07557156682014465, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 17:08:05,058 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:05,058 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:50:59<11:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:12,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01174723356962204, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.837, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009239845909178257, 'eval_loss_2': 0.0025073885917663574, 'eval_loss_3': -18.139753341674805, 'eval_loss_4': 0.14708060026168823, 'epoch': 26.13}
{'loss': 0.0062, 'grad_norm': 4.744813442230225, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.003049518447369337, 'loss_2': 0.0031280517578125, 'loss_3': -16.320266723632812, 'loss_4': 0.4105663597583771, 'epoch': 26.14}
{'loss': 0.0072, 'grad_norm': 4.961308479309082, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.005875207483768463, 'loss_2': 0.0013580322265625, 'loss_3': -16.34713363647461, 'loss_4': -0.04706592485308647, 'epoch': 26.15}
{'loss': 0.0109, 'grad_norm': 8.00271987915039, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.00878925435245037, 'loss_2': 0.002105712890625, 'loss_3': -16.252037048339844, 'loss_4': 0.033884331583976746, 'epoch': 26.15}
{'loss': 0.0094, 'grad_norm': 5.22580099105835, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.005088157020509243, 'loss_2': 0.004322052001953125, 'loss_3': -16.53081512451172, 'loss_4': 0.37349623441696167, 'epoch': 26.16}
{'loss': 0.0065, 'grad_norm': 4.400820732116699, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.0024969172663986683, 'loss_2': 0.004039764404296875, 'loss_3': -16.47502326965332, 'loss_4': -0.240336611866951, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 17:08:12,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:12,418 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:51:06<11:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:19,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011427594348788261, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.855, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00890605803579092, 'eval_loss_2': 0.0025215372443199158, 'eval_loss_3': -18.13726043701172, 'eval_loss_4': 0.10545062273740768, 'epoch': 26.16}
{'loss': 0.0242, 'grad_norm': 13.429899215698242, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.014963596127927303, 'loss_2': 0.0092620849609375, 'loss_3': -16.265241622924805, 'loss_4': 0.10280625522136688, 'epoch': 26.17}
{'loss': 0.0132, 'grad_norm': 5.733479976654053, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.011002231389284134, 'loss_2': 0.0021724700927734375, 'loss_3': -16.248645782470703, 'loss_4': -0.26726198196411133, 'epoch': 26.17}
{'loss': 0.015, 'grad_norm': 5.540146350860596, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.006598848383873701, 'loss_2': 0.00836944580078125, 'loss_3': -16.36486053466797, 'loss_4': -0.14161041378974915, 'epoch': 26.18}
{'loss': 0.0172, 'grad_norm': 5.391590595245361, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.007684660144150257, 'loss_2': 0.009521484375, 'loss_3': -16.24037742614746, 'loss_4': 0.1510750651359558, 'epoch': 26.19}
{'loss': 0.0053, 'grad_norm': 5.150404930114746, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.004095130134373903, 'loss_2': 0.0012311935424804688, 'loss_3': -16.306188583374023, 'loss_4': 0.052456334233284, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 17:08:19,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:19,769 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:51:13<11:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:27,117 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011667661368846893, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.001, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008767240680754185, 'eval_loss_2': 0.002900421619415283, 'eval_loss_3': -18.14237403869629, 'eval_loss_4': 0.06697546690702438, 'epoch': 26.19}
{'loss': 0.0077, 'grad_norm': 4.62546443939209, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.004349439404904842, 'loss_2': 0.003314971923828125, 'loss_3': -16.420242309570312, 'loss_4': -0.16242602467536926, 'epoch': 26.2}
{'loss': 0.0075, 'grad_norm': 5.135177135467529, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.004669956862926483, 'loss_2': 0.002796173095703125, 'loss_3': -16.53470230102539, 'loss_4': -0.0097145214676857, 'epoch': 26.2}
{'loss': 0.0077, 'grad_norm': 5.001976013183594, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.0032479241490364075, 'loss_2': 0.00441741943359375, 'loss_3': -16.400909423828125, 'loss_4': -0.1529712826013565, 'epoch': 26.21}
{'loss': 0.0106, 'grad_norm': 4.770780086517334, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.002708837855607271, 'loss_2': 0.0078582763671875, 'loss_3': -16.410551071166992, 'loss_4': 0.37817567586898804, 'epoch': 26.22}
{'loss': 0.0091, 'grad_norm': 6.0173540115356445, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.005761807318776846, 'loss_2': 0.003292083740234375, 'loss_3': -16.324851989746094, 'loss_4': -0.08365397900342941, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 17:08:27,117 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:27,117 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:21<11:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:34,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0117558054625988, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008986901491880417, 'eval_loss_2': 0.002768903970718384, 'eval_loss_3': -18.142683029174805, 'eval_loss_4': 0.015012888237833977, 'epoch': 26.22}
{'loss': 0.0061, 'grad_norm': 4.976877212524414, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.005737204570323229, 'loss_2': 0.0003485679626464844, 'loss_3': -16.264732360839844, 'loss_4': 0.19016501307487488, 'epoch': 26.23}
{'loss': 0.002, 'grad_norm': 4.295214653015137, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.0016721191350370646, 'loss_2': 0.00031948089599609375, 'loss_3': -16.477922439575195, 'loss_4': -0.28640860319137573, 'epoch': 26.23}
{'loss': 0.0218, 'grad_norm': 10.535771369934082, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.014636961743235588, 'loss_2': 0.00720977783203125, 'loss_3': -16.236907958984375, 'loss_4': -0.09933240711688995, 'epoch': 26.24}
{'loss': 0.0051, 'grad_norm': 4.648810863494873, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.0025832997635006905, 'loss_2': 0.0025615692138671875, 'loss_3': -16.479103088378906, 'loss_4': 0.11361625790596008, 'epoch': 26.24}
{'loss': 0.0067, 'grad_norm': 4.5320329666137695, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.0033317082561552525, 'loss_2': 0.003376007080078125, 'loss_3': -16.462730407714844, 'loss_4': -0.1953229159116745, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 17:08:34,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:34,471 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:28<11:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:41,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011593597941100597, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.513, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008723186329007149, 'eval_loss_2': 0.002870410680770874, 'eval_loss_3': -18.14252281188965, 'eval_loss_4': -0.020244818180799484, 'epoch': 26.25}
{'loss': 0.0185, 'grad_norm': 8.420856475830078, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.014967316761612892, 'loss_2': 0.0035724639892578125, 'loss_3': -16.190292358398438, 'loss_4': 0.006514115259051323, 'epoch': 26.26}
{'loss': 0.0051, 'grad_norm': 4.451144218444824, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.004827423486858606, 'loss_2': 0.00023102760314941406, 'loss_3': -16.426183700561523, 'loss_4': -0.001695096492767334, 'epoch': 26.26}
{'loss': 0.0128, 'grad_norm': 7.674750804901123, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.010378606617450714, 'loss_2': 0.0024700164794921875, 'loss_3': -16.472309112548828, 'loss_4': 0.45709294080734253, 'epoch': 26.27}
{'loss': 0.011, 'grad_norm': 5.200557708740234, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.006165884900838137, 'loss_2': 0.004871368408203125, 'loss_3': -16.165966033935547, 'loss_4': -0.16844186186790466, 'epoch': 26.27}
{'loss': 0.006, 'grad_norm': 4.652245998382568, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.004849071614444256, 'loss_2': 0.001129150390625, 'loss_3': -16.472522735595703, 'loss_4': -0.27176633477211, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 17:08:41,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:41,825 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:35<10:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:49,181 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011726250872015953, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.64, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00870551634579897, 'eval_loss_2': 0.003020733594894409, 'eval_loss_3': -18.141216278076172, 'eval_loss_4': -0.018600741401314735, 'epoch': 26.28}
{'loss': 0.0228, 'grad_norm': 6.459406852722168, 'learning_rate': 3.75e-06, 'loss_1': 0.008130937814712524, 'loss_2': 0.014678955078125, 'loss_3': -16.357826232910156, 'loss_4': -0.16939648985862732, 'epoch': 26.28}
{'loss': 0.005, 'grad_norm': 4.758278846740723, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.0032243228051811457, 'loss_2': 0.001819610595703125, 'loss_3': -16.30626678466797, 'loss_4': -0.29801613092422485, 'epoch': 26.29}
{'loss': 0.0845, 'grad_norm': 33.45430374145508, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.07995717227458954, 'loss_2': 0.0045166015625, 'loss_3': -16.38327407836914, 'loss_4': 0.36064285039901733, 'epoch': 26.3}
{'loss': 0.0039, 'grad_norm': 4.595110893249512, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.002833720063790679, 'loss_2': 0.0010509490966796875, 'loss_3': -16.294477462768555, 'loss_4': -0.4938066303730011, 'epoch': 26.3}
{'loss': 0.0124, 'grad_norm': 6.59024715423584, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.009909272193908691, 'loss_2': 0.002452850341796875, 'loss_3': -16.17864990234375, 'loss_4': -0.16966331005096436, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 17:08:49,181 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:49,181 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:43<10:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:08:56,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012372110038995743, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.42, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.008811095729470253, 'eval_loss_2': 0.003561016172170639, 'eval_loss_3': -18.15422821044922, 'eval_loss_4': 0.015827789902687073, 'epoch': 26.31}
{'loss': 0.0051, 'grad_norm': 4.718437194824219, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.004096075426787138, 'loss_2': 0.0010471343994140625, 'loss_3': -16.35552215576172, 'loss_4': 0.09656825661659241, 'epoch': 26.31}
{'loss': 0.0117, 'grad_norm': 5.843472003936768, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.010651089251041412, 'loss_2': 0.001026153564453125, 'loss_3': -16.31492805480957, 'loss_4': -0.14275377988815308, 'epoch': 26.32}
{'loss': 0.0043, 'grad_norm': 4.614970684051514, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.004115074872970581, 'loss_2': 0.0002143383026123047, 'loss_3': -16.536169052124023, 'loss_4': 0.1701202690601349, 'epoch': 26.33}
{'loss': 0.0056, 'grad_norm': 4.660258769989014, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.005578166805207729, 'loss_2': 3.1828880310058594e-05, 'loss_3': -16.346954345703125, 'loss_4': -0.05207115784287453, 'epoch': 26.33}
{'loss': 0.0102, 'grad_norm': 4.906614780426025, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.008138775825500488, 'loss_2': 0.0020542144775390625, 'loss_3': -16.43998146057129, 'loss_4': -0.142927885055542, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 17:08:56,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:08:56,553 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:51:50<10:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:03,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012361042201519012, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.69, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009052775800228119, 'eval_loss_2': 0.0033082664012908936, 'eval_loss_3': -18.15160369873047, 'eval_loss_4': -0.009980720467865467, 'epoch': 26.34}
{'loss': 0.0081, 'grad_norm': 21.70583152770996, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.004534668754786253, 'loss_2': 0.003566741943359375, 'loss_3': -16.57022476196289, 'loss_4': 0.11012877523899078, 'epoch': 26.34}
{'loss': 0.0062, 'grad_norm': 5.7077484130859375, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.005795198027044535, 'loss_2': 0.0004391670227050781, 'loss_3': -16.42308807373047, 'loss_4': 0.05639709532260895, 'epoch': 26.35}
{'loss': 0.0173, 'grad_norm': 8.267852783203125, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.010905703529715538, 'loss_2': 0.00637054443359375, 'loss_3': -16.19649887084961, 'loss_4': 0.047355808317661285, 'epoch': 26.35}
{'loss': 0.0131, 'grad_norm': 7.501114368438721, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.012191511690616608, 'loss_2': 0.00093841552734375, 'loss_3': -16.225454330444336, 'loss_4': 0.00014765560626983643, 'epoch': 26.36}
{'loss': 0.0056, 'grad_norm': 4.519312381744385, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.0038750984240323305, 'loss_2': 0.0017032623291015625, 'loss_3': -16.339828491210938, 'loss_4': -0.23367710411548615, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 17:09:03,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:03,916 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:51:57<10:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:11,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013321366161108017, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.954, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009823229163885117, 'eval_loss_2': 0.0034981369972229004, 'eval_loss_3': -18.137231826782227, 'eval_loss_4': -0.06796416640281677, 'epoch': 26.37}
{'loss': 0.007, 'grad_norm': 5.067824363708496, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.00674050347879529, 'loss_2': 0.00025010108947753906, 'loss_3': -16.255905151367188, 'loss_4': -0.22268693149089813, 'epoch': 26.37}
{'loss': 0.0082, 'grad_norm': 5.625394821166992, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.007029392756521702, 'loss_2': 0.001190185546875, 'loss_3': -16.318138122558594, 'loss_4': -0.17893420159816742, 'epoch': 26.38}
{'loss': 0.0335, 'grad_norm': 19.32701301574707, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.03016812913119793, 'loss_2': 0.00336456298828125, 'loss_3': -16.222143173217773, 'loss_4': -0.3557818531990051, 'epoch': 26.38}
{'loss': 0.0109, 'grad_norm': 11.507824897766113, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.010000105947256088, 'loss_2': 0.0009412765502929688, 'loss_3': -16.368789672851562, 'loss_4': 0.026783619076013565, 'epoch': 26.39}
{'loss': 0.0077, 'grad_norm': 5.046633243560791, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.005322595126926899, 'loss_2': 0.0023746490478515625, 'loss_3': -16.38270378112793, 'loss_4': -0.23956188559532166, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 17:09:11,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:11,276 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:52:05<10:48,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:09:18,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01389606948941946, 'eval_runtime': 4.0, 'eval_samples_per_second': 256.003, 'eval_steps_per_second': 4.0, 'eval_loss_1': 0.009506038390100002, 'eval_loss_2': 0.004390031099319458, 'eval_loss_3': -18.1464900970459, 'eval_loss_4': -0.12303879857063293, 'epoch': 26.4}
{'loss': 0.0111, 'grad_norm': 4.751172065734863, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.0029246557969599962, 'loss_2': 0.0081634521484375, 'loss_3': -16.42021369934082, 'loss_4': -0.2384725958108902, 'epoch': 26.4}
{'loss': 0.0082, 'grad_norm': 6.020048141479492, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.006304953247308731, 'loss_2': 0.0019378662109375, 'loss_3': -16.296218872070312, 'loss_4': -0.14578571915626526, 'epoch': 26.41}
{'loss': 0.0125, 'grad_norm': 6.9455037117004395, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.010010394267737865, 'loss_2': 0.002490997314453125, 'loss_3': -16.419485092163086, 'loss_4': -0.055744562298059464, 'epoch': 26.41}
{'loss': 0.0201, 'grad_norm': 7.9662861824035645, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.015355212613940239, 'loss_2': 0.00469970703125, 'loss_3': -16.471750259399414, 'loss_4': 0.09697243571281433, 'epoch': 26.42}
{'loss': 0.0042, 'grad_norm': 4.580287456512451, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.0023652762174606323, 'loss_2': 0.0018281936645507812, 'loss_3': -16.309614181518555, 'loss_4': -0.0916348397731781, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 17:09:18,833 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:18,833 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:52:12<10:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:26,204 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014225882478058338, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.312, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.009322536177933216, 'eval_loss_2': 0.004903346300125122, 'eval_loss_3': -18.14788055419922, 'eval_loss_4': -0.1601908951997757, 'epoch': 26.42}
{'loss': 0.0166, 'grad_norm': 9.785172462463379, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.011343427002429962, 'loss_2': 0.0052490234375, 'loss_3': -16.518306732177734, 'loss_4': -0.15427665412425995, 'epoch': 26.43}
{'loss': 0.0134, 'grad_norm': 4.671633720397949, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.003323466284200549, 'loss_2': 0.0101165771484375, 'loss_3': -16.317501068115234, 'loss_4': -0.14989247918128967, 'epoch': 26.44}
{'loss': 0.0146, 'grad_norm': 6.81915807723999, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.010462327860295773, 'loss_2': 0.004169464111328125, 'loss_3': -16.553190231323242, 'loss_4': -0.21922314167022705, 'epoch': 26.44}
{'loss': 0.0075, 'grad_norm': 5.255366325378418, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.004393515642732382, 'loss_2': 0.00308990478515625, 'loss_3': -16.50541877746582, 'loss_4': -0.10971181094646454, 'epoch': 26.45}
{'loss': 0.0039, 'grad_norm': 4.856068134307861, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.0019374183611944318, 'loss_2': 0.0019207000732421875, 'loss_3': -16.405105590820312, 'loss_4': -0.3048911690711975, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 17:09:26,204 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:26,204 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:20<10:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:33,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013575227931141853, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.964, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009550097398459911, 'eval_loss_2': 0.004025131464004517, 'eval_loss_3': -18.143735885620117, 'eval_loss_4': -0.21746399998664856, 'epoch': 26.45}
{'loss': 0.0039, 'grad_norm': 4.54163122177124, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.002400205470621586, 'loss_2': 0.001537322998046875, 'loss_3': -16.416284561157227, 'loss_4': 0.05263589322566986, 'epoch': 26.46}
{'loss': 0.0052, 'grad_norm': 4.737441539764404, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.004421094432473183, 'loss_2': 0.000766754150390625, 'loss_3': -16.44501495361328, 'loss_4': -0.2284073829650879, 'epoch': 26.47}
{'loss': 0.0068, 'grad_norm': 4.961340427398682, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.005085887387394905, 'loss_2': 0.0017375946044921875, 'loss_3': -16.39779281616211, 'loss_4': -0.1302095502614975, 'epoch': 26.47}
{'loss': 0.0096, 'grad_norm': 4.810563087463379, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0038641178980469704, 'loss_2': 0.00574493408203125, 'loss_3': -16.381696701049805, 'loss_4': -0.2454725056886673, 'epoch': 26.48}
{'loss': 0.0102, 'grad_norm': 7.3614959716796875, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.008526019752025604, 'loss_2': 0.001708984375, 'loss_3': -16.181838989257812, 'loss_4': -0.1717797815799713, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 17:09:33,564 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:33,564 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:27<10:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:40,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012896044179797173, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.691, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00952904112637043, 'eval_loss_2': 0.0033670030534267426, 'eval_loss_3': -18.14110565185547, 'eval_loss_4': -0.2706100046634674, 'epoch': 26.48}
{'loss': 0.0111, 'grad_norm': 4.6146626472473145, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.00634572422131896, 'loss_2': 0.004730224609375, 'loss_3': -16.39855194091797, 'loss_4': -0.925783097743988, 'epoch': 26.49}
{'loss': 0.0091, 'grad_norm': 4.281282424926758, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.0035529271699488163, 'loss_2': 0.00556182861328125, 'loss_3': -16.717069625854492, 'loss_4': 0.19897866249084473, 'epoch': 26.49}
{'loss': 0.0103, 'grad_norm': 4.765517234802246, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.005435593891888857, 'loss_2': 0.0048980712890625, 'loss_3': -16.414392471313477, 'loss_4': -0.38086754083633423, 'epoch': 26.5}
{'loss': 0.011, 'grad_norm': 5.263485431671143, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.009422047063708305, 'loss_2': 0.0016231536865234375, 'loss_3': -16.503440856933594, 'loss_4': -0.09165339171886444, 'epoch': 26.51}
{'loss': 0.0031, 'grad_norm': 4.381470203399658, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.0024169699754565954, 'loss_2': 0.0006699562072753906, 'loss_3': -16.39897918701172, 'loss_4': -0.27150681614875793, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 17:09:40,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:40,918 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:34<10:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:48,282 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013212615624070168, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.716, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009629303589463234, 'eval_loss_2': 0.0035833120346069336, 'eval_loss_3': -18.133329391479492, 'eval_loss_4': -0.27293530106544495, 'epoch': 26.51}
{'loss': 0.0126, 'grad_norm': 5.359838008880615, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.005551451817154884, 'loss_2': 0.00701904296875, 'loss_3': -16.47566795349121, 'loss_4': -0.45321446657180786, 'epoch': 26.52}
{'loss': 0.0124, 'grad_norm': 5.519741535186768, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.008364351466298103, 'loss_2': 0.004032135009765625, 'loss_3': -16.3957462310791, 'loss_4': 0.15586884319782257, 'epoch': 26.52}
{'loss': 0.0097, 'grad_norm': 4.971032619476318, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.007142610847949982, 'loss_2': 0.002597808837890625, 'loss_3': -16.53201675415039, 'loss_4': -0.6649293899536133, 'epoch': 26.53}
{'loss': 0.0071, 'grad_norm': 5.211850166320801, 'learning_rate': 3.5e-06, 'loss_1': 0.007041738834232092, 'loss_2': 1.0669231414794922e-05, 'loss_3': -16.3502197265625, 'loss_4': -0.35032957792282104, 'epoch': 26.53}
{'loss': 0.0046, 'grad_norm': 4.876834869384766, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.003966240677982569, 'loss_2': 0.0006537437438964844, 'loss_3': -16.605806350708008, 'loss_4': 0.052052050828933716, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 17:09:48,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:48,282 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:42<10:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:09:55,645 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013236820697784424, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.593, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009624116122722626, 'eval_loss_2': 0.003612704575061798, 'eval_loss_3': -18.12970542907715, 'eval_loss_4': -0.2788867950439453, 'epoch': 26.54}
{'loss': 0.0036, 'grad_norm': 4.814551830291748, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.001998923486098647, 'loss_2': 0.00156402587890625, 'loss_3': -16.416038513183594, 'loss_4': -0.3467446565628052, 'epoch': 26.55}
{'loss': 0.0107, 'grad_norm': 4.445186138153076, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.006232156418263912, 'loss_2': 0.004425048828125, 'loss_3': -16.3192081451416, 'loss_4': 0.05444330722093582, 'epoch': 26.55}
{'loss': 0.0132, 'grad_norm': 7.730992317199707, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.012450181879103184, 'loss_2': 0.0007562637329101562, 'loss_3': -16.416549682617188, 'loss_4': -0.1656109094619751, 'epoch': 26.56}
{'loss': 0.0069, 'grad_norm': 5.631352424621582, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.004245534539222717, 'loss_2': 0.0026798248291015625, 'loss_3': -16.387319564819336, 'loss_4': -0.35636910796165466, 'epoch': 26.56}
{'loss': 0.0091, 'grad_norm': 4.628047466278076, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.0058904909528791904, 'loss_2': 0.0032215118408203125, 'loss_3': -16.535545349121094, 'loss_4': -0.031393975019454956, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 17:09:55,645 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:09:55,645 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:52:49<10:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:03,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013341797515749931, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.249, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.009764223359525204, 'eval_loss_2': 0.0035775750875473022, 'eval_loss_3': -18.139728546142578, 'eval_loss_4': -0.2723928987979889, 'epoch': 26.57}
{'loss': 0.0066, 'grad_norm': 4.873950004577637, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.0033368379808962345, 'loss_2': 0.0032405853271484375, 'loss_3': -16.625455856323242, 'loss_4': -0.6671957969665527, 'epoch': 26.58}
{'loss': 0.0201, 'grad_norm': 7.854423999786377, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.012734383344650269, 'loss_2': 0.00737762451171875, 'loss_3': -16.610450744628906, 'loss_4': -0.06646442413330078, 'epoch': 26.58}
{'loss': 0.0053, 'grad_norm': 5.555913925170898, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.004024202935397625, 'loss_2': 0.00125885009765625, 'loss_3': -16.279048919677734, 'loss_4': -0.050284773111343384, 'epoch': 26.59}
{'loss': 0.0224, 'grad_norm': 7.326597690582275, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.019320299848914146, 'loss_2': 0.0030536651611328125, 'loss_3': -16.38589859008789, 'loss_4': -0.33279603719711304, 'epoch': 26.59}
{'loss': 0.0099, 'grad_norm': 5.404957294464111, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.006706359330564737, 'loss_2': 0.0031642913818359375, 'loss_3': -16.399707794189453, 'loss_4': -0.3930027186870575, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 17:10:03,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:03,007 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:52:56<10:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:10,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013538316823542118, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.021, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00956246443092823, 'eval_loss_2': 0.003975853323936462, 'eval_loss_3': -18.141700744628906, 'eval_loss_4': -0.26214733719825745, 'epoch': 26.6}
{'loss': 0.0042, 'grad_norm': 5.645509719848633, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.003754945704713464, 'loss_2': 0.00046324729919433594, 'loss_3': -16.44789695739746, 'loss_4': -0.3927942216396332, 'epoch': 26.6}
{'loss': 0.0159, 'grad_norm': 4.989676475524902, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.00523762870579958, 'loss_2': 0.0106201171875, 'loss_3': -16.33118438720703, 'loss_4': -0.29103851318359375, 'epoch': 26.61}
{'loss': 0.0076, 'grad_norm': 4.9970245361328125, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.005371575243771076, 'loss_2': 0.002197265625, 'loss_3': -16.341337203979492, 'loss_4': -0.4311184883117676, 'epoch': 26.62}
{'loss': 0.0152, 'grad_norm': 5.178096771240234, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.007563621737062931, 'loss_2': 0.0076446533203125, 'loss_3': -16.44770050048828, 'loss_4': -0.6772376298904419, 'epoch': 26.62}
{'loss': 0.0073, 'grad_norm': 31.494503021240234, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.004051562398672104, 'loss_2': 0.0032196044921875, 'loss_3': -16.382417678833008, 'loss_4': -0.3335447311401367, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 17:10:10,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:10,351 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:53:04<09:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:17,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014063101261854172, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.42, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.009314876049757004, 'eval_loss_2': 0.004748225212097168, 'eval_loss_3': -18.14399528503418, 'eval_loss_4': -0.22672805190086365, 'epoch': 26.63}
{'loss': 0.006, 'grad_norm': 4.525917053222656, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.002338023856282234, 'loss_2': 0.003665924072265625, 'loss_3': -16.36777114868164, 'loss_4': -0.3813745975494385, 'epoch': 26.63}
{'loss': 0.0051, 'grad_norm': 8.08322811126709, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.0031873721163719893, 'loss_2': 0.0018978118896484375, 'loss_3': -16.5386962890625, 'loss_4': -0.08853594958782196, 'epoch': 26.64}
{'loss': 0.0131, 'grad_norm': 4.8888702392578125, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.00531058618798852, 'loss_2': 0.0078125, 'loss_3': -16.190351486206055, 'loss_4': -0.21972796320915222, 'epoch': 26.65}
{'loss': 0.0097, 'grad_norm': 6.4454522132873535, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.009632401168346405, 'loss_2': 6.186962127685547e-05, 'loss_3': -16.285974502563477, 'loss_4': -0.409908652305603, 'epoch': 26.65}
{'loss': 0.0093, 'grad_norm': 5.193575859069824, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.008509608916938305, 'loss_2': 0.0007724761962890625, 'loss_3': -16.512704849243164, 'loss_4': -0.5272682905197144, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 17:10:17,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:17,694 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:53:11<09:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:25,044 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01428104005753994, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009235209785401821, 'eval_loss_2': 0.005045831203460693, 'eval_loss_3': -18.13713264465332, 'eval_loss_4': -0.18255293369293213, 'epoch': 26.66}
{'loss': 0.0077, 'grad_norm': 4.676917552947998, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.005334513261914253, 'loss_2': 0.0023956298828125, 'loss_3': -16.58077621459961, 'loss_4': 0.2687026858329773, 'epoch': 26.66}
{'loss': 0.0154, 'grad_norm': 7.357034683227539, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.006998185999691486, 'loss_2': 0.0084228515625, 'loss_3': -16.24476432800293, 'loss_4': -0.0486999973654747, 'epoch': 26.67}
{'loss': 0.0044, 'grad_norm': 4.690203666687012, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.002928453730419278, 'loss_2': 0.0015192031860351562, 'loss_3': -16.50537109375, 'loss_4': -0.044577255845069885, 'epoch': 26.67}
{'loss': 0.0086, 'grad_norm': 5.028748989105225, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.003263362916186452, 'loss_2': 0.00530242919921875, 'loss_3': -16.477142333984375, 'loss_4': -0.03856833279132843, 'epoch': 26.68}
{'loss': 0.007, 'grad_norm': 17.71329689025879, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.0061800917610526085, 'loss_2': 0.0008015632629394531, 'loss_3': -16.610370635986328, 'loss_4': -0.21565517783164978, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 17:10:25,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:25,044 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:18<09:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:32,399 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013437701389193535, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.259, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009362949058413506, 'eval_loss_2': 0.004074752330780029, 'eval_loss_3': -18.136173248291016, 'eval_loss_4': -0.15907984972000122, 'epoch': 26.69}
{'loss': 0.0055, 'grad_norm': 5.059500694274902, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.004866104107350111, 'loss_2': 0.000621795654296875, 'loss_3': -16.418289184570312, 'loss_4': -0.3480818271636963, 'epoch': 26.69}
{'loss': 0.0126, 'grad_norm': 5.8362226486206055, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.00718892365694046, 'loss_2': 0.00542449951171875, 'loss_3': -16.489511489868164, 'loss_4': -0.5727065801620483, 'epoch': 26.7}
{'loss': 0.0222, 'grad_norm': 12.361675262451172, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.019188618287444115, 'loss_2': 0.003002166748046875, 'loss_3': -16.35703468322754, 'loss_4': -0.0007012262940406799, 'epoch': 26.7}
{'loss': 0.0123, 'grad_norm': 6.075007438659668, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.011080002412199974, 'loss_2': 0.001171112060546875, 'loss_3': -16.583587646484375, 'loss_4': -0.47028905153274536, 'epoch': 26.71}
{'loss': 0.0092, 'grad_norm': 4.938070774078369, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.006091131828725338, 'loss_2': 0.003116607666015625, 'loss_3': -16.38770866394043, 'loss_4': -0.5275448560714722, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 17:10:32,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:32,399 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:26<09:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:39,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012569825164973736, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009283999912440777, 'eval_loss_2': 0.003285825252532959, 'eval_loss_3': -18.141605377197266, 'eval_loss_4': -0.1716056615114212, 'epoch': 26.72}
{'loss': 0.0061, 'grad_norm': 5.062320232391357, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.004033410921692848, 'loss_2': 0.002109527587890625, 'loss_3': -16.218032836914062, 'loss_4': -0.028447136282920837, 'epoch': 26.72}
{'loss': 0.0062, 'grad_norm': 4.814253330230713, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.005540155805647373, 'loss_2': 0.0006456375122070312, 'loss_3': -16.28451156616211, 'loss_4': -0.19302479922771454, 'epoch': 26.73}
{'loss': 0.0085, 'grad_norm': 4.833959579467773, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.003954629879444838, 'loss_2': 0.00455474853515625, 'loss_3': -16.492328643798828, 'loss_4': -0.03202281892299652, 'epoch': 26.73}
{'loss': 0.0052, 'grad_norm': 5.095747470855713, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.0035051300656050444, 'loss_2': 0.0016689300537109375, 'loss_3': -16.472698211669922, 'loss_4': 0.1748702973127365, 'epoch': 26.74}
{'loss': 0.0117, 'grad_norm': 5.31118631362915, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.006338909734040499, 'loss_2': 0.00537872314453125, 'loss_3': -16.22144889831543, 'loss_4': 0.26341015100479126, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 17:10:39,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:39,749 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:33<09:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:47,100 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012351380661129951, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.809, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009533877484500408, 'eval_loss_2': 0.002817504107952118, 'eval_loss_3': -18.14885902404785, 'eval_loss_4': -0.17320242524147034, 'epoch': 26.74}
{'loss': 0.0119, 'grad_norm': 8.69690990447998, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.011883295141160488, 'loss_2': 1.3649463653564453e-05, 'loss_3': -16.36798858642578, 'loss_4': -0.044382765889167786, 'epoch': 26.75}
{'loss': 0.0074, 'grad_norm': 4.63621187210083, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.0017415648326277733, 'loss_2': 0.005626678466796875, 'loss_3': -16.6495418548584, 'loss_4': 0.0731687843799591, 'epoch': 26.76}
{'loss': 0.0072, 'grad_norm': 4.748053550720215, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.004990090616047382, 'loss_2': 0.00217437744140625, 'loss_3': -16.508464813232422, 'loss_4': 0.32417064905166626, 'epoch': 26.76}
{'loss': 0.0071, 'grad_norm': 5.152122974395752, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.0042061279527843, 'loss_2': 0.00286865234375, 'loss_3': -16.237884521484375, 'loss_4': -0.3748606741428375, 'epoch': 26.77}
{'loss': 0.004, 'grad_norm': 4.447685241699219, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.003042674856260419, 'loss_2': 0.0009860992431640625, 'loss_3': -16.423593521118164, 'loss_4': -0.17960210144519806, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 17:10:47,100 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:47,100 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:41<09:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:10:54,450 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012720738537609577, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.083, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009788265451788902, 'eval_loss_2': 0.0029324740171432495, 'eval_loss_3': -18.15709686279297, 'eval_loss_4': -0.14574965834617615, 'epoch': 26.77}
{'loss': 0.013, 'grad_norm': 5.546498775482178, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.006189135834574699, 'loss_2': 0.00684356689453125, 'loss_3': -16.29496955871582, 'loss_4': 0.08551792800426483, 'epoch': 26.78}
{'loss': 0.0106, 'grad_norm': 4.578256130218506, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.0031292412895709276, 'loss_2': 0.007450103759765625, 'loss_3': -16.398075103759766, 'loss_4': -0.5015825033187866, 'epoch': 26.78}
{'loss': 0.0079, 'grad_norm': 5.841031074523926, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.005671934690326452, 'loss_2': 0.002246856689453125, 'loss_3': -16.551362991333008, 'loss_4': -0.1569444090127945, 'epoch': 26.79}
{'loss': 0.0047, 'grad_norm': 4.617208957672119, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.0045487117022275925, 'loss_2': 0.00011676549911499023, 'loss_3': -16.39732551574707, 'loss_4': -0.20415939390659332, 'epoch': 26.8}
{'loss': 0.0101, 'grad_norm': 5.076592922210693, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.004079820122569799, 'loss_2': 0.006031036376953125, 'loss_3': -16.44171142578125, 'loss_4': -0.2564302086830139, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 17:10:54,450 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:10:54,450 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:53:48<09:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:01,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012740612030029297, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.416, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00995897501707077, 'eval_loss_2': 0.0027816370129585266, 'eval_loss_3': -18.158098220825195, 'eval_loss_4': -0.12435120344161987, 'epoch': 26.8}
{'loss': 0.0107, 'grad_norm': 5.399765491485596, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.007990894839167595, 'loss_2': 0.002666473388671875, 'loss_3': -16.615028381347656, 'loss_4': -0.16575878858566284, 'epoch': 26.81}
{'loss': 0.0066, 'grad_norm': 5.447375297546387, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.006197942886501551, 'loss_2': 0.00043582916259765625, 'loss_3': -16.202220916748047, 'loss_4': -0.07504100352525711, 'epoch': 26.81}
{'loss': 0.0063, 'grad_norm': 4.485335826873779, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.004213927313685417, 'loss_2': 0.0021038055419921875, 'loss_3': -16.33399772644043, 'loss_4': -0.19404494762420654, 'epoch': 26.82}
{'loss': 0.0132, 'grad_norm': 10.387035369873047, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.01249273493885994, 'loss_2': 0.0006999969482421875, 'loss_3': -16.440807342529297, 'loss_4': -0.4244841933250427, 'epoch': 26.83}
{'loss': 0.0039, 'grad_norm': 4.65976095199585, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.0024123964831233025, 'loss_2': 0.0015239715576171875, 'loss_3': -16.431941986083984, 'loss_4': -0.43985047936439514, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 17:11:01,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:01,793 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:53:55<09:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:09,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012191830202937126, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.167, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00948567595332861, 'eval_loss_2': 0.0027061551809310913, 'eval_loss_3': -18.16206169128418, 'eval_loss_4': -0.09913991391658783, 'epoch': 26.83}
{'loss': 0.0067, 'grad_norm': 5.056734561920166, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.004630313720554113, 'loss_2': 0.002063751220703125, 'loss_3': -16.539798736572266, 'loss_4': -0.20941677689552307, 'epoch': 26.84}
{'loss': 0.0078, 'grad_norm': 5.107266902923584, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.0024079326540231705, 'loss_2': 0.00543975830078125, 'loss_3': -16.42793846130371, 'loss_4': 0.16850252449512482, 'epoch': 26.84}
{'loss': 0.0082, 'grad_norm': 5.558308124542236, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.004798161797225475, 'loss_2': 0.003421783447265625, 'loss_3': -16.318517684936523, 'loss_4': -0.24785000085830688, 'epoch': 26.85}
{'loss': 0.0047, 'grad_norm': 5.599015712738037, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.0030782108660787344, 'loss_2': 0.0016613006591796875, 'loss_3': -16.31740379333496, 'loss_4': -0.06327743828296661, 'epoch': 26.85}
{'loss': 0.0072, 'grad_norm': 5.175678730010986, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.007004843559116125, 'loss_2': 0.000209808349609375, 'loss_3': -16.31621551513672, 'loss_4': -0.19607694447040558, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 17:11:09,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:09,138 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:54:03<09:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:16,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012481589801609516, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00925086997449398, 'eval_loss_2': 0.0032307207584381104, 'eval_loss_3': -18.156455993652344, 'eval_loss_4': -0.04060488939285278, 'epoch': 26.86}
{'loss': 0.015, 'grad_norm': 5.05225944519043, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.006479584611952305, 'loss_2': 0.00852203369140625, 'loss_3': -16.398948669433594, 'loss_4': -0.14620056748390198, 'epoch': 26.87}
{'loss': 0.013, 'grad_norm': 6.586029529571533, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.010298892855644226, 'loss_2': 0.00272369384765625, 'loss_3': -16.278545379638672, 'loss_4': 0.4980924427509308, 'epoch': 26.87}
{'loss': 0.017, 'grad_norm': 8.895392417907715, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.013339054770767689, 'loss_2': 0.0036411285400390625, 'loss_3': -16.33709144592285, 'loss_4': -0.23437146842479706, 'epoch': 26.88}
{'loss': 0.0053, 'grad_norm': 5.610870361328125, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.005274154245853424, 'loss_2': 5.53131103515625e-05, 'loss_3': -16.36423110961914, 'loss_4': 0.1724180430173874, 'epoch': 26.88}
{'loss': 0.0234, 'grad_norm': 10.828283309936523, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.02152307704091072, 'loss_2': 0.00191497802734375, 'loss_3': -16.381282806396484, 'loss_4': 0.3090320825576782, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 17:11:16,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:16,488 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:54:10<09:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:23,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012913025915622711, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009365811944007874, 'eval_loss_2': 0.0035472139716148376, 'eval_loss_3': -18.151430130004883, 'eval_loss_4': 0.007772587239742279, 'epoch': 26.89}
{'loss': 0.011, 'grad_norm': 4.99704122543335, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.00706289941444993, 'loss_2': 0.003936767578125, 'loss_3': -16.372108459472656, 'loss_4': 0.6671969890594482, 'epoch': 26.9}
{'loss': 0.0051, 'grad_norm': 4.507972717285156, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.004672347102314234, 'loss_2': 0.0004010200500488281, 'loss_3': -16.184932708740234, 'loss_4': 0.2997063398361206, 'epoch': 26.9}
{'loss': 0.008, 'grad_norm': 4.935251235961914, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.003349224803969264, 'loss_2': 0.00469207763671875, 'loss_3': -16.278654098510742, 'loss_4': 0.22730717062950134, 'epoch': 26.91}
{'loss': 0.0084, 'grad_norm': 4.803545951843262, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.006650534924119711, 'loss_2': 0.00176239013671875, 'loss_3': -16.38286781311035, 'loss_4': -0.0744747668504715, 'epoch': 26.91}
{'loss': 0.0063, 'grad_norm': 5.036486625671387, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.002308696275576949, 'loss_2': 0.004009246826171875, 'loss_3': -16.523529052734375, 'loss_4': 0.050231389701366425, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 17:11:23,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:23,839 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:54:17<09:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:31,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01333664357662201, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.974, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00949834194034338, 'eval_loss_2': 0.0038383007049560547, 'eval_loss_3': -18.149200439453125, 'eval_loss_4': 0.04581892862915993, 'epoch': 26.92}
{'loss': 0.0106, 'grad_norm': 5.315495014190674, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.004013686440885067, 'loss_2': 0.006561279296875, 'loss_3': -16.203527450561523, 'loss_4': -0.40717336535453796, 'epoch': 26.92}
{'loss': 0.0114, 'grad_norm': 5.573816299438477, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.006713485345244408, 'loss_2': 0.004665374755859375, 'loss_3': -16.239788055419922, 'loss_4': 0.07482439279556274, 'epoch': 26.93}
{'loss': 0.0035, 'grad_norm': 5.090165615081787, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.0035413105506449938, 'loss_2': 7.271766662597656e-06, 'loss_3': -16.28067398071289, 'loss_4': 0.1787792444229126, 'epoch': 26.94}
{'loss': 0.0078, 'grad_norm': 5.017377853393555, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.002581152832135558, 'loss_2': 0.005252838134765625, 'loss_3': -16.56114387512207, 'loss_4': -0.12635403871536255, 'epoch': 26.94}
{'loss': 0.0236, 'grad_norm': 14.46117115020752, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.020445842295885086, 'loss_2': 0.0031566619873046875, 'loss_3': -16.241212844848633, 'loss_4': -0.22800537943840027, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 17:11:31,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:31,190 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:25<09:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:11:38,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01387973502278328, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.242, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009598935954272747, 'eval_loss_2': 0.004280798137187958, 'eval_loss_3': -18.14586639404297, 'eval_loss_4': 0.05643957480788231, 'epoch': 26.95}
{'loss': 0.007, 'grad_norm': 5.8061723709106445, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.0064894063398242, 'loss_2': 0.0004687309265136719, 'loss_3': -16.4328670501709, 'loss_4': 0.15934701263904572, 'epoch': 26.95}
{'loss': 0.0093, 'grad_norm': 6.887887001037598, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.007218163460493088, 'loss_2': 0.00211334228515625, 'loss_3': -16.415754318237305, 'loss_4': 0.621569812297821, 'epoch': 26.96}
{'loss': 0.009, 'grad_norm': 5.390515327453613, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.00572371669113636, 'loss_2': 0.0032806396484375, 'loss_3': -16.392467498779297, 'loss_4': 0.1886417716741562, 'epoch': 26.97}
{'loss': 0.0094, 'grad_norm': 7.05814790725708, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.008933991193771362, 'loss_2': 0.0005106925964355469, 'loss_3': -16.365211486816406, 'loss_4': -0.19215640425682068, 'epoch': 26.97}
{'loss': 0.016, 'grad_norm': 11.787385940551758, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.01246990729123354, 'loss_2': 0.003509521484375, 'loss_3': -16.26464080810547, 'loss_4': 0.44873595237731934, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 17:11:38,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:38,538 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:32<08:23,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 17:11:45,572 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014570672065019608, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009964704513549805, 'eval_loss_2': 0.004605967551469803, 'eval_loss_3': -18.140995025634766, 'eval_loss_4': 0.0906265377998352, 'epoch': 26.98}
{'loss': 0.0076, 'grad_norm': 5.292929649353027, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.007151973433792591, 'loss_2': 0.00045108795166015625, 'loss_3': -16.56724739074707, 'loss_4': 0.27227070927619934, 'epoch': 26.98}
{'loss': 0.0125, 'grad_norm': 5.119758129119873, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.007983802817761898, 'loss_2': 0.00447845458984375, 'loss_3': -16.248796463012695, 'loss_4': 0.6154345870018005, 'epoch': 26.99}
{'loss': 0.0081, 'grad_norm': 5.050522327423096, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.00378855736926198, 'loss_2': 0.0042724609375, 'loss_3': -16.34756851196289, 'loss_4': 0.590080976486206, 'epoch': 26.99}
{'loss': 0.0079, 'grad_norm': 6.753856182098389, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0019501259084790945, 'loss_2': 0.005931854248046875, 'loss_3': -16.346445083618164, 'loss_4': 0.361661821603775, 'epoch': 27.0}
{'loss': 0.0068, 'grad_norm': 4.667821407318115, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.00550718791782856, 'loss_2': 0.0012722015380859375, 'loss_3': -16.327762603759766, 'loss_4': 0.8236657381057739, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 17:11:45,572 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:45,572 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:39<08:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:11:52,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014109235256910324, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00980548094958067, 'eval_loss_2': 0.00430375337600708, 'eval_loss_3': -18.145069122314453, 'eval_loss_4': 0.10878675431013107, 'epoch': 27.01}
{'loss': 0.0082, 'grad_norm': 4.85361385345459, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.004925781860947609, 'loss_2': 0.003299713134765625, 'loss_3': -16.452388763427734, 'loss_4': 0.24480561912059784, 'epoch': 27.01}
{'loss': 0.006, 'grad_norm': 4.839268684387207, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.001823564525693655, 'loss_2': 0.004180908203125, 'loss_3': -16.524524688720703, 'loss_4': 0.21795271337032318, 'epoch': 27.02}
{'loss': 0.004, 'grad_norm': 4.645691394805908, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.003125634277239442, 'loss_2': 0.0008983612060546875, 'loss_3': -16.40531349182129, 'loss_4': 0.2936432957649231, 'epoch': 27.02}
{'loss': 0.0103, 'grad_norm': 6.191080570220947, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.008056354708969593, 'loss_2': 0.0022125244140625, 'loss_3': -16.489032745361328, 'loss_4': 0.11860345304012299, 'epoch': 27.03}
{'loss': 0.0149, 'grad_norm': 6.599018096923828, 'learning_rate': 3e-06, 'loss_1': 0.008188779465854168, 'loss_2': 0.0067138671875, 'loss_3': -16.29569435119629, 'loss_4': 0.10155683010816574, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 17:11:52,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:11:52,923 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:54:46<08:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:00,284 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01364569179713726, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.452, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009728742763400078, 'eval_loss_2': 0.003916949033737183, 'eval_loss_3': -18.143253326416016, 'eval_loss_4': 0.14707699418067932, 'epoch': 27.03}
{'loss': 0.0086, 'grad_norm': 4.318546295166016, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.0050020948983728886, 'loss_2': 0.0035858154296875, 'loss_3': -16.397611618041992, 'loss_4': 0.3380715250968933, 'epoch': 27.04}
{'loss': 0.0085, 'grad_norm': 4.633574485778809, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.003522933227941394, 'loss_2': 0.004974365234375, 'loss_3': -16.454326629638672, 'loss_4': 0.3236950635910034, 'epoch': 27.05}
{'loss': 0.0072, 'grad_norm': 5.7607879638671875, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.0070473309606313705, 'loss_2': 0.00010502338409423828, 'loss_3': -16.464780807495117, 'loss_4': 0.714888334274292, 'epoch': 27.05}
{'loss': 0.0223, 'grad_norm': 9.674430847167969, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.018420927226543427, 'loss_2': 0.00385284423828125, 'loss_3': -16.307140350341797, 'loss_4': -0.24128226935863495, 'epoch': 27.06}
{'loss': 0.0069, 'grad_norm': 5.142340183258057, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.00439446559175849, 'loss_2': 0.0025348663330078125, 'loss_3': -16.62460708618164, 'loss_4': 0.18961180746555328, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 17:12:00,284 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:00,284 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:54:54<08:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:07,632 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01367311179637909, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.024, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009893104434013367, 'eval_loss_2': 0.0037800073623657227, 'eval_loss_3': -18.137676239013672, 'eval_loss_4': 0.1829802393913269, 'epoch': 27.06}
{'loss': 0.008, 'grad_norm': 4.950870037078857, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.006010986398905516, 'loss_2': 0.0019779205322265625, 'loss_3': -16.34514617919922, 'loss_4': 0.36398255825042725, 'epoch': 27.07}
{'loss': 0.0088, 'grad_norm': 4.843628883361816, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.003289304208010435, 'loss_2': 0.005474090576171875, 'loss_3': -16.28752326965332, 'loss_4': 0.45041853189468384, 'epoch': 27.08}
{'loss': 0.0155, 'grad_norm': 9.875799179077148, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.01074370089918375, 'loss_2': 0.00478363037109375, 'loss_3': -16.20207977294922, 'loss_4': 0.16515852510929108, 'epoch': 27.08}
{'loss': 0.0119, 'grad_norm': 4.517385005950928, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.004361750092357397, 'loss_2': 0.0075531005859375, 'loss_3': -16.43100357055664, 'loss_4': 0.2843986749649048, 'epoch': 27.09}
{'loss': 0.008, 'grad_norm': 7.547872066497803, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.007304410915821791, 'loss_2': 0.0006914138793945312, 'loss_3': -16.405492782592773, 'loss_4': 0.3702337443828583, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 17:12:07,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:07,633 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:55:01<08:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:14,974 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01402317639440298, 'eval_runtime': 3.8026, 'eval_samples_per_second': 269.29, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010373793542385101, 'eval_loss_2': 0.003649383783340454, 'eval_loss_3': -18.13896369934082, 'eval_loss_4': 0.20182931423187256, 'epoch': 27.09}
{'loss': 0.0168, 'grad_norm': 5.050803184509277, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.008134366944432259, 'loss_2': 0.00865936279296875, 'loss_3': -16.431724548339844, 'loss_4': -0.21021032333374023, 'epoch': 27.1}
{'loss': 0.0103, 'grad_norm': 5.775831699371338, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.008803981356322765, 'loss_2': 0.0015420913696289062, 'loss_3': -16.573951721191406, 'loss_4': -0.013532906770706177, 'epoch': 27.1}
{'loss': 0.0089, 'grad_norm': 5.066512107849121, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.005661321803927422, 'loss_2': 0.00325775146484375, 'loss_3': -16.31243133544922, 'loss_4': 0.1946188360452652, 'epoch': 27.11}
{'loss': 0.008, 'grad_norm': 5.130350589752197, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.00405555684119463, 'loss_2': 0.0039825439453125, 'loss_3': -16.17123794555664, 'loss_4': 0.36511388421058655, 'epoch': 27.12}
{'loss': 0.0113, 'grad_norm': 5.386728286743164, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.0030475028324872255, 'loss_2': 0.0082855224609375, 'loss_3': -16.366214752197266, 'loss_4': 0.06527966260910034, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 17:12:14,974 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:14,974 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:55:08<08:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:22,319 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013177210465073586, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009944046847522259, 'eval_loss_2': 0.0032331645488739014, 'eval_loss_3': -18.135780334472656, 'eval_loss_4': 0.16529390215873718, 'epoch': 27.12}
{'loss': 0.0077, 'grad_norm': 4.898319244384766, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.005174600053578615, 'loss_2': 0.0024852752685546875, 'loss_3': -16.551057815551758, 'loss_4': 0.27584612369537354, 'epoch': 27.13}
{'loss': 0.011, 'grad_norm': 4.318782329559326, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.003723831381648779, 'loss_2': 0.00724029541015625, 'loss_3': -16.355640411376953, 'loss_4': 0.24249112606048584, 'epoch': 27.13}
{'loss': 0.0123, 'grad_norm': 5.128459930419922, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.005619311239570379, 'loss_2': 0.0067291259765625, 'loss_3': -16.29111099243164, 'loss_4': 0.2902181148529053, 'epoch': 27.14}
{'loss': 0.0102, 'grad_norm': 7.4174723625183105, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.009555348195135593, 'loss_2': 0.0006618499755859375, 'loss_3': -16.28019905090332, 'loss_4': -0.22524751722812653, 'epoch': 27.15}
{'loss': 0.0146, 'grad_norm': 8.331560134887695, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.012982139363884926, 'loss_2': 0.0016012191772460938, 'loss_3': -16.313175201416016, 'loss_4': 0.10126793384552002, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 17:12:22,319 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:22,320 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:55:16<08:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:29,661 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0127842016518116, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.347, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009991604834794998, 'eval_loss_2': 0.0027925968170166016, 'eval_loss_3': -18.126846313476562, 'eval_loss_4': 0.09496280550956726, 'epoch': 27.15}
{'loss': 0.0082, 'grad_norm': 5.475180149078369, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.0062950081191957, 'loss_2': 0.001941680908203125, 'loss_3': -16.4731388092041, 'loss_4': -0.10007844865322113, 'epoch': 27.16}
{'loss': 0.007, 'grad_norm': 5.126864433288574, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.005624779965728521, 'loss_2': 0.0013866424560546875, 'loss_3': -16.2965145111084, 'loss_4': 0.3199331760406494, 'epoch': 27.16}
{'loss': 0.0094, 'grad_norm': 6.01332426071167, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.006124773528426886, 'loss_2': 0.003276824951171875, 'loss_3': -16.538009643554688, 'loss_4': 0.35789725184440613, 'epoch': 27.17}
{'loss': 0.034, 'grad_norm': 14.224018096923828, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.027169570326805115, 'loss_2': 0.0067901611328125, 'loss_3': -16.41278839111328, 'loss_4': 0.19046743214130402, 'epoch': 27.17}
{'loss': 0.0051, 'grad_norm': 4.523573875427246, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.0028973971493542194, 'loss_2': 0.0022430419921875, 'loss_3': -16.462196350097656, 'loss_4': 0.06595759838819504, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 17:12:29,661 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:29,662 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:23<08:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:37,003 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012511632405221462, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.342, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009993186220526695, 'eval_loss_2': 0.0025184452533721924, 'eval_loss_3': -18.133399963378906, 'eval_loss_4': 0.04932774603366852, 'epoch': 27.18}
{'loss': 0.0061, 'grad_norm': 4.309996604919434, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.003519862424582243, 'loss_2': 0.0025463104248046875, 'loss_3': -16.519683837890625, 'loss_4': 0.04171883314847946, 'epoch': 27.19}
{'loss': 0.01, 'grad_norm': 5.870769500732422, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.007156196516007185, 'loss_2': 0.0028514862060546875, 'loss_3': -16.43912124633789, 'loss_4': -0.18402935564517975, 'epoch': 27.19}
{'loss': 0.0107, 'grad_norm': 6.002553939819336, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.007297697942703962, 'loss_2': 0.00344085693359375, 'loss_3': -16.198719024658203, 'loss_4': 0.025741908699274063, 'epoch': 27.2}
{'loss': 0.0083, 'grad_norm': 4.738422870635986, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.0024691422004252672, 'loss_2': 0.00579833984375, 'loss_3': -16.608755111694336, 'loss_4': 0.20171959698200226, 'epoch': 27.2}
{'loss': 0.0038, 'grad_norm': 4.247320175170898, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.0019836912397295237, 'loss_2': 0.0017910003662109375, 'loss_3': -16.48968505859375, 'loss_4': 0.11491064727306366, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 17:12:37,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:37,003 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:30<08:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:44,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012401457875967026, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.767, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009884040802717209, 'eval_loss_2': 0.002517417073249817, 'eval_loss_3': -18.140493392944336, 'eval_loss_4': 0.021095748990774155, 'epoch': 27.21}
{'loss': 0.0109, 'grad_norm': 4.329663276672363, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.00463494099676609, 'loss_2': 0.006256103515625, 'loss_3': -16.377483367919922, 'loss_4': 0.04669799283146858, 'epoch': 27.22}
{'loss': 0.0117, 'grad_norm': 4.75238561630249, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.004504951182752848, 'loss_2': 0.007228851318359375, 'loss_3': -16.388214111328125, 'loss_4': -0.10852763056755066, 'epoch': 27.22}
{'loss': 0.0106, 'grad_norm': 7.577381610870361, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.008846916258335114, 'loss_2': 0.0017862319946289062, 'loss_3': -16.34235191345215, 'loss_4': 0.1301950216293335, 'epoch': 27.23}
{'loss': 0.0143, 'grad_norm': 4.65040397644043, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.005367989186197519, 'loss_2': 0.00888824462890625, 'loss_3': -16.297569274902344, 'loss_4': -0.03250759840011597, 'epoch': 27.23}
{'loss': 0.0093, 'grad_norm': 6.443301677703857, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.0050905500538647175, 'loss_2': 0.00423431396484375, 'loss_3': -16.357547760009766, 'loss_4': 0.2750009596347809, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 17:12:44,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:44,357 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:38<08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:51,705 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01304511446505785, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.082, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010395766235888004, 'eval_loss_2': 0.0026493482291698456, 'eval_loss_3': -18.143146514892578, 'eval_loss_4': 0.01772225648164749, 'epoch': 27.24}
{'loss': 0.0091, 'grad_norm': 4.719140529632568, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.0056473552249372005, 'loss_2': 0.0034923553466796875, 'loss_3': -16.55379295349121, 'loss_4': 0.20198193192481995, 'epoch': 27.24}
{'loss': 0.0122, 'grad_norm': 6.636429786682129, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.006724716629832983, 'loss_2': 0.00551605224609375, 'loss_3': -16.552040100097656, 'loss_4': 0.3901897370815277, 'epoch': 27.25}
{'loss': 0.0231, 'grad_norm': 7.578113555908203, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.016274333000183105, 'loss_2': 0.006801605224609375, 'loss_3': -16.415542602539062, 'loss_4': -0.07503052055835724, 'epoch': 27.26}
{'loss': 0.0036, 'grad_norm': 4.98745584487915, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.00276117492467165, 'loss_2': 0.0007982254028320312, 'loss_3': -16.487125396728516, 'loss_4': -0.12177412956953049, 'epoch': 27.26}
{'loss': 0.0067, 'grad_norm': 5.090782165527344, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.006249300204217434, 'loss_2': 0.0004897117614746094, 'loss_3': -16.1607608795166, 'loss_4': 0.17361241579055786, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 17:12:51,705 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:51,705 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:45<08:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:12:59,047 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01362205296754837, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.215, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01037949975579977, 'eval_loss_2': 0.0032425522804260254, 'eval_loss_3': -18.14458465576172, 'eval_loss_4': 0.027985762804746628, 'epoch': 27.27}
{'loss': 0.0069, 'grad_norm': 6.707719326019287, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.005340540315955877, 'loss_2': 0.0015592575073242188, 'loss_3': -16.205793380737305, 'loss_4': 0.2666292190551758, 'epoch': 27.27}
{'loss': 0.0211, 'grad_norm': 8.81356143951416, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.020165609195828438, 'loss_2': 0.0009746551513671875, 'loss_3': -16.441112518310547, 'loss_4': 0.17171238362789154, 'epoch': 27.28}
{'loss': 0.008, 'grad_norm': 5.014188766479492, 'learning_rate': 2.75e-06, 'loss_1': 0.0054295859299600124, 'loss_2': 0.0025882720947265625, 'loss_3': -16.35151481628418, 'loss_4': -0.05187743902206421, 'epoch': 27.28}
{'loss': 0.0048, 'grad_norm': 4.809427261352539, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.004502312280237675, 'loss_2': 0.0003256797790527344, 'loss_3': -16.325740814208984, 'loss_4': -0.008907310664653778, 'epoch': 27.29}
{'loss': 0.0256, 'grad_norm': 12.793838500976562, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.02035168744623661, 'loss_2': 0.00522613525390625, 'loss_3': -16.290882110595703, 'loss_4': 0.12971609830856323, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 17:12:59,047 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:12:59,047 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:55:52<07:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:06,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013699430972337723, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.216, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010270196944475174, 'eval_loss_2': 0.003429234027862549, 'eval_loss_3': -18.153173446655273, 'eval_loss_4': 0.009413901716470718, 'epoch': 27.3}
{'loss': 0.0041, 'grad_norm': 4.570469379425049, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.001679767039604485, 'loss_2': 0.0023956298828125, 'loss_3': -16.532365798950195, 'loss_4': 0.1006065309047699, 'epoch': 27.3}
{'loss': 0.0687, 'grad_norm': 10.789347648620605, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.06251253932714462, 'loss_2': 0.006195068359375, 'loss_3': -16.34170913696289, 'loss_4': 0.3837125599384308, 'epoch': 27.31}
{'loss': 0.008, 'grad_norm': 4.618892669677734, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.004936502780765295, 'loss_2': 0.003086090087890625, 'loss_3': -16.299448013305664, 'loss_4': 0.19527143239974976, 'epoch': 27.31}
{'loss': 0.0234, 'grad_norm': 10.971549034118652, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.018900012597441673, 'loss_2': 0.00452423095703125, 'loss_3': -16.504802703857422, 'loss_4': 0.259503573179245, 'epoch': 27.32}
{'loss': 0.0111, 'grad_norm': 4.697079181671143, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.005520995240658522, 'loss_2': 0.00557708740234375, 'loss_3': -16.492530822753906, 'loss_4': -0.06976200640201569, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 17:13:06,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:06,395 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:56:00<07:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:13,746 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013856280595064163, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.234, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010140587575733662, 'eval_loss_2': 0.003715693950653076, 'eval_loss_3': -18.15291976928711, 'eval_loss_4': -0.0028788167983293533, 'epoch': 27.33}
{'loss': 0.0099, 'grad_norm': 4.795784950256348, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.003394200000911951, 'loss_2': 0.006496429443359375, 'loss_3': -16.31062126159668, 'loss_4': 0.22233982384204865, 'epoch': 27.33}
{'loss': 0.0048, 'grad_norm': 5.042120933532715, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.0019402275793254375, 'loss_2': 0.0028743743896484375, 'loss_3': -16.435394287109375, 'loss_4': -0.09664898365736008, 'epoch': 27.34}
{'loss': 0.0073, 'grad_norm': 5.073292255401611, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.0031250689644366503, 'loss_2': 0.00421905517578125, 'loss_3': -16.341306686401367, 'loss_4': 0.1944078654050827, 'epoch': 27.34}
{'loss': 0.0059, 'grad_norm': 13.356623649597168, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.0035016327165067196, 'loss_2': 0.002368927001953125, 'loss_3': -16.542709350585938, 'loss_4': 0.01964181661605835, 'epoch': 27.35}
{'loss': 0.0296, 'grad_norm': 13.49581241607666, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.026548374444246292, 'loss_2': 0.003017425537109375, 'loss_3': -16.340192794799805, 'loss_4': 0.28373825550079346, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 17:13:13,746 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:13,746 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:56:07<07:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:21,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013602258637547493, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.801, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009785475209355354, 'eval_loss_2': 0.0038167834281921387, 'eval_loss_3': -18.157926559448242, 'eval_loss_4': -0.02132200077176094, 'epoch': 27.35}
{'loss': 0.009, 'grad_norm': 7.174561977386475, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.006942909676581621, 'loss_2': 0.0020751953125, 'loss_3': -16.2552490234375, 'loss_4': -0.27720731496810913, 'epoch': 27.36}
{'loss': 0.0062, 'grad_norm': 4.80830192565918, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.004687450360506773, 'loss_2': 0.00153350830078125, 'loss_3': -16.249351501464844, 'loss_4': -0.30589377880096436, 'epoch': 27.37}
{'loss': 0.0091, 'grad_norm': 4.859884262084961, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.0047896020114421844, 'loss_2': 0.00435638427734375, 'loss_3': -16.356369018554688, 'loss_4': -0.378081738948822, 'epoch': 27.37}
{'loss': 0.005, 'grad_norm': 4.829836845397949, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.0035752826370298862, 'loss_2': 0.0013790130615234375, 'loss_3': -16.55490493774414, 'loss_4': 0.13544079661369324, 'epoch': 27.38}
{'loss': 0.0156, 'grad_norm': 7.842068672180176, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.01116069033741951, 'loss_2': 0.00440216064453125, 'loss_3': -16.423757553100586, 'loss_4': 0.1927022784948349, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 17:13:21,099 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:21,099 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:56:15<07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:28,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013645367696881294, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.112, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009581253863871098, 'eval_loss_2': 0.004064112901687622, 'eval_loss_3': -18.155851364135742, 'eval_loss_4': -0.033376097679138184, 'epoch': 27.38}
{'loss': 0.0089, 'grad_norm': 5.266847610473633, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.006525373551994562, 'loss_2': 0.0023345947265625, 'loss_3': -16.640867233276367, 'loss_4': 0.011708393692970276, 'epoch': 27.39}
{'loss': 0.0156, 'grad_norm': 6.893630504608154, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.008846460841596127, 'loss_2': 0.00678253173828125, 'loss_3': -16.401548385620117, 'loss_4': -0.018112260848283768, 'epoch': 27.4}
{'loss': 0.0757, 'grad_norm': 16.299341201782227, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.07478141784667969, 'loss_2': 0.0009393692016601562, 'loss_3': -16.364919662475586, 'loss_4': 0.46711644530296326, 'epoch': 27.4}
{'loss': 0.0054, 'grad_norm': 5.428348541259766, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.005179365631192923, 'loss_2': 0.0001964569091796875, 'loss_3': -16.400705337524414, 'loss_4': -0.03588134050369263, 'epoch': 27.41}
{'loss': 0.0082, 'grad_norm': 4.496176719665527, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.005147919058799744, 'loss_2': 0.003009796142578125, 'loss_3': -16.363073348999023, 'loss_4': -0.44404107332229614, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 17:13:28,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:28,446 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:22<07:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:35,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01304607093334198, 'eval_runtime': 3.8021, 'eval_samples_per_second': 269.326, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00905539933592081, 'eval_loss_2': 0.003990672528743744, 'eval_loss_3': -18.15081024169922, 'eval_loss_4': -0.025905044749379158, 'epoch': 27.41}
{'loss': 0.0075, 'grad_norm': 4.175976276397705, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.0035891856532543898, 'loss_2': 0.0038814544677734375, 'loss_3': -16.47475814819336, 'loss_4': -0.39627590775489807, 'epoch': 27.42}
{'loss': 0.0105, 'grad_norm': 5.228198051452637, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.00546994199976325, 'loss_2': 0.004993438720703125, 'loss_3': -16.546627044677734, 'loss_4': 0.03525810316205025, 'epoch': 27.42}
{'loss': 0.0094, 'grad_norm': 4.759560585021973, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.0057170637883245945, 'loss_2': 0.003635406494140625, 'loss_3': -16.37688446044922, 'loss_4': -0.14036637544631958, 'epoch': 27.43}
{'loss': 0.0136, 'grad_norm': 5.304034233093262, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.008353570476174355, 'loss_2': 0.00527191162109375, 'loss_3': -16.374439239501953, 'loss_4': -0.08264413475990295, 'epoch': 27.44}
{'loss': 0.0115, 'grad_norm': 4.594598770141602, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.003167213872075081, 'loss_2': 0.00836181640625, 'loss_3': -16.351688385009766, 'loss_4': -0.3075661361217499, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 17:13:35,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:35,783 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:29<07:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:43,124 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01267571747303009, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008924409747123718, 'eval_loss_2': 0.003751307725906372, 'eval_loss_3': -18.14849090576172, 'eval_loss_4': 0.0028346050530672073, 'epoch': 27.44}
{'loss': 0.0065, 'grad_norm': 4.3393049240112305, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.0032166677992790937, 'loss_2': 0.00327301025390625, 'loss_3': -16.49612808227539, 'loss_4': 0.0810585618019104, 'epoch': 27.45}
{'loss': 0.0061, 'grad_norm': 4.795777797698975, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.00486017856746912, 'loss_2': 0.0012378692626953125, 'loss_3': -16.365018844604492, 'loss_4': 0.12580159306526184, 'epoch': 27.45}
{'loss': 0.0182, 'grad_norm': 5.031618595123291, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.013685019686818123, 'loss_2': 0.004486083984375, 'loss_3': -16.384132385253906, 'loss_4': 0.22710025310516357, 'epoch': 27.46}
{'loss': 0.0111, 'grad_norm': 6.700969696044922, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.00817401148378849, 'loss_2': 0.002899169921875, 'loss_3': -16.316675186157227, 'loss_4': 0.21733219921588898, 'epoch': 27.47}
{'loss': 0.0038, 'grad_norm': 4.727696418762207, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.002640190999954939, 'loss_2': 0.00113677978515625, 'loss_3': -16.473915100097656, 'loss_4': -0.08987599611282349, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 17:13:43,124 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:43,124 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:37<07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:50,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012286394834518433, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.535, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009130842983722687, 'eval_loss_2': 0.003155551850795746, 'eval_loss_3': -18.14995765686035, 'eval_loss_4': 0.023385437205433846, 'epoch': 27.47}
{'loss': 0.0044, 'grad_norm': 4.899803161621094, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.0033989239018410444, 'loss_2': 0.00098419189453125, 'loss_3': -16.30953598022461, 'loss_4': 0.27201443910598755, 'epoch': 27.48}
{'loss': 0.0113, 'grad_norm': 4.8778581619262695, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.003537297248840332, 'loss_2': 0.0078125, 'loss_3': -16.304044723510742, 'loss_4': 0.2935153841972351, 'epoch': 27.48}
{'loss': 0.0059, 'grad_norm': 5.375614643096924, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.005234702955931425, 'loss_2': 0.0006628036499023438, 'loss_3': -16.23272705078125, 'loss_4': -0.49167683720588684, 'epoch': 27.49}
{'loss': 0.0126, 'grad_norm': 7.415318012237549, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.011605790816247463, 'loss_2': 0.0009613037109375, 'loss_3': -16.441282272338867, 'loss_4': 0.12962442636489868, 'epoch': 27.49}
{'loss': 0.0046, 'grad_norm': 4.447190284729004, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.003523630555719137, 'loss_2': 0.00103759765625, 'loss_3': -16.542430877685547, 'loss_4': 0.3157891035079956, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 17:13:50,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:50,467 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:44<07:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:13:57,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011993851512670517, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.201, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009311932139098644, 'eval_loss_2': 0.002681918442249298, 'eval_loss_3': -18.152206420898438, 'eval_loss_4': 0.024969736114144325, 'epoch': 27.5}
{'loss': 0.0066, 'grad_norm': 5.014269828796387, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.0064144376665353775, 'loss_2': 0.00022995471954345703, 'loss_3': -16.31742286682129, 'loss_4': -0.10854124277830124, 'epoch': 27.51}
{'loss': 0.0095, 'grad_norm': 5.922945022583008, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.005219764541834593, 'loss_2': 0.004314422607421875, 'loss_3': -16.433927536010742, 'loss_4': -0.07543960213661194, 'epoch': 27.51}
{'loss': 0.0152, 'grad_norm': 9.111936569213867, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.012598377652466297, 'loss_2': 0.0025768280029296875, 'loss_3': -16.269603729248047, 'loss_4': 0.42470717430114746, 'epoch': 27.52}
{'loss': 0.0062, 'grad_norm': 4.7160820960998535, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.0028815269470214844, 'loss_2': 0.00328826904296875, 'loss_3': -16.476057052612305, 'loss_4': 0.11852776259183884, 'epoch': 27.52}
{'loss': 0.0115, 'grad_norm': 8.250699043273926, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.00532354274764657, 'loss_2': 0.00614166259765625, 'loss_3': -16.55282211303711, 'loss_4': -0.5341187119483948, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 17:13:57,817 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:13:57,817 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:56:51<07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:05,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011034024879336357, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008818921633064747, 'eval_loss_2': 0.0022151023149490356, 'eval_loss_3': -18.15969467163086, 'eval_loss_4': 0.04540177062153816, 'epoch': 27.53}
{'loss': 0.0115, 'grad_norm': 8.045907974243164, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.0077882795594632626, 'loss_2': 0.003662109375, 'loss_3': -16.255521774291992, 'loss_4': 0.12089276313781738, 'epoch': 27.53}
{'loss': 0.015, 'grad_norm': 7.311008930206299, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.00593269569799304, 'loss_2': 0.009063720703125, 'loss_3': -16.464590072631836, 'loss_4': -0.047409772872924805, 'epoch': 27.54}
{'loss': 0.0116, 'grad_norm': 5.347380638122559, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.0045581660233438015, 'loss_2': 0.00705718994140625, 'loss_3': -16.4328670501709, 'loss_4': -0.12144467979669571, 'epoch': 27.55}
{'loss': 0.0101, 'grad_norm': 4.790955066680908, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.0042516980320215225, 'loss_2': 0.005889892578125, 'loss_3': -16.334312438964844, 'loss_4': 0.12157175689935684, 'epoch': 27.55}
{'loss': 0.0078, 'grad_norm': 5.459767818450928, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.006972015835344791, 'loss_2': 0.0008664131164550781, 'loss_3': -16.479190826416016, 'loss_4': -0.06747773289680481, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 17:14:05,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:05,180 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:56:59<07:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:12,533 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010863222181797028, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.263, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008388645946979523, 'eval_loss_2': 0.002474576234817505, 'eval_loss_3': -18.157154083251953, 'eval_loss_4': 0.047641508281230927, 'epoch': 27.56}
{'loss': 0.0124, 'grad_norm': 4.2014265060424805, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.0035474069882184267, 'loss_2': 0.00885009765625, 'loss_3': -16.48107147216797, 'loss_4': -0.24410253763198853, 'epoch': 27.56}
{'loss': 0.0056, 'grad_norm': 4.628785133361816, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.002757956041023135, 'loss_2': 0.0028514862060546875, 'loss_3': -16.404008865356445, 'loss_4': -0.041802678257226944, 'epoch': 27.57}
{'loss': 0.0067, 'grad_norm': 5.506719589233398, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.0059806169010698795, 'loss_2': 0.0007252693176269531, 'loss_3': -16.28194236755371, 'loss_4': 0.16834038496017456, 'epoch': 27.58}
{'loss': 0.005, 'grad_norm': 4.3057074546813965, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.0030676911119371653, 'loss_2': 0.0019178390502929688, 'loss_3': -16.436878204345703, 'loss_4': 0.2026006430387497, 'epoch': 27.58}
{'loss': 0.0052, 'grad_norm': 4.596391201019287, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.004278919193893671, 'loss_2': 0.0009088516235351562, 'loss_3': -16.342613220214844, 'loss_4': -0.15596550703048706, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 17:14:12,533 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:12,533 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:57:06<07:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:19,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010708323679864407, 'eval_runtime': 3.8008, 'eval_samples_per_second': 269.414, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008304828777909279, 'eval_loss_2': 0.002403493970632553, 'eval_loss_3': -18.16131591796875, 'eval_loss_4': 0.03245973587036133, 'epoch': 27.59}
{'loss': 0.0048, 'grad_norm': 5.292219161987305, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.004028943832963705, 'loss_2': 0.0007429122924804688, 'loss_3': -16.379108428955078, 'loss_4': 0.11008559167385101, 'epoch': 27.59}
{'loss': 0.0072, 'grad_norm': 4.287986755371094, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.0038963814731687307, 'loss_2': 0.0032958984375, 'loss_3': -16.43207550048828, 'loss_4': -0.45891767740249634, 'epoch': 27.6}
{'loss': 0.0064, 'grad_norm': 4.611351490020752, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.0023027232382446527, 'loss_2': 0.0041351318359375, 'loss_3': -16.35710334777832, 'loss_4': 0.3649812936782837, 'epoch': 27.6}
{'loss': 0.0097, 'grad_norm': 6.217264175415039, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.007244464010000229, 'loss_2': 0.00250244140625, 'loss_3': -16.30619239807129, 'loss_4': -0.1671038717031479, 'epoch': 27.61}
{'loss': 0.0069, 'grad_norm': 5.108638286590576, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.004903758876025677, 'loss_2': 0.0019664764404296875, 'loss_3': -16.30638313293457, 'loss_4': 0.0008849911391735077, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 17:14:19,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:19,874 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:57:13<06:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:27,211 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010640563443303108, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008046703413128853, 'eval_loss_2': 0.0025938600301742554, 'eval_loss_3': -18.16100311279297, 'eval_loss_4': 0.014997713267803192, 'epoch': 27.62}
{'loss': 0.0052, 'grad_norm': 4.848278045654297, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.0029897785279899836, 'loss_2': 0.0021820068359375, 'loss_3': -16.412092208862305, 'loss_4': -0.19106857478618622, 'epoch': 27.62}
{'loss': 0.0044, 'grad_norm': 4.565699577331543, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.0042378222569823265, 'loss_2': 0.00020420551300048828, 'loss_3': -16.053905487060547, 'loss_4': 0.12519721686840057, 'epoch': 27.63}
{'loss': 0.0076, 'grad_norm': 4.73619270324707, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.0028849823866039515, 'loss_2': 0.00469970703125, 'loss_3': -16.075984954833984, 'loss_4': -0.12568223476409912, 'epoch': 27.63}
{'loss': 0.0086, 'grad_norm': 4.786952972412109, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.004188048653304577, 'loss_2': 0.00445556640625, 'loss_3': -16.114091873168945, 'loss_4': -0.15533536672592163, 'epoch': 27.64}
{'loss': 0.0083, 'grad_norm': 4.856773376464844, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.004156293347477913, 'loss_2': 0.004161834716796875, 'loss_3': -16.406417846679688, 'loss_4': 0.29984229803085327, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 17:14:27,211 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:27,211 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:21<06:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:34,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011127864941954613, 'eval_runtime': 3.8007, 'eval_samples_per_second': 269.427, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.008316626772284508, 'eval_loss_2': 0.002811238169670105, 'eval_loss_3': -18.156505584716797, 'eval_loss_4': -0.004082683473825455, 'epoch': 27.65}
{'loss': 0.0086, 'grad_norm': 4.976485729217529, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.0062598856166005135, 'loss_2': 0.0023899078369140625, 'loss_3': -16.123077392578125, 'loss_4': -0.5314343571662903, 'epoch': 27.65}
{'loss': 0.0081, 'grad_norm': 4.6863837242126465, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.0038370820693671703, 'loss_2': 0.004241943359375, 'loss_3': -16.486581802368164, 'loss_4': -0.2007775902748108, 'epoch': 27.66}
{'loss': 0.0211, 'grad_norm': 6.577836990356445, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.009935387410223484, 'loss_2': 0.01113128662109375, 'loss_3': -16.439538955688477, 'loss_4': 0.17841193079948425, 'epoch': 27.66}
{'loss': 0.0025, 'grad_norm': 4.8245439529418945, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.0023506861180067062, 'loss_2': 0.00018405914306640625, 'loss_3': -16.26140594482422, 'loss_4': -0.10813334584236145, 'epoch': 27.67}
{'loss': 0.004, 'grad_norm': 4.635636329650879, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.0033587662037461996, 'loss_2': 0.0006704330444335938, 'loss_3': -16.348051071166992, 'loss_4': -0.04379469156265259, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 17:14:34,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:34,557 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:28<06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:41,908 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012213509529829025, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00872896984219551, 'eval_loss_2': 0.0034845396876335144, 'eval_loss_3': -18.14946174621582, 'eval_loss_4': -0.013734236359596252, 'epoch': 27.67}
{'loss': 0.0015, 'grad_norm': 4.7821550369262695, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.0014476865762844682, 'loss_2': 3.2782554626464844e-06, 'loss_3': -16.505306243896484, 'loss_4': 0.1262362003326416, 'epoch': 27.68}
{'loss': 0.0033, 'grad_norm': 4.579349517822266, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.002885888796299696, 'loss_2': 0.00043082237243652344, 'loss_3': -16.398653030395508, 'loss_4': 0.45110249519348145, 'epoch': 27.69}
{'loss': 0.0045, 'grad_norm': 4.302691459655762, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.0031260745599865913, 'loss_2': 0.0013484954833984375, 'loss_3': -16.36563491821289, 'loss_4': 0.19607612490653992, 'epoch': 27.69}
{'loss': 0.0103, 'grad_norm': 5.411717414855957, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.002741458360105753, 'loss_2': 0.007541656494140625, 'loss_3': -16.313411712646484, 'loss_4': -0.22314134240150452, 'epoch': 27.7}
{'loss': 0.0114, 'grad_norm': 4.955322265625, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.0034923208877444267, 'loss_2': 0.0079345703125, 'loss_3': -16.218505859375, 'loss_4': 0.2088310420513153, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 17:14:41,908 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:41,908 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:35<06:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:49,253 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012145867571234703, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.3, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008813668973743916, 'eval_loss_2': 0.003332197666168213, 'eval_loss_3': -18.14361000061035, 'eval_loss_4': -0.023547915741801262, 'epoch': 27.7}
{'loss': 0.0054, 'grad_norm': 4.774051666259766, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.003307231469079852, 'loss_2': 0.0021114349365234375, 'loss_3': -16.37030792236328, 'loss_4': -0.08952625095844269, 'epoch': 27.71}
{'loss': 0.0069, 'grad_norm': 5.410411834716797, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.005911580286920071, 'loss_2': 0.0010194778442382812, 'loss_3': -16.51404571533203, 'loss_4': 0.28895604610443115, 'epoch': 27.72}
{'loss': 0.0072, 'grad_norm': 5.572290897369385, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.005865047220140696, 'loss_2': 0.001331329345703125, 'loss_3': -16.38949966430664, 'loss_4': -0.017553776502609253, 'epoch': 27.72}
{'loss': 0.0061, 'grad_norm': 4.542917251586914, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.0025566229596734047, 'loss_2': 0.0035152435302734375, 'loss_3': -16.35051727294922, 'loss_4': -0.2283065915107727, 'epoch': 27.73}
{'loss': 0.0065, 'grad_norm': 5.968319892883301, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.006488081533461809, 'loss_2': 2.1398067474365234e-05, 'loss_3': -16.4091739654541, 'loss_4': -0.24152573943138123, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 17:14:49,253 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:49,253 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:43<06:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:14:56,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011689243838191032, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008652863092720509, 'eval_loss_2': 0.0030363798141479492, 'eval_loss_3': -18.143386840820312, 'eval_loss_4': -0.016591090708971024, 'epoch': 27.73}
{'loss': 0.0041, 'grad_norm': 5.118448257446289, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.0033204571809619665, 'loss_2': 0.0007472038269042969, 'loss_3': -16.353803634643555, 'loss_4': 0.2966908812522888, 'epoch': 27.74}
{'loss': 0.0108, 'grad_norm': 42.14788055419922, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.003940891940146685, 'loss_2': 0.006870269775390625, 'loss_3': -16.50628662109375, 'loss_4': 0.24091829359531403, 'epoch': 27.74}
{'loss': 0.0084, 'grad_norm': 4.879147052764893, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.003308064304292202, 'loss_2': 0.005126953125, 'loss_3': -16.39480972290039, 'loss_4': -0.28249871730804443, 'epoch': 27.75}
{'loss': 0.0082, 'grad_norm': 4.9937896728515625, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.004720776807516813, 'loss_2': 0.00345611572265625, 'loss_3': -16.373924255371094, 'loss_4': 0.32077670097351074, 'epoch': 27.76}
{'loss': 0.0049, 'grad_norm': 8.542496681213379, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.0030900887213647366, 'loss_2': 0.0018310546875, 'loss_3': -16.302661895751953, 'loss_4': 0.17444802820682526, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 17:14:56,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:14:56,602 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:57:50<06:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:03,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010932372882962227, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.43, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.0084850387647748, 'eval_loss_2': 0.002447333186864853, 'eval_loss_3': -18.141244888305664, 'eval_loss_4': 0.00985298678278923, 'epoch': 27.76}
{'loss': 0.0088, 'grad_norm': 5.253752708435059, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.006317607592791319, 'loss_2': 0.002445220947265625, 'loss_3': -16.50510025024414, 'loss_4': 0.2742864489555359, 'epoch': 27.77}
{'loss': 0.0079, 'grad_norm': 5.115786552429199, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.005014833528548479, 'loss_2': 0.0029125213623046875, 'loss_3': -16.327945709228516, 'loss_4': 0.061346426606178284, 'epoch': 27.77}
{'loss': 0.0112, 'grad_norm': 4.629915237426758, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.005363402422517538, 'loss_2': 0.00579071044921875, 'loss_3': -16.51776123046875, 'loss_4': -0.2845934331417084, 'epoch': 27.78}
{'loss': 0.0119, 'grad_norm': 13.025601387023926, 'learning_rate': 2.25e-06, 'loss_1': 0.005412328522652388, 'loss_2': 0.006450653076171875, 'loss_3': -16.4012393951416, 'loss_4': 0.2569848895072937, 'epoch': 27.78}
{'loss': 0.0034, 'grad_norm': 4.158996105194092, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.0023074953351169825, 'loss_2': 0.0011425018310546875, 'loss_3': -16.390228271484375, 'loss_4': 0.1508728265762329, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 17:15:03,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:03,944 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:57:57<06:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:11,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01077108085155487, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008388549089431763, 'eval_loss_2': 0.002382531762123108, 'eval_loss_3': -18.140975952148438, 'eval_loss_4': 0.039623625576496124, 'epoch': 27.79}
{'loss': 0.0123, 'grad_norm': 4.924604892730713, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.005373191088438034, 'loss_2': 0.006885528564453125, 'loss_3': -16.573974609375, 'loss_4': 0.14925970137119293, 'epoch': 27.8}
{'loss': 0.0178, 'grad_norm': 5.8236494064331055, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.01274045929312706, 'loss_2': 0.005077362060546875, 'loss_3': -16.373676300048828, 'loss_4': 0.3815842270851135, 'epoch': 27.8}
{'loss': 0.0109, 'grad_norm': 28.06715202331543, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.005791736301034689, 'loss_2': 0.00505828857421875, 'loss_3': -16.287593841552734, 'loss_4': 0.28088319301605225, 'epoch': 27.81}
{'loss': 0.0051, 'grad_norm': 4.844688415527344, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.002392631024122238, 'loss_2': 0.002727508544921875, 'loss_3': -16.26408576965332, 'loss_4': 0.08878470957279205, 'epoch': 27.81}
{'loss': 0.0096, 'grad_norm': 4.998938083648682, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.0050499653443694115, 'loss_2': 0.0045318603515625, 'loss_3': -16.37561798095703, 'loss_4': -0.6099567413330078, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 17:15:11,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:11,287 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:58:05<06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:18,636 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010836295783519745, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.019, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00841663870960474, 'eval_loss_2': 0.0024196580052375793, 'eval_loss_3': -18.147218704223633, 'eval_loss_4': 0.0663868635892868, 'epoch': 27.82}
{'loss': 0.0102, 'grad_norm': 4.598911285400391, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.005437727551907301, 'loss_2': 0.0047760009765625, 'loss_3': -16.32000732421875, 'loss_4': 0.006759464740753174, 'epoch': 27.83}
{'loss': 0.0132, 'grad_norm': 6.296590805053711, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.00703966012224555, 'loss_2': 0.00612640380859375, 'loss_3': -16.230758666992188, 'loss_4': -0.11122222244739532, 'epoch': 27.83}
{'loss': 0.0247, 'grad_norm': 12.960283279418945, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.023640044033527374, 'loss_2': 0.0010356903076171875, 'loss_3': -16.132688522338867, 'loss_4': 0.03477238118648529, 'epoch': 27.84}
{'loss': 0.0184, 'grad_norm': 13.59653377532959, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.016348274424672127, 'loss_2': 0.00208282470703125, 'loss_3': -16.266145706176758, 'loss_4': 0.3817836344242096, 'epoch': 27.84}
{'loss': 0.0193, 'grad_norm': 9.214605331420898, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.013112367130815983, 'loss_2': 0.0062103271484375, 'loss_3': -16.355892181396484, 'loss_4': 0.1790151298046112, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 17:15:18,636 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:18,637 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:58:12<06:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:25,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01109577901661396, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.348, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.008558796718716621, 'eval_loss_2': 0.002536982297897339, 'eval_loss_3': -18.152721405029297, 'eval_loss_4': 0.08499279618263245, 'epoch': 27.85}
{'loss': 0.0072, 'grad_norm': 5.898070812225342, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.006425858940929174, 'loss_2': 0.0007967948913574219, 'loss_3': -16.45694351196289, 'loss_4': -0.059565458446741104, 'epoch': 27.85}
{'loss': 0.0082, 'grad_norm': 5.511234283447266, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.007307499647140503, 'loss_2': 0.0008649826049804688, 'loss_3': -16.184110641479492, 'loss_4': 0.022584103047847748, 'epoch': 27.86}
{'loss': 0.007, 'grad_norm': 4.640558242797852, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.003683436894789338, 'loss_2': 0.00336456298828125, 'loss_3': -16.28801727294922, 'loss_4': 0.13406066596508026, 'epoch': 27.87}
{'loss': 0.007, 'grad_norm': 5.092103958129883, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.004745966754853725, 'loss_2': 0.0022735595703125, 'loss_3': -16.367008209228516, 'loss_4': -0.16594265401363373, 'epoch': 27.87}
{'loss': 0.0099, 'grad_norm': 4.662265777587891, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.002918024081736803, 'loss_2': 0.0070037841796875, 'loss_3': -16.344276428222656, 'loss_4': 0.30777859687805176, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 17:15:25,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:25,979 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:19<06:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:33,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01171046681702137, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008830920793116093, 'eval_loss_2': 0.0028795450925827026, 'eval_loss_3': -18.153743743896484, 'eval_loss_4': 0.1228267177939415, 'epoch': 27.88}
{'loss': 0.0023, 'grad_norm': 4.952615261077881, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.001921908464282751, 'loss_2': 0.0003974437713623047, 'loss_3': -16.206106185913086, 'loss_4': 0.4695284366607666, 'epoch': 27.88}
{'loss': 0.0045, 'grad_norm': 4.732394218444824, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.0037463121116161346, 'loss_2': 0.000720977783203125, 'loss_3': -16.28411865234375, 'loss_4': 0.16327686607837677, 'epoch': 27.89}
{'loss': 0.0056, 'grad_norm': 7.384044647216797, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.0035251860972493887, 'loss_2': 0.0020618438720703125, 'loss_3': -16.338420867919922, 'loss_4': -0.09610332548618317, 'epoch': 27.9}
{'loss': 0.0119, 'grad_norm': 6.500651836395264, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.009962473064661026, 'loss_2': 0.001953125, 'loss_3': -16.124126434326172, 'loss_4': 0.16229717433452606, 'epoch': 27.9}
{'loss': 0.0064, 'grad_norm': 4.558414459228516, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.003524601925164461, 'loss_2': 0.00283050537109375, 'loss_3': -16.186120986938477, 'loss_4': 0.17606264352798462, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 17:15:33,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:33,325 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:27<06:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:40,676 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011759736575186253, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.389, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00870549026876688, 'eval_loss_2': 0.0030542463064193726, 'eval_loss_3': -18.145313262939453, 'eval_loss_4': 0.19820864498615265, 'epoch': 27.91}
{'loss': 0.0033, 'grad_norm': 4.374797344207764, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.002349534537643194, 'loss_2': 0.0009603500366210938, 'loss_3': -16.33367347717285, 'loss_4': 0.265780508518219, 'epoch': 27.91}
{'loss': 0.0109, 'grad_norm': 6.998106956481934, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.006788946222513914, 'loss_2': 0.00414276123046875, 'loss_3': -16.396488189697266, 'loss_4': 0.23228871822357178, 'epoch': 27.92}
{'loss': 0.0087, 'grad_norm': 4.988715648651123, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.004253013525158167, 'loss_2': 0.00447845458984375, 'loss_3': -16.44542121887207, 'loss_4': 0.2520805597305298, 'epoch': 27.92}
{'loss': 0.0693, 'grad_norm': 13.25716781616211, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.06504295021295547, 'loss_2': 0.004207611083984375, 'loss_3': -16.359079360961914, 'loss_4': 0.45985424518585205, 'epoch': 27.93}
{'loss': 0.0036, 'grad_norm': 4.614037990570068, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.002607539528980851, 'loss_2': 0.0009713172912597656, 'loss_3': -16.375568389892578, 'loss_4': 0.007396183907985687, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 17:15:40,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:40,676 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:34<06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:15:48,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012116793543100357, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.975, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009210336953401566, 'eval_loss_2': 0.0029064565896987915, 'eval_loss_3': -18.13954734802246, 'eval_loss_4': 0.230801060795784, 'epoch': 27.94}
{'loss': 0.006, 'grad_norm': 4.488134860992432, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.004266929347068071, 'loss_2': 0.0017080307006835938, 'loss_3': -16.47048568725586, 'loss_4': 0.3260094225406647, 'epoch': 27.94}
{'loss': 0.009, 'grad_norm': 5.529688358306885, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.00628496753051877, 'loss_2': 0.00274658203125, 'loss_3': -16.38436508178711, 'loss_4': 0.4142943024635315, 'epoch': 27.95}
{'loss': 0.0079, 'grad_norm': 5.505420207977295, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.0041909231804311275, 'loss_2': 0.00371551513671875, 'loss_3': -16.507434844970703, 'loss_4': 0.4293001890182495, 'epoch': 27.95}
{'loss': 0.0033, 'grad_norm': 5.734414577484131, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.002540918765589595, 'loss_2': 0.0007295608520507812, 'loss_3': -16.39107894897461, 'loss_4': 0.03745028376579285, 'epoch': 27.96}
{'loss': 0.0069, 'grad_norm': 9.706673622131348, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.005654080770909786, 'loss_2': 0.00125885009765625, 'loss_3': -16.34184455871582, 'loss_4': 0.4584920406341553, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 17:15:48,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:48,027 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:41<05:56,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:15:55,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012100829742848873, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.388, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.009346319362521172, 'eval_loss_2': 0.002754509449005127, 'eval_loss_3': -18.13444709777832, 'eval_loss_4': 0.233621746301651, 'epoch': 27.97}
{'loss': 0.0091, 'grad_norm': 4.483986854553223, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.0029236692935228348, 'loss_2': 0.006145477294921875, 'loss_3': -16.5447998046875, 'loss_4': -0.05714711546897888, 'epoch': 27.97}
{'loss': 0.0058, 'grad_norm': 4.405381679534912, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.002948665525764227, 'loss_2': 0.002857208251953125, 'loss_3': -16.309534072875977, 'loss_4': 0.39329490065574646, 'epoch': 27.98}
{'loss': 0.0095, 'grad_norm': 5.596601486206055, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.007642141077667475, 'loss_2': 0.0018854141235351562, 'loss_3': -16.454151153564453, 'loss_4': -0.00289095938205719, 'epoch': 27.98}
{'loss': 0.0066, 'grad_norm': 5.319570064544678, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.0042592682875692844, 'loss_2': 0.00235748291015625, 'loss_3': -16.2426815032959, 'loss_4': -0.0169428288936615, 'epoch': 27.99}
{'loss': 0.007, 'grad_norm': 5.120928764343262, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.004776505753397942, 'loss_2': 0.0022029876708984375, 'loss_3': -16.207454681396484, 'loss_4': -0.11604597419500351, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 17:15:55,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:15:55,357 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:58:49<05:45,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 17:16:02,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011954260058701038, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.383, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.009361900389194489, 'eval_loss_2': 0.0025923587381839752, 'eval_loss_3': -18.132625579833984, 'eval_loss_4': 0.21256861090660095, 'epoch': 27.99}
{'loss': 0.004, 'grad_norm': 6.456742763519287, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.0008190323715098202, 'loss_2': 0.003173828125, 'loss_3': -16.423669815063477, 'loss_4': 0.4364864230155945, 'epoch': 28.0}
{'loss': 0.0317, 'grad_norm': 8.869790077209473, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.031035562977194786, 'loss_2': 0.0006799697875976562, 'loss_3': -16.26893424987793, 'loss_4': 0.09713906049728394, 'epoch': 28.01}
{'loss': 0.0061, 'grad_norm': 5.142269134521484, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0027498085983097553, 'loss_2': 0.0033245086669921875, 'loss_3': -16.47050666809082, 'loss_4': -0.0890960693359375, 'epoch': 28.01}
{'loss': 0.0137, 'grad_norm': 7.466897964477539, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.011721864342689514, 'loss_2': 0.002025604248046875, 'loss_3': -16.306381225585938, 'loss_4': 0.4174254238605499, 'epoch': 28.02}
{'loss': 0.0167, 'grad_norm': 9.654295921325684, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.015382970683276653, 'loss_2': 0.001277923583984375, 'loss_3': -16.46268653869629, 'loss_4': 0.04914015531539917, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 17:16:02,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:02,419 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:58:56<05:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:16:09,765 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012001723982393742, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.332, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.009384820237755775, 'eval_loss_2': 0.0026169046759605408, 'eval_loss_3': -18.12922477722168, 'eval_loss_4': 0.183004230260849, 'epoch': 28.02}
{'loss': 0.0037, 'grad_norm': 4.974302768707275, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.0028869961388409138, 'loss_2': 0.0008573532104492188, 'loss_3': -16.422197341918945, 'loss_4': 0.3329688608646393, 'epoch': 28.03}
{'loss': 0.0041, 'grad_norm': 4.286543369293213, 'learning_rate': 2e-06, 'loss_1': 0.0033663928043097258, 'loss_2': 0.0006966590881347656, 'loss_3': -16.56147003173828, 'loss_4': -0.01971498131752014, 'epoch': 28.03}
{'loss': 0.0108, 'grad_norm': 5.103015899658203, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.004082552157342434, 'loss_2': 0.0067596435546875, 'loss_3': -16.220491409301758, 'loss_4': 0.15744248032569885, 'epoch': 28.04}
{'loss': 0.014, 'grad_norm': 5.2972493171691895, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.005767766386270523, 'loss_2': 0.00823211669921875, 'loss_3': -16.312583923339844, 'loss_4': 0.12781673669815063, 'epoch': 28.05}
{'loss': 0.0112, 'grad_norm': 4.816885471343994, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.004442829173058271, 'loss_2': 0.00676727294921875, 'loss_3': -16.319751739501953, 'loss_4': 0.14195536077022552, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 17:16:09,765 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:09,765 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:59:03<05:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:17,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012120315805077553, 'eval_runtime': 3.7967, 'eval_samples_per_second': 269.707, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.009518840350210667, 'eval_loss_2': 0.0026014745235443115, 'eval_loss_3': -18.12946891784668, 'eval_loss_4': 0.17536121606826782, 'epoch': 28.05}
{'loss': 0.0097, 'grad_norm': 4.729508399963379, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.0035143534187227488, 'loss_2': 0.006229400634765625, 'loss_3': -16.554275512695312, 'loss_4': -0.15286335349082947, 'epoch': 28.06}
{'loss': 0.0043, 'grad_norm': 5.0208635330200195, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.0032176459208130836, 'loss_2': 0.0010557174682617188, 'loss_3': -16.354202270507812, 'loss_4': 0.13458043336868286, 'epoch': 28.06}
{'loss': 0.0039, 'grad_norm': 4.593947410583496, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.0025742279831320047, 'loss_2': 0.00128936767578125, 'loss_3': -16.312549591064453, 'loss_4': 0.39267200231552124, 'epoch': 28.07}
{'loss': 0.0113, 'grad_norm': 4.84094762802124, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.0037758846301585436, 'loss_2': 0.007511138916015625, 'loss_3': -16.30529022216797, 'loss_4': 0.12732520699501038, 'epoch': 28.08}
{'loss': 0.0051, 'grad_norm': 4.462081432342529, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.0027915474493056536, 'loss_2': 0.002323150634765625, 'loss_3': -16.35282325744629, 'loss_4': 0.08868178725242615, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 17:16:17,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:17,105 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:59:11<05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:24,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01257999986410141, 'eval_runtime': 3.7996, 'eval_samples_per_second': 269.503, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.009953036904335022, 'eval_loss_2': 0.002626962959766388, 'eval_loss_3': -18.132612228393555, 'eval_loss_4': 0.16740521788597107, 'epoch': 28.08}
{'loss': 0.0049, 'grad_norm': 4.739949703216553, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.002317241160199046, 'loss_2': 0.00262451171875, 'loss_3': -16.44834327697754, 'loss_4': 0.36562708020210266, 'epoch': 28.09}
{'loss': 0.0074, 'grad_norm': 4.356070518493652, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.0026366282254457474, 'loss_2': 0.004756927490234375, 'loss_3': -16.357271194458008, 'loss_4': 0.33468130230903625, 'epoch': 28.09}
{'loss': 0.0033, 'grad_norm': 4.4244384765625, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.0015861011343076825, 'loss_2': 0.0017566680908203125, 'loss_3': -16.394020080566406, 'loss_4': -0.15430620312690735, 'epoch': 28.1}
{'loss': 0.0066, 'grad_norm': 5.124617099761963, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.004227680619806051, 'loss_2': 0.00240325927734375, 'loss_3': -16.590423583984375, 'loss_4': -0.418044775724411, 'epoch': 28.1}
{'loss': 0.0048, 'grad_norm': 4.766333103179932, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.0024659608025103807, 'loss_2': 0.0023345947265625, 'loss_3': -16.04822540283203, 'loss_4': -0.05313960462808609, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 17:16:24,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:24,448 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:18<05:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:31,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013211779296398163, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.256, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010285596363246441, 'eval_loss_2': 0.0029261820018291473, 'eval_loss_3': -18.133331298828125, 'eval_loss_4': 0.1555977314710617, 'epoch': 28.11}
{'loss': 0.0044, 'grad_norm': 4.868091106414795, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.0025192287284880877, 'loss_2': 0.0018405914306640625, 'loss_3': -16.162084579467773, 'loss_4': 0.34195348620414734, 'epoch': 28.12}
{'loss': 0.0079, 'grad_norm': 4.595102787017822, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.0037322246935218573, 'loss_2': 0.004192352294921875, 'loss_3': -16.171218872070312, 'loss_4': 0.3279498815536499, 'epoch': 28.12}
{'loss': 0.0116, 'grad_norm': 5.56083869934082, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.006059444043785334, 'loss_2': 0.00550079345703125, 'loss_3': -16.350971221923828, 'loss_4': -0.12893146276474, 'epoch': 28.13}
{'loss': 0.0313, 'grad_norm': 11.578391075134277, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.029334651306271553, 'loss_2': 0.002010345458984375, 'loss_3': -16.387781143188477, 'loss_4': -0.12585817277431488, 'epoch': 28.13}
{'loss': 0.0037, 'grad_norm': 4.863969326019287, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.0026795146986842155, 'loss_2': 0.00104522705078125, 'loss_3': -16.4295597076416, 'loss_4': -0.032670363783836365, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 17:16:31,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:31,790 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:25<05:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:39,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013542166911065578, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.972, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010696439072489738, 'eval_loss_2': 0.0028457269072532654, 'eval_loss_3': -18.133020401000977, 'eval_loss_4': 0.14458976686000824, 'epoch': 28.14}
{'loss': 0.0054, 'grad_norm': 4.793751239776611, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.0029370493721216917, 'loss_2': 0.0024547576904296875, 'loss_3': -16.269054412841797, 'loss_4': 0.4533039927482605, 'epoch': 28.15}
{'loss': 0.0115, 'grad_norm': 5.415958881378174, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.007196460384875536, 'loss_2': 0.00434112548828125, 'loss_3': -16.414154052734375, 'loss_4': 0.14864546060562134, 'epoch': 28.15}
{'loss': 0.0125, 'grad_norm': 7.388076305389404, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.009660379029810429, 'loss_2': 0.0028171539306640625, 'loss_3': -16.35783576965332, 'loss_4': 0.06761657446622849, 'epoch': 28.16}
{'loss': 0.0938, 'grad_norm': 20.652896881103516, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.08754689246416092, 'loss_2': 0.006290435791015625, 'loss_3': -16.448287963867188, 'loss_4': 0.6589173674583435, 'epoch': 28.16}
{'loss': 0.0094, 'grad_norm': 4.818382740020752, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.00757757481187582, 'loss_2': 0.001865386962890625, 'loss_3': -16.376407623291016, 'loss_4': 0.27571356296539307, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 17:16:39,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:39,137 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:33<05:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:46,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013614148832857609, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.362, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010800272226333618, 'eval_loss_2': 0.002813875675201416, 'eval_loss_3': -18.130367279052734, 'eval_loss_4': 0.13658611476421356, 'epoch': 28.17}
{'loss': 0.0063, 'grad_norm': 4.884934425354004, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.0037712310440838337, 'loss_2': 0.002513885498046875, 'loss_3': -16.328842163085938, 'loss_4': 0.2979947626590729, 'epoch': 28.17}
{'loss': 0.0058, 'grad_norm': 4.815735340118408, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.004279586486518383, 'loss_2': 0.0015401840209960938, 'loss_3': -16.284645080566406, 'loss_4': 0.5615918040275574, 'epoch': 28.18}
{'loss': 0.0053, 'grad_norm': 5.06088924407959, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.005070282146334648, 'loss_2': 0.00022029876708984375, 'loss_3': -16.3668155670166, 'loss_4': -0.11870592832565308, 'epoch': 28.19}
{'loss': 0.0124, 'grad_norm': 4.81911039352417, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.004154288675636053, 'loss_2': 0.00824737548828125, 'loss_3': -16.29751205444336, 'loss_4': 0.019438862800598145, 'epoch': 28.19}
{'loss': 0.0069, 'grad_norm': 4.812691688537598, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.0022796576377004385, 'loss_2': 0.00466156005859375, 'loss_3': -16.370471954345703, 'loss_4': 0.25637513399124146, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 17:16:46,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:46,477 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:40<05:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:16:53,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013484032824635506, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.651, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010768468491733074, 'eval_loss_2': 0.002715565264225006, 'eval_loss_3': -18.126827239990234, 'eval_loss_4': 0.1276969313621521, 'epoch': 28.2}
{'loss': 0.0115, 'grad_norm': 5.383723258972168, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.006457605864852667, 'loss_2': 0.005039215087890625, 'loss_3': -16.22624969482422, 'loss_4': 0.1964341700077057, 'epoch': 28.2}
{'loss': 0.004, 'grad_norm': 4.437619686126709, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.0026480082888156176, 'loss_2': 0.001373291015625, 'loss_3': -16.43152618408203, 'loss_4': 0.3708183765411377, 'epoch': 28.21}
{'loss': 0.0073, 'grad_norm': 4.666309833526611, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.004427012056112289, 'loss_2': 0.00286102294921875, 'loss_3': -16.238521575927734, 'loss_4': 0.19067873060703278, 'epoch': 28.22}
{'loss': 0.007, 'grad_norm': 4.942735195159912, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.0038477510679513216, 'loss_2': 0.00319671630859375, 'loss_3': -16.171329498291016, 'loss_4': 0.16860181093215942, 'epoch': 28.22}
{'loss': 0.0077, 'grad_norm': 4.928469181060791, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.004307178780436516, 'loss_2': 0.0034027099609375, 'loss_3': -16.142868041992188, 'loss_4': -0.13377690315246582, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 17:16:53,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:16:53,808 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [1:59:47<05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:01,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013760336674749851, 'eval_runtime': 3.8017, 'eval_samples_per_second': 269.355, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010960795916616917, 'eval_loss_2': 0.0027995407581329346, 'eval_loss_3': -18.120433807373047, 'eval_loss_4': 0.11157314479351044, 'epoch': 28.23}
{'loss': 0.0033, 'grad_norm': 4.2768449783325195, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.001881986390799284, 'loss_2': 0.0013980865478515625, 'loss_3': -16.486217498779297, 'loss_4': -0.27199333906173706, 'epoch': 28.23}
{'loss': 0.0081, 'grad_norm': 5.134035110473633, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.005243944935500622, 'loss_2': 0.002864837646484375, 'loss_3': -16.47701072692871, 'loss_4': -0.03326445817947388, 'epoch': 28.24}
{'loss': 0.0088, 'grad_norm': 5.077390670776367, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.0038066450506448746, 'loss_2': 0.004993438720703125, 'loss_3': -16.425678253173828, 'loss_4': -0.11593735218048096, 'epoch': 28.24}
{'loss': 0.0099, 'grad_norm': 4.792320251464844, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.0032053329050540924, 'loss_2': 0.006744384765625, 'loss_3': -16.354324340820312, 'loss_4': 0.3199176490306854, 'epoch': 28.25}
{'loss': 0.0064, 'grad_norm': 7.655935764312744, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.00451064994558692, 'loss_2': 0.0018901824951171875, 'loss_3': -16.22988510131836, 'loss_4': 0.2910304367542267, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 17:17:01,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:01,159 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [1:59:55<05:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:08,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014039143919944763, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.338, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011167450807988644, 'eval_loss_2': 0.002871692180633545, 'eval_loss_3': -18.119077682495117, 'eval_loss_4': 0.08872769773006439, 'epoch': 28.26}
{'loss': 0.1749, 'grad_norm': 26.061254501342773, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.17430821061134338, 'loss_2': 0.0005917549133300781, 'loss_3': -16.253910064697266, 'loss_4': 0.576370358467102, 'epoch': 28.26}
{'loss': 0.0055, 'grad_norm': 4.645347595214844, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.0032695422414690256, 'loss_2': 0.00226593017578125, 'loss_3': -16.356727600097656, 'loss_4': -0.13060665130615234, 'epoch': 28.27}
{'loss': 0.0048, 'grad_norm': 4.520476818084717, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.003593145404011011, 'loss_2': 0.001239776611328125, 'loss_3': -16.26617431640625, 'loss_4': 0.18689784407615662, 'epoch': 28.27}
{'loss': 0.0053, 'grad_norm': 4.834131240844727, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.0024384907446801662, 'loss_2': 0.002864837646484375, 'loss_3': -16.386837005615234, 'loss_4': -0.0010148733854293823, 'epoch': 28.28}
{'loss': 0.0051, 'grad_norm': 4.8486328125, 'learning_rate': 1.75e-06, 'loss_1': 0.002650311915203929, 'loss_2': 0.00243377685546875, 'loss_3': -16.226314544677734, 'loss_4': 0.1846930831670761, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 17:17:08,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:08,499 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [2:00:02<05:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:15,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014330496080219746, 'eval_runtime': 3.8033, 'eval_samples_per_second': 269.241, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.011513759382069111, 'eval_loss_2': 0.0028167366981506348, 'eval_loss_3': -18.119070053100586, 'eval_loss_4': 0.049281518906354904, 'epoch': 28.28}
{'loss': 0.0126, 'grad_norm': 5.643041610717773, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.007787306327372789, 'loss_2': 0.004833221435546875, 'loss_3': -16.253582000732422, 'loss_4': -0.36778557300567627, 'epoch': 28.29}
{'loss': 0.0087, 'grad_norm': 4.811450958251953, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.0062868655659258366, 'loss_2': 0.0024051666259765625, 'loss_3': -16.303178787231445, 'loss_4': -0.23379209637641907, 'epoch': 28.3}
{'loss': 0.0035, 'grad_norm': 4.819445610046387, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.003064985852688551, 'loss_2': 0.00043773651123046875, 'loss_3': -16.209930419921875, 'loss_4': -0.2410428822040558, 'epoch': 28.3}
{'loss': 0.0097, 'grad_norm': 5.8526105880737305, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.007200051564723253, 'loss_2': 0.0024871826171875, 'loss_3': -16.380197525024414, 'loss_4': -0.5458704829216003, 'epoch': 28.31}
{'loss': 0.0056, 'grad_norm': 4.634421348571777, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.0028823446482419968, 'loss_2': 0.002742767333984375, 'loss_3': -16.343904495239258, 'loss_4': -0.09507177025079727, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 17:17:15,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:15,845 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [2:00:09<04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:23,193 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014705185778439045, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.86, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011850912123918533, 'eval_loss_2': 0.002854272723197937, 'eval_loss_3': -18.118255615234375, 'eval_loss_4': 0.03425423428416252, 'epoch': 28.31}
{'loss': 0.0057, 'grad_norm': 4.579803466796875, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.0015913356328383088, 'loss_2': 0.004093170166015625, 'loss_3': -16.396926879882812, 'loss_4': 0.07431187480688095, 'epoch': 28.32}
{'loss': 0.0683, 'grad_norm': 12.110452651977539, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.06440095603466034, 'loss_2': 0.00386810302734375, 'loss_3': -16.33623695373535, 'loss_4': 0.4982518255710602, 'epoch': 28.33}
{'loss': 0.0076, 'grad_norm': 5.699919700622559, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.005831294227391481, 'loss_2': 0.0017299652099609375, 'loss_3': -16.38186264038086, 'loss_4': -0.033910565078258514, 'epoch': 28.33}
{'loss': 0.0075, 'grad_norm': 19.812692642211914, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.0037229282315820456, 'loss_2': 0.003795623779296875, 'loss_3': -16.49585723876953, 'loss_4': 0.23129872977733612, 'epoch': 28.34}
{'loss': 0.0043, 'grad_norm': 4.260859489440918, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.0025794466491788626, 'loss_2': 0.00167083740234375, 'loss_3': -16.407615661621094, 'loss_4': 0.014524437487125397, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 17:17:23,194 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:23,194 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [2:00:17<04:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:30,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01472292561084032, 'eval_runtime': 3.8019, 'eval_samples_per_second': 269.341, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.011799167841672897, 'eval_loss_2': 0.0029237568378448486, 'eval_loss_3': -18.117618560791016, 'eval_loss_4': 0.04421152547001839, 'epoch': 28.34}
{'loss': 0.0042, 'grad_norm': 33.634647369384766, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.0033716110046952963, 'loss_2': 0.0007877349853515625, 'loss_3': -16.265228271484375, 'loss_4': 0.17596317827701569, 'epoch': 28.35}
{'loss': 0.0044, 'grad_norm': 5.706181049346924, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.0015917506534606218, 'loss_2': 0.0028324127197265625, 'loss_3': -16.338027954101562, 'loss_4': 0.19311556220054626, 'epoch': 28.35}
{'loss': 0.0052, 'grad_norm': 5.5004706382751465, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.004949528723955154, 'loss_2': 0.0002570152282714844, 'loss_3': -16.287002563476562, 'loss_4': 0.15269047021865845, 'epoch': 28.36}
{'loss': 0.0029, 'grad_norm': 4.660409450531006, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.0023564437869936228, 'loss_2': 0.0005221366882324219, 'loss_3': -16.321533203125, 'loss_4': -0.11138678342103958, 'epoch': 28.37}
{'loss': 0.012, 'grad_norm': 11.441473960876465, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.008279092609882355, 'loss_2': 0.00368499755859375, 'loss_3': -16.21524429321289, 'loss_4': 0.14568710327148438, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 17:17:30,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:30,540 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:24<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:37,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014367617666721344, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.536, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011459330096840858, 'eval_loss_2': 0.0029082894325256348, 'eval_loss_3': -18.12070655822754, 'eval_loss_4': 0.0523456446826458, 'epoch': 28.37}
{'loss': 0.0116, 'grad_norm': 5.820273399353027, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.005308905150741339, 'loss_2': 0.0063323974609375, 'loss_3': -16.38787841796875, 'loss_4': 0.18353065848350525, 'epoch': 28.38}
{'loss': 0.0029, 'grad_norm': 4.273970603942871, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.002353239804506302, 'loss_2': 0.0005207061767578125, 'loss_3': -16.445236206054688, 'loss_4': 0.018883362412452698, 'epoch': 28.38}
{'loss': 0.0108, 'grad_norm': 6.781185150146484, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.0056776609271764755, 'loss_2': 0.005146026611328125, 'loss_3': -16.242538452148438, 'loss_4': 0.2796640992164612, 'epoch': 28.39}
{'loss': 0.0118, 'grad_norm': 4.940471172332764, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.003947993274778128, 'loss_2': 0.0078125, 'loss_3': -16.421627044677734, 'loss_4': 0.04415814206004143, 'epoch': 28.4}
{'loss': 0.0034, 'grad_norm': 4.557364463806152, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.002985864644870162, 'loss_2': 0.0004379749298095703, 'loss_3': -16.25324249267578, 'loss_4': 0.06508549302816391, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 17:17:37,876 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:37,876 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:31<04:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:45,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014042733237147331, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01122533343732357, 'eval_loss_2': 0.002817399799823761, 'eval_loss_3': -18.121307373046875, 'eval_loss_4': 0.04768282175064087, 'epoch': 28.4}
{'loss': 0.0219, 'grad_norm': 9.064104080200195, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.019688807427883148, 'loss_2': 0.002193450927734375, 'loss_3': -16.257741928100586, 'loss_4': -0.21252740919589996, 'epoch': 28.41}
{'loss': 0.0217, 'grad_norm': 8.868815422058105, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.014129514805972576, 'loss_2': 0.007526397705078125, 'loss_3': -16.309158325195312, 'loss_4': 0.21210148930549622, 'epoch': 28.41}
{'loss': 0.0066, 'grad_norm': 4.406642913818359, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.0031169047579169273, 'loss_2': 0.003528594970703125, 'loss_3': -16.36058807373047, 'loss_4': 0.01188088208436966, 'epoch': 28.42}
{'loss': 0.0094, 'grad_norm': 4.325982093811035, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.002533507999032736, 'loss_2': 0.006870269775390625, 'loss_3': -16.361568450927734, 'loss_4': 0.14351366460323334, 'epoch': 28.42}
{'loss': 0.0156, 'grad_norm': 5.299532413482666, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.005461931228637695, 'loss_2': 0.01013946533203125, 'loss_3': -16.45870590209961, 'loss_4': 0.18966379761695862, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 17:17:45,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:45,224 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:39<04:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:52,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013721524737775326, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.285, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010899907909333706, 'eval_loss_2': 0.00282161682844162, 'eval_loss_3': -18.11920166015625, 'eval_loss_4': 0.06353751569986343, 'epoch': 28.43}
{'loss': 0.0105, 'grad_norm': 6.273653507232666, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.006646100431680679, 'loss_2': 0.0038700103759765625, 'loss_3': -16.259700775146484, 'loss_4': 0.3374258279800415, 'epoch': 28.44}
{'loss': 0.003, 'grad_norm': 4.456383228302002, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.0018401739653199911, 'loss_2': 0.0011434555053710938, 'loss_3': -16.323383331298828, 'loss_4': 0.26327943801879883, 'epoch': 28.44}
{'loss': 0.0074, 'grad_norm': 5.083880424499512, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.004635349381715059, 'loss_2': 0.0028095245361328125, 'loss_3': -16.344879150390625, 'loss_4': -0.1809411644935608, 'epoch': 28.45}
{'loss': 0.0083, 'grad_norm': 4.222413063049316, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.0024340269155800343, 'loss_2': 0.005859375, 'loss_3': -16.509784698486328, 'loss_4': 0.6290323138237, 'epoch': 28.45}
{'loss': 0.0053, 'grad_norm': 5.308902263641357, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.004714137874543667, 'loss_2': 0.0006356239318847656, 'loss_3': -16.174667358398438, 'loss_4': 0.14085271954536438, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 17:17:52,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:52,568 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:00:46<04:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:17:59,921 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013971706852316856, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.714, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010644306428730488, 'eval_loss_2': 0.003327399492263794, 'eval_loss_3': -18.11863899230957, 'eval_loss_4': 0.07981853187084198, 'epoch': 28.46}
{'loss': 0.0055, 'grad_norm': 4.673628330230713, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.0021023359149694443, 'loss_2': 0.0033779144287109375, 'loss_3': -16.43648910522461, 'loss_4': -0.006202362477779388, 'epoch': 28.47}
{'loss': 0.0113, 'grad_norm': 7.802882671356201, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.009953596629202366, 'loss_2': 0.00136566162109375, 'loss_3': -16.355636596679688, 'loss_4': -0.062070608139038086, 'epoch': 28.47}
{'loss': 0.0102, 'grad_norm': 4.486750602722168, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.005420604720711708, 'loss_2': 0.00473785400390625, 'loss_3': -16.269460678100586, 'loss_4': 0.38998696208000183, 'epoch': 28.48}
{'loss': 0.0072, 'grad_norm': 5.110276699066162, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.0044978042133152485, 'loss_2': 0.00274658203125, 'loss_3': -16.394630432128906, 'loss_4': 0.13742709159851074, 'epoch': 28.48}
{'loss': 0.006, 'grad_norm': 4.524858474731445, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.0029869431164115667, 'loss_2': 0.0029754638671875, 'loss_3': -16.44331169128418, 'loss_4': -0.05997519567608833, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 17:17:59,922 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:17:59,922 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:00:53<04:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:07,259 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014456826262176037, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.271, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010722155682742596, 'eval_loss_2': 0.003734670579433441, 'eval_loss_3': -18.11665153503418, 'eval_loss_4': 0.1052398830652237, 'epoch': 28.49}
{'loss': 0.0185, 'grad_norm': 7.933818340301514, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.016554556787014008, 'loss_2': 0.0019168853759765625, 'loss_3': -16.383590698242188, 'loss_4': 0.5203005075454712, 'epoch': 28.49}
{'loss': 0.0077, 'grad_norm': 4.916741847991943, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.005392470862716436, 'loss_2': 0.002277374267578125, 'loss_3': -16.436264038085938, 'loss_4': 0.10648440569639206, 'epoch': 28.5}
{'loss': 0.004, 'grad_norm': 5.098583698272705, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.002840217435732484, 'loss_2': 0.0011692047119140625, 'loss_3': -16.320940017700195, 'loss_4': -0.11279276013374329, 'epoch': 28.51}
{'loss': 0.0058, 'grad_norm': 4.593776226043701, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0029950719326734543, 'loss_2': 0.00278472900390625, 'loss_3': -16.132598876953125, 'loss_4': -0.05375298857688904, 'epoch': 28.51}
{'loss': 0.0113, 'grad_norm': 4.5674848556518555, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.006223869975656271, 'loss_2': 0.00511932373046875, 'loss_3': -16.245887756347656, 'loss_4': -0.007531311362981796, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 17:18:07,259 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:07,259 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:01:01<04:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:14,603 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014591999351978302, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.45, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010877079330384731, 'eval_loss_2': 0.003714919090270996, 'eval_loss_3': -18.113235473632812, 'eval_loss_4': 0.12783892452716827, 'epoch': 28.52}
{'loss': 0.0082, 'grad_norm': 5.7852559089660645, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.006409094203263521, 'loss_2': 0.0018157958984375, 'loss_3': -16.30370330810547, 'loss_4': 0.32176581025123596, 'epoch': 28.52}
{'loss': 0.0086, 'grad_norm': 4.517033576965332, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.005460694432258606, 'loss_2': 0.003116607666015625, 'loss_3': -16.225250244140625, 'loss_4': 0.3970046043395996, 'epoch': 28.53}
{'loss': 0.0096, 'grad_norm': 5.810491561889648, 'learning_rate': 1.5e-06, 'loss_1': 0.008261637762188911, 'loss_2': 0.0013217926025390625, 'loss_3': -16.232080459594727, 'loss_4': 0.19955012202262878, 'epoch': 28.53}
{'loss': 0.0062, 'grad_norm': 4.821032524108887, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.003993895370513201, 'loss_2': 0.00223541259765625, 'loss_3': -16.510986328125, 'loss_4': 0.29946163296699524, 'epoch': 28.54}
{'loss': 0.0084, 'grad_norm': 5.225407123565674, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.005951387342065573, 'loss_2': 0.0024547576904296875, 'loss_3': -16.37933349609375, 'loss_4': 0.33138930797576904, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 17:18:14,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:14,603 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:01:08<04:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:21,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01437852531671524, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.54, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01072967704385519, 'eval_loss_2': 0.0036488473415374756, 'eval_loss_3': -18.112911224365234, 'eval_loss_4': 0.13088612258434296, 'epoch': 28.55}
{'loss': 0.0045, 'grad_norm': 5.3756890296936035, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.00437129708006978, 'loss_2': 9.655952453613281e-05, 'loss_3': -16.268451690673828, 'loss_4': 0.48276495933532715, 'epoch': 28.55}
{'loss': 0.0096, 'grad_norm': 4.417087554931641, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.003327887272462249, 'loss_2': 0.006317138671875, 'loss_3': -16.393354415893555, 'loss_4': 0.3222580552101135, 'epoch': 28.56}
{'loss': 0.0062, 'grad_norm': 7.648221492767334, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.004017492290586233, 'loss_2': 0.002231597900390625, 'loss_3': -16.189105987548828, 'loss_4': 0.18290556967258453, 'epoch': 28.56}
{'loss': 0.0074, 'grad_norm': 5.200021266937256, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.006786478217691183, 'loss_2': 0.0006546974182128906, 'loss_3': -16.31442642211914, 'loss_4': 0.027997680008411407, 'epoch': 28.57}
{'loss': 0.0127, 'grad_norm': 5.967158317565918, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.012600678950548172, 'loss_2': 0.00013303756713867188, 'loss_3': -16.37641143798828, 'loss_4': 0.2138616144657135, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 17:18:21,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:21,942 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:01:16<04:12,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 17:18:29,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014420374296605587, 'eval_runtime': 4.0044, 'eval_samples_per_second': 255.716, 'eval_steps_per_second': 3.996, 'eval_loss_1': 0.01093415729701519, 'eval_loss_2': 0.0034862160682678223, 'eval_loss_3': -18.111980438232422, 'eval_loss_4': 0.13094280660152435, 'epoch': 28.58}
{'loss': 0.0074, 'grad_norm': 4.719013214111328, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.00703043770045042, 'loss_2': 0.0003337860107421875, 'loss_3': -16.33637237548828, 'loss_4': -0.09918472170829773, 'epoch': 28.58}
{'loss': 0.0075, 'grad_norm': 4.558900356292725, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.006588240619748831, 'loss_2': 0.000949859619140625, 'loss_3': -16.264188766479492, 'loss_4': -0.5415346622467041, 'epoch': 28.59}
{'loss': 0.0121, 'grad_norm': 4.739689350128174, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.0021233069710433483, 'loss_2': 0.00998687744140625, 'loss_3': -16.237688064575195, 'loss_4': 0.4028129577636719, 'epoch': 28.59}
{'loss': 0.0202, 'grad_norm': 12.449464797973633, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.018397917971014977, 'loss_2': 0.0017919540405273438, 'loss_3': -16.516559600830078, 'loss_4': -0.11505018919706345, 'epoch': 28.6}
{'loss': 0.0059, 'grad_norm': 4.89955997467041, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.004612600896507502, 'loss_2': 0.00125885009765625, 'loss_3': -16.50643539428711, 'loss_4': 0.2711585760116577, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 17:18:29,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:29,481 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:23<04:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:36,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014341146685183048, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01096485648304224, 'eval_loss_2': 0.003376290202140808, 'eval_loss_3': -18.107913970947266, 'eval_loss_4': 0.13136473298072815, 'epoch': 28.6}
{'loss': 0.0207, 'grad_norm': 10.616914749145508, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.02050161175429821, 'loss_2': 0.00016832351684570312, 'loss_3': -16.295124053955078, 'loss_4': 0.3112975060939789, 'epoch': 28.61}
{'loss': 0.0056, 'grad_norm': 5.24149751663208, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.0025197272188961506, 'loss_2': 0.00310516357421875, 'loss_3': -16.401845932006836, 'loss_4': 0.18072763085365295, 'epoch': 28.62}
{'loss': 0.0059, 'grad_norm': 4.510128498077393, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.004596203565597534, 'loss_2': 0.0013294219970703125, 'loss_3': -16.535526275634766, 'loss_4': 0.13082526624202728, 'epoch': 28.62}
{'loss': 0.0032, 'grad_norm': 4.496114730834961, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.0023006333503872156, 'loss_2': 0.0009021759033203125, 'loss_3': -16.37826156616211, 'loss_4': 0.018534719944000244, 'epoch': 28.63}
{'loss': 0.0087, 'grad_norm': 6.852184772491455, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.0054940590634942055, 'loss_2': 0.003231048583984375, 'loss_3': -16.352598190307617, 'loss_4': -0.2677145302295685, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 17:18:36,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:36,829 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:30<03:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:44,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014802259393036366, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011390489526093006, 'eval_loss_2': 0.0034117698669433594, 'eval_loss_3': -18.110681533813477, 'eval_loss_4': 0.13253659009933472, 'epoch': 28.63}
{'loss': 0.0055, 'grad_norm': 4.7523651123046875, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.0035054306499660015, 'loss_2': 0.0020389556884765625, 'loss_3': -16.492176055908203, 'loss_4': 0.10992459207773209, 'epoch': 28.64}
{'loss': 0.0099, 'grad_norm': 50.93324279785156, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.00839983019977808, 'loss_2': 0.001453399658203125, 'loss_3': -16.461139678955078, 'loss_4': 0.26531729102134705, 'epoch': 28.65}
{'loss': 0.0048, 'grad_norm': 4.639466285705566, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.004500519949942827, 'loss_2': 0.00026988983154296875, 'loss_3': -16.282310485839844, 'loss_4': 0.2647755444049835, 'epoch': 28.65}
{'loss': 0.0212, 'grad_norm': 12.790824890136719, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.018390389159321785, 'loss_2': 0.002796173095703125, 'loss_3': -16.24675750732422, 'loss_4': 0.47159743309020996, 'epoch': 28.66}
{'loss': 0.0117, 'grad_norm': 4.773852825164795, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.005573033355176449, 'loss_2': 0.0061187744140625, 'loss_3': -16.545852661132812, 'loss_4': 0.09468535333871841, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 17:18:44,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:44,175 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:38<03:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:51,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014723722822964191, 'eval_runtime': 3.7998, 'eval_samples_per_second': 269.485, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011534606106579304, 'eval_loss_2': 0.0031891167163848877, 'eval_loss_3': -18.113208770751953, 'eval_loss_4': 0.12744255363941193, 'epoch': 28.66}
{'loss': 0.0049, 'grad_norm': 5.082125663757324, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.004000889603048563, 'loss_2': 0.0008893013000488281, 'loss_3': -16.298255920410156, 'loss_4': 0.17117860913276672, 'epoch': 28.67}
{'loss': 0.0076, 'grad_norm': 4.633860111236572, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.0023327001836150885, 'loss_2': 0.005218505859375, 'loss_3': -16.425060272216797, 'loss_4': 0.30436164140701294, 'epoch': 28.67}
{'loss': 0.0122, 'grad_norm': 4.880879878997803, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.007843051105737686, 'loss_2': 0.00431060791015625, 'loss_3': -16.320627212524414, 'loss_4': -0.05903148651123047, 'epoch': 28.68}
{'loss': 0.0025, 'grad_norm': 4.401916980743408, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.0012459534918889403, 'loss_2': 0.001224517822265625, 'loss_3': -16.471996307373047, 'loss_4': -0.30464112758636475, 'epoch': 28.69}
{'loss': 0.0178, 'grad_norm': 7.758044719696045, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.01389923132956028, 'loss_2': 0.00389862060546875, 'loss_3': -16.287919998168945, 'loss_4': -0.5231122970581055, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 17:18:51,518 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:51,518 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:01:45<03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:18:58,856 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014610584825277328, 'eval_runtime': 3.7993, 'eval_samples_per_second': 269.52, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.011422272771596909, 'eval_loss_2': 0.00318831205368042, 'eval_loss_3': -18.113162994384766, 'eval_loss_4': 0.11811777949333191, 'epoch': 28.69}
{'loss': 0.0048, 'grad_norm': 4.26137113571167, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.003033527871593833, 'loss_2': 0.0017795562744140625, 'loss_3': -16.274499893188477, 'loss_4': 0.05132248252630234, 'epoch': 28.7}
{'loss': 0.0077, 'grad_norm': 5.952618598937988, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.005035966169089079, 'loss_2': 0.002704620361328125, 'loss_3': -16.373136520385742, 'loss_4': 0.340598464012146, 'epoch': 28.7}
{'loss': 0.013, 'grad_norm': 7.398231029510498, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.008034788072109222, 'loss_2': 0.004974365234375, 'loss_3': -16.237972259521484, 'loss_4': -0.2282109260559082, 'epoch': 28.71}
{'loss': 0.0073, 'grad_norm': 4.968177318572998, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.0043878983706235886, 'loss_2': 0.002925872802734375, 'loss_3': -16.366497039794922, 'loss_4': -0.006101340055465698, 'epoch': 28.72}
{'loss': 0.0094, 'grad_norm': 4.753969669342041, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.0034829580690711737, 'loss_2': 0.005950927734375, 'loss_3': -16.191144943237305, 'loss_4': 0.20284299552440643, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 17:18:58,857 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:18:58,857 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:01:52<03:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:06,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014138033613562584, 'eval_runtime': 3.7973, 'eval_samples_per_second': 269.664, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010946234688162804, 'eval_loss_2': 0.0031917989253997803, 'eval_loss_3': -18.11688995361328, 'eval_loss_4': 0.11592304706573486, 'epoch': 28.72}
{'loss': 0.0172, 'grad_norm': 12.878800392150879, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.01439391914755106, 'loss_2': 0.0028362274169921875, 'loss_3': -16.179183959960938, 'loss_4': 0.21211013197898865, 'epoch': 28.73}
{'loss': 0.0051, 'grad_norm': 4.875182628631592, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.002245018258690834, 'loss_2': 0.002834320068359375, 'loss_3': -16.51189422607422, 'loss_4': 0.6197932958602905, 'epoch': 28.73}
{'loss': 0.0069, 'grad_norm': 5.385750770568848, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.006250333972275257, 'loss_2': 0.0006256103515625, 'loss_3': -16.22347640991211, 'loss_4': -0.15719027817249298, 'epoch': 28.74}
{'loss': 0.0059, 'grad_norm': 5.246291637420654, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.0031537285540252924, 'loss_2': 0.0027065277099609375, 'loss_3': -16.478044509887695, 'loss_4': -0.2272396832704544, 'epoch': 28.74}
{'loss': 0.004, 'grad_norm': 5.1883978843688965, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.0033323524985462427, 'loss_2': 0.0007123947143554688, 'loss_3': -16.336620330810547, 'loss_4': 0.451449453830719, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 17:19:06,192 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:06,192 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:02:00<03:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:13,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014105824753642082, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.752, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.010940846987068653, 'eval_loss_2': 0.0031649768352508545, 'eval_loss_3': -18.122900009155273, 'eval_loss_4': 0.12677104771137238, 'epoch': 28.75}
{'loss': 0.0053, 'grad_norm': 4.257205009460449, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.004103125538676977, 'loss_2': 0.00122833251953125, 'loss_3': -16.323720932006836, 'loss_4': -0.37402427196502686, 'epoch': 28.76}
{'loss': 0.0089, 'grad_norm': 4.606208324432373, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.002035741927102208, 'loss_2': 0.0068511962890625, 'loss_3': -16.249858856201172, 'loss_4': -0.040297508239746094, 'epoch': 28.76}
{'loss': 0.012, 'grad_norm': 7.109382629394531, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.010764162987470627, 'loss_2': 0.0012149810791015625, 'loss_3': -16.510421752929688, 'loss_4': 0.23649320006370544, 'epoch': 28.77}
{'loss': 0.0086, 'grad_norm': 4.989026069641113, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.005460232496261597, 'loss_2': 0.0031414031982421875, 'loss_3': -16.435218811035156, 'loss_4': 0.11897526681423187, 'epoch': 28.77}
{'loss': 0.0081, 'grad_norm': 4.6362714767456055, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.003884176490828395, 'loss_2': 0.004180908203125, 'loss_3': -16.205554962158203, 'loss_4': 0.25350356101989746, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 17:19:13,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:13,531 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:02:07<03:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:20,874 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013743994757533073, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.095, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.010814366862177849, 'eval_loss_2': 0.0029296278953552246, 'eval_loss_3': -18.120990753173828, 'eval_loss_4': 0.1417790949344635, 'epoch': 28.78}
{'loss': 0.0095, 'grad_norm': 5.250491619110107, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.006749895866960287, 'loss_2': 0.002716064453125, 'loss_3': -16.343374252319336, 'loss_4': 0.13617554306983948, 'epoch': 28.78}
{'loss': 0.0103, 'grad_norm': 4.898806095123291, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.004786177538335323, 'loss_2': 0.0054931640625, 'loss_3': -16.210533142089844, 'loss_4': 0.21584919095039368, 'epoch': 28.79}
{'loss': 0.0044, 'grad_norm': 4.52564811706543, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.0017034824704751372, 'loss_2': 0.00269317626953125, 'loss_3': -16.40668296813965, 'loss_4': -0.14422942698001862, 'epoch': 28.8}
{'loss': 0.0113, 'grad_norm': 5.019692897796631, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.00576262641698122, 'loss_2': 0.005558013916015625, 'loss_3': -16.142879486083984, 'loss_4': 0.20952874422073364, 'epoch': 28.8}
{'loss': 0.0165, 'grad_norm': 5.590826034545898, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.006922449450939894, 'loss_2': 0.00960540771484375, 'loss_3': -16.386455535888672, 'loss_4': 0.3931286334991455, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 17:19:20,874 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:20,874 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:02:14<03:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:28,220 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013950055465102196, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.453, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.011044717393815517, 'eval_loss_2': 0.002905339002609253, 'eval_loss_3': -18.119401931762695, 'eval_loss_4': 0.1642385721206665, 'epoch': 28.81}
{'loss': 0.0093, 'grad_norm': 4.990948677062988, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.0040054721757769585, 'loss_2': 0.005340576171875, 'loss_3': -16.212570190429688, 'loss_4': 0.09183824062347412, 'epoch': 28.81}
{'loss': 0.0077, 'grad_norm': 4.7855024337768555, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.004382083658128977, 'loss_2': 0.003307342529296875, 'loss_3': -16.421966552734375, 'loss_4': 0.33913373947143555, 'epoch': 28.82}
{'loss': 0.0132, 'grad_norm': 4.643650531768799, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.0069635407999157906, 'loss_2': 0.00626373291015625, 'loss_3': -16.36046028137207, 'loss_4': 0.40508005023002625, 'epoch': 28.83}
{'loss': 0.0068, 'grad_norm': 4.548573017120361, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.003304319456219673, 'loss_2': 0.003467559814453125, 'loss_3': -16.316102981567383, 'loss_4': -0.12355521321296692, 'epoch': 28.83}
{'loss': 0.0042, 'grad_norm': 4.278157711029053, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.0036845318973064423, 'loss_2': 0.0005202293395996094, 'loss_3': -16.44636344909668, 'loss_4': -0.17894336581230164, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 17:19:28,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:28,221 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:22<03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:35,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014155518263578415, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.739, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.011205087415874004, 'eval_loss_2': 0.002950429916381836, 'eval_loss_3': -18.117252349853516, 'eval_loss_4': 0.16598419845104218, 'epoch': 28.84}
{'loss': 0.0063, 'grad_norm': 4.240715503692627, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.004230793099850416, 'loss_2': 0.002086639404296875, 'loss_3': -16.296985626220703, 'loss_4': 0.09000398218631744, 'epoch': 28.84}
{'loss': 0.0042, 'grad_norm': 4.822303295135498, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.003756799502298236, 'loss_2': 0.00047016143798828125, 'loss_3': -16.45326805114746, 'loss_4': -0.1425456404685974, 'epoch': 28.85}
{'loss': 0.0081, 'grad_norm': 4.801577091217041, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.003576735034584999, 'loss_2': 0.00447845458984375, 'loss_3': -16.35272216796875, 'loss_4': 0.20743635296821594, 'epoch': 28.85}
{'loss': 0.0097, 'grad_norm': 6.844527721405029, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.008223159238696098, 'loss_2': 0.00144195556640625, 'loss_3': -16.4638671875, 'loss_4': -0.01171673834323883, 'epoch': 28.86}
{'loss': 0.0058, 'grad_norm': 4.795204162597656, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.0036177237052470446, 'loss_2': 0.002231597900390625, 'loss_3': -16.414806365966797, 'loss_4': -0.12458716332912445, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 17:19:35,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:35,556 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:29<03:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:42,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014131913892924786, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.719, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.011074969545006752, 'eval_loss_2': 0.003056943416595459, 'eval_loss_3': -18.113574981689453, 'eval_loss_4': 0.17905114591121674, 'epoch': 28.87}
{'loss': 0.0029, 'grad_norm': 4.7831621170043945, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.0028053910937160254, 'loss_2': 0.0001266002655029297, 'loss_3': -16.278446197509766, 'loss_4': -0.10257263481616974, 'epoch': 28.87}
{'loss': 0.0041, 'grad_norm': 4.711252689361572, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.002712602959945798, 'loss_2': 0.0013484954833984375, 'loss_3': -16.44194984436035, 'loss_4': 0.24270018935203552, 'epoch': 28.88}
{'loss': 0.0035, 'grad_norm': 4.618561267852783, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.001976088620722294, 'loss_2': 0.00151824951171875, 'loss_3': -16.523244857788086, 'loss_4': 0.4335245192050934, 'epoch': 28.88}
{'loss': 0.0059, 'grad_norm': 4.347407341003418, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.002892877906560898, 'loss_2': 0.0030059814453125, 'loss_3': -16.23761749267578, 'loss_4': 0.14369510114192963, 'epoch': 28.89}
{'loss': 0.0067, 'grad_norm': 4.362464904785156, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.004641346633434296, 'loss_2': 0.002044677734375, 'loss_3': -16.225229263305664, 'loss_4': 0.23115584254264832, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 17:19:42,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:42,890 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:36<03:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:50,230 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014021189883351326, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.473, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.010646941140294075, 'eval_loss_2': 0.003374248743057251, 'eval_loss_3': -18.111087799072266, 'eval_loss_4': 0.1910357028245926, 'epoch': 28.9}
{'loss': 0.0066, 'grad_norm': 4.559450626373291, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.0034956226591020823, 'loss_2': 0.003139495849609375, 'loss_3': -16.269264221191406, 'loss_4': 0.21660703420639038, 'epoch': 28.9}
{'loss': 0.0101, 'grad_norm': 4.63394021987915, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.002908571856096387, 'loss_2': 0.007232666015625, 'loss_3': -16.547029495239258, 'loss_4': 0.1489608883857727, 'epoch': 28.91}
{'loss': 0.0071, 'grad_norm': 4.489803791046143, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.004466146696358919, 'loss_2': 0.0026397705078125, 'loss_3': -16.321964263916016, 'loss_4': 0.4485280513763428, 'epoch': 28.91}
{'loss': 0.0087, 'grad_norm': 5.967779636383057, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.006916772574186325, 'loss_2': 0.0017423629760742188, 'loss_3': -16.450572967529297, 'loss_4': 0.211480051279068, 'epoch': 28.92}
{'loss': 0.0046, 'grad_norm': 5.015533447265625, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.0035385037772357464, 'loss_2': 0.0010395050048828125, 'loss_3': -16.25906753540039, 'loss_4': 0.026379600167274475, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 17:19:50,230 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:50,230 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:44<03:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:19:57,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013817870989441872, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.296, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.010367059148848057, 'eval_loss_2': 0.0034508109092712402, 'eval_loss_3': -18.11245346069336, 'eval_loss_4': 0.20310567319393158, 'epoch': 28.92}
{'loss': 0.0093, 'grad_norm': 4.567508220672607, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.005291036795824766, 'loss_2': 0.00396728515625, 'loss_3': -16.186798095703125, 'loss_4': 0.12809401750564575, 'epoch': 28.93}
{'loss': 0.0093, 'grad_norm': 4.979307174682617, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.008321628905832767, 'loss_2': 0.0009641647338867188, 'loss_3': -16.277915954589844, 'loss_4': 0.6889208555221558, 'epoch': 28.94}
{'loss': 0.0063, 'grad_norm': 5.247410774230957, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.004363436251878738, 'loss_2': 0.001979827880859375, 'loss_3': -16.1156063079834, 'loss_4': -0.45249825716018677, 'epoch': 28.94}
{'loss': 0.0071, 'grad_norm': 4.525726318359375, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.0038474095053970814, 'loss_2': 0.003238677978515625, 'loss_3': -16.46964454650879, 'loss_4': 0.3381325602531433, 'epoch': 28.95}
{'loss': 0.0072, 'grad_norm': 4.767122745513916, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.004624222405254841, 'loss_2': 0.002582550048828125, 'loss_3': -16.497196197509766, 'loss_4': 0.4086114168167114, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 17:19:57,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:19:57,569 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:02:51<03:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:04,919 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013737984001636505, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.768, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010338673368096352, 'eval_loss_2': 0.0033993124961853027, 'eval_loss_3': -18.112903594970703, 'eval_loss_4': 0.2114540934562683, 'epoch': 28.95}
{'loss': 0.0098, 'grad_norm': 6.598211288452148, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.003905585967004299, 'loss_2': 0.005901336669921875, 'loss_3': -16.278701782226562, 'loss_4': 0.2966952323913574, 'epoch': 28.96}
{'loss': 0.0089, 'grad_norm': 6.081816673278809, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.007416967302560806, 'loss_2': 0.0014820098876953125, 'loss_3': -16.203968048095703, 'loss_4': -0.1554993987083435, 'epoch': 28.97}
{'loss': 0.0069, 'grad_norm': 4.565187454223633, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.0025738507974892855, 'loss_2': 0.004337310791015625, 'loss_3': -16.343120574951172, 'loss_4': 0.506248950958252, 'epoch': 28.97}
{'loss': 0.0028, 'grad_norm': 4.4376220703125, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.0022570197470486164, 'loss_2': 0.0005621910095214844, 'loss_3': -16.366315841674805, 'loss_4': 0.34061604738235474, 'epoch': 28.98}
{'loss': 0.0055, 'grad_norm': 4.331964492797852, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.002592044649645686, 'loss_2': 0.002872467041015625, 'loss_3': -16.36945343017578, 'loss_4': 0.027153581380844116, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 17:20:04,919 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:04,919 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:02:58<02:48,  1.01it/s][INFO|trainer.py:4226] 2025-01-21 17:20:11,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013773070648312569, 'eval_runtime': 3.7963, 'eval_samples_per_second': 269.736, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01039175782352686, 'eval_loss_2': 0.0033813118934631348, 'eval_loss_3': -18.119670867919922, 'eval_loss_4': 0.20778781175613403, 'epoch': 28.98}
{'loss': 0.0069, 'grad_norm': 5.29641056060791, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.006232290528714657, 'loss_2': 0.0006513595581054688, 'loss_3': -16.30417251586914, 'loss_4': 0.25913187861442566, 'epoch': 28.99}
{'loss': 0.004, 'grad_norm': 4.080018997192383, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0023496251087635756, 'loss_2': 0.0016956329345703125, 'loss_3': -16.481998443603516, 'loss_4': 0.3362526595592499, 'epoch': 28.99}
{'loss': 0.0156, 'grad_norm': 21.707382202148438, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.012732170522212982, 'loss_2': 0.002849578857421875, 'loss_3': -16.336620330810547, 'loss_4': 0.3185565769672394, 'epoch': 29.0}
{'loss': 0.004, 'grad_norm': 4.8512139320373535, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.00397731177508831, 'loss_2': 5.5670738220214844e-05, 'loss_3': -16.185585021972656, 'loss_4': 0.37952297925949097, 'epoch': 29.01}
{'loss': 0.0094, 'grad_norm': 5.64376163482666, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.004160756710916758, 'loss_2': 0.00525665283203125, 'loss_3': -16.444690704345703, 'loss_4': -0.24139806628227234, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 17:20:11,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:11,938 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:03:05<02:49,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:20:19,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013590611517429352, 'eval_runtime': 3.7991, 'eval_samples_per_second': 269.539, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.01024837139993906, 'eval_loss_2': 0.003342241048812866, 'eval_loss_3': -18.124591827392578, 'eval_loss_4': 0.20110738277435303, 'epoch': 29.01}
{'loss': 0.0095, 'grad_norm': 9.166990280151367, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.00431477278470993, 'loss_2': 0.005207061767578125, 'loss_3': -16.478174209594727, 'loss_4': -0.2689627408981323, 'epoch': 29.02}
{'loss': 0.0045, 'grad_norm': 4.625417709350586, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.004117514006793499, 'loss_2': 0.00041103363037109375, 'loss_3': -16.42471694946289, 'loss_4': 0.3439730107784271, 'epoch': 29.02}
{'loss': 0.008, 'grad_norm': 4.691357612609863, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.004502053372561932, 'loss_2': 0.003448486328125, 'loss_3': -16.305191040039062, 'loss_4': 0.47547850012779236, 'epoch': 29.03}
{'loss': 0.0067, 'grad_norm': 4.870241165161133, 'learning_rate': 1e-06, 'loss_1': 0.004178272560238838, 'loss_2': 0.002529144287109375, 'loss_3': -16.252195358276367, 'loss_4': 0.20389798283576965, 'epoch': 29.03}
{'loss': 0.0085, 'grad_norm': 5.401820659637451, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.005015173461288214, 'loss_2': 0.00350189208984375, 'loss_3': -16.340999603271484, 'loss_4': 0.30434608459472656, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 17:20:19,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:19,277 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:03:13<02:45,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:20:26,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013411561027169228, 'eval_runtime': 3.7975, 'eval_samples_per_second': 269.654, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010035858489573002, 'eval_loss_2': 0.003375701606273651, 'eval_loss_3': -18.128108978271484, 'eval_loss_4': 0.19526267051696777, 'epoch': 29.04}
{'loss': 0.0048, 'grad_norm': 5.1617207527160645, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.0031034257262945175, 'loss_2': 0.0016870498657226562, 'loss_3': -16.317119598388672, 'loss_4': 0.27804112434387207, 'epoch': 29.05}
{'loss': 0.0036, 'grad_norm': 5.155306816101074, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.003256908617913723, 'loss_2': 0.0003514289855957031, 'loss_3': -16.395601272583008, 'loss_4': -0.10572163760662079, 'epoch': 29.05}
{'loss': 0.0093, 'grad_norm': 4.766819953918457, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.00524947652593255, 'loss_2': 0.00406646728515625, 'loss_3': -16.47429656982422, 'loss_4': 0.2538512349128723, 'epoch': 29.06}
{'loss': 0.0172, 'grad_norm': 12.501614570617676, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.014452101662755013, 'loss_2': 0.0027332305908203125, 'loss_3': -16.218835830688477, 'loss_4': 0.19084200263023376, 'epoch': 29.06}
{'loss': 0.0131, 'grad_norm': 15.06602954864502, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.007646231446415186, 'loss_2': 0.005474090576171875, 'loss_3': -16.521732330322266, 'loss_4': -0.1870993971824646, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 17:20:26,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:26,610 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:20<02:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:33,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013440296985208988, 'eval_runtime': 3.7952, 'eval_samples_per_second': 269.812, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010206327773630619, 'eval_loss_2': 0.003233969211578369, 'eval_loss_3': -18.126171112060547, 'eval_loss_4': 0.1976408213376999, 'epoch': 29.07}
{'loss': 0.01, 'grad_norm': 5.343095779418945, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.007585535291582346, 'loss_2': 0.0024394989013671875, 'loss_3': -16.45404052734375, 'loss_4': 0.14190848171710968, 'epoch': 29.08}
{'loss': 0.003, 'grad_norm': 4.5798540115356445, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0024172901175916195, 'loss_2': 0.0005626678466796875, 'loss_3': -16.440401077270508, 'loss_4': 0.20299720764160156, 'epoch': 29.08}
{'loss': 0.0029, 'grad_norm': 4.230417251586914, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.0024227742105722427, 'loss_2': 0.00046372413635253906, 'loss_3': -16.307537078857422, 'loss_4': 0.4028662145137787, 'epoch': 29.09}
{'loss': 0.0904, 'grad_norm': 11.428278923034668, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.08980472385883331, 'loss_2': 0.0006313323974609375, 'loss_3': -16.511486053466797, 'loss_4': 0.494947612285614, 'epoch': 29.09}
{'loss': 0.0097, 'grad_norm': 5.136523246765137, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.009324672631919384, 'loss_2': 0.00041747093200683594, 'loss_3': -16.3011417388916, 'loss_4': 0.5286243557929993, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 17:20:33,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:33,945 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:27<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:41,287 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013432986102998257, 'eval_runtime': 3.8015, 'eval_samples_per_second': 269.368, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.01028840895742178, 'eval_loss_2': 0.003144577145576477, 'eval_loss_3': -18.12491798400879, 'eval_loss_4': 0.20221102237701416, 'epoch': 29.1}
{'loss': 0.0037, 'grad_norm': 4.783225059509277, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.0030313222669065, 'loss_2': 0.0006728172302246094, 'loss_3': -16.54706573486328, 'loss_4': 0.4294888973236084, 'epoch': 29.1}
{'loss': 0.004, 'grad_norm': 4.779757499694824, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.0024476831313222647, 'loss_2': 0.001598358154296875, 'loss_3': -16.41501235961914, 'loss_4': -0.04143214225769043, 'epoch': 29.11}
{'loss': 0.0151, 'grad_norm': 6.2464375495910645, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.00924959871917963, 'loss_2': 0.005870819091796875, 'loss_3': -16.414718627929688, 'loss_4': 0.2796939015388489, 'epoch': 29.12}
{'loss': 0.0066, 'grad_norm': 4.469924449920654, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.003614369546994567, 'loss_2': 0.003002166748046875, 'loss_3': -16.40432357788086, 'loss_4': 0.24199402332305908, 'epoch': 29.12}
{'loss': 0.0116, 'grad_norm': 4.504314422607422, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.003443371271714568, 'loss_2': 0.00820159912109375, 'loss_3': -16.471031188964844, 'loss_4': 0.24436743557453156, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 17:20:41,287 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:41,287 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:35<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:48,616 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013364626094698906, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.717, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01028261799365282, 'eval_loss_2': 0.0030820071697235107, 'eval_loss_3': -18.122406005859375, 'eval_loss_4': 0.21473652124404907, 'epoch': 29.13}
{'loss': 0.0132, 'grad_norm': 6.95560359954834, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.011297346092760563, 'loss_2': 0.0018663406372070312, 'loss_3': -16.12920379638672, 'loss_4': 0.4250817596912384, 'epoch': 29.13}
{'loss': 0.0028, 'grad_norm': 4.569636821746826, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.0021876487880945206, 'loss_2': 0.0005898475646972656, 'loss_3': -16.461151123046875, 'loss_4': 0.3736633360385895, 'epoch': 29.14}
{'loss': 0.0063, 'grad_norm': 4.552099227905273, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.002455563750118017, 'loss_2': 0.003849029541015625, 'loss_3': -16.367103576660156, 'loss_4': 0.22219595313072205, 'epoch': 29.15}
{'loss': 0.0108, 'grad_norm': 5.298753261566162, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.0051273163408041, 'loss_2': 0.00565338134765625, 'loss_3': -16.416027069091797, 'loss_4': 0.10832894593477249, 'epoch': 29.15}
{'loss': 0.0023, 'grad_norm': 5.14434289932251, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.0020618923008441925, 'loss_2': 0.0002582073211669922, 'loss_3': -16.329866409301758, 'loss_4': 0.040666498243808746, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 17:20:48,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:48,617 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:42<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:20:55,949 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01320401206612587, 'eval_runtime': 3.7983, 'eval_samples_per_second': 269.595, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010285023599863052, 'eval_loss_2': 0.0029189884662628174, 'eval_loss_3': -18.121623992919922, 'eval_loss_4': 0.2210693210363388, 'epoch': 29.16}
{'loss': 0.0078, 'grad_norm': 4.771406173706055, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.006634809076786041, 'loss_2': 0.00113677978515625, 'loss_3': -16.331302642822266, 'loss_4': -0.17041534185409546, 'epoch': 29.16}
{'loss': 0.0121, 'grad_norm': 4.918664455413818, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.002939548809081316, 'loss_2': 0.0091705322265625, 'loss_3': -16.40777587890625, 'loss_4': 0.05657769739627838, 'epoch': 29.17}
{'loss': 0.0048, 'grad_norm': 4.173099040985107, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.004336515907198191, 'loss_2': 0.00046443939208984375, 'loss_3': -16.305736541748047, 'loss_4': 0.3774186372756958, 'epoch': 29.17}
{'loss': 0.0054, 'grad_norm': 4.824766159057617, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.003789834212511778, 'loss_2': 0.0015687942504882812, 'loss_3': -16.464824676513672, 'loss_4': 0.17585285007953644, 'epoch': 29.18}
{'loss': 0.0056, 'grad_norm': 7.282060146331787, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.002557473722845316, 'loss_2': 0.00304412841796875, 'loss_3': -16.28338050842285, 'loss_4': 0.21713532507419586, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 17:20:55,949 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:20:55,950 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:03:49<02:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:03,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012966339476406574, 'eval_runtime': 3.799, 'eval_samples_per_second': 269.548, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010253160260617733, 'eval_loss_2': 0.0027131810784339905, 'eval_loss_3': -18.121152877807617, 'eval_loss_4': 0.23039421439170837, 'epoch': 29.19}
{'loss': 0.0115, 'grad_norm': 6.363165378570557, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.01140221580862999, 'loss_2': 0.00010466575622558594, 'loss_3': -16.41899871826172, 'loss_4': 0.7024258971214294, 'epoch': 29.19}
{'loss': 0.0075, 'grad_norm': 4.654035568237305, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.003655469510704279, 'loss_2': 0.003826141357421875, 'loss_3': -16.35272979736328, 'loss_4': 0.5367717146873474, 'epoch': 29.2}
{'loss': 0.0109, 'grad_norm': 8.683937072753906, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.010643201880156994, 'loss_2': 0.00030231475830078125, 'loss_3': -16.378265380859375, 'loss_4': -0.1782057285308838, 'epoch': 29.2}
{'loss': 0.0073, 'grad_norm': 6.047656536102295, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.0066778711043298244, 'loss_2': 0.0005998611450195312, 'loss_3': -16.31844711303711, 'loss_4': 0.09484114497900009, 'epoch': 29.21}
{'loss': 0.0219, 'grad_norm': 16.605712890625, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.019909877330064774, 'loss_2': 0.002025604248046875, 'loss_3': -16.718467712402344, 'loss_4': 0.22184748947620392, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 17:21:03,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:03,291 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:03:57<02:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:10,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012804945930838585, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.381, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.010184957645833492, 'eval_loss_2': 0.0026199892163276672, 'eval_loss_3': -18.121335983276367, 'eval_loss_4': 0.2442948967218399, 'epoch': 29.22}
{'loss': 0.0037, 'grad_norm': 4.8681511878967285, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.0027818146627396345, 'loss_2': 0.0008916854858398438, 'loss_3': -16.41040802001953, 'loss_4': 0.16398143768310547, 'epoch': 29.22}
{'loss': 0.0103, 'grad_norm': 5.965788841247559, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.007401581853628159, 'loss_2': 0.002902984619140625, 'loss_3': -16.174917221069336, 'loss_4': 0.18323473632335663, 'epoch': 29.23}
{'loss': 0.0116, 'grad_norm': 6.861437797546387, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.0067379409447312355, 'loss_2': 0.004901885986328125, 'loss_3': -16.38770866394043, 'loss_4': 0.35582005977630615, 'epoch': 29.23}
{'loss': 0.0062, 'grad_norm': 4.429779529571533, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.0024883211590349674, 'loss_2': 0.0036907196044921875, 'loss_3': -16.237384796142578, 'loss_4': 0.054140184074640274, 'epoch': 29.24}
{'loss': 0.0079, 'grad_norm': 19.356380462646484, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.006061611697077751, 'loss_2': 0.0018768310546875, 'loss_3': -16.225261688232422, 'loss_4': 0.2360278218984604, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 17:21:10,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:10,631 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:04:04<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:17,969 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012902485206723213, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.476, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01025735680013895, 'eval_loss_2': 0.0026451274752616882, 'eval_loss_3': -18.118633270263672, 'eval_loss_4': 0.2536669969558716, 'epoch': 29.24}
{'loss': 0.0069, 'grad_norm': 4.228335380554199, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.004733258858323097, 'loss_2': 0.002124786376953125, 'loss_3': -16.40648651123047, 'loss_4': -0.047283776104450226, 'epoch': 29.25}
{'loss': 0.0327, 'grad_norm': 12.900702476501465, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.027217922732234, 'loss_2': 0.005523681640625, 'loss_3': -16.394073486328125, 'loss_4': 0.1374441385269165, 'epoch': 29.26}
{'loss': 0.0842, 'grad_norm': 18.535324096679688, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.08205592632293701, 'loss_2': 0.00209808349609375, 'loss_3': -16.307514190673828, 'loss_4': 0.47776225209236145, 'epoch': 29.26}
{'loss': 0.0085, 'grad_norm': 4.8564934730529785, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.006908915471285582, 'loss_2': 0.0016193389892578125, 'loss_3': -16.24477195739746, 'loss_4': -0.014121286571025848, 'epoch': 29.27}
{'loss': 0.0082, 'grad_norm': 5.424771308898926, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.00678540114313364, 'loss_2': 0.00145721435546875, 'loss_3': -16.450132369995117, 'loss_4': -0.11629512906074524, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 17:21:17,969 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:17,970 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:04:11<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:25,310 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012944759801030159, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.265, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01031864620745182, 'eval_loss_2': 0.0026261135935783386, 'eval_loss_3': -18.117286682128906, 'eval_loss_4': 0.25934767723083496, 'epoch': 29.27}
{'loss': 0.0045, 'grad_norm': 4.482513427734375, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.002697510877624154, 'loss_2': 0.0017995834350585938, 'loss_3': -16.37646484375, 'loss_4': 0.3517893850803375, 'epoch': 29.28}
{'loss': 0.0064, 'grad_norm': 4.954380035400391, 'learning_rate': 7.5e-07, 'loss_1': 0.0030970806255936623, 'loss_2': 0.0032939910888671875, 'loss_3': -16.371471405029297, 'loss_4': -0.16099794209003448, 'epoch': 29.28}
{'loss': 0.0155, 'grad_norm': 7.782387733459473, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.014729920774698257, 'loss_2': 0.0007672309875488281, 'loss_3': -16.367290496826172, 'loss_4': 1.2540395259857178, 'epoch': 29.29}
{'loss': 0.003, 'grad_norm': 4.75300931930542, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.0028422875329852104, 'loss_2': 0.0001760721206665039, 'loss_3': -16.231128692626953, 'loss_4': 0.40338414907455444, 'epoch': 29.3}
{'loss': 0.0151, 'grad_norm': 9.1100435256958, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.011962395161390305, 'loss_2': 0.00318145751953125, 'loss_3': -16.221403121948242, 'loss_4': 0.31753915548324585, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 17:21:25,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:25,310 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:19<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:32,642 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012842974625527859, 'eval_runtime': 3.7961, 'eval_samples_per_second': 269.748, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.01036243885755539, 'eval_loss_2': 0.002480536699295044, 'eval_loss_3': -18.118511199951172, 'eval_loss_4': 0.25732046365737915, 'epoch': 29.3}
{'loss': 0.0029, 'grad_norm': 4.510651111602783, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.002840618835762143, 'loss_2': 1.1026859283447266e-05, 'loss_3': -16.39981460571289, 'loss_4': 0.3235477805137634, 'epoch': 29.31}
{'loss': 0.0058, 'grad_norm': 4.909976482391357, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.003139989450573921, 'loss_2': 0.0026264190673828125, 'loss_3': -16.3834228515625, 'loss_4': 0.570305347442627, 'epoch': 29.31}
{'loss': 0.0158, 'grad_norm': 5.6674041748046875, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.009971301071345806, 'loss_2': 0.005840301513671875, 'loss_3': -16.280733108520508, 'loss_4': 0.44169092178344727, 'epoch': 29.32}
{'loss': 0.0072, 'grad_norm': 5.324207305908203, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.0063737910240888596, 'loss_2': 0.0007801055908203125, 'loss_3': -16.066757202148438, 'loss_4': 0.1162051260471344, 'epoch': 29.33}
{'loss': 0.0056, 'grad_norm': 4.9114508628845215, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.003927425481379032, 'loss_2': 0.00164031982421875, 'loss_3': -16.4477481842041, 'loss_4': 0.2540169060230255, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 17:21:32,642 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:32,642 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:26<01:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:39,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01285153441131115, 'eval_runtime': 3.7966, 'eval_samples_per_second': 269.713, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.0103905675932765, 'eval_loss_2': 0.0024609677493572235, 'eval_loss_3': -18.117576599121094, 'eval_loss_4': 0.24823951721191406, 'epoch': 29.33}
{'loss': 0.0031, 'grad_norm': 4.325840950012207, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.002715497510507703, 'loss_2': 0.00033974647521972656, 'loss_3': -16.379070281982422, 'loss_4': 0.13823170959949493, 'epoch': 29.34}
{'loss': 0.004, 'grad_norm': 4.685794353485107, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.0030455999076366425, 'loss_2': 0.000995635986328125, 'loss_3': -16.499847412109375, 'loss_4': -0.07531987130641937, 'epoch': 29.34}
{'loss': 0.0111, 'grad_norm': 4.868631839752197, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.005755397025495768, 'loss_2': 0.00534820556640625, 'loss_3': -16.248628616333008, 'loss_4': -0.14005397260189056, 'epoch': 29.35}
{'loss': 0.0112, 'grad_norm': 5.157191753387451, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.005623969249427319, 'loss_2': 0.00555419921875, 'loss_3': -16.38154411315918, 'loss_4': 0.7323900461196899, 'epoch': 29.35}
{'loss': 0.005, 'grad_norm': 4.976613521575928, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.00305044068954885, 'loss_2': 0.0019407272338867188, 'loss_3': -16.330585479736328, 'loss_4': 0.30247431993484497, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 17:21:39,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:39,976 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:33<01:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:47,312 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012596020475029945, 'eval_runtime': 3.7965, 'eval_samples_per_second': 269.719, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.010188023559749126, 'eval_loss_2': 0.0024079978466033936, 'eval_loss_3': -18.121334075927734, 'eval_loss_4': 0.246118426322937, 'epoch': 29.36}
{'loss': 0.0135, 'grad_norm': 9.58859920501709, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.01069111842662096, 'loss_2': 0.002838134765625, 'loss_3': -16.292587280273438, 'loss_4': 0.28182679414749146, 'epoch': 29.37}
{'loss': 0.0059, 'grad_norm': 4.7613115310668945, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.0019796283449977636, 'loss_2': 0.0039043426513671875, 'loss_3': -16.222766876220703, 'loss_4': 0.7010505199432373, 'epoch': 29.37}
{'loss': 0.0139, 'grad_norm': 7.262022972106934, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.010927070863544941, 'loss_2': 0.0029468536376953125, 'loss_3': -16.34955596923828, 'loss_4': 0.6003091335296631, 'epoch': 29.38}
{'loss': 0.011, 'grad_norm': 4.681636810302734, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.006986407563090324, 'loss_2': 0.0040130615234375, 'loss_3': -16.340011596679688, 'loss_4': 0.18876028060913086, 'epoch': 29.38}
{'loss': 0.0109, 'grad_norm': 6.4103217124938965, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.009198888204991817, 'loss_2': 0.0017375946044921875, 'loss_3': -16.26474952697754, 'loss_4': 0.3883693814277649, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 17:21:47,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:47,312 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:41<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:21:54,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012545374222099781, 'eval_runtime': 3.7972, 'eval_samples_per_second': 269.674, 'eval_steps_per_second': 4.214, 'eval_loss_1': 0.01017909124493599, 'eval_loss_2': 0.002366282045841217, 'eval_loss_3': -18.123397827148438, 'eval_loss_4': 0.25116467475891113, 'epoch': 29.39}
{'loss': 0.0031, 'grad_norm': 4.650273323059082, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.001546442974358797, 'loss_2': 0.00159454345703125, 'loss_3': -16.556726455688477, 'loss_4': 0.30790168046951294, 'epoch': 29.4}
{'loss': 0.0094, 'grad_norm': 6.325896263122559, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.006689469330012798, 'loss_2': 0.002727508544921875, 'loss_3': -16.362735748291016, 'loss_4': 0.4313563108444214, 'epoch': 29.4}
{'loss': 0.0129, 'grad_norm': 15.197300910949707, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.009349283762276173, 'loss_2': 0.0035114288330078125, 'loss_3': -16.193401336669922, 'loss_4': -0.14763979613780975, 'epoch': 29.41}
{'loss': 0.007, 'grad_norm': 5.046400547027588, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.005689936690032482, 'loss_2': 0.0013227462768554688, 'loss_3': -16.170969009399414, 'loss_4': -0.0038838014006614685, 'epoch': 29.41}
{'loss': 0.0039, 'grad_norm': 20.353944778442383, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.001805350068025291, 'loss_2': 0.00205230712890625, 'loss_3': -16.545005798339844, 'loss_4': 0.3818889558315277, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 17:21:54,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:21:54,650 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:04:48<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:01,992 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012572892010211945, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010225252248346806, 'eval_loss_2': 0.0023476406931877136, 'eval_loss_3': -18.124664306640625, 'eval_loss_4': 0.2590143382549286, 'epoch': 29.42}
{'loss': 0.0065, 'grad_norm': 5.074192047119141, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.005492690950632095, 'loss_2': 0.0010099411010742188, 'loss_3': -16.501113891601562, 'loss_4': 0.5926529169082642, 'epoch': 29.42}
{'loss': 0.0042, 'grad_norm': 4.573232650756836, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.0028057368472218513, 'loss_2': 0.0013589859008789062, 'loss_3': -16.472457885742188, 'loss_4': -0.096266970038414, 'epoch': 29.43}
{'loss': 0.0135, 'grad_norm': 4.774688720703125, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.004231254570186138, 'loss_2': 0.00930023193359375, 'loss_3': -16.376285552978516, 'loss_4': 0.42444518208503723, 'epoch': 29.44}
{'loss': 0.0084, 'grad_norm': 4.644608020782471, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.00275346077978611, 'loss_2': 0.0055999755859375, 'loss_3': -16.384201049804688, 'loss_4': -0.04684818536043167, 'epoch': 29.44}
{'loss': 0.0115, 'grad_norm': 5.65440559387207, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.007799409795552492, 'loss_2': 0.003673553466796875, 'loss_3': -16.327957153320312, 'loss_4': 0.0714348554611206, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 17:22:01,992 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:01,993 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:04:55<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:09,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012613058090209961, 'eval_runtime': 3.7953, 'eval_samples_per_second': 269.811, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.0102744335308671, 'eval_loss_2': 0.002338625490665436, 'eval_loss_3': -18.125837326049805, 'eval_loss_4': 0.2613051235675812, 'epoch': 29.45}
{'loss': 0.0061, 'grad_norm': 5.134038925170898, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.005116881337016821, 'loss_2': 0.000957489013671875, 'loss_3': -16.424768447875977, 'loss_4': 0.669782280921936, 'epoch': 29.45}
{'loss': 0.0064, 'grad_norm': 4.8301005363464355, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.004541993606835604, 'loss_2': 0.0018444061279296875, 'loss_3': -16.352848052978516, 'loss_4': -0.06564058363437653, 'epoch': 29.46}
{'loss': 0.0107, 'grad_norm': 4.607191562652588, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.0037504443898797035, 'loss_2': 0.00690460205078125, 'loss_3': -16.453523635864258, 'loss_4': 0.5171610116958618, 'epoch': 29.47}
{'loss': 0.0056, 'grad_norm': 5.070557117462158, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.002720372751355171, 'loss_2': 0.002838134765625, 'loss_3': -16.211692810058594, 'loss_4': -0.3221890330314636, 'epoch': 29.47}
{'loss': 0.0116, 'grad_norm': 8.344436645507812, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.011461857706308365, 'loss_2': 0.00010776519775390625, 'loss_3': -16.38190460205078, 'loss_4': 0.060986921191215515, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 17:22:09,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:09,327 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:05:03<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:16,669 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012757392600178719, 'eval_runtime': 3.7985, 'eval_samples_per_second': 269.578, 'eval_steps_per_second': 4.212, 'eval_loss_1': 0.010356695391237736, 'eval_loss_2': 0.002400696277618408, 'eval_loss_3': -18.12580108642578, 'eval_loss_4': 0.25564974546432495, 'epoch': 29.48}
{'loss': 0.0088, 'grad_norm': 6.463792324066162, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.008376335725188255, 'loss_2': 0.00037479400634765625, 'loss_3': -16.16408920288086, 'loss_4': 0.2657153010368347, 'epoch': 29.48}
{'loss': 0.006, 'grad_norm': 4.606391906738281, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.003188052447512746, 'loss_2': 0.002773284912109375, 'loss_3': -16.33108139038086, 'loss_4': 0.22073425352573395, 'epoch': 29.49}
{'loss': 0.0144, 'grad_norm': 9.95482063293457, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.013421008363366127, 'loss_2': 0.0009388923645019531, 'loss_3': -16.20165252685547, 'loss_4': 0.011572107672691345, 'epoch': 29.49}
{'loss': 0.0081, 'grad_norm': 4.555245876312256, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.0020201499573886395, 'loss_2': 0.00605010986328125, 'loss_3': -16.38675880432129, 'loss_4': 0.22806695103645325, 'epoch': 29.5}
{'loss': 0.0123, 'grad_norm': 7.2155656814575195, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.011300187557935715, 'loss_2': 0.0009551048278808594, 'loss_3': -16.381288528442383, 'loss_4': 0.12059977650642395, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 17:22:16,669 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:16,669 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:05:10<01:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:24,006 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01288842223584652, 'eval_runtime': 3.798, 'eval_samples_per_second': 269.614, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.01044166274368763, 'eval_loss_2': 0.0024467594921588898, 'eval_loss_3': -18.126354217529297, 'eval_loss_4': 0.25268471240997314, 'epoch': 29.51}
{'loss': 0.0039, 'grad_norm': 4.4828948974609375, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.002486094133928418, 'loss_2': 0.00145721435546875, 'loss_3': -16.4012451171875, 'loss_4': 0.1894453465938568, 'epoch': 29.51}
{'loss': 0.0081, 'grad_norm': 4.728818893432617, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.005271674133837223, 'loss_2': 0.00281524658203125, 'loss_3': -16.430774688720703, 'loss_4': 0.15964066982269287, 'epoch': 29.52}
{'loss': 0.004, 'grad_norm': 13.81554889678955, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.003497914643958211, 'loss_2': 0.0005426406860351562, 'loss_3': -16.436012268066406, 'loss_4': 0.380168616771698, 'epoch': 29.52}
{'loss': 0.0046, 'grad_norm': 4.517297267913818, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.0018406823510304093, 'loss_2': 0.0027751922607421875, 'loss_3': -16.49205780029297, 'loss_4': 0.9900276064872742, 'epoch': 29.53}
{'loss': 0.0085, 'grad_norm': 8.188924789428711, 'learning_rate': 5e-07, 'loss_1': 0.0063521661795675755, 'loss_2': 0.0021514892578125, 'loss_3': -16.373910903930664, 'loss_4': 0.4875994324684143, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 17:22:24,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:24,007 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:17<01:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:31,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012948604300618172, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.883, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010462666861712933, 'eval_loss_2': 0.0024859383702278137, 'eval_loss_3': -18.12671661376953, 'eval_loss_4': 0.25214430689811707, 'epoch': 29.53}
{'loss': 0.0092, 'grad_norm': 4.782567024230957, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.004210489336401224, 'loss_2': 0.0049896240234375, 'loss_3': -16.251998901367188, 'loss_4': 0.36278706789016724, 'epoch': 29.54}
{'loss': 0.013, 'grad_norm': 6.988637447357178, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.007690512575209141, 'loss_2': 0.005279541015625, 'loss_3': -16.30438995361328, 'loss_4': 0.3168570399284363, 'epoch': 29.55}
{'loss': 0.0128, 'grad_norm': 5.068281650543213, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.011111517436802387, 'loss_2': 0.0016546249389648438, 'loss_3': -16.373825073242188, 'loss_4': 0.045676231384277344, 'epoch': 29.55}
{'loss': 0.006, 'grad_norm': 4.497582912445068, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.0017344353254884481, 'loss_2': 0.004314422607421875, 'loss_3': -16.440677642822266, 'loss_4': 0.2932738661766052, 'epoch': 29.56}
{'loss': 0.0099, 'grad_norm': 4.535201072692871, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.003235630691051483, 'loss_2': 0.0066375732421875, 'loss_3': -16.236175537109375, 'loss_4': -0.19285543262958527, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 17:22:31,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:31,339 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:25<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:38,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013053888455033302, 'eval_runtime': 3.8003, 'eval_samples_per_second': 269.45, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010518220253288746, 'eval_loss_2': 0.002535667270421982, 'eval_loss_3': -18.125743865966797, 'eval_loss_4': 0.252104789018631, 'epoch': 29.56}
{'loss': 0.0021, 'grad_norm': 4.520595550537109, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.0017798024928197265, 'loss_2': 0.00032639503479003906, 'loss_3': -16.40060043334961, 'loss_4': 0.26070964336395264, 'epoch': 29.57}
{'loss': 0.0124, 'grad_norm': 5.532266616821289, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.006891155149787664, 'loss_2': 0.0054779052734375, 'loss_3': -16.292049407958984, 'loss_4': 0.28942158818244934, 'epoch': 29.58}
{'loss': 0.0048, 'grad_norm': 4.721591472625732, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.002569406758993864, 'loss_2': 0.002277374267578125, 'loss_3': -16.223432540893555, 'loss_4': 0.2526136338710785, 'epoch': 29.58}
{'loss': 0.008, 'grad_norm': 4.77122688293457, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.003653507912531495, 'loss_2': 0.004390716552734375, 'loss_3': -16.413454055786133, 'loss_4': 0.24421826004981995, 'epoch': 29.59}
{'loss': 0.0071, 'grad_norm': 4.441532135009766, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.002969160908833146, 'loss_2': 0.004154205322265625, 'loss_3': -16.230424880981445, 'loss_4': -0.002274245023727417, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 17:22:38,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:38,677 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:32<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:22:46,022 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01332923024892807, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.236, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.010683882050216198, 'eval_loss_2': 0.0026453472673892975, 'eval_loss_3': -18.12405014038086, 'eval_loss_4': 0.2499062716960907, 'epoch': 29.59}
{'loss': 0.0053, 'grad_norm': 8.504826545715332, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.003333803964778781, 'loss_2': 0.00200653076171875, 'loss_3': -16.499813079833984, 'loss_4': 0.39729875326156616, 'epoch': 29.6}
{'loss': 0.0113, 'grad_norm': 6.103864669799805, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.008198290131986141, 'loss_2': 0.003055572509765625, 'loss_3': -16.40687370300293, 'loss_4': 0.1882893443107605, 'epoch': 29.6}
{'loss': 0.004, 'grad_norm': 4.854780673980713, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.0028886704239994287, 'loss_2': 0.0010805130004882812, 'loss_3': -16.40709114074707, 'loss_4': 0.3775178790092468, 'epoch': 29.61}
{'loss': 0.0097, 'grad_norm': 4.932491302490234, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.004541585221886635, 'loss_2': 0.0051116943359375, 'loss_3': -16.384376525878906, 'loss_4': 0.25118377804756165, 'epoch': 29.62}
{'loss': 0.0024, 'grad_norm': 4.649226188659668, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.0020741226617246866, 'loss_2': 0.00034546852111816406, 'loss_3': -16.501102447509766, 'loss_4': 0.21377035975456238, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 17:22:46,022 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:46,022 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:39<01:02,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:22:53,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013529736548662186, 'eval_runtime': 3.7955, 'eval_samples_per_second': 269.795, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.01072477363049984, 'eval_loss_2': 0.002804964780807495, 'eval_loss_3': -18.12382698059082, 'eval_loss_4': 0.24880848824977875, 'epoch': 29.62}
{'loss': 0.0093, 'grad_norm': 4.884040355682373, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.003350501647219062, 'loss_2': 0.00597381591796875, 'loss_3': -16.311824798583984, 'loss_4': 0.19810843467712402, 'epoch': 29.63}
{'loss': 0.0053, 'grad_norm': 4.944302082061768, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.0036525935865938663, 'loss_2': 0.0016679763793945312, 'loss_3': -16.43148422241211, 'loss_4': 0.4680813252925873, 'epoch': 29.63}
{'loss': 0.0099, 'grad_norm': 4.752987384796143, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.00560015719383955, 'loss_2': 0.00431060791015625, 'loss_3': -16.334814071655273, 'loss_4': -0.08291184157133102, 'epoch': 29.64}
{'loss': 0.0112, 'grad_norm': 5.146242618560791, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.008805768564343452, 'loss_2': 0.002422332763671875, 'loss_3': -16.286357879638672, 'loss_4': 0.592113733291626, 'epoch': 29.65}
{'loss': 0.0237, 'grad_norm': 16.565258026123047, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.02123245969414711, 'loss_2': 0.00250244140625, 'loss_3': -16.227317810058594, 'loss_4': 0.19335071742534637, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 17:22:53,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:22:53,347 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:05:47<00:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:00,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013666050508618355, 'eval_runtime': 3.7957, 'eval_samples_per_second': 269.781, 'eval_steps_per_second': 4.215, 'eval_loss_1': 0.0106909004971385, 'eval_loss_2': 0.002975150942802429, 'eval_loss_3': -18.123245239257812, 'eval_loss_4': 0.2497079074382782, 'epoch': 29.65}
{'loss': 0.0048, 'grad_norm': 4.78839635848999, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.0035861297510564327, 'loss_2': 0.0011892318725585938, 'loss_3': -16.516189575195312, 'loss_4': 0.5942373275756836, 'epoch': 29.66}
{'loss': 0.0061, 'grad_norm': 4.523266792297363, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.003399462904781103, 'loss_2': 0.0026702880859375, 'loss_3': -16.26654815673828, 'loss_4': 0.3671855926513672, 'epoch': 29.66}
{'loss': 0.0036, 'grad_norm': 4.3858795166015625, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.0031496228184551, 'loss_2': 0.0004520416259765625, 'loss_3': -16.366025924682617, 'loss_4': -0.4150547981262207, 'epoch': 29.67}
{'loss': 0.0026, 'grad_norm': 4.395342826843262, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.002294513862580061, 'loss_2': 0.000316619873046875, 'loss_3': -16.413360595703125, 'loss_4': 0.6335298418998718, 'epoch': 29.67}
{'loss': 0.0051, 'grad_norm': 4.378339767456055, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.0026995548978447914, 'loss_2': 0.0023708343505859375, 'loss_3': -16.4127140045166, 'loss_4': 0.5062841176986694, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 17:23:00,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:00,680 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:05:54<00:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:08,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013801067136228085, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.429, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010672897100448608, 'eval_loss_2': 0.0031281709671020508, 'eval_loss_3': -18.12342643737793, 'eval_loss_4': 0.249411478638649, 'epoch': 29.68}
{'loss': 0.0057, 'grad_norm': 5.004714488983154, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.004033196251839399, 'loss_2': 0.0016651153564453125, 'loss_3': -16.417585372924805, 'loss_4': 0.6099057197570801, 'epoch': 29.69}
{'loss': 0.0075, 'grad_norm': 4.257022380828857, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.005096686538308859, 'loss_2': 0.0023975372314453125, 'loss_3': -16.272441864013672, 'loss_4': -0.020845994353294373, 'epoch': 29.69}
{'loss': 0.0156, 'grad_norm': 5.990115165710449, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.007907668128609657, 'loss_2': 0.007659912109375, 'loss_3': -16.315046310424805, 'loss_4': 0.3012745678424835, 'epoch': 29.7}
{'loss': 0.0054, 'grad_norm': 4.596094608306885, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.0016750083304941654, 'loss_2': 0.003688812255859375, 'loss_3': -16.49933433532715, 'loss_4': 0.2707717716693878, 'epoch': 29.7}
{'loss': 0.0075, 'grad_norm': 5.188976764678955, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.0056191710755229, 'loss_2': 0.001850128173828125, 'loss_3': -16.392261505126953, 'loss_4': 0.005010738968849182, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 17:23:08,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:08,023 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:06:01<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:15,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013858401216566563, 'eval_runtime': 3.7954, 'eval_samples_per_second': 269.799, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010684573091566563, 'eval_loss_2': 0.003173828125, 'eval_loss_3': -18.122676849365234, 'eval_loss_4': 0.24459315836429596, 'epoch': 29.71}
{'loss': 0.0124, 'grad_norm': 5.351338863372803, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.004180895164608955, 'loss_2': 0.008209228515625, 'loss_3': -16.375152587890625, 'loss_4': 0.1535167694091797, 'epoch': 29.72}
{'loss': 0.0096, 'grad_norm': 5.43126916885376, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.0065432358533144, 'loss_2': 0.00302886962890625, 'loss_3': -16.30350685119629, 'loss_4': 0.06744557619094849, 'epoch': 29.72}
{'loss': 0.0126, 'grad_norm': 5.191991806030273, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.005028029438108206, 'loss_2': 0.0075531005859375, 'loss_3': -16.390439987182617, 'loss_4': 0.13248351216316223, 'epoch': 29.73}
{'loss': 0.0129, 'grad_norm': 5.829555511474609, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.009303299710154533, 'loss_2': 0.00356292724609375, 'loss_3': -16.252737045288086, 'loss_4': -0.2847473621368408, 'epoch': 29.73}
{'loss': 0.0058, 'grad_norm': 4.251090049743652, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.0034095668233931065, 'loss_2': 0.0023956298828125, 'loss_3': -16.547170639038086, 'loss_4': 0.5081596374511719, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 17:23:15,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:15,357 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:06:09<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:22,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013799046166241169, 'eval_runtime': 3.7992, 'eval_samples_per_second': 269.53, 'eval_steps_per_second': 4.211, 'eval_loss_1': 0.01064971648156643, 'eval_loss_2': 0.0031493306159973145, 'eval_loss_3': -18.12329864501953, 'eval_loss_4': 0.24277746677398682, 'epoch': 29.74}
{'loss': 0.006, 'grad_norm': 4.495145320892334, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.003410943318158388, 'loss_2': 0.002593994140625, 'loss_3': -16.471805572509766, 'loss_4': 0.35151344537734985, 'epoch': 29.74}
{'loss': 0.0051, 'grad_norm': 5.270223617553711, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.0032951459288597107, 'loss_2': 0.0017995834350585938, 'loss_3': -16.556259155273438, 'loss_4': 0.5882477760314941, 'epoch': 29.75}
{'loss': 0.0182, 'grad_norm': 5.462103366851807, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.012886280193924904, 'loss_2': 0.00531005859375, 'loss_3': -16.74028968811035, 'loss_4': 0.32191604375839233, 'epoch': 29.76}
{'loss': 0.0106, 'grad_norm': 4.743283271789551, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.004526849836111069, 'loss_2': 0.0060882568359375, 'loss_3': -16.357467651367188, 'loss_4': 0.6268224716186523, 'epoch': 29.76}
{'loss': 0.0047, 'grad_norm': 4.466866970062256, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.004608040675520897, 'loss_2': 6.878376007080078e-05, 'loss_3': -16.396007537841797, 'loss_4': 0.19584637880325317, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 17:23:22,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:22,688 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:06:16<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:30,017 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013759580440819263, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.965, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010679539293050766, 'eval_loss_2': 0.003080040216445923, 'eval_loss_3': -18.12335777282715, 'eval_loss_4': 0.24085019528865814, 'epoch': 29.77}
{'loss': 0.0069, 'grad_norm': 4.5254058837890625, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.0021846191957592964, 'loss_2': 0.00469207763671875, 'loss_3': -16.343223571777344, 'loss_4': 0.45292985439300537, 'epoch': 29.77}
{'loss': 0.0762, 'grad_norm': 12.04059886932373, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.07377398014068604, 'loss_2': 0.002437591552734375, 'loss_3': -16.424165725708008, 'loss_4': 0.24433663487434387, 'epoch': 29.78}
{'loss': 0.0028, 'grad_norm': 4.86277961730957, 'learning_rate': 2.5e-07, 'loss_1': 0.0023912678007036448, 'loss_2': 0.00040149688720703125, 'loss_3': -16.512502670288086, 'loss_4': -0.017675213515758514, 'epoch': 29.78}
{'loss': 0.0137, 'grad_norm': 4.812057018280029, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.004590730182826519, 'loss_2': 0.0091552734375, 'loss_3': -16.28426170349121, 'loss_4': 0.2685948610305786, 'epoch': 29.79}
{'loss': 0.006, 'grad_norm': 5.099761962890625, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.005965248681604862, 'loss_2': 4.2557716369628906e-05, 'loss_3': -16.312786102294922, 'loss_4': 0.3942098617553711, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 17:23:30,017 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:30,017 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:23<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:37,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013750246725976467, 'eval_runtime': 3.795, 'eval_samples_per_second': 269.826, 'eval_steps_per_second': 4.216, 'eval_loss_1': 0.010709084570407867, 'eval_loss_2': 0.0030411630868911743, 'eval_loss_3': -18.124122619628906, 'eval_loss_4': 0.23982194066047668, 'epoch': 29.8}
{'loss': 0.0048, 'grad_norm': 5.238909721374512, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.0032418263144791126, 'loss_2': 0.0015201568603515625, 'loss_3': -16.28497886657715, 'loss_4': -0.06487336754798889, 'epoch': 29.8}
{'loss': 0.0075, 'grad_norm': 4.273571491241455, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.0031968539115041494, 'loss_2': 0.004337310791015625, 'loss_3': -16.312721252441406, 'loss_4': 0.3558485507965088, 'epoch': 29.81}
{'loss': 0.0069, 'grad_norm': 4.573111534118652, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.004222237039357424, 'loss_2': 0.002685546875, 'loss_3': -16.387409210205078, 'loss_4': 0.1635684072971344, 'epoch': 29.81}
{'loss': 0.0056, 'grad_norm': 4.411386966705322, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.004109218250960112, 'loss_2': 0.001468658447265625, 'loss_3': -16.362468719482422, 'loss_4': 0.35288992524147034, 'epoch': 29.82}
{'loss': 0.0189, 'grad_norm': 7.852965831756592, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.014913400635123253, 'loss_2': 0.00395965576171875, 'loss_3': -16.250930786132812, 'loss_4': 0.08547867834568024, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 17:23:37,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:37,349 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:31<00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:44,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013714496046304703, 'eval_runtime': 3.7945, 'eval_samples_per_second': 269.865, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010677520185709, 'eval_loss_2': 0.003036975860595703, 'eval_loss_3': -18.123455047607422, 'eval_loss_4': 0.23731616139411926, 'epoch': 29.83}
{'loss': 0.0058, 'grad_norm': 4.7969584465026855, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.0029092077165842056, 'loss_2': 0.002857208251953125, 'loss_3': -16.38729476928711, 'loss_4': 0.20280766487121582, 'epoch': 29.83}
{'loss': 0.0038, 'grad_norm': 4.5847578048706055, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.0017787065589800477, 'loss_2': 0.00203704833984375, 'loss_3': -16.25168228149414, 'loss_4': -0.06809795647859573, 'epoch': 29.84}
{'loss': 0.0063, 'grad_norm': 4.526444435119629, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.0037559980992227793, 'loss_2': 0.002574920654296875, 'loss_3': -16.524581909179688, 'loss_4': 0.06539618968963623, 'epoch': 29.84}
{'loss': 0.0056, 'grad_norm': 5.2938232421875, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.005302388221025467, 'loss_2': 0.00029277801513671875, 'loss_3': -16.501609802246094, 'loss_4': 0.2065296173095703, 'epoch': 29.85}
{'loss': 0.0034, 'grad_norm': 4.103790283203125, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.00243386160582304, 'loss_2': 0.0010051727294921875, 'loss_3': -16.274173736572266, 'loss_4': 0.14853422343730927, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 17:23:44,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:44,686 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:38<00:20,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 17:23:52,010 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013706550933420658, 'eval_runtime': 3.7926, 'eval_samples_per_second': 269.998, 'eval_steps_per_second': 4.219, 'eval_loss_1': 0.01062159426510334, 'eval_loss_2': 0.0030849575996398926, 'eval_loss_3': -18.123046875, 'eval_loss_4': 0.23852117359638214, 'epoch': 29.85}
{'loss': 0.0118, 'grad_norm': 8.456087112426758, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.010279528796672821, 'loss_2': 0.00156402587890625, 'loss_3': -16.40092658996582, 'loss_4': 0.3457128405570984, 'epoch': 29.86}
{'loss': 0.0271, 'grad_norm': 10.231461524963379, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.026505565270781517, 'loss_2': 0.0006418228149414062, 'loss_3': -16.3081111907959, 'loss_4': 0.12717881798744202, 'epoch': 29.87}
{'loss': 0.0035, 'grad_norm': 5.105583667755127, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.002669482259079814, 'loss_2': 0.0007805824279785156, 'loss_3': -16.197490692138672, 'loss_4': -0.20821616053581238, 'epoch': 29.87}
{'loss': 0.0091, 'grad_norm': 5.1191301345825195, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.004970851819962263, 'loss_2': 0.00409698486328125, 'loss_3': -16.425132751464844, 'loss_4': 0.09742312133312225, 'epoch': 29.88}
{'loss': 0.0052, 'grad_norm': 4.7438201904296875, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.0022423863410949707, 'loss_2': 0.00299835205078125, 'loss_3': -16.454822540283203, 'loss_4': 0.4656450152397156, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 17:23:52,010 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:52,011 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:06:45<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:23:59,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0137456264346838, 'eval_runtime': 3.7982, 'eval_samples_per_second': 269.604, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.010617394931614399, 'eval_loss_2': 0.003128230571746826, 'eval_loss_3': -18.123329162597656, 'eval_loss_4': 0.23814323544502258, 'epoch': 29.88}
{'loss': 0.0063, 'grad_norm': 5.258978843688965, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.006039091851562262, 'loss_2': 0.00025463104248046875, 'loss_3': -16.351238250732422, 'loss_4': 0.2112768292427063, 'epoch': 29.89}
{'loss': 0.0159, 'grad_norm': 10.830724716186523, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.010031726211309433, 'loss_2': 0.005828857421875, 'loss_3': -16.325210571289062, 'loss_4': 0.1582917869091034, 'epoch': 29.9}
{'loss': 0.01, 'grad_norm': 5.843717575073242, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.006768894847482443, 'loss_2': 0.0032520294189453125, 'loss_3': -16.429920196533203, 'loss_4': -0.3923822343349457, 'epoch': 29.9}
{'loss': 0.0081, 'grad_norm': 4.782686710357666, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.004874680656939745, 'loss_2': 0.00318145751953125, 'loss_3': -16.06554412841797, 'loss_4': 0.19034570455551147, 'epoch': 29.91}
{'loss': 0.004, 'grad_norm': 4.752018451690674, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.0029564243741333485, 'loss_2': 0.001071929931640625, 'loss_3': -16.439720153808594, 'loss_4': 0.14120784401893616, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 17:23:59,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:23:59,351 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:06:53<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:06,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013741044327616692, 'eval_runtime': 3.7931, 'eval_samples_per_second': 269.964, 'eval_steps_per_second': 4.218, 'eval_loss_1': 0.010615123435854912, 'eval_loss_2': 0.00312592089176178, 'eval_loss_3': -18.12279510498047, 'eval_loss_4': 0.23685279488563538, 'epoch': 29.91}
{'loss': 0.0079, 'grad_norm': 4.4254584312438965, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.003314527915790677, 'loss_2': 0.0045623779296875, 'loss_3': -16.432960510253906, 'loss_4': 0.34269875288009644, 'epoch': 29.92}
{'loss': 0.0113, 'grad_norm': 6.242184638977051, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.008682946674525738, 'loss_2': 0.0026092529296875, 'loss_3': -16.441818237304688, 'loss_4': 0.4980345368385315, 'epoch': 29.92}
{'loss': 0.0071, 'grad_norm': 5.101836681365967, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.006833781022578478, 'loss_2': 0.0003027915954589844, 'loss_3': -16.241943359375, 'loss_4': 0.20260074734687805, 'epoch': 29.93}
{'loss': 0.0157, 'grad_norm': 7.151288032531738, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.010478104464709759, 'loss_2': 0.0052032470703125, 'loss_3': -16.169044494628906, 'loss_4': 0.11892817914485931, 'epoch': 29.94}
{'loss': 0.0094, 'grad_norm': 4.5942463874816895, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.0045881024561822414, 'loss_2': 0.00476837158203125, 'loss_3': -16.610084533691406, 'loss_4': 0.4579821825027466, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 17:24:06,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:06,681 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:07:00<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 17:24:14,014 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013695481233298779, 'eval_runtime': 3.7937, 'eval_samples_per_second': 269.92, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010576476342976093, 'eval_loss_2': 0.0031190067529678345, 'eval_loss_3': -18.122699737548828, 'eval_loss_4': 0.23505271971225739, 'epoch': 29.94}
{'loss': 0.0064, 'grad_norm': 5.22321891784668, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.004455068614333868, 'loss_2': 0.0019016265869140625, 'loss_3': -16.312532424926758, 'loss_4': 0.24660877883434296, 'epoch': 29.95}
{'loss': 0.0099, 'grad_norm': 5.7631096839904785, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.005003414582461119, 'loss_2': 0.00485992431640625, 'loss_3': -16.199174880981445, 'loss_4': 0.3436899185180664, 'epoch': 29.95}
{'loss': 0.0092, 'grad_norm': 4.1913652420043945, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.004219346214085817, 'loss_2': 0.00501251220703125, 'loss_3': -16.193464279174805, 'loss_4': 0.48028576374053955, 'epoch': 29.96}
{'loss': 0.0035, 'grad_norm': 4.516306400299072, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.0018772865878418088, 'loss_2': 0.00160980224609375, 'loss_3': -16.39041519165039, 'loss_4': 0.06785646080970764, 'epoch': 29.97}
{'loss': 0.0151, 'grad_norm': 7.467982769012451, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.011601666919887066, 'loss_2': 0.003520965576171875, 'loss_3': -16.332862854003906, 'loss_4': 0.1678219884634018, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 17:24:14,014 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:14,014 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:07<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 17:24:20,990 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01371605321764946, 'eval_runtime': 3.7942, 'eval_samples_per_second': 269.885, 'eval_steps_per_second': 4.217, 'eval_loss_1': 0.010576586239039898, 'eval_loss_2': 0.0031394660472869873, 'eval_loss_3': -18.122220993041992, 'eval_loss_4': 0.23411281406879425, 'epoch': 29.97}
{'loss': 0.0046, 'grad_norm': 4.6875, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.002832054626196623, 'loss_2': 0.0017232894897460938, 'loss_3': -16.44802474975586, 'loss_4': 0.7404221296310425, 'epoch': 29.98}
{'loss': 0.0107, 'grad_norm': 6.474554061889648, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.009777468629181385, 'loss_2': 0.0008821487426757812, 'loss_3': -16.414031982421875, 'loss_4': 0.5268905758857727, 'epoch': 29.98}
{'loss': 0.0281, 'grad_norm': 9.232690811157227, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.020494911819696426, 'loss_2': 0.00759124755859375, 'loss_3': -16.209199905395508, 'loss_4': 0.3052019476890564, 'epoch': 29.99}
{'loss': 0.0064, 'grad_norm': 5.234076976776123, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.006069578230381012, 'loss_2': 0.000301361083984375, 'loss_3': -16.298866271972656, 'loss_4': 0.49961018562316895, 'epoch': 29.99}
{'loss': 0.0176, 'grad_norm': 11.119770050048828, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.009234708733856678, 'loss_2': 0.00841522216796875, 'loss_3': -16.51647186279297, 'loss_4': 0.4259244203567505, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 17:24:20,990 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:20,990 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:11<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 17:24:24,791 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.013727670535445213, 'eval_runtime': 3.8005, 'eval_samples_per_second': 269.438, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.010598198510706425, 'eval_loss_2': 0.0031294748187065125, 'eval_loss_3': -18.122203826904297, 'eval_loss_4': 0.23369958996772766, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 17:24:24,792 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/checkpoint-2815 (score: 0.00988253764808178).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:11<00:00,  1.48s/it]
{'train_runtime': 7632.4221, 'train_samples_per_second': 43.15, 'train_steps_per_second': 0.676, 'train_loss': 0.04446019921715772, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 17:24:24,876 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64
[INFO|configuration_utils.py:420] 2025-01-21 17:24:24,877 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 17:24:25,361 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 17:24:25,362 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 17:24:25,363 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl3_gr-wneg64/special_tokens_map.json
01/21/2025 17:24:25 - INFO - __main__ -   ***** Train results *****
01/21/2025 17:24:25 - INFO - __main__ -     epoch = 30.0
01/21/2025 17:24:25 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 17:24:25 - INFO - __main__ -     train_loss = 0.04446019921715772
01/21/2025 17:24:25 - INFO - __main__ -     train_runtime = 7632.4221
01/21/2025 17:24:25 - INFO - __main__ -     train_samples_per_second = 43.15
01/21/2025 17:24:25 - INFO - __main__ -     train_steps_per_second = 0.676
01/21/2025 17:24:25 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 17:24:25,579 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 17:24:25,579 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 17:24:25,579 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.56it/s]
01/21/2025 17:24:29 - INFO - __main__ -   ***** Eval results *****
01/21/2025 17:24:29 - INFO - __main__ -     epoch = 30.0
01/21/2025 17:24:29 - INFO - __main__ -     eval_loss = 0.00988253764808178
01/21/2025 17:24:29 - INFO - __main__ -     eval_loss_1 = 0.0074276006780564785
01/21/2025 17:24:29 - INFO - __main__ -     eval_loss_2 = 0.0024549365043640137
01/21/2025 17:24:29 - INFO - __main__ -     eval_loss_3 = -18.21697998046875
01/21/2025 17:24:29 - INFO - __main__ -     eval_loss_4 = 1.1835525035858154
01/21/2025 17:24:29 - INFO - __main__ -     eval_runtime = 3.7942
01/21/2025 17:24:29 - INFO - __main__ -     eval_samples_per_second = 269.883
01/21/2025 17:24:29 - INFO - __main__ -     eval_steps_per_second = 4.217
