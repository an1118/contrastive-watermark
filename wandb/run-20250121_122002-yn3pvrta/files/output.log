  0%|                                                                                                                                                                                                                                        | 0/5160 [00:00<?, ?it/s][WARNING|logging.py:313] 2025-01-21 12:20:02,881 >> You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:04<1:06:33,  1.29it/s][INFO|trainer.py:4226] 2025-01-21 12:20:07,135 >>
{'loss': 3.0608, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 2.9839625358581543, 'loss_2': 0.07684326171875, 'loss_3': -13.70328140258789, 'loss_4': 9.949840545654297, 'epoch': 0.01}
{'loss': 3.4159, 'grad_norm': nan, 'learning_rate': 3e-05, 'loss_1': 3.3325419425964355, 'loss_2': 0.08331298828125, 'loss_3': -13.331350326538086, 'loss_4': 9.92608642578125, 'epoch': 0.01}
{'loss': 3.4014, 'grad_norm': inf, 'learning_rate': 3e-05, 'loss_1': 3.3325207233428955, 'loss_2': 0.06884765625, 'loss_3': -13.476580619812012, 'loss_4': 9.631412506103516, 'epoch': 0.02}
{'loss': 2.989, 'grad_norm': 143.43560791015625, 'learning_rate': 2.999418604651163e-05, 'loss_1': 2.922377109527588, 'loss_2': 0.066650390625, 'loss_3': -13.746009826660156, 'loss_4': 9.592080116271973, 'epoch': 0.02}
{'loss': 3.4101, 'grad_norm': 136.20730590820312, 'learning_rate': 2.9988372093023255e-05, 'loss_1': 3.3412365913391113, 'loss_2': 0.06890869140625, 'loss_3': -13.681958198547363, 'loss_4': 9.484638214111328, 'epoch': 0.03}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:07,135 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:07,135 >>   Batch size = 64
  0%|▏                                                                                                                                                                                                                             | 5/5160 [00:08<1:06:33,  1.29it/s][INFO|trainer.py:3910] 2025-01-21 12:20:10,934 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-5
[INFO|configuration_utils.py:420] 2025-01-21 12:20:10,936 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-5/config.json                                                                               
{'eval_loss': 1.6231402158737183, 'eval_runtime': 3.7978, 'eval_samples_per_second': 269.627, 'eval_steps_per_second': 4.213, 'eval_loss_1': 1.5569000244140625, 'eval_loss_2': 0.06624031066894531, 'eval_loss_3': -17.953819274902344, 'eval_loss_4': 7.610342502593994, 'epoch': 0.03}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:11,462 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-5/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:11,463 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:11,464 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-5/special_tokens_map.json
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:13<1:35:10,  1.11s/it][INFO|trainer.py:4226] 2025-01-21 12:20:15,934 >>
{'loss': 3.0968, 'grad_norm': 137.1215057373047, 'learning_rate': 2.9982558139534887e-05, 'loss_1': 3.0336384773254395, 'loss_2': 0.06317138671875, 'loss_3': -14.02107048034668, 'loss_4': 8.273065567016602, 'epoch': 0.03}
{'loss': 2.8967, 'grad_norm': 133.36917114257812, 'learning_rate': 2.9976744186046512e-05, 'loss_1': 2.8272769451141357, 'loss_2': 0.06939697265625, 'loss_3': -14.613136291503906, 'loss_4': 7.949534893035889, 'epoch': 0.04}
{'loss': 2.7283, 'grad_norm': 127.56985473632812, 'learning_rate': 2.997093023255814e-05, 'loss_1': 2.6520986557006836, 'loss_2': 0.076171875, 'loss_3': -14.722501754760742, 'loss_4': 6.996748924255371, 'epoch': 0.05}
{'loss': 2.567, 'grad_norm': 128.00851440429688, 'learning_rate': 2.996511627906977e-05, 'loss_1': 2.496799945831299, 'loss_2': 0.0701904296875, 'loss_3': -14.985294342041016, 'loss_4': 7.049566268920898, 'epoch': 0.05}
{'loss': 2.4041, 'grad_norm': 109.0740966796875, 'learning_rate': 2.9959302325581394e-05, 'loss_1': 2.3335368633270264, 'loss_2': 0.070556640625, 'loss_3': -14.881887435913086, 'loss_4': 6.92634391784668, 'epoch': 0.06}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:15,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:15,934 >>   Batch size = 64
  0%|▍                                                                                                                                                                                                                            | 10/5160 [00:16<1:35:10,  1.11s/it][INFO|trainer.py:3910] 2025-01-21 12:20:19,744 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-10
[INFO|configuration_utils.py:420] 2025-01-21 12:20:19,745 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-10/config.json                                                                              
{'eval_loss': 1.06170654296875, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.846, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.9923248291015625, 'eval_loss_2': 0.0693817138671875, 'eval_loss_3': -18.331262588500977, 'eval_loss_4': 6.58936882019043, 'epoch': 0.06}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:20,210 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-10/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:20,211 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-10/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:20,212 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-10/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:21,104 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-5] due to args.save_total_limit
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:21<1:39:17,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:20:24,755 >>
{'loss': 2.0756, 'grad_norm': 115.57970428466797, 'learning_rate': 2.9953488372093026e-05, 'loss_1': 2.006147861480713, 'loss_2': 0.0694580078125, 'loss_3': -15.145212173461914, 'loss_4': 7.161923408508301, 'epoch': 0.06}
{'loss': 2.1242, 'grad_norm': 116.27294921875, 'learning_rate': 2.994767441860465e-05, 'loss_1': 2.0583600997924805, 'loss_2': 0.0657958984375, 'loss_3': -15.040316581726074, 'loss_4': 6.546085357666016, 'epoch': 0.07}
{'loss': 1.971, 'grad_norm': 112.14286804199219, 'learning_rate': 2.994186046511628e-05, 'loss_1': 1.907501459121704, 'loss_2': 0.0634765625, 'loss_3': -15.153460502624512, 'loss_4': 7.619767189025879, 'epoch': 0.08}
{'loss': 1.7471, 'grad_norm': 106.15127563476562, 'learning_rate': 2.9936046511627906e-05, 'loss_1': 1.6895411014556885, 'loss_2': 0.057525634765625, 'loss_3': -15.152189254760742, 'loss_4': 7.2142229080200195, 'epoch': 0.08}
{'loss': 1.6213, 'grad_norm': 115.52961730957031, 'learning_rate': 2.9930232558139534e-05, 'loss_1': 1.5577841997146606, 'loss_2': 0.0634765625, 'loss_3': -15.209174156188965, 'loss_4': 7.968839645385742, 'epoch': 0.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:24,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:24,755 >>   Batch size = 64
  0%|▋                                                                                                                                                                                                                            | 15/5160 [00:25<1:39:17,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:20:28,554 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-15
[INFO|configuration_utils.py:420] 2025-01-21 12:20:28,556 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-15/config.json                                                                              
{'eval_loss': 0.6347042322158813, 'eval_runtime': 3.7976, 'eval_samples_per_second': 269.647, 'eval_steps_per_second': 4.213, 'eval_loss_1': 0.5798985362052917, 'eval_loss_2': 0.054805755615234375, 'eval_loss_3': -18.23687171936035, 'eval_loss_4': 7.882015228271484, 'epoch': 0.09}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:28,991 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-15/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:28,992 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-15/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:28,992 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-15/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:29,813 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-10] due to args.save_total_limit
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:30<1:39:08,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:20:33,460 >>
{'loss': 1.7908, 'grad_norm': 119.97489929199219, 'learning_rate': 2.9924418604651166e-05, 'loss_1': 1.7278841733932495, 'loss_2': 0.06292724609375, 'loss_3': -14.989360809326172, 'loss_4': 8.424823760986328, 'epoch': 0.09}
{'loss': 1.9035, 'grad_norm': 117.03862762451172, 'learning_rate': 2.991860465116279e-05, 'loss_1': 1.8512120246887207, 'loss_2': 0.05224609375, 'loss_3': -14.88294506072998, 'loss_4': 8.386467933654785, 'epoch': 0.1}
{'loss': 1.6837, 'grad_norm': 114.10928344726562, 'learning_rate': 2.991279069767442e-05, 'loss_1': 1.6327462196350098, 'loss_2': 0.050994873046875, 'loss_3': -15.20118522644043, 'loss_4': 9.12548828125, 'epoch': 0.1}
{'loss': 1.5096, 'grad_norm': 120.25212860107422, 'learning_rate': 2.9906976744186045e-05, 'loss_1': 1.4665769338607788, 'loss_2': 0.042999267578125, 'loss_3': -15.204753875732422, 'loss_4': 8.290146827697754, 'epoch': 0.11}
{'loss': 1.1315, 'grad_norm': 96.93343353271484, 'learning_rate': 2.9901162790697674e-05, 'loss_1': 1.089903712272644, 'loss_2': 0.04156494140625, 'loss_3': -15.545461654663086, 'loss_4': 7.028221130371094, 'epoch': 0.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:33,460 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:33,460 >>   Batch size = 64
  0%|▊                                                                                                                                                                                                                            | 20/5160 [00:34<1:39:08,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:20:37,267 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-20
[INFO|configuration_utils.py:420] 2025-01-21 12:20:37,270 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-20/config.json                                                                              
{'eval_loss': 0.5100795030593872, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.47096362709999084, 'eval_loss_2': 0.03911590576171875, 'eval_loss_3': -18.183956146240234, 'eval_loss_4': 8.2113037109375, 'epoch': 0.12}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:37,793 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-20/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:37,794 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-20/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:37,794 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-20/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:38,698 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-15] due to args.save_total_limit
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:39<1:40:19,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:20:42,356 >>
{'loss': 1.2516, 'grad_norm': 115.24484252929688, 'learning_rate': 2.9895348837209303e-05, 'loss_1': 1.208409070968628, 'loss_2': 0.043212890625, 'loss_3': -15.449928283691406, 'loss_4': 8.193275451660156, 'epoch': 0.12}
{'loss': 1.0342, 'grad_norm': 95.1222915649414, 'learning_rate': 2.988953488372093e-05, 'loss_1': 0.9888342618942261, 'loss_2': 0.04541015625, 'loss_3': -15.497719764709473, 'loss_4': 8.11398696899414, 'epoch': 0.13}
{'loss': 0.8299, 'grad_norm': 97.66398620605469, 'learning_rate': 2.988372093023256e-05, 'loss_1': 0.7945036292076111, 'loss_2': 0.035369873046875, 'loss_3': -15.691024780273438, 'loss_4': 7.682412147521973, 'epoch': 0.13}
{'loss': 0.9077, 'grad_norm': 103.29533386230469, 'learning_rate': 2.9877906976744185e-05, 'loss_1': 0.874613344669342, 'loss_2': 0.033050537109375, 'loss_3': -15.443111419677734, 'loss_4': 8.514411926269531, 'epoch': 0.14}
{'loss': 0.7817, 'grad_norm': 95.90323638916016, 'learning_rate': 2.9872093023255814e-05, 'loss_1': 0.7501864433288574, 'loss_2': 0.031524658203125, 'loss_3': -15.48180103302002, 'loss_4': 8.13845443725586, 'epoch': 0.15}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:42,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:42,356 >>   Batch size = 64
  0%|█                                                                                                                                                                                                                            | 25/5160 [00:43<1:40:19,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:20:46,158 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-25
[INFO|configuration_utils.py:420] 2025-01-21 12:20:46,159 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-25/config.json                                                                              
{'eval_loss': 0.20907926559448242, 'eval_runtime': 3.8, 'eval_samples_per_second': 269.471, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.17859315872192383, 'eval_loss_2': 0.030486106872558594, 'eval_loss_3': -18.27518653869629, 'eval_loss_4': 8.005448341369629, 'epoch': 0.15}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:46,604 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-25/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:46,606 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-25/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:46,606 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-25/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:47,437 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-20] due to args.save_total_limit
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:48<1:39:36,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:20:51,115 >>
{'loss': 0.7457, 'grad_norm': 93.14518737792969, 'learning_rate': 2.9866279069767442e-05, 'loss_1': 0.7103654742240906, 'loss_2': 0.035308837890625, 'loss_3': -15.371025085449219, 'loss_4': 8.382826805114746, 'epoch': 0.15}
{'loss': 0.7085, 'grad_norm': 86.56645202636719, 'learning_rate': 2.986046511627907e-05, 'loss_1': 0.6768167614936829, 'loss_2': 0.03167724609375, 'loss_3': -15.302118301391602, 'loss_4': 8.284198760986328, 'epoch': 0.16}
{'loss': 0.5592, 'grad_norm': 86.9115982055664, 'learning_rate': 2.98546511627907e-05, 'loss_1': 0.5330894589424133, 'loss_2': 0.026092529296875, 'loss_3': -15.156951904296875, 'loss_4': 7.0754899978637695, 'epoch': 0.16}
{'loss': 0.5561, 'grad_norm': 83.5687255859375, 'learning_rate': 2.9848837209302325e-05, 'loss_1': 0.5341729521751404, 'loss_2': 0.0219573974609375, 'loss_3': -15.028155326843262, 'loss_4': 6.971747875213623, 'epoch': 0.17}
{'loss': 0.3678, 'grad_norm': 61.78752517700195, 'learning_rate': 2.9843023255813954e-05, 'loss_1': 0.3590368628501892, 'loss_2': 0.0087432861328125, 'loss_3': -15.310083389282227, 'loss_4': 7.7680816650390625, 'epoch': 0.17}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:51,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:51,115 >>   Batch size = 64
  1%|█▎                                                                                                                                                                                                                           | 30/5160 [00:52<1:39:36,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:20:54,933 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-30
[INFO|configuration_utils.py:420] 2025-01-21 12:20:54,936 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-30/config.json                                                                              
{'eval_loss': 0.1295490711927414, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.314, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.11494354158639908, 'eval_loss_2': 0.014605522155761719, 'eval_loss_3': -18.12244987487793, 'eval_loss_4': 6.334150791168213, 'epoch': 0.17}
[INFO|modeling_utils.py:2988] 2025-01-21 12:20:55,403 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-30/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:20:55,405 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-30/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:20:55,405 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-30/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:20:56,297 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-25] due to args.save_total_limit
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [00:57<1:39:47,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:20:59,956 >>
{'loss': 0.7972, 'grad_norm': 92.0310287475586, 'learning_rate': 2.9837209302325582e-05, 'loss_1': 0.7825047373771667, 'loss_2': 0.0146484375, 'loss_3': -14.783123016357422, 'loss_4': 7.86508846282959, 'epoch': 0.18}
{'loss': 0.438, 'grad_norm': 67.21617889404297, 'learning_rate': 2.983139534883721e-05, 'loss_1': 0.4236903488636017, 'loss_2': 0.01428985595703125, 'loss_3': -14.869060516357422, 'loss_4': 5.282848358154297, 'epoch': 0.19}
{'loss': 0.533, 'grad_norm': 81.1355972290039, 'learning_rate': 2.9825581395348836e-05, 'loss_1': 0.5190653204917908, 'loss_2': 0.01397705078125, 'loss_3': -15.007253646850586, 'loss_4': 5.466021537780762, 'epoch': 0.19}
{'loss': 0.2745, 'grad_norm': 51.19461441040039, 'learning_rate': 2.9819767441860465e-05, 'loss_1': 0.2649637758731842, 'loss_2': 0.009552001953125, 'loss_3': -14.928766250610352, 'loss_4': 4.664312362670898, 'epoch': 0.2}
{'loss': 0.5023, 'grad_norm': 74.67372131347656, 'learning_rate': 2.9813953488372093e-05, 'loss_1': 0.5009751915931702, 'loss_2': 0.0013675689697265625, 'loss_3': -14.704095840454102, 'loss_4': 5.341509819030762, 'epoch': 0.2}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:20:59,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:20:59,956 >>   Batch size = 64
  1%|█▍                                                                                                                                                                                                                           | 35/5160 [01:00<1:39:47,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:21:03,780 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-35
[INFO|configuration_utils.py:420] 2025-01-21 12:21:03,781 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-35/config.json                                                                              
{'eval_loss': 0.11926205456256866, 'eval_runtime': 3.8221, 'eval_samples_per_second': 267.919, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.11446591466665268, 'eval_loss_2': 0.004796147346496582, 'eval_loss_3': -17.977067947387695, 'eval_loss_4': 4.428491592407227, 'epoch': 0.2}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:04,287 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-35/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:04,288 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-35/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:04,288 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-35/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:05,245 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-30] due to args.save_total_limit
  1%|█▋                                                                                                                                                                                                                           | 40/5160 [01:06<1:40:28,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 12:21:08,915 >>
{'loss': 0.4068, 'grad_norm': 59.54105758666992, 'learning_rate': 2.9808139534883722e-05, 'loss_1': 0.39951273798942566, 'loss_2': 0.00726318359375, 'loss_3': -14.916479110717773, 'loss_4': 4.708430290222168, 'epoch': 0.21}
{'loss': 0.3771, 'grad_norm': 57.709320068359375, 'learning_rate': 2.980232558139535e-05, 'loss_1': 0.3705122172832489, 'loss_2': 0.00656890869140625, 'loss_3': -14.815407752990723, 'loss_4': 4.195577144622803, 'epoch': 0.22}
{'loss': 0.5171, 'grad_norm': 68.7049789428711, 'learning_rate': 2.9796511627906976e-05, 'loss_1': 0.5134522318840027, 'loss_2': 0.003635406494140625, 'loss_3': -14.727585792541504, 'loss_4': 5.121946334838867, 'epoch': 0.22}
{'loss': 0.5085, 'grad_norm': 71.47762298583984, 'learning_rate': 2.9790697674418604e-05, 'loss_1': 0.5048234462738037, 'loss_2': 0.0036945343017578125, 'loss_3': -14.92050838470459, 'loss_4': 4.447379112243652, 'epoch': 0.23}
{'loss': 0.6501, 'grad_norm': 65.92176818847656, 'learning_rate': 2.9784883720930236e-05, 'loss_1': 0.6477069854736328, 'loss_2': 0.0024261474609375, 'loss_3': -14.77615737915039, 'loss_4': 4.964262962341309, 'epoch': 0.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:08,915 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:08,915 >>   Batch size = 64
  1%|█▉                                                                                                                                                                                                                           | 45/5160 [01:13<1:30:42,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:21:16,279 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.22272475063800812, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.21755951642990112, 'eval_loss_2': 0.005165234208106995, 'eval_loss_3': -17.75054168701172, 'eval_loss_4': 4.881860256195068, 'epoch': 0.23}
{'loss': 0.368, 'grad_norm': 63.994117736816406, 'learning_rate': 2.977906976744186e-05, 'loss_1': 0.3627857267856598, 'loss_2': 0.0052032470703125, 'loss_3': -14.952810287475586, 'loss_4': 4.594446659088135, 'epoch': 0.24}
{'loss': 0.3234, 'grad_norm': 61.155677795410156, 'learning_rate': 2.977325581395349e-05, 'loss_1': 0.316539466381073, 'loss_2': 0.006885528564453125, 'loss_3': -14.871915817260742, 'loss_4': 3.9470763206481934, 'epoch': 0.24}
{'loss': 0.4134, 'grad_norm': 57.45758819580078, 'learning_rate': 2.9767441860465116e-05, 'loss_1': 0.40272706747055054, 'loss_2': 0.0106353759765625, 'loss_3': -14.623534202575684, 'loss_4': 4.0791497230529785, 'epoch': 0.25}
{'loss': 0.4998, 'grad_norm': 59.23570251464844, 'learning_rate': 2.9761627906976744e-05, 'loss_1': 0.4905364513397217, 'loss_2': 0.00921630859375, 'loss_3': -14.709640502929688, 'loss_4': 4.262383460998535, 'epoch': 0.26}
{'loss': 0.3289, 'grad_norm': 55.16114807128906, 'learning_rate': 2.9755813953488373e-05, 'loss_1': 0.3222609758377075, 'loss_2': 0.0066680908203125, 'loss_3': -14.61828899383545, 'loss_4': 3.844916582107544, 'epoch': 0.26}
[INFO|trainer.py:4228] 2025-01-21 12:21:16,279 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:16,279 >>   Batch size = 64
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:20<1:29:03,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:21:23,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.1448524296283722, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.301, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.1359667032957077, 'eval_loss_2': 0.008885741233825684, 'eval_loss_3': -17.789047241210938, 'eval_loss_4': 3.821503162384033, 'epoch': 0.26}
{'loss': 0.2114, 'grad_norm': 49.237571716308594, 'learning_rate': 2.975e-05, 'loss_1': 0.20731832087039948, 'loss_2': 0.0041046142578125, 'loss_3': -14.922062873840332, 'loss_4': 4.012054443359375, 'epoch': 0.27}
{'loss': 0.1919, 'grad_norm': 43.21249771118164, 'learning_rate': 2.974418604651163e-05, 'loss_1': 0.18302544951438904, 'loss_2': 0.00891876220703125, 'loss_3': -14.620452880859375, 'loss_4': 2.445375919342041, 'epoch': 0.27}
{'loss': 0.2836, 'grad_norm': 45.45685577392578, 'learning_rate': 2.9738372093023255e-05, 'loss_1': 0.27056685090065, 'loss_2': 0.0129852294921875, 'loss_3': -14.879302978515625, 'loss_4': 2.998185157775879, 'epoch': 0.28}
{'loss': 0.3651, 'grad_norm': 61.489070892333984, 'learning_rate': 2.9732558139534884e-05, 'loss_1': 0.36446884274482727, 'loss_2': 0.0005965232849121094, 'loss_3': -14.51444149017334, 'loss_4': 3.0237865447998047, 'epoch': 0.28}
{'loss': 0.2374, 'grad_norm': 45.3031005859375, 'learning_rate': 2.9726744186046513e-05, 'loss_1': 0.23588788509368896, 'loss_2': 0.001468658447265625, 'loss_3': -14.739538192749023, 'loss_4': 2.423734664916992, 'epoch': 0.29}
[INFO|trainer.py:4228] 2025-01-21 12:21:23,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:23,655 >>   Batch size = 64
  1%|██▏                                                                                                                                                                                                                          | 50/5160 [01:24<1:29:03,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 12:21:27,469 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-50
[INFO|configuration_utils.py:420] 2025-01-21 12:21:27,471 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-50/config.json                                                                              
{'eval_loss': 0.05610613152384758, 'eval_runtime': 3.813, 'eval_samples_per_second': 268.555, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.052178941667079926, 'eval_loss_2': 0.003927186131477356, 'eval_loss_3': -17.933568954467773, 'eval_loss_4': 2.3954482078552246, 'epoch': 0.29}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:27,957 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-50/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:27,958 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-50/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:27,958 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-50/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:28,833 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-35] due to args.save_total_limit
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:29<1:37:37,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:21:32,485 >>
{'loss': 0.2268, 'grad_norm': 41.17874526977539, 'learning_rate': 2.972093023255814e-05, 'loss_1': 0.22474472224712372, 'loss_2': 0.0020389556884765625, 'loss_3': -14.953985214233398, 'loss_4': 2.742877244949341, 'epoch': 0.3}
{'loss': 0.2113, 'grad_norm': 46.82225036621094, 'learning_rate': 2.971511627906977e-05, 'loss_1': 0.19725634157657623, 'loss_2': 0.014007568359375, 'loss_3': -14.733222961425781, 'loss_4': 3.2495312690734863, 'epoch': 0.3}
{'loss': 0.1546, 'grad_norm': 32.98082733154297, 'learning_rate': 2.9709302325581395e-05, 'loss_1': 0.15335141122341156, 'loss_2': 0.001277923583984375, 'loss_3': -14.822380065917969, 'loss_4': 2.6069228649139404, 'epoch': 0.31}
{'loss': 0.2209, 'grad_norm': 50.76539993286133, 'learning_rate': 2.9703488372093024e-05, 'loss_1': 0.22049136459827423, 'loss_2': 0.0004534721374511719, 'loss_3': -14.818862915039062, 'loss_4': 3.3372998237609863, 'epoch': 0.31}
{'loss': 0.1595, 'grad_norm': 28.137388229370117, 'learning_rate': 2.9697674418604652e-05, 'loss_1': 0.1527324765920639, 'loss_2': 0.006744384765625, 'loss_3': -14.843786239624023, 'loss_4': 2.7326011657714844, 'epoch': 0.32}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:32,485 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:32,485 >>   Batch size = 64
  1%|██▎                                                                                                                                                                                                                          | 55/5160 [01:33<1:37:37,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:21:36,300 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-55
[INFO|configuration_utils.py:420] 2025-01-21 12:21:36,302 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-55/config.json                                                                              
{'eval_loss': 0.04910823702812195, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.453, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.042266517877578735, 'eval_loss_2': 0.006841719150543213, 'eval_loss_3': -17.952911376953125, 'eval_loss_4': 2.650235652923584, 'epoch': 0.32}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:36,802 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-55/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:36,803 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-55/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:36,804 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-55/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:37,742 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-50] due to args.save_total_limit
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:38<1:39:25,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:21:41,388 >>
{'loss': 0.1386, 'grad_norm': 43.71171569824219, 'learning_rate': 2.969186046511628e-05, 'loss_1': 0.1358090341091156, 'loss_2': 0.0028285980224609375, 'loss_3': -14.844636917114258, 'loss_4': 2.691429615020752, 'epoch': 0.33}
{'loss': 0.1633, 'grad_norm': 33.47273635864258, 'learning_rate': 2.9686046511627906e-05, 'loss_1': 0.15101617574691772, 'loss_2': 0.012237548828125, 'loss_3': -14.956439018249512, 'loss_4': 3.1836493015289307, 'epoch': 0.33}
{'loss': 0.1233, 'grad_norm': 26.961225509643555, 'learning_rate': 2.9680232558139535e-05, 'loss_1': 0.11588794738054276, 'loss_2': 0.00736236572265625, 'loss_3': -14.83736515045166, 'loss_4': 2.8092408180236816, 'epoch': 0.34}
{'loss': 0.1674, 'grad_norm': 35.271705627441406, 'learning_rate': 2.9674418604651164e-05, 'loss_1': 0.16333819925785065, 'loss_2': 0.00405120849609375, 'loss_3': -14.516196250915527, 'loss_4': 2.4466471672058105, 'epoch': 0.34}
{'loss': 0.1457, 'grad_norm': 38.981224060058594, 'learning_rate': 2.9668604651162792e-05, 'loss_1': 0.14534178376197815, 'loss_2': 0.0003757476806640625, 'loss_3': -14.615517616271973, 'loss_4': 2.2558441162109375, 'epoch': 0.35}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:41,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:41,388 >>   Batch size = 64
  1%|██▌                                                                                                                                                                                                                          | 60/5160 [01:42<1:39:25,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:21:45,206 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-60
[INFO|configuration_utils.py:420] 2025-01-21 12:21:45,208 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-60/config.json                                                                              
{'eval_loss': 0.048027895390987396, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.262, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.04158660024404526, 'eval_loss_2': 0.006441295146942139, 'eval_loss_3': -18.045705795288086, 'eval_loss_4': 2.1465156078338623, 'epoch': 0.35}
[INFO|modeling_utils.py:2988] 2025-01-21 12:21:45,722 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-60/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:21:45,723 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-60/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:21:45,724 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-60/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:21:46,670 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-55] due to args.save_total_limit
  1%|██▊                                                                                                                                                                                                                          | 65/5160 [01:47<1:39:57,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 12:21:50,336 >>
{'loss': 0.2059, 'grad_norm': 38.86274719238281, 'learning_rate': 2.966279069767442e-05, 'loss_1': 0.20364047586917877, 'loss_2': 0.002216339111328125, 'loss_3': -14.637697219848633, 'loss_4': 2.6467905044555664, 'epoch': 0.35}
{'loss': 0.143, 'grad_norm': 35.23473358154297, 'learning_rate': 2.9656976744186046e-05, 'loss_1': 0.13944710791110992, 'loss_2': 0.003543853759765625, 'loss_3': -14.713048934936523, 'loss_4': 2.1426169872283936, 'epoch': 0.36}
{'loss': 0.1512, 'grad_norm': 38.695865631103516, 'learning_rate': 2.9651162790697675e-05, 'loss_1': 0.13946962356567383, 'loss_2': 0.011688232421875, 'loss_3': -14.902583122253418, 'loss_4': 1.8943850994110107, 'epoch': 0.37}
{'loss': 0.1559, 'grad_norm': 31.011743545532227, 'learning_rate': 2.9645348837209303e-05, 'loss_1': 0.13904598355293274, 'loss_2': 0.016815185546875, 'loss_3': -15.073205947875977, 'loss_4': 2.7813010215759277, 'epoch': 0.37}
{'loss': 0.2534, 'grad_norm': 46.02655792236328, 'learning_rate': 2.9639534883720932e-05, 'loss_1': 0.23781901597976685, 'loss_2': 0.015625, 'loss_3': -14.768341064453125, 'loss_4': 2.5158207416534424, 'epoch': 0.38}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:21:50,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:50,337 >>   Batch size = 64
  1%|██▉                                                                                                                                                                                                                          | 70/5160 [01:54<1:30:21,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 12:21:57,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06194934993982315, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.786, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.050870753824710846, 'eval_loss_2': 0.011078596115112305, 'eval_loss_3': -18.11483383178711, 'eval_loss_4': 1.8122752904891968, 'epoch': 0.38}
{'loss': 0.1431, 'grad_norm': 36.65339279174805, 'learning_rate': 2.963372093023256e-05, 'loss_1': 0.12717266380786896, 'loss_2': 0.01593017578125, 'loss_3': -15.102811813354492, 'loss_4': 2.1993231773376465, 'epoch': 0.38}
{'loss': 0.1442, 'grad_norm': 35.01428985595703, 'learning_rate': 2.9627906976744186e-05, 'loss_1': 0.1340203732252121, 'loss_2': 0.01013946533203125, 'loss_3': -14.942195892333984, 'loss_4': 2.6379294395446777, 'epoch': 0.39}
{'loss': 0.2084, 'grad_norm': 38.49177169799805, 'learning_rate': 2.9622093023255814e-05, 'loss_1': 0.20329290628433228, 'loss_2': 0.00508880615234375, 'loss_3': -14.947471618652344, 'loss_4': 2.2392449378967285, 'epoch': 0.4}
{'loss': 0.0895, 'grad_norm': 30.103965759277344, 'learning_rate': 2.961627906976744e-05, 'loss_1': 0.08912257105112076, 'loss_2': 0.0004048347473144531, 'loss_3': -14.942383766174316, 'loss_4': 2.429619312286377, 'epoch': 0.4}
{'loss': 0.1263, 'grad_norm': 25.61493682861328, 'learning_rate': 2.9610465116279072e-05, 'loss_1': 0.11507269740104675, 'loss_2': 0.0112762451171875, 'loss_3': -15.291261672973633, 'loss_4': 1.8524329662322998, 'epoch': 0.41}
[INFO|trainer.py:4228] 2025-01-21 12:21:57,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:21:57,710 >>   Batch size = 64
  1%|███▏                                                                                                                                                                                                                         | 75/5160 [02:02<1:28:43,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:22:05,090 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06895194202661514, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.522, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.06327472627162933, 'eval_loss_2': 0.005677223205566406, 'eval_loss_3': -18.007532119750977, 'eval_loss_4': 2.015371084213257, 'epoch': 0.41}
{'loss': 0.1424, 'grad_norm': 30.435462951660156, 'learning_rate': 2.96046511627907e-05, 'loss_1': 0.1404123157262802, 'loss_2': 0.001949310302734375, 'loss_3': -14.865373611450195, 'loss_4': 1.8063019514083862, 'epoch': 0.41}
{'loss': 0.1986, 'grad_norm': 42.371376037597656, 'learning_rate': 2.9598837209302326e-05, 'loss_1': 0.18977901339530945, 'loss_2': 0.0088043212890625, 'loss_3': -14.971988677978516, 'loss_4': 2.26975154876709, 'epoch': 0.42}
{'loss': 0.2513, 'grad_norm': 52.08354949951172, 'learning_rate': 2.9593023255813954e-05, 'loss_1': 0.24248385429382324, 'loss_2': 0.0087738037109375, 'loss_3': -14.955818176269531, 'loss_4': 3.110990524291992, 'epoch': 0.42}
{'loss': 0.13, 'grad_norm': 37.79167556762695, 'learning_rate': 2.958720930232558e-05, 'loss_1': 0.12351211905479431, 'loss_2': 0.0064544677734375, 'loss_3': -14.721386909484863, 'loss_4': 1.665449857711792, 'epoch': 0.43}
{'loss': 0.2182, 'grad_norm': 46.257659912109375, 'learning_rate': 2.958139534883721e-05, 'loss_1': 0.20964950323104858, 'loss_2': 0.008575439453125, 'loss_3': -14.894097328186035, 'loss_4': 2.615293264389038, 'epoch': 0.44}
[INFO|trainer.py:4228] 2025-01-21 12:22:05,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:05,090 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:09<1:28:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:22:12,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08907701075077057, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.682, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.08372454345226288, 'eval_loss_2': 0.00535246729850769, 'eval_loss_3': -17.902101516723633, 'eval_loss_4': 3.0976200103759766, 'epoch': 0.44}
{'loss': 0.1208, 'grad_norm': 23.61530113220215, 'learning_rate': 2.957558139534884e-05, 'loss_1': 0.11793334037065506, 'loss_2': 0.0028820037841796875, 'loss_3': -14.980594635009766, 'loss_4': 3.565885305404663, 'epoch': 0.44}
{'loss': 0.1823, 'grad_norm': 45.49921798706055, 'learning_rate': 2.9569767441860465e-05, 'loss_1': 0.17638172209262848, 'loss_2': 0.00589752197265625, 'loss_3': -14.75060749053955, 'loss_4': 2.3459224700927734, 'epoch': 0.45}
{'loss': 0.1789, 'grad_norm': 47.855690002441406, 'learning_rate': 2.9563953488372094e-05, 'loss_1': 0.17583082616329193, 'loss_2': 0.003082275390625, 'loss_3': -14.708918571472168, 'loss_4': 2.9342360496520996, 'epoch': 0.45}
{'loss': 0.1348, 'grad_norm': 34.521236419677734, 'learning_rate': 2.955813953488372e-05, 'loss_1': 0.12925401329994202, 'loss_2': 0.0055389404296875, 'loss_3': -14.888228416442871, 'loss_4': 3.2969553470611572, 'epoch': 0.46}
{'loss': 0.1377, 'grad_norm': 32.07691955566406, 'learning_rate': 2.955232558139535e-05, 'loss_1': 0.1322471648454666, 'loss_2': 0.0054931640625, 'loss_3': -15.03721809387207, 'loss_4': 3.183602809906006, 'epoch': 0.47}
[INFO|trainer.py:4228] 2025-01-21 12:22:12,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:12,471 >>   Batch size = 64
  2%|███▍                                                                                                                                                                                                                         | 80/5160 [02:13<1:28:26,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:22:16,286 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-80
[INFO|configuration_utils.py:420] 2025-01-21 12:22:16,287 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-80/config.json                                                                              
{'eval_loss': 0.046328749507665634, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.501, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.03703323006629944, 'eval_loss_2': 0.009295519441366196, 'eval_loss_3': -18.1237850189209, 'eval_loss_4': 3.1424472332000732, 'epoch': 0.47}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:16,769 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-80/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:16,770 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-80/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:16,771 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-80/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:17,663 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-60] due to args.save_total_limit
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:18<1:37:15,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:22:21,320 >>
{'loss': 0.152, 'grad_norm': 38.12992858886719, 'learning_rate': 2.9546511627906976e-05, 'loss_1': 0.14779938757419586, 'loss_2': 0.0041961669921875, 'loss_3': -14.792404174804688, 'loss_4': 3.5029497146606445, 'epoch': 0.47}
{'loss': 0.1317, 'grad_norm': 31.595651626586914, 'learning_rate': 2.9540697674418605e-05, 'loss_1': 0.1164519190788269, 'loss_2': 0.0152435302734375, 'loss_3': -14.944449424743652, 'loss_4': 3.4890966415405273, 'epoch': 0.48}
{'loss': 0.1695, 'grad_norm': 29.718204498291016, 'learning_rate': 2.9534883720930234e-05, 'loss_1': 0.16822007298469543, 'loss_2': 0.001323699951171875, 'loss_3': -15.262242317199707, 'loss_4': 4.11788272857666, 'epoch': 0.48}
{'loss': 0.1902, 'grad_norm': 46.23467254638672, 'learning_rate': 2.952906976744186e-05, 'loss_1': 0.18762493133544922, 'loss_2': 0.00258636474609375, 'loss_3': -15.14118766784668, 'loss_4': 4.349785804748535, 'epoch': 0.49}
{'loss': 0.3363, 'grad_norm': 61.23988723754883, 'learning_rate': 2.952325581395349e-05, 'loss_1': 0.33376622200012207, 'loss_2': 0.0024871826171875, 'loss_3': -15.049070358276367, 'loss_4': 5.3606767654418945, 'epoch': 0.49}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:21,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:21,320 >>   Batch size = 64
  2%|███▋                                                                                                                                                                                                                         | 85/5160 [02:22<1:37:15,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:22:25,145 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-85
[INFO|configuration_utils.py:420] 2025-01-21 12:22:25,147 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-85/config.json                                                                              
{'eval_loss': 0.041502781212329865, 'eval_runtime': 3.824, 'eval_samples_per_second': 267.78, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.03257674723863602, 'eval_loss_2': 0.008926033973693848, 'eval_loss_3': -18.24826431274414, 'eval_loss_4': 4.175631523132324, 'epoch': 0.49}
[INFO|modeling_utils.py:2988] 2025-01-21 12:22:25,653 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-85/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:22:25,654 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-85/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:22:25,654 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-85/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:22:26,613 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-80] due to args.save_total_limit
  2%|███▊                                                                                                                                                                                                                         | 90/5160 [02:27<1:39:20,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 12:22:30,282 >>
{'loss': 0.2252, 'grad_norm': 39.37437057495117, 'learning_rate': 2.9517441860465116e-05, 'loss_1': 0.21335408091545105, 'loss_2': 0.01180267333984375, 'loss_3': -15.030933380126953, 'loss_4': 5.025285720825195, 'epoch': 0.5}
{'loss': 0.1636, 'grad_norm': 38.860660552978516, 'learning_rate': 2.9511627906976745e-05, 'loss_1': 0.14947201311588287, 'loss_2': 0.0140838623046875, 'loss_3': -15.150445938110352, 'loss_4': 5.176726818084717, 'epoch': 0.51}
{'loss': 0.2788, 'grad_norm': 50.690189361572266, 'learning_rate': 2.9505813953488374e-05, 'loss_1': 0.26397019624710083, 'loss_2': 0.01479339599609375, 'loss_3': -15.15058708190918, 'loss_4': 4.612029075622559, 'epoch': 0.51}
{'loss': 0.1859, 'grad_norm': 39.31443786621094, 'learning_rate': 2.95e-05, 'loss_1': 0.17977194488048553, 'loss_2': 0.00611114501953125, 'loss_3': -15.14844799041748, 'loss_4': 4.593042850494385, 'epoch': 0.52}
{'loss': 0.0933, 'grad_norm': 22.271228790283203, 'learning_rate': 2.949418604651163e-05, 'loss_1': 0.08754734694957733, 'loss_2': 0.0057830810546875, 'loss_3': -15.228863716125488, 'loss_4': 4.37907075881958, 'epoch': 0.52}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:22:30,282 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:30,282 >>   Batch size = 64
  2%|████                                                                                                                                                                                                                         | 95/5160 [02:34<1:29:58,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 12:22:37,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.043068110942840576, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.601, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.03631108999252319, 'eval_loss_2': 0.006757020950317383, 'eval_loss_3': -18.186626434326172, 'eval_loss_4': 3.436551570892334, 'epoch': 0.52}
{'loss': 0.2022, 'grad_norm': 44.54134750366211, 'learning_rate': 2.9488372093023256e-05, 'loss_1': 0.193306103348732, 'loss_2': 0.0089111328125, 'loss_3': -15.196893692016602, 'loss_4': 4.070102214813232, 'epoch': 0.53}
{'loss': 0.103, 'grad_norm': 26.423831939697266, 'learning_rate': 2.9482558139534885e-05, 'loss_1': 0.0971604734659195, 'loss_2': 0.0058441162109375, 'loss_3': -15.160807609558105, 'loss_4': 3.5905489921569824, 'epoch': 0.53}
{'loss': 0.143, 'grad_norm': 36.16116714477539, 'learning_rate': 2.947674418604651e-05, 'loss_1': 0.14064393937587738, 'loss_2': 0.002384185791015625, 'loss_3': -15.03582763671875, 'loss_4': 2.89523983001709, 'epoch': 0.54}
{'loss': 0.2194, 'grad_norm': 33.127410888671875, 'learning_rate': 2.947093023255814e-05, 'loss_1': 0.21222537755966187, 'loss_2': 0.0071258544921875, 'loss_3': -14.791595458984375, 'loss_4': 3.2314863204956055, 'epoch': 0.55}
{'loss': 0.1278, 'grad_norm': 43.13572692871094, 'learning_rate': 2.946511627906977e-05, 'loss_1': 0.11531227082014084, 'loss_2': 0.0124969482421875, 'loss_3': -15.035392761230469, 'loss_4': 3.2179601192474365, 'epoch': 0.55}
[INFO|trainer.py:4228] 2025-01-21 12:22:37,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:37,666 >>   Batch size = 64
  2%|████▎                                                                                                                                                                                                                       | 100/5160 [02:42<1:28:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:22:45,046 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.056483544409275055, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.539, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.03774622455239296, 'eval_loss_2': 0.018737316131591797, 'eval_loss_3': -18.0946102142334, 'eval_loss_4': 2.982609748840332, 'epoch': 0.55}
{'loss': 0.1627, 'grad_norm': 44.46876907348633, 'learning_rate': 2.9459302325581396e-05, 'loss_1': 0.1551809161901474, 'loss_2': 0.00754547119140625, 'loss_3': -15.061141014099121, 'loss_4': 3.031437873840332, 'epoch': 0.56}
{'loss': 0.162, 'grad_norm': 33.29682922363281, 'learning_rate': 2.9453488372093024e-05, 'loss_1': 0.1484191119670868, 'loss_2': 0.01361846923828125, 'loss_3': -15.020791053771973, 'loss_4': 2.641651153564453, 'epoch': 0.56}
{'loss': 0.1986, 'grad_norm': 42.01975631713867, 'learning_rate': 2.944767441860465e-05, 'loss_1': 0.1848798543214798, 'loss_2': 0.0136871337890625, 'loss_3': -15.105541229248047, 'loss_4': 3.0165200233459473, 'epoch': 0.57}
{'loss': 0.1603, 'grad_norm': 33.262916564941406, 'learning_rate': 2.944186046511628e-05, 'loss_1': 0.14606750011444092, 'loss_2': 0.0142669677734375, 'loss_3': -14.929512023925781, 'loss_4': 3.5948455333709717, 'epoch': 0.58}
{'loss': 0.2268, 'grad_norm': 39.17076110839844, 'learning_rate': 2.943604651162791e-05, 'loss_1': 0.2093307375907898, 'loss_2': 0.017425537109375, 'loss_3': -14.712729454040527, 'loss_4': 4.079648017883301, 'epoch': 0.58}
[INFO|trainer.py:4228] 2025-01-21 12:22:45,046 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:45,046 >>   Batch size = 64
  2%|████▍                                                                                                                                                                                                                       | 105/5160 [02:49<1:28:08,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:22:52,442 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05900982767343521, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.256, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.04642895609140396, 'eval_loss_2': 0.01258087158203125, 'eval_loss_3': -18.030935287475586, 'eval_loss_4': 3.6979057788848877, 'epoch': 0.58}
{'loss': 0.1755, 'grad_norm': 41.70847702026367, 'learning_rate': 2.9430232558139536e-05, 'loss_1': 0.16209040582180023, 'loss_2': 0.0134124755859375, 'loss_3': -15.053118705749512, 'loss_4': 3.81866455078125, 'epoch': 0.59}
{'loss': 0.1868, 'grad_norm': 35.7420768737793, 'learning_rate': 2.9424418604651164e-05, 'loss_1': 0.17798583209514618, 'loss_2': 0.00879669189453125, 'loss_3': -15.095832824707031, 'loss_4': 3.734701633453369, 'epoch': 0.59}
{'loss': 0.232, 'grad_norm': 49.752525329589844, 'learning_rate': 2.941860465116279e-05, 'loss_1': 0.21844147145748138, 'loss_2': 0.013519287109375, 'loss_3': -14.91472339630127, 'loss_4': 4.604653358459473, 'epoch': 0.6}
{'loss': 0.1783, 'grad_norm': 43.40764236450195, 'learning_rate': 2.941279069767442e-05, 'loss_1': 0.17644329369068146, 'loss_2': 0.0018329620361328125, 'loss_3': -14.997234344482422, 'loss_4': 4.698062896728516, 'epoch': 0.6}
{'loss': 0.1946, 'grad_norm': 40.08854293823242, 'learning_rate': 2.9406976744186047e-05, 'loss_1': 0.18645472824573517, 'loss_2': 0.00817108154296875, 'loss_3': -15.096739768981934, 'loss_4': 4.919528961181641, 'epoch': 0.61}
[INFO|trainer.py:4228] 2025-01-21 12:22:52,442 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:52,442 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [02:56<1:27:58,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:22:59,828 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05391892418265343, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.575, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.046296559274196625, 'eval_loss_2': 0.007622361183166504, 'eval_loss_3': -18.026338577270508, 'eval_loss_4': 4.0577826499938965, 'epoch': 0.61}
{'loss': 0.1141, 'grad_norm': 27.172761917114258, 'learning_rate': 2.9401162790697675e-05, 'loss_1': 0.11245420575141907, 'loss_2': 0.0016622543334960938, 'loss_3': -14.915090560913086, 'loss_4': 4.247593402862549, 'epoch': 0.62}
{'loss': 0.2681, 'grad_norm': 44.73490524291992, 'learning_rate': 2.9395348837209304e-05, 'loss_1': 0.24893784523010254, 'loss_2': 0.0192108154296875, 'loss_3': -14.802726745605469, 'loss_4': 4.460142135620117, 'epoch': 0.62}
{'loss': 0.0958, 'grad_norm': 23.147422790527344, 'learning_rate': 2.938953488372093e-05, 'loss_1': 0.09310238063335419, 'loss_2': 0.002655029296875, 'loss_3': -14.982426643371582, 'loss_4': 3.876854181289673, 'epoch': 0.63}
{'loss': 0.1072, 'grad_norm': 26.2425537109375, 'learning_rate': 2.938372093023256e-05, 'loss_1': 0.09865850955247879, 'loss_2': 0.00850677490234375, 'loss_3': -14.987531661987305, 'loss_4': 3.9850831031799316, 'epoch': 0.63}
{'loss': 0.1666, 'grad_norm': 42.661285400390625, 'learning_rate': 2.9377906976744186e-05, 'loss_1': 0.16383543610572815, 'loss_2': 0.0027923583984375, 'loss_3': -14.885013580322266, 'loss_4': 4.033590316772461, 'epoch': 0.64}
[INFO|trainer.py:4228] 2025-01-21 12:22:59,828 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:22:59,829 >>   Batch size = 64
  2%|████▋                                                                                                                                                                                                                       | 110/5160 [03:00<1:27:58,  1.05s/it][INFO|trainer.py:3910] 2025-01-21 12:23:03,646 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-110
[INFO|configuration_utils.py:420] 2025-01-21 12:23:03,648 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-110/config.json                                                                             
{'eval_loss': 0.04127243161201477, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.304, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.038261815905570984, 'eval_loss_2': 0.0030106157064437866, 'eval_loss_3': -18.091148376464844, 'eval_loss_4': 3.591648817062378, 'epoch': 0.64}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:04,158 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-110/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:04,160 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-110/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:04,160 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-110/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:05,115 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-85] due to args.save_total_limit
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:05<1:37:21,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:23:08,785 >>
{'loss': 0.3024, 'grad_norm': 50.871768951416016, 'learning_rate': 2.9372093023255815e-05, 'loss_1': 0.30030643939971924, 'loss_2': 0.0020599365234375, 'loss_3': -14.934444427490234, 'loss_4': 4.269793510437012, 'epoch': 0.65}
{'loss': 0.211, 'grad_norm': 45.618865966796875, 'learning_rate': 2.9366279069767444e-05, 'loss_1': 0.20825988054275513, 'loss_2': 0.0027866363525390625, 'loss_3': -14.902497291564941, 'loss_4': 4.333650588989258, 'epoch': 0.65}
{'loss': 0.2151, 'grad_norm': 46.43717575073242, 'learning_rate': 2.936046511627907e-05, 'loss_1': 0.20972025394439697, 'loss_2': 0.005340576171875, 'loss_3': -14.897363662719727, 'loss_4': 4.292643070220947, 'epoch': 0.66}
{'loss': 0.1559, 'grad_norm': 32.55588150024414, 'learning_rate': 2.93546511627907e-05, 'loss_1': 0.14225831627845764, 'loss_2': 0.013641357421875, 'loss_3': -15.137594223022461, 'loss_4': 3.830812931060791, 'epoch': 0.66}
{'loss': 0.158, 'grad_norm': 29.546964645385742, 'learning_rate': 2.9348837209302326e-05, 'loss_1': 0.14245596528053284, 'loss_2': 0.01556396484375, 'loss_3': -14.798820495605469, 'loss_4': 3.9866862297058105, 'epoch': 0.67}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:08,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:08,785 >>   Batch size = 64
  2%|████▉                                                                                                                                                                                                                       | 115/5160 [03:09<1:37:21,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 12:23:12,602 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-115
[INFO|configuration_utils.py:420] 2025-01-21 12:23:12,604 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-115/config.json                                                                             
{'eval_loss': 0.03978073224425316, 'eval_runtime': 3.8159, 'eval_samples_per_second': 268.35, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.027376292273402214, 'eval_loss_2': 0.012404441833496094, 'eval_loss_3': -18.154603958129883, 'eval_loss_4': 3.5079147815704346, 'epoch': 0.67}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:13,109 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-115/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:13,110 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-115/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:13,111 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-115/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:14,028 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-110] due to args.save_total_limit
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:14<1:38:36,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:23:17,698 >>
{'loss': 0.1767, 'grad_norm': 36.28224182128906, 'learning_rate': 2.9343023255813955e-05, 'loss_1': 0.17047123610973358, 'loss_2': 0.00620269775390625, 'loss_3': -14.974414825439453, 'loss_4': 4.8100128173828125, 'epoch': 0.67}
{'loss': 0.1139, 'grad_norm': 29.923673629760742, 'learning_rate': 2.933720930232558e-05, 'loss_1': 0.110158272087574, 'loss_2': 0.0037689208984375, 'loss_3': -15.116950035095215, 'loss_4': 3.794372320175171, 'epoch': 0.68}
{'loss': 0.0852, 'grad_norm': 23.27667808532715, 'learning_rate': 2.933139534883721e-05, 'loss_1': 0.07787636667490005, 'loss_2': 0.007293701171875, 'loss_3': -15.118922233581543, 'loss_4': 4.186820983886719, 'epoch': 0.69}
{'loss': 0.2328, 'grad_norm': 50.28171920776367, 'learning_rate': 2.932558139534884e-05, 'loss_1': 0.22683633863925934, 'loss_2': 0.00592803955078125, 'loss_3': -14.946844100952148, 'loss_4': 4.82071590423584, 'epoch': 0.69}
{'loss': 0.1435, 'grad_norm': 34.480491638183594, 'learning_rate': 2.9319767441860466e-05, 'loss_1': 0.13445588946342468, 'loss_2': 0.00902557373046875, 'loss_3': -14.922245025634766, 'loss_4': 4.080294609069824, 'epoch': 0.7}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:17,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:17,699 >>   Batch size = 64
  2%|█████                                                                                                                                                                                                                       | 120/5160 [03:18<1:38:36,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:23:21,510 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-120
[INFO|configuration_utils.py:420] 2025-01-21 12:23:21,512 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-120/config.json                                                                             
{'eval_loss': 0.029556622728705406, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.706, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02393457666039467, 'eval_loss_2': 0.005622044205665588, 'eval_loss_3': -18.13067626953125, 'eval_loss_4': 3.0465927124023438, 'epoch': 0.7}
[INFO|modeling_utils.py:2988] 2025-01-21 12:23:22,000 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-120/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:23:22,001 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-120/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:23:22,002 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-120/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:23:22,895 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-115] due to args.save_total_limit
  2%|█████▎                                                                                                                                                                                                                      | 125/5160 [03:23<1:38:18,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:23:26,559 >>
{'loss': 0.0754, 'grad_norm': 24.60639190673828, 'learning_rate': 2.9313953488372095e-05, 'loss_1': 0.07335080951452255, 'loss_2': 0.0020656585693359375, 'loss_3': -14.938383102416992, 'loss_4': 3.3320584297180176, 'epoch': 0.7}
{'loss': 0.1077, 'grad_norm': 22.0666561126709, 'learning_rate': 2.930813953488372e-05, 'loss_1': 0.09375054389238358, 'loss_2': 0.0139312744140625, 'loss_3': -14.995417594909668, 'loss_4': 3.4451165199279785, 'epoch': 0.71}
{'loss': 0.0985, 'grad_norm': 22.7271785736084, 'learning_rate': 2.930232558139535e-05, 'loss_1': 0.08803782612085342, 'loss_2': 0.01044464111328125, 'loss_3': -15.114498138427734, 'loss_4': 2.5503931045532227, 'epoch': 0.72}
{'loss': 0.0978, 'grad_norm': 19.882022857666016, 'learning_rate': 2.929651162790698e-05, 'loss_1': 0.08407073467969894, 'loss_2': 0.013702392578125, 'loss_3': -15.262306213378906, 'loss_4': 2.1518919467926025, 'epoch': 0.72}
{'loss': 0.0508, 'grad_norm': 14.95965576171875, 'learning_rate': 2.9290697674418606e-05, 'loss_1': 0.05029406026005745, 'loss_2': 0.0005273818969726562, 'loss_3': -15.041223526000977, 'loss_4': 2.3037610054016113, 'epoch': 0.73}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:23:26,560 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:26,560 >>   Batch size = 64
  3%|█████▌                                                                                                                                                                                                                      | 130/5160 [03:31<1:29:09,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:23:33,928 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03318445384502411, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.026061847805976868, 'eval_loss_2': 0.007122606039047241, 'eval_loss_3': -18.043798446655273, 'eval_loss_4': 1.804260015487671, 'epoch': 0.73}
{'loss': 0.076, 'grad_norm': 18.027254104614258, 'learning_rate': 2.9284883720930234e-05, 'loss_1': 0.06759989261627197, 'loss_2': 0.00838470458984375, 'loss_3': -15.1397066116333, 'loss_4': 1.8886327743530273, 'epoch': 0.73}
{'loss': 0.1234, 'grad_norm': 26.388723373413086, 'learning_rate': 2.927906976744186e-05, 'loss_1': 0.12205494195222855, 'loss_2': 0.001373291015625, 'loss_3': -15.113018035888672, 'loss_4': 2.0545918941497803, 'epoch': 0.74}
{'loss': 0.1013, 'grad_norm': 23.33997344970703, 'learning_rate': 2.927325581395349e-05, 'loss_1': 0.09658551216125488, 'loss_2': 0.00467681884765625, 'loss_3': -15.190556526184082, 'loss_4': 1.922990083694458, 'epoch': 0.74}
{'loss': 0.0755, 'grad_norm': 16.476789474487305, 'learning_rate': 2.9267441860465117e-05, 'loss_1': 0.06618162244558334, 'loss_2': 0.00933074951171875, 'loss_3': -15.332080841064453, 'loss_4': 2.11946439743042, 'epoch': 0.75}
{'loss': 0.0983, 'grad_norm': 23.29161834716797, 'learning_rate': 2.9261627906976746e-05, 'loss_1': 0.09307857602834702, 'loss_2': 0.0052642822265625, 'loss_3': -15.080863952636719, 'loss_4': 1.412937045097351, 'epoch': 0.76}
[INFO|trainer.py:4228] 2025-01-21 12:23:33,928 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:33,928 >>   Batch size = 64
  3%|█████▊                                                                                                                                                                                                                      | 135/5160 [03:38<1:27:34,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:23:41,303 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05588829517364502, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.405, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.05248244106769562, 'eval_loss_2': 0.003405854105949402, 'eval_loss_3': -17.909923553466797, 'eval_loss_4': 1.4987818002700806, 'epoch': 0.76}
{'loss': 0.1403, 'grad_norm': 36.815338134765625, 'learning_rate': 2.9255813953488374e-05, 'loss_1': 0.13339512050151825, 'loss_2': 0.006870269775390625, 'loss_3': -15.034358978271484, 'loss_4': 1.4323217868804932, 'epoch': 0.76}
{'loss': 0.0662, 'grad_norm': 18.7701416015625, 'learning_rate': 2.925e-05, 'loss_1': 0.06405432522296906, 'loss_2': 0.00211334228515625, 'loss_3': -15.248801231384277, 'loss_4': 1.420785665512085, 'epoch': 0.77}
{'loss': 0.1625, 'grad_norm': 33.613197326660156, 'learning_rate': 2.9244186046511628e-05, 'loss_1': 0.15341664850711823, 'loss_2': 0.00904083251953125, 'loss_3': -15.054647445678711, 'loss_4': 1.146130084991455, 'epoch': 0.77}
{'loss': 0.088, 'grad_norm': 20.09994125366211, 'learning_rate': 2.9238372093023257e-05, 'loss_1': 0.0707147866487503, 'loss_2': 0.017242431640625, 'loss_3': -15.280372619628906, 'loss_4': 1.6771564483642578, 'epoch': 0.78}
{'loss': 0.126, 'grad_norm': 30.332244873046875, 'learning_rate': 2.9232558139534885e-05, 'loss_1': 0.11116597056388855, 'loss_2': 0.0148773193359375, 'loss_3': -15.16411018371582, 'loss_4': 1.4498462677001953, 'epoch': 0.78}
[INFO|trainer.py:4228] 2025-01-21 12:23:41,303 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:41,303 >>   Batch size = 64
  3%|█████▉                                                                                                                                                                                                                      | 140/5160 [03:45<1:27:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:48,694 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07251624763011932, 'eval_runtime': 3.8235, 'eval_samples_per_second': 267.819, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.06181691214442253, 'eval_loss_2': 0.010699331760406494, 'eval_loss_3': -17.863433837890625, 'eval_loss_4': 1.5310704708099365, 'epoch': 0.78}
{'loss': 0.0967, 'grad_norm': 24.289936065673828, 'learning_rate': 2.9226744186046514e-05, 'loss_1': 0.08366910368204117, 'loss_2': 0.0130615234375, 'loss_3': -15.273181915283203, 'loss_4': 1.3418558835983276, 'epoch': 0.79}
{'loss': 0.3165, 'grad_norm': 53.72550582885742, 'learning_rate': 2.922093023255814e-05, 'loss_1': 0.29795071482658386, 'loss_2': 0.0185089111328125, 'loss_3': -14.91872501373291, 'loss_4': 1.730029582977295, 'epoch': 0.8}
{'loss': 0.0846, 'grad_norm': 20.35134506225586, 'learning_rate': 2.9215116279069768e-05, 'loss_1': 0.06303039193153381, 'loss_2': 0.02154541015625, 'loss_3': -15.403100967407227, 'loss_4': 2.2667980194091797, 'epoch': 0.8}
{'loss': 0.0931, 'grad_norm': 24.739891052246094, 'learning_rate': 2.9209302325581397e-05, 'loss_1': 0.08060147613286972, 'loss_2': 0.012451171875, 'loss_3': -15.233524322509766, 'loss_4': 1.7226415872573853, 'epoch': 0.81}
{'loss': 0.0737, 'grad_norm': 20.88658905029297, 'learning_rate': 2.9203488372093025e-05, 'loss_1': 0.0628347173333168, 'loss_2': 0.0109100341796875, 'loss_3': -15.265274047851562, 'loss_4': 2.069434642791748, 'epoch': 0.81}
[INFO|trainer.py:4228] 2025-01-21 12:23:48,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:48,694 >>   Batch size = 64
  3%|██████▏                                                                                                                                                                                                                     | 145/5160 [03:53<1:27:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:23:56,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.044333502650260925, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.456, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.040840402245521545, 'eval_loss_2': 0.00349310040473938, 'eval_loss_3': -17.97603988647461, 'eval_loss_4': 1.8421744108200073, 'epoch': 0.81}
{'loss': 0.076, 'grad_norm': 22.64620590209961, 'learning_rate': 2.919767441860465e-05, 'loss_1': 0.07330861687660217, 'loss_2': 0.002655029296875, 'loss_3': -15.12195110321045, 'loss_4': 1.699990153312683, 'epoch': 0.82}
{'loss': 0.0603, 'grad_norm': 16.814844131469727, 'learning_rate': 2.919186046511628e-05, 'loss_1': 0.05265851318836212, 'loss_2': 0.007610321044921875, 'loss_3': -15.218133926391602, 'loss_4': 2.3623690605163574, 'epoch': 0.83}
{'loss': 0.0997, 'grad_norm': 37.869468688964844, 'learning_rate': 2.9186046511627908e-05, 'loss_1': 0.09669812023639679, 'loss_2': 0.0030498504638671875, 'loss_3': -15.127096176147461, 'loss_4': 2.4369144439697266, 'epoch': 0.83}
{'loss': 0.0644, 'grad_norm': 16.91330909729004, 'learning_rate': 2.9180232558139536e-05, 'loss_1': 0.052801717072725296, 'loss_2': 0.01163482666015625, 'loss_3': -15.423189163208008, 'loss_4': 2.2750861644744873, 'epoch': 0.84}
{'loss': 0.0967, 'grad_norm': 26.036426544189453, 'learning_rate': 2.9174418604651165e-05, 'loss_1': 0.08364686369895935, 'loss_2': 0.01302337646484375, 'loss_3': -15.379631996154785, 'loss_4': 3.0243492126464844, 'epoch': 0.84}
[INFO|trainer.py:4228] 2025-01-21 12:23:56,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:23:56,080 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [04:00<1:27:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:03,459 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03494275361299515, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.019879940897226334, 'eval_loss_2': 0.015062808990478516, 'eval_loss_3': -18.119693756103516, 'eval_loss_4': 2.0403895378112793, 'epoch': 0.84}
{'loss': 0.0958, 'grad_norm': 26.414167404174805, 'learning_rate': 2.916860465116279e-05, 'loss_1': 0.09456690400838852, 'loss_2': 0.0012569427490234375, 'loss_3': -15.163093566894531, 'loss_4': 2.914590835571289, 'epoch': 0.85}
{'loss': 0.1612, 'grad_norm': 40.77667236328125, 'learning_rate': 2.916279069767442e-05, 'loss_1': 0.15260861814022064, 'loss_2': 0.0085906982421875, 'loss_3': -15.07778263092041, 'loss_4': 3.1267287731170654, 'epoch': 0.85}
{'loss': 0.0499, 'grad_norm': 12.840150833129883, 'learning_rate': 2.9156976744186047e-05, 'loss_1': 0.04556991159915924, 'loss_2': 0.0043792724609375, 'loss_3': -15.312253952026367, 'loss_4': 2.489105701446533, 'epoch': 0.86}
{'loss': 0.0587, 'grad_norm': 17.319704055786133, 'learning_rate': 2.9151162790697676e-05, 'loss_1': 0.058363210409879684, 'loss_2': 0.0003421306610107422, 'loss_3': -15.202364921569824, 'loss_4': 2.588369369506836, 'epoch': 0.87}
{'loss': 0.0459, 'grad_norm': 10.753552436828613, 'learning_rate': 2.9145348837209305e-05, 'loss_1': 0.03234255686402321, 'loss_2': 0.013519287109375, 'loss_3': -15.278554916381836, 'loss_4': 2.7935163974761963, 'epoch': 0.87}
[INFO|trainer.py:4228] 2025-01-21 12:24:03,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:03,460 >>   Batch size = 64
  3%|██████▍                                                                                                                                                                                                                     | 150/5160 [04:04<1:27:09,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:24:07,272 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-150
[INFO|configuration_utils.py:420] 2025-01-21 12:24:07,273 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-150/config.json                                                                             
{'eval_loss': 0.028588220477104187, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.685, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.021509036421775818, 'eval_loss_2': 0.007079184055328369, 'eval_loss_3': -18.10379981994629, 'eval_loss_4': 2.2547638416290283, 'epoch': 0.87}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:07,768 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-150/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:07,769 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-150/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:07,769 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-150/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:08,700 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-120] due to args.save_total_limit
  3%|██████▌                                                                                                                                                                                                                     | 155/5160 [04:09<1:36:03,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:24:12,348 >>
{'loss': 0.076, 'grad_norm': 21.476598739624023, 'learning_rate': 2.913953488372093e-05, 'loss_1': 0.06696847081184387, 'loss_2': 0.00904083251953125, 'loss_3': -15.306293487548828, 'loss_4': 2.913771629333496, 'epoch': 0.88}
{'loss': 0.0624, 'grad_norm': 19.114208221435547, 'learning_rate': 2.913372093023256e-05, 'loss_1': 0.054819948971271515, 'loss_2': 0.00753021240234375, 'loss_3': -15.418255805969238, 'loss_4': 1.9926064014434814, 'epoch': 0.88}
{'loss': 0.0742, 'grad_norm': 16.216562271118164, 'learning_rate': 2.9127906976744184e-05, 'loss_1': 0.058864232152700424, 'loss_2': 0.015350341796875, 'loss_3': -15.246830940246582, 'loss_4': 2.602208375930786, 'epoch': 0.89}
{'loss': 0.0798, 'grad_norm': 24.8375244140625, 'learning_rate': 2.9122093023255816e-05, 'loss_1': 0.0617792122066021, 'loss_2': 0.0180206298828125, 'loss_3': -15.292247772216797, 'loss_4': 2.6776695251464844, 'epoch': 0.9}
{'loss': 0.0588, 'grad_norm': 13.998451232910156, 'learning_rate': 2.9116279069767444e-05, 'loss_1': 0.04537583887577057, 'loss_2': 0.0134429931640625, 'loss_3': -15.30234146118164, 'loss_4': 2.25101900100708, 'epoch': 0.9}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:12,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:12,349 >>   Batch size = 64
  3%|██████▊                                                                                                                                                                                                                     | 160/5160 [04:16<1:28:27,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:24:19,725 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03015790320932865, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.887, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.025144463405013084, 'eval_loss_2': 0.0050134435296058655, 'eval_loss_3': -18.130935668945312, 'eval_loss_4': 1.695542573928833, 'epoch': 0.9}
{'loss': 0.0712, 'grad_norm': 18.838787078857422, 'learning_rate': 2.911046511627907e-05, 'loss_1': 0.06577280163764954, 'loss_2': 0.0054168701171875, 'loss_3': -15.460789680480957, 'loss_4': 1.1574983596801758, 'epoch': 0.91}
{'loss': 0.1068, 'grad_norm': 32.852439880371094, 'learning_rate': 2.91046511627907e-05, 'loss_1': 0.10193216055631638, 'loss_2': 0.0048828125, 'loss_3': -15.32691478729248, 'loss_4': 2.929980993270874, 'epoch': 0.91}
{'loss': 0.168, 'grad_norm': 39.539947509765625, 'learning_rate': 2.9098837209302324e-05, 'loss_1': 0.15499858558177948, 'loss_2': 0.0130157470703125, 'loss_3': -15.49807071685791, 'loss_4': 2.3475162982940674, 'epoch': 0.92}
{'loss': 0.135, 'grad_norm': 30.067626953125, 'learning_rate': 2.9093023255813956e-05, 'loss_1': 0.12242486327886581, 'loss_2': 0.0126190185546875, 'loss_3': -15.36556339263916, 'loss_4': 2.3359131813049316, 'epoch': 0.92}
{'loss': 0.1177, 'grad_norm': 25.548311233520508, 'learning_rate': 2.908720930232558e-05, 'loss_1': 0.10318449139595032, 'loss_2': 0.0145111083984375, 'loss_3': -15.387941360473633, 'loss_4': 1.7059262990951538, 'epoch': 0.93}
[INFO|trainer.py:4228] 2025-01-21 12:24:19,725 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:19,725 >>   Batch size = 64
  3%|███████                                                                                                                                                                                                                     | 165/5160 [04:24<1:27:08,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:24:27,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04043383151292801, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.631, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.02620644122362137, 'eval_loss_2': 0.01422739028930664, 'eval_loss_3': -18.126747131347656, 'eval_loss_4': 1.378117322921753, 'epoch': 0.93}
{'loss': 0.0916, 'grad_norm': 17.710861206054688, 'learning_rate': 2.908139534883721e-05, 'loss_1': 0.07520995289087296, 'loss_2': 0.016387939453125, 'loss_3': -15.241825103759766, 'loss_4': 1.4320175647735596, 'epoch': 0.94}
{'loss': 0.0798, 'grad_norm': 20.059938430786133, 'learning_rate': 2.9075581395348838e-05, 'loss_1': 0.06714146584272385, 'loss_2': 0.0126495361328125, 'loss_3': -15.359195709228516, 'loss_4': 2.2448112964630127, 'epoch': 0.94}
{'loss': 0.0962, 'grad_norm': 21.68140983581543, 'learning_rate': 2.9069767441860463e-05, 'loss_1': 0.09371404349803925, 'loss_2': 0.002483367919921875, 'loss_3': -15.284806251525879, 'loss_4': 2.1207633018493652, 'epoch': 0.95}
{'loss': 0.0487, 'grad_norm': 10.249434471130371, 'learning_rate': 2.9063953488372095e-05, 'loss_1': 0.04098912328481674, 'loss_2': 0.0076904296875, 'loss_3': -15.427596092224121, 'loss_4': 2.0006165504455566, 'epoch': 0.95}
{'loss': 0.1175, 'grad_norm': 22.9473934173584, 'learning_rate': 2.905813953488372e-05, 'loss_1': 0.11447320878505707, 'loss_2': 0.0030307769775390625, 'loss_3': -15.211870193481445, 'loss_4': 1.9320619106292725, 'epoch': 0.96}
[INFO|trainer.py:4228] 2025-01-21 12:24:27,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:27,108 >>   Batch size = 64
  3%|███████▏                                                                                                                                                                                                                    | 170/5160 [04:31<1:26:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:34,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03821738064289093, 'eval_runtime': 3.8223, 'eval_samples_per_second': 267.903, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.03372342884540558, 'eval_loss_2': 0.0044939517974853516, 'eval_loss_3': -18.049894332885742, 'eval_loss_4': 1.559620976448059, 'epoch': 0.96}
{'loss': 0.0594, 'grad_norm': 23.731552124023438, 'learning_rate': 2.905232558139535e-05, 'loss_1': 0.052253346890211105, 'loss_2': 0.007175445556640625, 'loss_3': -15.676798820495605, 'loss_4': 2.2277350425720215, 'epoch': 0.97}
{'loss': 0.0979, 'grad_norm': 20.63544273376465, 'learning_rate': 2.9046511627906978e-05, 'loss_1': 0.08633161336183548, 'loss_2': 0.0116119384765625, 'loss_3': -15.207128524780273, 'loss_4': 2.239785671234131, 'epoch': 0.97}
{'loss': 0.0591, 'grad_norm': 12.961784362792969, 'learning_rate': 2.9040697674418607e-05, 'loss_1': 0.05191578343510628, 'loss_2': 0.0072174072265625, 'loss_3': -15.380141258239746, 'loss_4': 1.8612713813781738, 'epoch': 0.98}
{'loss': 0.1729, 'grad_norm': 34.06482696533203, 'learning_rate': 2.9034883720930235e-05, 'loss_1': 0.16748034954071045, 'loss_2': 0.005435943603515625, 'loss_3': -15.064567565917969, 'loss_4': 1.305065393447876, 'epoch': 0.98}
{'loss': 0.088, 'grad_norm': 24.571151733398438, 'learning_rate': 2.902906976744186e-05, 'loss_1': 0.08483485877513885, 'loss_2': 0.00321197509765625, 'loss_3': -15.271750450134277, 'loss_4': 1.3726634979248047, 'epoch': 0.99}
[INFO|trainer.py:4228] 2025-01-21 12:24:34,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:34,495 >>   Batch size = 64
  3%|███████▍                                                                                                                                                                                                                    | 175/5160 [04:38<1:24:14,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 12:24:41,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04700306057929993, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.487, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.04135802388191223, 'eval_loss_2': 0.005645036697387695, 'eval_loss_3': -17.920700073242188, 'eval_loss_4': 0.9444057941436768, 'epoch': 0.99}
{'loss': 0.0664, 'grad_norm': 17.839950561523438, 'learning_rate': 2.902325581395349e-05, 'loss_1': 0.06560470163822174, 'loss_2': 0.0008349418640136719, 'loss_3': -15.062705039978027, 'loss_4': 0.7094178199768066, 'epoch': 0.99}
{'loss': 0.061, 'grad_norm': 33.84881591796875, 'learning_rate': 2.9017441860465114e-05, 'loss_1': 0.0564974844455719, 'loss_2': 0.004489898681640625, 'loss_3': -15.26967716217041, 'loss_4': 1.680169939994812, 'epoch': 1.0}
{'loss': 0.0596, 'grad_norm': 13.291887283325195, 'learning_rate': 2.9011627906976746e-05, 'loss_1': 0.05367642268538475, 'loss_2': 0.005924224853515625, 'loss_3': -15.165264129638672, 'loss_4': 1.068791389465332, 'epoch': 1.01}
{'loss': 0.0616, 'grad_norm': 21.304122924804688, 'learning_rate': 2.9005813953488375e-05, 'loss_1': 0.0508078970015049, 'loss_2': 0.010772705078125, 'loss_3': -15.261520385742188, 'loss_4': 0.5211562514305115, 'epoch': 1.01}
{'loss': 0.0572, 'grad_norm': 20.776973724365234, 'learning_rate': 2.9e-05, 'loss_1': 0.05400429666042328, 'loss_2': 0.003162384033203125, 'loss_3': -15.02570915222168, 'loss_4': 0.683551549911499, 'epoch': 1.02}
[INFO|trainer.py:4228] 2025-01-21 12:24:41,564 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:41,564 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:46<1:26:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:24:48,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042838096618652344, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.427, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.035590171813964844, 'eval_loss_2': 0.0072479248046875, 'eval_loss_3': -17.92826271057129, 'eval_loss_4': 0.3426394462585449, 'epoch': 1.02}
{'loss': 0.092, 'grad_norm': 47.86918258666992, 'learning_rate': 2.899418604651163e-05, 'loss_1': 0.09021619707345963, 'loss_2': 0.001796722412109375, 'loss_3': -15.107354164123535, 'loss_4': 1.1538413763046265, 'epoch': 1.02}
{'loss': 0.0365, 'grad_norm': 11.769974708557129, 'learning_rate': 2.8988372093023254e-05, 'loss_1': 0.03364616259932518, 'loss_2': 0.002819061279296875, 'loss_3': -15.084928512573242, 'loss_4': 0.7420799136161804, 'epoch': 1.03}
{'loss': 0.1573, 'grad_norm': 43.0408821105957, 'learning_rate': 2.8982558139534886e-05, 'loss_1': 0.14912348985671997, 'loss_2': 0.0081634521484375, 'loss_3': -15.11143684387207, 'loss_4': 1.1270477771759033, 'epoch': 1.03}
{'loss': 0.1168, 'grad_norm': 34.85219955444336, 'learning_rate': 2.8976744186046515e-05, 'loss_1': 0.11505812406539917, 'loss_2': 0.001750946044921875, 'loss_3': -15.143755912780762, 'loss_4': 0.621158242225647, 'epoch': 1.04}
{'loss': 0.1214, 'grad_norm': 29.990568161010742, 'learning_rate': 2.897093023255814e-05, 'loss_1': 0.11020343750715256, 'loss_2': 0.01120758056640625, 'loss_3': -15.02194595336914, 'loss_4': 0.3360595703125, 'epoch': 1.05}
[INFO|trainer.py:4228] 2025-01-21 12:24:48,945 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:48,946 >>   Batch size = 64
  3%|███████▋                                                                                                                                                                                                                    | 180/5160 [04:49<1:26:09,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:24:52,758 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-180
[INFO|configuration_utils.py:420] 2025-01-21 12:24:52,760 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-180/config.json                                                                             
{'eval_loss': 0.02835385501384735, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.674, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0205928236246109, 'eval_loss_2': 0.00776103138923645, 'eval_loss_3': -18.09343147277832, 'eval_loss_4': 0.9012356996536255, 'epoch': 1.05}
[INFO|modeling_utils.py:2988] 2025-01-21 12:24:53,239 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-180/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:24:53,241 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-180/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:24:53,241 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-180/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:24:54,171 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-150] due to args.save_total_limit
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:54<1:35:18,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:24:57,822 >>
{'loss': 0.1058, 'grad_norm': 29.535934448242188, 'learning_rate': 2.896511627906977e-05, 'loss_1': 0.09791640937328339, 'loss_2': 0.007904052734375, 'loss_3': -15.18289566040039, 'loss_4': 2.1701598167419434, 'epoch': 1.05}
{'loss': 0.1039, 'grad_norm': 28.28907585144043, 'learning_rate': 2.8959302325581394e-05, 'loss_1': 0.0908358097076416, 'loss_2': 0.0130615234375, 'loss_3': -15.138284683227539, 'loss_4': 1.7944040298461914, 'epoch': 1.06}
{'loss': 0.0944, 'grad_norm': 25.245136260986328, 'learning_rate': 2.8953488372093026e-05, 'loss_1': 0.08261074125766754, 'loss_2': 0.011749267578125, 'loss_3': -15.294061660766602, 'loss_4': 2.224977493286133, 'epoch': 1.06}
{'loss': 0.1817, 'grad_norm': 45.383453369140625, 'learning_rate': 2.894767441860465e-05, 'loss_1': 0.17996501922607422, 'loss_2': 0.0016880035400390625, 'loss_3': -14.898761749267578, 'loss_4': 2.1293046474456787, 'epoch': 1.07}
{'loss': 0.1091, 'grad_norm': 30.64968490600586, 'learning_rate': 2.894186046511628e-05, 'loss_1': 0.10812795907258987, 'loss_2': 0.0009832382202148438, 'loss_3': -15.12475299835205, 'loss_4': 1.526857852935791, 'epoch': 1.08}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:24:57,822 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:24:57,823 >>   Batch size = 64
  4%|███████▉                                                                                                                                                                                                                    | 185/5160 [04:58<1:35:18,  1.15s/it][INFO|trainer.py:3910] 2025-01-21 12:25:01,633 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-185
[INFO|configuration_utils.py:420] 2025-01-21 12:25:01,634 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-185/config.json                                                                             
{'eval_loss': 0.024085387587547302, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.019290044903755188, 'eval_loss_2': 0.004795342683792114, 'eval_loss_3': -18.046428680419922, 'eval_loss_4': 0.49100348353385925, 'epoch': 1.08}
[INFO|modeling_utils.py:2988] 2025-01-21 12:25:02,119 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-185/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:25:02,120 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-185/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:25:02,121 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-185/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:25:03,076 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-180] due to args.save_total_limit
  4%|████████                                                                                                                                                                                                                    | 190/5160 [05:03<1:36:57,  1.17s/it][INFO|trainer.py:4226] 2025-01-21 12:25:06,729 >>
{'loss': 0.0683, 'grad_norm': 25.530162811279297, 'learning_rate': 2.893604651162791e-05, 'loss_1': 0.06754066050052643, 'loss_2': 0.0007762908935546875, 'loss_3': -15.090301513671875, 'loss_4': 1.1735055446624756, 'epoch': 1.08}
{'loss': 0.0683, 'grad_norm': 26.706302642822266, 'learning_rate': 2.8930232558139534e-05, 'loss_1': 0.06581815332174301, 'loss_2': 0.0025177001953125, 'loss_3': -15.249187469482422, 'loss_4': 0.6381060481071472, 'epoch': 1.09}
{'loss': 0.1667, 'grad_norm': 35.629417419433594, 'learning_rate': 2.8924418604651166e-05, 'loss_1': 0.16212110221385956, 'loss_2': 0.00458526611328125, 'loss_3': -14.713592529296875, 'loss_4': 0.9016274213790894, 'epoch': 1.09}
{'loss': 0.0815, 'grad_norm': 22.59219741821289, 'learning_rate': 2.891860465116279e-05, 'loss_1': 0.07662785053253174, 'loss_2': 0.0048828125, 'loss_3': -14.96639633178711, 'loss_4': 0.5237675905227661, 'epoch': 1.1}
{'loss': 0.0598, 'grad_norm': 14.332796096801758, 'learning_rate': 2.891279069767442e-05, 'loss_1': 0.05128489062190056, 'loss_2': 0.0084991455078125, 'loss_3': -15.037160873413086, 'loss_4': 0.782585620880127, 'epoch': 1.1}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:25:06,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:06,730 >>   Batch size = 64
  4%|████████                                                                                                                                                                                                                    | 190/5160 [05:07<1:36:57,  1.17s/it][INFO|trainer.py:3910] 2025-01-21 12:25:10,545 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-190
[INFO|configuration_utils.py:420] 2025-01-21 12:25:10,547 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-190/config.json                                                                             
{'eval_loss': 0.022457167506217957, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.455, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.0161065012216568, 'eval_loss_2': 0.006350666284561157, 'eval_loss_3': -17.96193504333496, 'eval_loss_4': 0.4450988173484802, 'epoch': 1.1}
[INFO|modeling_utils.py:2988] 2025-01-21 12:25:11,056 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-190/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:25:11,057 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-190/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:25:11,057 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-190/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:25:12,006 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-185] due to args.save_total_limit
  4%|████████▎                                                                                                                                                                                                                   | 195/5160 [05:12<1:37:24,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 12:25:15,678 >>
{'loss': 0.1381, 'grad_norm': 34.56500244140625, 'learning_rate': 2.8906976744186048e-05, 'loss_1': 0.13700681924819946, 'loss_2': 0.0010528564453125, 'loss_3': -15.046890258789062, 'loss_4': 0.9027974605560303, 'epoch': 1.11}
{'loss': 0.1164, 'grad_norm': 31.254953384399414, 'learning_rate': 2.8901162790697673e-05, 'loss_1': 0.10691426694393158, 'loss_2': 0.00945281982421875, 'loss_3': -14.889049530029297, 'loss_4': 1.7129193544387817, 'epoch': 1.12}
{'loss': 0.1523, 'grad_norm': 47.04773712158203, 'learning_rate': 2.8895348837209305e-05, 'loss_1': 0.14074833691120148, 'loss_2': 0.0115203857421875, 'loss_3': -14.992076873779297, 'loss_4': 1.2973129749298096, 'epoch': 1.12}
{'loss': 0.0578, 'grad_norm': 14.06615161895752, 'learning_rate': 2.888953488372093e-05, 'loss_1': 0.03574101999402046, 'loss_2': 0.022064208984375, 'loss_3': -15.296692848205566, 'loss_4': 0.7963888645172119, 'epoch': 1.13}
{'loss': 0.0613, 'grad_norm': 30.261423110961914, 'learning_rate': 2.888372093023256e-05, 'loss_1': 0.04841393232345581, 'loss_2': 0.012908935546875, 'loss_3': -14.889131546020508, 'loss_4': 1.6603071689605713, 'epoch': 1.13}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:25:15,678 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:15,678 >>   Batch size = 64
  4%|████████▌                                                                                                                                                                                                                   | 200/5160 [05:20<1:27:55,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:25:23,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025215379893779755, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.937, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015815073624253273, 'eval_loss_2': 0.00940030813217163, 'eval_loss_3': -17.939821243286133, 'eval_loss_4': 0.5043711066246033, 'epoch': 1.13}
{'loss': 0.0552, 'grad_norm': 16.73890495300293, 'learning_rate': 2.8877906976744185e-05, 'loss_1': 0.048013653606176376, 'loss_2': 0.00714111328125, 'loss_3': -15.064453125, 'loss_4': 0.9401658773422241, 'epoch': 1.14}
{'loss': 0.0577, 'grad_norm': 22.84189224243164, 'learning_rate': 2.8872093023255813e-05, 'loss_1': 0.05705196037888527, 'loss_2': 0.0006856918334960938, 'loss_3': -15.194845199584961, 'loss_4': 0.9585741758346558, 'epoch': 1.15}
{'loss': 0.1402, 'grad_norm': 31.003314971923828, 'learning_rate': 2.8866279069767445e-05, 'loss_1': 0.13715577125549316, 'loss_2': 0.003078460693359375, 'loss_3': -15.13866138458252, 'loss_4': 0.42998114228248596, 'epoch': 1.15}
{'loss': 0.074, 'grad_norm': 25.36833953857422, 'learning_rate': 2.886046511627907e-05, 'loss_1': 0.06236858665943146, 'loss_2': 0.0116424560546875, 'loss_3': -15.32888412475586, 'loss_4': 1.209498405456543, 'epoch': 1.16}
{'loss': 0.0927, 'grad_norm': 20.16820526123047, 'learning_rate': 2.88546511627907e-05, 'loss_1': 0.07317574322223663, 'loss_2': 0.01953125, 'loss_3': -15.037727355957031, 'loss_4': 1.3048830032348633, 'epoch': 1.16}
[INFO|trainer.py:4228] 2025-01-21 12:25:23,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:23,043 >>   Batch size = 64
  4%|████████▋                                                                                                                                                                                                                   | 205/5160 [05:27<1:26:22,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:25:30,420 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03301070258021355, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.48, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.02159116603434086, 'eval_loss_2': 0.011419534683227539, 'eval_loss_3': -17.898834228515625, 'eval_loss_4': 0.928530752658844, 'epoch': 1.16}
{'loss': 0.0429, 'grad_norm': 11.111041069030762, 'learning_rate': 2.8848837209302324e-05, 'loss_1': 0.0304533950984478, 'loss_2': 0.01242828369140625, 'loss_3': -15.017335891723633, 'loss_4': 1.3796608448028564, 'epoch': 1.17}
{'loss': 0.1309, 'grad_norm': 34.348941802978516, 'learning_rate': 2.8843023255813953e-05, 'loss_1': 0.12078162282705307, 'loss_2': 0.0101470947265625, 'loss_3': -15.241829872131348, 'loss_4': 1.6474791765213013, 'epoch': 1.17}
{'loss': 0.0523, 'grad_norm': 16.118440628051758, 'learning_rate': 2.8837209302325585e-05, 'loss_1': 0.049027737230062485, 'loss_2': 0.003269195556640625, 'loss_3': -15.323105812072754, 'loss_4': 2.0942752361297607, 'epoch': 1.18}
{'loss': 0.0752, 'grad_norm': 29.525373458862305, 'learning_rate': 2.883139534883721e-05, 'loss_1': 0.07333710789680481, 'loss_2': 0.001819610595703125, 'loss_3': -15.109358787536621, 'loss_4': 2.3119192123413086, 'epoch': 1.19}
{'loss': 0.0762, 'grad_norm': 25.136436462402344, 'learning_rate': 2.882558139534884e-05, 'loss_1': 0.06674516946077347, 'loss_2': 0.0094757080078125, 'loss_3': -15.296789169311523, 'loss_4': 2.1711180210113525, 'epoch': 1.19}
[INFO|trainer.py:4228] 2025-01-21 12:25:30,420 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:30,420 >>   Batch size = 64
  4%|████████▉                                                                                                                                                                                                                   | 210/5160 [05:34<1:26:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:37,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03491584584116936, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.639, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.030367840081453323, 'eval_loss_2': 0.004548005759716034, 'eval_loss_3': -17.84307098388672, 'eval_loss_4': 1.8290812969207764, 'epoch': 1.19}
{'loss': 0.0683, 'grad_norm': 22.998668670654297, 'learning_rate': 2.8819767441860464e-05, 'loss_1': 0.06167377158999443, 'loss_2': 0.006591796875, 'loss_3': -15.033699035644531, 'loss_4': 2.015018939971924, 'epoch': 1.2}
{'loss': 0.1709, 'grad_norm': 38.74541091918945, 'learning_rate': 2.8813953488372093e-05, 'loss_1': 0.15525123476982117, 'loss_2': 0.01568603515625, 'loss_3': -15.043987274169922, 'loss_4': 2.7619240283966064, 'epoch': 1.2}
{'loss': 0.068, 'grad_norm': 22.75948715209961, 'learning_rate': 2.880813953488372e-05, 'loss_1': 0.06482156366109848, 'loss_2': 0.0031986236572265625, 'loss_3': -15.248088836669922, 'loss_4': 1.9808847904205322, 'epoch': 1.21}
{'loss': 0.0941, 'grad_norm': 26.854700088500977, 'learning_rate': 2.880232558139535e-05, 'loss_1': 0.09169512242078781, 'loss_2': 0.00238037109375, 'loss_3': -14.9495267868042, 'loss_4': 2.0901951789855957, 'epoch': 1.22}
{'loss': 0.1465, 'grad_norm': 18.97694206237793, 'learning_rate': 2.879651162790698e-05, 'loss_1': 0.13864213228225708, 'loss_2': 0.00782012939453125, 'loss_3': -15.05072021484375, 'loss_4': 2.3126220703125, 'epoch': 1.22}
[INFO|trainer.py:4228] 2025-01-21 12:25:37,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:37,795 >>   Batch size = 64
  4%|█████████▏                                                                                                                                                                                                                  | 215/5160 [05:42<1:26:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:45,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03158341348171234, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.542, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.026783928275108337, 'eval_loss_2': 0.004799485206604004, 'eval_loss_3': -17.934497833251953, 'eval_loss_4': 1.7316514253616333, 'epoch': 1.22}
{'loss': 0.0735, 'grad_norm': 26.048480987548828, 'learning_rate': 2.8790697674418604e-05, 'loss_1': 0.06701009720563889, 'loss_2': 0.006500244140625, 'loss_3': -15.0023193359375, 'loss_4': 1.4519696235656738, 'epoch': 1.23}
{'loss': 0.1244, 'grad_norm': 27.301773071289062, 'learning_rate': 2.8784883720930232e-05, 'loss_1': 0.11558466404676437, 'loss_2': 0.00884246826171875, 'loss_3': -15.373242378234863, 'loss_4': 2.405118465423584, 'epoch': 1.23}
{'loss': 0.0694, 'grad_norm': 19.008216857910156, 'learning_rate': 2.877906976744186e-05, 'loss_1': 0.0664760172367096, 'loss_2': 0.002948760986328125, 'loss_3': -15.111627578735352, 'loss_4': 1.8201961517333984, 'epoch': 1.24}
{'loss': 0.0716, 'grad_norm': 23.404762268066406, 'learning_rate': 2.877325581395349e-05, 'loss_1': 0.06878292560577393, 'loss_2': 0.00283050537109375, 'loss_3': -15.350035667419434, 'loss_4': 1.5671520233154297, 'epoch': 1.24}
{'loss': 0.036, 'grad_norm': 10.270594596862793, 'learning_rate': 2.876744186046512e-05, 'loss_1': 0.0317363515496254, 'loss_2': 0.004302978515625, 'loss_3': -15.262043952941895, 'loss_4': 2.434943675994873, 'epoch': 1.25}
[INFO|trainer.py:4228] 2025-01-21 12:25:45,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:45,179 >>   Batch size = 64
  4%|█████████▍                                                                                                                                                                                                                  | 220/5160 [05:49<1:25:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:52,557 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03255133330821991, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.603, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.018650099635124207, 'eval_loss_2': 0.013901233673095703, 'eval_loss_3': -18.092130661010742, 'eval_loss_4': 1.7319209575653076, 'epoch': 1.25}
{'loss': 0.0528, 'grad_norm': 16.540502548217773, 'learning_rate': 2.8761627906976744e-05, 'loss_1': 0.042852919548749924, 'loss_2': 0.009979248046875, 'loss_3': -15.294296264648438, 'loss_4': 1.3885363340377808, 'epoch': 1.26}
{'loss': 0.0791, 'grad_norm': 22.404714584350586, 'learning_rate': 2.8755813953488372e-05, 'loss_1': 0.07128404825925827, 'loss_2': 0.00780487060546875, 'loss_3': -15.399810791015625, 'loss_4': 2.6452367305755615, 'epoch': 1.26}
{'loss': 0.0627, 'grad_norm': 19.17802619934082, 'learning_rate': 2.875e-05, 'loss_1': 0.04685332253575325, 'loss_2': 0.015869140625, 'loss_3': -15.112815856933594, 'loss_4': 2.0000205039978027, 'epoch': 1.27}
{'loss': 0.0624, 'grad_norm': 16.711030960083008, 'learning_rate': 2.874418604651163e-05, 'loss_1': 0.04802681878209114, 'loss_2': 0.0143585205078125, 'loss_3': -15.23797607421875, 'loss_4': 2.401577949523926, 'epoch': 1.27}
{'loss': 0.0464, 'grad_norm': 12.682004928588867, 'learning_rate': 2.8738372093023255e-05, 'loss_1': 0.0371418222784996, 'loss_2': 0.0092620849609375, 'loss_3': -15.358458518981934, 'loss_4': 1.8189165592193604, 'epoch': 1.28}
[INFO|trainer.py:4228] 2025-01-21 12:25:52,557 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:52,557 >>   Batch size = 64
  4%|█████████▌                                                                                                                                                                                                                  | 225/5160 [05:57<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:25:59,931 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029559290036559105, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.805, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.02089158073067665, 'eval_loss_2': 0.008667707443237305, 'eval_loss_3': -18.080230712890625, 'eval_loss_4': 1.967651605606079, 'epoch': 1.28}
{'loss': 0.0378, 'grad_norm': 11.00581169128418, 'learning_rate': 2.8732558139534883e-05, 'loss_1': 0.036494288593530655, 'loss_2': 0.0012950897216796875, 'loss_3': -15.581674575805664, 'loss_4': 2.087125778198242, 'epoch': 1.28}
{'loss': 0.0964, 'grad_norm': 21.337295532226562, 'learning_rate': 2.8726744186046512e-05, 'loss_1': 0.09197424352169037, 'loss_2': 0.00446319580078125, 'loss_3': -15.15074634552002, 'loss_4': 2.4600753784179688, 'epoch': 1.29}
{'loss': 0.0617, 'grad_norm': 13.147310256958008, 'learning_rate': 2.872093023255814e-05, 'loss_1': 0.052232567220926285, 'loss_2': 0.009429931640625, 'loss_3': -15.367570877075195, 'loss_4': 2.2308409214019775, 'epoch': 1.3}
{'loss': 0.0413, 'grad_norm': 8.171175956726074, 'learning_rate': 2.871511627906977e-05, 'loss_1': 0.020336948335170746, 'loss_2': 0.02093505859375, 'loss_3': -15.279553413391113, 'loss_4': 1.6202387809753418, 'epoch': 1.3}
{'loss': 0.0805, 'grad_norm': 22.879682540893555, 'learning_rate': 2.8709302325581395e-05, 'loss_1': 0.07700874656438828, 'loss_2': 0.003444671630859375, 'loss_3': -15.376361846923828, 'loss_4': 1.9980846643447876, 'epoch': 1.31}
[INFO|trainer.py:4228] 2025-01-21 12:25:59,931 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:25:59,931 >>   Batch size = 64
  4%|█████████▊                                                                                                                                                                                                                  | 230/5160 [06:04<1:25:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:07,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03607327491044998, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.455, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.032688550651073456, 'eval_loss_2': 0.003384724259376526, 'eval_loss_3': -18.057804107666016, 'eval_loss_4': 1.815002202987671, 'epoch': 1.31}
{'loss': 0.0258, 'grad_norm': 7.971848964691162, 'learning_rate': 2.8703488372093023e-05, 'loss_1': 0.021246232092380524, 'loss_2': 0.004589080810546875, 'loss_3': -15.300230026245117, 'loss_4': 2.2122364044189453, 'epoch': 1.31}
{'loss': 0.0375, 'grad_norm': 14.338059425354004, 'learning_rate': 2.8697674418604652e-05, 'loss_1': 0.03436920791864395, 'loss_2': 0.0031223297119140625, 'loss_3': -15.38784122467041, 'loss_4': 2.0984549522399902, 'epoch': 1.32}
{'loss': 0.0336, 'grad_norm': 10.632039070129395, 'learning_rate': 2.869186046511628e-05, 'loss_1': 0.033116310834884644, 'loss_2': 0.00047969818115234375, 'loss_3': -15.353371620178223, 'loss_4': 1.2288613319396973, 'epoch': 1.33}
{'loss': 0.0535, 'grad_norm': 13.7983980178833, 'learning_rate': 2.868604651162791e-05, 'loss_1': 0.0445643812417984, 'loss_2': 0.008941650390625, 'loss_3': -15.389301300048828, 'loss_4': 1.934789776802063, 'epoch': 1.33}
{'loss': 0.0533, 'grad_norm': 18.08734893798828, 'learning_rate': 2.8680232558139534e-05, 'loss_1': 0.049204159528017044, 'loss_2': 0.00408172607421875, 'loss_3': -15.054258346557617, 'loss_4': 1.476241111755371, 'epoch': 1.34}
[INFO|trainer.py:4228] 2025-01-21 12:26:07,318 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:07,318 >>   Batch size = 64
  5%|██████████                                                                                                                                                                                                                  | 235/5160 [06:11<1:25:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:14,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.042744822800159454, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.025, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.03949658200144768, 'eval_loss_2': 0.0032482370734214783, 'eval_loss_3': -18.058223724365234, 'eval_loss_4': 1.2215991020202637, 'epoch': 1.34}
{'loss': 0.0876, 'grad_norm': 26.71566390991211, 'learning_rate': 2.8674418604651163e-05, 'loss_1': 0.0830908715724945, 'loss_2': 0.0045013427734375, 'loss_3': -15.179802894592285, 'loss_4': 1.1805446147918701, 'epoch': 1.34}
{'loss': 0.0862, 'grad_norm': 21.36412811279297, 'learning_rate': 2.866860465116279e-05, 'loss_1': 0.07873132079839706, 'loss_2': 0.00750732421875, 'loss_3': -15.215899467468262, 'loss_4': 1.440192461013794, 'epoch': 1.35}
{'loss': 0.1279, 'grad_norm': 31.223888397216797, 'learning_rate': 2.866279069767442e-05, 'loss_1': 0.1209767609834671, 'loss_2': 0.0069580078125, 'loss_3': -15.155872344970703, 'loss_4': 1.3936514854431152, 'epoch': 1.35}
{'loss': 0.0469, 'grad_norm': 15.440658569335938, 'learning_rate': 2.865697674418605e-05, 'loss_1': 0.04468946158885956, 'loss_2': 0.002208709716796875, 'loss_3': -15.095714569091797, 'loss_4': 1.2815439701080322, 'epoch': 1.36}
{'loss': 0.0395, 'grad_norm': 11.761393547058105, 'learning_rate': 2.8651162790697674e-05, 'loss_1': 0.03732210397720337, 'loss_2': 0.002166748046875, 'loss_3': -15.036521911621094, 'loss_4': 0.4709673523902893, 'epoch': 1.37}
[INFO|trainer.py:4228] 2025-01-21 12:26:14,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:14,691 >>   Batch size = 64
  5%|██████████▏                                                                                                                                                                                                                 | 240/5160 [06:19<1:25:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:22,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.048881031572818756, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.04615514725446701, 'eval_loss_2': 0.0027258843183517456, 'eval_loss_3': -18.026344299316406, 'eval_loss_4': 0.9784135818481445, 'epoch': 1.37}
{'loss': 0.045, 'grad_norm': 13.554910659790039, 'learning_rate': 2.8645348837209303e-05, 'loss_1': 0.04297943413257599, 'loss_2': 0.001979827880859375, 'loss_3': -15.234735488891602, 'loss_4': 1.100008249282837, 'epoch': 1.37}
{'loss': 0.067, 'grad_norm': 18.40825653076172, 'learning_rate': 2.863953488372093e-05, 'loss_1': 0.06540192663669586, 'loss_2': 0.001583099365234375, 'loss_3': -15.110016822814941, 'loss_4': 1.0735926628112793, 'epoch': 1.38}
{'loss': 0.0544, 'grad_norm': 22.603450775146484, 'learning_rate': 2.863372093023256e-05, 'loss_1': 0.053499240428209305, 'loss_2': 0.0009336471557617188, 'loss_3': -15.05980110168457, 'loss_4': 1.0885118246078491, 'epoch': 1.38}
{'loss': 0.0437, 'grad_norm': 14.792888641357422, 'learning_rate': 2.862790697674419e-05, 'loss_1': 0.042815789580345154, 'loss_2': 0.0008907318115234375, 'loss_3': -15.302738189697266, 'loss_4': 1.1246798038482666, 'epoch': 1.39}
{'loss': 0.0327, 'grad_norm': 11.27438735961914, 'learning_rate': 2.8622093023255814e-05, 'loss_1': 0.028120260685682297, 'loss_2': 0.00460052490234375, 'loss_3': -15.29978084564209, 'loss_4': 1.3622164726257324, 'epoch': 1.4}
[INFO|trainer.py:4228] 2025-01-21 12:26:22,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:22,062 >>   Batch size = 64
  5%|██████████▍                                                                                                                                                                                                                 | 245/5160 [06:26<1:25:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:29,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04589074105024338, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.648, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.038729485124349594, 'eval_loss_2': 0.007161259651184082, 'eval_loss_3': -18.10038185119629, 'eval_loss_4': 1.329899787902832, 'epoch': 1.4}
{'loss': 0.0401, 'grad_norm': 11.042028427124023, 'learning_rate': 2.8616279069767442e-05, 'loss_1': 0.03822780027985573, 'loss_2': 0.001861572265625, 'loss_3': -15.353702545166016, 'loss_4': 1.5839285850524902, 'epoch': 1.4}
{'loss': 0.0988, 'grad_norm': 29.824630737304688, 'learning_rate': 2.861046511627907e-05, 'loss_1': 0.09572490304708481, 'loss_2': 0.0030689239501953125, 'loss_3': -15.29761028289795, 'loss_4': 1.9057064056396484, 'epoch': 1.41}
{'loss': 0.0565, 'grad_norm': 16.429819107055664, 'learning_rate': 2.86046511627907e-05, 'loss_1': 0.05194879323244095, 'loss_2': 0.00450897216796875, 'loss_3': -15.179819107055664, 'loss_4': 1.9373960494995117, 'epoch': 1.41}
{'loss': 0.0477, 'grad_norm': 16.591463088989258, 'learning_rate': 2.8598837209302325e-05, 'loss_1': 0.042906615883111954, 'loss_2': 0.004817962646484375, 'loss_3': -15.361451148986816, 'loss_4': 1.8438488245010376, 'epoch': 1.42}
{'loss': 0.0576, 'grad_norm': 24.755727767944336, 'learning_rate': 2.8593023255813954e-05, 'loss_1': 0.05227665603160858, 'loss_2': 0.00531005859375, 'loss_3': -15.32545280456543, 'loss_4': 1.8535919189453125, 'epoch': 1.42}
[INFO|trainer.py:4228] 2025-01-21 12:26:29,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:29,449 >>   Batch size = 64
  5%|██████████▋                                                                                                                                                                                                                 | 250/5160 [06:33<1:25:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:36,830 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04156716167926788, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.451, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.03542486950755119, 'eval_loss_2': 0.006142288446426392, 'eval_loss_3': -18.20531463623047, 'eval_loss_4': 1.998866081237793, 'epoch': 1.42}
{'loss': 0.1121, 'grad_norm': 25.978519439697266, 'learning_rate': 2.8587209302325582e-05, 'loss_1': 0.10100197046995163, 'loss_2': 0.01110076904296875, 'loss_3': -15.58747673034668, 'loss_4': 2.6759285926818848, 'epoch': 1.43}
{'loss': 0.1654, 'grad_norm': 27.08574676513672, 'learning_rate': 2.858139534883721e-05, 'loss_1': 0.15305548906326294, 'loss_2': 0.0123443603515625, 'loss_3': -15.283137321472168, 'loss_4': 2.4433367252349854, 'epoch': 1.44}
{'loss': 0.1119, 'grad_norm': 30.36284065246582, 'learning_rate': 2.857558139534884e-05, 'loss_1': 0.09903602302074432, 'loss_2': 0.012847900390625, 'loss_3': -15.24015998840332, 'loss_4': 2.4645962715148926, 'epoch': 1.44}
{'loss': 0.0743, 'grad_norm': 16.273773193359375, 'learning_rate': 2.8569767441860465e-05, 'loss_1': 0.05889870226383209, 'loss_2': 0.01538848876953125, 'loss_3': -15.304222106933594, 'loss_4': 2.084569215774536, 'epoch': 1.45}
{'loss': 0.0796, 'grad_norm': 16.87556266784668, 'learning_rate': 2.8563953488372093e-05, 'loss_1': 0.06305956095457077, 'loss_2': 0.0164947509765625, 'loss_3': -15.44281005859375, 'loss_4': 2.4400482177734375, 'epoch': 1.45}
[INFO|trainer.py:4228] 2025-01-21 12:26:36,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:36,830 >>   Batch size = 64
  5%|██████████▊                                                                                                                                                                                                                 | 255/5160 [06:41<1:25:27,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:26:44,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04498451575636864, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.03776174411177635, 'eval_loss_2': 0.007222771644592285, 'eval_loss_3': -18.221176147460938, 'eval_loss_4': 1.9383517503738403, 'epoch': 1.45}
{'loss': 0.0941, 'grad_norm': 22.541820526123047, 'learning_rate': 2.8558139534883722e-05, 'loss_1': 0.08473758399486542, 'loss_2': 0.0093994140625, 'loss_3': -15.466184616088867, 'loss_4': 2.9966185092926025, 'epoch': 1.46}
{'loss': 0.1046, 'grad_norm': 22.73011589050293, 'learning_rate': 2.855232558139535e-05, 'loss_1': 0.09492489695549011, 'loss_2': 0.00970458984375, 'loss_3': -15.647692680358887, 'loss_4': 2.0817129611968994, 'epoch': 1.47}
{'loss': 0.0593, 'grad_norm': 16.39105987548828, 'learning_rate': 2.854651162790698e-05, 'loss_1': 0.05808408185839653, 'loss_2': 0.00118255615234375, 'loss_3': -15.322803497314453, 'loss_4': 1.7097444534301758, 'epoch': 1.47}
{'loss': 0.2054, 'grad_norm': 37.26625061035156, 'learning_rate': 2.8540697674418605e-05, 'loss_1': 0.2016039490699768, 'loss_2': 0.00382232666015625, 'loss_3': -15.510364532470703, 'loss_4': 2.1372416019439697, 'epoch': 1.48}
{'loss': 0.1106, 'grad_norm': 25.783803939819336, 'learning_rate': 2.8534883720930233e-05, 'loss_1': 0.10237447172403336, 'loss_2': 0.0082244873046875, 'loss_3': -15.616739273071289, 'loss_4': 1.334097146987915, 'epoch': 1.48}
[INFO|trainer.py:4228] 2025-01-21 12:26:44,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:44,216 >>   Batch size = 64
  5%|███████████                                                                                                                                                                                                                 | 260/5160 [06:48<1:25:21,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:26:51,610 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05344337224960327, 'eval_runtime': 3.8179, 'eval_samples_per_second': 268.211, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.04055685177445412, 'eval_loss_2': 0.012886524200439453, 'eval_loss_3': -18.245895385742188, 'eval_loss_4': 1.2676353454589844, 'epoch': 1.48}
{'loss': 0.0745, 'grad_norm': 24.771955490112305, 'learning_rate': 2.852906976744186e-05, 'loss_1': 0.06657350808382034, 'loss_2': 0.00789642333984375, 'loss_3': -15.454107284545898, 'loss_4': 1.1265897750854492, 'epoch': 1.49}
{'loss': 0.0469, 'grad_norm': 9.742911338806152, 'learning_rate': 2.852325581395349e-05, 'loss_1': 0.033947158604860306, 'loss_2': 0.01300048828125, 'loss_3': -15.706683158874512, 'loss_4': 1.597959041595459, 'epoch': 1.49}
{'loss': 0.1257, 'grad_norm': 29.655288696289062, 'learning_rate': 2.851744186046512e-05, 'loss_1': 0.12169013172388077, 'loss_2': 0.00402069091796875, 'loss_3': -15.51211929321289, 'loss_4': 1.6812448501586914, 'epoch': 1.5}
{'loss': 0.1328, 'grad_norm': 38.990177154541016, 'learning_rate': 2.8511627906976744e-05, 'loss_1': 0.12477532774209976, 'loss_2': 0.0080718994140625, 'loss_3': -15.584696769714355, 'loss_4': 2.1116132736206055, 'epoch': 1.51}
{'loss': 0.1278, 'grad_norm': 23.8985652923584, 'learning_rate': 2.8505813953488373e-05, 'loss_1': 0.12356270104646683, 'loss_2': 0.004238128662109375, 'loss_3': -15.59715747833252, 'loss_4': 1.5250604152679443, 'epoch': 1.51}
[INFO|trainer.py:4228] 2025-01-21 12:26:51,610 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:51,610 >>   Batch size = 64
  5%|███████████▎                                                                                                                                                                                                                | 265/5160 [06:56<1:25:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:26:58,995 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04716012626886368, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.306, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.04454490914940834, 'eval_loss_2': 0.002615220844745636, 'eval_loss_3': -18.20098876953125, 'eval_loss_4': 0.8466655015945435, 'epoch': 1.51}
{'loss': 0.1386, 'grad_norm': 46.211883544921875, 'learning_rate': 2.8499999999999998e-05, 'loss_1': 0.13248592615127563, 'loss_2': 0.0061492919921875, 'loss_3': -15.322423934936523, 'loss_4': 1.0476326942443848, 'epoch': 1.52}
{'loss': 0.1182, 'grad_norm': 38.57194137573242, 'learning_rate': 2.849418604651163e-05, 'loss_1': 0.10723689943552017, 'loss_2': 0.0109710693359375, 'loss_3': -15.463945388793945, 'loss_4': 0.849841833114624, 'epoch': 1.52}
{'loss': 0.0946, 'grad_norm': 20.54681968688965, 'learning_rate': 2.848837209302326e-05, 'loss_1': 0.08284910023212433, 'loss_2': 0.01177978515625, 'loss_3': -15.313000679016113, 'loss_4': 0.9999645948410034, 'epoch': 1.53}
{'loss': 0.0791, 'grad_norm': 26.61089515686035, 'learning_rate': 2.8482558139534884e-05, 'loss_1': 0.07513230293989182, 'loss_2': 0.00400543212890625, 'loss_3': -15.082435607910156, 'loss_4': 0.44243133068084717, 'epoch': 1.53}
{'loss': 0.1221, 'grad_norm': 24.656766891479492, 'learning_rate': 2.8476744186046513e-05, 'loss_1': 0.1139313280582428, 'loss_2': 0.00815582275390625, 'loss_3': -15.41932487487793, 'loss_4': 0.8014014363288879, 'epoch': 1.54}
[INFO|trainer.py:4228] 2025-01-21 12:26:58,995 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:26:58,995 >>   Batch size = 64
  5%|███████████▌                                                                                                                                                                                                                | 270/5160 [07:03<1:25:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:06,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10414634644985199, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.576, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.09133349359035492, 'eval_loss_2': 0.01281285285949707, 'eval_loss_3': -17.90468406677246, 'eval_loss_4': 1.0800162553787231, 'epoch': 1.54}
{'loss': 0.1892, 'grad_norm': 46.04573059082031, 'learning_rate': 2.8470930232558138e-05, 'loss_1': 0.17568263411521912, 'loss_2': 0.0134735107421875, 'loss_3': -15.204578399658203, 'loss_4': 1.2558513879776, 'epoch': 1.55}
{'loss': 0.1231, 'grad_norm': 27.41176414489746, 'learning_rate': 2.846511627906977e-05, 'loss_1': 0.1114993691444397, 'loss_2': 0.011627197265625, 'loss_3': -14.973880767822266, 'loss_4': 1.1247437000274658, 'epoch': 1.55}
{'loss': 0.126, 'grad_norm': 42.94756317138672, 'learning_rate': 2.8459302325581395e-05, 'loss_1': 0.1091100350022316, 'loss_2': 0.01690673828125, 'loss_3': -15.161072731018066, 'loss_4': 0.9170486330986023, 'epoch': 1.56}
{'loss': 0.0463, 'grad_norm': 13.946563720703125, 'learning_rate': 2.8453488372093024e-05, 'loss_1': 0.04060285538434982, 'loss_2': 0.005657196044921875, 'loss_3': -15.146404266357422, 'loss_4': 0.4004274606704712, 'epoch': 1.56}
{'loss': 0.0986, 'grad_norm': 29.569360733032227, 'learning_rate': 2.8447674418604652e-05, 'loss_1': 0.08850693702697754, 'loss_2': 0.01012420654296875, 'loss_3': -15.162026405334473, 'loss_4': 0.3586511015892029, 'epoch': 1.57}
[INFO|trainer.py:4228] 2025-01-21 12:27:06,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:06,374 >>   Batch size = 64
  5%|███████████▋                                                                                                                                                                                                                | 275/5160 [07:10<1:24:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:13,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.07209315896034241, 'eval_runtime': 3.823, 'eval_samples_per_second': 267.855, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.06432405114173889, 'eval_loss_2': 0.007769107818603516, 'eval_loss_3': -17.947906494140625, 'eval_loss_4': 1.1520922183990479, 'epoch': 1.57}
{'loss': 0.0436, 'grad_norm': 14.989006042480469, 'learning_rate': 2.8441860465116278e-05, 'loss_1': 0.03885820508003235, 'loss_2': 0.00469207763671875, 'loss_3': -15.445167541503906, 'loss_4': 1.2810306549072266, 'epoch': 1.58}
{'loss': 0.0416, 'grad_norm': 13.96524429321289, 'learning_rate': 2.843604651162791e-05, 'loss_1': 0.04033105447888374, 'loss_2': 0.00128173828125, 'loss_3': -15.254332542419434, 'loss_4': 1.0858640670776367, 'epoch': 1.58}
{'loss': 0.1094, 'grad_norm': 33.464149475097656, 'learning_rate': 2.8430232558139535e-05, 'loss_1': 0.10633619874715805, 'loss_2': 0.0030765533447265625, 'loss_3': -15.490550994873047, 'loss_4': 1.667222023010254, 'epoch': 1.59}
{'loss': 0.0463, 'grad_norm': 14.397046089172363, 'learning_rate': 2.8424418604651164e-05, 'loss_1': 0.044418442994356155, 'loss_2': 0.0019197463989257812, 'loss_3': -15.642942428588867, 'loss_4': 1.5165832042694092, 'epoch': 1.59}
{'loss': 0.0663, 'grad_norm': 20.0686092376709, 'learning_rate': 2.8418604651162792e-05, 'loss_1': 0.059538066387176514, 'loss_2': 0.0067138671875, 'loss_3': -15.31572437286377, 'loss_4': 1.6619826555252075, 'epoch': 1.6}
[INFO|trainer.py:4228] 2025-01-21 12:27:13,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:13,757 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:18<1:24:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:21,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.033555686473846436, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.71, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.02686418406665325, 'eval_loss_2': 0.006691500544548035, 'eval_loss_3': -18.15810775756836, 'eval_loss_4': 1.8019143342971802, 'epoch': 1.6}
{'loss': 0.0763, 'grad_norm': 28.35833740234375, 'learning_rate': 2.8412790697674418e-05, 'loss_1': 0.06882664561271667, 'loss_2': 0.0074920654296875, 'loss_3': -15.45486831665039, 'loss_4': 1.9350500106811523, 'epoch': 1.6}
{'loss': 0.0633, 'grad_norm': 18.319011688232422, 'learning_rate': 2.840697674418605e-05, 'loss_1': 0.05798088759183884, 'loss_2': 0.0053253173828125, 'loss_3': -15.274158477783203, 'loss_4': 1.9505977630615234, 'epoch': 1.61}
{'loss': 0.0507, 'grad_norm': 12.995308876037598, 'learning_rate': 2.8401162790697675e-05, 'loss_1': 0.04626573249697685, 'loss_2': 0.00443267822265625, 'loss_3': -15.250958442687988, 'loss_4': 2.654585123062134, 'epoch': 1.62}
{'loss': 0.0997, 'grad_norm': 38.87879943847656, 'learning_rate': 2.8395348837209303e-05, 'loss_1': 0.09675469994544983, 'loss_2': 0.002899169921875, 'loss_3': -15.182588577270508, 'loss_4': 3.0689804553985596, 'epoch': 1.62}
{'loss': 0.0756, 'grad_norm': 17.26607894897461, 'learning_rate': 2.838953488372093e-05, 'loss_1': 0.06841979175806046, 'loss_2': 0.007205963134765625, 'loss_3': -15.485817909240723, 'loss_4': 3.492264747619629, 'epoch': 1.63}
[INFO|trainer.py:4228] 2025-01-21 12:27:21,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:21,141 >>   Batch size = 64
  5%|███████████▉                                                                                                                                                                                                                | 280/5160 [07:22<1:24:54,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:27:24,954 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-280
[INFO|configuration_utils.py:420] 2025-01-21 12:27:24,956 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-280/config.json                                                                             
{'eval_loss': 0.02085837349295616, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.617, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01754024252295494, 'eval_loss_2': 0.0033181309700012207, 'eval_loss_3': -18.25267791748047, 'eval_loss_4': 2.883831739425659, 'epoch': 1.63}
[INFO|modeling_utils.py:2988] 2025-01-21 12:27:25,467 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-280/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:27:25,468 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-280/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:27:25,469 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-280/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:27:26,391 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-190] due to args.save_total_limit
  6%|████████████▏                                                                                                                                                                                                               | 285/5160 [07:27<1:33:40,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:27:30,044 >>
{'loss': 0.0432, 'grad_norm': 13.930363655090332, 'learning_rate': 2.8383720930232557e-05, 'loss_1': 0.0411556176841259, 'loss_2': 0.002056121826171875, 'loss_3': -15.488035202026367, 'loss_4': 3.1613149642944336, 'epoch': 1.63}
{'loss': 0.0645, 'grad_norm': 15.544522285461426, 'learning_rate': 2.837790697674419e-05, 'loss_1': 0.05592777580022812, 'loss_2': 0.0085296630859375, 'loss_3': -15.405413627624512, 'loss_4': 3.2724294662475586, 'epoch': 1.64}
{'loss': 0.0772, 'grad_norm': 21.319345474243164, 'learning_rate': 2.8372093023255815e-05, 'loss_1': 0.07346668839454651, 'loss_2': 0.00370025634765625, 'loss_3': -15.406332015991211, 'loss_4': 2.272364616394043, 'epoch': 1.65}
{'loss': 0.0837, 'grad_norm': 17.3983097076416, 'learning_rate': 2.8366279069767443e-05, 'loss_1': 0.07503699511289597, 'loss_2': 0.008636474609375, 'loss_3': -15.420196533203125, 'loss_4': 3.73997163772583, 'epoch': 1.65}
{'loss': 0.0909, 'grad_norm': 27.744985580444336, 'learning_rate': 2.836046511627907e-05, 'loss_1': 0.08415008336305618, 'loss_2': 0.00672149658203125, 'loss_3': -15.524072647094727, 'loss_4': 2.8881382942199707, 'epoch': 1.66}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:27:30,045 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:30,045 >>   Batch size = 64
  6%|████████████▎                                                                                                                                                                                                               | 290/5160 [07:34<1:26:00,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:27:37,410 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026985827833414078, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.088, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.018208684399724007, 'eval_loss_2': 0.008777141571044922, 'eval_loss_3': -18.244342803955078, 'eval_loss_4': 2.3095197677612305, 'epoch': 1.66}
{'loss': 0.064, 'grad_norm': 24.720876693725586, 'learning_rate': 2.8354651162790697e-05, 'loss_1': 0.05531555414199829, 'loss_2': 0.008636474609375, 'loss_3': -15.329825401306152, 'loss_4': 2.7186622619628906, 'epoch': 1.66}
{'loss': 0.0564, 'grad_norm': 18.20937156677246, 'learning_rate': 2.8348837209302326e-05, 'loss_1': 0.05082112178206444, 'loss_2': 0.0055694580078125, 'loss_3': -15.509403228759766, 'loss_4': 2.0077621936798096, 'epoch': 1.67}
{'loss': 0.0647, 'grad_norm': 18.606760025024414, 'learning_rate': 2.8343023255813954e-05, 'loss_1': 0.055096086114645004, 'loss_2': 0.00965118408203125, 'loss_3': -15.187163352966309, 'loss_4': 2.441737174987793, 'epoch': 1.67}
{'loss': 0.1003, 'grad_norm': 24.23075294494629, 'learning_rate': 2.8337209302325583e-05, 'loss_1': 0.09111402928829193, 'loss_2': 0.00920867919921875, 'loss_3': -15.404012680053711, 'loss_4': 2.9786548614501953, 'epoch': 1.68}
{'loss': 0.0638, 'grad_norm': 20.278301239013672, 'learning_rate': 2.8331395348837208e-05, 'loss_1': 0.055119071155786514, 'loss_2': 0.0086822509765625, 'loss_3': -15.391290664672852, 'loss_4': 2.446422576904297, 'epoch': 1.69}
[INFO|trainer.py:4228] 2025-01-21 12:27:37,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:37,410 >>   Batch size = 64
  6%|████████████▌                                                                                                                                                                                                               | 295/5160 [07:42<1:25:43,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:27:44,959 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03586959093809128, 'eval_runtime': 3.9892, 'eval_samples_per_second': 256.695, 'eval_steps_per_second': 4.011, 'eval_loss_1': 0.03178313747048378, 'eval_loss_2': 0.004086457192897797, 'eval_loss_3': -18.160324096679688, 'eval_loss_4': 2.2394556999206543, 'epoch': 1.69}
{'loss': 0.1683, 'grad_norm': 51.171897888183594, 'learning_rate': 2.8325581395348837e-05, 'loss_1': 0.15889662504196167, 'loss_2': 0.0094451904296875, 'loss_3': -15.334426879882812, 'loss_4': 3.1226840019226074, 'epoch': 1.69}
{'loss': 0.0408, 'grad_norm': 19.802934646606445, 'learning_rate': 2.8319767441860465e-05, 'loss_1': 0.04024637117981911, 'loss_2': 0.0005159378051757812, 'loss_3': -15.578039169311523, 'loss_4': 2.446188449859619, 'epoch': 1.7}
{'loss': 0.0943, 'grad_norm': 28.578506469726562, 'learning_rate': 2.8313953488372094e-05, 'loss_1': 0.09366518259048462, 'loss_2': 0.0005903244018554688, 'loss_3': -15.141569137573242, 'loss_4': 2.100821018218994, 'epoch': 1.7}
{'loss': 0.1356, 'grad_norm': 32.46905517578125, 'learning_rate': 2.8308139534883723e-05, 'loss_1': 0.12939175963401794, 'loss_2': 0.0061798095703125, 'loss_3': -15.817627906799316, 'loss_4': 2.858654260635376, 'epoch': 1.71}
{'loss': 0.1474, 'grad_norm': 37.08457946777344, 'learning_rate': 2.8302325581395348e-05, 'loss_1': 0.14313487708568573, 'loss_2': 0.004253387451171875, 'loss_3': -15.62589168548584, 'loss_4': 2.5797924995422363, 'epoch': 1.72}
[INFO|trainer.py:4228] 2025-01-21 12:27:44,959 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:44,959 >>   Batch size = 64
  6%|████████████▊                                                                                                                                                                                                               | 300/5160 [07:49<1:24:43,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:27:52,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022626785561442375, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.018857862800359726, 'eval_loss_2': 0.0037689208984375, 'eval_loss_3': -18.3106746673584, 'eval_loss_4': 2.490879535675049, 'epoch': 1.72}
{'loss': 0.029, 'grad_norm': 11.63923168182373, 'learning_rate': 2.829651162790698e-05, 'loss_1': 0.026326877996325493, 'loss_2': 0.00267791748046875, 'loss_3': -15.331697463989258, 'loss_4': 2.286987781524658, 'epoch': 1.72}
{'loss': 0.0682, 'grad_norm': 19.93084144592285, 'learning_rate': 2.8290697674418605e-05, 'loss_1': 0.06049470230937004, 'loss_2': 0.007694244384765625, 'loss_3': -15.561967849731445, 'loss_4': 2.55361008644104, 'epoch': 1.73}
{'loss': 0.058, 'grad_norm': 25.636268615722656, 'learning_rate': 2.8284883720930234e-05, 'loss_1': 0.05230829492211342, 'loss_2': 0.005649566650390625, 'loss_3': -15.514153480529785, 'loss_4': 3.2944414615631104, 'epoch': 1.73}
{'loss': 0.0423, 'grad_norm': 20.250446319580078, 'learning_rate': 2.827906976744186e-05, 'loss_1': 0.039291515946388245, 'loss_2': 0.002994537353515625, 'loss_3': -15.578475952148438, 'loss_4': 3.333301544189453, 'epoch': 1.74}
{'loss': 0.0885, 'grad_norm': 19.806901931762695, 'learning_rate': 2.8273255813953488e-05, 'loss_1': 0.0715760886669159, 'loss_2': 0.0168914794921875, 'loss_3': -15.43237590789795, 'loss_4': 2.613804340362549, 'epoch': 1.74}
[INFO|trainer.py:4228] 2025-01-21 12:27:52,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:52,338 >>   Batch size = 64
  6%|█████████████                                                                                                                                                                                                               | 305/5160 [07:56<1:24:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:27:59,710 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.029934056103229523, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.495, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01766837388277054, 'eval_loss_2': 0.012265682220458984, 'eval_loss_3': -18.315868377685547, 'eval_loss_4': 1.906461238861084, 'epoch': 1.74}
{'loss': 0.0826, 'grad_norm': 26.52582359313965, 'learning_rate': 2.826744186046512e-05, 'loss_1': 0.08016521483659744, 'loss_2': 0.002483367919921875, 'loss_3': -15.347230911254883, 'loss_4': 2.938683032989502, 'epoch': 1.75}
{'loss': 0.0648, 'grad_norm': 13.62826156616211, 'learning_rate': 2.8261627906976745e-05, 'loss_1': 0.04967348277568817, 'loss_2': 0.015106201171875, 'loss_3': -15.336515426635742, 'loss_4': 1.8475382328033447, 'epoch': 1.76}
{'loss': 0.0303, 'grad_norm': 8.92485523223877, 'learning_rate': 2.8255813953488374e-05, 'loss_1': 0.026544731110334396, 'loss_2': 0.003795623779296875, 'loss_3': -15.449715614318848, 'loss_4': 2.3948349952697754, 'epoch': 1.76}
{'loss': 0.0864, 'grad_norm': 22.147708892822266, 'learning_rate': 2.825e-05, 'loss_1': 0.07156692445278168, 'loss_2': 0.01483154296875, 'loss_3': -15.295629501342773, 'loss_4': 2.174811363220215, 'epoch': 1.77}
{'loss': 0.1178, 'grad_norm': 34.00338363647461, 'learning_rate': 2.8244186046511628e-05, 'loss_1': 0.11224686354398727, 'loss_2': 0.00551605224609375, 'loss_3': -15.559990882873535, 'loss_4': 1.792306661605835, 'epoch': 1.77}
[INFO|trainer.py:4228] 2025-01-21 12:27:59,710 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:27:59,710 >>   Batch size = 64
  6%|█████████████▏                                                                                                                                                                                                              | 310/5160 [08:04<1:24:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:07,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022059792652726173, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.78, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01391863077878952, 'eval_loss_2': 0.008141160011291504, 'eval_loss_3': -18.27799415588379, 'eval_loss_4': 1.4380135536193848, 'epoch': 1.77}
{'loss': 0.1172, 'grad_norm': 36.0355224609375, 'learning_rate': 2.823837209302326e-05, 'loss_1': 0.11443419009447098, 'loss_2': 0.002788543701171875, 'loss_3': -15.350666046142578, 'loss_4': 1.9929144382476807, 'epoch': 1.78}
{'loss': 0.0869, 'grad_norm': 19.50861358642578, 'learning_rate': 2.8232558139534885e-05, 'loss_1': 0.06968581676483154, 'loss_2': 0.0171661376953125, 'loss_3': -15.401163101196289, 'loss_4': 1.9510647058486938, 'epoch': 1.78}
{'loss': 0.0831, 'grad_norm': 20.376142501831055, 'learning_rate': 2.8226744186046513e-05, 'loss_1': 0.06774702668190002, 'loss_2': 0.0153350830078125, 'loss_3': -15.237013816833496, 'loss_4': 1.4429936408996582, 'epoch': 1.79}
{'loss': 0.1121, 'grad_norm': 21.463451385498047, 'learning_rate': 2.822093023255814e-05, 'loss_1': 0.08318879455327988, 'loss_2': 0.02886962890625, 'loss_3': -15.398874282836914, 'loss_4': 2.0419859886169434, 'epoch': 1.8}
{'loss': 0.0714, 'grad_norm': 17.708892822265625, 'learning_rate': 2.8215116279069767e-05, 'loss_1': 0.04632596671581268, 'loss_2': 0.0250701904296875, 'loss_3': -15.576223373413086, 'loss_4': 1.5502277612686157, 'epoch': 1.8}
[INFO|trainer.py:4228] 2025-01-21 12:28:07,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:07,088 >>   Batch size = 64
  6%|█████████████▍                                                                                                                                                                                                              | 315/5160 [08:11<1:24:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:14,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.041221559047698975, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.104, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.021533433347940445, 'eval_loss_2': 0.019688129425048828, 'eval_loss_3': -18.18552589416504, 'eval_loss_4': 1.5375373363494873, 'epoch': 1.8}
{'loss': 0.0599, 'grad_norm': 17.774274826049805, 'learning_rate': 2.8209302325581396e-05, 'loss_1': 0.04141220822930336, 'loss_2': 0.0184478759765625, 'loss_3': -15.477087020874023, 'loss_4': 1.42698073387146, 'epoch': 1.81}
{'loss': 0.0524, 'grad_norm': 10.556406021118164, 'learning_rate': 2.8203488372093025e-05, 'loss_1': 0.036478687077760696, 'loss_2': 0.015960693359375, 'loss_3': -15.597002029418945, 'loss_4': 1.3725829124450684, 'epoch': 1.81}
{'loss': 0.1832, 'grad_norm': 34.423919677734375, 'learning_rate': 2.8197674418604653e-05, 'loss_1': 0.16726458072662354, 'loss_2': 0.0159149169921875, 'loss_3': -15.26494312286377, 'loss_4': 1.7299833297729492, 'epoch': 1.82}
{'loss': 0.0441, 'grad_norm': 11.417731285095215, 'learning_rate': 2.819186046511628e-05, 'loss_1': 0.033018674701452255, 'loss_2': 0.01108551025390625, 'loss_3': -15.494327545166016, 'loss_4': 1.9706281423568726, 'epoch': 1.83}
{'loss': 0.1003, 'grad_norm': 29.32783317565918, 'learning_rate': 2.8186046511627907e-05, 'loss_1': 0.09859440475702286, 'loss_2': 0.0017137527465820312, 'loss_3': -15.492344856262207, 'loss_4': 1.7932826280593872, 'epoch': 1.83}
[INFO|trainer.py:4228] 2025-01-21 12:28:14,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:14,461 >>   Batch size = 64
  6%|█████████████▋                                                                                                                                                                                                              | 320/5160 [08:18<1:23:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:21,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025006629526615143, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.017445938661694527, 'eval_loss_2': 0.007560692727565765, 'eval_loss_3': -18.252429962158203, 'eval_loss_4': 1.1184813976287842, 'epoch': 1.83}
{'loss': 0.0438, 'grad_norm': 10.870849609375, 'learning_rate': 2.8180232558139536e-05, 'loss_1': 0.04160181060433388, 'loss_2': 0.0022106170654296875, 'loss_3': -15.490975379943848, 'loss_4': 1.6216659545898438, 'epoch': 1.84}
{'loss': 0.0845, 'grad_norm': 24.382186889648438, 'learning_rate': 2.8174418604651164e-05, 'loss_1': 0.07742171734571457, 'loss_2': 0.00711822509765625, 'loss_3': -15.625468254089355, 'loss_4': 1.9239675998687744, 'epoch': 1.84}
{'loss': 0.0458, 'grad_norm': 7.968959808349609, 'learning_rate': 2.8168604651162793e-05, 'loss_1': 0.025305241346359253, 'loss_2': 0.0205078125, 'loss_3': -15.462739944458008, 'loss_4': 1.2766493558883667, 'epoch': 1.85}
{'loss': 0.0724, 'grad_norm': 17.68583106994629, 'learning_rate': 2.8162790697674418e-05, 'loss_1': 0.05096527189016342, 'loss_2': 0.021392822265625, 'loss_3': -15.527579307556152, 'loss_4': 1.1553640365600586, 'epoch': 1.85}
{'loss': 0.0753, 'grad_norm': 15.83963680267334, 'learning_rate': 2.8156976744186047e-05, 'loss_1': 0.05872144550085068, 'loss_2': 0.0165863037109375, 'loss_3': -15.474366188049316, 'loss_4': 1.4422837495803833, 'epoch': 1.86}
[INFO|trainer.py:4228] 2025-01-21 12:28:21,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:21,825 >>   Batch size = 64
  6%|█████████████▊                                                                                                                                                                                                              | 325/5160 [08:26<1:23:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:29,192 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03325415775179863, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015116228722035885, 'eval_loss_2': 0.01813793182373047, 'eval_loss_3': -18.262264251708984, 'eval_loss_4': 0.9079754948616028, 'epoch': 1.86}
{'loss': 0.0473, 'grad_norm': 7.353935718536377, 'learning_rate': 2.8151162790697675e-05, 'loss_1': 0.024281393736600876, 'loss_2': 0.0230560302734375, 'loss_3': -15.50722885131836, 'loss_4': 0.3418349623680115, 'epoch': 1.87}
{'loss': 0.0434, 'grad_norm': 9.821332931518555, 'learning_rate': 2.8145348837209304e-05, 'loss_1': 0.026583850383758545, 'loss_2': 0.016845703125, 'loss_3': -15.662405014038086, 'loss_4': 1.0010442733764648, 'epoch': 1.87}
{'loss': 0.048, 'grad_norm': 19.59132194519043, 'learning_rate': 2.813953488372093e-05, 'loss_1': 0.03801388293504715, 'loss_2': 0.0100250244140625, 'loss_3': -15.431571960449219, 'loss_4': 0.692585289478302, 'epoch': 1.88}
{'loss': 0.0803, 'grad_norm': 30.604475021362305, 'learning_rate': 2.8133720930232558e-05, 'loss_1': 0.07914355397224426, 'loss_2': 0.001194000244140625, 'loss_3': -15.456323623657227, 'loss_4': 1.2432584762573242, 'epoch': 1.88}
{'loss': 0.0424, 'grad_norm': 16.26194953918457, 'learning_rate': 2.8127906976744187e-05, 'loss_1': 0.04223181679844856, 'loss_2': 0.00016069412231445312, 'loss_3': -15.481992721557617, 'loss_4': 0.7304054498672485, 'epoch': 1.89}
[INFO|trainer.py:4228] 2025-01-21 12:28:29,193 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:29,193 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:33<1:23:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:28:36,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024539537727832794, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.696, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.017147013917565346, 'eval_loss_2': 0.007392525672912598, 'eval_loss_3': -18.206310272216797, 'eval_loss_4': 1.0802757740020752, 'epoch': 1.89}
{'loss': 0.0418, 'grad_norm': 10.641304016113281, 'learning_rate': 2.8122093023255815e-05, 'loss_1': 0.026401441544294357, 'loss_2': 0.0154266357421875, 'loss_3': -15.604101181030273, 'loss_4': 1.51676607131958, 'epoch': 1.9}
{'loss': 0.0496, 'grad_norm': 26.11192512512207, 'learning_rate': 2.8116279069767444e-05, 'loss_1': 0.04572907090187073, 'loss_2': 0.00382232666015625, 'loss_3': -15.704882621765137, 'loss_4': 1.3717583417892456, 'epoch': 1.9}
{'loss': 0.0499, 'grad_norm': 14.65743637084961, 'learning_rate': 2.811046511627907e-05, 'loss_1': 0.03621111810207367, 'loss_2': 0.013702392578125, 'loss_3': -15.449311256408691, 'loss_4': 1.3342863321304321, 'epoch': 1.91}
{'loss': 0.0424, 'grad_norm': 13.217952728271484, 'learning_rate': 2.8104651162790698e-05, 'loss_1': 0.03745526447892189, 'loss_2': 0.004974365234375, 'loss_3': -15.42837905883789, 'loss_4': 0.007163539528846741, 'epoch': 1.91}
{'loss': 0.0433, 'grad_norm': 11.624122619628906, 'learning_rate': 2.8098837209302326e-05, 'loss_1': 0.039986055344343185, 'loss_2': 0.0033550262451171875, 'loss_3': -15.38744068145752, 'loss_4': 0.4486839175224304, 'epoch': 1.92}
[INFO|trainer.py:4228] 2025-01-21 12:28:36,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:36,569 >>   Batch size = 64
  6%|██████████████                                                                                                                                                                                                              | 330/5160 [08:37<1:23:54,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:28:40,381 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-330
[INFO|configuration_utils.py:420] 2025-01-21 12:28:40,383 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-330/config.json                                                                             
{'eval_loss': 0.018803223967552185, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.68, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.015425179153680801, 'eval_loss_2': 0.0033780448138713837, 'eval_loss_3': -18.229351043701172, 'eval_loss_4': 0.34840530157089233, 'epoch': 1.92}
[INFO|modeling_utils.py:2988] 2025-01-21 12:28:40,867 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-330/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:28:40,869 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-330/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:28:40,869 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-330/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:28:41,808 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-280] due to args.save_total_limit
  6%|██████████████▎                                                                                                                                                                                                             | 335/5160 [08:42<1:32:28,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:28:45,454 >>
{'loss': 0.0399, 'grad_norm': 13.952774047851562, 'learning_rate': 2.8093023255813955e-05, 'loss_1': 0.03538317233324051, 'loss_2': 0.00449371337890625, 'loss_3': -15.506542205810547, 'loss_4': 0.5976847410202026, 'epoch': 1.92}
{'loss': 0.0311, 'grad_norm': 12.22203540802002, 'learning_rate': 2.8087209302325584e-05, 'loss_1': 0.028013287112116814, 'loss_2': 0.003055572509765625, 'loss_3': -15.59449291229248, 'loss_4': 0.2560819089412689, 'epoch': 1.93}
{'loss': 0.1141, 'grad_norm': 32.157135009765625, 'learning_rate': 2.808139534883721e-05, 'loss_1': 0.10845617949962616, 'loss_2': 0.005664825439453125, 'loss_3': -15.301660537719727, 'loss_4': 0.6357425451278687, 'epoch': 1.94}
{'loss': 0.0435, 'grad_norm': 11.02971076965332, 'learning_rate': 2.8075581395348838e-05, 'loss_1': 0.032082125544548035, 'loss_2': 0.0114288330078125, 'loss_3': -15.337593078613281, 'loss_4': 0.10032595694065094, 'epoch': 1.94}
{'loss': 0.059, 'grad_norm': 15.352887153625488, 'learning_rate': 2.8069767441860463e-05, 'loss_1': 0.04873591288924217, 'loss_2': 0.0102996826171875, 'loss_3': -15.586990356445312, 'loss_4': -0.43591344356536865, 'epoch': 1.95}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:28:45,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:45,454 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:49<1:25:04,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:28:52,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020140357315540314, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.99, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013249345123767853, 'eval_loss_2': 0.006891012191772461, 'eval_loss_3': -18.255512237548828, 'eval_loss_4': -0.009594576433300972, 'epoch': 1.95}
{'loss': 0.0364, 'grad_norm': 9.981952667236328, 'learning_rate': 2.8063953488372095e-05, 'loss_1': 0.03028181940317154, 'loss_2': 0.006137847900390625, 'loss_3': -15.491847038269043, 'loss_4': 0.6233882904052734, 'epoch': 1.95}
{'loss': 0.0616, 'grad_norm': 17.03173828125, 'learning_rate': 2.8058139534883723e-05, 'loss_1': 0.058891743421554565, 'loss_2': 0.002681732177734375, 'loss_3': -15.436771392822266, 'loss_4': -0.10275159776210785, 'epoch': 1.96}
{'loss': 0.0723, 'grad_norm': 17.076168060302734, 'learning_rate': 2.805232558139535e-05, 'loss_1': 0.060476772487163544, 'loss_2': 0.011871337890625, 'loss_3': -15.347625732421875, 'loss_4': -0.12357495725154877, 'epoch': 1.97}
{'loss': 0.0845, 'grad_norm': 23.071441650390625, 'learning_rate': 2.8046511627906977e-05, 'loss_1': 0.07808183878660202, 'loss_2': 0.00640106201171875, 'loss_3': -15.354520797729492, 'loss_4': 0.3486449718475342, 'epoch': 1.97}
{'loss': 0.0409, 'grad_norm': 10.42899227142334, 'learning_rate': 2.8040697674418603e-05, 'loss_1': 0.03047553263604641, 'loss_2': 0.0103759765625, 'loss_3': -15.474662780761719, 'loss_4': 1.032153606414795, 'epoch': 1.98}
[INFO|trainer.py:4228] 2025-01-21 12:28:52,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:28:52,818 >>   Batch size = 64
  7%|██████████████▍                                                                                                                                                                                                             | 340/5160 [08:53<1:25:04,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:28:56,626 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-340
[INFO|configuration_utils.py:420] 2025-01-21 12:28:56,627 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-340/config.json                                                                             
{'eval_loss': 0.01562187448143959, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.993, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01291179284453392, 'eval_loss_2': 0.00271008163690567, 'eval_loss_3': -18.24554443359375, 'eval_loss_4': 0.14463481307029724, 'epoch': 1.98}
[INFO|modeling_utils.py:2988] 2025-01-21 12:28:57,133 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-340/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:28:57,135 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-340/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:28:57,135 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-340/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:28:58,072 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-330] due to args.save_total_limit
  7%|██████████████▋                                                                                                                                                                                                             | 345/5160 [08:58<1:27:47,  1.09s/it][INFO|trainer.py:4226] 2025-01-21 12:29:01,418 >>
{'loss': 0.0502, 'grad_norm': 12.416144371032715, 'learning_rate': 2.8034883720930235e-05, 'loss_1': 0.04597146436572075, 'loss_2': 0.004276275634765625, 'loss_3': -15.552483558654785, 'loss_4': 0.7714411020278931, 'epoch': 1.98}
{'loss': 0.0547, 'grad_norm': 29.1656436920166, 'learning_rate': 2.8029069767441863e-05, 'loss_1': 0.05101092532277107, 'loss_2': 0.003704071044921875, 'loss_3': -15.381372451782227, 'loss_4': 0.7128078937530518, 'epoch': 1.99}
{'loss': 0.0575, 'grad_norm': 13.467584609985352, 'learning_rate': 2.802325581395349e-05, 'loss_1': 0.0490117110311985, 'loss_2': 0.008453369140625, 'loss_3': -15.45240592956543, 'loss_4': 0.4868212342262268, 'epoch': 1.99}
{'loss': 0.0565, 'grad_norm': 22.399587631225586, 'learning_rate': 2.8017441860465117e-05, 'loss_1': 0.05622067674994469, 'loss_2': 0.00027251243591308594, 'loss_3': -15.188600540161133, 'loss_4': 1.1233320236206055, 'epoch': 2.0}
{'loss': 0.033, 'grad_norm': 11.412501335144043, 'learning_rate': 2.8011627906976742e-05, 'loss_1': 0.03110343962907791, 'loss_2': 0.001861572265625, 'loss_3': -15.545492172241211, 'loss_4': -0.056313127279281616, 'epoch': 2.01}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:29:01,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:01,418 >>   Batch size = 64
  7%|██████████████▉                                                                                                                                                                                                             | 350/5160 [09:05<1:24:05,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:29:08,772 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017026197165250778, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.223, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.012352509424090385, 'eval_loss_2': 0.004673689603805542, 'eval_loss_3': -18.232154846191406, 'eval_loss_4': 0.25060173869132996, 'epoch': 2.01}
{'loss': 0.0404, 'grad_norm': 9.084844589233398, 'learning_rate': 2.8005813953488374e-05, 'loss_1': 0.03365406021475792, 'loss_2': 0.0067901611328125, 'loss_3': -15.544548034667969, 'loss_4': 0.5534128546714783, 'epoch': 2.01}
{'loss': 0.0488, 'grad_norm': 10.296512603759766, 'learning_rate': 2.8e-05, 'loss_1': 0.03247208893299103, 'loss_2': 0.0162811279296875, 'loss_3': -15.542990684509277, 'loss_4': 0.5232862234115601, 'epoch': 2.02}
{'loss': 0.0441, 'grad_norm': 13.833715438842773, 'learning_rate': 2.7994186046511628e-05, 'loss_1': 0.04071100428700447, 'loss_2': 0.00341033935546875, 'loss_3': -15.411166191101074, 'loss_4': 0.13798435032367706, 'epoch': 2.02}
{'loss': 0.0295, 'grad_norm': 7.270508289337158, 'learning_rate': 2.7988372093023257e-05, 'loss_1': 0.019345372915267944, 'loss_2': 0.0101776123046875, 'loss_3': -15.417203903198242, 'loss_4': -0.08054302632808685, 'epoch': 2.03}
{'loss': 0.0422, 'grad_norm': 9.66578483581543, 'learning_rate': 2.7982558139534882e-05, 'loss_1': 0.02754911035299301, 'loss_2': 0.0146331787109375, 'loss_3': -15.51272964477539, 'loss_4': 0.4400535225868225, 'epoch': 2.03}
[INFO|trainer.py:4228] 2025-01-21 12:29:08,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:08,774 >>   Batch size = 64
  7%|███████████████▏                                                                                                                                                                                                            | 355/5160 [09:13<1:23:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:16,138 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020292187109589577, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.937, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.016576681286096573, 'eval_loss_2': 0.003715507686138153, 'eval_loss_3': -18.137292861938477, 'eval_loss_4': 0.7519358992576599, 'epoch': 2.03}
{'loss': 0.0493, 'grad_norm': 12.33505630493164, 'learning_rate': 2.7976744186046514e-05, 'loss_1': 0.04379911720752716, 'loss_2': 0.0055084228515625, 'loss_3': -15.347944259643555, 'loss_4': 0.6266744136810303, 'epoch': 2.04}
{'loss': 0.0707, 'grad_norm': 15.905771255493164, 'learning_rate': 2.797093023255814e-05, 'loss_1': 0.05985230579972267, 'loss_2': 0.0108184814453125, 'loss_3': -15.445960998535156, 'loss_4': 1.496894121170044, 'epoch': 2.05}
{'loss': 0.0586, 'grad_norm': 11.599408149719238, 'learning_rate': 2.7965116279069768e-05, 'loss_1': 0.043914999812841415, 'loss_2': 0.01470947265625, 'loss_3': -15.566596984863281, 'loss_4': 0.6076928377151489, 'epoch': 2.05}
{'loss': 0.096, 'grad_norm': 33.083744049072266, 'learning_rate': 2.7959302325581397e-05, 'loss_1': 0.08704792708158493, 'loss_2': 0.00893402099609375, 'loss_3': -15.5316801071167, 'loss_4': 1.2706321477890015, 'epoch': 2.06}
{'loss': 0.0369, 'grad_norm': 13.464249610900879, 'learning_rate': 2.7953488372093022e-05, 'loss_1': 0.03266005218029022, 'loss_2': 0.0041961669921875, 'loss_3': -15.344189643859863, 'loss_4': 1.4829421043395996, 'epoch': 2.06}
[INFO|trainer.py:4228] 2025-01-21 12:29:16,138 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:16,138 >>   Batch size = 64
  7%|███████████████▎                                                                                                                                                                                                            | 360/5160 [09:20<1:23:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:23,503 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03223288059234619, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.884, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.025496480986475945, 'eval_loss_2': 0.006736397743225098, 'eval_loss_3': -18.08488655090332, 'eval_loss_4': 1.6136599779129028, 'epoch': 2.06}
{'loss': 0.0575, 'grad_norm': 21.93646240234375, 'learning_rate': 2.7947674418604654e-05, 'loss_1': 0.054464902728796005, 'loss_2': 0.0030040740966796875, 'loss_3': -15.501582145690918, 'loss_4': 1.4312982559204102, 'epoch': 2.07}
{'loss': 0.1105, 'grad_norm': 21.285879135131836, 'learning_rate': 2.794186046511628e-05, 'loss_1': 0.10255247354507446, 'loss_2': 0.0079345703125, 'loss_3': -15.579002380371094, 'loss_4': 1.4690799713134766, 'epoch': 2.08}
{'loss': 0.0602, 'grad_norm': 13.582619667053223, 'learning_rate': 2.7936046511627908e-05, 'loss_1': 0.05308561399579048, 'loss_2': 0.007091522216796875, 'loss_3': -15.274314880371094, 'loss_4': 1.9957163333892822, 'epoch': 2.08}
{'loss': 0.0673, 'grad_norm': 21.939659118652344, 'learning_rate': 2.7930232558139533e-05, 'loss_1': 0.058116886764764786, 'loss_2': 0.0092315673828125, 'loss_3': -15.2255277633667, 'loss_4': 2.320096254348755, 'epoch': 2.09}
{'loss': 0.0515, 'grad_norm': 17.068912506103516, 'learning_rate': 2.7924418604651165e-05, 'loss_1': 0.049374233931303024, 'loss_2': 0.0020885467529296875, 'loss_3': -15.548964500427246, 'loss_4': 2.005713939666748, 'epoch': 2.09}
[INFO|trainer.py:4228] 2025-01-21 12:29:23,503 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:23,503 >>   Batch size = 64
  7%|███████████████▌                                                                                                                                                                                                            | 365/5160 [09:28<1:23:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:30,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027547333389520645, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.07, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.023817451670765877, 'eval_loss_2': 0.003729879856109619, 'eval_loss_3': -18.1469783782959, 'eval_loss_4': 2.2410640716552734, 'epoch': 2.09}
{'loss': 0.0461, 'grad_norm': 15.956490516662598, 'learning_rate': 2.7918604651162794e-05, 'loss_1': 0.04518865421414375, 'loss_2': 0.000934600830078125, 'loss_3': -15.704188346862793, 'loss_4': 1.9358367919921875, 'epoch': 2.1}
{'loss': 0.0418, 'grad_norm': 9.096855163574219, 'learning_rate': 2.791279069767442e-05, 'loss_1': 0.03424904868006706, 'loss_2': 0.007537841796875, 'loss_3': -15.749815940856934, 'loss_4': 2.062905788421631, 'epoch': 2.1}
{'loss': 0.0706, 'grad_norm': 21.308500289916992, 'learning_rate': 2.7906976744186048e-05, 'loss_1': 0.06441273540258408, 'loss_2': 0.006214141845703125, 'loss_3': -15.319389343261719, 'loss_4': 2.230933427810669, 'epoch': 2.11}
{'loss': 0.0415, 'grad_norm': 10.608105659484863, 'learning_rate': 2.7901162790697673e-05, 'loss_1': 0.035041242837905884, 'loss_2': 0.00649261474609375, 'loss_3': -15.489642143249512, 'loss_4': 2.1808066368103027, 'epoch': 2.12}
{'loss': 0.0531, 'grad_norm': 12.975994110107422, 'learning_rate': 2.7895348837209305e-05, 'loss_1': 0.04131074249744415, 'loss_2': 0.01180267333984375, 'loss_3': -15.230724334716797, 'loss_4': 1.5775744915008545, 'epoch': 2.12}
[INFO|trainer.py:4228] 2025-01-21 12:29:30,870 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:30,870 >>   Batch size = 64
  7%|███████████████▊                                                                                                                                                                                                            | 370/5160 [09:35<1:23:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:38,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023149920627474785, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01986876130104065, 'eval_loss_2': 0.0032811611890792847, 'eval_loss_3': -18.200815200805664, 'eval_loss_4': 2.579735279083252, 'epoch': 2.12}
{'loss': 0.1009, 'grad_norm': 38.964561462402344, 'learning_rate': 2.7889534883720933e-05, 'loss_1': 0.09944374859333038, 'loss_2': 0.0014171600341796875, 'loss_3': -15.315292358398438, 'loss_4': 2.4690113067626953, 'epoch': 2.13}
{'loss': 0.0469, 'grad_norm': 12.635767936706543, 'learning_rate': 2.788372093023256e-05, 'loss_1': 0.04208790510892868, 'loss_2': 0.0048370361328125, 'loss_3': -15.412786483764648, 'loss_4': 2.723292350769043, 'epoch': 2.13}
{'loss': 0.0655, 'grad_norm': 21.442428588867188, 'learning_rate': 2.7877906976744187e-05, 'loss_1': 0.04944109544157982, 'loss_2': 0.0160369873046875, 'loss_3': -15.347978591918945, 'loss_4': 3.244903326034546, 'epoch': 2.14}
{'loss': 0.0437, 'grad_norm': 10.592877388000488, 'learning_rate': 2.7872093023255813e-05, 'loss_1': 0.04150456562638283, 'loss_2': 0.002223968505859375, 'loss_3': -15.476705551147461, 'loss_4': 3.109890937805176, 'epoch': 2.15}
{'loss': 0.061, 'grad_norm': 18.634136199951172, 'learning_rate': 2.7866279069767445e-05, 'loss_1': 0.05972466617822647, 'loss_2': 0.0012769699096679688, 'loss_3': -15.44781494140625, 'loss_4': 3.302114248275757, 'epoch': 2.15}
[INFO|trainer.py:4228] 2025-01-21 12:29:38,237 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:38,237 >>   Batch size = 64
  7%|███████████████▉                                                                                                                                                                                                            | 375/5160 [09:42<1:23:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:45,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022865142673254013, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.019143324345350266, 'eval_loss_2': 0.0037218183279037476, 'eval_loss_3': -18.200210571289062, 'eval_loss_4': 3.0905463695526123, 'epoch': 2.15}
{'loss': 0.0471, 'grad_norm': 12.745253562927246, 'learning_rate': 2.786046511627907e-05, 'loss_1': 0.038414061069488525, 'loss_2': 0.0087127685546875, 'loss_3': -15.495025634765625, 'loss_4': 2.7744317054748535, 'epoch': 2.16}
{'loss': 0.1424, 'grad_norm': 32.27018737792969, 'learning_rate': 2.78546511627907e-05, 'loss_1': 0.13922084867954254, 'loss_2': 0.00321197509765625, 'loss_3': -15.532011032104492, 'loss_4': 2.8731133937835693, 'epoch': 2.16}
{'loss': 0.0426, 'grad_norm': 11.949566841125488, 'learning_rate': 2.7848837209302327e-05, 'loss_1': 0.041775692254304886, 'loss_2': 0.0008182525634765625, 'loss_3': -15.692143440246582, 'loss_4': 3.6074070930480957, 'epoch': 2.17}
{'loss': 0.0453, 'grad_norm': 10.958346366882324, 'learning_rate': 2.7843023255813952e-05, 'loss_1': 0.03173849359154701, 'loss_2': 0.0135498046875, 'loss_3': -15.706650733947754, 'loss_4': 2.9132957458496094, 'epoch': 2.17}
{'loss': 0.0381, 'grad_norm': 10.723100662231445, 'learning_rate': 2.7837209302325584e-05, 'loss_1': 0.03180877864360809, 'loss_2': 0.0062713623046875, 'loss_3': -15.508194923400879, 'loss_4': 2.8143973350524902, 'epoch': 2.18}
[INFO|trainer.py:4228] 2025-01-21 12:29:45,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:45,609 >>   Batch size = 64
  7%|████████████████▏                                                                                                                                                                                                           | 380/5160 [09:50<1:23:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:29:52,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024722538888454437, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.016823073849081993, 'eval_loss_2': 0.007899463176727295, 'eval_loss_3': -18.249343872070312, 'eval_loss_4': 2.931291341781616, 'epoch': 2.18}
{'loss': 0.1267, 'grad_norm': 32.21625900268555, 'learning_rate': 2.783139534883721e-05, 'loss_1': 0.11567912995815277, 'loss_2': 0.01103973388671875, 'loss_3': -15.299149513244629, 'loss_4': 3.2439403533935547, 'epoch': 2.19}
{'loss': 0.0499, 'grad_norm': 14.436100006103516, 'learning_rate': 2.7825581395348838e-05, 'loss_1': 0.0472688227891922, 'loss_2': 0.0026264190673828125, 'loss_3': -15.423481941223145, 'loss_4': 3.4162333011627197, 'epoch': 2.19}
{'loss': 0.0558, 'grad_norm': 21.2823543548584, 'learning_rate': 2.7819767441860467e-05, 'loss_1': 0.050043415278196335, 'loss_2': 0.0057525634765625, 'loss_3': -15.687450408935547, 'loss_4': 3.0499022006988525, 'epoch': 2.2}
{'loss': 0.07, 'grad_norm': 26.25411033630371, 'learning_rate': 2.7813953488372092e-05, 'loss_1': 0.06690454483032227, 'loss_2': 0.003124237060546875, 'loss_3': -15.676603317260742, 'loss_4': 3.757406234741211, 'epoch': 2.2}
{'loss': 0.0461, 'grad_norm': 13.372723579406738, 'learning_rate': 2.7808139534883724e-05, 'loss_1': 0.0449533611536026, 'loss_2': 0.0011005401611328125, 'loss_3': -15.856904983520508, 'loss_4': 3.6229171752929688, 'epoch': 2.21}
[INFO|trainer.py:4228] 2025-01-21 12:29:52,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:29:52,987 >>   Batch size = 64
  7%|████████████████▍                                                                                                                                                                                                           | 385/5160 [09:57<1:23:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:00,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022931043058633804, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.221, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.018258607015013695, 'eval_loss_2': 0.004672437906265259, 'eval_loss_3': -18.265186309814453, 'eval_loss_4': 3.0804247856140137, 'epoch': 2.21}
{'loss': 0.0913, 'grad_norm': 32.94279098510742, 'learning_rate': 2.780232558139535e-05, 'loss_1': 0.08458708226680756, 'loss_2': 0.0066680908203125, 'loss_3': -15.585966110229492, 'loss_4': 3.6735033988952637, 'epoch': 2.22}
{'loss': 0.0644, 'grad_norm': 40.0404167175293, 'learning_rate': 2.7796511627906978e-05, 'loss_1': 0.0595337338745594, 'loss_2': 0.004878997802734375, 'loss_3': -15.596525192260742, 'loss_4': 3.0445284843444824, 'epoch': 2.22}
{'loss': 0.0566, 'grad_norm': 11.488346099853516, 'learning_rate': 2.7790697674418603e-05, 'loss_1': 0.04504160210490227, 'loss_2': 0.01155853271484375, 'loss_3': -15.762077331542969, 'loss_4': 3.1722567081451416, 'epoch': 2.23}
{'loss': 0.0471, 'grad_norm': 10.025651931762695, 'learning_rate': 2.7784883720930232e-05, 'loss_1': 0.03635688126087189, 'loss_2': 0.010711669921875, 'loss_3': -15.774072647094727, 'loss_4': 3.7428903579711914, 'epoch': 2.23}
{'loss': 0.0779, 'grad_norm': 24.683767318725586, 'learning_rate': 2.7779069767441864e-05, 'loss_1': 0.0743679329752922, 'loss_2': 0.003566741943359375, 'loss_3': -15.644625663757324, 'loss_4': 3.268777370452881, 'epoch': 2.24}
[INFO|trainer.py:4228] 2025-01-21 12:30:00,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:00,369 >>   Batch size = 64
  8%|████████████████▋                                                                                                                                                                                                           | 390/5160 [10:04<1:23:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:07,751 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023326460272073746, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.642, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.019982043653726578, 'eval_loss_2': 0.003344416618347168, 'eval_loss_3': -18.213924407958984, 'eval_loss_4': 3.1343109607696533, 'epoch': 2.24}
{'loss': 0.041, 'grad_norm': 10.41441822052002, 'learning_rate': 2.777325581395349e-05, 'loss_1': 0.040208443999290466, 'loss_2': 0.0007486343383789062, 'loss_3': -15.640592575073242, 'loss_4': 3.2385759353637695, 'epoch': 2.24}
{'loss': 0.0973, 'grad_norm': 21.72044563293457, 'learning_rate': 2.7767441860465118e-05, 'loss_1': 0.0909813866019249, 'loss_2': 0.0062713623046875, 'loss_3': -15.664206504821777, 'loss_4': 3.5455358028411865, 'epoch': 2.25}
{'loss': 0.0567, 'grad_norm': 12.69045352935791, 'learning_rate': 2.7761627906976743e-05, 'loss_1': 0.04529588297009468, 'loss_2': 0.01139068603515625, 'loss_3': -15.51475715637207, 'loss_4': 3.2155189514160156, 'epoch': 2.26}
{'loss': 0.0897, 'grad_norm': 23.382980346679688, 'learning_rate': 2.775581395348837e-05, 'loss_1': 0.07796002179384232, 'loss_2': 0.01177978515625, 'loss_3': -15.513912200927734, 'loss_4': 3.4569685459136963, 'epoch': 2.26}
{'loss': 0.0972, 'grad_norm': 22.15576934814453, 'learning_rate': 2.7750000000000004e-05, 'loss_1': 0.08731736987829208, 'loss_2': 0.0099029541015625, 'loss_3': -15.694972038269043, 'loss_4': 3.36293888092041, 'epoch': 2.27}
[INFO|trainer.py:4228] 2025-01-21 12:30:07,751 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:07,751 >>   Batch size = 64
  8%|████████████████▊                                                                                                                                                                                                           | 395/5160 [10:12<1:22:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:15,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.046394698321819305, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.037448521703481674, 'eval_loss_2': 0.00894618034362793, 'eval_loss_3': -18.119943618774414, 'eval_loss_4': 2.9974465370178223, 'epoch': 2.27}
{'loss': 0.0696, 'grad_norm': 29.274734497070312, 'learning_rate': 2.774418604651163e-05, 'loss_1': 0.06844896823167801, 'loss_2': 0.0011491775512695312, 'loss_3': -15.691633224487305, 'loss_4': 2.975780487060547, 'epoch': 2.27}
{'loss': 0.0573, 'grad_norm': 19.21527671813965, 'learning_rate': 2.7738372093023258e-05, 'loss_1': 0.04616709426045418, 'loss_2': 0.0111236572265625, 'loss_3': -15.673665046691895, 'loss_4': 3.164046287536621, 'epoch': 2.28}
{'loss': 0.0687, 'grad_norm': 15.919645309448242, 'learning_rate': 2.7732558139534883e-05, 'loss_1': 0.06047692894935608, 'loss_2': 0.0081939697265625, 'loss_3': -15.661476135253906, 'loss_4': 3.2317957878112793, 'epoch': 2.28}
{'loss': 0.1048, 'grad_norm': 27.38811492919922, 'learning_rate': 2.772674418604651e-05, 'loss_1': 0.09563402831554413, 'loss_2': 0.00917816162109375, 'loss_3': -15.666206359863281, 'loss_4': 2.804798126220703, 'epoch': 2.29}
{'loss': 0.0421, 'grad_norm': 11.181214332580566, 'learning_rate': 2.772093023255814e-05, 'loss_1': 0.03443565592169762, 'loss_2': 0.0076751708984375, 'loss_3': -15.563150405883789, 'loss_4': 2.1551969051361084, 'epoch': 2.3}
[INFO|trainer.py:4228] 2025-01-21 12:30:15,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:15,119 >>   Batch size = 64
  8%|█████████████████                                                                                                                                                                                                           | 400/5160 [10:19<1:22:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:22,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02199489064514637, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.908, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01851034350693226, 'eval_loss_2': 0.0034845471382141113, 'eval_loss_3': -18.171558380126953, 'eval_loss_4': 2.240457773208618, 'epoch': 2.3}
{'loss': 0.048, 'grad_norm': 18.564237594604492, 'learning_rate': 2.771511627906977e-05, 'loss_1': 0.047534000128507614, 'loss_2': 0.0004172325134277344, 'loss_3': -15.506729125976562, 'loss_4': 2.5741159915924072, 'epoch': 2.3}
{'loss': 0.0404, 'grad_norm': 12.910154342651367, 'learning_rate': 2.7709302325581397e-05, 'loss_1': 0.03314678743481636, 'loss_2': 0.007232666015625, 'loss_3': -15.723482131958008, 'loss_4': 2.4633631706237793, 'epoch': 2.31}
{'loss': 0.0481, 'grad_norm': 13.925615310668945, 'learning_rate': 2.7703488372093023e-05, 'loss_1': 0.042837053537368774, 'loss_2': 0.0052490234375, 'loss_3': -15.711505889892578, 'loss_4': 2.120091438293457, 'epoch': 2.31}
{'loss': 0.1296, 'grad_norm': 31.91980743408203, 'learning_rate': 2.769767441860465e-05, 'loss_1': 0.1234903559088707, 'loss_2': 0.00608062744140625, 'loss_3': -15.36303424835205, 'loss_4': 1.876695990562439, 'epoch': 2.32}
{'loss': 0.0993, 'grad_norm': 25.696012496948242, 'learning_rate': 2.769186046511628e-05, 'loss_1': 0.08896613866090775, 'loss_2': 0.01035308837890625, 'loss_3': -15.669320106506348, 'loss_4': 2.196357488632202, 'epoch': 2.33}
[INFO|trainer.py:4228] 2025-01-21 12:30:22,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:22,488 >>   Batch size = 64
  8%|█████████████████▎                                                                                                                                                                                                          | 405/5160 [10:27<1:22:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:29,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.021192491054534912, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.772, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013622820377349854, 'eval_loss_2': 0.007569670677185059, 'eval_loss_3': -18.207218170166016, 'eval_loss_4': 1.6156972646713257, 'epoch': 2.33}
{'loss': 0.0738, 'grad_norm': 20.553340911865234, 'learning_rate': 2.768604651162791e-05, 'loss_1': 0.06429199129343033, 'loss_2': 0.009490966796875, 'loss_3': -15.70864486694336, 'loss_4': 2.103949546813965, 'epoch': 2.33}
{'loss': 0.0294, 'grad_norm': 8.877433776855469, 'learning_rate': 2.7680232558139537e-05, 'loss_1': 0.022117257118225098, 'loss_2': 0.0072479248046875, 'loss_3': -15.404446601867676, 'loss_4': 1.4995194673538208, 'epoch': 2.34}
{'loss': 0.0252, 'grad_norm': 7.355611801147461, 'learning_rate': 2.7674418604651162e-05, 'loss_1': 0.019169099628925323, 'loss_2': 0.006069183349609375, 'loss_3': -15.676958084106445, 'loss_4': 1.674074649810791, 'epoch': 2.34}
{'loss': 0.0715, 'grad_norm': 22.455564498901367, 'learning_rate': 2.766860465116279e-05, 'loss_1': 0.06782177090644836, 'loss_2': 0.0036678314208984375, 'loss_3': -15.344572067260742, 'loss_4': 1.93692147731781, 'epoch': 2.35}
{'loss': 0.043, 'grad_norm': 14.669782638549805, 'learning_rate': 2.766279069767442e-05, 'loss_1': 0.03734001889824867, 'loss_2': 0.0056304931640625, 'loss_3': -15.438146591186523, 'loss_4': 1.9220473766326904, 'epoch': 2.35}
[INFO|trainer.py:4228] 2025-01-21 12:30:29,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:29,865 >>   Batch size = 64
  8%|█████████████████▍                                                                                                                                                                                                          | 410/5160 [10:34<1:22:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:37,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017223719507455826, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.479, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01300815213471651, 'eval_loss_2': 0.00421556830406189, 'eval_loss_3': -18.218069076538086, 'eval_loss_4': 1.4375988245010376, 'epoch': 2.35}
{'loss': 0.0434, 'grad_norm': 12.552877426147461, 'learning_rate': 2.7656976744186048e-05, 'loss_1': 0.039671748876571655, 'loss_2': 0.003749847412109375, 'loss_3': -15.564784049987793, 'loss_4': 2.3332576751708984, 'epoch': 2.36}
{'loss': 0.0571, 'grad_norm': 16.416444778442383, 'learning_rate': 2.7651162790697673e-05, 'loss_1': 0.04983571916818619, 'loss_2': 0.007259368896484375, 'loss_3': -15.780381202697754, 'loss_4': 1.6771790981292725, 'epoch': 2.37}
{'loss': 0.0474, 'grad_norm': 13.822650909423828, 'learning_rate': 2.7645348837209302e-05, 'loss_1': 0.032628078013658524, 'loss_2': 0.0148162841796875, 'loss_3': -15.592278480529785, 'loss_4': 1.0743122100830078, 'epoch': 2.37}
{'loss': 0.0374, 'grad_norm': 11.384245872497559, 'learning_rate': 2.763953488372093e-05, 'loss_1': 0.03729607164859772, 'loss_2': 0.0001125335693359375, 'loss_3': -15.494144439697266, 'loss_4': 1.6522185802459717, 'epoch': 2.38}
{'loss': 0.0364, 'grad_norm': 11.253026008605957, 'learning_rate': 2.763372093023256e-05, 'loss_1': 0.02636190690100193, 'loss_2': 0.010009765625, 'loss_3': -15.736620903015137, 'loss_4': 2.051055669784546, 'epoch': 2.38}
[INFO|trainer.py:4228] 2025-01-21 12:30:37,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:37,239 >>   Batch size = 64
  8%|█████████████████▋                                                                                                                                                                                                          | 415/5160 [10:41<1:22:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:44,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024715453386306763, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.854, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014951496385037899, 'eval_loss_2': 0.009763956069946289, 'eval_loss_3': -18.254535675048828, 'eval_loss_4': 1.440483808517456, 'epoch': 2.38}
{'loss': 0.0728, 'grad_norm': 24.596832275390625, 'learning_rate': 2.7627906976744188e-05, 'loss_1': 0.06629239022731781, 'loss_2': 0.00650787353515625, 'loss_3': -15.573780059814453, 'loss_4': 1.8005907535552979, 'epoch': 2.39}
{'loss': 0.1011, 'grad_norm': 23.95732307434082, 'learning_rate': 2.7622093023255813e-05, 'loss_1': 0.08873689919710159, 'loss_2': 0.0123138427734375, 'loss_3': -15.442638397216797, 'loss_4': 1.7907390594482422, 'epoch': 2.4}
{'loss': 0.0194, 'grad_norm': 6.013772964477539, 'learning_rate': 2.7616279069767442e-05, 'loss_1': 0.012077280320227146, 'loss_2': 0.00734710693359375, 'loss_3': -15.728830337524414, 'loss_4': 1.0806491374969482, 'epoch': 2.4}
{'loss': 0.0271, 'grad_norm': 8.40599536895752, 'learning_rate': 2.761046511627907e-05, 'loss_1': 0.02422669716179371, 'loss_2': 0.0028324127197265625, 'loss_3': -15.494377136230469, 'loss_4': 1.4226443767547607, 'epoch': 2.41}
{'loss': 0.0416, 'grad_norm': 13.420368194580078, 'learning_rate': 2.76046511627907e-05, 'loss_1': 0.03789045661687851, 'loss_2': 0.003681182861328125, 'loss_3': -15.809835433959961, 'loss_4': 1.3093502521514893, 'epoch': 2.41}
[INFO|trainer.py:4228] 2025-01-21 12:30:44,603 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:44,603 >>   Batch size = 64
  8%|█████████████████▉                                                                                                                                                                                                          | 420/5160 [10:49<1:22:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:51,981 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023571383208036423, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.815, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.017679253593087196, 'eval_loss_2': 0.005892127752304077, 'eval_loss_3': -18.236658096313477, 'eval_loss_4': 1.1346707344055176, 'epoch': 2.41}
{'loss': 0.0236, 'grad_norm': 12.044109344482422, 'learning_rate': 2.7598837209302328e-05, 'loss_1': 0.022144543007016182, 'loss_2': 0.0014810562133789062, 'loss_3': -15.52216911315918, 'loss_4': 1.3356497287750244, 'epoch': 2.42}
{'loss': 0.0498, 'grad_norm': 10.422606468200684, 'learning_rate': 2.7593023255813953e-05, 'loss_1': 0.037466950714588165, 'loss_2': 0.012298583984375, 'loss_3': -15.58877944946289, 'loss_4': 1.2405238151550293, 'epoch': 2.42}
{'loss': 0.0341, 'grad_norm': 7.69615364074707, 'learning_rate': 2.758720930232558e-05, 'loss_1': 0.019808711484074593, 'loss_2': 0.0143280029296875, 'loss_3': -15.738927841186523, 'loss_4': 0.890224814414978, 'epoch': 2.43}
{'loss': 0.0234, 'grad_norm': 6.5580644607543945, 'learning_rate': 2.7581395348837207e-05, 'loss_1': 0.019142599776387215, 'loss_2': 0.00424957275390625, 'loss_3': -15.858474731445312, 'loss_4': 1.305895209312439, 'epoch': 2.44}
{'loss': 0.063, 'grad_norm': 20.62802505493164, 'learning_rate': 2.757558139534884e-05, 'loss_1': 0.04846736043691635, 'loss_2': 0.01450347900390625, 'loss_3': -15.588468551635742, 'loss_4': 0.6023845672607422, 'epoch': 2.44}
[INFO|trainer.py:4228] 2025-01-21 12:30:51,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:51,981 >>   Batch size = 64
  8%|██████████████████                                                                                                                                                                                                          | 425/5160 [10:56<1:22:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:30:59,354 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03347153961658478, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.425, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.02573607861995697, 'eval_loss_2': 0.007735460996627808, 'eval_loss_3': -18.20216941833496, 'eval_loss_4': 1.0508402585983276, 'epoch': 2.44}
{'loss': 0.0473, 'grad_norm': 14.353193283081055, 'learning_rate': 2.7569767441860468e-05, 'loss_1': 0.04053331911563873, 'loss_2': 0.00676727294921875, 'loss_3': -15.461553573608398, 'loss_4': 1.6420010328292847, 'epoch': 2.45}
{'loss': 0.0266, 'grad_norm': 8.142873764038086, 'learning_rate': 2.7563953488372093e-05, 'loss_1': 0.0213356614112854, 'loss_2': 0.00525665283203125, 'loss_3': -15.538839340209961, 'loss_4': 1.1049308776855469, 'epoch': 2.45}
{'loss': 0.0267, 'grad_norm': 8.362963676452637, 'learning_rate': 2.755813953488372e-05, 'loss_1': 0.02413192391395569, 'loss_2': 0.002597808837890625, 'loss_3': -15.756399154663086, 'loss_4': 0.7129981517791748, 'epoch': 2.46}
{'loss': 0.0406, 'grad_norm': 9.106189727783203, 'learning_rate': 2.755232558139535e-05, 'loss_1': 0.036969415843486786, 'loss_2': 0.0036106109619140625, 'loss_3': -15.553366661071777, 'loss_4': 1.8968474864959717, 'epoch': 2.47}
{'loss': 0.0352, 'grad_norm': 8.697037696838379, 'learning_rate': 2.754651162790698e-05, 'loss_1': 0.03299884498119354, 'loss_2': 0.0022068023681640625, 'loss_3': -15.405485153198242, 'loss_4': 1.4311470985412598, 'epoch': 2.47}
[INFO|trainer.py:4228] 2025-01-21 12:30:59,354 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:30:59,354 >>   Batch size = 64
  8%|██████████████████▎                                                                                                                                                                                                         | 430/5160 [11:03<1:21:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:06,713 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05113524943590164, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.04708806425333023, 'eval_loss_2': 0.004047185182571411, 'eval_loss_3': -18.177425384521484, 'eval_loss_4': 1.5703654289245605, 'epoch': 2.47}
{'loss': 0.028, 'grad_norm': 8.588762283325195, 'learning_rate': 2.7540697674418607e-05, 'loss_1': 0.023376021534204483, 'loss_2': 0.004634857177734375, 'loss_3': -15.600768089294434, 'loss_4': 1.2190148830413818, 'epoch': 2.48}
{'loss': 0.0296, 'grad_norm': 9.772923469543457, 'learning_rate': 2.7534883720930233e-05, 'loss_1': 0.02686522901058197, 'loss_2': 0.002777099609375, 'loss_3': -15.47449779510498, 'loss_4': 1.7837140560150146, 'epoch': 2.48}
{'loss': 0.0261, 'grad_norm': 8.787230491638184, 'learning_rate': 2.752906976744186e-05, 'loss_1': 0.02522238902747631, 'loss_2': 0.000858306884765625, 'loss_3': -15.742422103881836, 'loss_4': 1.8685290813446045, 'epoch': 2.49}
{'loss': 0.0216, 'grad_norm': 7.54369592666626, 'learning_rate': 2.752325581395349e-05, 'loss_1': 0.02035067044198513, 'loss_2': 0.0012340545654296875, 'loss_3': -15.924221992492676, 'loss_4': 1.7349400520324707, 'epoch': 2.49}
{'loss': 0.0761, 'grad_norm': 21.369712829589844, 'learning_rate': 2.751744186046512e-05, 'loss_1': 0.07356251776218414, 'loss_2': 0.0025424957275390625, 'loss_3': -15.746541023254395, 'loss_4': 2.320298194885254, 'epoch': 2.5}
[INFO|trainer.py:4228] 2025-01-21 12:31:06,713 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:06,713 >>   Batch size = 64
  8%|██████████████████▌                                                                                                                                                                                                         | 435/5160 [11:11<1:22:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:14,089 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06515026092529297, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.618, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.061605796217918396, 'eval_loss_2': 0.003544449806213379, 'eval_loss_3': -18.1298828125, 'eval_loss_4': 2.2105677127838135, 'epoch': 2.5}
{'loss': 0.0394, 'grad_norm': 12.87426471710205, 'learning_rate': 2.7511627906976744e-05, 'loss_1': 0.03872915729880333, 'loss_2': 0.0006880760192871094, 'loss_3': -15.57131290435791, 'loss_4': 2.069441318511963, 'epoch': 2.51}
{'loss': 0.0389, 'grad_norm': 16.637958526611328, 'learning_rate': 2.7505813953488372e-05, 'loss_1': 0.032799579203128815, 'loss_2': 0.00614166259765625, 'loss_3': -15.752649307250977, 'loss_4': 2.3556101322174072, 'epoch': 2.51}
{'loss': 0.0356, 'grad_norm': 9.500783920288086, 'learning_rate': 2.75e-05, 'loss_1': 0.030751528218388557, 'loss_2': 0.0048675537109375, 'loss_3': -15.545591354370117, 'loss_4': 2.677544116973877, 'epoch': 2.52}
{'loss': 0.1116, 'grad_norm': 23.471235275268555, 'learning_rate': 2.749418604651163e-05, 'loss_1': 0.10697128623723984, 'loss_2': 0.00461578369140625, 'loss_3': -15.644569396972656, 'loss_4': 2.721298933029175, 'epoch': 2.52}
{'loss': 0.0191, 'grad_norm': 6.4560227394104, 'learning_rate': 2.7488372093023258e-05, 'loss_1': 0.017134971916675568, 'loss_2': 0.0019512176513671875, 'loss_3': -15.612852096557617, 'loss_4': 1.7076305150985718, 'epoch': 2.53}
[INFO|trainer.py:4228] 2025-01-21 12:31:14,089 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:14,089 >>   Batch size = 64
  9%|██████████████████▊                                                                                                                                                                                                         | 440/5160 [11:18<1:22:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:21,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025889955461025238, 'eval_runtime': 3.8142, 'eval_samples_per_second': 268.473, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.016944488510489464, 'eval_loss_2': 0.008945465087890625, 'eval_loss_3': -18.325525283813477, 'eval_loss_4': 2.220851182937622, 'epoch': 2.53}
{'loss': 0.099, 'grad_norm': 24.464752197265625, 'learning_rate': 2.7482558139534883e-05, 'loss_1': 0.08818870782852173, 'loss_2': 0.01085662841796875, 'loss_3': -15.597162246704102, 'loss_4': 2.8132355213165283, 'epoch': 2.53}
{'loss': 0.0339, 'grad_norm': 9.050309181213379, 'learning_rate': 2.7476744186046512e-05, 'loss_1': 0.026961348950862885, 'loss_2': 0.006908416748046875, 'loss_3': -15.63618278503418, 'loss_4': 2.4600672721862793, 'epoch': 2.54}
{'loss': 0.0527, 'grad_norm': 12.055316925048828, 'learning_rate': 2.747093023255814e-05, 'loss_1': 0.038789402693510056, 'loss_2': 0.01395416259765625, 'loss_3': -15.915567398071289, 'loss_4': 2.792496681213379, 'epoch': 2.55}
{'loss': 0.0625, 'grad_norm': 23.15959930419922, 'learning_rate': 2.746511627906977e-05, 'loss_1': 0.06107727438211441, 'loss_2': 0.0014514923095703125, 'loss_3': -15.639759063720703, 'loss_4': 2.749831438064575, 'epoch': 2.55}
{'loss': 0.0467, 'grad_norm': 11.887640953063965, 'learning_rate': 2.7459302325581398e-05, 'loss_1': 0.04519803449511528, 'loss_2': 0.001453399658203125, 'loss_3': -15.814311981201172, 'loss_4': 2.6537978649139404, 'epoch': 2.56}
[INFO|trainer.py:4228] 2025-01-21 12:31:21,472 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:21,472 >>   Batch size = 64
  9%|██████████████████▉                                                                                                                                                                                                         | 445/5160 [11:25<1:21:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:28,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02506544068455696, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01677681878209114, 'eval_loss_2': 0.00828862190246582, 'eval_loss_3': -18.381654739379883, 'eval_loss_4': 2.643535614013672, 'epoch': 2.56}
{'loss': 0.0462, 'grad_norm': 12.972433090209961, 'learning_rate': 2.7453488372093023e-05, 'loss_1': 0.036731649190187454, 'loss_2': 0.00946044921875, 'loss_3': -15.73440933227539, 'loss_4': 3.00880765914917, 'epoch': 2.56}
{'loss': 0.0956, 'grad_norm': 27.541358947753906, 'learning_rate': 2.7447674418604652e-05, 'loss_1': 0.08768384158611298, 'loss_2': 0.00787353515625, 'loss_3': -15.715330123901367, 'loss_4': 3.374001979827881, 'epoch': 2.57}
{'loss': 0.0543, 'grad_norm': 17.41888999938965, 'learning_rate': 2.7441860465116277e-05, 'loss_1': 0.054073266685009, 'loss_2': 0.0002474784851074219, 'loss_3': -15.830872535705566, 'loss_4': 2.6270711421966553, 'epoch': 2.58}
{'loss': 0.0567, 'grad_norm': 16.046152114868164, 'learning_rate': 2.743604651162791e-05, 'loss_1': 0.052695631980895996, 'loss_2': 0.003978729248046875, 'loss_3': -15.751229286193848, 'loss_4': 3.8389554023742676, 'epoch': 2.58}
{'loss': 0.0853, 'grad_norm': 20.750120162963867, 'learning_rate': 2.7430232558139538e-05, 'loss_1': 0.07633734494447708, 'loss_2': 0.008941650390625, 'loss_3': -15.713132858276367, 'loss_4': 2.5035388469696045, 'epoch': 2.59}
[INFO|trainer.py:4228] 2025-01-21 12:31:28,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:28,845 >>   Batch size = 64
  9%|███████████████████▏                                                                                                                                                                                                        | 450/5160 [11:33<1:21:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:36,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020513124763965607, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.853, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015248844400048256, 'eval_loss_2': 0.0052642822265625, 'eval_loss_3': -18.387100219726562, 'eval_loss_4': 2.491060733795166, 'epoch': 2.59}
{'loss': 0.0472, 'grad_norm': 17.123058319091797, 'learning_rate': 2.7424418604651163e-05, 'loss_1': 0.04413774609565735, 'loss_2': 0.0030155181884765625, 'loss_3': -15.762123107910156, 'loss_4': 2.793325424194336, 'epoch': 2.59}
{'loss': 0.0659, 'grad_norm': 24.677396774291992, 'learning_rate': 2.741860465116279e-05, 'loss_1': 0.06202571839094162, 'loss_2': 0.00390625, 'loss_3': -15.832534790039062, 'loss_4': 2.541679859161377, 'epoch': 2.6}
{'loss': 0.072, 'grad_norm': 23.16891860961914, 'learning_rate': 2.7412790697674417e-05, 'loss_1': 0.0645916759967804, 'loss_2': 0.0074310302734375, 'loss_3': -15.645231246948242, 'loss_4': 2.914428234100342, 'epoch': 2.6}
{'loss': 0.0436, 'grad_norm': 10.605158805847168, 'learning_rate': 2.740697674418605e-05, 'loss_1': 0.03658346086740494, 'loss_2': 0.007015228271484375, 'loss_3': -15.876882553100586, 'loss_4': 2.4041359424591064, 'epoch': 2.61}
{'loss': 0.0808, 'grad_norm': 26.907014846801758, 'learning_rate': 2.7401162790697674e-05, 'loss_1': 0.07965967059135437, 'loss_2': 0.001155853271484375, 'loss_3': -15.777117729187012, 'loss_4': 1.8885002136230469, 'epoch': 2.62}
[INFO|trainer.py:4228] 2025-01-21 12:31:36,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:36,222 >>   Batch size = 64
  9%|███████████████████▍                                                                                                                                                                                                        | 455/5160 [11:40<1:21:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:43,591 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016267940402030945, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.91, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012847048230469227, 'eval_loss_2': 0.003420889377593994, 'eval_loss_3': -18.318359375, 'eval_loss_4': 1.8266538381576538, 'epoch': 2.62}
{'loss': 0.0261, 'grad_norm': 8.440205574035645, 'learning_rate': 2.7395348837209303e-05, 'loss_1': 0.025597719475626945, 'loss_2': 0.0005130767822265625, 'loss_3': -15.715019226074219, 'loss_4': 1.9786388874053955, 'epoch': 2.62}
{'loss': 0.036, 'grad_norm': 10.94570255279541, 'learning_rate': 2.738953488372093e-05, 'loss_1': 0.03343379497528076, 'loss_2': 0.002532958984375, 'loss_3': -15.86775016784668, 'loss_4': 2.2458395957946777, 'epoch': 2.63}
{'loss': 0.0296, 'grad_norm': 9.562180519104004, 'learning_rate': 2.7383720930232557e-05, 'loss_1': 0.02751316875219345, 'loss_2': 0.00213623046875, 'loss_3': -15.705204963684082, 'loss_4': 2.1579785346984863, 'epoch': 2.63}
{'loss': 0.1517, 'grad_norm': 33.57353210449219, 'learning_rate': 2.737790697674419e-05, 'loss_1': 0.1428910493850708, 'loss_2': 0.0088348388671875, 'loss_3': -15.475885391235352, 'loss_4': 2.0352983474731445, 'epoch': 2.64}
{'loss': 0.0263, 'grad_norm': 9.410404205322266, 'learning_rate': 2.7372093023255814e-05, 'loss_1': 0.022597860544919968, 'loss_2': 0.003665924072265625, 'loss_3': -15.6331205368042, 'loss_4': 1.7001879215240479, 'epoch': 2.65}
[INFO|trainer.py:4228] 2025-01-21 12:31:43,591 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:43,591 >>   Batch size = 64
  9%|███████████████████▌                                                                                                                                                                                                        | 460/5160 [11:48<1:21:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:50,955 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01645270735025406, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.013140269555151463, 'eval_loss_2': 0.003312438726425171, 'eval_loss_3': -18.301502227783203, 'eval_loss_4': 1.4993349313735962, 'epoch': 2.65}
{'loss': 0.0196, 'grad_norm': 8.191062927246094, 'learning_rate': 2.7366279069767443e-05, 'loss_1': 0.018612004816532135, 'loss_2': 0.0010128021240234375, 'loss_3': -15.746567726135254, 'loss_4': 1.538948893547058, 'epoch': 2.65}
{'loss': 0.0258, 'grad_norm': 8.584714889526367, 'learning_rate': 2.736046511627907e-05, 'loss_1': 0.021283872425556183, 'loss_2': 0.004547119140625, 'loss_3': -15.824031829833984, 'loss_4': 2.00437593460083, 'epoch': 2.66}
{'loss': 0.0277, 'grad_norm': 6.294613838195801, 'learning_rate': 2.7354651162790696e-05, 'loss_1': 0.017966575920581818, 'loss_2': 0.009735107421875, 'loss_3': -15.797685623168945, 'loss_4': 1.2451109886169434, 'epoch': 2.66}
{'loss': 0.0346, 'grad_norm': 11.855956077575684, 'learning_rate': 2.734883720930233e-05, 'loss_1': 0.03359105810523033, 'loss_2': 0.001033782958984375, 'loss_3': -15.77836799621582, 'loss_4': 1.2381211519241333, 'epoch': 2.67}
{'loss': 0.0359, 'grad_norm': 11.094259262084961, 'learning_rate': 2.7343023255813954e-05, 'loss_1': 0.031846459954977036, 'loss_2': 0.00408172607421875, 'loss_3': -15.874787330627441, 'loss_4': 1.4139124155044556, 'epoch': 2.67}
[INFO|trainer.py:4228] 2025-01-21 12:31:50,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:50,956 >>   Batch size = 64
  9%|███████████████████▊                                                                                                                                                                                                        | 465/5160 [11:55<1:21:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:31:58,338 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018195608630776405, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.261, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.013063290156424046, 'eval_loss_2': 0.005132317543029785, 'eval_loss_3': -18.30622100830078, 'eval_loss_4': 1.16978919506073, 'epoch': 2.67}
{'loss': 0.0336, 'grad_norm': 9.572186470031738, 'learning_rate': 2.7337209302325582e-05, 'loss_1': 0.029575619846582413, 'loss_2': 0.004001617431640625, 'loss_3': -15.839591979980469, 'loss_4': 1.250291109085083, 'epoch': 2.68}
{'loss': 0.0202, 'grad_norm': 7.757167816162109, 'learning_rate': 2.7331395348837208e-05, 'loss_1': 0.019012968987226486, 'loss_2': 0.0011835098266601562, 'loss_3': -15.748448371887207, 'loss_4': 1.5480928421020508, 'epoch': 2.69}
{'loss': 0.0281, 'grad_norm': 8.693284034729004, 'learning_rate': 2.7325581395348836e-05, 'loss_1': 0.026548000052571297, 'loss_2': 0.001506805419921875, 'loss_3': -16.05850601196289, 'loss_4': 0.9858832359313965, 'epoch': 2.69}
{'loss': 0.045, 'grad_norm': 18.631107330322266, 'learning_rate': 2.7319767441860468e-05, 'loss_1': 0.04262561723589897, 'loss_2': 0.00235748291015625, 'loss_3': -15.659860610961914, 'loss_4': 1.8202574253082275, 'epoch': 2.7}
{'loss': 0.042, 'grad_norm': 14.358322143554688, 'learning_rate': 2.7313953488372093e-05, 'loss_1': 0.03543775528669357, 'loss_2': 0.0065155029296875, 'loss_3': -15.746328353881836, 'loss_4': 1.016190528869629, 'epoch': 2.7}
[INFO|trainer.py:4228] 2025-01-21 12:31:58,338 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:31:58,338 >>   Batch size = 64
  9%|████████████████████                                                                                                                                                                                                        | 470/5160 [12:02<1:21:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:05,705 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025716636329889297, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.779, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.018457384780049324, 'eval_loss_2': 0.007259249687194824, 'eval_loss_3': -18.193105697631836, 'eval_loss_4': 1.4664206504821777, 'epoch': 2.7}
{'loss': 0.0282, 'grad_norm': 6.981716156005859, 'learning_rate': 2.7308139534883722e-05, 'loss_1': 0.018917253240942955, 'loss_2': 0.009307861328125, 'loss_3': -15.64361572265625, 'loss_4': 1.3266878128051758, 'epoch': 2.71}
{'loss': 0.0201, 'grad_norm': 6.4677605628967285, 'learning_rate': 2.7302325581395347e-05, 'loss_1': 0.01909811794757843, 'loss_2': 0.0010480880737304688, 'loss_3': -15.588617324829102, 'loss_4': 1.643322467803955, 'epoch': 2.72}
{'loss': 0.0534, 'grad_norm': 16.039155960083008, 'learning_rate': 2.7296511627906976e-05, 'loss_1': 0.052527446299791336, 'loss_2': 0.0009212493896484375, 'loss_3': -15.676421165466309, 'loss_4': 1.4313136339187622, 'epoch': 2.72}
{'loss': 0.1272, 'grad_norm': 24.831544876098633, 'learning_rate': 2.7290697674418608e-05, 'loss_1': 0.12609177827835083, 'loss_2': 0.001087188720703125, 'loss_3': -15.716425895690918, 'loss_4': 1.6285003423690796, 'epoch': 2.73}
{'loss': 0.1056, 'grad_norm': 32.41006088256836, 'learning_rate': 2.7284883720930233e-05, 'loss_1': 0.1011052206158638, 'loss_2': 0.004482269287109375, 'loss_3': -15.70489501953125, 'loss_4': 1.6314666271209717, 'epoch': 2.73}
[INFO|trainer.py:4228] 2025-01-21 12:32:05,705 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:05,706 >>   Batch size = 64
  9%|████████████████████▎                                                                                                                                                                                                       | 475/5160 [12:10<1:21:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:13,065 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.06421870738267899, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.039, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.055996187031269073, 'eval_loss_2': 0.008222520351409912, 'eval_loss_3': -18.039974212646484, 'eval_loss_4': 2.0971603393554688, 'epoch': 2.73}
{'loss': 0.1593, 'grad_norm': 34.5308952331543, 'learning_rate': 2.7279069767441862e-05, 'loss_1': 0.15103526413440704, 'loss_2': 0.00830078125, 'loss_3': -15.34722900390625, 'loss_4': 2.0457327365875244, 'epoch': 2.74}
{'loss': 0.168, 'grad_norm': 28.288171768188477, 'learning_rate': 2.7273255813953487e-05, 'loss_1': 0.15852107107639313, 'loss_2': 0.0094757080078125, 'loss_3': -15.527058601379395, 'loss_4': 2.5345540046691895, 'epoch': 2.74}
{'loss': 0.0661, 'grad_norm': 17.683765411376953, 'learning_rate': 2.7267441860465116e-05, 'loss_1': 0.05421406775712967, 'loss_2': 0.0118408203125, 'loss_3': -15.863578796386719, 'loss_4': 2.6133713722229004, 'epoch': 2.75}
{'loss': 0.0668, 'grad_norm': 21.072118759155273, 'learning_rate': 2.7261627906976744e-05, 'loss_1': 0.06225282698869705, 'loss_2': 0.0045318603515625, 'loss_3': -15.425178527832031, 'loss_4': 2.0372724533081055, 'epoch': 2.76}
{'loss': 0.1232, 'grad_norm': 28.593921661376953, 'learning_rate': 2.7255813953488373e-05, 'loss_1': 0.11597489565610886, 'loss_2': 0.0072479248046875, 'loss_3': -15.537854194641113, 'loss_4': 2.7065224647521973, 'epoch': 2.76}
[INFO|trainer.py:4228] 2025-01-21 12:32:13,065 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:13,065 >>   Batch size = 64
  9%|████████████████████▍                                                                                                                                                                                                       | 480/5160 [12:17<1:21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:20,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10931654274463654, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.409, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.10234896838665009, 'eval_loss_2': 0.00696757435798645, 'eval_loss_3': -17.938339233398438, 'eval_loss_4': 2.7237274646759033, 'epoch': 2.76}
{'loss': 0.1168, 'grad_norm': 23.699512481689453, 'learning_rate': 2.725e-05, 'loss_1': 0.1038520336151123, 'loss_2': 0.01290130615234375, 'loss_3': -15.771090507507324, 'loss_4': 2.9615347385406494, 'epoch': 2.77}
{'loss': 0.1513, 'grad_norm': 32.322261810302734, 'learning_rate': 2.7244186046511627e-05, 'loss_1': 0.14845630526542664, 'loss_2': 0.0028018951416015625, 'loss_3': -15.599968910217285, 'loss_4': 2.7575907707214355, 'epoch': 2.77}
{'loss': 0.0747, 'grad_norm': 19.46950340270996, 'learning_rate': 2.7238372093023256e-05, 'loss_1': 0.07231159508228302, 'loss_2': 0.0023784637451171875, 'loss_3': -15.685797691345215, 'loss_4': 2.4273834228515625, 'epoch': 2.78}
{'loss': 0.0491, 'grad_norm': 16.496047973632812, 'learning_rate': 2.7232558139534884e-05, 'loss_1': 0.036793746054172516, 'loss_2': 0.0123291015625, 'loss_3': -15.676121711730957, 'loss_4': 2.1979517936706543, 'epoch': 2.78}
{'loss': 0.0245, 'grad_norm': 6.41865873336792, 'learning_rate': 2.7226744186046513e-05, 'loss_1': 0.015256376937031746, 'loss_2': 0.0092315673828125, 'loss_3': -15.824084281921387, 'loss_4': 2.2016196250915527, 'epoch': 2.79}
[INFO|trainer.py:4228] 2025-01-21 12:32:20,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:20,439 >>   Batch size = 64
  9%|████████████████████▋                                                                                                                                                                                                       | 485/5160 [12:24<1:21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:27,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016788946464657784, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.139, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.012739883735775948, 'eval_loss_2': 0.004049062728881836, 'eval_loss_3': -18.26369857788086, 'eval_loss_4': 2.218019962310791, 'epoch': 2.79}
{'loss': 0.0424, 'grad_norm': 10.193924903869629, 'learning_rate': 2.722093023255814e-05, 'loss_1': 0.03627798333764076, 'loss_2': 0.0061492919921875, 'loss_3': -15.810772895812988, 'loss_4': 2.3861284255981445, 'epoch': 2.8}
{'loss': 0.0443, 'grad_norm': 17.31456756591797, 'learning_rate': 2.7215116279069767e-05, 'loss_1': 0.039072152227163315, 'loss_2': 0.005218505859375, 'loss_3': -15.896621704101562, 'loss_4': 2.871528387069702, 'epoch': 2.8}
{'loss': 0.0419, 'grad_norm': 13.497810363769531, 'learning_rate': 2.7209302325581395e-05, 'loss_1': 0.03506220504641533, 'loss_2': 0.0067901611328125, 'loss_3': -15.806467056274414, 'loss_4': 2.7558374404907227, 'epoch': 2.81}
{'loss': 0.0912, 'grad_norm': 20.140878677368164, 'learning_rate': 2.7203488372093024e-05, 'loss_1': 0.08080802112817764, 'loss_2': 0.0103759765625, 'loss_3': -15.839080810546875, 'loss_4': 3.1852378845214844, 'epoch': 2.81}
{'loss': 0.0546, 'grad_norm': 10.607975006103516, 'learning_rate': 2.7197674418604653e-05, 'loss_1': 0.043263331055641174, 'loss_2': 0.01132965087890625, 'loss_3': -15.818276405334473, 'loss_4': 2.882399559020996, 'epoch': 2.82}
[INFO|trainer.py:4228] 2025-01-21 12:32:27,829 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:27,829 >>   Batch size = 64
  9%|████████████████████▉                                                                                                                                                                                                       | 490/5160 [12:32<1:21:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:35,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02636255882680416, 'eval_runtime': 3.8208, 'eval_samples_per_second': 268.01, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.014420648105442524, 'eval_loss_2': 0.011941909790039062, 'eval_loss_3': -18.315906524658203, 'eval_loss_4': 2.6535189151763916, 'epoch': 2.82}
{'loss': 0.1129, 'grad_norm': 24.3118896484375, 'learning_rate': 2.7191860465116278e-05, 'loss_1': 0.10235493630170822, 'loss_2': 0.01053619384765625, 'loss_3': -15.770462036132812, 'loss_4': 3.2182483673095703, 'epoch': 2.83}
{'loss': 0.0372, 'grad_norm': 8.819087982177734, 'learning_rate': 2.7186046511627906e-05, 'loss_1': 0.027123501524329185, 'loss_2': 0.01007080078125, 'loss_3': -15.930992126464844, 'loss_4': 2.8668203353881836, 'epoch': 2.83}
{'loss': 0.0539, 'grad_norm': 12.89963150024414, 'learning_rate': 2.718023255813954e-05, 'loss_1': 0.04219726473093033, 'loss_2': 0.01168060302734375, 'loss_3': -15.91543960571289, 'loss_4': 3.0334858894348145, 'epoch': 2.84}
{'loss': 0.0478, 'grad_norm': 9.322161674499512, 'learning_rate': 2.7174418604651164e-05, 'loss_1': 0.032283809036016464, 'loss_2': 0.01556396484375, 'loss_3': -15.755935668945312, 'loss_4': 2.4204556941986084, 'epoch': 2.84}
{'loss': 0.0144, 'grad_norm': 6.438995361328125, 'learning_rate': 2.7168604651162792e-05, 'loss_1': 0.013237422332167625, 'loss_2': 0.001155853271484375, 'loss_3': -15.703680038452148, 'loss_4': 2.368542432785034, 'epoch': 2.85}
[INFO|trainer.py:4228] 2025-01-21 12:32:35,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:35,217 >>   Batch size = 64
 10%|█████████████████████                                                                                                                                                                                                       | 495/5160 [12:39<1:21:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:42,594 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016997529193758965, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.257, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.012575848959386349, 'eval_loss_2': 0.00442168116569519, 'eval_loss_3': -18.308393478393555, 'eval_loss_4': 2.230684757232666, 'epoch': 2.85}
{'loss': 0.0879, 'grad_norm': 21.862037658691406, 'learning_rate': 2.7162790697674418e-05, 'loss_1': 0.08464767783880234, 'loss_2': 0.00327301025390625, 'loss_3': -15.684972763061523, 'loss_4': 2.3741440773010254, 'epoch': 2.85}
{'loss': 0.0434, 'grad_norm': 14.976834297180176, 'learning_rate': 2.7156976744186046e-05, 'loss_1': 0.03702065721154213, 'loss_2': 0.006366729736328125, 'loss_3': -15.90578842163086, 'loss_4': 2.1319785118103027, 'epoch': 2.86}
{'loss': 0.0812, 'grad_norm': 31.09893226623535, 'learning_rate': 2.7151162790697678e-05, 'loss_1': 0.0745290145277977, 'loss_2': 0.00667572021484375, 'loss_3': -15.79650592803955, 'loss_4': 2.1804897785186768, 'epoch': 2.87}
{'loss': 0.0724, 'grad_norm': 22.90328598022461, 'learning_rate': 2.7145348837209304e-05, 'loss_1': 0.05642168968915939, 'loss_2': 0.0159759521484375, 'loss_3': -15.760566711425781, 'loss_4': 1.6765776872634888, 'epoch': 2.87}
{'loss': 0.0256, 'grad_norm': 10.627357482910156, 'learning_rate': 2.7139534883720932e-05, 'loss_1': 0.023393377661705017, 'loss_2': 0.0022296905517578125, 'loss_3': -15.601411819458008, 'loss_4': 1.6464323997497559, 'epoch': 2.88}
[INFO|trainer.py:4228] 2025-01-21 12:32:42,594 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:42,594 >>   Batch size = 64
 10%|█████████████████████▎                                                                                                                                                                                                      | 500/5160 [12:47<1:20:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:49,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025673972442746162, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.876, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.014539526775479317, 'eval_loss_2': 0.011134445667266846, 'eval_loss_3': -18.28150749206543, 'eval_loss_4': 1.7234477996826172, 'epoch': 2.88}
{'loss': 0.0633, 'grad_norm': 29.661561965942383, 'learning_rate': 2.7133720930232557e-05, 'loss_1': 0.04800856485962868, 'loss_2': 0.0153045654296875, 'loss_3': -15.824289321899414, 'loss_4': 1.6260838508605957, 'epoch': 2.88}
{'loss': 0.0462, 'grad_norm': 7.893099308013916, 'learning_rate': 2.7127906976744186e-05, 'loss_1': 0.03185070678591728, 'loss_2': 0.01430511474609375, 'loss_3': -15.886970520019531, 'loss_4': 2.271223545074463, 'epoch': 2.89}
{'loss': 0.0439, 'grad_norm': 10.773857116699219, 'learning_rate': 2.7122093023255815e-05, 'loss_1': 0.03464946523308754, 'loss_2': 0.00921630859375, 'loss_3': -15.726530075073242, 'loss_4': 1.7072594165802002, 'epoch': 2.9}
{'loss': 0.0447, 'grad_norm': 10.697741508483887, 'learning_rate': 2.7116279069767443e-05, 'loss_1': 0.03795527666807175, 'loss_2': 0.00670623779296875, 'loss_3': -15.740150451660156, 'loss_4': 1.6647645235061646, 'epoch': 2.9}
{'loss': 0.0724, 'grad_norm': 22.08877182006836, 'learning_rate': 2.7110465116279072e-05, 'loss_1': 0.06413495540618896, 'loss_2': 0.00824737548828125, 'loss_3': -15.909444808959961, 'loss_4': 1.6670093536376953, 'epoch': 2.91}
[INFO|trainer.py:4228] 2025-01-21 12:32:49,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:49,963 >>   Batch size = 64
 10%|█████████████████████▌                                                                                                                                                                                                      | 505/5160 [12:54<1:20:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:32:57,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.028917819261550903, 'eval_runtime': 3.8193, 'eval_samples_per_second': 268.111, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.023608548566699028, 'eval_loss_2': 0.005309268832206726, 'eval_loss_3': -18.21143913269043, 'eval_loss_4': 1.509944200515747, 'epoch': 2.91}
{'loss': 0.0373, 'grad_norm': 10.301313400268555, 'learning_rate': 2.7104651162790697e-05, 'loss_1': 0.028136497363448143, 'loss_2': 0.0092010498046875, 'loss_3': -15.907950401306152, 'loss_4': 1.5795118808746338, 'epoch': 2.91}
{'loss': 0.0759, 'grad_norm': 21.395599365234375, 'learning_rate': 2.7098837209302326e-05, 'loss_1': 0.07389257103204727, 'loss_2': 0.002025604248046875, 'loss_3': -15.94013786315918, 'loss_4': 1.6878128051757812, 'epoch': 2.92}
{'loss': 0.0609, 'grad_norm': 24.723217010498047, 'learning_rate': 2.7093023255813954e-05, 'loss_1': 0.055086635053157806, 'loss_2': 0.00579833984375, 'loss_3': -15.922126770019531, 'loss_4': 1.0843980312347412, 'epoch': 2.92}
{'loss': 0.0339, 'grad_norm': 9.705093383789062, 'learning_rate': 2.7087209302325583e-05, 'loss_1': 0.02883155830204487, 'loss_2': 0.00508880615234375, 'loss_3': -15.87298583984375, 'loss_4': 1.0037589073181152, 'epoch': 2.93}
{'loss': 0.0536, 'grad_norm': 11.88793659210205, 'learning_rate': 2.708139534883721e-05, 'loss_1': 0.0435333289206028, 'loss_2': 0.01007843017578125, 'loss_3': -15.69896125793457, 'loss_4': 0.9308335781097412, 'epoch': 2.94}
[INFO|trainer.py:4228] 2025-01-21 12:32:57,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:32:57,336 >>   Batch size = 64
 10%|█████████████████████▋                                                                                                                                                                                                      | 510/5160 [13:01<1:20:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:04,698 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03040722943842411, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.81, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01697496511042118, 'eval_loss_2': 0.01343226432800293, 'eval_loss_3': -18.221220016479492, 'eval_loss_4': 0.9695900678634644, 'epoch': 2.94}
{'loss': 0.066, 'grad_norm': 21.24304962158203, 'learning_rate': 2.7075581395348837e-05, 'loss_1': 0.059407759457826614, 'loss_2': 0.0065460205078125, 'loss_3': -15.754353523254395, 'loss_4': 1.181496024131775, 'epoch': 2.94}
{'loss': 0.042, 'grad_norm': 12.968801498413086, 'learning_rate': 2.7069767441860466e-05, 'loss_1': 0.028037304058670998, 'loss_2': 0.014007568359375, 'loss_3': -15.488710403442383, 'loss_4': 0.6224938631057739, 'epoch': 2.95}
{'loss': 0.0226, 'grad_norm': 10.075998306274414, 'learning_rate': 2.7063953488372094e-05, 'loss_1': 0.02194182574748993, 'loss_2': 0.0006656646728515625, 'loss_3': -15.415519714355469, 'loss_4': 0.752941906452179, 'epoch': 2.95}
{'loss': 0.0403, 'grad_norm': 11.702954292297363, 'learning_rate': 2.7058139534883723e-05, 'loss_1': 0.038148291409015656, 'loss_2': 0.002117156982421875, 'loss_3': -15.67631721496582, 'loss_4': 0.5512369871139526, 'epoch': 2.96}
{'loss': 0.0754, 'grad_norm': 25.96399688720703, 'learning_rate': 2.7052325581395348e-05, 'loss_1': 0.060182537883520126, 'loss_2': 0.01523590087890625, 'loss_3': -15.682304382324219, 'loss_4': 1.3017957210540771, 'epoch': 2.97}
[INFO|trainer.py:4228] 2025-01-21 12:33:04,698 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:04,698 >>   Batch size = 64
 10%|█████████████████████▉                                                                                                                                                                                                      | 515/5160 [13:09<1:20:05,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:33:12,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019111547619104385, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.773, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013803482986986637, 'eval_loss_2': 0.005308061838150024, 'eval_loss_3': -18.254596710205078, 'eval_loss_4': 0.6976931095123291, 'epoch': 2.97}
{'loss': 0.0293, 'grad_norm': 9.608893394470215, 'learning_rate': 2.7046511627906977e-05, 'loss_1': 0.02588558942079544, 'loss_2': 0.0033702850341796875, 'loss_3': -15.701467514038086, 'loss_4': 0.5776000022888184, 'epoch': 2.97}
{'loss': 0.02, 'grad_norm': 10.892959594726562, 'learning_rate': 2.7040697674418605e-05, 'loss_1': 0.018691686913371086, 'loss_2': 0.00125885009765625, 'loss_3': -15.72472095489502, 'loss_4': 0.7219355702400208, 'epoch': 2.98}
{'loss': 0.0646, 'grad_norm': 22.04210090637207, 'learning_rate': 2.7034883720930234e-05, 'loss_1': 0.06207936257123947, 'loss_2': 0.0024967193603515625, 'loss_3': -15.780830383300781, 'loss_4': 1.0138698816299438, 'epoch': 2.98}
{'loss': 0.054, 'grad_norm': 18.592138290405273, 'learning_rate': 2.7029069767441863e-05, 'loss_1': 0.051725663244724274, 'loss_2': 0.00223541259765625, 'loss_3': -15.590293884277344, 'loss_4': 1.062431812286377, 'epoch': 2.99}
{'loss': 0.0542, 'grad_norm': 16.051565170288086, 'learning_rate': 2.7023255813953488e-05, 'loss_1': 0.04938146471977234, 'loss_2': 0.00479888916015625, 'loss_3': -15.713384628295898, 'loss_4': 0.8989100456237793, 'epoch': 2.99}
[INFO|trainer.py:4228] 2025-01-21 12:33:12,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:12,044 >>   Batch size = 64
 10%|██████████████████████▏                                                                                                                                                                                                     | 520/5160 [13:16<1:19:00,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:33:19,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019077425822615623, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.137, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.014691532589495182, 'eval_loss_2': 0.004385892301797867, 'eval_loss_3': -18.312118530273438, 'eval_loss_4': 1.1015543937683105, 'epoch': 2.99}
{'loss': 0.0169, 'grad_norm': 8.344681739807129, 'learning_rate': 2.7017441860465116e-05, 'loss_1': 0.007287666667252779, 'loss_2': 0.0096435546875, 'loss_3': -15.838454246520996, 'loss_4': 1.292486548423767, 'epoch': 3.0}
{'loss': 0.0511, 'grad_norm': 22.90300750732422, 'learning_rate': 2.7011627906976745e-05, 'loss_1': 0.04488028213381767, 'loss_2': 0.0061798095703125, 'loss_3': -15.792125701904297, 'loss_4': 1.3203060626983643, 'epoch': 3.01}
{'loss': 0.0446, 'grad_norm': 24.11758804321289, 'learning_rate': 2.7005813953488374e-05, 'loss_1': 0.03745588660240173, 'loss_2': 0.007110595703125, 'loss_3': -15.990169525146484, 'loss_4': 1.4359023571014404, 'epoch': 3.01}
{'loss': 0.0809, 'grad_norm': 23.003421783447266, 'learning_rate': 2.7000000000000002e-05, 'loss_1': 0.07702015340328217, 'loss_2': 0.003910064697265625, 'loss_3': -16.05295181274414, 'loss_4': 1.2630112171173096, 'epoch': 3.02}
{'loss': 0.0638, 'grad_norm': 14.528881072998047, 'learning_rate': 2.6994186046511628e-05, 'loss_1': 0.05878814309835434, 'loss_2': 0.0050048828125, 'loss_3': -15.922429084777832, 'loss_4': 1.154720425605774, 'epoch': 3.02}
[INFO|trainer.py:4228] 2025-01-21 12:33:19,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:19,132 >>   Batch size = 64
 10%|██████████████████████▍                                                                                                                                                                                                     | 525/5160 [13:23<1:20:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:26,489 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01965615153312683, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.921, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01557126920670271, 'eval_loss_2': 0.004084885120391846, 'eval_loss_3': -18.320648193359375, 'eval_loss_4': 0.897693395614624, 'epoch': 3.02}
{'loss': 0.055, 'grad_norm': 13.914546966552734, 'learning_rate': 2.6988372093023256e-05, 'loss_1': 0.04627675563097, 'loss_2': 0.008697509765625, 'loss_3': -15.850505828857422, 'loss_4': 0.8423771858215332, 'epoch': 3.03}
{'loss': 0.0347, 'grad_norm': 15.116044044494629, 'learning_rate': 2.698255813953488e-05, 'loss_1': 0.032609619200229645, 'loss_2': 0.00206756591796875, 'loss_3': -16.024616241455078, 'loss_4': 1.0072121620178223, 'epoch': 3.03}
{'loss': 0.0281, 'grad_norm': 9.909459114074707, 'learning_rate': 2.6976744186046514e-05, 'loss_1': 0.027828894555568695, 'loss_2': 0.0002875328063964844, 'loss_3': -15.833211898803711, 'loss_4': 1.0862445831298828, 'epoch': 3.04}
{'loss': 0.0231, 'grad_norm': 6.721325397491455, 'learning_rate': 2.6970930232558142e-05, 'loss_1': 0.018844403326511383, 'loss_2': 0.004291534423828125, 'loss_3': -15.954056739807129, 'loss_4': 0.7905653119087219, 'epoch': 3.05}
{'loss': 0.0588, 'grad_norm': 18.938024520874023, 'learning_rate': 2.6965116279069767e-05, 'loss_1': 0.057325150817632675, 'loss_2': 0.0014791488647460938, 'loss_3': -15.784952163696289, 'loss_4': 0.26741790771484375, 'epoch': 3.05}
[INFO|trainer.py:4228] 2025-01-21 12:33:26,489 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:26,489 >>   Batch size = 64
 10%|██████████████████████▌                                                                                                                                                                                                     | 530/5160 [13:31<1:20:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:33,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01751912757754326, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.697, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.014005130156874657, 'eval_loss_2': 0.0035139992833137512, 'eval_loss_3': -18.29254150390625, 'eval_loss_4': 0.07805927097797394, 'epoch': 3.05}
{'loss': 0.1265, 'grad_norm': 41.96319580078125, 'learning_rate': 2.6959302325581396e-05, 'loss_1': 0.11505258828401566, 'loss_2': 0.0113983154296875, 'loss_3': -15.789331436157227, 'loss_4': 1.2143833637237549, 'epoch': 3.06}
{'loss': 0.0335, 'grad_norm': 14.691211700439453, 'learning_rate': 2.695348837209302e-05, 'loss_1': 0.03292747214436531, 'loss_2': 0.0005526542663574219, 'loss_3': -16.09003257751465, 'loss_4': 0.017511889338493347, 'epoch': 3.06}
{'loss': 0.0851, 'grad_norm': 34.70705032348633, 'learning_rate': 2.6947674418604653e-05, 'loss_1': 0.07817647606134415, 'loss_2': 0.00687408447265625, 'loss_3': -15.920207977294922, 'loss_4': 0.19354569911956787, 'epoch': 3.07}
{'loss': 0.0457, 'grad_norm': 9.309782981872559, 'learning_rate': 2.6941860465116282e-05, 'loss_1': 0.03436729311943054, 'loss_2': 0.011322021484375, 'loss_3': -15.797788619995117, 'loss_4': -0.29981762170791626, 'epoch': 3.08}
{'loss': 0.0724, 'grad_norm': 18.610815048217773, 'learning_rate': 2.6936046511627907e-05, 'loss_1': 0.056610893458127975, 'loss_2': 0.0158233642578125, 'loss_3': -16.010753631591797, 'loss_4': 0.03557524085044861, 'epoch': 3.08}
[INFO|trainer.py:4228] 2025-01-21 12:33:33,860 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:33,860 >>   Batch size = 64
 10%|██████████████████████▊                                                                                                                                                                                                     | 535/5160 [13:38<1:20:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:41,213 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02115001156926155, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.099, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.01416959147900343, 'eval_loss_2': 0.006980419158935547, 'eval_loss_3': -18.278339385986328, 'eval_loss_4': -0.2262628674507141, 'epoch': 3.08}
{'loss': 0.1058, 'grad_norm': 27.702716827392578, 'learning_rate': 2.6930232558139536e-05, 'loss_1': 0.0955953523516655, 'loss_2': 0.0102386474609375, 'loss_3': -15.712822914123535, 'loss_4': 0.0847267359495163, 'epoch': 3.09}
{'loss': 0.0303, 'grad_norm': 10.686413764953613, 'learning_rate': 2.692441860465116e-05, 'loss_1': 0.024995405226945877, 'loss_2': 0.005313873291015625, 'loss_3': -15.920355796813965, 'loss_4': -0.0891990065574646, 'epoch': 3.09}
{'loss': 0.059, 'grad_norm': 18.073381423950195, 'learning_rate': 2.6918604651162793e-05, 'loss_1': 0.055429667234420776, 'loss_2': 0.003597259521484375, 'loss_3': -16.11560821533203, 'loss_4': -0.3687129616737366, 'epoch': 3.1}
{'loss': 0.0507, 'grad_norm': 14.021973609924316, 'learning_rate': 2.691279069767442e-05, 'loss_1': 0.04244353249669075, 'loss_2': 0.00823974609375, 'loss_3': -15.93518352508545, 'loss_4': -0.5171908140182495, 'epoch': 3.1}
{'loss': 0.0648, 'grad_norm': 21.59151268005371, 'learning_rate': 2.6906976744186047e-05, 'loss_1': 0.05843918025493622, 'loss_2': 0.006378173828125, 'loss_3': -15.932075500488281, 'loss_4': -0.2455185055732727, 'epoch': 3.11}
[INFO|trainer.py:4228] 2025-01-21 12:33:41,213 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:41,213 >>   Batch size = 64
 10%|███████████████████████                                                                                                                                                                                                     | 540/5160 [13:45<1:20:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:48,575 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016907930374145508, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.089, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012723565101623535, 'eval_loss_2': 0.004184365272521973, 'eval_loss_3': -18.28230857849121, 'eval_loss_4': -0.26492324471473694, 'epoch': 3.11}
{'loss': 0.0831, 'grad_norm': 18.5675048828125, 'learning_rate': 2.6901162790697676e-05, 'loss_1': 0.08081161230802536, 'loss_2': 0.00232696533203125, 'loss_3': -15.940967559814453, 'loss_4': 0.46971845626831055, 'epoch': 3.12}
{'loss': 0.0372, 'grad_norm': 9.413569450378418, 'learning_rate': 2.68953488372093e-05, 'loss_1': 0.031015247106552124, 'loss_2': 0.00618743896484375, 'loss_3': -15.97014045715332, 'loss_4': -0.9424211978912354, 'epoch': 3.12}
{'loss': 0.049, 'grad_norm': 19.716699600219727, 'learning_rate': 2.6889534883720933e-05, 'loss_1': 0.04832204803824425, 'loss_2': 0.00070953369140625, 'loss_3': -15.745574951171875, 'loss_4': -0.2975390553474426, 'epoch': 3.13}
{'loss': 0.0608, 'grad_norm': 14.749606132507324, 'learning_rate': 2.6883720930232558e-05, 'loss_1': 0.05515101179480553, 'loss_2': 0.005619049072265625, 'loss_3': -16.054340362548828, 'loss_4': -0.1852370798587799, 'epoch': 3.13}
{'loss': 0.0365, 'grad_norm': 9.870072364807129, 'learning_rate': 2.6877906976744187e-05, 'loss_1': 0.03588005527853966, 'loss_2': 0.0005702972412109375, 'loss_3': -15.996284484863281, 'loss_4': -0.4343939423561096, 'epoch': 3.14}
[INFO|trainer.py:4228] 2025-01-21 12:33:48,575 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:48,575 >>   Batch size = 64
 11%|███████████████████████▏                                                                                                                                                                                                    | 545/5160 [13:53<1:20:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:33:55,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02071242406964302, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.858, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.013006779365241528, 'eval_loss_2': 0.0077056437730789185, 'eval_loss_3': -18.307697296142578, 'eval_loss_4': -0.33518141508102417, 'epoch': 3.14}
{'loss': 0.0284, 'grad_norm': 11.20274543762207, 'learning_rate': 2.6872093023255815e-05, 'loss_1': 0.0225407462567091, 'loss_2': 0.005840301513671875, 'loss_3': -15.852602005004883, 'loss_4': -0.6348729133605957, 'epoch': 3.15}
{'loss': 0.0566, 'grad_norm': 20.212482452392578, 'learning_rate': 2.686627906976744e-05, 'loss_1': 0.04167022183537483, 'loss_2': 0.0149688720703125, 'loss_3': -15.796821594238281, 'loss_4': -0.1541367471218109, 'epoch': 3.15}
{'loss': 0.0712, 'grad_norm': 22.072406768798828, 'learning_rate': 2.6860465116279073e-05, 'loss_1': 0.06681929528713226, 'loss_2': 0.004367828369140625, 'loss_3': -15.837627410888672, 'loss_4': -0.05110941082239151, 'epoch': 3.16}
{'loss': 0.0518, 'grad_norm': 15.889902114868164, 'learning_rate': 2.6854651162790698e-05, 'loss_1': 0.04981926083564758, 'loss_2': 0.0020084381103515625, 'loss_3': -15.949838638305664, 'loss_4': -0.29469034075737, 'epoch': 3.16}
{'loss': 0.0444, 'grad_norm': 11.747897148132324, 'learning_rate': 2.6848837209302326e-05, 'loss_1': 0.04021690413355827, 'loss_2': 0.004192352294921875, 'loss_3': -16.084217071533203, 'loss_4': -0.32802140712738037, 'epoch': 3.17}
[INFO|trainer.py:4228] 2025-01-21 12:33:55,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:33:55,938 >>   Batch size = 64
 11%|███████████████████████▍                                                                                                                                                                                                    | 550/5160 [14:00<1:20:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:03,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01717914268374443, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.625, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.013958917930722237, 'eval_loss_2': 0.0032202228903770447, 'eval_loss_3': -18.36361312866211, 'eval_loss_4': -0.38702625036239624, 'epoch': 3.17}
{'loss': 0.0653, 'grad_norm': 27.836450576782227, 'learning_rate': 2.6843023255813952e-05, 'loss_1': 0.06219245120882988, 'loss_2': 0.0030975341796875, 'loss_3': -15.947583198547363, 'loss_4': -0.8347623348236084, 'epoch': 3.17}
{'loss': 0.0526, 'grad_norm': 17.771881103515625, 'learning_rate': 2.683720930232558e-05, 'loss_1': 0.049547288566827774, 'loss_2': 0.00301361083984375, 'loss_3': -15.93595027923584, 'loss_4': -0.5993571877479553, 'epoch': 3.18}
{'loss': 0.0366, 'grad_norm': 9.806639671325684, 'learning_rate': 2.6831395348837212e-05, 'loss_1': 0.03010980598628521, 'loss_2': 0.006496429443359375, 'loss_3': -15.939363479614258, 'loss_4': -0.4041636288166046, 'epoch': 3.19}
{'loss': 0.0405, 'grad_norm': 19.708284378051758, 'learning_rate': 2.6825581395348838e-05, 'loss_1': 0.03939748927950859, 'loss_2': 0.0011034011840820312, 'loss_3': -16.223529815673828, 'loss_4': -0.009664889425039291, 'epoch': 3.19}
{'loss': 0.0368, 'grad_norm': 15.537485122680664, 'learning_rate': 2.6819767441860466e-05, 'loss_1': 0.03533108904957771, 'loss_2': 0.001514434814453125, 'loss_3': -16.028305053710938, 'loss_4': 0.31215816736221313, 'epoch': 3.2}
[INFO|trainer.py:4228] 2025-01-21 12:34:03,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:03,308 >>   Batch size = 64
 11%|███████████████████████▋                                                                                                                                                                                                    | 555/5160 [14:07<1:19:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:10,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01567259058356285, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013040955178439617, 'eval_loss_2': 0.002631634473800659, 'eval_loss_3': -18.371076583862305, 'eval_loss_4': 0.10097964107990265, 'epoch': 3.2}
{'loss': 0.0306, 'grad_norm': 8.544632911682129, 'learning_rate': 2.681395348837209e-05, 'loss_1': 0.024861181154847145, 'loss_2': 0.00577545166015625, 'loss_3': -15.832935333251953, 'loss_4': 0.7672908306121826, 'epoch': 3.2}
{'loss': 0.0605, 'grad_norm': 19.714557647705078, 'learning_rate': 2.6808139534883724e-05, 'loss_1': 0.05862484127283096, 'loss_2': 0.0019168853759765625, 'loss_3': -15.732830047607422, 'loss_4': 0.12834905087947845, 'epoch': 3.21}
{'loss': 0.052, 'grad_norm': 15.413436889648438, 'learning_rate': 2.6802325581395352e-05, 'loss_1': 0.04832317680120468, 'loss_2': 0.003631591796875, 'loss_3': -15.9920072555542, 'loss_4': 0.7712627649307251, 'epoch': 3.22}
{'loss': 0.1017, 'grad_norm': 26.946035385131836, 'learning_rate': 2.6796511627906977e-05, 'loss_1': 0.09483997523784637, 'loss_2': 0.00690460205078125, 'loss_3': -15.953360557556152, 'loss_4': 0.492626816034317, 'epoch': 3.22}
{'loss': 0.0553, 'grad_norm': 16.863557815551758, 'learning_rate': 2.6790697674418606e-05, 'loss_1': 0.055092547088861465, 'loss_2': 0.00020241737365722656, 'loss_3': -15.885900497436523, 'loss_4': 0.07078367471694946, 'epoch': 3.23}
[INFO|trainer.py:4228] 2025-01-21 12:34:10,671 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:10,671 >>   Batch size = 64
 11%|███████████████████████▉                                                                                                                                                                                                    | 560/5160 [14:15<1:19:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:18,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018570980057120323, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.911, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013913462869822979, 'eval_loss_2': 0.004657518118619919, 'eval_loss_3': -18.362199783325195, 'eval_loss_4': 0.17992210388183594, 'epoch': 3.23}
{'loss': 0.0659, 'grad_norm': 19.08959197998047, 'learning_rate': 2.678488372093023e-05, 'loss_1': 0.06299734115600586, 'loss_2': 0.002872467041015625, 'loss_3': -15.884740829467773, 'loss_4': 0.2998959422111511, 'epoch': 3.23}
{'loss': 0.0701, 'grad_norm': 23.70297622680664, 'learning_rate': 2.6779069767441863e-05, 'loss_1': 0.06799609959125519, 'loss_2': 0.0021381378173828125, 'loss_3': -15.86988353729248, 'loss_4': -0.4761384427547455, 'epoch': 3.24}
{'loss': 0.0498, 'grad_norm': 15.074575424194336, 'learning_rate': 2.677325581395349e-05, 'loss_1': 0.046969518065452576, 'loss_2': 0.0028285980224609375, 'loss_3': -15.740463256835938, 'loss_4': 0.2464609444141388, 'epoch': 3.24}
{'loss': 0.0521, 'grad_norm': 14.71712875366211, 'learning_rate': 2.6767441860465117e-05, 'loss_1': 0.049554094672203064, 'loss_2': 0.0025348663330078125, 'loss_3': -15.908245086669922, 'loss_4': 0.07272017002105713, 'epoch': 3.25}
{'loss': 0.0524, 'grad_norm': 13.921396255493164, 'learning_rate': 2.6761627906976746e-05, 'loss_1': 0.05110758915543556, 'loss_2': 0.00128173828125, 'loss_3': -15.877120971679688, 'loss_4': 0.2277849018573761, 'epoch': 3.26}
[INFO|trainer.py:4228] 2025-01-21 12:34:18,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:18,037 >>   Batch size = 64
 11%|████████████████████████                                                                                                                                                                                                    | 565/5160 [14:22<1:19:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:25,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019379984587430954, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.128, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.016742324456572533, 'eval_loss_2': 0.0026376619935035706, 'eval_loss_3': -18.336999893188477, 'eval_loss_4': 0.051015399396419525, 'epoch': 3.26}
{'loss': 0.0688, 'grad_norm': 15.88735580444336, 'learning_rate': 2.675581395348837e-05, 'loss_1': 0.0639280155301094, 'loss_2': 0.00492095947265625, 'loss_3': -15.736015319824219, 'loss_4': 0.2267356812953949, 'epoch': 3.26}
{'loss': 0.0462, 'grad_norm': 19.87856674194336, 'learning_rate': 2.6750000000000003e-05, 'loss_1': 0.04451112821698189, 'loss_2': 0.0016498565673828125, 'loss_3': -15.865469932556152, 'loss_4': 0.2857559323310852, 'epoch': 3.27}
{'loss': 0.0835, 'grad_norm': 24.42307472229004, 'learning_rate': 2.674418604651163e-05, 'loss_1': 0.07007654756307602, 'loss_2': 0.01345062255859375, 'loss_3': -15.802206993103027, 'loss_4': 0.3891845643520355, 'epoch': 3.27}
{'loss': 0.0507, 'grad_norm': 12.103313446044922, 'learning_rate': 2.6738372093023257e-05, 'loss_1': 0.0428205244243145, 'loss_2': 0.00792694091796875, 'loss_3': -15.732927322387695, 'loss_4': 0.09562426805496216, 'epoch': 3.28}
{'loss': 0.0545, 'grad_norm': 17.166250228881836, 'learning_rate': 2.6732558139534886e-05, 'loss_1': 0.051736246794462204, 'loss_2': 0.0027923583984375, 'loss_3': -15.728134155273438, 'loss_4': 0.07694779336452484, 'epoch': 3.28}
[INFO|trainer.py:4228] 2025-01-21 12:34:25,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:25,396 >>   Batch size = 64
 11%|████████████████████████▎                                                                                                                                                                                                   | 570/5160 [14:29<1:19:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:32,755 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025651924312114716, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.022645970806479454, 'eval_loss_2': 0.0030059516429901123, 'eval_loss_3': -18.237323760986328, 'eval_loss_4': 0.4318869411945343, 'epoch': 3.28}
{'loss': 0.0299, 'grad_norm': 10.041277885437012, 'learning_rate': 2.672674418604651e-05, 'loss_1': 0.029589032754302025, 'loss_2': 0.0003147125244140625, 'loss_3': -15.637178421020508, 'loss_4': 0.6244892477989197, 'epoch': 3.29}
{'loss': 0.1432, 'grad_norm': 26.625619888305664, 'learning_rate': 2.6720930232558143e-05, 'loss_1': 0.14014072716236115, 'loss_2': 0.0030670166015625, 'loss_3': -15.791891098022461, 'loss_4': 0.6880886554718018, 'epoch': 3.3}
{'loss': 0.0451, 'grad_norm': 10.618383407592773, 'learning_rate': 2.6715116279069768e-05, 'loss_1': 0.03608543798327446, 'loss_2': 0.00901031494140625, 'loss_3': -15.823616027832031, 'loss_4': 0.5837833285331726, 'epoch': 3.3}
{'loss': 0.055, 'grad_norm': 11.998200416564941, 'learning_rate': 2.6709302325581397e-05, 'loss_1': 0.04101693257689476, 'loss_2': 0.014007568359375, 'loss_3': -15.784852027893066, 'loss_4': 0.9369673728942871, 'epoch': 3.31}
{'loss': 0.051, 'grad_norm': 12.376193046569824, 'learning_rate': 2.6703488372093022e-05, 'loss_1': 0.039941832423210144, 'loss_2': 0.01110076904296875, 'loss_3': -15.63596248626709, 'loss_4': 0.8100886940956116, 'epoch': 3.31}
[INFO|trainer.py:4228] 2025-01-21 12:34:32,755 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:32,755 >>   Batch size = 64
 11%|████████████████████████▌                                                                                                                                                                                                   | 575/5160 [14:37<1:19:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:40,134 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04907234013080597, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.272, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.042486678808927536, 'eval_loss_2': 0.006585657596588135, 'eval_loss_3': -18.120248794555664, 'eval_loss_4': 1.1076819896697998, 'epoch': 3.31}
{'loss': 0.0646, 'grad_norm': 21.479320526123047, 'learning_rate': 2.669767441860465e-05, 'loss_1': 0.059159133583307266, 'loss_2': 0.005458831787109375, 'loss_3': -15.819113731384277, 'loss_4': 1.0652775764465332, 'epoch': 3.32}
{'loss': 0.0297, 'grad_norm': 9.372003555297852, 'learning_rate': 2.6691860465116283e-05, 'loss_1': 0.02893237955868244, 'loss_2': 0.0007238388061523438, 'loss_3': -15.710328102111816, 'loss_4': 1.4076625108718872, 'epoch': 3.33}
{'loss': 0.0279, 'grad_norm': 8.634435653686523, 'learning_rate': 2.6686046511627908e-05, 'loss_1': 0.023676618933677673, 'loss_2': 0.004241943359375, 'loss_3': -15.7218656539917, 'loss_4': 1.3505645990371704, 'epoch': 3.33}
{'loss': 0.0849, 'grad_norm': 22.601985931396484, 'learning_rate': 2.6680232558139537e-05, 'loss_1': 0.07253653556108475, 'loss_2': 0.012359619140625, 'loss_3': -15.77657413482666, 'loss_4': 1.2250181436538696, 'epoch': 3.34}
{'loss': 0.0848, 'grad_norm': 26.153841018676758, 'learning_rate': 2.6674418604651162e-05, 'loss_1': 0.0810999721288681, 'loss_2': 0.0036754608154296875, 'loss_3': -15.92246150970459, 'loss_4': 1.5316429138183594, 'epoch': 3.34}
[INFO|trainer.py:4228] 2025-01-21 12:34:40,134 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:40,134 >>   Batch size = 64
 11%|████████████████████████▋                                                                                                                                                                                                   | 580/5160 [14:44<1:19:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:47,500 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03578244894742966, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.81, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.029850509017705917, 'eval_loss_2': 0.005931943655014038, 'eval_loss_3': -18.125782012939453, 'eval_loss_4': 1.3975197076797485, 'epoch': 3.34}
{'loss': 0.0551, 'grad_norm': 17.805604934692383, 'learning_rate': 2.666860465116279e-05, 'loss_1': 0.049112461507320404, 'loss_2': 0.005950927734375, 'loss_3': -15.618871688842773, 'loss_4': 1.4974005222320557, 'epoch': 3.35}
{'loss': 0.0356, 'grad_norm': 9.091192245483398, 'learning_rate': 2.666279069767442e-05, 'loss_1': 0.028956295922398567, 'loss_2': 0.0066680908203125, 'loss_3': -15.41370677947998, 'loss_4': 0.894524872303009, 'epoch': 3.35}
{'loss': 0.0523, 'grad_norm': 23.752788543701172, 'learning_rate': 2.6656976744186048e-05, 'loss_1': 0.04707736149430275, 'loss_2': 0.00521087646484375, 'loss_3': -15.63398551940918, 'loss_4': 1.3132926225662231, 'epoch': 3.36}
{'loss': 0.112, 'grad_norm': 36.48236083984375, 'learning_rate': 2.6651162790697676e-05, 'loss_1': 0.11145748198032379, 'loss_2': 0.0005502700805664062, 'loss_3': -15.753765106201172, 'loss_4': 1.563981294631958, 'epoch': 3.37}
{'loss': 0.0827, 'grad_norm': 27.527427673339844, 'learning_rate': 2.66453488372093e-05, 'loss_1': 0.07458490878343582, 'loss_2': 0.0081634521484375, 'loss_3': -15.719156265258789, 'loss_4': 2.4077939987182617, 'epoch': 3.37}
[INFO|trainer.py:4228] 2025-01-21 12:34:47,500 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:47,500 >>   Batch size = 64
 11%|████████████████████████▉                                                                                                                                                                                                   | 585/5160 [14:52<1:19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:34:54,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.040514569729566574, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03670147806406021, 'eval_loss_2': 0.0038130879402160645, 'eval_loss_3': -18.12738609313965, 'eval_loss_4': 2.0702643394470215, 'epoch': 3.37}
{'loss': 0.0687, 'grad_norm': 16.255691528320312, 'learning_rate': 2.663953488372093e-05, 'loss_1': 0.06076306849718094, 'loss_2': 0.007904052734375, 'loss_3': -15.84461784362793, 'loss_4': 2.0647478103637695, 'epoch': 3.38}
{'loss': 0.0531, 'grad_norm': 16.189350128173828, 'learning_rate': 2.663372093023256e-05, 'loss_1': 0.043717432767152786, 'loss_2': 0.0093536376953125, 'loss_3': -15.850936889648438, 'loss_4': 2.186927318572998, 'epoch': 3.38}
{'loss': 0.0487, 'grad_norm': 15.44304084777832, 'learning_rate': 2.6627906976744187e-05, 'loss_1': 0.044843919575214386, 'loss_2': 0.003826141357421875, 'loss_3': -15.83215045928955, 'loss_4': 2.17425537109375, 'epoch': 3.39}
{'loss': 0.0982, 'grad_norm': 33.404640197753906, 'learning_rate': 2.6622093023255816e-05, 'loss_1': 0.09208917617797852, 'loss_2': 0.00615692138671875, 'loss_3': -15.758867263793945, 'loss_4': 2.370084285736084, 'epoch': 3.4}
{'loss': 0.0587, 'grad_norm': 13.559063911437988, 'learning_rate': 2.661627906976744e-05, 'loss_1': 0.05822593346238136, 'loss_2': 0.0004782676696777344, 'loss_3': -15.870508193969727, 'loss_4': 2.797849655151367, 'epoch': 3.4}
[INFO|trainer.py:4228] 2025-01-21 12:34:54,861 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:34:54,861 >>   Batch size = 64
 11%|█████████████████████████▏                                                                                                                                                                                                  | 590/5160 [14:59<1:19:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:02,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022365067154169083, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.01960257813334465, 'eval_loss_2': 0.0027624890208244324, 'eval_loss_3': -18.248960494995117, 'eval_loss_4': 2.5176541805267334, 'epoch': 3.4}
{'loss': 0.0653, 'grad_norm': 18.324207305908203, 'learning_rate': 2.661046511627907e-05, 'loss_1': 0.06137067824602127, 'loss_2': 0.0038909912109375, 'loss_3': -16.03775978088379, 'loss_4': 2.4652161598205566, 'epoch': 3.41}
{'loss': 0.1121, 'grad_norm': 52.46543502807617, 'learning_rate': 2.66046511627907e-05, 'loss_1': 0.10540245473384857, 'loss_2': 0.00670623779296875, 'loss_3': -16.054424285888672, 'loss_4': 3.4217889308929443, 'epoch': 3.41}
{'loss': 0.0821, 'grad_norm': 22.76504135131836, 'learning_rate': 2.6598837209302327e-05, 'loss_1': 0.07123757898807526, 'loss_2': 0.0108795166015625, 'loss_3': -16.050861358642578, 'loss_4': 2.587282180786133, 'epoch': 3.42}
{'loss': 0.1334, 'grad_norm': 38.6429557800293, 'learning_rate': 2.6593023255813952e-05, 'loss_1': 0.13258247077465057, 'loss_2': 0.0008497238159179688, 'loss_3': -16.180572509765625, 'loss_4': 3.8633172512054443, 'epoch': 3.42}
{'loss': 0.0724, 'grad_norm': 14.75810432434082, 'learning_rate': 2.658720930232558e-05, 'loss_1': 0.06309611350297928, 'loss_2': 0.00927734375, 'loss_3': -15.979241371154785, 'loss_4': 4.062119007110596, 'epoch': 3.43}
[INFO|trainer.py:4228] 2025-01-21 12:35:02,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:02,226 >>   Batch size = 64
 12%|█████████████████████████▎                                                                                                                                                                                                  | 595/5160 [15:06<1:19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:09,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030844181776046753, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.845, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.021502256393432617, 'eval_loss_2': 0.009341925382614136, 'eval_loss_3': -18.368366241455078, 'eval_loss_4': 3.79485821723938, 'epoch': 3.43}
{'loss': 0.1293, 'grad_norm': 27.171245574951172, 'learning_rate': 2.658139534883721e-05, 'loss_1': 0.1094575971364975, 'loss_2': 0.0198516845703125, 'loss_3': -16.23931312561035, 'loss_4': 4.141751289367676, 'epoch': 3.44}
{'loss': 0.1085, 'grad_norm': 26.971105575561523, 'learning_rate': 2.657558139534884e-05, 'loss_1': 0.09851676225662231, 'loss_2': 0.0100250244140625, 'loss_3': -16.280948638916016, 'loss_4': 5.268136978149414, 'epoch': 3.44}
{'loss': 0.1076, 'grad_norm': 21.977046966552734, 'learning_rate': 2.6569767441860467e-05, 'loss_1': 0.0922636091709137, 'loss_2': 0.01532745361328125, 'loss_3': -16.006500244140625, 'loss_4': 5.201144695281982, 'epoch': 3.45}
{'loss': 0.0794, 'grad_norm': 23.839252471923828, 'learning_rate': 2.6563953488372092e-05, 'loss_1': 0.07279378920793533, 'loss_2': 0.0065765380859375, 'loss_3': -15.947685241699219, 'loss_4': 4.680599689483643, 'epoch': 3.45}
{'loss': 0.1004, 'grad_norm': 31.861759185791016, 'learning_rate': 2.655813953488372e-05, 'loss_1': 0.09500855952501297, 'loss_2': 0.005401611328125, 'loss_3': -16.161623001098633, 'loss_4': 5.732150077819824, 'epoch': 3.46}
[INFO|trainer.py:4228] 2025-01-21 12:35:09,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:09,602 >>   Batch size = 64
 12%|█████████████████████████▌                                                                                                                                                                                                  | 600/5160 [15:14<1:19:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:16,974 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03732211887836456, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.937, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03209717571735382, 'eval_loss_2': 0.005224943161010742, 'eval_loss_3': -18.38977813720703, 'eval_loss_4': 4.041901588439941, 'epoch': 3.46}
{'loss': 0.1344, 'grad_norm': 29.348512649536133, 'learning_rate': 2.655232558139535e-05, 'loss_1': 0.12825548648834229, 'loss_2': 0.00615692138671875, 'loss_3': -16.02400779724121, 'loss_4': 4.52786111831665, 'epoch': 3.47}
{'loss': 0.0646, 'grad_norm': 15.358259201049805, 'learning_rate': 2.6546511627906978e-05, 'loss_1': 0.06213490664958954, 'loss_2': 0.002437591552734375, 'loss_3': -16.034687042236328, 'loss_4': 4.335640907287598, 'epoch': 3.47}
{'loss': 0.0565, 'grad_norm': 18.793500900268555, 'learning_rate': 2.6540697674418607e-05, 'loss_1': 0.0524725615978241, 'loss_2': 0.0040435791015625, 'loss_3': -16.110477447509766, 'loss_4': 3.730618715286255, 'epoch': 3.48}
{'loss': 0.0534, 'grad_norm': 15.584611892700195, 'learning_rate': 2.6534883720930232e-05, 'loss_1': 0.051196325570344925, 'loss_2': 0.0021839141845703125, 'loss_3': -15.96630859375, 'loss_4': 2.198665142059326, 'epoch': 3.48}
{'loss': 0.0284, 'grad_norm': 7.466380596160889, 'learning_rate': 2.652906976744186e-05, 'loss_1': 0.017684509977698326, 'loss_2': 0.01071929931640625, 'loss_3': -16.118812561035156, 'loss_4': 2.0868818759918213, 'epoch': 3.49}
[INFO|trainer.py:4228] 2025-01-21 12:35:16,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:16,975 >>   Batch size = 64
 12%|█████████████████████████▊                                                                                                                                                                                                  | 605/5160 [15:21<1:19:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:24,359 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018648812547326088, 'eval_runtime': 3.8201, 'eval_samples_per_second': 268.054, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.014880508184432983, 'eval_loss_2': 0.003768306225538254, 'eval_loss_3': -18.336750030517578, 'eval_loss_4': 1.629765272140503, 'epoch': 3.49}
{'loss': 0.0394, 'grad_norm': 10.650470733642578, 'learning_rate': 2.6523255813953486e-05, 'loss_1': 0.030396580696105957, 'loss_2': 0.0089569091796875, 'loss_3': -16.024667739868164, 'loss_4': 1.8148472309112549, 'epoch': 3.49}
{'loss': 0.042, 'grad_norm': 17.665380477905273, 'learning_rate': 2.6517441860465118e-05, 'loss_1': 0.03911652788519859, 'loss_2': 0.002834320068359375, 'loss_3': -16.098255157470703, 'loss_4': 1.821505069732666, 'epoch': 3.5}
{'loss': 0.049, 'grad_norm': 14.66973876953125, 'learning_rate': 2.6511627906976747e-05, 'loss_1': 0.04802768677473068, 'loss_2': 0.00101470947265625, 'loss_3': -15.917682647705078, 'loss_4': 0.814529538154602, 'epoch': 3.51}
{'loss': 0.018, 'grad_norm': 7.146814346313477, 'learning_rate': 2.6505813953488372e-05, 'loss_1': 0.01591315306723118, 'loss_2': 0.00212860107421875, 'loss_3': -15.808008193969727, 'loss_4': 0.6160943508148193, 'epoch': 3.51}
{'loss': 0.0305, 'grad_norm': 9.513284683227539, 'learning_rate': 2.65e-05, 'loss_1': 0.027465643361210823, 'loss_2': 0.003009796142578125, 'loss_3': -16.072162628173828, 'loss_4': 0.9491141438484192, 'epoch': 3.52}
[INFO|trainer.py:4228] 2025-01-21 12:35:24,359 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:24,359 >>   Batch size = 64
 12%|██████████████████████████                                                                                                                                                                                                  | 610/5160 [15:28<1:18:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:31,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015746017917990685, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.632, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011732881888747215, 'eval_loss_2': 0.004013136029243469, 'eval_loss_3': -18.237815856933594, 'eval_loss_4': 0.6923361420631409, 'epoch': 3.52}
{'loss': 0.0232, 'grad_norm': 8.429971694946289, 'learning_rate': 2.6494186046511626e-05, 'loss_1': 0.022800426930189133, 'loss_2': 0.0003719329833984375, 'loss_3': -15.859395027160645, 'loss_4': 0.6918821930885315, 'epoch': 3.52}
{'loss': 0.0431, 'grad_norm': 11.194720268249512, 'learning_rate': 2.6488372093023258e-05, 'loss_1': 0.03954368084669113, 'loss_2': 0.003509521484375, 'loss_3': -15.830421447753906, 'loss_4': 0.495617538690567, 'epoch': 3.53}
{'loss': 0.0303, 'grad_norm': 6.880715370178223, 'learning_rate': 2.6482558139534886e-05, 'loss_1': 0.02776005119085312, 'loss_2': 0.002536773681640625, 'loss_3': -15.885300636291504, 'loss_4': 0.47343680262565613, 'epoch': 3.53}
{'loss': 0.0199, 'grad_norm': 6.074589729309082, 'learning_rate': 2.647674418604651e-05, 'loss_1': 0.018632177263498306, 'loss_2': 0.0012187957763671875, 'loss_3': -15.868061065673828, 'loss_4': 1.0147764682769775, 'epoch': 3.54}
{'loss': 0.158, 'grad_norm': 22.140064239501953, 'learning_rate': 2.647093023255814e-05, 'loss_1': 0.15412914752960205, 'loss_2': 0.003894805908203125, 'loss_3': -15.72714614868164, 'loss_4': 1.3483765125274658, 'epoch': 3.55}
[INFO|trainer.py:4228] 2025-01-21 12:35:31,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:31,726 >>   Batch size = 64
 12%|██████████████████████████▏                                                                                                                                                                                                 | 615/5160 [15:36<1:18:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:39,105 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03397246450185776, 'eval_runtime': 3.8245, 'eval_samples_per_second': 267.746, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.0288715623319149, 'eval_loss_2': 0.005100905895233154, 'eval_loss_3': -18.037384033203125, 'eval_loss_4': 1.5141887664794922, 'epoch': 3.55}
{'loss': 0.0251, 'grad_norm': 11.290828704833984, 'learning_rate': 2.6465116279069765e-05, 'loss_1': 0.023066189140081406, 'loss_2': 0.002056121826171875, 'loss_3': -15.831521987915039, 'loss_4': 1.755088448524475, 'epoch': 3.55}
{'loss': 0.0362, 'grad_norm': 14.252140998840332, 'learning_rate': 2.6459302325581397e-05, 'loss_1': 0.03329361230134964, 'loss_2': 0.002918243408203125, 'loss_3': -15.696560859680176, 'loss_4': 1.8416025638580322, 'epoch': 3.56}
{'loss': 0.024, 'grad_norm': 5.8628106117248535, 'learning_rate': 2.6453488372093023e-05, 'loss_1': 0.011807586066424847, 'loss_2': 0.01220703125, 'loss_3': -15.879697799682617, 'loss_4': 1.5705407857894897, 'epoch': 3.56}
{'loss': 0.0324, 'grad_norm': 10.379093170166016, 'learning_rate': 2.644767441860465e-05, 'loss_1': 0.021747058257460594, 'loss_2': 0.0106048583984375, 'loss_3': -15.563018798828125, 'loss_4': 1.7338496446609497, 'epoch': 3.57}
{'loss': 0.0598, 'grad_norm': 33.703556060791016, 'learning_rate': 2.644186046511628e-05, 'loss_1': 0.057084325700998306, 'loss_2': 0.0026760101318359375, 'loss_3': -15.661415100097656, 'loss_4': 2.010498046875, 'epoch': 3.58}
[INFO|trainer.py:4228] 2025-01-21 12:35:39,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:39,105 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:43<1:18:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:35:46,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02900906838476658, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.025213178247213364, 'eval_loss_2': 0.0037958920001983643, 'eval_loss_3': -18.056137084960938, 'eval_loss_4': 1.6384369134902954, 'epoch': 3.58}
{'loss': 0.0418, 'grad_norm': 14.861735343933105, 'learning_rate': 2.643604651162791e-05, 'loss_1': 0.03351200371980667, 'loss_2': 0.00830078125, 'loss_3': -15.81373405456543, 'loss_4': 1.1885199546813965, 'epoch': 3.58}
{'loss': 0.0211, 'grad_norm': 8.380077362060547, 'learning_rate': 2.6430232558139537e-05, 'loss_1': 0.01945914886891842, 'loss_2': 0.0015964508056640625, 'loss_3': -15.9813871383667, 'loss_4': 1.4252464771270752, 'epoch': 3.59}
{'loss': 0.0465, 'grad_norm': 26.482370376586914, 'learning_rate': 2.6424418604651162e-05, 'loss_1': 0.044984325766563416, 'loss_2': 0.0015106201171875, 'loss_3': -15.969700813293457, 'loss_4': 1.6136327981948853, 'epoch': 3.59}
{'loss': 0.0405, 'grad_norm': 12.556888580322266, 'learning_rate': 2.641860465116279e-05, 'loss_1': 0.030284196138381958, 'loss_2': 0.0102386474609375, 'loss_3': -15.926401138305664, 'loss_4': 1.372994065284729, 'epoch': 3.6}
{'loss': 0.0136, 'grad_norm': 6.1506829261779785, 'learning_rate': 2.641279069767442e-05, 'loss_1': 0.010988907888531685, 'loss_2': 0.00258636474609375, 'loss_3': -16.180667877197266, 'loss_4': 1.2329951524734497, 'epoch': 3.6}
[INFO|trainer.py:4228] 2025-01-21 12:35:46,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:46,470 >>   Batch size = 64
 12%|██████████████████████████▍                                                                                                                                                                                                 | 620/5160 [15:47<1:18:47,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:35:50,283 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-620
[INFO|configuration_utils.py:420] 2025-01-21 12:35:50,285 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-620/config.json                                                                             
{'eval_loss': 0.014625728130340576, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.657, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011801810003817081, 'eval_loss_2': 0.0028239190578460693, 'eval_loss_3': -18.307544708251953, 'eval_loss_4': 1.517531394958496, 'epoch': 3.6}
[INFO|modeling_utils.py:2988] 2025-01-21 12:35:50,767 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-620/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:35:50,768 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-620/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:35:50,768 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-620/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:35:51,740 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-340] due to args.save_total_limit
 12%|██████████████████████████▋                                                                                                                                                                                                 | 625/5160 [15:52<1:27:12,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:35:55,391 >>
{'loss': 0.0307, 'grad_norm': 11.76601791381836, 'learning_rate': 2.640697674418605e-05, 'loss_1': 0.0272089634090662, 'loss_2': 0.00350189208984375, 'loss_3': -16.04556655883789, 'loss_4': 1.5974048376083374, 'epoch': 3.61}
{'loss': 0.0481, 'grad_norm': 16.45808219909668, 'learning_rate': 2.6401162790697677e-05, 'loss_1': 0.043064966797828674, 'loss_2': 0.00505828857421875, 'loss_3': -16.024208068847656, 'loss_4': 2.1662185192108154, 'epoch': 3.62}
{'loss': 0.0199, 'grad_norm': 6.656040191650391, 'learning_rate': 2.6395348837209302e-05, 'loss_1': 0.017018092796206474, 'loss_2': 0.002838134765625, 'loss_3': -16.038047790527344, 'loss_4': 1.845365047454834, 'epoch': 3.62}
{'loss': 0.053, 'grad_norm': 17.49701690673828, 'learning_rate': 2.638953488372093e-05, 'loss_1': 0.04806789383292198, 'loss_2': 0.004924774169921875, 'loss_3': -15.823041915893555, 'loss_4': 1.3228882551193237, 'epoch': 3.63}
{'loss': 0.0577, 'grad_norm': 31.9216365814209, 'learning_rate': 2.6383720930232556e-05, 'loss_1': 0.057287927716970444, 'loss_2': 0.0004534721374511719, 'loss_3': -16.0604305267334, 'loss_4': 2.1170389652252197, 'epoch': 3.63}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:35:55,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:35:55,391 >>   Batch size = 64
 12%|██████████████████████████▊                                                                                                                                                                                                 | 630/5160 [15:59<1:20:03,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:36:02,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018934471532702446, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.539, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.015272513031959534, 'eval_loss_2': 0.0036619603633880615, 'eval_loss_3': -18.35495948791504, 'eval_loss_4': 1.6998182535171509, 'epoch': 3.63}
{'loss': 0.0612, 'grad_norm': 27.791175842285156, 'learning_rate': 2.6377906976744188e-05, 'loss_1': 0.05407825484871864, 'loss_2': 0.007080078125, 'loss_3': -16.21776008605957, 'loss_4': 1.6276154518127441, 'epoch': 3.64}
{'loss': 0.0288, 'grad_norm': 14.858834266662598, 'learning_rate': 2.6372093023255817e-05, 'loss_1': 0.026739148423075676, 'loss_2': 0.002033233642578125, 'loss_3': -15.895267486572266, 'loss_4': 1.7419660091400146, 'epoch': 3.65}
{'loss': 0.0666, 'grad_norm': 16.846174240112305, 'learning_rate': 2.6366279069767442e-05, 'loss_1': 0.057700805366039276, 'loss_2': 0.008880615234375, 'loss_3': -16.034664154052734, 'loss_4': 1.949540615081787, 'epoch': 3.65}
{'loss': 0.0367, 'grad_norm': 7.8121490478515625, 'learning_rate': 2.636046511627907e-05, 'loss_1': 0.026247715577483177, 'loss_2': 0.01041412353515625, 'loss_3': -15.903886795043945, 'loss_4': 2.2269668579101562, 'epoch': 3.66}
{'loss': 0.029, 'grad_norm': 10.594407081604004, 'learning_rate': 2.6354651162790696e-05, 'loss_1': 0.02721424587070942, 'loss_2': 0.001766204833984375, 'loss_3': -16.132652282714844, 'loss_4': 1.819725513458252, 'epoch': 3.66}
[INFO|trainer.py:4228] 2025-01-21 12:36:02,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:02,763 >>   Batch size = 64
 12%|███████████████████████████                                                                                                                                                                                                 | 635/5160 [16:07<1:19:46,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:36:10,314 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02107107639312744, 'eval_runtime': 3.9889, 'eval_samples_per_second': 256.715, 'eval_steps_per_second': 4.011, 'eval_loss_1': 0.01758420467376709, 'eval_loss_2': 0.0034868717193603516, 'eval_loss_3': -18.374515533447266, 'eval_loss_4': 1.6512789726257324, 'epoch': 3.66}
{'loss': 0.0808, 'grad_norm': 19.631261825561523, 'learning_rate': 2.6348837209302328e-05, 'loss_1': 0.07618774473667145, 'loss_2': 0.004581451416015625, 'loss_3': -15.956616401672363, 'loss_4': 2.768411636352539, 'epoch': 3.67}
{'loss': 0.0186, 'grad_norm': 7.6137919425964355, 'learning_rate': 2.6343023255813957e-05, 'loss_1': 0.01858142949640751, 'loss_2': 4.845857620239258e-05, 'loss_3': -16.161468505859375, 'loss_4': 1.9137976169586182, 'epoch': 3.67}
{'loss': 0.0544, 'grad_norm': 17.52716827392578, 'learning_rate': 2.6337209302325582e-05, 'loss_1': 0.05245091766119003, 'loss_2': 0.0019283294677734375, 'loss_3': -16.005863189697266, 'loss_4': 2.9123783111572266, 'epoch': 3.68}
{'loss': 0.0595, 'grad_norm': 15.183694839477539, 'learning_rate': 2.633139534883721e-05, 'loss_1': 0.05377168208360672, 'loss_2': 0.00577545166015625, 'loss_3': -15.991636276245117, 'loss_4': 1.7328193187713623, 'epoch': 3.69}
{'loss': 0.047, 'grad_norm': 18.004379272460938, 'learning_rate': 2.6325581395348836e-05, 'loss_1': 0.039391469210386276, 'loss_2': 0.00757598876953125, 'loss_3': -16.312305450439453, 'loss_4': 2.435511350631714, 'epoch': 3.69}
[INFO|trainer.py:4228] 2025-01-21 12:36:10,314 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:10,314 >>   Batch size = 64
 12%|███████████████████████████▎                                                                                                                                                                                                | 640/5160 [16:14<1:18:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:17,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026647046208381653, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01819010078907013, 'eval_loss_2': 0.008456945419311523, 'eval_loss_3': -18.375808715820312, 'eval_loss_4': 1.4504830837249756, 'epoch': 3.69}
{'loss': 0.0567, 'grad_norm': 23.598909378051758, 'learning_rate': 2.6319767441860468e-05, 'loss_1': 0.04191245883703232, 'loss_2': 0.0148162841796875, 'loss_3': -16.14917755126953, 'loss_4': 2.4120540618896484, 'epoch': 3.7}
{'loss': 0.0644, 'grad_norm': 18.855064392089844, 'learning_rate': 2.6313953488372093e-05, 'loss_1': 0.04755110293626785, 'loss_2': 0.016815185546875, 'loss_3': -16.126693725585938, 'loss_4': 1.9546430110931396, 'epoch': 3.7}
{'loss': 0.103, 'grad_norm': 20.609432220458984, 'learning_rate': 2.630813953488372e-05, 'loss_1': 0.08982142060995102, 'loss_2': 0.01314544677734375, 'loss_3': -15.679330825805664, 'loss_4': 1.2509766817092896, 'epoch': 3.71}
{'loss': 0.0546, 'grad_norm': 21.31293296813965, 'learning_rate': 2.630232558139535e-05, 'loss_1': 0.04768228530883789, 'loss_2': 0.00696563720703125, 'loss_3': -16.198022842407227, 'loss_4': 1.0231006145477295, 'epoch': 3.72}
{'loss': 0.0792, 'grad_norm': 20.790361404418945, 'learning_rate': 2.6296511627906975e-05, 'loss_1': 0.06512001156806946, 'loss_2': 0.01410675048828125, 'loss_3': -15.923197746276855, 'loss_4': 1.4270166158676147, 'epoch': 3.72}
[INFO|trainer.py:4228] 2025-01-21 12:36:17,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:17,674 >>   Batch size = 64
 12%|███████████████████████████▌                                                                                                                                                                                                | 645/5160 [16:22<1:18:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:25,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01678219437599182, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.107, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.012894905172288418, 'eval_loss_2': 0.003887288272380829, 'eval_loss_3': -18.302349090576172, 'eval_loss_4': 0.6067368984222412, 'epoch': 3.72}
{'loss': 0.033, 'grad_norm': 11.333598136901855, 'learning_rate': 2.6290697674418607e-05, 'loss_1': 0.028954122215509415, 'loss_2': 0.0040130615234375, 'loss_3': -16.05573081970215, 'loss_4': 0.5593198537826538, 'epoch': 3.73}
{'loss': 0.0134, 'grad_norm': 5.609767913818359, 'learning_rate': 2.6284883720930233e-05, 'loss_1': 0.012447013519704342, 'loss_2': 0.0009059906005859375, 'loss_3': -16.18208122253418, 'loss_4': 1.5146749019622803, 'epoch': 3.73}
{'loss': 0.0896, 'grad_norm': 32.27914810180664, 'learning_rate': 2.627906976744186e-05, 'loss_1': 0.08365115523338318, 'loss_2': 0.00591278076171875, 'loss_3': -16.072795867919922, 'loss_4': 0.7361690402030945, 'epoch': 3.74}
{'loss': 0.024, 'grad_norm': 7.422140598297119, 'learning_rate': 2.627325581395349e-05, 'loss_1': 0.02311580628156662, 'loss_2': 0.0009250640869140625, 'loss_3': -16.219482421875, 'loss_4': 0.22704800963401794, 'epoch': 3.74}
{'loss': 0.0607, 'grad_norm': 17.463577270507812, 'learning_rate': 2.6267441860465115e-05, 'loss_1': 0.06027878820896149, 'loss_2': 0.00045013427734375, 'loss_3': -16.230487823486328, 'loss_4': 0.4578791856765747, 'epoch': 3.75}
[INFO|trainer.py:4228] 2025-01-21 12:36:25,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:25,037 >>   Batch size = 64
 13%|███████████████████████████▋                                                                                                                                                                                                | 650/5160 [16:29<1:18:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:32,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016854261979460716, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.999, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.013213490135967731, 'eval_loss_2': 0.00364077091217041, 'eval_loss_3': -18.2777156829834, 'eval_loss_4': 0.1997186839580536, 'epoch': 3.75}
{'loss': 0.0293, 'grad_norm': 8.97421932220459, 'learning_rate': 2.6261627906976747e-05, 'loss_1': 0.021256187930703163, 'loss_2': 0.0080108642578125, 'loss_3': -16.090612411499023, 'loss_4': 0.5611297488212585, 'epoch': 3.76}
{'loss': 0.0246, 'grad_norm': 6.7478437423706055, 'learning_rate': 2.6255813953488372e-05, 'loss_1': 0.02205822244286537, 'loss_2': 0.002521514892578125, 'loss_3': -16.227153778076172, 'loss_4': 0.2877955734729767, 'epoch': 3.76}
{'loss': 0.0308, 'grad_norm': 11.899638175964355, 'learning_rate': 2.625e-05, 'loss_1': 0.02800258994102478, 'loss_2': 0.0028324127197265625, 'loss_3': -16.27196502685547, 'loss_4': 0.12169963866472244, 'epoch': 3.77}
{'loss': 0.0262, 'grad_norm': 7.520839691162109, 'learning_rate': 2.6244186046511626e-05, 'loss_1': 0.02259313315153122, 'loss_2': 0.0036411285400390625, 'loss_3': -16.197792053222656, 'loss_4': 0.05029955506324768, 'epoch': 3.77}
{'loss': 0.0401, 'grad_norm': 12.213794708251953, 'learning_rate': 2.6238372093023255e-05, 'loss_1': 0.039765581488609314, 'loss_2': 0.00034999847412109375, 'loss_3': -16.142778396606445, 'loss_4': 0.045989006757736206, 'epoch': 3.78}
[INFO|trainer.py:4228] 2025-01-21 12:36:32,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:32,395 >>   Batch size = 64
 13%|███████████████████████████▉                                                                                                                                                                                                | 655/5160 [16:36<1:18:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:39,774 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02251584455370903, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.043, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.01413489505648613, 'eval_loss_2': 0.0083809494972229, 'eval_loss_3': -18.245132446289062, 'eval_loss_4': 0.11842748522758484, 'epoch': 3.78}
{'loss': 0.0416, 'grad_norm': 12.457077980041504, 'learning_rate': 2.6232558139534887e-05, 'loss_1': 0.03227105364203453, 'loss_2': 0.009368896484375, 'loss_3': -16.001785278320312, 'loss_4': 0.25472795963287354, 'epoch': 3.78}
{'loss': 0.0428, 'grad_norm': 15.19381046295166, 'learning_rate': 2.6226744186046512e-05, 'loss_1': 0.03247859701514244, 'loss_2': 0.010345458984375, 'loss_3': -16.015625, 'loss_4': 0.2700461149215698, 'epoch': 3.79}
{'loss': 0.0268, 'grad_norm': 10.429716110229492, 'learning_rate': 2.622093023255814e-05, 'loss_1': 0.023976746946573257, 'loss_2': 0.002872467041015625, 'loss_3': -16.030353546142578, 'loss_4': -0.1464913785457611, 'epoch': 3.8}
{'loss': 0.0277, 'grad_norm': 6.882566928863525, 'learning_rate': 2.6215116279069766e-05, 'loss_1': 0.015695692971348763, 'loss_2': 0.01202392578125, 'loss_3': -16.138437271118164, 'loss_4': -0.07131284475326538, 'epoch': 3.8}
{'loss': 0.0389, 'grad_norm': 8.83679485321045, 'learning_rate': 2.6209302325581395e-05, 'loss_1': 0.031499478965997696, 'loss_2': 0.0073699951171875, 'loss_3': -15.951593399047852, 'loss_4': -0.21477457880973816, 'epoch': 3.81}
[INFO|trainer.py:4228] 2025-01-21 12:36:39,774 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:39,774 >>   Batch size = 64
 13%|████████████████████████████▏                                                                                                                                                                                               | 660/5160 [16:44<1:18:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:47,142 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017990436404943466, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.444, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.013753438368439674, 'eval_loss_2': 0.004236996173858643, 'eval_loss_3': -18.250682830810547, 'eval_loss_4': -0.06688223779201508, 'epoch': 3.81}
{'loss': 0.0271, 'grad_norm': 7.1090803146362305, 'learning_rate': 2.6203488372093027e-05, 'loss_1': 0.02114744856953621, 'loss_2': 0.0059967041015625, 'loss_3': -16.06694793701172, 'loss_4': -0.004902541637420654, 'epoch': 3.81}
{'loss': 0.0261, 'grad_norm': 12.862776756286621, 'learning_rate': 2.6197674418604652e-05, 'loss_1': 0.025820406153798103, 'loss_2': 0.00030612945556640625, 'loss_3': -15.885719299316406, 'loss_4': -0.005570009350776672, 'epoch': 3.82}
{'loss': 0.042, 'grad_norm': 16.138647079467773, 'learning_rate': 2.619186046511628e-05, 'loss_1': 0.0393763929605484, 'loss_2': 0.002643585205078125, 'loss_3': -15.858917236328125, 'loss_4': 0.20025956630706787, 'epoch': 3.83}
{'loss': 0.0315, 'grad_norm': 7.419932842254639, 'learning_rate': 2.6186046511627906e-05, 'loss_1': 0.018767334520816803, 'loss_2': 0.01268768310546875, 'loss_3': -15.937021255493164, 'loss_4': -0.13613292574882507, 'epoch': 3.83}
{'loss': 0.049, 'grad_norm': 12.401357650756836, 'learning_rate': 2.6180232558139535e-05, 'loss_1': 0.02782064862549305, 'loss_2': 0.021148681640625, 'loss_3': -15.86636734008789, 'loss_4': -0.06848590075969696, 'epoch': 3.84}
[INFO|trainer.py:4228] 2025-01-21 12:36:47,142 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:47,142 >>   Batch size = 64
 13%|████████████████████████████▎                                                                                                                                                                                               | 665/5160 [16:51<1:18:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:36:54,515 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03170349448919296, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.742, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.013308546505868435, 'eval_loss_2': 0.018394947052001953, 'eval_loss_3': -18.239864349365234, 'eval_loss_4': 0.09823622554540634, 'epoch': 3.84}
{'loss': 0.0601, 'grad_norm': 13.724534034729004, 'learning_rate': 2.6174418604651163e-05, 'loss_1': 0.03853481262922287, 'loss_2': 0.0215606689453125, 'loss_3': -16.006484985351562, 'loss_4': -0.23913070559501648, 'epoch': 3.84}
{'loss': 0.0322, 'grad_norm': 7.469205379486084, 'learning_rate': 2.6168604651162792e-05, 'loss_1': 0.016218269243836403, 'loss_2': 0.016021728515625, 'loss_3': -16.017547607421875, 'loss_4': 0.32053041458129883, 'epoch': 3.85}
{'loss': 0.0292, 'grad_norm': 4.927254676818848, 'learning_rate': 2.616279069767442e-05, 'loss_1': 0.009951593354344368, 'loss_2': 0.019287109375, 'loss_3': -16.0738468170166, 'loss_4': 0.31127721071243286, 'epoch': 3.85}
{'loss': 0.0428, 'grad_norm': 9.601256370544434, 'learning_rate': 2.6156976744186046e-05, 'loss_1': 0.02736884541809559, 'loss_2': 0.015411376953125, 'loss_3': -15.921881675720215, 'loss_4': 0.5122599601745605, 'epoch': 3.86}
{'loss': 0.0507, 'grad_norm': 16.6904296875, 'learning_rate': 2.6151162790697674e-05, 'loss_1': 0.03655075281858444, 'loss_2': 0.01416015625, 'loss_3': -16.011287689208984, 'loss_4': 0.6841121912002563, 'epoch': 3.87}
[INFO|trainer.py:4228] 2025-01-21 12:36:54,516 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:36:54,516 >>   Batch size = 64
 13%|████████████████████████████▌                                                                                                                                                                                               | 670/5160 [16:59<1:17:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:01,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020617254078388214, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.56, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011035272851586342, 'eval_loss_2': 0.009581983089447021, 'eval_loss_3': -18.23907470703125, 'eval_loss_4': 0.16563642024993896, 'epoch': 3.87}
{'loss': 0.0402, 'grad_norm': 18.01395034790039, 'learning_rate': 2.6145348837209303e-05, 'loss_1': 0.0379287451505661, 'loss_2': 0.002300262451171875, 'loss_3': -15.83236026763916, 'loss_4': 0.5504879951477051, 'epoch': 3.87}
{'loss': 0.0202, 'grad_norm': 7.5856804847717285, 'learning_rate': 2.613953488372093e-05, 'loss_1': 0.020049843937158585, 'loss_2': 0.0001347064971923828, 'loss_3': -16.088558197021484, 'loss_4': 0.31877997517585754, 'epoch': 3.88}
{'loss': 0.0309, 'grad_norm': 9.756071090698242, 'learning_rate': 2.613372093023256e-05, 'loss_1': 0.026682892814278603, 'loss_2': 0.00418853759765625, 'loss_3': -16.174854278564453, 'loss_4': 0.21013958752155304, 'epoch': 3.88}
{'loss': 0.0268, 'grad_norm': 10.163406372070312, 'learning_rate': 2.6127906976744185e-05, 'loss_1': 0.02278214320540428, 'loss_2': 0.004024505615234375, 'loss_3': -16.118160247802734, 'loss_4': 0.3181389570236206, 'epoch': 3.89}
{'loss': 0.0508, 'grad_norm': 19.716501235961914, 'learning_rate': 2.6122093023255814e-05, 'loss_1': 0.044559989124536514, 'loss_2': 0.00626373291015625, 'loss_3': -15.97164249420166, 'loss_4': 0.5326452255249023, 'epoch': 3.9}
[INFO|trainer.py:4228] 2025-01-21 12:37:01,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:01,886 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:06<1:17:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:09,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016013458371162415, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.645, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010301545262336731, 'eval_loss_2': 0.005711913108825684, 'eval_loss_3': -18.240522384643555, 'eval_loss_4': 0.19884222745895386, 'epoch': 3.9}
{'loss': 0.0629, 'grad_norm': 21.845666885375977, 'learning_rate': 2.6116279069767443e-05, 'loss_1': 0.05838540941476822, 'loss_2': 0.00449371337890625, 'loss_3': -15.881102561950684, 'loss_4': 0.5596269965171814, 'epoch': 3.9}
{'loss': 0.0435, 'grad_norm': 14.333511352539062, 'learning_rate': 2.611046511627907e-05, 'loss_1': 0.028245391324162483, 'loss_2': 0.01520538330078125, 'loss_3': -15.957712173461914, 'loss_4': 0.18785330653190613, 'epoch': 3.91}
{'loss': 0.0352, 'grad_norm': 9.589410781860352, 'learning_rate': 2.6104651162790697e-05, 'loss_1': 0.02506064623594284, 'loss_2': 0.01015472412109375, 'loss_3': -16.098796844482422, 'loss_4': 0.09006129205226898, 'epoch': 3.91}
{'loss': 0.0233, 'grad_norm': 6.5732831954956055, 'learning_rate': 2.6098837209302325e-05, 'loss_1': 0.016225222498178482, 'loss_2': 0.00705718994140625, 'loss_3': -16.017654418945312, 'loss_4': 0.13279496133327484, 'epoch': 3.92}
{'loss': 0.0155, 'grad_norm': 6.305502891540527, 'learning_rate': 2.6093023255813954e-05, 'loss_1': 0.01528109796345234, 'loss_2': 0.00021719932556152344, 'loss_3': -16.019893646240234, 'loss_4': 0.22052983939647675, 'epoch': 3.92}
[INFO|trainer.py:4228] 2025-01-21 12:37:09,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:09,251 >>   Batch size = 64
 13%|████████████████████████████▊                                                                                                                                                                                               | 675/5160 [17:10<1:17:46,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:37:13,063 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-675
[INFO|configuration_utils.py:420] 2025-01-21 12:37:13,064 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-675/config.json                                                                             
{'eval_loss': 0.013971608132123947, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.67, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010132307186722755, 'eval_loss_2': 0.0038392990827560425, 'eval_loss_3': -18.20686149597168, 'eval_loss_4': 0.4220574200153351, 'epoch': 3.92}
[INFO|modeling_utils.py:2988] 2025-01-21 12:37:13,560 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-675/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:37:13,561 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-675/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:37:13,562 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-675/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:37:14,508 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-620] due to args.save_total_limit
 13%|████████████████████████████▉                                                                                                                                                                                               | 680/5160 [17:15<1:25:58,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:37:18,159 >>
{'loss': 0.0345, 'grad_norm': 11.264820098876953, 'learning_rate': 2.6087209302325582e-05, 'loss_1': 0.03162485733628273, 'loss_2': 0.0028896331787109375, 'loss_3': -15.890328407287598, 'loss_4': 0.5648821592330933, 'epoch': 3.93}
{'loss': 0.0515, 'grad_norm': 23.897029876708984, 'learning_rate': 2.608139534883721e-05, 'loss_1': 0.045780736953020096, 'loss_2': 0.005725860595703125, 'loss_3': -15.886590957641602, 'loss_4': 0.6627888679504395, 'epoch': 3.94}
{'loss': 0.0339, 'grad_norm': 10.736742973327637, 'learning_rate': 2.6075581395348836e-05, 'loss_1': 0.0308595672249794, 'loss_2': 0.003025054931640625, 'loss_3': -16.036518096923828, 'loss_4': 0.33418479561805725, 'epoch': 3.94}
{'loss': 0.0323, 'grad_norm': 18.042987823486328, 'learning_rate': 2.6069767441860465e-05, 'loss_1': 0.02556493692100048, 'loss_2': 0.0067138671875, 'loss_3': -15.959848403930664, 'loss_4': 0.328646719455719, 'epoch': 3.95}
{'loss': 0.026, 'grad_norm': 10.00505256652832, 'learning_rate': 2.6063953488372094e-05, 'loss_1': 0.019794248044490814, 'loss_2': 0.006206512451171875, 'loss_3': -16.05379867553711, 'loss_4': 1.4030511379241943, 'epoch': 3.95}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:37:18,159 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:18,159 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:22<1:19:03,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:37:25,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016606278717517853, 'eval_runtime': 3.8181, 'eval_samples_per_second': 268.194, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.009883174672722816, 'eval_loss_2': 0.0067231059074401855, 'eval_loss_3': -18.184066772460938, 'eval_loss_4': 0.8398823738098145, 'epoch': 3.95}
{'loss': 0.0682, 'grad_norm': 18.139347076416016, 'learning_rate': 2.6058139534883722e-05, 'loss_1': 0.06521886587142944, 'loss_2': 0.003025054931640625, 'loss_3': -16.0024356842041, 'loss_4': 1.1017131805419922, 'epoch': 3.96}
{'loss': 0.0291, 'grad_norm': 13.132183074951172, 'learning_rate': 2.605232558139535e-05, 'loss_1': 0.026336833834648132, 'loss_2': 0.00274658203125, 'loss_3': -15.701286315917969, 'loss_4': 0.6559971570968628, 'epoch': 3.97}
{'loss': 0.0146, 'grad_norm': 5.968669891357422, 'learning_rate': 2.6046511627906976e-05, 'loss_1': 0.013384150341153145, 'loss_2': 0.0012350082397460938, 'loss_3': -15.978771209716797, 'loss_4': 0.7433037161827087, 'epoch': 3.97}
{'loss': 0.0298, 'grad_norm': 12.057379722595215, 'learning_rate': 2.6040697674418605e-05, 'loss_1': 0.027469154447317123, 'loss_2': 0.002361297607421875, 'loss_3': -16.090940475463867, 'loss_4': 1.3004828691482544, 'epoch': 3.98}
{'loss': 0.0141, 'grad_norm': 5.011316299438477, 'learning_rate': 2.6034883720930233e-05, 'loss_1': 0.013325036503374577, 'loss_2': 0.000782012939453125, 'loss_3': -15.919888496398926, 'loss_4': 1.355377435684204, 'epoch': 3.98}
[INFO|trainer.py:4228] 2025-01-21 12:37:25,534 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:25,534 >>   Batch size = 64
 13%|█████████████████████████████▏                                                                                                                                                                                              | 685/5160 [17:26<1:19:03,  1.06s/it][INFO|trainer.py:3910] 2025-01-21 12:37:29,343 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-685
[INFO|configuration_utils.py:420] 2025-01-21 12:37:29,344 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-685/config.json                                                                             
{'eval_loss': 0.011780654080212116, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009398412890732288, 'eval_loss_2': 0.002382241189479828, 'eval_loss_3': -18.234498977661133, 'eval_loss_4': 1.167948603630066, 'epoch': 3.98}
[INFO|modeling_utils.py:2988] 2025-01-21 12:37:29,848 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-685/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:37:29,849 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-685/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:37:29,849 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-685/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:37:30,779 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-675] due to args.save_total_limit
 13%|█████████████████████████████▍                                                                                                                                                                                              | 690/5160 [17:31<1:22:43,  1.11s/it][INFO|trainer.py:4226] 2025-01-21 12:37:34,105 >>
{'loss': 0.0333, 'grad_norm': 15.094134330749512, 'learning_rate': 2.6029069767441862e-05, 'loss_1': 0.027912640944123268, 'loss_2': 0.00540924072265625, 'loss_3': -15.920498847961426, 'loss_4': 1.2583894729614258, 'epoch': 3.99}
{'loss': 0.0205, 'grad_norm': 6.014854907989502, 'learning_rate': 2.602325581395349e-05, 'loss_1': 0.012925907969474792, 'loss_2': 0.007610321044921875, 'loss_3': -16.039031982421875, 'loss_4': 1.5917835235595703, 'epoch': 3.99}
{'loss': 0.0114, 'grad_norm': 7.8769121170043945, 'learning_rate': 2.6017441860465116e-05, 'loss_1': 0.007034078240394592, 'loss_2': 0.00432586669921875, 'loss_3': -15.543837547302246, 'loss_4': 1.7029892206192017, 'epoch': 4.0}
{'loss': 0.0196, 'grad_norm': 7.762902736663818, 'learning_rate': 2.6011627906976745e-05, 'loss_1': 0.017650486901402473, 'loss_2': 0.00194549560546875, 'loss_3': -15.947978973388672, 'loss_4': 1.1582672595977783, 'epoch': 4.01}
{'loss': 0.0363, 'grad_norm': 9.504637718200684, 'learning_rate': 2.6005813953488373e-05, 'loss_1': 0.03554642200469971, 'loss_2': 0.0007634162902832031, 'loss_3': -15.94168758392334, 'loss_4': 1.1326467990875244, 'epoch': 4.01}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:37:34,105 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:34,105 >>   Batch size = 64
 13%|█████████████████████████████▋                                                                                                                                                                                              | 695/5160 [17:38<1:18:19,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:37:41,469 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013877593912184238, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.076, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00853666104376316, 'eval_loss_2': 0.005340933799743652, 'eval_loss_3': -18.326126098632812, 'eval_loss_4': 1.2125643491744995, 'epoch': 4.01}
{'loss': 0.0241, 'grad_norm': 7.685820579528809, 'learning_rate': 2.6000000000000002e-05, 'loss_1': 0.022633571177721024, 'loss_2': 0.0014743804931640625, 'loss_3': -15.806059837341309, 'loss_4': 1.6298270225524902, 'epoch': 4.02}
{'loss': 0.0194, 'grad_norm': 7.887890815734863, 'learning_rate': 2.599418604651163e-05, 'loss_1': 0.015579801052808762, 'loss_2': 0.003826141357421875, 'loss_3': -15.940701484680176, 'loss_4': 1.2191451787948608, 'epoch': 4.02}
{'loss': 0.028, 'grad_norm': 6.480352878570557, 'learning_rate': 2.5988372093023256e-05, 'loss_1': 0.015110856853425503, 'loss_2': 0.0128631591796875, 'loss_3': -16.048812866210938, 'loss_4': 1.3633246421813965, 'epoch': 4.03}
{'loss': 0.0756, 'grad_norm': 18.913780212402344, 'learning_rate': 2.5982558139534884e-05, 'loss_1': 0.07370463758707047, 'loss_2': 0.001873016357421875, 'loss_3': -16.056856155395508, 'loss_4': 1.7843327522277832, 'epoch': 4.03}
{'loss': 0.031, 'grad_norm': 11.047039985656738, 'learning_rate': 2.5976744186046513e-05, 'loss_1': 0.023442069068551064, 'loss_2': 0.007598876953125, 'loss_3': -16.005168914794922, 'loss_4': 1.4194331169128418, 'epoch': 4.04}
[INFO|trainer.py:4228] 2025-01-21 12:37:41,469 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:41,469 >>   Batch size = 64
 14%|█████████████████████████████▊                                                                                                                                                                                              | 700/5160 [17:45<1:17:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:48,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01880975440144539, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.766, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010659775696694851, 'eval_loss_2': 0.008149981498718262, 'eval_loss_3': -18.334949493408203, 'eval_loss_4': 1.2174066305160522, 'epoch': 4.04}
{'loss': 0.0243, 'grad_norm': 9.4471435546875, 'learning_rate': 2.597093023255814e-05, 'loss_1': 0.019655369222164154, 'loss_2': 0.00461578369140625, 'loss_3': -15.77872371673584, 'loss_4': 1.5500216484069824, 'epoch': 4.05}
{'loss': 0.076, 'grad_norm': 30.768360137939453, 'learning_rate': 2.5965116279069767e-05, 'loss_1': 0.0662531852722168, 'loss_2': 0.00974273681640625, 'loss_3': -15.963462829589844, 'loss_4': 1.9286551475524902, 'epoch': 4.05}
{'loss': 0.0266, 'grad_norm': 6.932571887969971, 'learning_rate': 2.5959302325581395e-05, 'loss_1': 0.024425704032182693, 'loss_2': 0.0022125244140625, 'loss_3': -16.022872924804688, 'loss_4': 1.0559672117233276, 'epoch': 4.06}
{'loss': 0.0269, 'grad_norm': 9.79875659942627, 'learning_rate': 2.5953488372093024e-05, 'loss_1': 0.024575481191277504, 'loss_2': 0.002315521240234375, 'loss_3': -16.038618087768555, 'loss_4': 1.2704925537109375, 'epoch': 4.06}
{'loss': 0.0276, 'grad_norm': 8.09071159362793, 'learning_rate': 2.5947674418604653e-05, 'loss_1': 0.022758740931749344, 'loss_2': 0.0048675537109375, 'loss_3': -16.109506607055664, 'loss_4': 0.6983374357223511, 'epoch': 4.07}
[INFO|trainer.py:4228] 2025-01-21 12:37:48,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:48,839 >>   Batch size = 64
 14%|██████████████████████████████                                                                                                                                                                                              | 705/5160 [17:53<1:17:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:37:56,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01295253075659275, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010147863999009132, 'eval_loss_2': 0.002804666757583618, 'eval_loss_3': -18.344894409179688, 'eval_loss_4': 0.8284876942634583, 'epoch': 4.07}
{'loss': 0.015, 'grad_norm': 5.185369968414307, 'learning_rate': 2.594186046511628e-05, 'loss_1': 0.010521329939365387, 'loss_2': 0.00447845458984375, 'loss_3': -16.089494705200195, 'loss_4': 1.3840508460998535, 'epoch': 4.08}
{'loss': 0.0222, 'grad_norm': 6.430498123168945, 'learning_rate': 2.5936046511627907e-05, 'loss_1': 0.016457973048090935, 'loss_2': 0.00569915771484375, 'loss_3': -16.187305450439453, 'loss_4': 0.8275570273399353, 'epoch': 4.08}
{'loss': 0.0218, 'grad_norm': 6.303732872009277, 'learning_rate': 2.5930232558139535e-05, 'loss_1': 0.015574777498841286, 'loss_2': 0.006175994873046875, 'loss_3': -16.01595115661621, 'loss_4': 0.9712026119232178, 'epoch': 4.09}
{'loss': 0.0267, 'grad_norm': 8.106541633605957, 'learning_rate': 2.5924418604651164e-05, 'loss_1': 0.019731666892766953, 'loss_2': 0.00695037841796875, 'loss_3': -15.992225646972656, 'loss_4': 0.8426339626312256, 'epoch': 4.09}
{'loss': 0.0142, 'grad_norm': 6.832472324371338, 'learning_rate': 2.5918604651162792e-05, 'loss_1': 0.009968835860490799, 'loss_2': 0.0042572021484375, 'loss_3': -16.197572708129883, 'loss_4': 0.09309088438749313, 'epoch': 4.1}
[INFO|trainer.py:4228] 2025-01-21 12:37:56,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:37:56,206 >>   Batch size = 64
 14%|██████████████████████████████▎                                                                                                                                                                                             | 710/5160 [18:00<1:17:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:03,582 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01289354171603918, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.245, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.009713560342788696, 'eval_loss_2': 0.003179982304573059, 'eval_loss_3': -18.351097106933594, 'eval_loss_4': 0.38759738206863403, 'epoch': 4.1}
{'loss': 0.0259, 'grad_norm': 7.549890995025635, 'learning_rate': 2.591279069767442e-05, 'loss_1': 0.01860532909631729, 'loss_2': 0.007293701171875, 'loss_3': -15.958122253417969, 'loss_4': 0.3717976212501526, 'epoch': 4.1}
{'loss': 0.046, 'grad_norm': 12.823348045349121, 'learning_rate': 2.5906976744186046e-05, 'loss_1': 0.04142061248421669, 'loss_2': 0.00453948974609375, 'loss_3': -16.054874420166016, 'loss_4': 0.9414191246032715, 'epoch': 4.11}
{'loss': 0.0551, 'grad_norm': 15.261247634887695, 'learning_rate': 2.5901162790697675e-05, 'loss_1': 0.04551083222031593, 'loss_2': 0.009613037109375, 'loss_3': -16.26622200012207, 'loss_4': 1.0452560186386108, 'epoch': 4.12}
{'loss': 0.0328, 'grad_norm': 9.448565483093262, 'learning_rate': 2.58953488372093e-05, 'loss_1': 0.02325303666293621, 'loss_2': 0.00957489013671875, 'loss_3': -16.124523162841797, 'loss_4': -0.07407788187265396, 'epoch': 4.12}
{'loss': 0.0846, 'grad_norm': 18.15401268005371, 'learning_rate': 2.5889534883720932e-05, 'loss_1': 0.06969793885946274, 'loss_2': 0.014862060546875, 'loss_3': -16.235029220581055, 'loss_4': 0.8333629369735718, 'epoch': 4.13}
[INFO|trainer.py:4228] 2025-01-21 12:38:03,582 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:03,582 >>   Batch size = 64
 14%|██████████████████████████████▍                                                                                                                                                                                             | 715/5160 [18:08<1:17:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:10,942 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022298388183116913, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.206, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010219627059996128, 'eval_loss_2': 0.01207876205444336, 'eval_loss_3': -18.340181350708008, 'eval_loss_4': 0.09257018566131592, 'epoch': 4.13}
{'loss': 0.0329, 'grad_norm': 8.671914100646973, 'learning_rate': 2.588372093023256e-05, 'loss_1': 0.024273667484521866, 'loss_2': 0.008636474609375, 'loss_3': -16.06830596923828, 'loss_4': -0.09389092028141022, 'epoch': 4.13}
{'loss': 0.1016, 'grad_norm': 36.00327682495117, 'learning_rate': 2.5877906976744186e-05, 'loss_1': 0.08936428278684616, 'loss_2': 0.01220703125, 'loss_3': -16.000967025756836, 'loss_4': 0.36239320039749146, 'epoch': 4.14}
{'loss': 0.02, 'grad_norm': 6.509768486022949, 'learning_rate': 2.5872093023255815e-05, 'loss_1': 0.014581175521016121, 'loss_2': 0.005401611328125, 'loss_3': -16.109420776367188, 'loss_4': -0.28237390518188477, 'epoch': 4.15}
{'loss': 0.0147, 'grad_norm': 5.366913318634033, 'learning_rate': 2.586627906976744e-05, 'loss_1': 0.011284205131232738, 'loss_2': 0.00342559814453125, 'loss_3': -16.113750457763672, 'loss_4': 0.315658301115036, 'epoch': 4.15}
{'loss': 0.0269, 'grad_norm': 14.281444549560547, 'learning_rate': 2.5860465116279072e-05, 'loss_1': 0.021482883021235466, 'loss_2': 0.005420684814453125, 'loss_3': -16.14671516418457, 'loss_4': -0.8190698623657227, 'epoch': 4.16}
[INFO|trainer.py:4228] 2025-01-21 12:38:10,942 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:10,942 >>   Batch size = 64
 14%|██████████████████████████████▋                                                                                                                                                                                             | 720/5160 [18:15<1:16:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:18,302 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013711513951420784, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.892, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010537068359553814, 'eval_loss_2': 0.0031744465231895447, 'eval_loss_3': -18.318870544433594, 'eval_loss_4': -0.3835444450378418, 'epoch': 4.16}
{'loss': 0.0186, 'grad_norm': 7.291057109832764, 'learning_rate': 2.5854651162790697e-05, 'loss_1': 0.01657908596098423, 'loss_2': 0.00202178955078125, 'loss_3': -16.137392044067383, 'loss_4': -0.45081838965415955, 'epoch': 4.16}
{'loss': 0.0161, 'grad_norm': 5.699477672576904, 'learning_rate': 2.5848837209302326e-05, 'loss_1': 0.01109451986849308, 'loss_2': 0.00498199462890625, 'loss_3': -16.00728988647461, 'loss_4': -0.30963751673698425, 'epoch': 4.17}
{'loss': 0.0496, 'grad_norm': 19.265047073364258, 'learning_rate': 2.5843023255813955e-05, 'loss_1': 0.0399135947227478, 'loss_2': 0.0097198486328125, 'loss_3': -16.20038414001465, 'loss_4': -0.7454255223274231, 'epoch': 4.17}
{'loss': 0.033, 'grad_norm': 8.327593803405762, 'learning_rate': 2.583720930232558e-05, 'loss_1': 0.018209410831332207, 'loss_2': 0.01483917236328125, 'loss_3': -16.215349197387695, 'loss_4': -0.09764871001243591, 'epoch': 4.18}
{'loss': 0.0308, 'grad_norm': 7.596287250518799, 'learning_rate': 2.5831395348837212e-05, 'loss_1': 0.01787061244249344, 'loss_2': 0.01290130615234375, 'loss_3': -16.101667404174805, 'loss_4': -0.33621323108673096, 'epoch': 4.19}
[INFO|trainer.py:4228] 2025-01-21 12:38:18,302 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:18,302 >>   Batch size = 64
 14%|██████████████████████████████▉                                                                                                                                                                                             | 725/5160 [18:22<1:16:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:25,664 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0230125542730093, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.052, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011644398793578148, 'eval_loss_2': 0.011368155479431152, 'eval_loss_3': -18.223970413208008, 'eval_loss_4': -0.5258402824401855, 'epoch': 4.19}
{'loss': 0.0434, 'grad_norm': 11.664036750793457, 'learning_rate': 2.5825581395348837e-05, 'loss_1': 0.0323098823428154, 'loss_2': 0.01105499267578125, 'loss_3': -16.07355308532715, 'loss_4': -0.8690789341926575, 'epoch': 4.19}
{'loss': 0.0242, 'grad_norm': 7.9753007888793945, 'learning_rate': 2.5819767441860466e-05, 'loss_1': 0.020345449447631836, 'loss_2': 0.00380706787109375, 'loss_3': -15.829644203186035, 'loss_4': -0.8450194001197815, 'epoch': 4.2}
{'loss': 0.0193, 'grad_norm': 6.559108257293701, 'learning_rate': 2.5813953488372094e-05, 'loss_1': 0.010260014794766903, 'loss_2': 0.0090789794921875, 'loss_3': -16.146114349365234, 'loss_4': -0.5981465578079224, 'epoch': 4.2}
{'loss': 0.0406, 'grad_norm': 11.665491104125977, 'learning_rate': 2.580813953488372e-05, 'loss_1': 0.030439255759119987, 'loss_2': 0.010162353515625, 'loss_3': -15.987241744995117, 'loss_4': -0.2762327790260315, 'epoch': 4.21}
{'loss': 0.0228, 'grad_norm': 8.063958168029785, 'learning_rate': 2.580232558139535e-05, 'loss_1': 0.015925820916891098, 'loss_2': 0.00685882568359375, 'loss_3': -16.104921340942383, 'loss_4': -0.3103398084640503, 'epoch': 4.22}
[INFO|trainer.py:4228] 2025-01-21 12:38:25,664 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:25,665 >>   Batch size = 64
 14%|███████████████████████████████                                                                                                                                                                                             | 730/5160 [18:30<1:16:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:33,027 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02198689617216587, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.726, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01440658699721098, 'eval_loss_2': 0.007580310106277466, 'eval_loss_3': -18.171199798583984, 'eval_loss_4': -0.3704017996788025, 'epoch': 4.22}
{'loss': 0.0124, 'grad_norm': 6.008430004119873, 'learning_rate': 2.5796511627906977e-05, 'loss_1': 0.012219403870403767, 'loss_2': 0.00019693374633789062, 'loss_3': -16.26337432861328, 'loss_4': -0.19965025782585144, 'epoch': 4.22}
{'loss': 0.0249, 'grad_norm': 7.3777618408203125, 'learning_rate': 2.5790697674418605e-05, 'loss_1': 0.01257703173905611, 'loss_2': 0.012298583984375, 'loss_3': -15.974328994750977, 'loss_4': -0.1443328559398651, 'epoch': 4.23}
{'loss': 0.0219, 'grad_norm': 10.175149917602539, 'learning_rate': 2.578488372093023e-05, 'loss_1': 0.017718913033604622, 'loss_2': 0.004131317138671875, 'loss_3': -15.963521957397461, 'loss_4': -0.38429611921310425, 'epoch': 4.23}
{'loss': 0.039, 'grad_norm': 7.966097831726074, 'learning_rate': 2.577906976744186e-05, 'loss_1': 0.014804799109697342, 'loss_2': 0.0241851806640625, 'loss_3': -15.929838180541992, 'loss_4': -0.12328342348337173, 'epoch': 4.24}
{'loss': 0.0313, 'grad_norm': 8.917465209960938, 'learning_rate': 2.577325581395349e-05, 'loss_1': 0.016289088875055313, 'loss_2': 0.0149688720703125, 'loss_3': -15.937105178833008, 'loss_4': -0.3312242329120636, 'epoch': 4.24}
[INFO|trainer.py:4228] 2025-01-21 12:38:33,027 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:33,027 >>   Batch size = 64
 14%|███████████████████████████████▎                                                                                                                                                                                            | 735/5160 [18:37<1:16:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:40,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022076880559325218, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.264, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.016077734529972076, 'eval_loss_2': 0.005999147891998291, 'eval_loss_3': -18.078046798706055, 'eval_loss_4': -0.17803920805454254, 'epoch': 4.24}
{'loss': 0.0378, 'grad_norm': 20.054391860961914, 'learning_rate': 2.5767441860465117e-05, 'loss_1': 0.029144752770662308, 'loss_2': 0.00862884521484375, 'loss_3': -15.653216361999512, 'loss_4': -0.12161852419376373, 'epoch': 4.25}
{'loss': 0.0191, 'grad_norm': 7.320940971374512, 'learning_rate': 2.5761627906976745e-05, 'loss_1': 0.013980264775454998, 'loss_2': 0.005126953125, 'loss_3': -15.655706405639648, 'loss_4': -0.3010205626487732, 'epoch': 4.26}
{'loss': 0.0139, 'grad_norm': 5.836244106292725, 'learning_rate': 2.575581395348837e-05, 'loss_1': 0.011392401531338692, 'loss_2': 0.00254058837890625, 'loss_3': -15.785433769226074, 'loss_4': 0.3082161843776703, 'epoch': 4.26}
{'loss': 0.0221, 'grad_norm': 6.837056636810303, 'learning_rate': 2.575e-05, 'loss_1': 0.01889873668551445, 'loss_2': 0.003204345703125, 'loss_3': -15.817468643188477, 'loss_4': -0.21372437477111816, 'epoch': 4.27}
{'loss': 0.0094, 'grad_norm': 4.964352607727051, 'learning_rate': 2.574418604651163e-05, 'loss_1': 0.00684755016118288, 'loss_2': 0.0025787353515625, 'loss_3': -15.963214874267578, 'loss_4': -0.5618956685066223, 'epoch': 4.27}
[INFO|trainer.py:4228] 2025-01-21 12:38:40,401 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:40,401 >>   Batch size = 64
 14%|███████████████████████████████▌                                                                                                                                                                                            | 740/5160 [18:44<1:16:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:47,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022146355360746384, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.17, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.015212665311992168, 'eval_loss_2': 0.006933689117431641, 'eval_loss_3': -18.0706844329834, 'eval_loss_4': 0.018303774297237396, 'epoch': 4.27}
{'loss': 0.0403, 'grad_norm': 12.795884132385254, 'learning_rate': 2.5738372093023256e-05, 'loss_1': 0.03653893992304802, 'loss_2': 0.0038051605224609375, 'loss_3': -15.96142578125, 'loss_4': 0.04670324921607971, 'epoch': 4.28}
{'loss': 0.0248, 'grad_norm': 5.483896255493164, 'learning_rate': 2.5732558139534885e-05, 'loss_1': 0.010803265497088432, 'loss_2': 0.0139617919921875, 'loss_3': -15.870134353637695, 'loss_4': 0.23966094851493835, 'epoch': 4.28}
{'loss': 0.0288, 'grad_norm': 10.874077796936035, 'learning_rate': 2.572674418604651e-05, 'loss_1': 0.024129942059516907, 'loss_2': 0.0046539306640625, 'loss_3': -15.65127182006836, 'loss_4': 0.2748974859714508, 'epoch': 4.29}
{'loss': 0.0354, 'grad_norm': 18.44724464416504, 'learning_rate': 2.572093023255814e-05, 'loss_1': 0.02859257534146309, 'loss_2': 0.00682830810546875, 'loss_3': -15.88734245300293, 'loss_4': -0.06134168803691864, 'epoch': 4.3}
{'loss': 0.0137, 'grad_norm': 5.428335666656494, 'learning_rate': 2.5715116279069768e-05, 'loss_1': 0.009160913527011871, 'loss_2': 0.004528045654296875, 'loss_3': -16.032001495361328, 'loss_4': 0.23257410526275635, 'epoch': 4.3}
[INFO|trainer.py:4228] 2025-01-21 12:38:47,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:47,771 >>   Batch size = 64
 14%|███████████████████████████████▊                                                                                                                                                                                            | 745/5160 [18:52<1:16:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:38:55,129 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01617792807519436, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.634, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011937026865780354, 'eval_loss_2': 0.004240900278091431, 'eval_loss_3': -18.074678421020508, 'eval_loss_4': 0.16329973936080933, 'epoch': 4.3}
{'loss': 0.0185, 'grad_norm': 8.705467224121094, 'learning_rate': 2.5709302325581396e-05, 'loss_1': 0.015998883172869682, 'loss_2': 0.0025310516357421875, 'loss_3': -15.955829620361328, 'loss_4': 0.22099581360816956, 'epoch': 4.31}
{'loss': 0.0236, 'grad_norm': 10.595917701721191, 'learning_rate': 2.5703488372093025e-05, 'loss_1': 0.020661428570747375, 'loss_2': 0.002964019775390625, 'loss_3': -15.694225311279297, 'loss_4': 0.27624279260635376, 'epoch': 4.31}
{'loss': 0.0136, 'grad_norm': 7.854106903076172, 'learning_rate': 2.569767441860465e-05, 'loss_1': 0.013310663402080536, 'loss_2': 0.0002589225769042969, 'loss_3': -15.690788269042969, 'loss_4': -0.24358054995536804, 'epoch': 4.32}
{'loss': 0.0291, 'grad_norm': 9.973420143127441, 'learning_rate': 2.569186046511628e-05, 'loss_1': 0.023678019642829895, 'loss_2': 0.00543975830078125, 'loss_3': -15.845026969909668, 'loss_4': -0.05233529210090637, 'epoch': 4.33}
{'loss': 0.0177, 'grad_norm': 6.136768817901611, 'learning_rate': 2.5686046511627907e-05, 'loss_1': 0.012242507189512253, 'loss_2': 0.005451202392578125, 'loss_3': -15.719059944152832, 'loss_4': -0.025151565670967102, 'epoch': 4.33}
[INFO|trainer.py:4228] 2025-01-21 12:38:55,130 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:38:55,130 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [18:59<1:16:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:02,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01643717847764492, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.639, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007317905779927969, 'eval_loss_2': 0.009119272232055664, 'eval_loss_3': -18.106096267700195, 'eval_loss_4': 0.37021923065185547, 'epoch': 4.33}
{'loss': 0.0256, 'grad_norm': 5.3599162101745605, 'learning_rate': 2.5680232558139536e-05, 'loss_1': 0.009847410023212433, 'loss_2': 0.015716552734375, 'loss_3': -15.864389419555664, 'loss_4': 0.0012539923191070557, 'epoch': 4.34}
{'loss': 0.0277, 'grad_norm': 6.599753379821777, 'learning_rate': 2.5674418604651165e-05, 'loss_1': 0.015526778995990753, 'loss_2': 0.01216888427734375, 'loss_3': -15.597763061523438, 'loss_4': 0.13530951738357544, 'epoch': 4.34}
{'loss': 0.0259, 'grad_norm': 8.078690528869629, 'learning_rate': 2.566860465116279e-05, 'loss_1': 0.018578875809907913, 'loss_2': 0.007305145263671875, 'loss_3': -15.84835433959961, 'loss_4': 1.2365670204162598, 'epoch': 4.35}
{'loss': 0.0234, 'grad_norm': 10.414579391479492, 'learning_rate': 2.5662790697674422e-05, 'loss_1': 0.023004168644547462, 'loss_2': 0.00039386749267578125, 'loss_3': -15.773035049438477, 'loss_4': 0.798577606678009, 'epoch': 4.35}
{'loss': 0.0196, 'grad_norm': 7.630716800689697, 'learning_rate': 2.5656976744186047e-05, 'loss_1': 0.01633635349571705, 'loss_2': 0.003292083740234375, 'loss_3': -15.789798736572266, 'loss_4': 0.8235106468200684, 'epoch': 4.36}
[INFO|trainer.py:4228] 2025-01-21 12:39:02,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:02,495 >>   Batch size = 64
 15%|███████████████████████████████▉                                                                                                                                                                                            | 750/5160 [19:03<1:16:29,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:39:06,306 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-750
[INFO|configuration_utils.py:420] 2025-01-21 12:39:06,307 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-750/config.json                                                                             
{'eval_loss': 0.009978678077459335, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.809, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006565640680491924, 'eval_loss_2': 0.0034130364656448364, 'eval_loss_3': -18.160390853881836, 'eval_loss_4': 0.6948316097259521, 'epoch': 4.36}
[INFO|modeling_utils.py:2988] 2025-01-21 12:39:06,785 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-750/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:39:06,786 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-750/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:39:06,787 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-750/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:39:07,690 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-685] due to args.save_total_limit
 15%|████████████████████████████████▏                                                                                                                                                                                           | 755/5160 [19:08<1:24:09,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:39:11,331 >>
{'loss': 0.0153, 'grad_norm': 6.732758522033691, 'learning_rate': 2.5651162790697676e-05, 'loss_1': 0.014387441799044609, 'loss_2': 0.000946044921875, 'loss_3': -15.922677040100098, 'loss_4': 0.7971431016921997, 'epoch': 4.37}
{'loss': 0.0163, 'grad_norm': 7.8420257568359375, 'learning_rate': 2.56453488372093e-05, 'loss_1': 0.015672247856855392, 'loss_2': 0.0006184577941894531, 'loss_3': -16.018054962158203, 'loss_4': 0.5753422379493713, 'epoch': 4.37}
{'loss': 0.0253, 'grad_norm': 9.731535911560059, 'learning_rate': 2.563953488372093e-05, 'loss_1': 0.0143871596083045, 'loss_2': 0.01094818115234375, 'loss_3': -15.92190170288086, 'loss_4': 0.4136090874671936, 'epoch': 4.38}
{'loss': 0.0539, 'grad_norm': 13.719290733337402, 'learning_rate': 2.563372093023256e-05, 'loss_1': 0.0409947894513607, 'loss_2': 0.0129547119140625, 'loss_3': -15.794092178344727, 'loss_4': 1.3524342775344849, 'epoch': 4.38}
{'loss': 0.0112, 'grad_norm': 6.442680358886719, 'learning_rate': 2.5627906976744187e-05, 'loss_1': 0.010754904709756374, 'loss_2': 0.00045680999755859375, 'loss_3': -15.847511291503906, 'loss_4': 0.5643497705459595, 'epoch': 4.39}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:39:11,331 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:11,331 >>   Batch size = 64
 15%|████████████████████████████████▍                                                                                                                                                                                           | 760/5160 [19:15<1:17:44,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:39:18,704 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022050507366657257, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007631904445588589, 'eval_loss_2': 0.014418601989746094, 'eval_loss_3': -18.18864631652832, 'eval_loss_4': 1.2147787809371948, 'epoch': 4.39}
{'loss': 0.0288, 'grad_norm': 6.60408353805542, 'learning_rate': 2.5622093023255815e-05, 'loss_1': 0.0118956808000803, 'loss_2': 0.01690673828125, 'loss_3': -15.83804988861084, 'loss_4': 1.013119101524353, 'epoch': 4.4}
{'loss': 0.0469, 'grad_norm': 15.802937507629395, 'learning_rate': 2.561627906976744e-05, 'loss_1': 0.03510230779647827, 'loss_2': 0.0118408203125, 'loss_3': -15.841019630432129, 'loss_4': 1.5503242015838623, 'epoch': 4.4}
{'loss': 0.037, 'grad_norm': 7.773906230926514, 'learning_rate': 2.561046511627907e-05, 'loss_1': 0.01390054915100336, 'loss_2': 0.0230712890625, 'loss_3': -15.803597450256348, 'loss_4': 1.5655866861343384, 'epoch': 4.41}
{'loss': 0.0435, 'grad_norm': 13.216684341430664, 'learning_rate': 2.56046511627907e-05, 'loss_1': 0.027587002143263817, 'loss_2': 0.015960693359375, 'loss_3': -15.797143936157227, 'loss_4': 1.4918346405029297, 'epoch': 4.41}
{'loss': 0.0283, 'grad_norm': 7.808916091918945, 'learning_rate': 2.5598837209302327e-05, 'loss_1': 0.01597370207309723, 'loss_2': 0.01236724853515625, 'loss_3': -15.963895797729492, 'loss_4': 1.8794289827346802, 'epoch': 4.42}
[INFO|trainer.py:4228] 2025-01-21 12:39:18,704 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:18,704 >>   Batch size = 64
 15%|████████████████████████████████▌                                                                                                                                                                                           | 765/5160 [19:23<1:16:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:26,079 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01998119242489338, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.437, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009046124294400215, 'eval_loss_2': 0.010935068130493164, 'eval_loss_3': -18.162471771240234, 'eval_loss_4': 1.558862566947937, 'epoch': 4.42}
{'loss': 0.028, 'grad_norm': 7.947207450866699, 'learning_rate': 2.5593023255813955e-05, 'loss_1': 0.015898965299129486, 'loss_2': 0.0121307373046875, 'loss_3': -16.149993896484375, 'loss_4': 1.5351557731628418, 'epoch': 4.42}
{'loss': 0.0151, 'grad_norm': 6.790986061096191, 'learning_rate': 2.558720930232558e-05, 'loss_1': 0.013970521278679371, 'loss_2': 0.00116729736328125, 'loss_3': -15.969355583190918, 'loss_4': 1.855811595916748, 'epoch': 4.43}
{'loss': 0.027, 'grad_norm': 6.429976940155029, 'learning_rate': 2.558139534883721e-05, 'loss_1': 0.016688698902726173, 'loss_2': 0.01031494140625, 'loss_3': -15.974615097045898, 'loss_4': 1.6768245697021484, 'epoch': 4.44}
{'loss': 0.0533, 'grad_norm': 13.620535850524902, 'learning_rate': 2.5575581395348838e-05, 'loss_1': 0.04114677011966705, 'loss_2': 0.012115478515625, 'loss_3': -15.899751663208008, 'loss_4': 1.8303114175796509, 'epoch': 4.44}
{'loss': 0.0139, 'grad_norm': 5.939953327178955, 'learning_rate': 2.5569767441860466e-05, 'loss_1': 0.013125224970281124, 'loss_2': 0.0007295608520507812, 'loss_3': -15.96886920928955, 'loss_4': 1.9617581367492676, 'epoch': 4.45}
[INFO|trainer.py:4228] 2025-01-21 12:39:26,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:26,079 >>   Batch size = 64
 15%|████████████████████████████████▊                                                                                                                                                                                           | 770/5160 [19:30<1:16:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:33,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011941734701395035, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.897, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008720342069864273, 'eval_loss_2': 0.0032213926315307617, 'eval_loss_3': -18.16585922241211, 'eval_loss_4': 1.5789614915847778, 'epoch': 4.45}
{'loss': 0.0455, 'grad_norm': 11.489838600158691, 'learning_rate': 2.5563953488372095e-05, 'loss_1': 0.03981760889291763, 'loss_2': 0.005710601806640625, 'loss_3': -15.88495922088623, 'loss_4': 2.1655521392822266, 'epoch': 4.45}
{'loss': 0.0444, 'grad_norm': 24.229976654052734, 'learning_rate': 2.555813953488372e-05, 'loss_1': 0.04392269253730774, 'loss_2': 0.0005016326904296875, 'loss_3': -16.053401947021484, 'loss_4': 1.896219253540039, 'epoch': 4.46}
{'loss': 0.0132, 'grad_norm': 5.56735897064209, 'learning_rate': 2.555232558139535e-05, 'loss_1': 0.011431535705924034, 'loss_2': 0.0017757415771484375, 'loss_3': -15.858283042907715, 'loss_4': 1.462360143661499, 'epoch': 4.47}
{'loss': 0.0178, 'grad_norm': 5.769542217254639, 'learning_rate': 2.5546511627906978e-05, 'loss_1': 0.014212503097951412, 'loss_2': 0.0035495758056640625, 'loss_3': -15.90304183959961, 'loss_4': 1.800956130027771, 'epoch': 4.47}
{'loss': 0.0264, 'grad_norm': 8.066330909729004, 'learning_rate': 2.5540697674418606e-05, 'loss_1': 0.023389147594571114, 'loss_2': 0.0030384063720703125, 'loss_3': -15.877808570861816, 'loss_4': 1.9695066213607788, 'epoch': 4.48}
[INFO|trainer.py:4228] 2025-01-21 12:39:33,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:33,449 >>   Batch size = 64
 15%|█████████████████████████████████                                                                                                                                                                                           | 775/5160 [19:37<1:16:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:40,811 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013071030378341675, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.042, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008802682161331177, 'eval_loss_2': 0.004268348217010498, 'eval_loss_3': -18.17466163635254, 'eval_loss_4': 1.7004860639572144, 'epoch': 4.48}
{'loss': 0.0281, 'grad_norm': 16.15785789489746, 'learning_rate': 2.5534883720930235e-05, 'loss_1': 0.025085214525461197, 'loss_2': 0.003002166748046875, 'loss_3': -15.7146577835083, 'loss_4': 1.635412573814392, 'epoch': 4.48}
{'loss': 0.0208, 'grad_norm': 10.316874504089355, 'learning_rate': 2.552906976744186e-05, 'loss_1': 0.020075416192412376, 'loss_2': 0.0007352828979492188, 'loss_3': -15.97216796875, 'loss_4': 1.7622220516204834, 'epoch': 4.49}
{'loss': 0.0297, 'grad_norm': 9.228140830993652, 'learning_rate': 2.552325581395349e-05, 'loss_1': 0.027890758588910103, 'loss_2': 0.00177001953125, 'loss_3': -15.78819465637207, 'loss_4': 2.1758217811584473, 'epoch': 4.49}
{'loss': 0.0315, 'grad_norm': 9.878737449645996, 'learning_rate': 2.5517441860465117e-05, 'loss_1': 0.030067216604948044, 'loss_2': 0.001438140869140625, 'loss_3': -16.020925521850586, 'loss_4': 2.1624858379364014, 'epoch': 4.5}
{'loss': 0.0234, 'grad_norm': 12.727665901184082, 'learning_rate': 2.5511627906976746e-05, 'loss_1': 0.023113150149583817, 'loss_2': 0.0002837181091308594, 'loss_3': -15.95535945892334, 'loss_4': 1.92634916305542, 'epoch': 4.51}
[INFO|trainer.py:4228] 2025-01-21 12:39:40,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:40,811 >>   Batch size = 64
 15%|█████████████████████████████████▎                                                                                                                                                                                          | 780/5160 [19:45<1:16:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:48,179 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016859564930200577, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.017, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010238354094326496, 'eval_loss_2': 0.006621211767196655, 'eval_loss_3': -18.20846939086914, 'eval_loss_4': 2.0684139728546143, 'epoch': 4.51}
{'loss': 0.0201, 'grad_norm': 7.673298358917236, 'learning_rate': 2.550581395348837e-05, 'loss_1': 0.013483148068189621, 'loss_2': 0.00665283203125, 'loss_3': -15.922139167785645, 'loss_4': 2.2427079677581787, 'epoch': 4.51}
{'loss': 0.0356, 'grad_norm': 11.067659378051758, 'learning_rate': 2.55e-05, 'loss_1': 0.028882699087262154, 'loss_2': 0.006755828857421875, 'loss_3': -16.04239845275879, 'loss_4': 2.3587374687194824, 'epoch': 4.52}
{'loss': 0.0242, 'grad_norm': 7.364618301391602, 'learning_rate': 2.549418604651163e-05, 'loss_1': 0.022071393206715584, 'loss_2': 0.002117156982421875, 'loss_3': -15.934282302856445, 'loss_4': 1.7393460273742676, 'epoch': 4.52}
{'loss': 0.1342, 'grad_norm': 36.58293914794922, 'learning_rate': 2.5488372093023257e-05, 'loss_1': 0.12887464463710785, 'loss_2': 0.00536346435546875, 'loss_3': -15.710107803344727, 'loss_4': 1.610122561454773, 'epoch': 4.53}
{'loss': 0.0326, 'grad_norm': 9.041808128356934, 'learning_rate': 2.5482558139534886e-05, 'loss_1': 0.02175586111843586, 'loss_2': 0.0108489990234375, 'loss_3': -15.976198196411133, 'loss_4': 2.204805374145508, 'epoch': 4.53}
[INFO|trainer.py:4228] 2025-01-21 12:39:48,179 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:48,179 >>   Batch size = 64
 15%|█████████████████████████████████▍                                                                                                                                                                                          | 785/5160 [19:52<1:15:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:39:55,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015701649710536003, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011231479234993458, 'eval_loss_2': 0.004470169544219971, 'eval_loss_3': -18.197906494140625, 'eval_loss_4': 1.7434606552124023, 'epoch': 4.53}
{'loss': 0.0259, 'grad_norm': 9.430846214294434, 'learning_rate': 2.547674418604651e-05, 'loss_1': 0.021051382645964622, 'loss_2': 0.00485992431640625, 'loss_3': -15.964519500732422, 'loss_4': 1.4100863933563232, 'epoch': 4.54}
{'loss': 0.0498, 'grad_norm': 14.512656211853027, 'learning_rate': 2.547093023255814e-05, 'loss_1': 0.04618998244404793, 'loss_2': 0.003597259521484375, 'loss_3': -16.043716430664062, 'loss_4': 1.5052640438079834, 'epoch': 4.55}
{'loss': 0.0238, 'grad_norm': 10.932765007019043, 'learning_rate': 2.5465116279069768e-05, 'loss_1': 0.022437313571572304, 'loss_2': 0.0013904571533203125, 'loss_3': -15.877181053161621, 'loss_4': 1.1872611045837402, 'epoch': 4.55}
{'loss': 0.024, 'grad_norm': 8.279387474060059, 'learning_rate': 2.5459302325581397e-05, 'loss_1': 0.02331688068807125, 'loss_2': 0.0007038116455078125, 'loss_3': -15.844789505004883, 'loss_4': 1.3194928169250488, 'epoch': 4.56}
{'loss': 0.0238, 'grad_norm': 10.22482967376709, 'learning_rate': 2.5453488372093025e-05, 'loss_1': 0.023374168202280998, 'loss_2': 0.0004324913024902344, 'loss_3': -15.786348342895508, 'loss_4': 1.7649357318878174, 'epoch': 4.56}
[INFO|trainer.py:4228] 2025-01-21 12:39:55,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:39:55,548 >>   Batch size = 64
 15%|█████████████████████████████████▋                                                                                                                                                                                          | 790/5160 [20:00<1:15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:02,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01754850149154663, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.175, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.010143964551389217, 'eval_loss_2': 0.007404536008834839, 'eval_loss_3': -18.248817443847656, 'eval_loss_4': 1.636704921722412, 'epoch': 4.56}
{'loss': 0.0137, 'grad_norm': 5.257950305938721, 'learning_rate': 2.544767441860465e-05, 'loss_1': 0.011303320527076721, 'loss_2': 0.00238037109375, 'loss_3': -16.140369415283203, 'loss_4': 1.8413593769073486, 'epoch': 4.57}
{'loss': 0.0559, 'grad_norm': 25.735143661499023, 'learning_rate': 2.544186046511628e-05, 'loss_1': 0.04284162074327469, 'loss_2': 0.013031005859375, 'loss_3': -15.90365219116211, 'loss_4': 1.6387581825256348, 'epoch': 4.58}
{'loss': 0.0497, 'grad_norm': 17.150711059570312, 'learning_rate': 2.5436046511627905e-05, 'loss_1': 0.03973083943128586, 'loss_2': 0.00994110107421875, 'loss_3': -15.990032196044922, 'loss_4': 1.6993076801300049, 'epoch': 4.58}
{'loss': 0.0283, 'grad_norm': 8.05539321899414, 'learning_rate': 2.5430232558139537e-05, 'loss_1': 0.01792873442173004, 'loss_2': 0.0103759765625, 'loss_3': -15.649449348449707, 'loss_4': 1.5104501247406006, 'epoch': 4.59}
{'loss': 0.0278, 'grad_norm': 5.405879020690918, 'learning_rate': 2.5424418604651165e-05, 'loss_1': 0.014171685092151165, 'loss_2': 0.0136260986328125, 'loss_3': -15.802728652954102, 'loss_4': 2.0057902336120605, 'epoch': 4.59}
[INFO|trainer.py:4228] 2025-01-21 12:40:02,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:02,929 >>   Batch size = 64
 15%|█████████████████████████████████▉                                                                                                                                                                                          | 795/5160 [20:07<1:15:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:10,301 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01555062085390091, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.568, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011085891164839268, 'eval_loss_2': 0.004464730620384216, 'eval_loss_3': -18.284738540649414, 'eval_loss_4': 1.936184048652649, 'epoch': 4.59}
{'loss': 0.0197, 'grad_norm': 7.016684055328369, 'learning_rate': 2.541860465116279e-05, 'loss_1': 0.016856923699378967, 'loss_2': 0.00281524658203125, 'loss_3': -16.011287689208984, 'loss_4': 2.1121010780334473, 'epoch': 4.6}
{'loss': 0.0293, 'grad_norm': 8.934926986694336, 'learning_rate': 2.541279069767442e-05, 'loss_1': 0.02824339084327221, 'loss_2': 0.0010166168212890625, 'loss_3': -15.696210861206055, 'loss_4': 2.1531624794006348, 'epoch': 4.6}
{'loss': 0.0516, 'grad_norm': 17.868257522583008, 'learning_rate': 2.5406976744186044e-05, 'loss_1': 0.04961740970611572, 'loss_2': 0.0020313262939453125, 'loss_3': -15.951517105102539, 'loss_4': 1.5878926515579224, 'epoch': 4.61}
{'loss': 0.0185, 'grad_norm': 5.934749603271484, 'learning_rate': 2.5401162790697676e-05, 'loss_1': 0.016264449805021286, 'loss_2': 0.002285003662109375, 'loss_3': -15.887933731079102, 'loss_4': 1.8178662061691284, 'epoch': 4.62}
{'loss': 0.0125, 'grad_norm': 6.6752190589904785, 'learning_rate': 2.5395348837209305e-05, 'loss_1': 0.011164627969264984, 'loss_2': 0.00131988525390625, 'loss_3': -15.899724960327148, 'loss_4': 2.101558208465576, 'epoch': 4.62}
[INFO|trainer.py:4228] 2025-01-21 12:40:10,301 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:10,301 >>   Batch size = 64
 16%|██████████████████████████████████                                                                                                                                                                                          | 800/5160 [20:14<1:15:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:17,672 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01455992553383112, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.612, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010367573238909245, 'eval_loss_2': 0.004192352294921875, 'eval_loss_3': -18.2510929107666, 'eval_loss_4': 1.9881247282028198, 'epoch': 4.62}
{'loss': 0.0401, 'grad_norm': 9.047297477722168, 'learning_rate': 2.538953488372093e-05, 'loss_1': 0.03228093311190605, 'loss_2': 0.00782012939453125, 'loss_3': -15.878506660461426, 'loss_4': 2.363447666168213, 'epoch': 4.63}
{'loss': 0.0243, 'grad_norm': 7.97740364074707, 'learning_rate': 2.538372093023256e-05, 'loss_1': 0.019687876105308533, 'loss_2': 0.00457000732421875, 'loss_3': -15.7686185836792, 'loss_4': 1.971037745475769, 'epoch': 4.63}
{'loss': 0.0426, 'grad_norm': 19.273208618164062, 'learning_rate': 2.5377906976744184e-05, 'loss_1': 0.04211848974227905, 'loss_2': 0.0004482269287109375, 'loss_3': -15.75158405303955, 'loss_4': 1.9245719909667969, 'epoch': 4.64}
{'loss': 0.0371, 'grad_norm': 8.704573631286621, 'learning_rate': 2.5372093023255816e-05, 'loss_1': 0.029232436791062355, 'loss_2': 0.00791168212890625, 'loss_3': -15.89543342590332, 'loss_4': 2.005946636199951, 'epoch': 4.65}
{'loss': 0.0354, 'grad_norm': 11.936659812927246, 'learning_rate': 2.536627906976744e-05, 'loss_1': 0.030604103580117226, 'loss_2': 0.0047760009765625, 'loss_3': -15.845867156982422, 'loss_4': 1.8628287315368652, 'epoch': 4.65}
[INFO|trainer.py:4228] 2025-01-21 12:40:17,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:17,673 >>   Batch size = 64
 16%|██████████████████████████████████▎                                                                                                                                                                                         | 805/5160 [20:22<1:15:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:25,044 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016695642843842506, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.995, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01013043150305748, 'eval_loss_2': 0.006565213203430176, 'eval_loss_3': -18.298988342285156, 'eval_loss_4': 1.8762928247451782, 'epoch': 4.65}
{'loss': 0.0375, 'grad_norm': 10.533036231994629, 'learning_rate': 2.536046511627907e-05, 'loss_1': 0.030362796038389206, 'loss_2': 0.00717926025390625, 'loss_3': -15.773103713989258, 'loss_4': 1.5112342834472656, 'epoch': 4.66}
{'loss': 0.038, 'grad_norm': 13.007841110229492, 'learning_rate': 2.53546511627907e-05, 'loss_1': 0.02577836811542511, 'loss_2': 0.01222991943359375, 'loss_3': -15.75861930847168, 'loss_4': 2.1855170726776123, 'epoch': 4.66}
{'loss': 0.0294, 'grad_norm': 10.603630065917969, 'learning_rate': 2.5348837209302324e-05, 'loss_1': 0.01889854483306408, 'loss_2': 0.01052093505859375, 'loss_3': -15.85374641418457, 'loss_4': 1.726550579071045, 'epoch': 4.67}
{'loss': 0.0275, 'grad_norm': 9.656783103942871, 'learning_rate': 2.5343023255813956e-05, 'loss_1': 0.025586802512407303, 'loss_2': 0.0019254684448242188, 'loss_3': -15.9046049118042, 'loss_4': 2.3292784690856934, 'epoch': 4.67}
{'loss': 0.0415, 'grad_norm': 14.164018630981445, 'learning_rate': 2.533720930232558e-05, 'loss_1': 0.0398637130856514, 'loss_2': 0.0016431808471679688, 'loss_3': -15.695442199707031, 'loss_4': 2.3724961280822754, 'epoch': 4.68}
[INFO|trainer.py:4228] 2025-01-21 12:40:25,044 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:25,044 >>   Batch size = 64
 16%|██████████████████████████████████▌                                                                                                                                                                                         | 810/5160 [20:29<1:15:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:32,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0146767757833004, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.86, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010699894279241562, 'eval_loss_2': 0.003976881504058838, 'eval_loss_3': -18.268308639526367, 'eval_loss_4': 2.153193473815918, 'epoch': 4.68}
{'loss': 0.0438, 'grad_norm': 19.038129806518555, 'learning_rate': 2.533139534883721e-05, 'loss_1': 0.03202803060412407, 'loss_2': 0.0117950439453125, 'loss_3': -15.941596984863281, 'loss_4': 2.398249864578247, 'epoch': 4.69}
{'loss': 0.0293, 'grad_norm': 10.714505195617676, 'learning_rate': 2.532558139534884e-05, 'loss_1': 0.028013553470373154, 'loss_2': 0.0012798309326171875, 'loss_3': -15.632163047790527, 'loss_4': 2.1445956230163574, 'epoch': 4.69}
{'loss': 0.048, 'grad_norm': 14.472904205322266, 'learning_rate': 2.5319767441860464e-05, 'loss_1': 0.04538079723715782, 'loss_2': 0.002593994140625, 'loss_3': -15.66566276550293, 'loss_4': 2.1294002532958984, 'epoch': 4.7}
{'loss': 0.0268, 'grad_norm': 9.743782997131348, 'learning_rate': 2.5313953488372096e-05, 'loss_1': 0.01705782301723957, 'loss_2': 0.0097503662109375, 'loss_3': -15.59056282043457, 'loss_4': 2.3629043102264404, 'epoch': 4.7}
{'loss': 0.0255, 'grad_norm': 13.662609100341797, 'learning_rate': 2.530813953488372e-05, 'loss_1': 0.023450465872883797, 'loss_2': 0.0020275115966796875, 'loss_3': -16.002742767333984, 'loss_4': 2.2471251487731934, 'epoch': 4.71}
[INFO|trainer.py:4228] 2025-01-21 12:40:32,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:32,417 >>   Batch size = 64
 16%|██████████████████████████████████▋                                                                                                                                                                                         | 815/5160 [20:36<1:15:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:39,788 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0163294468075037, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009656887501478195, 'eval_loss_2': 0.006672561168670654, 'eval_loss_3': -18.22870445251465, 'eval_loss_4': 2.2823545932769775, 'epoch': 4.71}
{'loss': 0.0234, 'grad_norm': 7.739156723022461, 'learning_rate': 2.530232558139535e-05, 'loss_1': 0.01525253988802433, 'loss_2': 0.00815582275390625, 'loss_3': -15.727006912231445, 'loss_4': 1.6781810522079468, 'epoch': 4.72}
{'loss': 0.0257, 'grad_norm': 8.698277473449707, 'learning_rate': 2.5296511627906975e-05, 'loss_1': 0.025347910821437836, 'loss_2': 0.000335693359375, 'loss_3': -15.781709671020508, 'loss_4': 2.155095100402832, 'epoch': 4.72}
{'loss': 0.0135, 'grad_norm': 5.870229721069336, 'learning_rate': 2.5290697674418607e-05, 'loss_1': 0.011215787380933762, 'loss_2': 0.00223541259765625, 'loss_3': -15.971014976501465, 'loss_4': 2.5592808723449707, 'epoch': 4.73}
{'loss': 0.0237, 'grad_norm': 10.470931053161621, 'learning_rate': 2.5284883720930235e-05, 'loss_1': 0.020578932017087936, 'loss_2': 0.003147125244140625, 'loss_3': -15.87393569946289, 'loss_4': 2.14778995513916, 'epoch': 4.73}
{'loss': 0.0141, 'grad_norm': 6.738585472106934, 'learning_rate': 2.527906976744186e-05, 'loss_1': 0.010724936611950397, 'loss_2': 0.003337860107421875, 'loss_3': -15.848955154418945, 'loss_4': 1.6388344764709473, 'epoch': 4.74}
[INFO|trainer.py:4228] 2025-01-21 12:40:39,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:39,788 >>   Batch size = 64
 16%|██████████████████████████████████▉                                                                                                                                                                                         | 820/5160 [20:44<1:15:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:47,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01255064271390438, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.203, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.00958398450165987, 'eval_loss_2': 0.002966657280921936, 'eval_loss_3': -18.243207931518555, 'eval_loss_4': 1.977236032485962, 'epoch': 4.74}
{'loss': 0.0188, 'grad_norm': 7.650949478149414, 'learning_rate': 2.527325581395349e-05, 'loss_1': 0.018316006287932396, 'loss_2': 0.00046253204345703125, 'loss_3': -15.858903884887695, 'loss_4': 2.343921422958374, 'epoch': 4.74}
{'loss': 0.0434, 'grad_norm': 17.613731384277344, 'learning_rate': 2.5267441860465115e-05, 'loss_1': 0.035623859614133835, 'loss_2': 0.0077972412109375, 'loss_3': -15.934698104858398, 'loss_4': 1.7150516510009766, 'epoch': 4.75}
{'loss': 0.0251, 'grad_norm': 9.275080680847168, 'learning_rate': 2.5261627906976747e-05, 'loss_1': 0.018763387575745583, 'loss_2': 0.006378173828125, 'loss_3': -15.82097339630127, 'loss_4': 2.0842342376708984, 'epoch': 4.76}
{'loss': 0.0271, 'grad_norm': 9.285683631896973, 'learning_rate': 2.5255813953488375e-05, 'loss_1': 0.017120404168963432, 'loss_2': 0.0099945068359375, 'loss_3': -15.794660568237305, 'loss_4': 1.5840927362442017, 'epoch': 4.76}
{'loss': 0.0179, 'grad_norm': 6.739621162414551, 'learning_rate': 2.525e-05, 'loss_1': 0.014454192481935024, 'loss_2': 0.003475189208984375, 'loss_3': -15.828093528747559, 'loss_4': 1.5175774097442627, 'epoch': 4.77}
[INFO|trainer.py:4228] 2025-01-21 12:40:47,172 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:47,172 >>   Batch size = 64
 16%|███████████████████████████████████▏                                                                                                                                                                                        | 825/5160 [20:51<1:15:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:40:54,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015169794671237469, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008617455139756203, 'eval_loss_2': 0.006552338600158691, 'eval_loss_3': -18.184185028076172, 'eval_loss_4': 1.6725811958312988, 'epoch': 4.77}
{'loss': 0.0408, 'grad_norm': 10.80433177947998, 'learning_rate': 2.524418604651163e-05, 'loss_1': 0.02881917543709278, 'loss_2': 0.0119476318359375, 'loss_3': -15.706274032592773, 'loss_4': 1.7198631763458252, 'epoch': 4.77}
{'loss': 0.0188, 'grad_norm': 5.764054775238037, 'learning_rate': 2.5238372093023254e-05, 'loss_1': 0.011382627300918102, 'loss_2': 0.00742340087890625, 'loss_3': -15.931557655334473, 'loss_4': 1.4097565412521362, 'epoch': 4.78}
{'loss': 0.1207, 'grad_norm': 37.06428527832031, 'learning_rate': 2.5232558139534886e-05, 'loss_1': 0.11379136890172958, 'loss_2': 0.00685882568359375, 'loss_3': -15.926835060119629, 'loss_4': 2.0725460052490234, 'epoch': 4.78}
{'loss': 0.0134, 'grad_norm': 5.4501166343688965, 'learning_rate': 2.522674418604651e-05, 'loss_1': 0.011259856633841991, 'loss_2': 0.00211334228515625, 'loss_3': -15.720584869384766, 'loss_4': 1.58943772315979, 'epoch': 4.79}
{'loss': 0.033, 'grad_norm': 15.71546745300293, 'learning_rate': 2.522093023255814e-05, 'loss_1': 0.03249436616897583, 'loss_2': 0.0004868507385253906, 'loss_3': -15.877220153808594, 'loss_4': 1.5098049640655518, 'epoch': 4.8}
[INFO|trainer.py:4228] 2025-01-21 12:40:54,538 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:40:54,538 >>   Batch size = 64
 16%|███████████████████████████████████▍                                                                                                                                                                                        | 830/5160 [20:59<1:15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:01,894 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013975932262837887, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.933, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01113069150596857, 'eval_loss_2': 0.0028452426195144653, 'eval_loss_3': -18.186641693115234, 'eval_loss_4': 1.6883045434951782, 'epoch': 4.8}
{'loss': 0.0185, 'grad_norm': 10.487653732299805, 'learning_rate': 2.521511627906977e-05, 'loss_1': 0.016445690765976906, 'loss_2': 0.002071380615234375, 'loss_3': -15.679765701293945, 'loss_4': 1.2786452770233154, 'epoch': 4.8}
{'loss': 0.0273, 'grad_norm': 13.477561950683594, 'learning_rate': 2.5209302325581394e-05, 'loss_1': 0.026396729052066803, 'loss_2': 0.000865936279296875, 'loss_3': -15.846475601196289, 'loss_4': 1.5981359481811523, 'epoch': 4.81}
{'loss': 0.0472, 'grad_norm': 14.114922523498535, 'learning_rate': 2.5203488372093026e-05, 'loss_1': 0.037028029561042786, 'loss_2': 0.01016998291015625, 'loss_3': -15.834217071533203, 'loss_4': 1.3448790311813354, 'epoch': 4.81}
{'loss': 0.0236, 'grad_norm': 11.932197570800781, 'learning_rate': 2.519767441860465e-05, 'loss_1': 0.02321581542491913, 'loss_2': 0.0003705024719238281, 'loss_3': -15.776117324829102, 'loss_4': 1.920727014541626, 'epoch': 4.82}
{'loss': 0.014, 'grad_norm': 6.055910110473633, 'learning_rate': 2.519186046511628e-05, 'loss_1': 0.011299901641905308, 'loss_2': 0.0026721954345703125, 'loss_3': -15.832539558410645, 'loss_4': 1.5532114505767822, 'epoch': 4.83}
[INFO|trainer.py:4228] 2025-01-21 12:41:01,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:01,895 >>   Batch size = 64
 16%|███████████████████████████████████▌                                                                                                                                                                                        | 835/5160 [21:06<1:15:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:09,257 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014408422634005547, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.037, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010672733187675476, 'eval_loss_2': 0.0037356913089752197, 'eval_loss_3': -18.200878143310547, 'eval_loss_4': 1.8593336343765259, 'epoch': 4.83}
{'loss': 0.023, 'grad_norm': 8.671114921569824, 'learning_rate': 2.518604651162791e-05, 'loss_1': 0.014618651941418648, 'loss_2': 0.0083465576171875, 'loss_3': -15.703180313110352, 'loss_4': 1.0572787523269653, 'epoch': 4.83}
{'loss': 0.0754, 'grad_norm': 24.71087646484375, 'learning_rate': 2.5180232558139534e-05, 'loss_1': 0.07069386541843414, 'loss_2': 0.00473785400390625, 'loss_3': -15.581799507141113, 'loss_4': 1.9877450466156006, 'epoch': 4.84}
{'loss': 0.0564, 'grad_norm': 13.564741134643555, 'learning_rate': 2.5174418604651166e-05, 'loss_1': 0.05473357439041138, 'loss_2': 0.0016384124755859375, 'loss_3': -15.820419311523438, 'loss_4': 1.3893513679504395, 'epoch': 4.84}
{'loss': 0.0223, 'grad_norm': 8.402544975280762, 'learning_rate': 2.516860465116279e-05, 'loss_1': 0.018778054043650627, 'loss_2': 0.0034942626953125, 'loss_3': -15.849679946899414, 'loss_4': 1.8770767450332642, 'epoch': 4.85}
{'loss': 0.0165, 'grad_norm': 7.2585930824279785, 'learning_rate': 2.516279069767442e-05, 'loss_1': 0.01585223712027073, 'loss_2': 0.0006914138793945312, 'loss_3': -15.77579116821289, 'loss_4': 2.5277154445648193, 'epoch': 4.85}
[INFO|trainer.py:4228] 2025-01-21 12:41:09,257 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:09,257 >>   Batch size = 64
 16%|███████████████████████████████████▊                                                                                                                                                                                        | 840/5160 [21:13<1:14:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:16,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013557728379964828, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.06, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010253633372485638, 'eval_loss_2': 0.003304094076156616, 'eval_loss_3': -18.222457885742188, 'eval_loss_4': 2.0432026386260986, 'epoch': 4.85}
{'loss': 0.0192, 'grad_norm': 7.768312931060791, 'learning_rate': 2.5156976744186045e-05, 'loss_1': 0.017931567505002022, 'loss_2': 0.001300811767578125, 'loss_3': -15.847289085388184, 'loss_4': 2.291593551635742, 'epoch': 4.86}
{'loss': 0.0286, 'grad_norm': 7.984760284423828, 'learning_rate': 2.5151162790697674e-05, 'loss_1': 0.020375488325953484, 'loss_2': 0.00823974609375, 'loss_3': -15.630455017089844, 'loss_4': 2.126400947570801, 'epoch': 4.87}
{'loss': 0.0295, 'grad_norm': 10.580026626586914, 'learning_rate': 2.5145348837209306e-05, 'loss_1': 0.019283179193735123, 'loss_2': 0.01021575927734375, 'loss_3': -15.765058517456055, 'loss_4': 2.643618106842041, 'epoch': 4.87}
{'loss': 0.016, 'grad_norm': 7.564557075500488, 'learning_rate': 2.513953488372093e-05, 'loss_1': 0.012925457209348679, 'loss_2': 0.0030536651611328125, 'loss_3': -15.755524635314941, 'loss_4': 2.0018558502197266, 'epoch': 4.88}
{'loss': 0.0449, 'grad_norm': 22.006471633911133, 'learning_rate': 2.513372093023256e-05, 'loss_1': 0.04274812713265419, 'loss_2': 0.0021209716796875, 'loss_3': -15.74422550201416, 'loss_4': 1.6035025119781494, 'epoch': 4.88}
[INFO|trainer.py:4228] 2025-01-21 12:41:16,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:16,617 >>   Batch size = 64
 16%|████████████████████████████████████                                                                                                                                                                                        | 845/5160 [21:21<1:14:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:23,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017032209783792496, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.694, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013644772581756115, 'eval_loss_2': 0.003387436270713806, 'eval_loss_3': -18.145732879638672, 'eval_loss_4': 1.9948649406433105, 'epoch': 4.88}
{'loss': 0.0122, 'grad_norm': 6.359632968902588, 'learning_rate': 2.5127906976744185e-05, 'loss_1': 0.011242126114666462, 'loss_2': 0.0009918212890625, 'loss_3': -15.858329772949219, 'loss_4': 1.848766803741455, 'epoch': 4.89}
{'loss': 0.0122, 'grad_norm': 5.745532512664795, 'learning_rate': 2.5122093023255813e-05, 'loss_1': 0.010940570384263992, 'loss_2': 0.00128173828125, 'loss_3': -15.983304977416992, 'loss_4': 1.930816888809204, 'epoch': 4.9}
{'loss': 0.0248, 'grad_norm': 10.275672912597656, 'learning_rate': 2.5116279069767445e-05, 'loss_1': 0.016178838908672333, 'loss_2': 0.008636474609375, 'loss_3': -15.922786712646484, 'loss_4': 1.7886601686477661, 'epoch': 4.9}
{'loss': 0.0183, 'grad_norm': 12.81578254699707, 'learning_rate': 2.511046511627907e-05, 'loss_1': 0.017152026295661926, 'loss_2': 0.0011396408081054688, 'loss_3': -15.72484302520752, 'loss_4': 1.8440577983856201, 'epoch': 4.91}
{'loss': 0.0412, 'grad_norm': 13.308786392211914, 'learning_rate': 2.51046511627907e-05, 'loss_1': 0.03964640572667122, 'loss_2': 0.0015783309936523438, 'loss_3': -15.700485229492188, 'loss_4': 1.550838589668274, 'epoch': 4.91}
[INFO|trainer.py:4228] 2025-01-21 12:41:23,992 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:23,992 >>   Batch size = 64
 16%|████████████████████████████████████▏                                                                                                                                                                                       | 850/5160 [21:28<1:14:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:31,362 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0274465624243021, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.496, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.024849632754921913, 'eval_loss_2': 0.002596929669380188, 'eval_loss_3': -18.046859741210938, 'eval_loss_4': 2.144423484802246, 'epoch': 4.91}
{'loss': 0.0138, 'grad_norm': 6.598797798156738, 'learning_rate': 2.5098837209302325e-05, 'loss_1': 0.012134968303143978, 'loss_2': 0.00162506103515625, 'loss_3': -15.732576370239258, 'loss_4': 1.9449539184570312, 'epoch': 4.92}
{'loss': 0.0452, 'grad_norm': 14.024299621582031, 'learning_rate': 2.5093023255813953e-05, 'loss_1': 0.03450876101851463, 'loss_2': 0.0107269287109375, 'loss_3': -15.642364501953125, 'loss_4': 1.5596028566360474, 'epoch': 4.92}
{'loss': 0.0161, 'grad_norm': 6.051727294921875, 'learning_rate': 2.5087209302325582e-05, 'loss_1': 0.014521362259984016, 'loss_2': 0.0015888214111328125, 'loss_3': -15.674083709716797, 'loss_4': 2.1081581115722656, 'epoch': 4.93}
{'loss': 0.0336, 'grad_norm': 10.13736343383789, 'learning_rate': 2.508139534883721e-05, 'loss_1': 0.032423947006464005, 'loss_2': 0.0012054443359375, 'loss_3': -15.882848739624023, 'loss_4': 1.867990255355835, 'epoch': 4.94}
{'loss': 0.03, 'grad_norm': 8.260530471801758, 'learning_rate': 2.507558139534884e-05, 'loss_1': 0.02101999707520008, 'loss_2': 0.0089874267578125, 'loss_3': -15.46154499053955, 'loss_4': 1.548654317855835, 'epoch': 4.94}
[INFO|trainer.py:4228] 2025-01-21 12:41:31,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:31,362 >>   Batch size = 64
 17%|████████████████████████████████████▍                                                                                                                                                                                       | 855/5160 [21:35<1:14:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:41:38,728 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026798322796821594, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.886, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.024160027503967285, 'eval_loss_2': 0.002638295292854309, 'eval_loss_3': -18.030040740966797, 'eval_loss_4': 2.2738077640533447, 'epoch': 4.94}
{'loss': 0.0601, 'grad_norm': 18.164331436157227, 'learning_rate': 2.5069767441860464e-05, 'loss_1': 0.059580255299806595, 'loss_2': 0.0005064010620117188, 'loss_3': -15.75853157043457, 'loss_4': 2.1811907291412354, 'epoch': 4.95}
{'loss': 0.0641, 'grad_norm': 29.399709701538086, 'learning_rate': 2.5063953488372093e-05, 'loss_1': 0.06238711625337601, 'loss_2': 0.0017070770263671875, 'loss_3': -15.705549240112305, 'loss_4': 2.2313365936279297, 'epoch': 4.95}
{'loss': 0.0608, 'grad_norm': 17.771587371826172, 'learning_rate': 2.505813953488372e-05, 'loss_1': 0.056777819991111755, 'loss_2': 0.0040130615234375, 'loss_3': -15.501338958740234, 'loss_4': 2.0973563194274902, 'epoch': 4.96}
{'loss': 0.0207, 'grad_norm': 7.555367946624756, 'learning_rate': 2.505232558139535e-05, 'loss_1': 0.01874079555273056, 'loss_2': 0.00194549560546875, 'loss_3': -15.711872100830078, 'loss_4': 2.214526653289795, 'epoch': 4.97}
{'loss': 0.0198, 'grad_norm': 9.98109245300293, 'learning_rate': 2.504651162790698e-05, 'loss_1': 0.016974786296486855, 'loss_2': 0.0027923583984375, 'loss_3': -15.976597785949707, 'loss_4': 2.2596654891967773, 'epoch': 4.97}
[INFO|trainer.py:4228] 2025-01-21 12:41:38,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:38,728 >>   Batch size = 64
 17%|████████████████████████████████████▋                                                                                                                                                                                       | 860/5160 [21:42<1:07:04,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 12:41:45,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023932049050927162, 'eval_runtime': 3.8054, 'eval_samples_per_second': 269.091, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.02016782946884632, 'eval_loss_2': 0.003764219582080841, 'eval_loss_3': -18.062950134277344, 'eval_loss_4': 2.2546262741088867, 'epoch': 4.97}
{'loss': 0.0225, 'grad_norm': 7.491996765136719, 'learning_rate': 2.5040697674418604e-05, 'loss_1': 0.01808464527130127, 'loss_2': 0.00446319580078125, 'loss_3': -15.712236404418945, 'loss_4': 2.0563554763793945, 'epoch': 4.98}
{'loss': 0.0694, 'grad_norm': 19.10818862915039, 'learning_rate': 2.5034883720930233e-05, 'loss_1': 0.06760043650865555, 'loss_2': 0.0017757415771484375, 'loss_3': -15.897686958312988, 'loss_4': 2.406132698059082, 'epoch': 4.98}
{'loss': 0.0204, 'grad_norm': 7.849483013153076, 'learning_rate': 2.502906976744186e-05, 'loss_1': 0.018071871250867844, 'loss_2': 0.0022792816162109375, 'loss_3': -15.720151901245117, 'loss_4': 1.9031023979187012, 'epoch': 4.99}
{'loss': 0.0166, 'grad_norm': 6.948374271392822, 'learning_rate': 2.502325581395349e-05, 'loss_1': 0.015600280836224556, 'loss_2': 0.0009918212890625, 'loss_3': -15.709632873535156, 'loss_4': 2.226428508758545, 'epoch': 4.99}
{'loss': 0.0133, 'grad_norm': 6.101282596588135, 'learning_rate': 2.5017441860465115e-05, 'loss_1': 0.007273994851857424, 'loss_2': 0.00598907470703125, 'loss_3': -15.921211242675781, 'loss_4': 2.416038990020752, 'epoch': 5.0}
[INFO|trainer.py:4228] 2025-01-21 12:41:45,736 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:45,736 >>   Batch size = 64
 17%|████████████████████████████████████▉                                                                                                                                                                                       | 865/5160 [21:50<1:13:29,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:41:53,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03282183036208153, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.717, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0198783241212368, 'eval_loss_2': 0.012943506240844727, 'eval_loss_3': -18.08648109436035, 'eval_loss_4': 2.224947214126587, 'epoch': 5.0}
{'loss': 0.0425, 'grad_norm': 10.670430183410645, 'learning_rate': 2.5011627906976744e-05, 'loss_1': 0.03322174400091171, 'loss_2': 0.009307861328125, 'loss_3': -15.620267868041992, 'loss_4': 1.6908602714538574, 'epoch': 5.01}
{'loss': 0.0338, 'grad_norm': 7.146762847900391, 'learning_rate': 2.5005813953488373e-05, 'loss_1': 0.020778607577085495, 'loss_2': 0.013031005859375, 'loss_3': -15.975465774536133, 'loss_4': 2.249410629272461, 'epoch': 5.01}
{'loss': 0.0343, 'grad_norm': 10.920077323913574, 'learning_rate': 2.5e-05, 'loss_1': 0.024686161428689957, 'loss_2': 0.00963592529296875, 'loss_3': -15.95578670501709, 'loss_4': 2.0982251167297363, 'epoch': 5.02}
{'loss': 0.055, 'grad_norm': 25.200477600097656, 'learning_rate': 2.499418604651163e-05, 'loss_1': 0.048493996262550354, 'loss_2': 0.00647735595703125, 'loss_3': -15.73813533782959, 'loss_4': 1.989607572555542, 'epoch': 5.02}
{'loss': 0.0237, 'grad_norm': 7.4044342041015625, 'learning_rate': 2.4988372093023255e-05, 'loss_1': 0.021616414189338684, 'loss_2': 0.0021038055419921875, 'loss_3': -15.818431854248047, 'loss_4': 1.945007085800171, 'epoch': 5.03}
[INFO|trainer.py:4228] 2025-01-21 12:41:53,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:41:53,146 >>   Batch size = 64
 17%|█████████████████████████████████████                                                                                                                                                                                       | 870/5160 [21:57<1:14:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:00,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03213850408792496, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.051, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02460477501153946, 'eval_loss_2': 0.007533729076385498, 'eval_loss_3': -18.091991424560547, 'eval_loss_4': 2.1257846355438232, 'epoch': 5.03}
{'loss': 0.0268, 'grad_norm': 10.376007080078125, 'learning_rate': 2.4982558139534884e-05, 'loss_1': 0.023557621985673904, 'loss_2': 0.0032062530517578125, 'loss_3': -15.813318252563477, 'loss_4': 2.053497552871704, 'epoch': 5.03}
{'loss': 0.0413, 'grad_norm': 18.634262084960938, 'learning_rate': 2.4976744186046512e-05, 'loss_1': 0.03443466126918793, 'loss_2': 0.00688934326171875, 'loss_3': -15.503146171569824, 'loss_4': 1.5426708459854126, 'epoch': 5.04}
{'loss': 0.0276, 'grad_norm': 13.559171676635742, 'learning_rate': 2.497093023255814e-05, 'loss_1': 0.023512428626418114, 'loss_2': 0.0040435791015625, 'loss_3': -15.622238159179688, 'loss_4': 2.4228763580322266, 'epoch': 5.05}
{'loss': 0.0246, 'grad_norm': 6.495588302612305, 'learning_rate': 2.496511627906977e-05, 'loss_1': 0.015131070278584957, 'loss_2': 0.00946044921875, 'loss_3': -15.762672424316406, 'loss_4': 2.0293362140655518, 'epoch': 5.05}
{'loss': 0.1883, 'grad_norm': 25.709463119506836, 'learning_rate': 2.4959302325581395e-05, 'loss_1': 0.17859962582588196, 'loss_2': 0.009674072265625, 'loss_3': -15.924276351928711, 'loss_4': 2.2823729515075684, 'epoch': 5.06}
[INFO|trainer.py:4228] 2025-01-21 12:42:00,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:00,508 >>   Batch size = 64
 17%|█████████████████████████████████████▎                                                                                                                                                                                      | 875/5160 [22:05<1:14:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:07,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022292155772447586, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.319, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.01702793315052986, 'eval_loss_2': 0.005264222621917725, 'eval_loss_3': -18.152690887451172, 'eval_loss_4': 2.1740078926086426, 'epoch': 5.06}
{'loss': 0.0354, 'grad_norm': 7.9879279136657715, 'learning_rate': 2.4953488372093023e-05, 'loss_1': 0.02433837205171585, 'loss_2': 0.01107025146484375, 'loss_3': -15.627951622009277, 'loss_4': 2.197819709777832, 'epoch': 5.06}
{'loss': 0.0493, 'grad_norm': 14.263410568237305, 'learning_rate': 2.494767441860465e-05, 'loss_1': 0.04272741824388504, 'loss_2': 0.006591796875, 'loss_3': -15.640758514404297, 'loss_4': 2.4245553016662598, 'epoch': 5.07}
{'loss': 0.0203, 'grad_norm': 10.163808822631836, 'learning_rate': 2.494186046511628e-05, 'loss_1': 0.018146786838769913, 'loss_2': 0.0021228790283203125, 'loss_3': -15.851760864257812, 'loss_4': 2.0590415000915527, 'epoch': 5.08}
{'loss': 0.0263, 'grad_norm': 8.475849151611328, 'learning_rate': 2.493604651162791e-05, 'loss_1': 0.019299784675240517, 'loss_2': 0.00701904296875, 'loss_3': -15.932917594909668, 'loss_4': 2.210080862045288, 'epoch': 5.08}
{'loss': 0.0357, 'grad_norm': 16.07037925720215, 'learning_rate': 2.4930232558139535e-05, 'loss_1': 0.035405758768320084, 'loss_2': 0.0002589225769042969, 'loss_3': -15.937273025512695, 'loss_4': 2.0289835929870605, 'epoch': 5.09}
[INFO|trainer.py:4228] 2025-01-21 12:42:07,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:07,891 >>   Batch size = 64
 17%|█████████████████████████████████████▌                                                                                                                                                                                      | 880/5160 [22:12<1:14:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:15,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015997489914298058, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.892, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012934376485645771, 'eval_loss_2': 0.003063112497329712, 'eval_loss_3': -18.220626831054688, 'eval_loss_4': 2.2924675941467285, 'epoch': 5.09}
{'loss': 0.0228, 'grad_norm': 6.584693908691406, 'learning_rate': 2.4924418604651163e-05, 'loss_1': 0.01764541305601597, 'loss_2': 0.005126953125, 'loss_3': -16.08623504638672, 'loss_4': 2.370826005935669, 'epoch': 5.09}
{'loss': 0.0165, 'grad_norm': 6.043041229248047, 'learning_rate': 2.4918604651162792e-05, 'loss_1': 0.012054121121764183, 'loss_2': 0.00444793701171875, 'loss_3': -15.925674438476562, 'loss_4': 2.1787261962890625, 'epoch': 5.1}
{'loss': 0.0506, 'grad_norm': 14.453914642333984, 'learning_rate': 2.491279069767442e-05, 'loss_1': 0.04402933642268181, 'loss_2': 0.00659942626953125, 'loss_3': -15.64665412902832, 'loss_4': 2.502748966217041, 'epoch': 5.1}
{'loss': 0.0247, 'grad_norm': 8.982498168945312, 'learning_rate': 2.4906976744186046e-05, 'loss_1': 0.023457184433937073, 'loss_2': 0.0012378692626953125, 'loss_3': -15.964433670043945, 'loss_4': 2.137943744659424, 'epoch': 5.11}
{'loss': 0.0346, 'grad_norm': 16.455997467041016, 'learning_rate': 2.4901162790697674e-05, 'loss_1': 0.0332128182053566, 'loss_2': 0.00136566162109375, 'loss_3': -15.877821922302246, 'loss_4': 2.1712048053741455, 'epoch': 5.12}
[INFO|trainer.py:4228] 2025-01-21 12:42:15,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:15,262 >>   Batch size = 64
 17%|█████████████████████████████████████▋                                                                                                                                                                                      | 885/5160 [22:19<1:14:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:22,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015351985581219196, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.819, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011886468157172203, 'eval_loss_2': 0.003465518355369568, 'eval_loss_3': -18.27851104736328, 'eval_loss_4': 2.382859230041504, 'epoch': 5.12}
{'loss': 0.057, 'grad_norm': 18.611289978027344, 'learning_rate': 2.4895348837209303e-05, 'loss_1': 0.0520215667784214, 'loss_2': 0.00502777099609375, 'loss_3': -15.906723976135254, 'loss_4': 2.4775824546813965, 'epoch': 5.12}
{'loss': 0.0307, 'grad_norm': 8.653709411621094, 'learning_rate': 2.488953488372093e-05, 'loss_1': 0.026569152250885963, 'loss_2': 0.0041656494140625, 'loss_3': -15.935964584350586, 'loss_4': 2.352595806121826, 'epoch': 5.13}
{'loss': 0.0243, 'grad_norm': 7.586522102355957, 'learning_rate': 2.488372093023256e-05, 'loss_1': 0.022235365584492683, 'loss_2': 0.0020198822021484375, 'loss_3': -16.00609016418457, 'loss_4': 2.204610824584961, 'epoch': 5.13}
{'loss': 0.1383, 'grad_norm': 35.66656494140625, 'learning_rate': 2.4877906976744186e-05, 'loss_1': 0.13247305154800415, 'loss_2': 0.005817413330078125, 'loss_3': -15.899385452270508, 'loss_4': 3.252791166305542, 'epoch': 5.14}
{'loss': 0.0302, 'grad_norm': 10.22486400604248, 'learning_rate': 2.4872093023255814e-05, 'loss_1': 0.029297029599547386, 'loss_2': 0.0008587837219238281, 'loss_3': -15.899179458618164, 'loss_4': 2.7344138622283936, 'epoch': 5.15}
[INFO|trainer.py:4228] 2025-01-21 12:42:22,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:22,637 >>   Batch size = 64
 17%|█████████████████████████████████████▉                                                                                                                                                                                      | 890/5160 [22:27<1:14:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:30,013 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01673313044011593, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.02, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012467958964407444, 'eval_loss_2': 0.0042651742696762085, 'eval_loss_3': -18.3008975982666, 'eval_loss_4': 2.3961095809936523, 'epoch': 5.15}
{'loss': 0.0219, 'grad_norm': 6.019128799438477, 'learning_rate': 2.4866279069767443e-05, 'loss_1': 0.01424811314791441, 'loss_2': 0.00768280029296875, 'loss_3': -15.947903633117676, 'loss_4': 1.7482060194015503, 'epoch': 5.15}
{'loss': 0.0221, 'grad_norm': 7.975317001342773, 'learning_rate': 2.486046511627907e-05, 'loss_1': 0.018962396308779716, 'loss_2': 0.0030918121337890625, 'loss_3': -15.971954345703125, 'loss_4': 2.9608030319213867, 'epoch': 5.16}
{'loss': 0.0297, 'grad_norm': 9.787994384765625, 'learning_rate': 2.48546511627907e-05, 'loss_1': 0.027733149006962776, 'loss_2': 0.0019435882568359375, 'loss_3': -15.912978172302246, 'loss_4': 1.886136770248413, 'epoch': 5.16}
{'loss': 0.0394, 'grad_norm': 14.25369930267334, 'learning_rate': 2.4848837209302325e-05, 'loss_1': 0.033921994268894196, 'loss_2': 0.005428314208984375, 'loss_3': -16.095394134521484, 'loss_4': 2.076000213623047, 'epoch': 5.17}
{'loss': 0.0284, 'grad_norm': 11.247450828552246, 'learning_rate': 2.4843023255813954e-05, 'loss_1': 0.02709430269896984, 'loss_2': 0.0013399124145507812, 'loss_3': -15.853729248046875, 'loss_4': 1.4513258934020996, 'epoch': 5.17}
[INFO|trainer.py:4228] 2025-01-21 12:42:30,014 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:30,014 >>   Batch size = 64
 17%|██████████████████████████████████████▏                                                                                                                                                                                     | 895/5160 [22:34<1:13:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:37,375 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0176069475710392, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.053, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.012116673402488232, 'eval_loss_2': 0.0054902732372283936, 'eval_loss_3': -18.309017181396484, 'eval_loss_4': 1.978325366973877, 'epoch': 5.17}
{'loss': 0.0292, 'grad_norm': 6.886704444885254, 'learning_rate': 2.483720930232558e-05, 'loss_1': 0.021889392286539078, 'loss_2': 0.0073089599609375, 'loss_3': -16.165889739990234, 'loss_4': 1.7995473146438599, 'epoch': 5.18}
{'loss': 0.0272, 'grad_norm': 6.610238552093506, 'learning_rate': 2.483139534883721e-05, 'loss_1': 0.019901342689990997, 'loss_2': 0.007320404052734375, 'loss_3': -15.967020034790039, 'loss_4': 1.8283283710479736, 'epoch': 5.19}
{'loss': 0.0455, 'grad_norm': 17.0721492767334, 'learning_rate': 2.482558139534884e-05, 'loss_1': 0.043115805834531784, 'loss_2': 0.0024204254150390625, 'loss_3': -15.736539840698242, 'loss_4': 1.7814862728118896, 'epoch': 5.19}
{'loss': 0.016, 'grad_norm': 6.199958801269531, 'learning_rate': 2.4819767441860465e-05, 'loss_1': 0.01309887133538723, 'loss_2': 0.00293731689453125, 'loss_3': -15.895776748657227, 'loss_4': 1.284860610961914, 'epoch': 5.2}
{'loss': 0.0263, 'grad_norm': 7.948736190795898, 'learning_rate': 2.4813953488372094e-05, 'loss_1': 0.022585827857255936, 'loss_2': 0.0036716461181640625, 'loss_3': -16.04212188720703, 'loss_4': 1.4551191329956055, 'epoch': 5.2}
[INFO|trainer.py:4228] 2025-01-21 12:42:37,375 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:37,375 >>   Batch size = 64
 17%|██████████████████████████████████████▎                                                                                                                                                                                     | 900/5160 [22:41<1:13:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:44,749 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014258794486522675, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011520430445671082, 'eval_loss_2': 0.002738364040851593, 'eval_loss_3': -18.260461807250977, 'eval_loss_4': 1.6776292324066162, 'epoch': 5.2}
{'loss': 0.0238, 'grad_norm': 6.605022430419922, 'learning_rate': 2.480813953488372e-05, 'loss_1': 0.019305724650621414, 'loss_2': 0.00453948974609375, 'loss_3': -15.854673385620117, 'loss_4': 1.521744728088379, 'epoch': 5.21}
{'loss': 0.1514, 'grad_norm': 28.12996482849121, 'learning_rate': 2.480232558139535e-05, 'loss_1': 0.14149507880210876, 'loss_2': 0.00986480712890625, 'loss_3': -15.998774528503418, 'loss_4': 2.3651745319366455, 'epoch': 5.22}
{'loss': 0.0276, 'grad_norm': 8.03424072265625, 'learning_rate': 2.479651162790698e-05, 'loss_1': 0.021016009151935577, 'loss_2': 0.0066070556640625, 'loss_3': -15.824616432189941, 'loss_4': 1.1241812705993652, 'epoch': 5.22}
{'loss': 0.0184, 'grad_norm': 6.373186111450195, 'learning_rate': 2.4790697674418605e-05, 'loss_1': 0.016303405165672302, 'loss_2': 0.0021228790283203125, 'loss_3': -15.777477264404297, 'loss_4': 1.356041669845581, 'epoch': 5.23}
{'loss': 0.0457, 'grad_norm': 9.448854446411133, 'learning_rate': 2.4784883720930233e-05, 'loss_1': 0.027516115456819534, 'loss_2': 0.0181732177734375, 'loss_3': -16.013648986816406, 'loss_4': 1.832137942314148, 'epoch': 5.23}
[INFO|trainer.py:4228] 2025-01-21 12:42:44,749 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:44,749 >>   Batch size = 64
 18%|██████████████████████████████████████▌                                                                                                                                                                                     | 905/5160 [22:49<1:13:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:52,127 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01793583109974861, 'eval_runtime': 3.8227, 'eval_samples_per_second': 267.873, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.01423545554280281, 'eval_loss_2': 0.0037003755569458008, 'eval_loss_3': -18.179685592651367, 'eval_loss_4': 1.7502306699752808, 'epoch': 5.23}
{'loss': 0.013, 'grad_norm': 7.5327067375183105, 'learning_rate': 2.477906976744186e-05, 'loss_1': 0.012053034268319607, 'loss_2': 0.0009627342224121094, 'loss_3': -15.911958694458008, 'loss_4': 1.5285871028900146, 'epoch': 5.24}
{'loss': 0.0263, 'grad_norm': 9.113565444946289, 'learning_rate': 2.477325581395349e-05, 'loss_1': 0.02444654330611229, 'loss_2': 0.0018129348754882812, 'loss_3': -15.866403579711914, 'loss_4': 1.6958534717559814, 'epoch': 5.24}
{'loss': 0.0235, 'grad_norm': 7.260190963745117, 'learning_rate': 2.4767441860465116e-05, 'loss_1': 0.020107371732592583, 'loss_2': 0.0033664703369140625, 'loss_3': -16.01311492919922, 'loss_4': 1.7621665000915527, 'epoch': 5.25}
{'loss': 0.0384, 'grad_norm': 14.435843467712402, 'learning_rate': 2.4761627906976745e-05, 'loss_1': 0.03675713762640953, 'loss_2': 0.0016393661499023438, 'loss_3': -15.852158546447754, 'loss_4': 1.7029625177383423, 'epoch': 5.26}
{'loss': 0.0272, 'grad_norm': 12.620467185974121, 'learning_rate': 2.4755813953488373e-05, 'loss_1': 0.024009160697460175, 'loss_2': 0.0032196044921875, 'loss_3': -15.840078353881836, 'loss_4': 1.8755693435668945, 'epoch': 5.26}
[INFO|trainer.py:4228] 2025-01-21 12:42:52,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:52,127 >>   Batch size = 64
 18%|██████████████████████████████████████▊                                                                                                                                                                                     | 910/5160 [22:56<1:13:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:42:59,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03187229484319687, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.641, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.025570299476385117, 'eval_loss_2': 0.006301999092102051, 'eval_loss_3': -18.133485794067383, 'eval_loss_4': 2.2457029819488525, 'epoch': 5.26}
{'loss': 0.0215, 'grad_norm': 5.5431809425354, 'learning_rate': 2.475e-05, 'loss_1': 0.011997084133327007, 'loss_2': 0.009521484375, 'loss_3': -16.065935134887695, 'loss_4': 1.7867834568023682, 'epoch': 5.27}
{'loss': 0.0205, 'grad_norm': 6.540831565856934, 'learning_rate': 2.474418604651163e-05, 'loss_1': 0.016214914619922638, 'loss_2': 0.004241943359375, 'loss_3': -15.855045318603516, 'loss_4': 1.9111618995666504, 'epoch': 5.27}
{'loss': 0.0299, 'grad_norm': 11.293350219726562, 'learning_rate': 2.4738372093023256e-05, 'loss_1': 0.026769913733005524, 'loss_2': 0.003116607666015625, 'loss_3': -15.604177474975586, 'loss_4': 2.476226568222046, 'epoch': 5.28}
{'loss': 0.0387, 'grad_norm': 18.98756980895996, 'learning_rate': 2.4732558139534884e-05, 'loss_1': 0.033850524574518204, 'loss_2': 0.0048370361328125, 'loss_3': -16.018144607543945, 'loss_4': 2.5274007320404053, 'epoch': 5.28}
{'loss': 0.0259, 'grad_norm': 9.188462257385254, 'learning_rate': 2.4726744186046513e-05, 'loss_1': 0.02551574818789959, 'loss_2': 0.0003905296325683594, 'loss_3': -15.688663482666016, 'loss_4': 2.752418279647827, 'epoch': 5.29}
[INFO|trainer.py:4228] 2025-01-21 12:42:59,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:42:59,499 >>   Batch size = 64
 18%|███████████████████████████████████████                                                                                                                                                                                     | 915/5160 [23:04<1:13:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:06,875 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023798419162631035, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.136, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0202548336237669, 'eval_loss_2': 0.0035435855388641357, 'eval_loss_3': -18.167760848999023, 'eval_loss_4': 2.6812102794647217, 'epoch': 5.29}
{'loss': 0.052, 'grad_norm': 19.56672477722168, 'learning_rate': 2.4720930232558138e-05, 'loss_1': 0.05190087482333183, 'loss_2': 6.824731826782227e-05, 'loss_3': -15.840852737426758, 'loss_4': 2.4694466590881348, 'epoch': 5.3}
{'loss': 0.0318, 'grad_norm': 11.084589958190918, 'learning_rate': 2.471511627906977e-05, 'loss_1': 0.030920444056391716, 'loss_2': 0.0008726119995117188, 'loss_3': -15.857137680053711, 'loss_4': 2.6012964248657227, 'epoch': 5.3}
{'loss': 0.0181, 'grad_norm': 6.454715728759766, 'learning_rate': 2.4709302325581396e-05, 'loss_1': 0.014870662242174149, 'loss_2': 0.00322723388671875, 'loss_3': -15.840993881225586, 'loss_4': 2.876141309738159, 'epoch': 5.31}
{'loss': 0.02, 'grad_norm': 7.271457672119141, 'learning_rate': 2.4703488372093024e-05, 'loss_1': 0.017974013462662697, 'loss_2': 0.001995086669921875, 'loss_3': -15.773929595947266, 'loss_4': 2.596764087677002, 'epoch': 5.31}
{'loss': 0.0288, 'grad_norm': 6.093356132507324, 'learning_rate': 2.469767441860465e-05, 'loss_1': 0.017547670751810074, 'loss_2': 0.011260986328125, 'loss_3': -15.990519523620605, 'loss_4': 2.7364678382873535, 'epoch': 5.32}
[INFO|trainer.py:4228] 2025-01-21 12:43:06,875 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:06,876 >>   Batch size = 64
 18%|███████████████████████████████████████▏                                                                                                                                                                                    | 920/5160 [23:11<1:13:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:14,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014355405233800411, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.377, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.011015101335942745, 'eval_loss_2': 0.003340303897857666, 'eval_loss_3': -18.26688003540039, 'eval_loss_4': 2.75435733795166, 'epoch': 5.32}
{'loss': 0.0231, 'grad_norm': 7.057753562927246, 'learning_rate': 2.4691860465116278e-05, 'loss_1': 0.02298957295715809, 'loss_2': 0.00015354156494140625, 'loss_3': -16.14533042907715, 'loss_4': 3.1415529251098633, 'epoch': 5.33}
{'loss': 0.032, 'grad_norm': 8.193893432617188, 'learning_rate': 2.468604651162791e-05, 'loss_1': 0.025396309792995453, 'loss_2': 0.006557464599609375, 'loss_3': -16.119449615478516, 'loss_4': 2.5512938499450684, 'epoch': 5.33}
{'loss': 0.025, 'grad_norm': 7.835959434509277, 'learning_rate': 2.4680232558139535e-05, 'loss_1': 0.020524587482213974, 'loss_2': 0.00452423095703125, 'loss_3': -15.964569091796875, 'loss_4': 2.9503140449523926, 'epoch': 5.34}
{'loss': 0.0283, 'grad_norm': 8.326959609985352, 'learning_rate': 2.4674418604651164e-05, 'loss_1': 0.025528540834784508, 'loss_2': 0.002780914306640625, 'loss_3': -15.864577293395996, 'loss_4': 2.5557589530944824, 'epoch': 5.34}
{'loss': 0.0156, 'grad_norm': 6.118647575378418, 'learning_rate': 2.466860465116279e-05, 'loss_1': 0.013993144035339355, 'loss_2': 0.001617431640625, 'loss_3': -15.967313766479492, 'loss_4': 2.829218864440918, 'epoch': 5.35}
[INFO|trainer.py:4228] 2025-01-21 12:43:14,263 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:14,263 >>   Batch size = 64
 18%|███████████████████████████████████████▍                                                                                                                                                                                    | 925/5160 [23:18<1:13:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:21,648 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014855112880468369, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.308, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008942927233874798, 'eval_loss_2': 0.005912184715270996, 'eval_loss_3': -18.24502944946289, 'eval_loss_4': 2.611191749572754, 'epoch': 5.35}
{'loss': 0.0226, 'grad_norm': 6.5670952796936035, 'learning_rate': 2.4662790697674418e-05, 'loss_1': 0.014799335040152073, 'loss_2': 0.007843017578125, 'loss_3': -15.910870552062988, 'loss_4': 2.856454849243164, 'epoch': 5.35}
{'loss': 0.0284, 'grad_norm': 13.343806266784668, 'learning_rate': 2.465697674418605e-05, 'loss_1': 0.02635611966252327, 'loss_2': 0.002056121826171875, 'loss_3': -15.878327369689941, 'loss_4': 2.330864429473877, 'epoch': 5.36}
{'loss': 0.0307, 'grad_norm': 15.805314064025879, 'learning_rate': 2.4651162790697675e-05, 'loss_1': 0.028145408257842064, 'loss_2': 0.002597808837890625, 'loss_3': -15.793025970458984, 'loss_4': 2.194382429122925, 'epoch': 5.37}
{'loss': 0.0255, 'grad_norm': 6.475462436676025, 'learning_rate': 2.4645348837209304e-05, 'loss_1': 0.0157649964094162, 'loss_2': 0.0096893310546875, 'loss_3': -15.762212753295898, 'loss_4': 2.033634662628174, 'epoch': 5.37}
{'loss': 0.1056, 'grad_norm': 20.106658935546875, 'learning_rate': 2.463953488372093e-05, 'loss_1': 0.10313532501459122, 'loss_2': 0.0024890899658203125, 'loss_3': -15.857690811157227, 'loss_4': 1.935410976409912, 'epoch': 5.38}
[INFO|trainer.py:4228] 2025-01-21 12:43:21,648 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:21,648 >>   Batch size = 64
 18%|███████████████████████████████████████▋                                                                                                                                                                                    | 930/5160 [23:26<1:13:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:29,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013723050244152546, 'eval_runtime': 3.8273, 'eval_samples_per_second': 267.554, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.008363811299204826, 'eval_loss_2': 0.005359239876270294, 'eval_loss_3': -18.232561111450195, 'eval_loss_4': 2.254305362701416, 'epoch': 5.38}
{'loss': 0.0201, 'grad_norm': 6.323119163513184, 'learning_rate': 2.4633720930232558e-05, 'loss_1': 0.010676831007003784, 'loss_2': 0.0094146728515625, 'loss_3': -15.718831062316895, 'loss_4': 2.0627074241638184, 'epoch': 5.38}
{'loss': 0.0115, 'grad_norm': 5.239357948303223, 'learning_rate': 2.4627906976744186e-05, 'loss_1': 0.009452189318835735, 'loss_2': 0.002079010009765625, 'loss_3': -15.782248497009277, 'loss_4': 2.1528568267822266, 'epoch': 5.39}
{'loss': 0.021, 'grad_norm': 5.801895618438721, 'learning_rate': 2.4622093023255815e-05, 'loss_1': 0.015315981581807137, 'loss_2': 0.00567626953125, 'loss_3': -15.88339614868164, 'loss_4': 1.7614021301269531, 'epoch': 5.4}
{'loss': 0.0335, 'grad_norm': 9.526742935180664, 'learning_rate': 2.4616279069767444e-05, 'loss_1': 0.02489577606320381, 'loss_2': 0.008636474609375, 'loss_3': -15.764701843261719, 'loss_4': 1.6513406038284302, 'epoch': 5.4}
{'loss': 0.0206, 'grad_norm': 12.390347480773926, 'learning_rate': 2.461046511627907e-05, 'loss_1': 0.02024400234222412, 'loss_2': 0.00040149688720703125, 'loss_3': -15.817719459533691, 'loss_4': 2.5167195796966553, 'epoch': 5.41}
[INFO|trainer.py:4228] 2025-01-21 12:43:29,042 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:29,042 >>   Batch size = 64
 18%|███████████████████████████████████████▊                                                                                                                                                                                    | 935/5160 [23:33<1:13:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:36,413 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01180620864033699, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.542, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007340145297348499, 'eval_loss_2': 0.004466064274311066, 'eval_loss_3': -18.20823860168457, 'eval_loss_4': 1.9673898220062256, 'epoch': 5.41}
{'loss': 0.0265, 'grad_norm': 9.013806343078613, 'learning_rate': 2.4604651162790697e-05, 'loss_1': 0.02043759450316429, 'loss_2': 0.006099700927734375, 'loss_3': -15.912334442138672, 'loss_4': 1.708089828491211, 'epoch': 5.41}
{'loss': 0.0203, 'grad_norm': 5.657679080963135, 'learning_rate': 2.4598837209302326e-05, 'loss_1': 0.012827984988689423, 'loss_2': 0.00751495361328125, 'loss_3': -15.859907150268555, 'loss_4': 1.9326915740966797, 'epoch': 5.42}
{'loss': 0.0235, 'grad_norm': 8.24068546295166, 'learning_rate': 2.4593023255813955e-05, 'loss_1': 0.015045611187815666, 'loss_2': 0.00844573974609375, 'loss_3': -15.855119705200195, 'loss_4': 1.628402590751648, 'epoch': 5.42}
{'loss': 0.0338, 'grad_norm': 11.169955253601074, 'learning_rate': 2.4587209302325583e-05, 'loss_1': 0.025438081473112106, 'loss_2': 0.00836181640625, 'loss_3': -15.645147323608398, 'loss_4': 1.9435651302337646, 'epoch': 5.43}
{'loss': 0.0236, 'grad_norm': 8.119963645935059, 'learning_rate': 2.458139534883721e-05, 'loss_1': 0.01763780228793621, 'loss_2': 0.005939483642578125, 'loss_3': -15.74709701538086, 'loss_4': 1.3726707696914673, 'epoch': 5.44}
[INFO|trainer.py:4228] 2025-01-21 12:43:36,414 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:36,414 >>   Batch size = 64
 18%|████████████████████████████████████████                                                                                                                                                                                    | 940/5160 [23:40<1:13:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:43,789 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015015202574431896, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.543, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007098275236785412, 'eval_loss_2': 0.007916927337646484, 'eval_loss_3': -18.147232055664062, 'eval_loss_4': 1.5016642808914185, 'epoch': 5.44}
{'loss': 0.0152, 'grad_norm': 5.408026218414307, 'learning_rate': 2.4575581395348837e-05, 'loss_1': 0.009801342152059078, 'loss_2': 0.00537872314453125, 'loss_3': -15.808808326721191, 'loss_4': 1.8118619918823242, 'epoch': 5.44}
{'loss': 0.038, 'grad_norm': 15.643167495727539, 'learning_rate': 2.4569767441860466e-05, 'loss_1': 0.02792118862271309, 'loss_2': 0.0100555419921875, 'loss_3': -16.03380012512207, 'loss_4': 1.091102123260498, 'epoch': 5.45}
{'loss': 0.0406, 'grad_norm': 10.87019157409668, 'learning_rate': 2.4563953488372094e-05, 'loss_1': 0.03496589511632919, 'loss_2': 0.005615234375, 'loss_3': -15.994400978088379, 'loss_4': 1.1004835367202759, 'epoch': 5.45}
{'loss': 0.078, 'grad_norm': 28.56908416748047, 'learning_rate': 2.455813953488372e-05, 'loss_1': 0.0660872682929039, 'loss_2': 0.0118865966796875, 'loss_3': -15.926712036132812, 'loss_4': 1.729426383972168, 'epoch': 5.46}
{'loss': 0.0166, 'grad_norm': 5.412227630615234, 'learning_rate': 2.4552325581395348e-05, 'loss_1': 0.009643944911658764, 'loss_2': 0.0069732666015625, 'loss_3': -16.05072593688965, 'loss_4': 1.1373437643051147, 'epoch': 5.47}
[INFO|trainer.py:4228] 2025-01-21 12:43:43,789 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:43,789 >>   Batch size = 64
 18%|████████████████████████████████████████▎                                                                                                                                                                                   | 945/5160 [23:48<1:13:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:51,173 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02009643241763115, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.233, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.008885754272341728, 'eval_loss_2': 0.01121068000793457, 'eval_loss_3': -18.09001350402832, 'eval_loss_4': 0.9890639781951904, 'epoch': 5.47}
{'loss': 0.0412, 'grad_norm': 10.275693893432617, 'learning_rate': 2.454651162790698e-05, 'loss_1': 0.03665432333946228, 'loss_2': 0.0045166015625, 'loss_3': -15.701223373413086, 'loss_4': 1.161623239517212, 'epoch': 5.47}
{'loss': 0.0219, 'grad_norm': 11.097747802734375, 'learning_rate': 2.4540697674418606e-05, 'loss_1': 0.01856340654194355, 'loss_2': 0.0033016204833984375, 'loss_3': -16.152854919433594, 'loss_4': 1.1998943090438843, 'epoch': 5.48}
{'loss': 0.0141, 'grad_norm': 5.245055198669434, 'learning_rate': 2.4534883720930234e-05, 'loss_1': 0.007656525820493698, 'loss_2': 0.0064544677734375, 'loss_3': -15.843076705932617, 'loss_4': 0.9751261472702026, 'epoch': 5.48}
{'loss': 0.0152, 'grad_norm': 6.755849361419678, 'learning_rate': 2.452906976744186e-05, 'loss_1': 0.013917933218181133, 'loss_2': 0.0012340545654296875, 'loss_3': -15.871912956237793, 'loss_4': 0.8791831731796265, 'epoch': 5.49}
{'loss': 0.02, 'grad_norm': 6.5084757804870605, 'learning_rate': 2.4523255813953488e-05, 'loss_1': 0.011472067795693874, 'loss_2': 0.0085296630859375, 'loss_3': -16.081052780151367, 'loss_4': 0.47680291533470154, 'epoch': 5.49}
[INFO|trainer.py:4228] 2025-01-21 12:43:51,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:51,174 >>   Batch size = 64
 18%|████████████████████████████████████████▌                                                                                                                                                                                   | 950/5160 [23:55<1:13:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:43:58,552 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012975024059414864, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.383, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.008727089501917362, 'eval_loss_2': 0.004247933626174927, 'eval_loss_3': -18.154603958129883, 'eval_loss_4': 0.8336493968963623, 'epoch': 5.49}
{'loss': 0.0201, 'grad_norm': 9.088201522827148, 'learning_rate': 2.451744186046512e-05, 'loss_1': 0.01379898376762867, 'loss_2': 0.00634765625, 'loss_3': -15.846639633178711, 'loss_4': 0.7673578858375549, 'epoch': 5.5}
{'loss': 0.0349, 'grad_norm': 17.362951278686523, 'learning_rate': 2.4511627906976745e-05, 'loss_1': 0.021616142243146896, 'loss_2': 0.0133056640625, 'loss_3': -15.935043334960938, 'loss_4': 0.8007471561431885, 'epoch': 5.51}
{'loss': 0.0202, 'grad_norm': 5.797778606414795, 'learning_rate': 2.4505813953488374e-05, 'loss_1': 0.010836141183972359, 'loss_2': 0.00937652587890625, 'loss_3': -15.855696678161621, 'loss_4': 0.6748827695846558, 'epoch': 5.51}
{'loss': 0.027, 'grad_norm': 7.691203594207764, 'learning_rate': 2.45e-05, 'loss_1': 0.013123276643455029, 'loss_2': 0.01392364501953125, 'loss_3': -15.808540344238281, 'loss_4': 1.2940795421600342, 'epoch': 5.52}
{'loss': 0.0528, 'grad_norm': 16.00599479675293, 'learning_rate': 2.4494186046511628e-05, 'loss_1': 0.03260352090001106, 'loss_2': 0.020172119140625, 'loss_3': -15.748392105102539, 'loss_4': 0.21257975697517395, 'epoch': 5.52}
[INFO|trainer.py:4228] 2025-01-21 12:43:58,552 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:43:58,552 >>   Batch size = 64
 19%|████████████████████████████████████████▋                                                                                                                                                                                   | 955/5160 [24:03<1:13:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:05,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01268325001001358, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.427, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.008269764482975006, 'eval_loss_2': 0.004413485527038574, 'eval_loss_3': -18.179702758789062, 'eval_loss_4': 0.83173668384552, 'epoch': 5.52}
{'loss': 0.0736, 'grad_norm': 16.872404098510742, 'learning_rate': 2.4488372093023256e-05, 'loss_1': 0.06994336098432541, 'loss_2': 0.003704071044921875, 'loss_3': -16.108383178710938, 'loss_4': 1.4074854850769043, 'epoch': 5.53}
{'loss': 0.0087, 'grad_norm': 4.590095043182373, 'learning_rate': 2.4482558139534885e-05, 'loss_1': 0.008618905209004879, 'loss_2': 7.045269012451172e-05, 'loss_3': -15.936166763305664, 'loss_4': 1.4308172464370728, 'epoch': 5.53}
{'loss': 0.0199, 'grad_norm': 5.678926944732666, 'learning_rate': 2.4476744186046514e-05, 'loss_1': 0.009906986728310585, 'loss_2': 0.01001739501953125, 'loss_3': -15.870576858520508, 'loss_4': 1.146702527999878, 'epoch': 5.54}
{'loss': 0.0123, 'grad_norm': 6.929126739501953, 'learning_rate': 2.447093023255814e-05, 'loss_1': 0.01221091952174902, 'loss_2': 0.00013446807861328125, 'loss_3': -16.020263671875, 'loss_4': 0.45525822043418884, 'epoch': 5.55}
{'loss': 0.0139, 'grad_norm': 4.805466651916504, 'learning_rate': 2.4465116279069768e-05, 'loss_1': 0.00895377341657877, 'loss_2': 0.004985809326171875, 'loss_3': -16.112289428710938, 'loss_4': 1.1360384225845337, 'epoch': 5.55}
[INFO|trainer.py:4228] 2025-01-21 12:44:05,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:05,933 >>   Batch size = 64
 19%|████████████████████████████████████████▉                                                                                                                                                                                   | 960/5160 [24:10<1:13:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:13,321 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017015356570482254, 'eval_runtime': 3.8268, 'eval_samples_per_second': 267.583, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.008197206072509289, 'eval_loss_2': 0.00881814956665039, 'eval_loss_3': -18.21023178100586, 'eval_loss_4': 0.846480131149292, 'epoch': 5.55}
{'loss': 0.0217, 'grad_norm': 9.388275146484375, 'learning_rate': 2.4459302325581396e-05, 'loss_1': 0.016832508146762848, 'loss_2': 0.004901885986328125, 'loss_3': -15.768960952758789, 'loss_4': 0.6740958094596863, 'epoch': 5.56}
{'loss': 0.0261, 'grad_norm': 7.135102272033691, 'learning_rate': 2.4453488372093025e-05, 'loss_1': 0.019522907212376595, 'loss_2': 0.006534576416015625, 'loss_3': -16.08868408203125, 'loss_4': 0.9567224979400635, 'epoch': 5.56}
{'loss': 0.0137, 'grad_norm': 5.945190906524658, 'learning_rate': 2.4447674418604654e-05, 'loss_1': 0.013581949286162853, 'loss_2': 0.0001367330551147461, 'loss_3': -15.938760757446289, 'loss_4': 0.5017687082290649, 'epoch': 5.57}
{'loss': 0.0267, 'grad_norm': 11.938878059387207, 'learning_rate': 2.444186046511628e-05, 'loss_1': 0.02361820824444294, 'loss_2': 0.0030517578125, 'loss_3': -15.8531494140625, 'loss_4': 1.0887205600738525, 'epoch': 5.58}
{'loss': 0.0257, 'grad_norm': 10.112421035766602, 'learning_rate': 2.4436046511627907e-05, 'loss_1': 0.020161963999271393, 'loss_2': 0.00551605224609375, 'loss_3': -16.011384963989258, 'loss_4': 0.9009710550308228, 'epoch': 5.58}
[INFO|trainer.py:4228] 2025-01-21 12:44:13,322 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:13,322 >>   Batch size = 64
 19%|█████████████████████████████████████████▏                                                                                                                                                                                  | 965/5160 [24:17<1:12:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:20,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014000685885548592, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.608, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01034546084702015, 'eval_loss_2': 0.0036552250385284424, 'eval_loss_3': -18.22075653076172, 'eval_loss_4': 0.754332423210144, 'epoch': 5.58}
{'loss': 0.0165, 'grad_norm': 5.9251251220703125, 'learning_rate': 2.4430232558139536e-05, 'loss_1': 0.011008869856595993, 'loss_2': 0.0054473876953125, 'loss_3': -16.178817749023438, 'loss_4': 0.7713663578033447, 'epoch': 5.59}
{'loss': 0.0654, 'grad_norm': 18.788787841796875, 'learning_rate': 2.4424418604651165e-05, 'loss_1': 0.06321221590042114, 'loss_2': 0.00215911865234375, 'loss_3': -16.108352661132812, 'loss_4': 0.9371739029884338, 'epoch': 5.59}
{'loss': 0.0195, 'grad_norm': 7.717349529266357, 'learning_rate': 2.441860465116279e-05, 'loss_1': 0.016638176515698433, 'loss_2': 0.0028934478759765625, 'loss_3': -15.92770004272461, 'loss_4': 0.6805349588394165, 'epoch': 5.6}
{'loss': 0.0257, 'grad_norm': 9.82505989074707, 'learning_rate': 2.441279069767442e-05, 'loss_1': 0.020416030660271645, 'loss_2': 0.005252838134765625, 'loss_3': -16.046127319335938, 'loss_4': 0.9180871844291687, 'epoch': 5.6}
{'loss': 0.0416, 'grad_norm': 27.292593002319336, 'learning_rate': 2.4406976744186047e-05, 'loss_1': 0.04033975675702095, 'loss_2': 0.001232147216796875, 'loss_3': -15.922135353088379, 'loss_4': 0.443602055311203, 'epoch': 5.61}
[INFO|trainer.py:4228] 2025-01-21 12:44:20,685 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:20,685 >>   Batch size = 64
 19%|█████████████████████████████████████████▎                                                                                                                                                                                  | 970/5160 [24:25<1:12:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:28,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016291897743940353, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.769, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.011705335229635239, 'eval_loss_2': 0.004586562514305115, 'eval_loss_3': -18.16714859008789, 'eval_loss_4': 0.714659571647644, 'epoch': 5.61}
{'loss': 0.0159, 'grad_norm': 6.1658196449279785, 'learning_rate': 2.4401162790697676e-05, 'loss_1': 0.01443085540086031, 'loss_2': 0.00147247314453125, 'loss_3': -16.034189224243164, 'loss_4': 0.3764902949333191, 'epoch': 5.62}
{'loss': 0.0342, 'grad_norm': 16.88196563720703, 'learning_rate': 2.4395348837209304e-05, 'loss_1': 0.034247756004333496, 'loss_2': 8.344650268554688e-07, 'loss_3': -15.997307777404785, 'loss_4': 0.9143999814987183, 'epoch': 5.62}
{'loss': 0.0192, 'grad_norm': 8.152750015258789, 'learning_rate': 2.438953488372093e-05, 'loss_1': 0.016175493597984314, 'loss_2': 0.003017425537109375, 'loss_3': -16.183475494384766, 'loss_4': 1.1590814590454102, 'epoch': 5.63}
{'loss': 0.0119, 'grad_norm': 5.209873199462891, 'learning_rate': 2.4383720930232558e-05, 'loss_1': 0.007859635166823864, 'loss_2': 0.004058837890625, 'loss_3': -15.913875579833984, 'loss_4': 1.0007317066192627, 'epoch': 5.63}
{'loss': 0.0164, 'grad_norm': 6.1087965965271, 'learning_rate': 2.4377906976744187e-05, 'loss_1': 0.01430748961865902, 'loss_2': 0.00206756591796875, 'loss_3': -16.08869743347168, 'loss_4': 0.05183775722980499, 'epoch': 5.64}
[INFO|trainer.py:4228] 2025-01-21 12:44:28,050 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:28,050 >>   Batch size = 64
 19%|█████████████████████████████████████████▌                                                                                                                                                                                  | 975/5160 [24:32<1:14:33,  1.07s/it][INFO|trainer.py:4226] 2025-01-21 12:44:35,602 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014834113419055939, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.973, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010584660805761814, 'eval_loss_2': 0.004249453544616699, 'eval_loss_3': -18.144027709960938, 'eval_loss_4': 0.556054949760437, 'epoch': 5.64}
{'loss': 0.0282, 'grad_norm': 14.336235046386719, 'learning_rate': 2.4372093023255816e-05, 'loss_1': 0.02632547914981842, 'loss_2': 0.0018453598022460938, 'loss_3': -15.778789520263672, 'loss_4': 0.3772541582584381, 'epoch': 5.65}
{'loss': 0.0155, 'grad_norm': 8.009923934936523, 'learning_rate': 2.4366279069767444e-05, 'loss_1': 0.014158091507852077, 'loss_2': 0.001377105712890625, 'loss_3': -16.006519317626953, 'loss_4': 0.5119020938873291, 'epoch': 5.65}
{'loss': 0.0202, 'grad_norm': 8.079313278198242, 'learning_rate': 2.436046511627907e-05, 'loss_1': 0.01704028993844986, 'loss_2': 0.00311279296875, 'loss_3': -16.10457992553711, 'loss_4': 1.2340669631958008, 'epoch': 5.66}
{'loss': 0.018, 'grad_norm': 6.993402481079102, 'learning_rate': 2.4354651162790698e-05, 'loss_1': 0.014546255581080914, 'loss_2': 0.00344085693359375, 'loss_3': -16.090412139892578, 'loss_4': 0.6879482865333557, 'epoch': 5.66}
{'loss': 0.0372, 'grad_norm': 16.238780975341797, 'learning_rate': 2.4348837209302323e-05, 'loss_1': 0.03695034980773926, 'loss_2': 0.0002193450927734375, 'loss_3': -15.745984077453613, 'loss_4': 1.5304737091064453, 'epoch': 5.67}
[INFO|trainer.py:4228] 2025-01-21 12:44:35,602 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:35,602 >>   Batch size = 64
 19%|█████████████████████████████████████████▊                                                                                                                                                                                  | 980/5160 [24:40<1:12:59,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:44:42,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018012089654803276, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.497, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.013920796103775501, 'eval_loss_2': 0.0040912926197052, 'eval_loss_3': -18.14670181274414, 'eval_loss_4': 0.912409245967865, 'epoch': 5.67}
{'loss': 0.0444, 'grad_norm': 13.354042053222656, 'learning_rate': 2.4343023255813955e-05, 'loss_1': 0.040293700993061066, 'loss_2': 0.00408172607421875, 'loss_3': -15.874022483825684, 'loss_4': 0.7554359436035156, 'epoch': 5.67}
{'loss': 0.0129, 'grad_norm': 6.969778537750244, 'learning_rate': 2.4337209302325584e-05, 'loss_1': 0.012762562371790409, 'loss_2': 0.00014138221740722656, 'loss_3': -15.910346984863281, 'loss_4': 0.35019028186798096, 'epoch': 5.68}
{'loss': 0.0356, 'grad_norm': 16.177642822265625, 'learning_rate': 2.433139534883721e-05, 'loss_1': 0.03407939895987511, 'loss_2': 0.0014810562133789062, 'loss_3': -16.224010467529297, 'loss_4': 1.6256399154663086, 'epoch': 5.69}
{'loss': 0.0412, 'grad_norm': 14.0264892578125, 'learning_rate': 2.4325581395348838e-05, 'loss_1': 0.0332038477063179, 'loss_2': 0.0079803466796875, 'loss_3': -16.242326736450195, 'loss_4': 1.2912254333496094, 'epoch': 5.69}
{'loss': 0.0169, 'grad_norm': 5.597218990325928, 'learning_rate': 2.4319767441860463e-05, 'loss_1': 0.011529223062098026, 'loss_2': 0.00534820556640625, 'loss_3': -16.00971221923828, 'loss_4': 1.659509539604187, 'epoch': 5.7}
[INFO|trainer.py:4228] 2025-01-21 12:44:42,983 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:42,983 >>   Batch size = 64
 19%|█████████████████████████████████████████▉                                                                                                                                                                                  | 985/5160 [24:47<1:12:43,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:44:50,374 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018792880699038506, 'eval_runtime': 3.825, 'eval_samples_per_second': 267.716, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.015412774868309498, 'eval_loss_2': 0.003380104899406433, 'eval_loss_3': -18.19283676147461, 'eval_loss_4': 1.6994788646697998, 'epoch': 5.7}
{'loss': 0.0317, 'grad_norm': 8.90186882019043, 'learning_rate': 2.4313953488372095e-05, 'loss_1': 0.023835059255361557, 'loss_2': 0.00783538818359375, 'loss_3': -16.11893081665039, 'loss_4': 1.9687613248825073, 'epoch': 5.7}
{'loss': 0.0384, 'grad_norm': 13.238929748535156, 'learning_rate': 2.4308139534883724e-05, 'loss_1': 0.03419043868780136, 'loss_2': 0.0042572021484375, 'loss_3': -15.965499877929688, 'loss_4': 1.9781365394592285, 'epoch': 5.71}
{'loss': 0.0275, 'grad_norm': 7.409235954284668, 'learning_rate': 2.430232558139535e-05, 'loss_1': 0.017537862062454224, 'loss_2': 0.00998687744140625, 'loss_3': -16.10717010498047, 'loss_4': 1.8401823043823242, 'epoch': 5.72}
{'loss': 0.042, 'grad_norm': 12.493573188781738, 'learning_rate': 2.4296511627906978e-05, 'loss_1': 0.034970495849847794, 'loss_2': 0.006999969482421875, 'loss_3': -16.143646240234375, 'loss_4': 2.483614444732666, 'epoch': 5.72}
{'loss': 0.0307, 'grad_norm': 8.143829345703125, 'learning_rate': 2.4290697674418603e-05, 'loss_1': 0.027751712128520012, 'loss_2': 0.002925872802734375, 'loss_3': -15.987199783325195, 'loss_4': 1.9899976253509521, 'epoch': 5.73}
[INFO|trainer.py:4228] 2025-01-21 12:44:50,374 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:50,374 >>   Batch size = 64
 19%|██████████████████████████████████████████▏                                                                                                                                                                                 | 990/5160 [24:54<1:12:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:44:57,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024400878697633743, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.289, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.020077930763363838, 'eval_loss_2': 0.004322946071624756, 'eval_loss_3': -18.222597122192383, 'eval_loss_4': 2.2373476028442383, 'epoch': 5.73}
{'loss': 0.0351, 'grad_norm': 12.550633430480957, 'learning_rate': 2.4284883720930235e-05, 'loss_1': 0.03398476168513298, 'loss_2': 0.0011138916015625, 'loss_3': -15.857878684997559, 'loss_4': 2.538731813430786, 'epoch': 5.73}
{'loss': 0.0298, 'grad_norm': 9.225664138793945, 'learning_rate': 2.427906976744186e-05, 'loss_1': 0.024698983877897263, 'loss_2': 0.005069732666015625, 'loss_3': -15.952404022216797, 'loss_4': 2.4100780487060547, 'epoch': 5.74}
{'loss': 0.0456, 'grad_norm': 10.992053031921387, 'learning_rate': 2.427325581395349e-05, 'loss_1': 0.03748558089137077, 'loss_2': 0.00807952880859375, 'loss_3': -16.171436309814453, 'loss_4': 2.7740488052368164, 'epoch': 5.74}
{'loss': 0.0491, 'grad_norm': 16.259355545043945, 'learning_rate': 2.4267441860465117e-05, 'loss_1': 0.04481380432844162, 'loss_2': 0.0043182373046875, 'loss_3': -16.008928298950195, 'loss_4': 2.8660881519317627, 'epoch': 5.75}
{'loss': 0.0288, 'grad_norm': 8.390451431274414, 'learning_rate': 2.4261627906976743e-05, 'loss_1': 0.027097925543785095, 'loss_2': 0.00174713134765625, 'loss_3': -16.022525787353516, 'loss_4': 2.8638710975646973, 'epoch': 5.76}
[INFO|trainer.py:4228] 2025-01-21 12:44:57,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:44:57,750 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                 | 995/5160 [25:02<1:12:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:05,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0243392176926136, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.268, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.018376503139734268, 'eval_loss_2': 0.0059627145528793335, 'eval_loss_3': -18.24887466430664, 'eval_loss_4': 2.47379732131958, 'epoch': 5.76}
{'loss': 0.0449, 'grad_norm': 13.424029350280762, 'learning_rate': 2.4255813953488375e-05, 'loss_1': 0.03708342835307121, 'loss_2': 0.00777435302734375, 'loss_3': -16.085229873657227, 'loss_4': 3.1567864418029785, 'epoch': 5.76}
{'loss': 0.0325, 'grad_norm': 7.15627908706665, 'learning_rate': 2.425e-05, 'loss_1': 0.024146195501089096, 'loss_2': 0.008392333984375, 'loss_3': -16.141847610473633, 'loss_4': 2.505443572998047, 'epoch': 5.77}
{'loss': 0.0631, 'grad_norm': 12.702847480773926, 'learning_rate': 2.424418604651163e-05, 'loss_1': 0.05928228050470352, 'loss_2': 0.0038299560546875, 'loss_3': -16.166452407836914, 'loss_4': 3.283459424972534, 'epoch': 5.77}
{'loss': 0.0413, 'grad_norm': 14.412399291992188, 'learning_rate': 2.4238372093023257e-05, 'loss_1': 0.038912758231163025, 'loss_2': 0.002429962158203125, 'loss_3': -16.041173934936523, 'loss_4': 2.496267795562744, 'epoch': 5.78}
{'loss': 0.0404, 'grad_norm': 9.827698707580566, 'learning_rate': 2.4232558139534882e-05, 'loss_1': 0.03213552385568619, 'loss_2': 0.0082244873046875, 'loss_3': -15.806682586669922, 'loss_4': 2.8145337104797363, 'epoch': 5.78}
[INFO|trainer.py:4228] 2025-01-21 12:45:05,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:05,132 >>   Batch size = 64
 19%|██████████████████████████████████████████▍                                                                                                                                                                                | 1000/5160 [25:09<1:12:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:12,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022194573655724525, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.599, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01696658879518509, 'eval_loss_2': 0.005227982997894287, 'eval_loss_3': -18.247203826904297, 'eval_loss_4': 2.5959463119506836, 'epoch': 5.78}
{'loss': 0.0569, 'grad_norm': 15.140151023864746, 'learning_rate': 2.4226744186046514e-05, 'loss_1': 0.044498786330223083, 'loss_2': 0.0124053955078125, 'loss_3': -15.851300239562988, 'loss_4': 2.601986885070801, 'epoch': 5.79}
{'loss': 0.0564, 'grad_norm': 21.14385986328125, 'learning_rate': 2.422093023255814e-05, 'loss_1': 0.05511676147580147, 'loss_2': 0.001247406005859375, 'loss_3': -15.884342193603516, 'loss_4': 2.913888454437256, 'epoch': 5.8}
{'loss': 0.0325, 'grad_norm': 8.749635696411133, 'learning_rate': 2.421511627906977e-05, 'loss_1': 0.030700761824846268, 'loss_2': 0.0017728805541992188, 'loss_3': -15.974404335021973, 'loss_4': 2.8815860748291016, 'epoch': 5.8}
{'loss': 0.0314, 'grad_norm': 9.734658241271973, 'learning_rate': 2.4209302325581394e-05, 'loss_1': 0.02233242243528366, 'loss_2': 0.00905609130859375, 'loss_3': -16.241470336914062, 'loss_4': 2.761916160583496, 'epoch': 5.81}
{'loss': 0.0349, 'grad_norm': 8.646357536315918, 'learning_rate': 2.4203488372093022e-05, 'loss_1': 0.025889409705996513, 'loss_2': 0.0090484619140625, 'loss_3': -15.979287147521973, 'loss_4': 3.1184775829315186, 'epoch': 5.81}
[INFO|trainer.py:4228] 2025-01-21 12:45:12,509 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:12,509 >>   Batch size = 64
 19%|██████████████████████████████████████████▋                                                                                                                                                                                | 1005/5160 [25:17<1:12:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:19,885 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01654769480228424, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.368, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.01361703872680664, 'eval_loss_2': 0.0029306560754776, 'eval_loss_3': -18.289642333984375, 'eval_loss_4': 2.6738972663879395, 'epoch': 5.81}
{'loss': 0.0431, 'grad_norm': 13.290905952453613, 'learning_rate': 2.4197674418604654e-05, 'loss_1': 0.041784077882766724, 'loss_2': 0.001338958740234375, 'loss_3': -16.147850036621094, 'loss_4': 1.978050708770752, 'epoch': 5.82}
{'loss': 0.0612, 'grad_norm': 17.016868591308594, 'learning_rate': 2.419186046511628e-05, 'loss_1': 0.05606161803007126, 'loss_2': 0.005157470703125, 'loss_3': -16.055770874023438, 'loss_4': 2.926755666732788, 'epoch': 5.83}
{'loss': 0.0444, 'grad_norm': 14.206135749816895, 'learning_rate': 2.4186046511627908e-05, 'loss_1': 0.03925465792417526, 'loss_2': 0.00516510009765625, 'loss_3': -15.888710021972656, 'loss_4': 2.790938377380371, 'epoch': 5.83}
{'loss': 0.0311, 'grad_norm': 9.339388847351074, 'learning_rate': 2.4180232558139533e-05, 'loss_1': 0.026659151539206505, 'loss_2': 0.004405975341796875, 'loss_3': -16.265411376953125, 'loss_4': 2.7193667888641357, 'epoch': 5.84}
{'loss': 0.0201, 'grad_norm': 5.751183986663818, 'learning_rate': 2.4174418604651165e-05, 'loss_1': 0.014017269015312195, 'loss_2': 0.00605010986328125, 'loss_3': -16.146957397460938, 'loss_4': 2.5817716121673584, 'epoch': 5.84}
[INFO|trainer.py:4228] 2025-01-21 12:45:19,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:19,885 >>   Batch size = 64
 20%|██████████████████████████████████████████▊                                                                                                                                                                                | 1010/5160 [25:24<1:12:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:27,261 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01719534769654274, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.172, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.009993914514780045, 'eval_loss_2': 0.007201433181762695, 'eval_loss_3': -18.288951873779297, 'eval_loss_4': 2.5988264083862305, 'epoch': 5.84}
{'loss': 0.0943, 'grad_norm': 17.824514389038086, 'learning_rate': 2.416860465116279e-05, 'loss_1': 0.09312645345926285, 'loss_2': 0.001178741455078125, 'loss_3': -16.125205993652344, 'loss_4': 3.214749336242676, 'epoch': 5.85}
{'loss': 0.0365, 'grad_norm': 8.417685508728027, 'learning_rate': 2.416279069767442e-05, 'loss_1': 0.025108492001891136, 'loss_2': 0.01141357421875, 'loss_3': -16.100799560546875, 'loss_4': 2.7581491470336914, 'epoch': 5.85}
{'loss': 0.0704, 'grad_norm': 27.93430519104004, 'learning_rate': 2.4156976744186048e-05, 'loss_1': 0.06900674104690552, 'loss_2': 0.0013446807861328125, 'loss_3': -16.05767059326172, 'loss_4': 2.840961456298828, 'epoch': 5.86}
{'loss': 0.0251, 'grad_norm': 8.038572311401367, 'learning_rate': 2.4151162790697673e-05, 'loss_1': 0.022274944931268692, 'loss_2': 0.0028018951416015625, 'loss_3': -16.200681686401367, 'loss_4': 3.0172696113586426, 'epoch': 5.87}
{'loss': 0.0504, 'grad_norm': 19.831527709960938, 'learning_rate': 2.4145348837209305e-05, 'loss_1': 0.0503201000392437, 'loss_2': 8.606910705566406e-05, 'loss_3': -16.10287857055664, 'loss_4': 2.6200437545776367, 'epoch': 5.87}
[INFO|trainer.py:4228] 2025-01-21 12:45:27,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:27,261 >>   Batch size = 64
 20%|███████████████████████████████████████████                                                                                                                                                                                | 1015/5160 [25:31<1:12:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:34,651 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014536595903337002, 'eval_runtime': 3.8246, 'eval_samples_per_second': 267.742, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.010550388135015965, 'eval_loss_2': 0.0039862096309661865, 'eval_loss_3': -18.31296157836914, 'eval_loss_4': 2.5980606079101562, 'epoch': 5.87}
{'loss': 0.0193, 'grad_norm': 6.2505574226379395, 'learning_rate': 2.413953488372093e-05, 'loss_1': 0.01676768623292446, 'loss_2': 0.0025310516357421875, 'loss_3': -16.228702545166016, 'loss_4': 2.6722583770751953, 'epoch': 5.88}
{'loss': 0.038, 'grad_norm': 16.13250160217285, 'learning_rate': 2.413372093023256e-05, 'loss_1': 0.03407946974039078, 'loss_2': 0.00396728515625, 'loss_3': -16.23063850402832, 'loss_4': 2.8886818885803223, 'epoch': 5.88}
{'loss': 0.021, 'grad_norm': 8.598686218261719, 'learning_rate': 2.4127906976744188e-05, 'loss_1': 0.018955230712890625, 'loss_2': 0.0019969940185546875, 'loss_3': -16.11430549621582, 'loss_4': 2.7315304279327393, 'epoch': 5.89}
{'loss': 0.0245, 'grad_norm': 7.490289688110352, 'learning_rate': 2.4122093023255813e-05, 'loss_1': 0.017799416556954384, 'loss_2': 0.006656646728515625, 'loss_3': -16.31816291809082, 'loss_4': 3.0523548126220703, 'epoch': 5.9}
{'loss': 0.0337, 'grad_norm': 9.927770614624023, 'learning_rate': 2.4116279069767445e-05, 'loss_1': 0.02766389213502407, 'loss_2': 0.00605010986328125, 'loss_3': -15.913095474243164, 'loss_4': 2.828115224838257, 'epoch': 5.9}
[INFO|trainer.py:4228] 2025-01-21 12:45:34,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:34,651 >>   Batch size = 64
 20%|███████████████████████████████████████████▎                                                                                                                                                                               | 1020/5160 [25:39<1:11:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:42,031 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014886599034070969, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.322, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.01021501049399376, 'eval_loss_2': 0.0046715885400772095, 'eval_loss_3': -18.333251953125, 'eval_loss_4': 2.496523380279541, 'epoch': 5.9}
{'loss': 0.0402, 'grad_norm': 14.368205070495605, 'learning_rate': 2.411046511627907e-05, 'loss_1': 0.03830450028181076, 'loss_2': 0.0019168853759765625, 'loss_3': -16.156543731689453, 'loss_4': 2.7008001804351807, 'epoch': 5.91}
{'loss': 0.0672, 'grad_norm': 14.128230094909668, 'learning_rate': 2.41046511627907e-05, 'loss_1': 0.054036591202020645, 'loss_2': 0.0131378173828125, 'loss_3': -16.355892181396484, 'loss_4': 3.446709156036377, 'epoch': 5.91}
{'loss': 0.0176, 'grad_norm': 6.052940845489502, 'learning_rate': 2.4098837209302324e-05, 'loss_1': 0.012619431130588055, 'loss_2': 0.00498199462890625, 'loss_3': -16.137752532958984, 'loss_4': 2.815764904022217, 'epoch': 5.92}
{'loss': 0.0213, 'grad_norm': 9.18007755279541, 'learning_rate': 2.4093023255813953e-05, 'loss_1': 0.020154394209384918, 'loss_2': 0.0011577606201171875, 'loss_3': -16.219358444213867, 'loss_4': 1.8578965663909912, 'epoch': 5.92}
{'loss': 0.0998, 'grad_norm': 26.43733787536621, 'learning_rate': 2.4087209302325585e-05, 'loss_1': 0.09551804512739182, 'loss_2': 0.0043182373046875, 'loss_3': -16.03158187866211, 'loss_4': 2.6443686485290527, 'epoch': 5.93}
[INFO|trainer.py:4228] 2025-01-21 12:45:42,032 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:42,032 >>   Batch size = 64
 20%|███████████████████████████████████████████▌                                                                                                                                                                               | 1025/5160 [25:46<1:11:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:49,413 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012959012761712074, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.218, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.009461983107030392, 'eval_loss_2': 0.003497030586004257, 'eval_loss_3': -18.341379165649414, 'eval_loss_4': 2.3842570781707764, 'epoch': 5.93}
{'loss': 0.0525, 'grad_norm': 24.24431037902832, 'learning_rate': 2.408139534883721e-05, 'loss_1': 0.04969519004225731, 'loss_2': 0.0028400421142578125, 'loss_3': -16.320087432861328, 'loss_4': 2.04538631439209, 'epoch': 5.94}
{'loss': 0.0119, 'grad_norm': 6.4672112464904785, 'learning_rate': 2.407558139534884e-05, 'loss_1': 0.009777001105248928, 'loss_2': 0.002132415771484375, 'loss_3': -16.305492401123047, 'loss_4': 2.229299545288086, 'epoch': 5.94}
{'loss': 0.0592, 'grad_norm': 16.901504516601562, 'learning_rate': 2.4069767441860464e-05, 'loss_1': 0.057396989315748215, 'loss_2': 0.001773834228515625, 'loss_3': -16.00441551208496, 'loss_4': 2.43462872505188, 'epoch': 5.95}
{'loss': 0.0247, 'grad_norm': 10.564713478088379, 'learning_rate': 2.4063953488372092e-05, 'loss_1': 0.022184493020176888, 'loss_2': 0.002536773681640625, 'loss_3': -16.05257797241211, 'loss_4': 2.7381036281585693, 'epoch': 5.95}
{'loss': 0.0236, 'grad_norm': 6.847476959228516, 'learning_rate': 2.4058139534883724e-05, 'loss_1': 0.018051648512482643, 'loss_2': 0.005523681640625, 'loss_3': -16.288204193115234, 'loss_4': 3.358624219894409, 'epoch': 5.96}
[INFO|trainer.py:4228] 2025-01-21 12:45:49,413 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:49,413 >>   Batch size = 64
 20%|███████████████████████████████████████████▋                                                                                                                                                                               | 1030/5160 [25:53<1:11:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:45:56,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016299694776535034, 'eval_runtime': 3.8198, 'eval_samples_per_second': 268.08, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.010987131856381893, 'eval_loss_2': 0.005312561988830566, 'eval_loss_3': -18.33929443359375, 'eval_loss_4': 2.1549947261810303, 'epoch': 5.96}
{'loss': 0.0209, 'grad_norm': 7.958334922790527, 'learning_rate': 2.405232558139535e-05, 'loss_1': 0.020812559872865677, 'loss_2': 9.739398956298828e-05, 'loss_3': -16.314414978027344, 'loss_4': 2.345273971557617, 'epoch': 5.97}
{'loss': 0.0335, 'grad_norm': 15.343584060668945, 'learning_rate': 2.404651162790698e-05, 'loss_1': 0.03034704178571701, 'loss_2': 0.003200531005859375, 'loss_3': -16.293319702148438, 'loss_4': 2.79258131980896, 'epoch': 5.97}
{'loss': 0.0319, 'grad_norm': 10.328266143798828, 'learning_rate': 2.4040697674418604e-05, 'loss_1': 0.0265190452337265, 'loss_2': 0.0053558349609375, 'loss_3': -16.04033660888672, 'loss_4': 2.5231895446777344, 'epoch': 5.98}
{'loss': 0.0156, 'grad_norm': 5.759439945220947, 'learning_rate': 2.4034883720930232e-05, 'loss_1': 0.012038694694638252, 'loss_2': 0.00351715087890625, 'loss_3': -16.150665283203125, 'loss_4': 2.4842028617858887, 'epoch': 5.98}
{'loss': 0.035, 'grad_norm': 9.918448448181152, 'learning_rate': 2.402906976744186e-05, 'loss_1': 0.026708656921982765, 'loss_2': 0.0082550048828125, 'loss_3': -15.984052658081055, 'loss_4': 2.0874361991882324, 'epoch': 5.99}
[INFO|trainer.py:4228] 2025-01-21 12:45:56,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:45:56,799 >>   Batch size = 64
 20%|███████████████████████████████████████████▉                                                                                                                                                                               | 1035/5160 [26:01<1:09:43,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 12:46:03,879 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017299093306064606, 'eval_runtime': 3.8315, 'eval_samples_per_second': 267.257, 'eval_steps_per_second': 4.176, 'eval_loss_1': 0.012152830138802528, 'eval_loss_2': 0.0051462650299072266, 'eval_loss_3': -18.34410858154297, 'eval_loss_4': 1.815054178237915, 'epoch': 5.99}
{'loss': 0.0344, 'grad_norm': 13.039785385131836, 'learning_rate': 2.402325581395349e-05, 'loss_1': 0.033797599375247955, 'loss_2': 0.0005826950073242188, 'loss_3': -16.18784523010254, 'loss_4': 1.9302868843078613, 'epoch': 5.99}
{'loss': 0.0182, 'grad_norm': 9.993345260620117, 'learning_rate': 2.4017441860465118e-05, 'loss_1': 0.01352316327393055, 'loss_2': 0.004669189453125, 'loss_3': -16.05052947998047, 'loss_4': 1.9856114387512207, 'epoch': 6.0}
{'loss': 0.0111, 'grad_norm': 5.1647419929504395, 'learning_rate': 2.4011627906976743e-05, 'loss_1': 0.009568211622536182, 'loss_2': 0.0015201568603515625, 'loss_3': -16.40827751159668, 'loss_4': 1.6640348434448242, 'epoch': 6.01}
{'loss': 0.0575, 'grad_norm': 18.330060958862305, 'learning_rate': 2.4005813953488372e-05, 'loss_1': 0.051071323454380035, 'loss_2': 0.0064239501953125, 'loss_3': -16.213726043701172, 'loss_4': 2.401780843734741, 'epoch': 6.01}
{'loss': 0.024, 'grad_norm': 12.055185317993164, 'learning_rate': 2.4e-05, 'loss_1': 0.02002200298011303, 'loss_2': 0.00397491455078125, 'loss_3': -16.351306915283203, 'loss_4': 1.742624044418335, 'epoch': 6.02}
[INFO|trainer.py:4228] 2025-01-21 12:46:03,879 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:03,879 >>   Batch size = 64
 20%|████████████████████████████████████████████▏                                                                                                                                                                              | 1040/5160 [26:08<1:11:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:11,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013229241594672203, 'eval_runtime': 3.8212, 'eval_samples_per_second': 267.98, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.009464009664952755, 'eval_loss_2': 0.0037652328610420227, 'eval_loss_3': -18.328786849975586, 'eval_loss_4': 1.4716460704803467, 'epoch': 6.02}
{'loss': 0.0305, 'grad_norm': 9.943211555480957, 'learning_rate': 2.399418604651163e-05, 'loss_1': 0.024633435532450676, 'loss_2': 0.0059051513671875, 'loss_3': -16.304397583007812, 'loss_4': 1.906100869178772, 'epoch': 6.02}
{'loss': 0.0258, 'grad_norm': 7.343831539154053, 'learning_rate': 2.3988372093023258e-05, 'loss_1': 0.022169575095176697, 'loss_2': 0.00365447998046875, 'loss_3': -16.318130493164062, 'loss_4': 1.7046256065368652, 'epoch': 6.03}
{'loss': 0.0192, 'grad_norm': 6.568203926086426, 'learning_rate': 2.3982558139534883e-05, 'loss_1': 0.015132816508412361, 'loss_2': 0.00408935546875, 'loss_3': -16.24517059326172, 'loss_4': 1.6430578231811523, 'epoch': 6.03}
{'loss': 0.0124, 'grad_norm': 5.214555263519287, 'learning_rate': 2.3976744186046512e-05, 'loss_1': 0.01060448307543993, 'loss_2': 0.0017490386962890625, 'loss_3': -16.086027145385742, 'loss_4': 1.5475382804870605, 'epoch': 6.04}
{'loss': 0.0194, 'grad_norm': 7.398515701293945, 'learning_rate': 2.397093023255814e-05, 'loss_1': 0.017425047233700752, 'loss_2': 0.00197601318359375, 'loss_3': -16.014751434326172, 'loss_4': 1.614039659500122, 'epoch': 6.05}
[INFO|trainer.py:4228] 2025-01-21 12:46:11,255 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:11,255 >>   Batch size = 64
 20%|████████████████████████████████████████████▎                                                                                                                                                                              | 1045/5160 [26:15<1:11:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:18,625 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014704074710607529, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.418, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.008165072649717331, 'eval_loss_2': 0.006539002060890198, 'eval_loss_3': -18.269193649291992, 'eval_loss_4': 1.2059674263000488, 'epoch': 6.05}
{'loss': 0.0265, 'grad_norm': 11.155963897705078, 'learning_rate': 2.396511627906977e-05, 'loss_1': 0.019815046340227127, 'loss_2': 0.0066375732421875, 'loss_3': -15.921091079711914, 'loss_4': 1.0142261981964111, 'epoch': 6.05}
{'loss': 0.0284, 'grad_norm': 10.996581077575684, 'learning_rate': 2.3959302325581394e-05, 'loss_1': 0.0252179317176342, 'loss_2': 0.003143310546875, 'loss_3': -16.229331970214844, 'loss_4': 1.755144476890564, 'epoch': 6.06}
{'loss': 0.019, 'grad_norm': 7.360907554626465, 'learning_rate': 2.3953488372093023e-05, 'loss_1': 0.018651455640792847, 'loss_2': 0.0003104209899902344, 'loss_3': -16.244815826416016, 'loss_4': 1.3742313385009766, 'epoch': 6.06}
{'loss': 0.0157, 'grad_norm': 6.367530822753906, 'learning_rate': 2.394767441860465e-05, 'loss_1': 0.013647506013512611, 'loss_2': 0.002010345458984375, 'loss_3': -16.06911849975586, 'loss_4': 1.174208164215088, 'epoch': 6.07}
{'loss': 0.0176, 'grad_norm': 7.450968265533447, 'learning_rate': 2.394186046511628e-05, 'loss_1': 0.015317654237151146, 'loss_2': 0.00229644775390625, 'loss_3': -16.226024627685547, 'loss_4': 1.4551113843917847, 'epoch': 6.08}
[INFO|trainer.py:4228] 2025-01-21 12:46:18,625 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:18,625 >>   Batch size = 64
 20%|████████████████████████████████████████████▌                                                                                                                                                                              | 1050/5160 [26:23<1:11:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:25,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013838483020663261, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.045, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008984637446701527, 'eval_loss_2': 0.00485384464263916, 'eval_loss_3': -18.23320198059082, 'eval_loss_4': 0.9079136848449707, 'epoch': 6.08}
{'loss': 0.0267, 'grad_norm': 7.706326484680176, 'learning_rate': 2.393604651162791e-05, 'loss_1': 0.020671162754297256, 'loss_2': 0.006031036376953125, 'loss_3': -16.12160873413086, 'loss_4': 0.7338593006134033, 'epoch': 6.08}
{'loss': 0.0125, 'grad_norm': 5.777223110198975, 'learning_rate': 2.3930232558139534e-05, 'loss_1': 0.0110140610486269, 'loss_2': 0.001483917236328125, 'loss_3': -16.169536590576172, 'loss_4': 1.1564652919769287, 'epoch': 6.09}
{'loss': 0.0156, 'grad_norm': 5.5590620040893555, 'learning_rate': 2.3924418604651163e-05, 'loss_1': 0.012076434679329395, 'loss_2': 0.00353240966796875, 'loss_3': -16.159561157226562, 'loss_4': 1.052339792251587, 'epoch': 6.09}
{'loss': 0.0114, 'grad_norm': 5.442382335662842, 'learning_rate': 2.391860465116279e-05, 'loss_1': 0.006292662117630243, 'loss_2': 0.00505828857421875, 'loss_3': -16.17562484741211, 'loss_4': 0.708158552646637, 'epoch': 6.1}
{'loss': 0.0224, 'grad_norm': 5.852184295654297, 'learning_rate': 2.391279069767442e-05, 'loss_1': 0.009822641499340534, 'loss_2': 0.01261138916015625, 'loss_3': -15.885200500488281, 'loss_4': 0.881925106048584, 'epoch': 6.1}
[INFO|trainer.py:4228] 2025-01-21 12:46:25,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:25,986 >>   Batch size = 64
 20%|████████████████████████████████████████████▊                                                                                                                                                                              | 1055/5160 [26:30<1:11:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:33,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015210609883069992, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.575, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009551744908094406, 'eval_loss_2': 0.005658864974975586, 'eval_loss_3': -18.226051330566406, 'eval_loss_4': 0.8786225318908691, 'epoch': 6.1}
{'loss': 0.0225, 'grad_norm': 7.064645767211914, 'learning_rate': 2.390697674418605e-05, 'loss_1': 0.019364187493920326, 'loss_2': 0.003143310546875, 'loss_3': -15.966897964477539, 'loss_4': 0.5894739627838135, 'epoch': 6.11}
{'loss': 0.0502, 'grad_norm': 14.088265419006348, 'learning_rate': 2.3901162790697674e-05, 'loss_1': 0.03734302148222923, 'loss_2': 0.0128326416015625, 'loss_3': -15.768248558044434, 'loss_4': 0.9361085891723633, 'epoch': 6.12}
{'loss': 0.0125, 'grad_norm': 5.6137542724609375, 'learning_rate': 2.3895348837209302e-05, 'loss_1': 0.009282128885388374, 'loss_2': 0.00322723388671875, 'loss_3': -15.914827346801758, 'loss_4': 1.569627285003662, 'epoch': 6.12}
{'loss': 0.018, 'grad_norm': 5.865466594696045, 'learning_rate': 2.3889534883720928e-05, 'loss_1': 0.010893796570599079, 'loss_2': 0.0070648193359375, 'loss_3': -15.872618675231934, 'loss_4': 0.9008852243423462, 'epoch': 6.13}
{'loss': 0.0225, 'grad_norm': 7.622907638549805, 'learning_rate': 2.388372093023256e-05, 'loss_1': 0.018675871193408966, 'loss_2': 0.00377655029296875, 'loss_3': -16.085567474365234, 'loss_4': 1.3723901510238647, 'epoch': 6.13}
[INFO|trainer.py:4228] 2025-01-21 12:46:33,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:33,352 >>   Batch size = 64
 21%|████████████████████████████████████████████▉                                                                                                                                                                              | 1060/5160 [26:37<1:11:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:40,724 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017139317467808723, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.711, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01026463694870472, 'eval_loss_2': 0.006874680519104004, 'eval_loss_3': -18.199718475341797, 'eval_loss_4': 0.8523364663124084, 'epoch': 6.13}
{'loss': 0.0121, 'grad_norm': 6.226791858673096, 'learning_rate': 2.387790697674419e-05, 'loss_1': 0.011905721388757229, 'loss_2': 0.000186920166015625, 'loss_3': -16.093624114990234, 'loss_4': 1.2180229425430298, 'epoch': 6.14}
{'loss': 0.0241, 'grad_norm': 8.718365669250488, 'learning_rate': 2.3872093023255814e-05, 'loss_1': 0.022043444216251373, 'loss_2': 0.00209808349609375, 'loss_3': -15.799226760864258, 'loss_4': 1.222315788269043, 'epoch': 6.15}
{'loss': 0.0227, 'grad_norm': 5.666340351104736, 'learning_rate': 2.3866279069767442e-05, 'loss_1': 0.010481813922524452, 'loss_2': 0.01220703125, 'loss_3': -16.155399322509766, 'loss_4': 0.8391579389572144, 'epoch': 6.15}
{'loss': 0.0136, 'grad_norm': 5.7910590171813965, 'learning_rate': 2.3860465116279067e-05, 'loss_1': 0.013399003073573112, 'loss_2': 0.0002301931381225586, 'loss_3': -16.10129165649414, 'loss_4': 1.1724339723587036, 'epoch': 6.16}
{'loss': 0.0316, 'grad_norm': 7.370070934295654, 'learning_rate': 2.38546511627907e-05, 'loss_1': 0.02146332897245884, 'loss_2': 0.01012420654296875, 'loss_3': -16.041500091552734, 'loss_4': 0.41519343852996826, 'epoch': 6.16}
[INFO|trainer.py:4228] 2025-01-21 12:46:40,724 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:40,724 >>   Batch size = 64
 21%|█████████████████████████████████████████████▏                                                                                                                                                                             | 1065/5160 [26:45<1:11:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:48,091 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020225077867507935, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.507, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01121631171554327, 'eval_loss_2': 0.00900876522064209, 'eval_loss_3': -18.187040328979492, 'eval_loss_4': 0.650343656539917, 'epoch': 6.16}
{'loss': 0.0363, 'grad_norm': 10.24104118347168, 'learning_rate': 2.3848837209302328e-05, 'loss_1': 0.02219761349260807, 'loss_2': 0.014129638671875, 'loss_3': -16.110084533691406, 'loss_4': 0.47294288873672485, 'epoch': 6.17}
{'loss': 0.0286, 'grad_norm': 6.666654586791992, 'learning_rate': 2.3843023255813953e-05, 'loss_1': 0.01572001352906227, 'loss_2': 0.01288604736328125, 'loss_3': -16.147357940673828, 'loss_4': 0.837173581123352, 'epoch': 6.17}
{'loss': 0.0522, 'grad_norm': 21.343942642211914, 'learning_rate': 2.3837209302325582e-05, 'loss_1': 0.051774073392152786, 'loss_2': 0.00038909912109375, 'loss_3': -15.904130935668945, 'loss_4': 0.6878706216812134, 'epoch': 6.18}
{'loss': 0.0246, 'grad_norm': 8.136636734008789, 'learning_rate': 2.3831395348837207e-05, 'loss_1': 0.020900780335068703, 'loss_2': 0.00370025634765625, 'loss_3': -15.995357513427734, 'loss_4': 0.7978053092956543, 'epoch': 6.19}
{'loss': 0.0186, 'grad_norm': 7.059906959533691, 'learning_rate': 2.382558139534884e-05, 'loss_1': 0.01632240042090416, 'loss_2': 0.002323150634765625, 'loss_3': -16.124528884887695, 'loss_4': 0.6789975762367249, 'epoch': 6.19}
[INFO|trainer.py:4228] 2025-01-21 12:46:48,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:48,092 >>   Batch size = 64
 21%|█████████████████████████████████████████████▍                                                                                                                                                                             | 1070/5160 [26:52<1:11:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:46:55,474 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019592110067605972, 'eval_runtime': 3.8215, 'eval_samples_per_second': 267.955, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.013201267458498478, 'eval_loss_2': 0.0063908398151397705, 'eval_loss_3': -18.17559242248535, 'eval_loss_4': 0.3985779881477356, 'epoch': 6.19}
{'loss': 0.0434, 'grad_norm': 15.264181137084961, 'learning_rate': 2.3819767441860464e-05, 'loss_1': 0.03438888117671013, 'loss_2': 0.00904083251953125, 'loss_3': -15.825613021850586, 'loss_4': 1.06002938747406, 'epoch': 6.2}
{'loss': 0.0253, 'grad_norm': 5.3183746337890625, 'learning_rate': 2.3813953488372093e-05, 'loss_1': 0.012070253491401672, 'loss_2': 0.01318359375, 'loss_3': -16.279186248779297, 'loss_4': 0.6692788600921631, 'epoch': 6.2}
{'loss': 0.0393, 'grad_norm': 13.025067329406738, 'learning_rate': 2.3808139534883722e-05, 'loss_1': 0.03044028766453266, 'loss_2': 0.008880615234375, 'loss_3': -16.108402252197266, 'loss_4': 0.5765972137451172, 'epoch': 6.21}
{'loss': 0.0226, 'grad_norm': 5.616795063018799, 'learning_rate': 2.380232558139535e-05, 'loss_1': 0.013284197077155113, 'loss_2': 0.009307861328125, 'loss_3': -16.076522827148438, 'loss_4': 0.30368831753730774, 'epoch': 6.22}
{'loss': 0.0135, 'grad_norm': 5.748073577880859, 'learning_rate': 2.379651162790698e-05, 'loss_1': 0.008829060941934586, 'loss_2': 0.00467681884765625, 'loss_3': -16.084274291992188, 'loss_4': -0.14247795939445496, 'epoch': 6.22}
[INFO|trainer.py:4228] 2025-01-21 12:46:55,474 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:46:55,475 >>   Batch size = 64
 21%|█████████████████████████████████████████████▋                                                                                                                                                                             | 1075/5160 [26:59<1:10:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:02,848 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015348249115049839, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.417, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.012081758119165897, 'eval_loss_2': 0.0032664909958839417, 'eval_loss_3': -18.25359535217285, 'eval_loss_4': 0.04256964847445488, 'epoch': 6.22}
{'loss': 0.0229, 'grad_norm': 8.623693466186523, 'learning_rate': 2.3790697674418604e-05, 'loss_1': 0.021892007440328598, 'loss_2': 0.00101470947265625, 'loss_3': -16.06620216369629, 'loss_4': -0.038572557270526886, 'epoch': 6.23}
{'loss': 0.0386, 'grad_norm': 14.848705291748047, 'learning_rate': 2.3784883720930233e-05, 'loss_1': 0.037940531969070435, 'loss_2': 0.0006351470947265625, 'loss_3': -15.981989860534668, 'loss_4': 0.511509895324707, 'epoch': 6.23}
{'loss': 0.0149, 'grad_norm': 7.311318874359131, 'learning_rate': 2.377906976744186e-05, 'loss_1': 0.013725334778428078, 'loss_2': 0.0011777877807617188, 'loss_3': -15.987199783325195, 'loss_4': 0.1930009126663208, 'epoch': 6.24}
{'loss': 0.029, 'grad_norm': 11.321721076965332, 'learning_rate': 2.377325581395349e-05, 'loss_1': 0.028790442273020744, 'loss_2': 0.000194549560546875, 'loss_3': -15.946568489074707, 'loss_4': 0.3278576135635376, 'epoch': 6.24}
{'loss': 0.0364, 'grad_norm': 11.208389282226562, 'learning_rate': 2.376744186046512e-05, 'loss_1': 0.026254910975694656, 'loss_2': 0.0101776123046875, 'loss_3': -16.2795352935791, 'loss_4': 0.42729318141937256, 'epoch': 6.25}
[INFO|trainer.py:4228] 2025-01-21 12:47:02,848 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:02,848 >>   Batch size = 64
 21%|█████████████████████████████████████████████▊                                                                                                                                                                             | 1080/5160 [27:07<1:10:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:10,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01970142312347889, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.48, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.014247746206820011, 'eval_loss_2': 0.005453675985336304, 'eval_loss_3': -18.29989242553711, 'eval_loss_4': 0.21140338480472565, 'epoch': 6.25}
{'loss': 0.0257, 'grad_norm': 8.22692584991455, 'learning_rate': 2.3761627906976744e-05, 'loss_1': 0.02128378115594387, 'loss_2': 0.0044097900390625, 'loss_3': -16.27378273010254, 'loss_4': -0.11182017624378204, 'epoch': 6.26}
{'loss': 0.0343, 'grad_norm': 11.939764976501465, 'learning_rate': 2.3755813953488373e-05, 'loss_1': 0.03212735801935196, 'loss_2': 0.0021877288818359375, 'loss_3': -16.195636749267578, 'loss_4': -0.06418304145336151, 'epoch': 6.26}
{'loss': 0.0381, 'grad_norm': 11.687261581420898, 'learning_rate': 2.3749999999999998e-05, 'loss_1': 0.031631022691726685, 'loss_2': 0.006465911865234375, 'loss_3': -16.304515838623047, 'loss_4': 0.3546236753463745, 'epoch': 6.27}
{'loss': 0.0215, 'grad_norm': 7.796019554138184, 'learning_rate': 2.374418604651163e-05, 'loss_1': 0.018857745453715324, 'loss_2': 0.0026416778564453125, 'loss_3': -16.481365203857422, 'loss_4': 0.5887620449066162, 'epoch': 6.27}
{'loss': 0.038, 'grad_norm': 16.896060943603516, 'learning_rate': 2.373837209302326e-05, 'loss_1': 0.03559676185250282, 'loss_2': 0.0024166107177734375, 'loss_3': -16.229034423828125, 'loss_4': 0.7586169242858887, 'epoch': 6.28}
[INFO|trainer.py:4228] 2025-01-21 12:47:10,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:10,224 >>   Batch size = 64
 21%|██████████████████████████████████████████████                                                                                                                                                                             | 1085/5160 [27:14<1:10:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:17,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01926727592945099, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.531, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01589883491396904, 'eval_loss_2': 0.003368441015481949, 'eval_loss_3': -18.387950897216797, 'eval_loss_4': 0.23108990490436554, 'epoch': 6.28}
{'loss': 0.0303, 'grad_norm': 8.421667098999023, 'learning_rate': 2.3732558139534884e-05, 'loss_1': 0.024558525532484055, 'loss_2': 0.00572967529296875, 'loss_3': -16.54290008544922, 'loss_4': 0.6157747507095337, 'epoch': 6.28}
{'loss': 0.0173, 'grad_norm': 5.429963111877441, 'learning_rate': 2.3726744186046512e-05, 'loss_1': 0.014782030135393143, 'loss_2': 0.002521514892578125, 'loss_3': -16.423778533935547, 'loss_4': -0.2724856436252594, 'epoch': 6.29}
{'loss': 0.0283, 'grad_norm': 9.264059066772461, 'learning_rate': 2.3720930232558138e-05, 'loss_1': 0.027748264372348785, 'loss_2': 0.00058746337890625, 'loss_3': -16.463552474975586, 'loss_4': 0.38317176699638367, 'epoch': 6.3}
{'loss': 0.0336, 'grad_norm': 8.381564140319824, 'learning_rate': 2.371511627906977e-05, 'loss_1': 0.027607668191194534, 'loss_2': 0.006008148193359375, 'loss_3': -16.374420166015625, 'loss_4': 0.21746903657913208, 'epoch': 6.3}
{'loss': 0.0468, 'grad_norm': 14.303752899169922, 'learning_rate': 2.37093023255814e-05, 'loss_1': 0.044280972331762314, 'loss_2': 0.0024871826171875, 'loss_3': -16.327665328979492, 'loss_4': 0.2043113112449646, 'epoch': 6.31}
[INFO|trainer.py:4228] 2025-01-21 12:47:17,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:17,588 >>   Batch size = 64
 21%|██████████████████████████████████████████████▎                                                                                                                                                                            | 1090/5160 [27:22<1:10:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:24,960 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018470119684934616, 'eval_runtime': 3.8179, 'eval_samples_per_second': 268.209, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.015691658481955528, 'eval_loss_2': 0.002778463065624237, 'eval_loss_3': -18.3909969329834, 'eval_loss_4': 0.0729452446103096, 'epoch': 6.31}
{'loss': 0.124, 'grad_norm': 24.629409790039062, 'learning_rate': 2.3703488372093024e-05, 'loss_1': 0.1237793117761612, 'loss_2': 0.00021791458129882812, 'loss_3': -16.294017791748047, 'loss_4': 0.6600240468978882, 'epoch': 6.31}
{'loss': 0.0229, 'grad_norm': 7.377011775970459, 'learning_rate': 2.3697674418604652e-05, 'loss_1': 0.019442467018961906, 'loss_2': 0.00341033935546875, 'loss_3': -16.450437545776367, 'loss_4': 0.4382084012031555, 'epoch': 6.32}
{'loss': 0.0307, 'grad_norm': 8.926291465759277, 'learning_rate': 2.3691860465116277e-05, 'loss_1': 0.027162820100784302, 'loss_2': 0.0034923553466796875, 'loss_3': -16.235267639160156, 'loss_4': 0.6715574264526367, 'epoch': 6.33}
{'loss': 0.0589, 'grad_norm': 23.693510055541992, 'learning_rate': 2.368604651162791e-05, 'loss_1': 0.058617446571588516, 'loss_2': 0.00027370452880859375, 'loss_3': -16.419139862060547, 'loss_4': 0.11521607637405396, 'epoch': 6.33}
{'loss': 0.0247, 'grad_norm': 7.163378715515137, 'learning_rate': 2.3680232558139535e-05, 'loss_1': 0.022729214280843735, 'loss_2': 0.0019216537475585938, 'loss_3': -16.192848205566406, 'loss_4': 0.4502098560333252, 'epoch': 6.34}
[INFO|trainer.py:4228] 2025-01-21 12:47:24,960 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:24,961 >>   Batch size = 64
 21%|██████████████████████████████████████████████▍                                                                                                                                                                            | 1095/5160 [27:29<1:10:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:32,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018567750230431557, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.141, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.015415298752486706, 'eval_loss_2': 0.0031524524092674255, 'eval_loss_3': -18.384662628173828, 'eval_loss_4': 0.06224144250154495, 'epoch': 6.34}
{'loss': 0.0411, 'grad_norm': 12.665120124816895, 'learning_rate': 2.3674418604651163e-05, 'loss_1': 0.04062046855688095, 'loss_2': 0.0005135536193847656, 'loss_3': -16.506328582763672, 'loss_4': 0.2771649658679962, 'epoch': 6.34}
{'loss': 0.0323, 'grad_norm': 9.426072120666504, 'learning_rate': 2.3668604651162792e-05, 'loss_1': 0.02925068326294422, 'loss_2': 0.0030364990234375, 'loss_3': -16.303733825683594, 'loss_4': 0.3876476287841797, 'epoch': 6.35}
{'loss': 0.0281, 'grad_norm': 6.702030181884766, 'learning_rate': 2.3662790697674417e-05, 'loss_1': 0.024129360914230347, 'loss_2': 0.00392913818359375, 'loss_3': -16.156841278076172, 'loss_4': 0.1691795289516449, 'epoch': 6.35}
{'loss': 0.0334, 'grad_norm': 9.421380043029785, 'learning_rate': 2.365697674418605e-05, 'loss_1': 0.02971147932112217, 'loss_2': 0.003662109375, 'loss_3': -16.380603790283203, 'loss_4': 0.27596232295036316, 'epoch': 6.36}
{'loss': 0.0321, 'grad_norm': 15.579212188720703, 'learning_rate': 2.3651162790697675e-05, 'loss_1': 0.02871371991932392, 'loss_2': 0.003383636474609375, 'loss_3': -16.393665313720703, 'loss_4': 0.3139277994632721, 'epoch': 6.37}
[INFO|trainer.py:4228] 2025-01-21 12:47:32,332 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:32,333 >>   Batch size = 64
 21%|██████████████████████████████████████████████▋                                                                                                                                                                            | 1100/5160 [27:36<1:10:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:39,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01968616247177124, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.337, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.013877270743250847, 'eval_loss_2': 0.005808889865875244, 'eval_loss_3': -18.40376853942871, 'eval_loss_4': 0.14465589821338654, 'epoch': 6.37}
{'loss': 0.0736, 'grad_norm': 22.189233779907227, 'learning_rate': 2.3645348837209303e-05, 'loss_1': 0.060158420354127884, 'loss_2': 0.0134124755859375, 'loss_3': -16.21392059326172, 'loss_4': 0.5228284597396851, 'epoch': 6.37}
{'loss': 0.0339, 'grad_norm': 10.966567993164062, 'learning_rate': 2.3639534883720932e-05, 'loss_1': 0.03008807636797428, 'loss_2': 0.0037994384765625, 'loss_3': -16.328628540039062, 'loss_4': 0.03635619580745697, 'epoch': 6.38}
{'loss': 0.0324, 'grad_norm': 7.194294452667236, 'learning_rate': 2.3633720930232557e-05, 'loss_1': 0.021316567435860634, 'loss_2': 0.01113128662109375, 'loss_3': -16.566909790039062, 'loss_4': 0.4422447681427002, 'epoch': 6.38}
{'loss': 0.041, 'grad_norm': 16.230194091796875, 'learning_rate': 2.362790697674419e-05, 'loss_1': 0.0330439992249012, 'loss_2': 0.0079803466796875, 'loss_3': -16.36859893798828, 'loss_4': -0.14610767364501953, 'epoch': 6.39}
{'loss': 0.0208, 'grad_norm': 6.171344757080078, 'learning_rate': 2.3622093023255814e-05, 'loss_1': 0.017213091254234314, 'loss_2': 0.0035953521728515625, 'loss_3': -16.44987678527832, 'loss_4': -0.2498551607131958, 'epoch': 6.4}
[INFO|trainer.py:4228] 2025-01-21 12:47:39,706 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:39,706 >>   Batch size = 64
 21%|██████████████████████████████████████████████▉                                                                                                                                                                            | 1105/5160 [27:44<1:10:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:47,077 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01470191776752472, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.494, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01142407488077879, 'eval_loss_2': 0.003277841955423355, 'eval_loss_3': -18.374343872070312, 'eval_loss_4': -0.06889395415782928, 'epoch': 6.4}
{'loss': 0.0298, 'grad_norm': 11.240513801574707, 'learning_rate': 2.3616279069767443e-05, 'loss_1': 0.025257812812924385, 'loss_2': 0.00458526611328125, 'loss_3': -16.43317413330078, 'loss_4': 0.100889652967453, 'epoch': 6.4}
{'loss': 0.0296, 'grad_norm': 10.217766761779785, 'learning_rate': 2.3610465116279068e-05, 'loss_1': 0.02662001922726631, 'loss_2': 0.0029582977294921875, 'loss_3': -16.43657684326172, 'loss_4': 0.17518684267997742, 'epoch': 6.41}
{'loss': 0.0441, 'grad_norm': 16.30206871032715, 'learning_rate': 2.3604651162790697e-05, 'loss_1': 0.04344312474131584, 'loss_2': 0.0006113052368164062, 'loss_3': -16.45907211303711, 'loss_4': 0.07032737135887146, 'epoch': 6.41}
{'loss': 0.0248, 'grad_norm': 7.641776084899902, 'learning_rate': 2.359883720930233e-05, 'loss_1': 0.018524890765547752, 'loss_2': 0.0062255859375, 'loss_3': -16.556467056274414, 'loss_4': 0.6938521265983582, 'epoch': 6.42}
{'loss': 0.0201, 'grad_norm': 9.27868366241455, 'learning_rate': 2.3593023255813954e-05, 'loss_1': 0.017461491748690605, 'loss_2': 0.0026340484619140625, 'loss_3': -16.42148208618164, 'loss_4': 0.3349267542362213, 'epoch': 6.42}
[INFO|trainer.py:4228] 2025-01-21 12:47:47,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:47,077 >>   Batch size = 64
 22%|███████████████████████████████████████████████                                                                                                                                                                            | 1110/5160 [27:51<1:10:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:47:54,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016001088544726372, 'eval_runtime': 3.813, 'eval_samples_per_second': 268.553, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011454683728516102, 'eval_loss_2': 0.004546403884887695, 'eval_loss_3': -18.339336395263672, 'eval_loss_4': 0.0737452432513237, 'epoch': 6.42}
{'loss': 0.0387, 'grad_norm': 7.81245756149292, 'learning_rate': 2.3587209302325583e-05, 'loss_1': 0.026790672913193703, 'loss_2': 0.0118865966796875, 'loss_3': -16.25354766845703, 'loss_4': 0.4398415684700012, 'epoch': 6.43}
{'loss': 0.019, 'grad_norm': 7.504834175109863, 'learning_rate': 2.3581395348837208e-05, 'loss_1': 0.013848535716533661, 'loss_2': 0.005176544189453125, 'loss_3': -16.437091827392578, 'loss_4': 0.4515562653541565, 'epoch': 6.44}
{'loss': 0.0327, 'grad_norm': 11.587757110595703, 'learning_rate': 2.3575581395348837e-05, 'loss_1': 0.02510998398065567, 'loss_2': 0.0075531005859375, 'loss_3': -16.389503479003906, 'loss_4': 0.24445882439613342, 'epoch': 6.44}
{'loss': 0.018, 'grad_norm': 6.192589282989502, 'learning_rate': 2.356976744186047e-05, 'loss_1': 0.013266419991850853, 'loss_2': 0.004726409912109375, 'loss_3': -16.25346565246582, 'loss_4': 0.22635865211486816, 'epoch': 6.45}
{'loss': 0.0108, 'grad_norm': 5.454001426696777, 'learning_rate': 2.3563953488372094e-05, 'loss_1': 0.009816166013479233, 'loss_2': 0.000980377197265625, 'loss_3': -16.491437911987305, 'loss_4': 0.5962364673614502, 'epoch': 6.45}
[INFO|trainer.py:4228] 2025-01-21 12:47:54,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:47:54,449 >>   Batch size = 64
 22%|███████████████████████████████████████████████▎                                                                                                                                                                           | 1115/5160 [27:58<1:10:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:01,813 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017245806753635406, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.684, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013306298293173313, 'eval_loss_2': 0.003939509391784668, 'eval_loss_3': -18.296812057495117, 'eval_loss_4': 0.187018021941185, 'epoch': 6.45}
{'loss': 0.0195, 'grad_norm': 6.316002368927002, 'learning_rate': 2.3558139534883722e-05, 'loss_1': 0.018255185335874557, 'loss_2': 0.0012226104736328125, 'loss_3': -16.376495361328125, 'loss_4': -0.05092334747314453, 'epoch': 6.46}
{'loss': 0.0245, 'grad_norm': 7.277780055999756, 'learning_rate': 2.3552325581395348e-05, 'loss_1': 0.020467592403292656, 'loss_2': 0.0039825439453125, 'loss_3': -16.30643653869629, 'loss_4': 0.3357483744621277, 'epoch': 6.47}
{'loss': 0.0167, 'grad_norm': 7.297545909881592, 'learning_rate': 2.3546511627906976e-05, 'loss_1': 0.014899978414177895, 'loss_2': 0.001789093017578125, 'loss_3': -16.233989715576172, 'loss_4': 0.616273045539856, 'epoch': 6.47}
{'loss': 0.0202, 'grad_norm': 5.866306304931641, 'learning_rate': 2.3540697674418605e-05, 'loss_1': 0.01403758954256773, 'loss_2': 0.006137847900390625, 'loss_3': -16.28662109375, 'loss_4': 0.1677962988615036, 'epoch': 6.48}
{'loss': 0.0247, 'grad_norm': 10.202664375305176, 'learning_rate': 2.3534883720930234e-05, 'loss_1': 0.024585958570241928, 'loss_2': 0.0001316070556640625, 'loss_3': -16.282007217407227, 'loss_4': 0.6167124509811401, 'epoch': 6.48}
[INFO|trainer.py:4228] 2025-01-21 12:48:01,813 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:01,813 >>   Batch size = 64
 22%|███████████████████████████████████████████████▌                                                                                                                                                                           | 1120/5160 [28:06<1:10:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:09,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017060352489352226, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.445, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.012692106887698174, 'eval_loss_2': 0.004368245601654053, 'eval_loss_3': -18.270479202270508, 'eval_loss_4': 0.42485466599464417, 'epoch': 6.48}
{'loss': 0.0166, 'grad_norm': 4.932040691375732, 'learning_rate': 2.3529069767441862e-05, 'loss_1': 0.008354448713362217, 'loss_2': 0.00821685791015625, 'loss_3': -16.273107528686523, 'loss_4': 0.5800848603248596, 'epoch': 6.49}
{'loss': 0.0252, 'grad_norm': 7.5378570556640625, 'learning_rate': 2.3523255813953487e-05, 'loss_1': 0.018438825383782387, 'loss_2': 0.006744384765625, 'loss_3': -16.317840576171875, 'loss_4': 0.693813681602478, 'epoch': 6.49}
{'loss': 0.02, 'grad_norm': 7.709506034851074, 'learning_rate': 2.3517441860465116e-05, 'loss_1': 0.01975127123296261, 'loss_2': 0.0002541542053222656, 'loss_3': -16.287391662597656, 'loss_4': 0.40359169244766235, 'epoch': 6.5}
{'loss': 0.0164, 'grad_norm': 5.388133525848389, 'learning_rate': 2.3511627906976745e-05, 'loss_1': 0.010738324373960495, 'loss_2': 0.00563812255859375, 'loss_3': -16.296329498291016, 'loss_4': 0.5280876159667969, 'epoch': 6.51}
{'loss': 0.0329, 'grad_norm': 10.308624267578125, 'learning_rate': 2.3505813953488373e-05, 'loss_1': 0.026282571256160736, 'loss_2': 0.00661468505859375, 'loss_3': -16.2088565826416, 'loss_4': 0.24331504106521606, 'epoch': 6.51}
[INFO|trainer.py:4228] 2025-01-21 12:48:09,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:09,186 >>   Batch size = 64
 22%|███████████████████████████████████████████████▋                                                                                                                                                                           | 1125/5160 [28:13<1:10:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:16,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015631191432476044, 'eval_runtime': 3.822, 'eval_samples_per_second': 267.924, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.011321218684315681, 'eval_loss_2': 0.0043099746108055115, 'eval_loss_3': -18.283615112304688, 'eval_loss_4': 0.33857572078704834, 'epoch': 6.51}
{'loss': 0.0256, 'grad_norm': 8.233316421508789, 'learning_rate': 2.3500000000000002e-05, 'loss_1': 0.02046394906938076, 'loss_2': 0.00516510009765625, 'loss_3': -16.399354934692383, 'loss_4': 1.0456852912902832, 'epoch': 6.52}
{'loss': 0.0398, 'grad_norm': 11.768498420715332, 'learning_rate': 2.3494186046511627e-05, 'loss_1': 0.022985899820923805, 'loss_2': 0.016845703125, 'loss_3': -16.253646850585938, 'loss_4': 0.3691278100013733, 'epoch': 6.52}
{'loss': 0.0116, 'grad_norm': 6.521688461303711, 'learning_rate': 2.3488372093023256e-05, 'loss_1': 0.008975978009402752, 'loss_2': 0.0026264190673828125, 'loss_3': -16.335731506347656, 'loss_4': 0.2003265768289566, 'epoch': 6.53}
{'loss': 0.0242, 'grad_norm': 8.612106323242188, 'learning_rate': 2.3482558139534885e-05, 'loss_1': 0.02166694961488247, 'loss_2': 0.00254058837890625, 'loss_3': -16.16843032836914, 'loss_4': -0.03615706413984299, 'epoch': 6.53}
{'loss': 0.0141, 'grad_norm': 6.31270170211792, 'learning_rate': 2.3476744186046513e-05, 'loss_1': 0.012183667160570621, 'loss_2': 0.001895904541015625, 'loss_3': -16.117137908935547, 'loss_4': -0.09702805429697037, 'epoch': 6.54}
[INFO|trainer.py:4228] 2025-01-21 12:48:16,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:16,569 >>   Batch size = 64
 22%|███████████████████████████████████████████████▉                                                                                                                                                                           | 1130/5160 [28:21<1:09:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:23,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015634043142199516, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.225, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.01066998578608036, 'eval_loss_2': 0.004964057356119156, 'eval_loss_3': -18.25706672668457, 'eval_loss_4': 0.3807908296585083, 'epoch': 6.54}
{'loss': 0.0145, 'grad_norm': 5.779504299163818, 'learning_rate': 2.347093023255814e-05, 'loss_1': 0.00891087856143713, 'loss_2': 0.00554656982421875, 'loss_3': -16.33601188659668, 'loss_4': 0.24448436498641968, 'epoch': 6.55}
{'loss': 0.0277, 'grad_norm': 17.418222427368164, 'learning_rate': 2.3465116279069767e-05, 'loss_1': 0.02592848427593708, 'loss_2': 0.0017681121826171875, 'loss_3': -16.229774475097656, 'loss_4': 0.6029753684997559, 'epoch': 6.55}
{'loss': 0.0251, 'grad_norm': 7.557514190673828, 'learning_rate': 2.3459302325581396e-05, 'loss_1': 0.016672290861606598, 'loss_2': 0.0084228515625, 'loss_3': -16.339929580688477, 'loss_4': 0.8773531317710876, 'epoch': 6.56}
{'loss': 0.0165, 'grad_norm': 7.330599784851074, 'learning_rate': 2.3453488372093024e-05, 'loss_1': 0.013996727764606476, 'loss_2': 0.0025043487548828125, 'loss_3': -16.12079429626465, 'loss_4': 0.695647120475769, 'epoch': 6.56}
{'loss': 0.0193, 'grad_norm': 6.251429557800293, 'learning_rate': 2.3447674418604653e-05, 'loss_1': 0.009834039025008678, 'loss_2': 0.0095062255859375, 'loss_3': -16.10255241394043, 'loss_4': 0.8247448205947876, 'epoch': 6.57}
[INFO|trainer.py:4228] 2025-01-21 12:48:23,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:23,938 >>   Batch size = 64
 22%|████████████████████████████████████████████████▏                                                                                                                                                                          | 1135/5160 [28:28<1:09:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:31,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016254298388957977, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01136600412428379, 'eval_loss_2': 0.004888296127319336, 'eval_loss_3': -18.20818328857422, 'eval_loss_4': 0.8696032762527466, 'epoch': 6.57}
{'loss': 0.0286, 'grad_norm': 9.644546508789062, 'learning_rate': 2.3441860465116278e-05, 'loss_1': 0.020502252504229546, 'loss_2': 0.00814056396484375, 'loss_3': -16.10264015197754, 'loss_4': 0.6455131769180298, 'epoch': 6.58}
{'loss': 0.0124, 'grad_norm': 5.273857593536377, 'learning_rate': 2.3436046511627907e-05, 'loss_1': 0.00964768510311842, 'loss_2': 0.002750396728515625, 'loss_3': -16.189014434814453, 'loss_4': 1.4382319450378418, 'epoch': 6.58}
{'loss': 0.0292, 'grad_norm': 11.680071830749512, 'learning_rate': 2.343023255813954e-05, 'loss_1': 0.0259883850812912, 'loss_2': 0.003208160400390625, 'loss_3': -16.26634407043457, 'loss_4': 1.0535759925842285, 'epoch': 6.59}
{'loss': 0.0191, 'grad_norm': 7.788078784942627, 'learning_rate': 2.3424418604651164e-05, 'loss_1': 0.016510607674717903, 'loss_2': 0.002605438232421875, 'loss_3': -16.254161834716797, 'loss_4': 1.138598918914795, 'epoch': 6.59}
{'loss': 0.0362, 'grad_norm': 11.516408920288086, 'learning_rate': 2.3418604651162793e-05, 'loss_1': 0.03039807640016079, 'loss_2': 0.0058441162109375, 'loss_3': -16.195240020751953, 'loss_4': 1.1918044090270996, 'epoch': 6.6}
[INFO|trainer.py:4228] 2025-01-21 12:48:31,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:31,299 >>   Batch size = 64
 22%|████████████████████████████████████████████████▍                                                                                                                                                                          | 1140/5160 [28:35<1:09:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:38,665 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016585320234298706, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.0132362712174654, 'eval_loss_2': 0.0033490508794784546, 'eval_loss_3': -18.182628631591797, 'eval_loss_4': 1.5065840482711792, 'epoch': 6.6}
{'loss': 0.0312, 'grad_norm': 9.754667282104492, 'learning_rate': 2.3412790697674418e-05, 'loss_1': 0.019605161622166634, 'loss_2': 0.0116119384765625, 'loss_3': -16.025819778442383, 'loss_4': 1.327491283416748, 'epoch': 6.6}
{'loss': 0.0249, 'grad_norm': 10.958622932434082, 'learning_rate': 2.3406976744186047e-05, 'loss_1': 0.020343786105513573, 'loss_2': 0.004512786865234375, 'loss_3': -15.910438537597656, 'loss_4': 1.7509275674819946, 'epoch': 6.61}
{'loss': 0.0112, 'grad_norm': 5.185125350952148, 'learning_rate': 2.3401162790697675e-05, 'loss_1': 0.008591334335505962, 'loss_2': 0.0025997161865234375, 'loss_3': -15.998615264892578, 'loss_4': 1.977266788482666, 'epoch': 6.62}
{'loss': 0.017, 'grad_norm': 6.095362186431885, 'learning_rate': 2.3395348837209304e-05, 'loss_1': 0.010951747186481953, 'loss_2': 0.00606536865234375, 'loss_3': -16.025039672851562, 'loss_4': 1.5330456495285034, 'epoch': 6.62}
{'loss': 0.0883, 'grad_norm': 24.651010513305664, 'learning_rate': 2.3389534883720932e-05, 'loss_1': 0.07921835780143738, 'loss_2': 0.00909423828125, 'loss_3': -16.01875877380371, 'loss_4': 1.6188819408416748, 'epoch': 6.63}
[INFO|trainer.py:4228] 2025-01-21 12:48:38,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:38,666 >>   Batch size = 64
 22%|████████████████████████████████████████████████▌                                                                                                                                                                          | 1145/5160 [28:43<1:09:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:46,020 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01315292902290821, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.134, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009557248093187809, 'eval_loss_2': 0.003595679998397827, 'eval_loss_3': -18.19609260559082, 'eval_loss_4': 2.1536803245544434, 'epoch': 6.63}
{'loss': 0.0546, 'grad_norm': 19.20528221130371, 'learning_rate': 2.3383720930232558e-05, 'loss_1': 0.05299646779894829, 'loss_2': 0.00159454345703125, 'loss_3': -16.13735580444336, 'loss_4': 2.1773667335510254, 'epoch': 6.63}
{'loss': 0.0179, 'grad_norm': 7.616693019866943, 'learning_rate': 2.3377906976744186e-05, 'loss_1': 0.013246092945337296, 'loss_2': 0.00464630126953125, 'loss_3': -16.210269927978516, 'loss_4': 2.1225314140319824, 'epoch': 6.64}
{'loss': 0.0198, 'grad_norm': 6.365996837615967, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.013932177796959877, 'loss_2': 0.00583648681640625, 'loss_3': -15.941715240478516, 'loss_4': 2.235011577606201, 'epoch': 6.65}
{'loss': 0.0853, 'grad_norm': inf, 'learning_rate': 2.3372093023255815e-05, 'loss_1': 0.08122038096189499, 'loss_2': 0.0040435791015625, 'loss_3': -15.92824935913086, 'loss_4': 2.064359664916992, 'epoch': 6.65}
{'loss': 0.0378, 'grad_norm': 10.970914840698242, 'learning_rate': 2.3366279069767444e-05, 'loss_1': 0.031455278396606445, 'loss_2': 0.00632476806640625, 'loss_3': -16.146697998046875, 'loss_4': 2.5741474628448486, 'epoch': 6.66}
[INFO|trainer.py:4228] 2025-01-21 12:48:46,020 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:46,020 >>   Batch size = 64
 22%|████████████████████████████████████████████████▊                                                                                                                                                                          | 1150/5160 [28:50<1:09:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:48:53,388 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01268752571195364, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008536790497601032, 'eval_loss_2': 0.0041507333517074585, 'eval_loss_3': -18.230445861816406, 'eval_loss_4': 2.2208750247955322, 'epoch': 6.66}
{'loss': 0.0211, 'grad_norm': 15.506580352783203, 'learning_rate': 2.3360465116279072e-05, 'loss_1': 0.017550960183143616, 'loss_2': 0.0035400390625, 'loss_3': -16.270950317382812, 'loss_4': 2.2718665599823, 'epoch': 6.66}
{'loss': 0.0203, 'grad_norm': 9.608131408691406, 'learning_rate': 2.3354651162790697e-05, 'loss_1': 0.01835605688393116, 'loss_2': 0.001979827880859375, 'loss_3': -15.829411506652832, 'loss_4': 2.34482741355896, 'epoch': 6.67}
{'loss': 0.018, 'grad_norm': 10.938511848449707, 'learning_rate': 2.3348837209302326e-05, 'loss_1': 0.017791466787457466, 'loss_2': 0.00019228458404541016, 'loss_3': -16.216184616088867, 'loss_4': 2.4011623859405518, 'epoch': 6.67}
{'loss': 0.0422, 'grad_norm': 13.38955307006836, 'learning_rate': 2.3343023255813955e-05, 'loss_1': 0.03464340791106224, 'loss_2': 0.0075836181640625, 'loss_3': -16.125593185424805, 'loss_4': 3.110166549682617, 'epoch': 6.68}
{'loss': 0.0134, 'grad_norm': 5.851352214813232, 'learning_rate': 2.3337209302325583e-05, 'loss_1': 0.01036108285188675, 'loss_2': 0.0030059814453125, 'loss_3': -16.21765899658203, 'loss_4': 2.5793375968933105, 'epoch': 6.69}
[INFO|trainer.py:4228] 2025-01-21 12:48:53,388 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:48:53,388 >>   Batch size = 64
 22%|█████████████████████████████████████████████████                                                                                                                                                                          | 1155/5160 [28:57<1:09:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:00,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012932462617754936, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.526, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008707551285624504, 'eval_loss_2': 0.004224911332130432, 'eval_loss_3': -18.242883682250977, 'eval_loss_4': 2.2144837379455566, 'epoch': 6.69}
{'loss': 0.0256, 'grad_norm': 9.059109687805176, 'learning_rate': 2.333139534883721e-05, 'loss_1': 0.02042776718735695, 'loss_2': 0.005161285400390625, 'loss_3': -16.07973861694336, 'loss_4': 3.331368923187256, 'epoch': 6.69}
{'loss': 0.0161, 'grad_norm': 6.775950908660889, 'learning_rate': 2.3325581395348837e-05, 'loss_1': 0.013155709020793438, 'loss_2': 0.002971649169921875, 'loss_3': -16.130956649780273, 'loss_4': 2.6882030963897705, 'epoch': 6.7}
{'loss': 0.0341, 'grad_norm': 17.834543228149414, 'learning_rate': 2.3319767441860466e-05, 'loss_1': 0.028892211616039276, 'loss_2': 0.005191802978515625, 'loss_3': -16.056076049804688, 'loss_4': 2.4032888412475586, 'epoch': 6.7}
{'loss': 0.0284, 'grad_norm': 9.443900108337402, 'learning_rate': 2.3313953488372095e-05, 'loss_1': 0.020982131361961365, 'loss_2': 0.00740814208984375, 'loss_3': -16.19317626953125, 'loss_4': 2.8285248279571533, 'epoch': 6.71}
{'loss': 0.0222, 'grad_norm': 7.946367263793945, 'learning_rate': 2.3308139534883723e-05, 'loss_1': 0.016394371166825294, 'loss_2': 0.00577545166015625, 'loss_3': -16.149471282958984, 'loss_4': 2.3768839836120605, 'epoch': 6.72}
[INFO|trainer.py:4228] 2025-01-21 12:49:00,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:00,763 >>   Batch size = 64
 22%|█████████████████████████████████████████████████▏                                                                                                                                                                         | 1160/5160 [29:05<1:09:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:08,129 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011969709768891335, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.824, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008864670991897583, 'eval_loss_2': 0.0031050369143486023, 'eval_loss_3': -18.255138397216797, 'eval_loss_4': 2.2650766372680664, 'epoch': 6.72}
{'loss': 0.0225, 'grad_norm': 9.537823677062988, 'learning_rate': 2.330232558139535e-05, 'loss_1': 0.0184478759765625, 'loss_2': 0.00400543212890625, 'loss_3': -16.1304931640625, 'loss_4': 2.325413703918457, 'epoch': 6.72}
{'loss': 0.0169, 'grad_norm': 5.976108074188232, 'learning_rate': 2.3296511627906977e-05, 'loss_1': 0.013504203408956528, 'loss_2': 0.0034332275390625, 'loss_3': -16.15860366821289, 'loss_4': 2.1023447513580322, 'epoch': 6.73}
{'loss': 0.0456, 'grad_norm': 13.545802116394043, 'learning_rate': 2.3290697674418606e-05, 'loss_1': 0.041071753948926926, 'loss_2': 0.00457000732421875, 'loss_3': -16.226869583129883, 'loss_4': 2.3830103874206543, 'epoch': 6.73}
{'loss': 0.1579, 'grad_norm': 36.068885803222656, 'learning_rate': 2.3284883720930234e-05, 'loss_1': 0.15547917783260345, 'loss_2': 0.002384185791015625, 'loss_3': -16.18819808959961, 'loss_4': 2.974879264831543, 'epoch': 6.74}
{'loss': 0.0261, 'grad_norm': 7.966414928436279, 'learning_rate': 2.3279069767441863e-05, 'loss_1': 0.019245536997914314, 'loss_2': 0.00689697265625, 'loss_3': -16.160213470458984, 'loss_4': 2.2351126670837402, 'epoch': 6.74}
[INFO|trainer.py:4228] 2025-01-21 12:49:08,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:08,129 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▍                                                                                                                                                                         | 1165/5160 [29:12<1:09:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:15,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013050793670117855, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.757, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009115799330174923, 'eval_loss_2': 0.003934994339942932, 'eval_loss_3': -18.25116729736328, 'eval_loss_4': 1.9529019594192505, 'epoch': 6.74}
{'loss': 0.032, 'grad_norm': 6.546110153198242, 'learning_rate': 2.3273255813953488e-05, 'loss_1': 0.020284339785575867, 'loss_2': 0.01175689697265625, 'loss_3': -16.16519546508789, 'loss_4': 2.0679733753204346, 'epoch': 6.75}
{'loss': 0.026, 'grad_norm': 10.884245872497559, 'learning_rate': 2.3267441860465117e-05, 'loss_1': 0.02592787705361843, 'loss_2': 7.474422454833984e-05, 'loss_3': -15.965662002563477, 'loss_4': 2.0701680183410645, 'epoch': 6.76}
{'loss': 0.017, 'grad_norm': 8.3004789352417, 'learning_rate': 2.3261627906976742e-05, 'loss_1': 0.015597794204950333, 'loss_2': 0.0014057159423828125, 'loss_3': -16.115819931030273, 'loss_4': 1.7745146751403809, 'epoch': 6.76}
{'loss': 0.0246, 'grad_norm': 15.302931785583496, 'learning_rate': 2.3255813953488374e-05, 'loss_1': 0.02419489249587059, 'loss_2': 0.0003986358642578125, 'loss_3': -16.05377197265625, 'loss_4': 2.001713752746582, 'epoch': 6.77}
{'loss': 0.0135, 'grad_norm': 7.953303813934326, 'learning_rate': 2.3250000000000003e-05, 'loss_1': 0.012277722358703613, 'loss_2': 0.0011882781982421875, 'loss_3': -16.275588989257812, 'loss_4': 1.8949453830718994, 'epoch': 6.77}
[INFO|trainer.py:4228] 2025-01-21 12:49:15,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:15,493 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▋                                                                                                                                                                         | 1170/5160 [29:20<1:09:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:22,859 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01263190433382988, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.571, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009481141343712807, 'eval_loss_2': 0.003150761127471924, 'eval_loss_3': -18.209638595581055, 'eval_loss_4': 1.7820682525634766, 'epoch': 6.77}
{'loss': 0.0365, 'grad_norm': 10.41188907623291, 'learning_rate': 2.3244186046511628e-05, 'loss_1': 0.0332157239317894, 'loss_2': 0.00333404541015625, 'loss_3': -15.943947792053223, 'loss_4': 1.7241053581237793, 'epoch': 6.78}
{'loss': 0.0104, 'grad_norm': 5.216730117797852, 'learning_rate': 2.3238372093023257e-05, 'loss_1': 0.008633367717266083, 'loss_2': 0.00179290771484375, 'loss_3': -16.097333908081055, 'loss_4': 1.5882954597473145, 'epoch': 6.78}
{'loss': 0.0185, 'grad_norm': 10.532691955566406, 'learning_rate': 2.3232558139534882e-05, 'loss_1': 0.017644070088863373, 'loss_2': 0.0008449554443359375, 'loss_3': -15.949651718139648, 'loss_4': 1.758960485458374, 'epoch': 6.79}
{'loss': 0.0192, 'grad_norm': 8.636183738708496, 'learning_rate': 2.3226744186046514e-05, 'loss_1': 0.017800191417336464, 'loss_2': 0.0014247894287109375, 'loss_3': -16.07880973815918, 'loss_4': 1.6404502391815186, 'epoch': 6.8}
{'loss': 0.0126, 'grad_norm': 6.13589334487915, 'learning_rate': 2.322093023255814e-05, 'loss_1': 0.010989103466272354, 'loss_2': 0.00160980224609375, 'loss_3': -16.116214752197266, 'loss_4': 1.6507856845855713, 'epoch': 6.8}
[INFO|trainer.py:4228] 2025-01-21 12:49:22,859 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:22,859 >>   Batch size = 64
 23%|█████████████████████████████████████████████████▊                                                                                                                                                                         | 1175/5160 [29:27<1:09:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:30,226 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015533411875367165, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010832096450030804, 'eval_loss_2': 0.0047013163566589355, 'eval_loss_3': -18.179750442504883, 'eval_loss_4': 1.7738703489303589, 'epoch': 6.8}
{'loss': 0.019, 'grad_norm': 5.261571884155273, 'learning_rate': 2.3215116279069768e-05, 'loss_1': 0.011726748198270798, 'loss_2': 0.007289886474609375, 'loss_3': -16.162883758544922, 'loss_4': 1.7497437000274658, 'epoch': 6.81}
{'loss': 0.0175, 'grad_norm': 7.488417625427246, 'learning_rate': 2.3209302325581396e-05, 'loss_1': 0.01692635752260685, 'loss_2': 0.0005555152893066406, 'loss_3': -15.989913940429688, 'loss_4': 1.6592462062835693, 'epoch': 6.81}
{'loss': 0.0091, 'grad_norm': 5.425441741943359, 'learning_rate': 2.320348837209302e-05, 'loss_1': 0.007498213090002537, 'loss_2': 0.0015926361083984375, 'loss_3': -16.229568481445312, 'loss_4': 1.4253990650177002, 'epoch': 6.82}
{'loss': 0.0215, 'grad_norm': 9.18941593170166, 'learning_rate': 2.3197674418604654e-05, 'loss_1': 0.016920119524002075, 'loss_2': 0.00457763671875, 'loss_3': -16.13387680053711, 'loss_4': 1.4363576173782349, 'epoch': 6.83}
{'loss': 0.0239, 'grad_norm': 8.802074432373047, 'learning_rate': 2.319186046511628e-05, 'loss_1': 0.01708805561065674, 'loss_2': 0.0068206787109375, 'loss_3': -16.24842643737793, 'loss_4': 1.3041918277740479, 'epoch': 6.83}
[INFO|trainer.py:4228] 2025-01-21 12:49:30,226 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:30,226 >>   Batch size = 64
 23%|██████████████████████████████████████████████████                                                                                                                                                                         | 1180/5160 [29:34<1:09:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:37,600 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01908840239048004, 'eval_runtime': 3.8171, 'eval_samples_per_second': 268.269, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.013584388419985771, 'eval_loss_2': 0.005504012107849121, 'eval_loss_3': -18.143535614013672, 'eval_loss_4': 1.3495771884918213, 'epoch': 6.83}
{'loss': 0.0412, 'grad_norm': 17.774450302124023, 'learning_rate': 2.3186046511627907e-05, 'loss_1': 0.031008053570985794, 'loss_2': 0.01020050048828125, 'loss_3': -16.193592071533203, 'loss_4': 1.156813144683838, 'epoch': 6.84}
{'loss': 0.0166, 'grad_norm': 6.7943596839904785, 'learning_rate': 2.3180232558139536e-05, 'loss_1': 0.009683896787464619, 'loss_2': 0.00690460205078125, 'loss_3': -16.165929794311523, 'loss_4': 0.9686480760574341, 'epoch': 6.84}
{'loss': 0.0098, 'grad_norm': 6.224272727966309, 'learning_rate': 2.317441860465116e-05, 'loss_1': 0.008713588118553162, 'loss_2': 0.0011348724365234375, 'loss_3': -15.969144821166992, 'loss_4': 1.4127055406570435, 'epoch': 6.85}
{'loss': 0.0456, 'grad_norm': 21.267200469970703, 'learning_rate': 2.3168604651162793e-05, 'loss_1': 0.03925960138440132, 'loss_2': 0.006290435791015625, 'loss_3': -16.023681640625, 'loss_4': 1.1475255489349365, 'epoch': 6.85}
{'loss': 0.0158, 'grad_norm': 10.252394676208496, 'learning_rate': 2.316279069767442e-05, 'loss_1': 0.013673772104084492, 'loss_2': 0.002147674560546875, 'loss_3': -16.217300415039062, 'loss_4': 0.999035120010376, 'epoch': 6.86}
[INFO|trainer.py:4228] 2025-01-21 12:49:37,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:37,601 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▎                                                                                                                                                                        | 1185/5160 [29:42<1:08:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:44,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014790588058531284, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.713, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.011638486757874489, 'eval_loss_2': 0.00315210223197937, 'eval_loss_3': -18.173852920532227, 'eval_loss_4': 0.7492544054985046, 'epoch': 6.86}
{'loss': 0.0239, 'grad_norm': 9.463343620300293, 'learning_rate': 2.3156976744186047e-05, 'loss_1': 0.022522417828440666, 'loss_2': 0.0014200210571289062, 'loss_3': -15.96007251739502, 'loss_4': 0.6627225875854492, 'epoch': 6.87}
{'loss': 0.058, 'grad_norm': 18.923553466796875, 'learning_rate': 2.3151162790697673e-05, 'loss_1': 0.05657638981938362, 'loss_2': 0.0014476776123046875, 'loss_3': -16.109617233276367, 'loss_4': 1.4255011081695557, 'epoch': 6.87}
{'loss': 0.021, 'grad_norm': 5.445211410522461, 'learning_rate': 2.31453488372093e-05, 'loss_1': 0.009020362049341202, 'loss_2': 0.011932373046875, 'loss_3': -16.229999542236328, 'loss_4': 0.3815041184425354, 'epoch': 6.88}
{'loss': 0.0172, 'grad_norm': 6.935335159301758, 'learning_rate': 2.3139534883720933e-05, 'loss_1': 0.015179493464529514, 'loss_2': 0.00200653076171875, 'loss_3': -16.178194046020508, 'loss_4': 0.9610400199890137, 'epoch': 6.88}
{'loss': 0.0219, 'grad_norm': 7.28887414932251, 'learning_rate': 2.313372093023256e-05, 'loss_1': 0.020053841173648834, 'loss_2': 0.001804351806640625, 'loss_3': -16.371559143066406, 'loss_4': -0.3505452573299408, 'epoch': 6.89}
[INFO|trainer.py:4228] 2025-01-21 12:49:44,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:44,965 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▌                                                                                                                                                                        | 1190/5160 [29:49<1:08:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:52,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014375092461705208, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.95, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010803298093378544, 'eval_loss_2': 0.0035717934370040894, 'eval_loss_3': -18.187198638916016, 'eval_loss_4': 0.1318586766719818, 'epoch': 6.89}
{'loss': 0.0216, 'grad_norm': 11.323384284973145, 'learning_rate': 2.3127906976744187e-05, 'loss_1': 0.0186275914311409, 'loss_2': 0.002971649169921875, 'loss_3': -16.525833129882812, 'loss_4': -0.21751222014427185, 'epoch': 6.9}
{'loss': 0.0151, 'grad_norm': 8.250494003295898, 'learning_rate': 2.3122093023255812e-05, 'loss_1': 0.014187676832079887, 'loss_2': 0.0009126663208007812, 'loss_3': -16.020721435546875, 'loss_4': -0.32785505056381226, 'epoch': 6.9}
{'loss': 0.0172, 'grad_norm': 5.786115646362305, 'learning_rate': 2.311627906976744e-05, 'loss_1': 0.009316020645201206, 'loss_2': 0.0078887939453125, 'loss_3': -16.30572509765625, 'loss_4': 0.22609955072402954, 'epoch': 6.91}
{'loss': 0.025, 'grad_norm': 7.94216775894165, 'learning_rate': 2.3110465116279073e-05, 'loss_1': 0.019899878650903702, 'loss_2': 0.00510406494140625, 'loss_3': -16.27136993408203, 'loss_4': -0.20584355294704437, 'epoch': 6.91}
{'loss': 0.0117, 'grad_norm': 6.253385543823242, 'learning_rate': 2.3104651162790698e-05, 'loss_1': 0.010706701315939426, 'loss_2': 0.0010089874267578125, 'loss_3': -16.157907485961914, 'loss_4': -0.1384502649307251, 'epoch': 6.92}
[INFO|trainer.py:4228] 2025-01-21 12:49:52,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:52,324 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▋                                                                                                                                                                        | 1195/5160 [29:56<1:08:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:49:59,685 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0163748599588871, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.01116781122982502, 'eval_loss_2': 0.005207046866416931, 'eval_loss_3': -18.209075927734375, 'eval_loss_4': -0.32144325971603394, 'epoch': 6.92}
{'loss': 0.0204, 'grad_norm': 7.542669773101807, 'learning_rate': 2.3098837209302327e-05, 'loss_1': 0.016318436712026596, 'loss_2': 0.0040740966796875, 'loss_3': -16.06136703491211, 'loss_4': -0.1869669407606125, 'epoch': 6.92}
{'loss': 0.0728, 'grad_norm': 31.660314559936523, 'learning_rate': 2.3093023255813952e-05, 'loss_1': 0.07272782176733017, 'loss_2': 9.059906005859375e-05, 'loss_3': -15.838635444641113, 'loss_4': 0.06034010648727417, 'epoch': 6.93}
{'loss': 0.0237, 'grad_norm': 9.929326057434082, 'learning_rate': 2.308720930232558e-05, 'loss_1': 0.016879916191101074, 'loss_2': 0.006816864013671875, 'loss_3': -16.104217529296875, 'loss_4': -0.7376923561096191, 'epoch': 6.94}
{'loss': 0.0118, 'grad_norm': 6.228155612945557, 'learning_rate': 2.308139534883721e-05, 'loss_1': 0.0100183030590415, 'loss_2': 0.0017604827880859375, 'loss_3': -16.261716842651367, 'loss_4': -0.9762378931045532, 'epoch': 6.94}
{'loss': 0.0306, 'grad_norm': 8.150988578796387, 'learning_rate': 2.3075581395348838e-05, 'loss_1': 0.02260778285562992, 'loss_2': 0.007965087890625, 'loss_3': -16.20604705810547, 'loss_4': -0.25879061222076416, 'epoch': 6.95}
[INFO|trainer.py:4228] 2025-01-21 12:49:59,686 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:49:59,686 >>   Batch size = 64
 23%|██████████████████████████████████████████████████▉                                                                                                                                                                        | 1200/5160 [30:04<1:08:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:07,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01696762815117836, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.792, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012416276149451733, 'eval_loss_2': 0.004551351070404053, 'eval_loss_3': -18.222021102905273, 'eval_loss_4': -0.72004234790802, 'epoch': 6.95}
{'loss': 0.0114, 'grad_norm': 4.963057994842529, 'learning_rate': 2.3069767441860467e-05, 'loss_1': 0.006907963193953037, 'loss_2': 0.00449371337890625, 'loss_3': -16.321462631225586, 'loss_4': 0.012986809015274048, 'epoch': 6.95}
{'loss': 0.0256, 'grad_norm': 6.885290622711182, 'learning_rate': 2.3063953488372092e-05, 'loss_1': 0.019759763032197952, 'loss_2': 0.005840301513671875, 'loss_3': -16.14310073852539, 'loss_4': -1.004088044166565, 'epoch': 6.96}
{'loss': 0.0327, 'grad_norm': 8.261646270751953, 'learning_rate': 2.3058139534883724e-05, 'loss_1': 0.026947656646370888, 'loss_2': 0.00577545166015625, 'loss_3': -16.02297592163086, 'loss_4': -0.12007725238800049, 'epoch': 6.97}
{'loss': 0.0143, 'grad_norm': 6.6074371337890625, 'learning_rate': 2.305232558139535e-05, 'loss_1': 0.013385399244725704, 'loss_2': 0.0009517669677734375, 'loss_3': -16.25556182861328, 'loss_4': -0.25867223739624023, 'epoch': 6.97}
{'loss': 0.0413, 'grad_norm': 12.421440124511719, 'learning_rate': 2.3046511627906978e-05, 'loss_1': 0.03727716952562332, 'loss_2': 0.0040283203125, 'loss_3': -16.094009399414062, 'loss_4': -0.4848724603652954, 'epoch': 6.98}
[INFO|trainer.py:4228] 2025-01-21 12:50:07,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:07,041 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▏                                                                                                                                                                       | 1205/5160 [30:11<1:04:34,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 12:50:14,094 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01636756956577301, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.443, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011464819312095642, 'eval_loss_2': 0.004902750253677368, 'eval_loss_3': -18.230058670043945, 'eval_loss_4': -0.6929837465286255, 'epoch': 6.98}
{'loss': 0.0122, 'grad_norm': 5.769559860229492, 'learning_rate': 2.3040697674418606e-05, 'loss_1': 0.00794441718608141, 'loss_2': 0.0042266845703125, 'loss_3': -16.156635284423828, 'loss_4': -0.2285967618227005, 'epoch': 6.98}
{'loss': 0.0236, 'grad_norm': 5.664840221405029, 'learning_rate': 2.303488372093023e-05, 'loss_1': 0.019627368077635765, 'loss_2': 0.003936767578125, 'loss_3': -16.218109130859375, 'loss_4': -0.11030332744121552, 'epoch': 6.99}
{'loss': 0.0175, 'grad_norm': 9.941427230834961, 'learning_rate': 2.3029069767441864e-05, 'loss_1': 0.016424372792243958, 'loss_2': 0.0010585784912109375, 'loss_3': -16.38159942626953, 'loss_4': -0.2517462968826294, 'epoch': 6.99}
{'loss': 0.0071, 'grad_norm': 6.244786739349365, 'learning_rate': 2.302325581395349e-05, 'loss_1': 0.005826896522194147, 'loss_2': 0.0013217926025390625, 'loss_3': -16.337812423706055, 'loss_4': -0.19911888241767883, 'epoch': 7.0}
{'loss': 0.0183, 'grad_norm': 6.3424153327941895, 'learning_rate': 2.3017441860465118e-05, 'loss_1': 0.016329742968082428, 'loss_2': 0.0019989013671875, 'loss_3': -16.12095832824707, 'loss_4': -0.8164469003677368, 'epoch': 7.01}
[INFO|trainer.py:4228] 2025-01-21 12:50:14,094 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:14,094 >>   Batch size = 64
 23%|███████████████████████████████████████████████████▎                                                                                                                                                                       | 1210/5160 [30:18<1:07:46,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 12:50:21,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019269894808530807, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.29, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.012646968476474285, 'eval_loss_2': 0.006622925400733948, 'eval_loss_3': -18.223388671875, 'eval_loss_4': -0.6303810477256775, 'epoch': 7.01}
{'loss': 0.0374, 'grad_norm': 14.301825523376465, 'learning_rate': 2.3011627906976743e-05, 'loss_1': 0.03319336846470833, 'loss_2': 0.004199981689453125, 'loss_3': -16.374229431152344, 'loss_4': -0.746284008026123, 'epoch': 7.01}
{'loss': 0.0349, 'grad_norm': 12.358293533325195, 'learning_rate': 2.300581395348837e-05, 'loss_1': 0.031032763421535492, 'loss_2': 0.00386810302734375, 'loss_3': -16.141578674316406, 'loss_4': -0.09293238073587418, 'epoch': 7.02}
{'loss': 0.0328, 'grad_norm': 8.787137985229492, 'learning_rate': 2.3000000000000003e-05, 'loss_1': 0.02437586709856987, 'loss_2': 0.0084075927734375, 'loss_3': -16.204437255859375, 'loss_4': -0.9074080586433411, 'epoch': 7.02}
{'loss': 0.0285, 'grad_norm': 9.356812477111816, 'learning_rate': 2.299418604651163e-05, 'loss_1': 0.02494893968105316, 'loss_2': 0.003513336181640625, 'loss_3': -16.043338775634766, 'loss_4': -0.033353693783283234, 'epoch': 7.03}
{'loss': 0.0118, 'grad_norm': 5.064920902252197, 'learning_rate': 2.2988372093023257e-05, 'loss_1': 0.009831549599766731, 'loss_2': 0.0019969940185546875, 'loss_3': -16.197864532470703, 'loss_4': -0.40273845195770264, 'epoch': 7.03}
[INFO|trainer.py:4228] 2025-01-21 12:50:21,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:21,458 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:25<1:08:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:28,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013590285554528236, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.565, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009080270305275917, 'eval_loss_2': 0.004510015249252319, 'eval_loss_3': -18.237712860107422, 'eval_loss_4': -0.37923645973205566, 'epoch': 7.03}
{'loss': 0.0157, 'grad_norm': 6.784626483917236, 'learning_rate': 2.2982558139534883e-05, 'loss_1': 0.015330095775425434, 'loss_2': 0.0003540515899658203, 'loss_3': -16.238666534423828, 'loss_4': 0.15253721177577972, 'epoch': 7.04}
{'loss': 0.0199, 'grad_norm': 10.88362979888916, 'learning_rate': 2.297674418604651e-05, 'loss_1': 0.01697838306427002, 'loss_2': 0.0028839111328125, 'loss_3': -16.067367553710938, 'loss_4': -0.23265674710273743, 'epoch': 7.05}
{'loss': 0.0383, 'grad_norm': 10.377102851867676, 'learning_rate': 2.2970930232558143e-05, 'loss_1': 0.035770632326602936, 'loss_2': 0.0025234222412109375, 'loss_3': -16.416776657104492, 'loss_4': -0.3637006878852844, 'epoch': 7.05}
{'loss': 0.0193, 'grad_norm': 7.8085432052612305, 'learning_rate': 2.296511627906977e-05, 'loss_1': 0.017365915700793266, 'loss_2': 0.001972198486328125, 'loss_3': -16.31914710998535, 'loss_4': -0.16072380542755127, 'epoch': 7.06}
{'loss': 0.0269, 'grad_norm': 8.39589786529541, 'learning_rate': 2.2959302325581397e-05, 'loss_1': 0.021250328049063683, 'loss_2': 0.0056304931640625, 'loss_3': -16.516738891601562, 'loss_4': 0.2472429871559143, 'epoch': 7.06}
[INFO|trainer.py:4228] 2025-01-21 12:50:28,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:28,827 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▌                                                                                                                                                                       | 1215/5160 [30:29<1:08:19,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:50:32,636 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1215
[INFO|configuration_utils.py:420] 2025-01-21 12:50:32,637 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1215/config.json                                                                            
{'eval_loss': 0.009606593288481236, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.947, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007352978922426701, 'eval_loss_2': 0.002253614366054535, 'eval_loss_3': -18.26836395263672, 'eval_loss_4': -0.09304127097129822, 'epoch': 7.06}
[INFO|modeling_utils.py:2988] 2025-01-21 12:50:33,122 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1215/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:50:33,123 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1215/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:50:33,124 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1215/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:50:34,073 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-750] due to args.save_total_limit
 24%|███████████████████████████████████████████████████▊                                                                                                                                                                       | 1220/5160 [30:34<1:15:26,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:50:37,709 >>
{'loss': 0.0271, 'grad_norm': 9.184056282043457, 'learning_rate': 2.2953488372093022e-05, 'loss_1': 0.015342455357313156, 'loss_2': 0.01178741455078125, 'loss_3': -16.31273651123047, 'loss_4': 0.3290451765060425, 'epoch': 7.07}
{'loss': 0.0191, 'grad_norm': 7.507098197937012, 'learning_rate': 2.294767441860465e-05, 'loss_1': 0.017927436158061028, 'loss_2': 0.0011768341064453125, 'loss_3': -15.971237182617188, 'loss_4': 1.0222206115722656, 'epoch': 7.08}
{'loss': 0.0142, 'grad_norm': 5.698087692260742, 'learning_rate': 2.294186046511628e-05, 'loss_1': 0.008982084691524506, 'loss_2': 0.00518798828125, 'loss_3': -16.139171600341797, 'loss_4': 0.09640996903181076, 'epoch': 7.08}
{'loss': 0.0248, 'grad_norm': 8.732754707336426, 'learning_rate': 2.2936046511627908e-05, 'loss_1': 0.01294315978884697, 'loss_2': 0.011810302734375, 'loss_3': -16.174999237060547, 'loss_4': 0.42212802171707153, 'epoch': 7.09}
{'loss': 0.0733, 'grad_norm': 17.317720413208008, 'learning_rate': 2.2930232558139537e-05, 'loss_1': 0.06497204303741455, 'loss_2': 0.00835418701171875, 'loss_3': -16.212444305419922, 'loss_4': 1.0823485851287842, 'epoch': 7.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:50:37,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:37,709 >>   Batch size = 64
 24%|███████████████████████████████████████████████████▉                                                                                                                                                                       | 1225/5160 [30:42<1:09:19,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:50:45,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013104621320962906, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007442031521350145, 'eval_loss_2': 0.005662590265274048, 'eval_loss_3': -18.245975494384766, 'eval_loss_4': 0.3408881425857544, 'epoch': 7.09}
{'loss': 0.0186, 'grad_norm': 5.009909152984619, 'learning_rate': 2.2924418604651162e-05, 'loss_1': 0.0091436468064785, 'loss_2': 0.0094757080078125, 'loss_3': -16.399383544921875, 'loss_4': 0.8571352958679199, 'epoch': 7.1}
{'loss': 0.032, 'grad_norm': 8.86493968963623, 'learning_rate': 2.291860465116279e-05, 'loss_1': 0.026580458506941795, 'loss_2': 0.005458831787109375, 'loss_3': -16.194852828979492, 'loss_4': 0.4802992343902588, 'epoch': 7.1}
{'loss': 0.0147, 'grad_norm': 6.767936706542969, 'learning_rate': 2.291279069767442e-05, 'loss_1': 0.013615330681204796, 'loss_2': 0.0011281967163085938, 'loss_3': -16.327796936035156, 'loss_4': 0.11524742841720581, 'epoch': 7.11}
{'loss': 0.0229, 'grad_norm': 7.6472649574279785, 'learning_rate': 2.2906976744186048e-05, 'loss_1': 0.019191499799489975, 'loss_2': 0.003719329833984375, 'loss_3': -16.205036163330078, 'loss_4': 0.8568389415740967, 'epoch': 7.12}
{'loss': 0.0201, 'grad_norm': 7.658222675323486, 'learning_rate': 2.2901162790697677e-05, 'loss_1': 0.01757025346159935, 'loss_2': 0.00250244140625, 'loss_3': -16.293392181396484, 'loss_4': 0.6031454801559448, 'epoch': 7.12}
[INFO|trainer.py:4228] 2025-01-21 12:50:45,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:45,064 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▏                                                                                                                                                                      | 1230/5160 [30:49<1:08:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:52,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014905158430337906, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.837, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011196707375347614, 'eval_loss_2': 0.003708451986312866, 'eval_loss_3': -18.239198684692383, 'eval_loss_4': 0.34132012724876404, 'epoch': 7.12}
{'loss': 0.0195, 'grad_norm': 6.766160011291504, 'learning_rate': 2.2895348837209302e-05, 'loss_1': 0.01534714549779892, 'loss_2': 0.004180908203125, 'loss_3': -16.159093856811523, 'loss_4': 0.04431557655334473, 'epoch': 7.13}
{'loss': 0.0335, 'grad_norm': 8.9142484664917, 'learning_rate': 2.288953488372093e-05, 'loss_1': 0.02807769738137722, 'loss_2': 0.005413055419921875, 'loss_3': -16.238815307617188, 'loss_4': 0.1821213662624359, 'epoch': 7.13}
{'loss': 0.041, 'grad_norm': 13.993616104125977, 'learning_rate': 2.288372093023256e-05, 'loss_1': 0.03684058040380478, 'loss_2': 0.0041351318359375, 'loss_3': -16.457616806030273, 'loss_4': 0.2909623384475708, 'epoch': 7.14}
{'loss': 0.0216, 'grad_norm': 6.708907604217529, 'learning_rate': 2.2877906976744188e-05, 'loss_1': 0.015466222539544106, 'loss_2': 0.0060882568359375, 'loss_3': -16.26894760131836, 'loss_4': 0.822020947933197, 'epoch': 7.15}
{'loss': 0.0282, 'grad_norm': 7.3659234046936035, 'learning_rate': 2.2872093023255813e-05, 'loss_1': 0.020459791645407677, 'loss_2': 0.007701873779296875, 'loss_3': -16.442886352539062, 'loss_4': 0.03959089517593384, 'epoch': 7.15}
[INFO|trainer.py:4228] 2025-01-21 12:50:52,425 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:52,425 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▍                                                                                                                                                                      | 1235/5160 [30:56<1:08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:50:59,793 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018049687147140503, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.374, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.013901500031352043, 'eval_loss_2': 0.0041481852531433105, 'eval_loss_3': -18.219478607177734, 'eval_loss_4': 0.25612130761146545, 'epoch': 7.15}
{'loss': 0.0226, 'grad_norm': 6.864758014678955, 'learning_rate': 2.286627906976744e-05, 'loss_1': 0.017024420201778412, 'loss_2': 0.00554656982421875, 'loss_3': -16.21487808227539, 'loss_4': -0.2763747572898865, 'epoch': 7.16}
{'loss': 0.0724, 'grad_norm': 21.846893310546875, 'learning_rate': 2.286046511627907e-05, 'loss_1': 0.0704820454120636, 'loss_2': 0.001922607421875, 'loss_3': -16.14272689819336, 'loss_4': 0.35779422521591187, 'epoch': 7.16}
{'loss': 0.0206, 'grad_norm': 6.797190189361572, 'learning_rate': 2.28546511627907e-05, 'loss_1': 0.019775107502937317, 'loss_2': 0.0008401870727539062, 'loss_3': -16.47646713256836, 'loss_4': 0.6098830103874207, 'epoch': 7.17}
{'loss': 0.0305, 'grad_norm': 11.062994956970215, 'learning_rate': 2.2848837209302328e-05, 'loss_1': 0.026287339627742767, 'loss_2': 0.00421905517578125, 'loss_3': -16.198287963867188, 'loss_4': 0.569129467010498, 'epoch': 7.17}
{'loss': 0.0286, 'grad_norm': 6.230666637420654, 'learning_rate': 2.2843023255813953e-05, 'loss_1': 0.018095936626195908, 'loss_2': 0.010498046875, 'loss_3': -16.02300453186035, 'loss_4': 0.2652783989906311, 'epoch': 7.18}
[INFO|trainer.py:4228] 2025-01-21 12:50:59,793 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:50:59,793 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▋                                                                                                                                                                      | 1240/5160 [31:04<1:08:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:07,165 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02195359393954277, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.566, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01485542580485344, 'eval_loss_2': 0.007098168134689331, 'eval_loss_3': -18.213409423828125, 'eval_loss_4': 0.5190197229385376, 'epoch': 7.18}
{'loss': 0.0317, 'grad_norm': 8.526534080505371, 'learning_rate': 2.283720930232558e-05, 'loss_1': 0.02127043530344963, 'loss_2': 0.01043701171875, 'loss_3': -16.461944580078125, 'loss_4': 0.26969093084335327, 'epoch': 7.19}
{'loss': 0.0644, 'grad_norm': 28.81006622314453, 'learning_rate': 2.283139534883721e-05, 'loss_1': 0.061460692435503006, 'loss_2': 0.002918243408203125, 'loss_3': -16.09672737121582, 'loss_4': 0.5334521532058716, 'epoch': 7.19}
{'loss': 0.0378, 'grad_norm': 9.402222633361816, 'learning_rate': 2.282558139534884e-05, 'loss_1': 0.032485704869031906, 'loss_2': 0.0053558349609375, 'loss_3': -16.386442184448242, 'loss_4': 0.542532205581665, 'epoch': 7.2}
{'loss': 0.0262, 'grad_norm': 8.585153579711914, 'learning_rate': 2.2819767441860467e-05, 'loss_1': 0.02294749580323696, 'loss_2': 0.00322723388671875, 'loss_3': -16.337596893310547, 'loss_4': 0.714233934879303, 'epoch': 7.2}
{'loss': 0.0146, 'grad_norm': 6.052867889404297, 'learning_rate': 2.2813953488372093e-05, 'loss_1': 0.012216847389936447, 'loss_2': 0.0023345947265625, 'loss_3': -16.268075942993164, 'loss_4': 0.39863747358322144, 'epoch': 7.21}
[INFO|trainer.py:4228] 2025-01-21 12:51:07,165 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:07,165 >>   Batch size = 64
 24%|████████████████████████████████████████████████████▊                                                                                                                                                                      | 1245/5160 [31:11<1:07:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:14,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018929850310087204, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.433, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.014679874293506145, 'eval_loss_2': 0.004249975085258484, 'eval_loss_3': -18.207929611206055, 'eval_loss_4': 0.7659482955932617, 'epoch': 7.21}
{'loss': 0.0193, 'grad_norm': 6.694381237030029, 'learning_rate': 2.280813953488372e-05, 'loss_1': 0.01790197193622589, 'loss_2': 0.001377105712890625, 'loss_3': -16.232437133789062, 'loss_4': 0.6244158744812012, 'epoch': 7.22}
{'loss': 0.0193, 'grad_norm': 8.202054023742676, 'learning_rate': 2.2802325581395346e-05, 'loss_1': 0.015648864209651947, 'loss_2': 0.00363922119140625, 'loss_3': -16.24118423461914, 'loss_4': 1.1738221645355225, 'epoch': 7.22}
{'loss': 0.0129, 'grad_norm': 5.043391227722168, 'learning_rate': 2.279651162790698e-05, 'loss_1': 0.009733922779560089, 'loss_2': 0.003131866455078125, 'loss_3': -16.321531295776367, 'loss_4': 1.184862494468689, 'epoch': 7.23}
{'loss': 0.0344, 'grad_norm': 9.187134742736816, 'learning_rate': 2.2790697674418607e-05, 'loss_1': 0.025002211332321167, 'loss_2': 0.00936126708984375, 'loss_3': -16.1726131439209, 'loss_4': 0.7663103342056274, 'epoch': 7.23}
{'loss': 0.024, 'grad_norm': 10.875189781188965, 'learning_rate': 2.2784883720930232e-05, 'loss_1': 0.01678018644452095, 'loss_2': 0.007171630859375, 'loss_3': -16.199716567993164, 'loss_4': 0.6844474077224731, 'epoch': 7.24}
[INFO|trainer.py:4228] 2025-01-21 12:51:14,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:14,532 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████                                                                                                                                                                      | 1250/5160 [31:19<1:07:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:21,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01666289195418358, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.6, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.012011904269456863, 'eval_loss_2': 0.004650987684726715, 'eval_loss_3': -18.165130615234375, 'eval_loss_4': 1.0220800638198853, 'epoch': 7.24}
{'loss': 0.012, 'grad_norm': 5.399659633636475, 'learning_rate': 2.277906976744186e-05, 'loss_1': 0.007625422440469265, 'loss_2': 0.004383087158203125, 'loss_3': -16.27370834350586, 'loss_4': 0.728535532951355, 'epoch': 7.24}
{'loss': 0.0217, 'grad_norm': 8.01717758178711, 'learning_rate': 2.2773255813953486e-05, 'loss_1': 0.0209782924503088, 'loss_2': 0.0007228851318359375, 'loss_3': -16.348222732543945, 'loss_4': 1.3970128297805786, 'epoch': 7.25}
{'loss': 0.0281, 'grad_norm': 14.693052291870117, 'learning_rate': 2.2767441860465118e-05, 'loss_1': 0.026247497648000717, 'loss_2': 0.0018167495727539062, 'loss_3': -16.268611907958984, 'loss_4': 0.8852614164352417, 'epoch': 7.26}
{'loss': 0.0129, 'grad_norm': 6.604883193969727, 'learning_rate': 2.2761627906976747e-05, 'loss_1': 0.011826656758785248, 'loss_2': 0.0010280609130859375, 'loss_3': -16.06420135498047, 'loss_4': 0.7401422262191772, 'epoch': 7.26}
{'loss': 0.0185, 'grad_norm': 6.425743103027344, 'learning_rate': 2.2755813953488372e-05, 'loss_1': 0.015810413286089897, 'loss_2': 0.00270843505859375, 'loss_3': -16.144088745117188, 'loss_4': 0.9173676371574402, 'epoch': 7.27}
[INFO|trainer.py:4228] 2025-01-21 12:51:21,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:21,898 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▎                                                                                                                                                                     | 1255/5160 [31:26<1:07:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:29,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01622341014444828, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.775, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01151872519403696, 'eval_loss_2': 0.004704684019088745, 'eval_loss_3': -18.1889591217041, 'eval_loss_4': 0.9812833666801453, 'epoch': 7.27}
{'loss': 0.0289, 'grad_norm': 9.152016639709473, 'learning_rate': 2.275e-05, 'loss_1': 0.01716490276157856, 'loss_2': 0.0117645263671875, 'loss_3': -16.079193115234375, 'loss_4': 1.200803279876709, 'epoch': 7.27}
{'loss': 0.0163, 'grad_norm': 7.050744533538818, 'learning_rate': 2.2744186046511626e-05, 'loss_1': 0.013768238946795464, 'loss_2': 0.00251007080078125, 'loss_3': -16.076757431030273, 'loss_4': 1.253082513809204, 'epoch': 7.28}
{'loss': 0.0146, 'grad_norm': 7.491860389709473, 'learning_rate': 2.2738372093023258e-05, 'loss_1': 0.011977950111031532, 'loss_2': 0.002605438232421875, 'loss_3': -16.418590545654297, 'loss_4': 0.9875058531761169, 'epoch': 7.28}
{'loss': 0.041, 'grad_norm': 9.798811912536621, 'learning_rate': 2.2732558139534883e-05, 'loss_1': 0.03585907071828842, 'loss_2': 0.00510406494140625, 'loss_3': -16.20755386352539, 'loss_4': 0.8245892524719238, 'epoch': 7.29}
{'loss': 0.0382, 'grad_norm': 9.502313613891602, 'learning_rate': 2.2726744186046512e-05, 'loss_1': 0.03187768906354904, 'loss_2': 0.006328582763671875, 'loss_3': -16.08910369873047, 'loss_4': 0.9424083232879639, 'epoch': 7.3}
[INFO|trainer.py:4228] 2025-01-21 12:51:29,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:29,258 >>   Batch size = 64
 24%|█████████████████████████████████████████████████████▍                                                                                                                                                                     | 1260/5160 [31:33<1:07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:36,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01680579036474228, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.61, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010977526195347309, 'eval_loss_2': 0.005828261375427246, 'eval_loss_3': -18.20754623413086, 'eval_loss_4': 0.8242275714874268, 'epoch': 7.3}
{'loss': 0.0118, 'grad_norm': 6.211828708648682, 'learning_rate': 2.272093023255814e-05, 'loss_1': 0.009856363758444786, 'loss_2': 0.0019626617431640625, 'loss_3': -16.2135009765625, 'loss_4': 0.559135913848877, 'epoch': 7.3}
{'loss': 0.0683, 'grad_norm': 18.404516220092773, 'learning_rate': 2.2715116279069766e-05, 'loss_1': 0.06336066871881485, 'loss_2': 0.00496673583984375, 'loss_3': -16.066425323486328, 'loss_4': 0.832504391670227, 'epoch': 7.31}
{'loss': 0.0471, 'grad_norm': 14.546509742736816, 'learning_rate': 2.2709302325581398e-05, 'loss_1': 0.04458222910761833, 'loss_2': 0.0025310516357421875, 'loss_3': -16.083593368530273, 'loss_4': 1.3026251792907715, 'epoch': 7.31}
{'loss': 0.015, 'grad_norm': 6.487203121185303, 'learning_rate': 2.2703488372093023e-05, 'loss_1': 0.013357303105294704, 'loss_2': 0.0016651153564453125, 'loss_3': -16.12332534790039, 'loss_4': 0.9441036581993103, 'epoch': 7.32}
{'loss': 0.0213, 'grad_norm': 9.643683433532715, 'learning_rate': 2.269767441860465e-05, 'loss_1': 0.019932877272367477, 'loss_2': 0.0013675689697265625, 'loss_3': -16.115901947021484, 'loss_4': 0.7606371641159058, 'epoch': 7.33}
[INFO|trainer.py:4228] 2025-01-21 12:51:36,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:36,631 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▋                                                                                                                                                                     | 1265/5160 [31:41<1:07:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:44,009 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017705727368593216, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.325, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.013798930682241917, 'eval_loss_2': 0.003906797617673874, 'eval_loss_3': -18.158594131469727, 'eval_loss_4': 1.0222722291946411, 'epoch': 7.33}
{'loss': 0.093, 'grad_norm': 19.981658935546875, 'learning_rate': 2.269186046511628e-05, 'loss_1': 0.08478261530399323, 'loss_2': 0.00824737548828125, 'loss_3': -16.261131286621094, 'loss_4': 1.4070944786071777, 'epoch': 7.33}
{'loss': 0.0833, 'grad_norm': 21.20687484741211, 'learning_rate': 2.268604651162791e-05, 'loss_1': 0.07300737500190735, 'loss_2': 0.01029205322265625, 'loss_3': -16.224449157714844, 'loss_4': 0.38890573382377625, 'epoch': 7.34}
{'loss': 0.0142, 'grad_norm': 6.3815083503723145, 'learning_rate': 2.2680232558139538e-05, 'loss_1': 0.013912521302700043, 'loss_2': 0.0002655982971191406, 'loss_3': -16.2337589263916, 'loss_4': 0.7437730431556702, 'epoch': 7.34}
{'loss': 0.024, 'grad_norm': 9.23459243774414, 'learning_rate': 2.2674418604651163e-05, 'loss_1': 0.019591283053159714, 'loss_2': 0.00440216064453125, 'loss_3': -16.41350555419922, 'loss_4': 0.9484820365905762, 'epoch': 7.35}
{'loss': 0.0547, 'grad_norm': 20.98015594482422, 'learning_rate': 2.266860465116279e-05, 'loss_1': 0.051905557513237, 'loss_2': 0.00281524658203125, 'loss_3': -16.24215316772461, 'loss_4': 1.7532017230987549, 'epoch': 7.35}
[INFO|trainer.py:4228] 2025-01-21 12:51:44,009 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:44,009 >>   Batch size = 64
 25%|█████████████████████████████████████████████████████▉                                                                                                                                                                     | 1270/5160 [31:48<1:07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:51,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020504740998148918, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.989, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.016111256554722786, 'eval_loss_2': 0.004393484443426132, 'eval_loss_3': -18.088031768798828, 'eval_loss_4': 1.5782347917556763, 'epoch': 7.35}
{'loss': 0.0266, 'grad_norm': 9.469259262084961, 'learning_rate': 2.2662790697674417e-05, 'loss_1': 0.022798661142587662, 'loss_2': 0.0037841796875, 'loss_3': -15.957745552062988, 'loss_4': 1.3653095960617065, 'epoch': 7.36}
{'loss': 0.0649, 'grad_norm': 21.71593475341797, 'learning_rate': 2.265697674418605e-05, 'loss_1': 0.0636407807469368, 'loss_2': 0.0012187957763671875, 'loss_3': -15.93869400024414, 'loss_4': 1.5921032428741455, 'epoch': 7.37}
{'loss': 0.07, 'grad_norm': 23.916486740112305, 'learning_rate': 2.2651162790697677e-05, 'loss_1': 0.0695267841219902, 'loss_2': 0.00044226646423339844, 'loss_3': -16.008708953857422, 'loss_4': 1.0536906719207764, 'epoch': 7.37}
{'loss': 0.0228, 'grad_norm': 7.429420471191406, 'learning_rate': 2.2645348837209303e-05, 'loss_1': 0.013848167844116688, 'loss_2': 0.0089263916015625, 'loss_3': -16.074474334716797, 'loss_4': 1.5477579832077026, 'epoch': 7.38}
{'loss': 0.0566, 'grad_norm': 16.12306022644043, 'learning_rate': 2.263953488372093e-05, 'loss_1': 0.049396611750125885, 'loss_2': 0.0072021484375, 'loss_3': -16.267122268676758, 'loss_4': 2.0267181396484375, 'epoch': 7.38}
[INFO|trainer.py:4228] 2025-01-21 12:51:51,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:51,367 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████                                                                                                                                                                     | 1275/5160 [31:55<1:07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:51:58,726 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018011601641774178, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.67, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013939203694462776, 'eval_loss_2': 0.004072397947311401, 'eval_loss_3': -18.131872177124023, 'eval_loss_4': 1.9208736419677734, 'epoch': 7.38}
{'loss': 0.0081, 'grad_norm': 5.282156944274902, 'learning_rate': 2.2633720930232556e-05, 'loss_1': 0.007922621443867683, 'loss_2': 0.000225067138671875, 'loss_3': -16.205415725708008, 'loss_4': 1.7258481979370117, 'epoch': 7.39}
{'loss': 0.0144, 'grad_norm': 5.709559440612793, 'learning_rate': 2.262790697674419e-05, 'loss_1': 0.010496152564883232, 'loss_2': 0.003925323486328125, 'loss_3': -16.22446060180664, 'loss_4': 1.6295039653778076, 'epoch': 7.4}
{'loss': 0.01, 'grad_norm': 4.949910640716553, 'learning_rate': 2.2622093023255817e-05, 'loss_1': 0.0068662213161587715, 'loss_2': 0.003093719482421875, 'loss_3': -16.156675338745117, 'loss_4': 1.343745231628418, 'epoch': 7.4}
{'loss': 0.0212, 'grad_norm': 5.611676216125488, 'learning_rate': 2.2616279069767442e-05, 'loss_1': 0.009232054464519024, 'loss_2': 0.0120086669921875, 'loss_3': -16.134315490722656, 'loss_4': 1.9358582496643066, 'epoch': 7.41}
{'loss': 0.024, 'grad_norm': 13.412309646606445, 'learning_rate': 2.261046511627907e-05, 'loss_1': 0.019406525418162346, 'loss_2': 0.0045623779296875, 'loss_3': -16.24985122680664, 'loss_4': 1.9603811502456665, 'epoch': 7.41}
[INFO|trainer.py:4228] 2025-01-21 12:51:58,726 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:51:58,726 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▎                                                                                                                                                                    | 1280/5160 [32:03<1:07:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:06,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017160028219223022, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.642, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.012124687433242798, 'eval_loss_2': 0.005035340785980225, 'eval_loss_3': -18.156051635742188, 'eval_loss_4': 2.0976529121398926, 'epoch': 7.41}
{'loss': 0.0308, 'grad_norm': 11.85970401763916, 'learning_rate': 2.2604651162790696e-05, 'loss_1': 0.022629372775554657, 'loss_2': 0.0081939697265625, 'loss_3': -16.30967903137207, 'loss_4': 2.0193495750427246, 'epoch': 7.42}
{'loss': 0.0109, 'grad_norm': 5.758783340454102, 'learning_rate': 2.2598837209302328e-05, 'loss_1': 0.009004095569252968, 'loss_2': 0.0019378662109375, 'loss_3': -16.07145118713379, 'loss_4': 1.9961471557617188, 'epoch': 7.42}
{'loss': 0.0133, 'grad_norm': 5.779948711395264, 'learning_rate': 2.2593023255813953e-05, 'loss_1': 0.012755231000483036, 'loss_2': 0.0005908012390136719, 'loss_3': -16.152008056640625, 'loss_4': 1.8206424713134766, 'epoch': 7.43}
{'loss': 0.011, 'grad_norm': 5.338799953460693, 'learning_rate': 2.2587209302325582e-05, 'loss_1': 0.007632599677890539, 'loss_2': 0.0033435821533203125, 'loss_3': -16.379528045654297, 'loss_4': 1.7898023128509521, 'epoch': 7.44}
{'loss': 0.0173, 'grad_norm': 6.021650314331055, 'learning_rate': 2.258139534883721e-05, 'loss_1': 0.012613664381206036, 'loss_2': 0.00472259521484375, 'loss_3': -16.13198471069336, 'loss_4': 1.7754608392715454, 'epoch': 7.44}
[INFO|trainer.py:4228] 2025-01-21 12:52:06,088 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:06,088 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▌                                                                                                                                                                    | 1285/5160 [32:10<1:07:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:13,449 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013404790312051773, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.793, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01019344199448824, 'eval_loss_2': 0.0032113492488861084, 'eval_loss_3': -18.1906795501709, 'eval_loss_4': 1.729321002960205, 'epoch': 7.44}
{'loss': 0.0186, 'grad_norm': 13.122139930725098, 'learning_rate': 2.2575581395348836e-05, 'loss_1': 0.015857310965657234, 'loss_2': 0.002758026123046875, 'loss_3': -16.092254638671875, 'loss_4': 1.716313123703003, 'epoch': 7.45}
{'loss': 0.0184, 'grad_norm': 8.079863548278809, 'learning_rate': 2.2569767441860468e-05, 'loss_1': 0.014667603187263012, 'loss_2': 0.00372314453125, 'loss_3': -16.084365844726562, 'loss_4': 1.3360954523086548, 'epoch': 7.45}
{'loss': 0.0173, 'grad_norm': 9.81846809387207, 'learning_rate': 2.2563953488372093e-05, 'loss_1': 0.016058525070548058, 'loss_2': 0.0012664794921875, 'loss_3': -16.179637908935547, 'loss_4': 1.184896469116211, 'epoch': 7.46}
{'loss': 0.0185, 'grad_norm': 7.399385929107666, 'learning_rate': 2.2558139534883722e-05, 'loss_1': 0.01766020990908146, 'loss_2': 0.0008687973022460938, 'loss_3': -16.275300979614258, 'loss_4': 1.5034198760986328, 'epoch': 7.47}
{'loss': 0.0229, 'grad_norm': 9.626864433288574, 'learning_rate': 2.255232558139535e-05, 'loss_1': 0.018075598403811455, 'loss_2': 0.0047760009765625, 'loss_3': -16.181804656982422, 'loss_4': 1.149857521057129, 'epoch': 7.47}
[INFO|trainer.py:4228] 2025-01-21 12:52:13,449 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:13,449 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▊                                                                                                                                                                    | 1290/5160 [32:17<1:07:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:20,827 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01592937856912613, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.142, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.011078997515141964, 'eval_loss_2': 0.004850380122661591, 'eval_loss_3': -18.199905395507812, 'eval_loss_4': 1.20429527759552, 'epoch': 7.47}
{'loss': 0.0429, 'grad_norm': 13.241817474365234, 'learning_rate': 2.2546511627906976e-05, 'loss_1': 0.03842926397919655, 'loss_2': 0.004444122314453125, 'loss_3': -16.10306167602539, 'loss_4': 1.3471746444702148, 'epoch': 7.48}
{'loss': 0.0204, 'grad_norm': 5.717702865600586, 'learning_rate': 2.2540697674418608e-05, 'loss_1': 0.010767744854092598, 'loss_2': 0.00958251953125, 'loss_3': -16.293930053710938, 'loss_4': 1.1137762069702148, 'epoch': 7.48}
{'loss': 0.0129, 'grad_norm': 5.815823078155518, 'learning_rate': 2.2534883720930233e-05, 'loss_1': 0.012762256897985935, 'loss_2': 0.00011008977890014648, 'loss_3': -16.348756790161133, 'loss_4': 1.530599594116211, 'epoch': 7.49}
{'loss': 0.0202, 'grad_norm': 8.719287872314453, 'learning_rate': 2.252906976744186e-05, 'loss_1': 0.017563017085194588, 'loss_2': 0.002681732177734375, 'loss_3': -16.17496109008789, 'loss_4': 1.064469575881958, 'epoch': 7.49}
{'loss': 0.0178, 'grad_norm': 8.154800415039062, 'learning_rate': 2.2523255813953487e-05, 'loss_1': 0.017337016761302948, 'loss_2': 0.000438690185546875, 'loss_3': -16.130916595458984, 'loss_4': 0.928295373916626, 'epoch': 7.5}
[INFO|trainer.py:4228] 2025-01-21 12:52:20,827 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:20,827 >>   Batch size = 64
 25%|██████████████████████████████████████████████████████▉                                                                                                                                                                    | 1295/5160 [32:25<1:07:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:28,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014224941842257977, 'eval_runtime': 3.8162, 'eval_samples_per_second': 268.332, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.010355914942920208, 'eval_loss_2': 0.0038690268993377686, 'eval_loss_3': -18.207626342773438, 'eval_loss_4': 0.874933123588562, 'epoch': 7.5}
{'loss': 0.0202, 'grad_norm': 5.819323539733887, 'learning_rate': 2.2517441860465116e-05, 'loss_1': 0.0122118154540658, 'loss_2': 0.00803375244140625, 'loss_3': -16.504695892333984, 'loss_4': 0.9293226003646851, 'epoch': 7.51}
{'loss': 0.0163, 'grad_norm': 12.636794090270996, 'learning_rate': 2.2511627906976748e-05, 'loss_1': 0.01520245335996151, 'loss_2': 0.0011425018310546875, 'loss_3': -16.331634521484375, 'loss_4': 1.302985429763794, 'epoch': 7.51}
{'loss': 0.013, 'grad_norm': 5.4549102783203125, 'learning_rate': 2.2505813953488373e-05, 'loss_1': 0.0109031293541193, 'loss_2': 0.0020751953125, 'loss_3': -16.18611717224121, 'loss_4': 0.5451761484146118, 'epoch': 7.52}
{'loss': 0.0234, 'grad_norm': 6.260141372680664, 'learning_rate': 2.25e-05, 'loss_1': 0.013520310632884502, 'loss_2': 0.009918212890625, 'loss_3': -16.0770206451416, 'loss_4': 0.6380119323730469, 'epoch': 7.52}
{'loss': 0.0151, 'grad_norm': 7.678072929382324, 'learning_rate': 2.2494186046511627e-05, 'loss_1': 0.012959228828549385, 'loss_2': 0.00209808349609375, 'loss_3': -16.278621673583984, 'loss_4': 0.9478130340576172, 'epoch': 7.53}
[INFO|trainer.py:4228] 2025-01-21 12:52:28,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:28,198 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▏                                                                                                                                                                   | 1300/5160 [32:32<1:06:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:35,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015558848157525063, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.75, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009993204846978188, 'eval_loss_2': 0.005565643310546875, 'eval_loss_3': -18.250904083251953, 'eval_loss_4': 0.5762588381767273, 'epoch': 7.53}
{'loss': 0.0256, 'grad_norm': 8.651152610778809, 'learning_rate': 2.2488372093023255e-05, 'loss_1': 0.01977722719311714, 'loss_2': 0.00579833984375, 'loss_3': -16.214502334594727, 'loss_4': 0.5216430425643921, 'epoch': 7.53}
{'loss': 0.0136, 'grad_norm': 5.465645790100098, 'learning_rate': 2.2482558139534884e-05, 'loss_1': 0.012123983353376389, 'loss_2': 0.0014743804931640625, 'loss_3': -16.12604522705078, 'loss_4': 0.3884236812591553, 'epoch': 7.54}
{'loss': 0.0807, 'grad_norm': 25.38707733154297, 'learning_rate': 2.2476744186046513e-05, 'loss_1': 0.07290694117546082, 'loss_2': 0.00775909423828125, 'loss_3': -16.30965805053711, 'loss_4': 1.497198224067688, 'epoch': 7.55}
{'loss': 0.0819, 'grad_norm': 46.48051834106445, 'learning_rate': 2.247093023255814e-05, 'loss_1': 0.08103714138269424, 'loss_2': 0.0008764266967773438, 'loss_3': -16.049602508544922, 'loss_4': 0.7063267827033997, 'epoch': 7.55}
{'loss': 0.0079, 'grad_norm': 5.244917392730713, 'learning_rate': 2.2465116279069766e-05, 'loss_1': 0.006794951856136322, 'loss_2': 0.0011205673217773438, 'loss_3': -16.314563751220703, 'loss_4': 0.4019021987915039, 'epoch': 7.56}
[INFO|trainer.py:4228] 2025-01-21 12:52:35,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:35,566 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▍                                                                                                                                                                   | 1305/5160 [32:40<1:06:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:42,925 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01603308692574501, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.653, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00872865691781044, 'eval_loss_2': 0.00730443000793457, 'eval_loss_3': -18.267513275146484, 'eval_loss_4': 0.32482436299324036, 'epoch': 7.56}
{'loss': 0.0182, 'grad_norm': 8.349358558654785, 'learning_rate': 2.2459302325581395e-05, 'loss_1': 0.012620139867067337, 'loss_2': 0.0055694580078125, 'loss_3': -16.210113525390625, 'loss_4': 0.6760192513465881, 'epoch': 7.56}
{'loss': 0.0185, 'grad_norm': 6.284585475921631, 'learning_rate': 2.2453488372093024e-05, 'loss_1': 0.012829920276999474, 'loss_2': 0.00568389892578125, 'loss_3': -16.151830673217773, 'loss_4': 0.3108777105808258, 'epoch': 7.57}
{'loss': 0.0114, 'grad_norm': 6.258193016052246, 'learning_rate': 2.2447674418604652e-05, 'loss_1': 0.010193697176873684, 'loss_2': 0.0011653900146484375, 'loss_3': -16.281719207763672, 'loss_4': 0.3583377003669739, 'epoch': 7.58}
{'loss': 0.022, 'grad_norm': 10.321189880371094, 'learning_rate': 2.244186046511628e-05, 'loss_1': 0.02070506662130356, 'loss_2': 0.0013227462768554688, 'loss_3': -16.11589813232422, 'loss_4': -0.18094885349273682, 'epoch': 7.58}
{'loss': 0.0223, 'grad_norm': 7.6333842277526855, 'learning_rate': 2.2436046511627906e-05, 'loss_1': 0.01698199287056923, 'loss_2': 0.00528717041015625, 'loss_3': -16.072166442871094, 'loss_4': 0.25139665603637695, 'epoch': 7.59}
[INFO|trainer.py:4228] 2025-01-21 12:52:42,925 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:42,925 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▌                                                                                                                                                                   | 1310/5160 [32:47<1:06:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:50,290 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01190622802823782, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.58, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00827889982610941, 'eval_loss_2': 0.0036273300647735596, 'eval_loss_3': -18.23095703125, 'eval_loss_4': 0.2188459038734436, 'epoch': 7.59}
{'loss': 0.0237, 'grad_norm': 8.340286254882812, 'learning_rate': 2.2430232558139535e-05, 'loss_1': 0.01851983740925789, 'loss_2': 0.0051727294921875, 'loss_3': -16.218799591064453, 'loss_4': 0.28789660334587097, 'epoch': 7.59}
{'loss': 0.0195, 'grad_norm': 8.837068557739258, 'learning_rate': 2.2424418604651163e-05, 'loss_1': 0.01299342792481184, 'loss_2': 0.006465911865234375, 'loss_3': -15.921688079833984, 'loss_4': 0.4539477229118347, 'epoch': 7.6}
{'loss': 0.0362, 'grad_norm': 20.386886596679688, 'learning_rate': 2.2418604651162792e-05, 'loss_1': 0.03364453837275505, 'loss_2': 0.0025997161865234375, 'loss_3': -16.02115821838379, 'loss_4': 0.15414290130138397, 'epoch': 7.6}
{'loss': 0.0219, 'grad_norm': 11.128795623779297, 'learning_rate': 2.2412790697674417e-05, 'loss_1': 0.016790052875876427, 'loss_2': 0.00514984130859375, 'loss_3': -16.31338119506836, 'loss_4': 0.11303257197141647, 'epoch': 7.61}
{'loss': 0.0208, 'grad_norm': 10.422554016113281, 'learning_rate': 2.2406976744186046e-05, 'loss_1': 0.017168940976262093, 'loss_2': 0.0036773681640625, 'loss_3': -16.30883026123047, 'loss_4': 0.5274214744567871, 'epoch': 7.62}
[INFO|trainer.py:4228] 2025-01-21 12:52:50,290 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:50,290 >>   Batch size = 64
 25%|███████████████████████████████████████████████████████▊                                                                                                                                                                   | 1315/5160 [32:54<1:06:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:52:57,660 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014054997824132442, 'eval_runtime': 3.8169, 'eval_samples_per_second': 268.279, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.00856412947177887, 'eval_loss_2': 0.0054908692836761475, 'eval_loss_3': -18.215301513671875, 'eval_loss_4': 0.2783854901790619, 'epoch': 7.62}
{'loss': 0.0468, 'grad_norm': 13.079333305358887, 'learning_rate': 2.2401162790697675e-05, 'loss_1': 0.03150906041264534, 'loss_2': 0.01528167724609375, 'loss_3': -16.13766860961914, 'loss_4': 0.12430328130722046, 'epoch': 7.62}
{'loss': 0.0282, 'grad_norm': 9.441069602966309, 'learning_rate': 2.2395348837209303e-05, 'loss_1': 0.020678343251347542, 'loss_2': 0.007568359375, 'loss_3': -16.330190658569336, 'loss_4': 0.7959287762641907, 'epoch': 7.63}
{'loss': 0.0159, 'grad_norm': 5.638418674468994, 'learning_rate': 2.2389534883720932e-05, 'loss_1': 0.008876807056367397, 'loss_2': 0.00701141357421875, 'loss_3': -16.131940841674805, 'loss_4': -0.10222180187702179, 'epoch': 7.63}
{'loss': 0.021, 'grad_norm': 7.1556396484375, 'learning_rate': 2.2383720930232557e-05, 'loss_1': 0.011294834315776825, 'loss_2': 0.0097198486328125, 'loss_3': -16.146194458007812, 'loss_4': 0.0389995351433754, 'epoch': 7.64}
{'loss': 0.0252, 'grad_norm': 12.08604621887207, 'learning_rate': 2.2377906976744186e-05, 'loss_1': 0.023587750270962715, 'loss_2': 0.0016431808471679688, 'loss_3': -16.06206703186035, 'loss_4': 0.5566073060035706, 'epoch': 7.65}
[INFO|trainer.py:4228] 2025-01-21 12:52:57,660 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:52:57,660 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████                                                                                                                                                                   | 1320/5160 [33:02<1:07:50,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:53:05,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017123281955718994, 'eval_runtime': 3.8173, 'eval_samples_per_second': 268.252, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.009983419440686703, 'eval_loss_2': 0.007139861583709717, 'eval_loss_3': -18.217864990234375, 'eval_loss_4': 0.4342762529850006, 'epoch': 7.65}
{'loss': 0.018, 'grad_norm': 5.861075401306152, 'learning_rate': 2.2372093023255814e-05, 'loss_1': 0.010114633478224277, 'loss_2': 0.007843017578125, 'loss_3': -16.129138946533203, 'loss_4': 0.4256114065647125, 'epoch': 7.65}
{'loss': 0.0248, 'grad_norm': 7.057726860046387, 'learning_rate': 2.2366279069767443e-05, 'loss_1': 0.015416866168379784, 'loss_2': 0.00936126708984375, 'loss_3': -16.372236251831055, 'loss_4': 0.5806477069854736, 'epoch': 7.66}
{'loss': 0.0479, 'grad_norm': 13.318690299987793, 'learning_rate': 2.236046511627907e-05, 'loss_1': 0.035333212465047836, 'loss_2': 0.01259613037109375, 'loss_3': -16.141666412353516, 'loss_4': 1.3404147624969482, 'epoch': 7.66}
{'loss': 0.0639, 'grad_norm': 19.41082000732422, 'learning_rate': 2.2354651162790697e-05, 'loss_1': 0.046982552856206894, 'loss_2': 0.0168914794921875, 'loss_3': -16.299842834472656, 'loss_4': 0.4674367606639862, 'epoch': 7.67}
{'loss': 0.0297, 'grad_norm': 6.797125339508057, 'learning_rate': 2.2348837209302326e-05, 'loss_1': 0.01064583845436573, 'loss_2': 0.0190887451171875, 'loss_3': -16.01095199584961, 'loss_4': 0.5648210048675537, 'epoch': 7.67}
[INFO|trainer.py:4228] 2025-01-21 12:53:05,217 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:05,217 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▏                                                                                                                                                                  | 1325/5160 [33:09<1:06:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:12,580 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018269410356879234, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.731, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008856406435370445, 'eval_loss_2': 0.009413003921508789, 'eval_loss_3': -18.215129852294922, 'eval_loss_4': 0.4916345179080963, 'epoch': 7.67}
{'loss': 0.0293, 'grad_norm': 8.507766723632812, 'learning_rate': 2.234302325581395e-05, 'loss_1': 0.021108893677592278, 'loss_2': 0.008148193359375, 'loss_3': -16.297304153442383, 'loss_4': 0.11188818514347076, 'epoch': 7.68}
{'loss': 0.0261, 'grad_norm': 9.307576179504395, 'learning_rate': 2.2337209302325583e-05, 'loss_1': 0.020085619762539864, 'loss_2': 0.0060272216796875, 'loss_3': -16.26458168029785, 'loss_4': 0.5863609313964844, 'epoch': 7.69}
{'loss': 0.024, 'grad_norm': 6.411583423614502, 'learning_rate': 2.233139534883721e-05, 'loss_1': 0.012998181395232677, 'loss_2': 0.0109710693359375, 'loss_3': -16.28151512145996, 'loss_4': 0.7763203382492065, 'epoch': 7.69}
{'loss': 0.0237, 'grad_norm': 12.316292762756348, 'learning_rate': 2.2325581395348837e-05, 'loss_1': 0.020357690751552582, 'loss_2': 0.003314971923828125, 'loss_3': -16.111894607543945, 'loss_4': 0.37259960174560547, 'epoch': 7.7}
{'loss': 0.0545, 'grad_norm': 23.33639144897461, 'learning_rate': 2.2319767441860465e-05, 'loss_1': 0.04014800861477852, 'loss_2': 0.01434326171875, 'loss_3': -16.189224243164062, 'loss_4': 0.6115627288818359, 'epoch': 7.7}
[INFO|trainer.py:4228] 2025-01-21 12:53:12,580 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:12,580 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▍                                                                                                                                                                  | 1330/5160 [33:17<1:06:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:19,950 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01562434434890747, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.692, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010563401505351067, 'eval_loss_2': 0.005060940980911255, 'eval_loss_3': -18.225975036621094, 'eval_loss_4': 0.3122066855430603, 'epoch': 7.7}
{'loss': 0.0281, 'grad_norm': 12.030708312988281, 'learning_rate': 2.231395348837209e-05, 'loss_1': 0.02130942977964878, 'loss_2': 0.006744384765625, 'loss_3': -16.212162017822266, 'loss_4': 0.5081841349601746, 'epoch': 7.71}
{'loss': 0.0343, 'grad_norm': 11.991006851196289, 'learning_rate': 2.2308139534883723e-05, 'loss_1': 0.0220725629478693, 'loss_2': 0.01219940185546875, 'loss_3': -16.263778686523438, 'loss_4': 0.09330087155103683, 'epoch': 7.72}
{'loss': 0.0248, 'grad_norm': 11.730375289916992, 'learning_rate': 2.230232558139535e-05, 'loss_1': 0.021051280200481415, 'loss_2': 0.0037250518798828125, 'loss_3': -16.287109375, 'loss_4': 0.7445752620697021, 'epoch': 7.72}
{'loss': 0.0585, 'grad_norm': 15.740598678588867, 'learning_rate': 2.2296511627906976e-05, 'loss_1': 0.05041835829615593, 'loss_2': 0.008087158203125, 'loss_3': -16.34431266784668, 'loss_4': 0.5812965035438538, 'epoch': 7.73}
{'loss': 0.0207, 'grad_norm': 6.086959362030029, 'learning_rate': 2.2290697674418605e-05, 'loss_1': 0.009590874426066875, 'loss_2': 0.011138916015625, 'loss_3': -16.33406639099121, 'loss_4': -0.039588604122400284, 'epoch': 7.73}
[INFO|trainer.py:4228] 2025-01-21 12:53:19,951 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:19,951 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▋                                                                                                                                                                  | 1335/5160 [33:24<1:06:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:27,320 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018668821081519127, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.338, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.01049613207578659, 'eval_loss_2': 0.008172690868377686, 'eval_loss_3': -18.241212844848633, 'eval_loss_4': 0.23600193858146667, 'epoch': 7.73}
{'loss': 0.0411, 'grad_norm': 12.194056510925293, 'learning_rate': 2.2284883720930234e-05, 'loss_1': 0.03682094067335129, 'loss_2': 0.004302978515625, 'loss_3': -16.29302215576172, 'loss_4': 0.1896815299987793, 'epoch': 7.74}
{'loss': 0.0218, 'grad_norm': 8.250404357910156, 'learning_rate': 2.2279069767441862e-05, 'loss_1': 0.019502757117152214, 'loss_2': 0.00234222412109375, 'loss_3': -16.310501098632812, 'loss_4': 0.2885802090167999, 'epoch': 7.74}
{'loss': 0.027, 'grad_norm': 8.703312873840332, 'learning_rate': 2.2273255813953488e-05, 'loss_1': 0.01958666928112507, 'loss_2': 0.007415771484375, 'loss_3': -16.188220977783203, 'loss_4': 0.11297392845153809, 'epoch': 7.75}
{'loss': 0.0404, 'grad_norm': 13.258084297180176, 'learning_rate': 2.2267441860465116e-05, 'loss_1': 0.028231345117092133, 'loss_2': 0.01212310791015625, 'loss_3': -16.182292938232422, 'loss_4': 0.6393510103225708, 'epoch': 7.76}
{'loss': 0.0185, 'grad_norm': 6.943414688110352, 'learning_rate': 2.2261627906976745e-05, 'loss_1': 0.012028506956994534, 'loss_2': 0.00647735595703125, 'loss_3': -16.398597717285156, 'loss_4': 0.23784378170967102, 'epoch': 7.76}
[INFO|trainer.py:4228] 2025-01-21 12:53:27,320 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:27,320 >>   Batch size = 64
 26%|████████████████████████████████████████████████████████▊                                                                                                                                                                  | 1340/5160 [33:31<1:06:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:34,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014050891622900963, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.403, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009993096813559532, 'eval_loss_2': 0.004057794809341431, 'eval_loss_3': -18.23910140991211, 'eval_loss_4': 0.3683861494064331, 'epoch': 7.76}
{'loss': 0.0348, 'grad_norm': 12.55813980102539, 'learning_rate': 2.2255813953488373e-05, 'loss_1': 0.03381374850869179, 'loss_2': 0.0009489059448242188, 'loss_3': -16.600934982299805, 'loss_4': 0.6577280759811401, 'epoch': 7.77}
{'loss': 0.0353, 'grad_norm': 13.87515926361084, 'learning_rate': 2.2250000000000002e-05, 'loss_1': 0.03161931037902832, 'loss_2': 0.003726959228515625, 'loss_3': -16.292789459228516, 'loss_4': 0.4617460370063782, 'epoch': 7.77}
{'loss': 0.0255, 'grad_norm': 12.672870635986328, 'learning_rate': 2.2244186046511627e-05, 'loss_1': 0.024229036644101143, 'loss_2': 0.0012445449829101562, 'loss_3': -16.395511627197266, 'loss_4': 0.7959253787994385, 'epoch': 7.78}
{'loss': 0.0727, 'grad_norm': 14.553380012512207, 'learning_rate': 2.2238372093023256e-05, 'loss_1': 0.06984883546829224, 'loss_2': 0.002872467041015625, 'loss_3': -16.019424438476562, 'loss_4': 0.7939160466194153, 'epoch': 7.78}
{'loss': 0.037, 'grad_norm': 12.85634994506836, 'learning_rate': 2.2232558139534885e-05, 'loss_1': 0.03596515953540802, 'loss_2': 0.001049041748046875, 'loss_3': -16.33823013305664, 'loss_4': 0.48940491676330566, 'epoch': 7.79}
[INFO|trainer.py:4228] 2025-01-21 12:53:34,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:34,691 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████                                                                                                                                                                  | 1345/5160 [33:39<1:06:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:42,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013305841945111752, 'eval_runtime': 3.8227, 'eval_samples_per_second': 267.874, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.009951978921890259, 'eval_loss_2': 0.0033538639545440674, 'eval_loss_3': -18.27641487121582, 'eval_loss_4': 0.44568219780921936, 'epoch': 7.79}
{'loss': 0.0141, 'grad_norm': 5.72908878326416, 'learning_rate': 2.2226744186046513e-05, 'loss_1': 0.013865241780877113, 'loss_2': 0.0002079010009765625, 'loss_3': -16.317102432250977, 'loss_4': 0.21599307656288147, 'epoch': 7.8}
{'loss': 0.0234, 'grad_norm': 9.335124969482422, 'learning_rate': 2.2220930232558142e-05, 'loss_1': 0.022914187982678413, 'loss_2': 0.0005016326904296875, 'loss_3': -16.35025978088379, 'loss_4': 0.4745483994483948, 'epoch': 7.8}
{'loss': 0.0288, 'grad_norm': 11.647244453430176, 'learning_rate': 2.2215116279069767e-05, 'loss_1': 0.02834140509366989, 'loss_2': 0.0004363059997558594, 'loss_3': -16.298458099365234, 'loss_4': 0.04098239541053772, 'epoch': 7.81}
{'loss': 0.0205, 'grad_norm': 5.056023120880127, 'learning_rate': 2.2209302325581396e-05, 'loss_1': 0.008752651512622833, 'loss_2': 0.01177978515625, 'loss_3': -16.469127655029297, 'loss_4': 0.40147149562835693, 'epoch': 7.81}
{'loss': 0.0185, 'grad_norm': 5.683743476867676, 'learning_rate': 2.220348837209302e-05, 'loss_1': 0.015870673581957817, 'loss_2': 0.002666473388671875, 'loss_3': -16.466777801513672, 'loss_4': 0.45236295461654663, 'epoch': 7.82}
[INFO|trainer.py:4228] 2025-01-21 12:53:42,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:42,072 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▎                                                                                                                                                                 | 1350/5160 [33:46<1:06:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:49,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014154158532619476, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.587, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010105900466442108, 'eval_loss_2': 0.004048258066177368, 'eval_loss_3': -18.223215103149414, 'eval_loss_4': 0.5386170148849487, 'epoch': 7.82}
{'loss': 0.0426, 'grad_norm': 12.599077224731445, 'learning_rate': 2.2197674418604653e-05, 'loss_1': 0.03962676227092743, 'loss_2': 0.0029888153076171875, 'loss_3': -16.496902465820312, 'loss_4': 0.5387129187583923, 'epoch': 7.83}
{'loss': 0.0229, 'grad_norm': 6.846208572387695, 'learning_rate': 2.219186046511628e-05, 'loss_1': 0.016871830448508263, 'loss_2': 0.006015777587890625, 'loss_3': -16.3364200592041, 'loss_4': 0.24008752405643463, 'epoch': 7.83}
{'loss': 0.0247, 'grad_norm': 6.541736125946045, 'learning_rate': 2.2186046511627907e-05, 'loss_1': 0.012771295383572578, 'loss_2': 0.01190185546875, 'loss_3': -16.415225982666016, 'loss_4': 0.6152429580688477, 'epoch': 7.84}
{'loss': 0.0146, 'grad_norm': 6.228801727294922, 'learning_rate': 2.2180232558139536e-05, 'loss_1': 0.012232515029609203, 'loss_2': 0.00237274169921875, 'loss_3': -16.37724494934082, 'loss_4': 0.3131905794143677, 'epoch': 7.84}
{'loss': 0.063, 'grad_norm': 30.498098373413086, 'learning_rate': 2.217441860465116e-05, 'loss_1': 0.06126325577497482, 'loss_2': 0.0017671585083007812, 'loss_3': -16.39824676513672, 'loss_4': 0.9996707439422607, 'epoch': 7.85}
[INFO|trainer.py:4228] 2025-01-21 12:53:49,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:49,445 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▌                                                                                                                                                                 | 1355/5160 [33:53<1:06:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:53:56,815 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015029126778244972, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.451, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011178042739629745, 'eval_loss_2': 0.003851085901260376, 'eval_loss_3': -18.177684783935547, 'eval_loss_4': 0.8115800619125366, 'epoch': 7.85}
{'loss': 0.0237, 'grad_norm': 10.414084434509277, 'learning_rate': 2.2168604651162793e-05, 'loss_1': 0.020863041281700134, 'loss_2': 0.0028095245361328125, 'loss_3': -16.422481536865234, 'loss_4': 0.43606463074684143, 'epoch': 7.85}
{'loss': 0.0233, 'grad_norm': 6.373589515686035, 'learning_rate': 2.216279069767442e-05, 'loss_1': 0.016943462193012238, 'loss_2': 0.00637054443359375, 'loss_3': -16.387529373168945, 'loss_4': 0.7749303579330444, 'epoch': 7.86}
{'loss': 0.0186, 'grad_norm': 7.880307674407959, 'learning_rate': 2.2156976744186047e-05, 'loss_1': 0.013745450414717197, 'loss_2': 0.0048065185546875, 'loss_3': -16.28278350830078, 'loss_4': 0.9921009540557861, 'epoch': 7.87}
{'loss': 0.0241, 'grad_norm': 6.404728412628174, 'learning_rate': 2.2151162790697675e-05, 'loss_1': 0.01703011803328991, 'loss_2': 0.00711822509765625, 'loss_3': -16.333858489990234, 'loss_4': 0.6565439105033875, 'epoch': 7.87}
{'loss': 0.0173, 'grad_norm': 6.894225120544434, 'learning_rate': 2.21453488372093e-05, 'loss_1': 0.013450768776237965, 'loss_2': 0.0038471221923828125, 'loss_3': -16.393421173095703, 'loss_4': 0.964370608329773, 'epoch': 7.88}
[INFO|trainer.py:4228] 2025-01-21 12:53:56,815 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:53:56,815 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▋                                                                                                                                                                 | 1360/5160 [34:01<1:06:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:04,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016184557229280472, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010128159075975418, 'eval_loss_2': 0.006056398153305054, 'eval_loss_3': -18.17652702331543, 'eval_loss_4': 1.1336266994476318, 'epoch': 7.88}
{'loss': 0.0206, 'grad_norm': 5.324829578399658, 'learning_rate': 2.2139534883720933e-05, 'loss_1': 0.011834628880023956, 'loss_2': 0.0087738037109375, 'loss_3': -16.30515480041504, 'loss_4': 1.0731654167175293, 'epoch': 7.88}
{'loss': 0.0209, 'grad_norm': 6.260402202606201, 'learning_rate': 2.2133720930232558e-05, 'loss_1': 0.010613142512738705, 'loss_2': 0.01029205322265625, 'loss_3': -16.2752742767334, 'loss_4': 1.1851603984832764, 'epoch': 7.89}
{'loss': 0.0216, 'grad_norm': 6.003758430480957, 'learning_rate': 2.2127906976744186e-05, 'loss_1': 0.011507395654916763, 'loss_2': 0.01004791259765625, 'loss_3': -16.344823837280273, 'loss_4': 1.3120288848876953, 'epoch': 7.9}
{'loss': 0.0169, 'grad_norm': 5.419090747833252, 'learning_rate': 2.2122093023255815e-05, 'loss_1': 0.013074537739157677, 'loss_2': 0.003871917724609375, 'loss_3': -16.362934112548828, 'loss_4': 1.2485918998718262, 'epoch': 7.9}
{'loss': 0.0261, 'grad_norm': 13.45445728302002, 'learning_rate': 2.211627906976744e-05, 'loss_1': 0.0175553560256958, 'loss_2': 0.00858306884765625, 'loss_3': -16.299240112304688, 'loss_4': 0.7049883008003235, 'epoch': 7.91}
[INFO|trainer.py:4228] 2025-01-21 12:54:04,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:04,189 >>   Batch size = 64
 26%|█████████████████████████████████████████████████████████▉                                                                                                                                                                 | 1365/5160 [34:08<1:05:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:11,554 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012958724051713943, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.784, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009371479041874409, 'eval_loss_2': 0.0035872459411621094, 'eval_loss_3': -18.18383026123047, 'eval_loss_4': 1.1867289543151855, 'epoch': 7.91}
{'loss': 0.0126, 'grad_norm': 6.338836193084717, 'learning_rate': 2.2110465116279072e-05, 'loss_1': 0.011271519586443901, 'loss_2': 0.0012845993041992188, 'loss_3': -16.205181121826172, 'loss_4': 1.0780465602874756, 'epoch': 7.91}
{'loss': 0.0327, 'grad_norm': 10.73808479309082, 'learning_rate': 2.2104651162790698e-05, 'loss_1': 0.026871586218476295, 'loss_2': 0.0058746337890625, 'loss_3': -16.162567138671875, 'loss_4': 0.9867699146270752, 'epoch': 7.92}
{'loss': 0.018, 'grad_norm': 5.918644428253174, 'learning_rate': 2.2098837209302326e-05, 'loss_1': 0.011646481230854988, 'loss_2': 0.0063934326171875, 'loss_3': -16.103130340576172, 'loss_4': 0.8095240592956543, 'epoch': 7.92}
{'loss': 0.0208, 'grad_norm': 7.285789966583252, 'learning_rate': 2.2093023255813955e-05, 'loss_1': 0.014233527705073357, 'loss_2': 0.00653076171875, 'loss_3': -16.417770385742188, 'loss_4': 1.0384469032287598, 'epoch': 7.93}
{'loss': 0.0166, 'grad_norm': 6.564113140106201, 'learning_rate': 2.208720930232558e-05, 'loss_1': 0.011523276567459106, 'loss_2': 0.005096435546875, 'loss_3': -16.238311767578125, 'loss_4': 0.6863523721694946, 'epoch': 7.94}
[INFO|trainer.py:4228] 2025-01-21 12:54:11,554 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:11,554 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▏                                                                                                                                                                | 1370/5160 [34:16<1:05:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:18,934 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014762962237000465, 'eval_runtime': 3.8201, 'eval_samples_per_second': 268.055, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.009648943319916725, 'eval_loss_2': 0.00511401891708374, 'eval_loss_3': -18.184146881103516, 'eval_loss_4': 1.030647873878479, 'epoch': 7.94}
{'loss': 0.015, 'grad_norm': 6.079246520996094, 'learning_rate': 2.2081395348837212e-05, 'loss_1': 0.012179121375083923, 'loss_2': 0.0028057098388671875, 'loss_3': -16.265823364257812, 'loss_4': 0.978095531463623, 'epoch': 7.94}
{'loss': 0.0356, 'grad_norm': 10.732829093933105, 'learning_rate': 2.2075581395348837e-05, 'loss_1': 0.021085483953356743, 'loss_2': 0.014556884765625, 'loss_3': -16.152103424072266, 'loss_4': 0.8303526639938354, 'epoch': 7.95}
{'loss': 0.0193, 'grad_norm': 5.162801265716553, 'learning_rate': 2.2069767441860466e-05, 'loss_1': 0.010105169378221035, 'loss_2': 0.00919342041015625, 'loss_3': -16.37645149230957, 'loss_4': 1.2643895149230957, 'epoch': 7.95}
{'loss': 0.0216, 'grad_norm': 5.945324420928955, 'learning_rate': 2.206395348837209e-05, 'loss_1': 0.010533677414059639, 'loss_2': 0.0110626220703125, 'loss_3': -16.207141876220703, 'loss_4': 0.666251003742218, 'epoch': 7.96}
{'loss': 0.0411, 'grad_norm': 9.115191459655762, 'learning_rate': 2.205813953488372e-05, 'loss_1': 0.02897629514336586, 'loss_2': 0.01216888427734375, 'loss_3': -16.066837310791016, 'loss_4': 0.971837043762207, 'epoch': 7.97}
[INFO|trainer.py:4228] 2025-01-21 12:54:18,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:18,934 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▎                                                                                                                                                                | 1375/5160 [34:23<1:05:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:26,291 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015344834886491299, 'eval_runtime': 3.8199, 'eval_samples_per_second': 268.072, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.009603758342564106, 'eval_loss_2': 0.0057410746812820435, 'eval_loss_3': -18.250978469848633, 'eval_loss_4': 0.8659178614616394, 'epoch': 7.97}
{'loss': 0.016, 'grad_norm': 7.743185043334961, 'learning_rate': 2.2052325581395352e-05, 'loss_1': 0.01303650252521038, 'loss_2': 0.00296783447265625, 'loss_3': -16.23976707458496, 'loss_4': 0.6053037643432617, 'epoch': 7.97}
{'loss': 0.0159, 'grad_norm': 7.119235515594482, 'learning_rate': 2.2046511627906977e-05, 'loss_1': 0.012844945304095745, 'loss_2': 0.003055572509765625, 'loss_3': -16.39585304260254, 'loss_4': 0.8580509424209595, 'epoch': 7.98}
{'loss': 0.0242, 'grad_norm': 7.928913116455078, 'learning_rate': 2.2040697674418606e-05, 'loss_1': 0.022849388420581818, 'loss_2': 0.0013484954833984375, 'loss_3': -16.440793991088867, 'loss_4': 0.7515034675598145, 'epoch': 7.98}
{'loss': 0.0347, 'grad_norm': 17.84587287902832, 'learning_rate': 2.203488372093023e-05, 'loss_1': 0.03302481025457382, 'loss_2': 0.0016584396362304688, 'loss_3': -16.273685455322266, 'loss_4': 0.6779273152351379, 'epoch': 7.99}
{'loss': 0.0125, 'grad_norm': 6.049660682678223, 'learning_rate': 2.202906976744186e-05, 'loss_1': 0.011121170595288277, 'loss_2': 0.0014057159423828125, 'loss_3': -16.42105484008789, 'loss_4': 0.6691691875457764, 'epoch': 7.99}
[INFO|trainer.py:4228] 2025-01-21 12:54:26,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:26,291 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▌                                                                                                                                                                | 1380/5160 [34:30<1:04:18,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 12:54:33,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01645778678357601, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.36, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.011527752503752708, 'eval_loss_2': 0.004930034279823303, 'eval_loss_3': -18.324129104614258, 'eval_loss_4': 0.47958314418792725, 'epoch': 7.99}
{'loss': 0.0241, 'grad_norm': 10.078617095947266, 'learning_rate': 2.202325581395349e-05, 'loss_1': 0.01673896610736847, 'loss_2': 0.00731658935546875, 'loss_3': -16.627901077270508, 'loss_4': -0.20328672230243683, 'epoch': 8.0}
{'loss': 0.0236, 'grad_norm': 8.942316055297852, 'learning_rate': 2.2017441860465117e-05, 'loss_1': 0.021551666781306267, 'loss_2': 0.0020084381103515625, 'loss_3': -16.301284790039062, 'loss_4': 0.5032592415809631, 'epoch': 8.01}
{'loss': 0.0223, 'grad_norm': 6.998755931854248, 'learning_rate': 2.2011627906976746e-05, 'loss_1': 0.017713401466608047, 'loss_2': 0.00457000732421875, 'loss_3': -16.40774917602539, 'loss_4': 0.15008802711963654, 'epoch': 8.01}
{'loss': 0.017, 'grad_norm': 5.238180160522461, 'learning_rate': 2.200581395348837e-05, 'loss_1': 0.008392191492021084, 'loss_2': 0.008636474609375, 'loss_3': -16.329769134521484, 'loss_4': 0.6282437443733215, 'epoch': 8.02}
{'loss': 0.0258, 'grad_norm': 9.845470428466797, 'learning_rate': 2.2e-05, 'loss_1': 0.023913411423563957, 'loss_2': 0.0018787384033203125, 'loss_3': -16.42391586303711, 'loss_4': 0.48413747549057007, 'epoch': 8.02}
[INFO|trainer.py:4228] 2025-01-21 12:54:33,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:33,371 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▊                                                                                                                                                                | 1385/5160 [34:37<1:05:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:40,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018927454948425293, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.714, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.015144303441047668, 'eval_loss_2': 0.0037831515073776245, 'eval_loss_3': -18.304182052612305, 'eval_loss_4': 0.2964664399623871, 'epoch': 8.02}
{'loss': 0.0313, 'grad_norm': 8.263567924499512, 'learning_rate': 2.1994186046511628e-05, 'loss_1': 0.02817363850772381, 'loss_2': 0.003093719482421875, 'loss_3': -16.26633644104004, 'loss_4': 0.07528989762067795, 'epoch': 8.03}
{'loss': 0.0351, 'grad_norm': 14.903707504272461, 'learning_rate': 2.1988372093023257e-05, 'loss_1': 0.03431043028831482, 'loss_2': 0.0007557868957519531, 'loss_3': -16.171581268310547, 'loss_4': 0.20220927894115448, 'epoch': 8.03}
{'loss': 0.0268, 'grad_norm': 8.35583782196045, 'learning_rate': 2.1982558139534885e-05, 'loss_1': 0.02175961248576641, 'loss_2': 0.0050048828125, 'loss_3': -16.397300720214844, 'loss_4': 0.023438967764377594, 'epoch': 8.04}
{'loss': 0.0322, 'grad_norm': 10.300084114074707, 'learning_rate': 2.197674418604651e-05, 'loss_1': 0.026707520708441734, 'loss_2': 0.00551605224609375, 'loss_3': -16.42498016357422, 'loss_4': 0.1631453037261963, 'epoch': 8.05}
{'loss': 0.0182, 'grad_norm': 6.823974609375, 'learning_rate': 2.197093023255814e-05, 'loss_1': 0.015468740835785866, 'loss_2': 0.0027313232421875, 'loss_3': -16.3754825592041, 'loss_4': 0.2201041728258133, 'epoch': 8.05}
[INFO|trainer.py:4228] 2025-01-21 12:54:40,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:40,738 >>   Batch size = 64
 27%|██████████████████████████████████████████████████████████▉                                                                                                                                                                | 1390/5160 [34:45<1:05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:48,098 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023709582164883614, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.625, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.017290139570832253, 'eval_loss_2': 0.006419442594051361, 'eval_loss_3': -18.239154815673828, 'eval_loss_4': 0.4761948883533478, 'epoch': 8.05}
{'loss': 0.0533, 'grad_norm': 21.448108673095703, 'learning_rate': 2.1965116279069768e-05, 'loss_1': 0.050260163843631744, 'loss_2': 0.002994537353515625, 'loss_3': -16.423091888427734, 'loss_4': 0.19091670215129852, 'epoch': 8.06}
{'loss': 0.0323, 'grad_norm': 12.241355895996094, 'learning_rate': 2.1959302325581396e-05, 'loss_1': 0.031892210245132446, 'loss_2': 0.000362396240234375, 'loss_3': -16.222511291503906, 'loss_4': 0.4945746660232544, 'epoch': 8.06}
{'loss': 0.0291, 'grad_norm': 9.104287147521973, 'learning_rate': 2.1953488372093025e-05, 'loss_1': 0.019702879711985588, 'loss_2': 0.00943756103515625, 'loss_3': -16.470123291015625, 'loss_4': 0.5260106325149536, 'epoch': 8.07}
{'loss': 0.0187, 'grad_norm': 6.26331090927124, 'learning_rate': 2.194767441860465e-05, 'loss_1': 0.013784286566078663, 'loss_2': 0.0048828125, 'loss_3': -16.247940063476562, 'loss_4': 0.20865663886070251, 'epoch': 8.08}
{'loss': 0.0139, 'grad_norm': 5.937747001647949, 'learning_rate': 2.194186046511628e-05, 'loss_1': 0.010407814756035805, 'loss_2': 0.003513336181640625, 'loss_3': -16.080142974853516, 'loss_4': 0.37397661805152893, 'epoch': 8.08}
[INFO|trainer.py:4228] 2025-01-21 12:54:48,098 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:48,098 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▏                                                                                                                                                               | 1395/5160 [34:52<1:05:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:54:55,463 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030821120366454124, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.75, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.026290282607078552, 'eval_loss_2': 0.0045308396220207214, 'eval_loss_3': -18.153152465820312, 'eval_loss_4': 0.6534139513969421, 'epoch': 8.08}
{'loss': 0.015, 'grad_norm': 6.875075817108154, 'learning_rate': 2.1936046511627908e-05, 'loss_1': 0.013024832122027874, 'loss_2': 0.001956939697265625, 'loss_3': -16.333906173706055, 'loss_4': 0.2727581858634949, 'epoch': 8.09}
{'loss': 0.0136, 'grad_norm': 5.897167205810547, 'learning_rate': 2.1930232558139536e-05, 'loss_1': 0.009893176145851612, 'loss_2': 0.0037479400634765625, 'loss_3': -16.2119083404541, 'loss_4': 0.26149982213974, 'epoch': 8.09}
{'loss': 0.04, 'grad_norm': 11.918335914611816, 'learning_rate': 2.192441860465116e-05, 'loss_1': 0.03968370705842972, 'loss_2': 0.00034165382385253906, 'loss_3': -16.420804977416992, 'loss_4': 0.7721234560012817, 'epoch': 8.1}
{'loss': 0.0156, 'grad_norm': 5.68930721282959, 'learning_rate': 2.191860465116279e-05, 'loss_1': 0.01140472199767828, 'loss_2': 0.00423431396484375, 'loss_3': -16.030559539794922, 'loss_4': 0.9969639778137207, 'epoch': 8.1}
{'loss': 0.0098, 'grad_norm': 6.471923828125, 'learning_rate': 2.1912790697674422e-05, 'loss_1': 0.009116926230490208, 'loss_2': 0.0006456375122070312, 'loss_3': -16.190704345703125, 'loss_4': 0.5731168389320374, 'epoch': 8.11}
[INFO|trainer.py:4228] 2025-01-21 12:54:55,464 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:54:55,464 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▍                                                                                                                                                               | 1400/5160 [34:59<1:05:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:02,838 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.05026327818632126, 'eval_runtime': 3.8167, 'eval_samples_per_second': 268.296, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.045162077993154526, 'eval_loss_2': 0.005101203918457031, 'eval_loss_3': -18.07434844970703, 'eval_loss_4': 0.8830181956291199, 'epoch': 8.11}
{'loss': 0.0188, 'grad_norm': 8.395805358886719, 'learning_rate': 2.1906976744186047e-05, 'loss_1': 0.015761494636535645, 'loss_2': 0.0030574798583984375, 'loss_3': -16.376445770263672, 'loss_4': 0.6600654125213623, 'epoch': 8.12}
{'loss': 0.0257, 'grad_norm': 9.574667930603027, 'learning_rate': 2.1901162790697676e-05, 'loss_1': 0.019463522359728813, 'loss_2': 0.00627899169921875, 'loss_3': -16.330978393554688, 'loss_4': 0.6644218564033508, 'epoch': 8.12}
{'loss': 0.0481, 'grad_norm': 24.849952697753906, 'learning_rate': 2.18953488372093e-05, 'loss_1': 0.043198347091674805, 'loss_2': 0.0048828125, 'loss_3': -15.972322463989258, 'loss_4': 0.5382956862449646, 'epoch': 8.13}
{'loss': 0.0089, 'grad_norm': 5.037174701690674, 'learning_rate': 2.188953488372093e-05, 'loss_1': 0.006869523320347071, 'loss_2': 0.001995086669921875, 'loss_3': -16.00041961669922, 'loss_4': 0.6015064120292664, 'epoch': 8.13}
{'loss': 0.0206, 'grad_norm': 5.69281005859375, 'learning_rate': 2.1883720930232562e-05, 'loss_1': 0.010446032509207726, 'loss_2': 0.0101470947265625, 'loss_3': -16.23154640197754, 'loss_4': 0.7416713833808899, 'epoch': 8.14}
[INFO|trainer.py:4228] 2025-01-21 12:55:02,838 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:02,838 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▋                                                                                                                                                               | 1405/5160 [35:07<1:05:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:10,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.034320298582315445, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.825, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.027924904599785805, 'eval_loss_2': 0.006395399570465088, 'eval_loss_3': -18.140052795410156, 'eval_loss_4': 1.185011863708496, 'epoch': 8.14}
{'loss': 0.0182, 'grad_norm': 5.0886383056640625, 'learning_rate': 2.1877906976744187e-05, 'loss_1': 0.007734035607427359, 'loss_2': 0.010467529296875, 'loss_3': -16.127727508544922, 'loss_4': 0.8584990501403809, 'epoch': 8.15}
{'loss': 0.0228, 'grad_norm': 8.505134582519531, 'learning_rate': 2.1872093023255816e-05, 'loss_1': 0.019754189997911453, 'loss_2': 0.0030059814453125, 'loss_3': -15.97209358215332, 'loss_4': 1.052703857421875, 'epoch': 8.15}
{'loss': 0.0149, 'grad_norm': 5.824510097503662, 'learning_rate': 2.186627906976744e-05, 'loss_1': 0.011406098492443562, 'loss_2': 0.0034942626953125, 'loss_3': -16.208646774291992, 'loss_4': 0.48597604036331177, 'epoch': 8.16}
{'loss': 0.0118, 'grad_norm': 4.630733013153076, 'learning_rate': 2.186046511627907e-05, 'loss_1': 0.005310683976858854, 'loss_2': 0.006511688232421875, 'loss_3': -16.16546630859375, 'loss_4': 1.3037304878234863, 'epoch': 8.16}
{'loss': 0.0098, 'grad_norm': 5.308848857879639, 'learning_rate': 2.1854651162790698e-05, 'loss_1': 0.005547157488763332, 'loss_2': 0.00421905517578125, 'loss_3': -16.47197151184082, 'loss_4': 0.9616090655326843, 'epoch': 8.17}
[INFO|trainer.py:4228] 2025-01-21 12:55:10,201 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:10,201 >>   Batch size = 64
 27%|███████████████████████████████████████████████████████████▊                                                                                                                                                               | 1410/5160 [35:14<1:05:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:17,567 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020949658006429672, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.645, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.016598250716924667, 'eval_loss_2': 0.004351407289505005, 'eval_loss_3': -18.161846160888672, 'eval_loss_4': 1.326584815979004, 'epoch': 8.17}
{'loss': 0.0199, 'grad_norm': 11.7300386428833, 'learning_rate': 2.1848837209302327e-05, 'loss_1': 0.01689387671649456, 'loss_2': 0.003017425537109375, 'loss_3': -15.967059135437012, 'loss_4': 1.1720398664474487, 'epoch': 8.17}
{'loss': 0.0268, 'grad_norm': 10.364019393920898, 'learning_rate': 2.1843023255813956e-05, 'loss_1': 0.020246073603630066, 'loss_2': 0.0065155029296875, 'loss_3': -16.297502517700195, 'loss_4': 1.238742470741272, 'epoch': 8.18}
{'loss': 0.0145, 'grad_norm': 5.260268688201904, 'learning_rate': 2.183720930232558e-05, 'loss_1': 0.0092020183801651, 'loss_2': 0.00531005859375, 'loss_3': -16.528139114379883, 'loss_4': 0.9912552833557129, 'epoch': 8.19}
{'loss': 0.0293, 'grad_norm': 6.792809963226318, 'learning_rate': 2.183139534883721e-05, 'loss_1': 0.019056828692555428, 'loss_2': 0.0102386474609375, 'loss_3': -16.262859344482422, 'loss_4': 1.4510159492492676, 'epoch': 8.19}
{'loss': 0.0137, 'grad_norm': 7.211972713470459, 'learning_rate': 2.1825581395348838e-05, 'loss_1': 0.013705708086490631, 'loss_2': 4.470348358154297e-06, 'loss_3': -16.30071258544922, 'loss_4': 2.0966882705688477, 'epoch': 8.2}
[INFO|trainer.py:4228] 2025-01-21 12:55:17,567 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:17,567 >>   Batch size = 64
 27%|████████████████████████████████████████████████████████████                                                                                                                                                               | 1415/5160 [35:22<1:04:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:24,929 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018358655273914337, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.954, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013797289691865444, 'eval_loss_2': 0.004561364650726318, 'eval_loss_3': -18.1923885345459, 'eval_loss_4': 1.6800495386123657, 'epoch': 8.2}
{'loss': 0.0242, 'grad_norm': 15.461207389831543, 'learning_rate': 2.1819767441860467e-05, 'loss_1': 0.022830134257674217, 'loss_2': 0.001415252685546875, 'loss_3': -16.300207138061523, 'loss_4': 1.51777982711792, 'epoch': 8.2}
{'loss': 0.0122, 'grad_norm': 6.318922996520996, 'learning_rate': 2.1813953488372095e-05, 'loss_1': 0.011372659355401993, 'loss_2': 0.0008497238159179688, 'loss_3': -16.168235778808594, 'loss_4': 1.3732414245605469, 'epoch': 8.21}
{'loss': 0.0168, 'grad_norm': 5.930440902709961, 'learning_rate': 2.180813953488372e-05, 'loss_1': 0.012980814091861248, 'loss_2': 0.0038433074951171875, 'loss_3': -16.267818450927734, 'loss_4': 1.7627662420272827, 'epoch': 8.22}
{'loss': 0.0116, 'grad_norm': 4.919095516204834, 'learning_rate': 2.180232558139535e-05, 'loss_1': 0.004403294529765844, 'loss_2': 0.00724029541015625, 'loss_3': -16.32696533203125, 'loss_4': 1.7042258977890015, 'epoch': 8.22}
{'loss': 0.0102, 'grad_norm': 4.603829860687256, 'learning_rate': 2.1796511627906978e-05, 'loss_1': 0.004750893916934729, 'loss_2': 0.005443572998046875, 'loss_3': -16.4139404296875, 'loss_4': 1.3507442474365234, 'epoch': 8.23}
[INFO|trainer.py:4228] 2025-01-21 12:55:24,929 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:24,929 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▎                                                                                                                                                              | 1420/5160 [35:29<1:04:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:32,297 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017905401065945625, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.699, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.013365279883146286, 'eval_loss_2': 0.0045401230454444885, 'eval_loss_3': -18.226703643798828, 'eval_loss_4': 1.9555673599243164, 'epoch': 8.23}
{'loss': 0.0254, 'grad_norm': 10.209444999694824, 'learning_rate': 2.1790697674418606e-05, 'loss_1': 0.021907750517129898, 'loss_2': 0.003459930419921875, 'loss_3': -16.275991439819336, 'loss_4': 2.055561065673828, 'epoch': 8.23}
{'loss': 0.0237, 'grad_norm': 10.482993125915527, 'learning_rate': 2.1784883720930232e-05, 'loss_1': 0.019359778612852097, 'loss_2': 0.004302978515625, 'loss_3': -16.036907196044922, 'loss_4': 2.628227710723877, 'epoch': 8.24}
{'loss': 0.0136, 'grad_norm': 5.838391304016113, 'learning_rate': 2.177906976744186e-05, 'loss_1': 0.009288256987929344, 'loss_2': 0.004322052001953125, 'loss_3': -16.266765594482422, 'loss_4': 2.254794120788574, 'epoch': 8.24}
{'loss': 0.0141, 'grad_norm': 5.122793197631836, 'learning_rate': 2.177325581395349e-05, 'loss_1': 0.0052507370710372925, 'loss_2': 0.00881195068359375, 'loss_3': -16.192296981811523, 'loss_4': 1.8438820838928223, 'epoch': 8.25}
{'loss': 0.011, 'grad_norm': 5.890027046203613, 'learning_rate': 2.1767441860465118e-05, 'loss_1': 0.009693550877273083, 'loss_2': 0.001293182373046875, 'loss_3': -16.1949405670166, 'loss_4': 2.104160785675049, 'epoch': 8.26}
[INFO|trainer.py:4228] 2025-01-21 12:55:32,297 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:32,298 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▍                                                                                                                                                              | 1425/5160 [35:36<1:04:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:39,684 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03436572104692459, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.498, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.029869485646486282, 'eval_loss_2': 0.004496239125728607, 'eval_loss_3': -18.147430419921875, 'eval_loss_4': 2.2861218452453613, 'epoch': 8.26}
{'loss': 0.0452, 'grad_norm': 11.401993751525879, 'learning_rate': 2.1761627906976746e-05, 'loss_1': 0.036631204187870026, 'loss_2': 0.008544921875, 'loss_3': -16.11090660095215, 'loss_4': 1.9585742950439453, 'epoch': 8.26}
{'loss': 0.0399, 'grad_norm': 13.393144607543945, 'learning_rate': 2.175581395348837e-05, 'loss_1': 0.03894447535276413, 'loss_2': 0.0009527206420898438, 'loss_3': -16.383163452148438, 'loss_4': 2.204530715942383, 'epoch': 8.27}
{'loss': 0.024, 'grad_norm': 10.305367469787598, 'learning_rate': 2.175e-05, 'loss_1': 0.01879221200942993, 'loss_2': 0.005245208740234375, 'loss_3': -16.248680114746094, 'loss_4': 2.32822322845459, 'epoch': 8.27}
{'loss': 0.0175, 'grad_norm': 11.491939544677734, 'learning_rate': 2.174418604651163e-05, 'loss_1': 0.016765408217906952, 'loss_2': 0.000690460205078125, 'loss_3': -16.03583526611328, 'loss_4': 2.427694320678711, 'epoch': 8.28}
{'loss': 0.0303, 'grad_norm': 8.946366310119629, 'learning_rate': 2.1738372093023257e-05, 'loss_1': 0.0213699322193861, 'loss_2': 0.00897216796875, 'loss_3': -16.283618927001953, 'loss_4': 1.8526875972747803, 'epoch': 8.28}
[INFO|trainer.py:4228] 2025-01-21 12:55:39,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:39,684 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▋                                                                                                                                                              | 1430/5160 [35:44<1:04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:47,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09373392164707184, 'eval_runtime': 3.8234, 'eval_samples_per_second': 267.825, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.0875076875090599, 'eval_loss_2': 0.006226241588592529, 'eval_loss_3': -18.029617309570312, 'eval_loss_4': 2.705775260925293, 'epoch': 8.28}
{'loss': 0.031, 'grad_norm': 9.445867538452148, 'learning_rate': 2.1732558139534886e-05, 'loss_1': 0.018958553671836853, 'loss_2': 0.011993408203125, 'loss_3': -16.03307342529297, 'loss_4': 2.114445924758911, 'epoch': 8.29}
{'loss': 0.0158, 'grad_norm': 4.972400665283203, 'learning_rate': 2.172674418604651e-05, 'loss_1': 0.006291270721703768, 'loss_2': 0.0095062255859375, 'loss_3': -16.50217056274414, 'loss_4': 2.290527820587158, 'epoch': 8.3}
{'loss': 0.0382, 'grad_norm': 12.239185333251953, 'learning_rate': 2.172093023255814e-05, 'loss_1': 0.03645376116037369, 'loss_2': 0.001758575439453125, 'loss_3': -16.2015438079834, 'loss_4': 2.55357027053833, 'epoch': 8.3}
{'loss': 0.0584, 'grad_norm': 29.596031188964844, 'learning_rate': 2.1715116279069765e-05, 'loss_1': 0.05394362285733223, 'loss_2': 0.004413604736328125, 'loss_3': -15.870161056518555, 'loss_4': 2.668473482131958, 'epoch': 8.31}
{'loss': 0.0609, 'grad_norm': 15.873303413391113, 'learning_rate': 2.1709302325581397e-05, 'loss_1': 0.05892219766974449, 'loss_2': 0.002010345458984375, 'loss_3': -16.05228042602539, 'loss_4': 2.7792410850524902, 'epoch': 8.31}
[INFO|trainer.py:4228] 2025-01-21 12:55:47,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:47,062 >>   Batch size = 64
 28%|████████████████████████████████████████████████████████████▉                                                                                                                                                              | 1435/5160 [35:51<1:04:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:55:54,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.08965922892093658, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.56, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.08547718822956085, 'eval_loss_2': 0.004182040691375732, 'eval_loss_3': -18.05501365661621, 'eval_loss_4': 3.004390239715576, 'epoch': 8.31}
{'loss': 0.0228, 'grad_norm': 8.989598274230957, 'learning_rate': 2.1703488372093026e-05, 'loss_1': 0.01876044273376465, 'loss_2': 0.004016876220703125, 'loss_3': -16.391637802124023, 'loss_4': 2.608107805252075, 'epoch': 8.32}
{'loss': 0.0855, 'grad_norm': 27.224456787109375, 'learning_rate': 2.169767441860465e-05, 'loss_1': 0.07373286038637161, 'loss_2': 0.01174163818359375, 'loss_3': -15.979918479919434, 'loss_4': 2.728837490081787, 'epoch': 8.33}
{'loss': 0.0269, 'grad_norm': 5.7019877433776855, 'learning_rate': 2.169186046511628e-05, 'loss_1': 0.014660765416920185, 'loss_2': 0.0122528076171875, 'loss_3': -16.038162231445312, 'loss_4': 3.1712052822113037, 'epoch': 8.33}
{'loss': 0.0276, 'grad_norm': 6.284787178039551, 'learning_rate': 2.1686046511627905e-05, 'loss_1': 0.015666663646697998, 'loss_2': 0.0119171142578125, 'loss_3': -16.313858032226562, 'loss_4': 2.526859760284424, 'epoch': 8.34}
{'loss': 0.0488, 'grad_norm': 20.121788024902344, 'learning_rate': 2.1680232558139537e-05, 'loss_1': 0.03530748933553696, 'loss_2': 0.0134429931640625, 'loss_3': -16.12598419189453, 'loss_4': 3.0441489219665527, 'epoch': 8.34}
[INFO|trainer.py:4228] 2025-01-21 12:55:54,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:55:54,434 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████                                                                                                                                                              | 1440/5160 [35:58<1:04:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:01,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027650218456983566, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.814, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01802186481654644, 'eval_loss_2': 0.009628355503082275, 'eval_loss_3': -18.2365779876709, 'eval_loss_4': 3.077854871749878, 'epoch': 8.34}
{'loss': 0.0122, 'grad_norm': 4.9213385581970215, 'learning_rate': 2.1674418604651162e-05, 'loss_1': 0.0069012329913675785, 'loss_2': 0.005279541015625, 'loss_3': -16.25597381591797, 'loss_4': 2.9711427688598633, 'epoch': 8.35}
{'loss': 0.0171, 'grad_norm': 4.498130798339844, 'learning_rate': 2.166860465116279e-05, 'loss_1': 0.009493020363152027, 'loss_2': 0.00756072998046875, 'loss_3': -16.298704147338867, 'loss_4': 2.637558937072754, 'epoch': 8.35}
{'loss': 0.0244, 'grad_norm': 8.300980567932129, 'learning_rate': 2.166279069767442e-05, 'loss_1': 0.024290617555379868, 'loss_2': 0.0001583099365234375, 'loss_3': -16.041671752929688, 'loss_4': 3.4283711910247803, 'epoch': 8.36}
{'loss': 0.0419, 'grad_norm': 17.470109939575195, 'learning_rate': 2.1656976744186045e-05, 'loss_1': 0.041458189487457275, 'loss_2': 0.0004189014434814453, 'loss_3': -16.109111785888672, 'loss_4': 3.6149559020996094, 'epoch': 8.37}
{'loss': 0.0165, 'grad_norm': 5.983677387237549, 'learning_rate': 2.1651162790697677e-05, 'loss_1': 0.0156560018658638, 'loss_2': 0.0008358955383300781, 'loss_3': -16.331562042236328, 'loss_4': 3.184671640396118, 'epoch': 8.37}
[INFO|trainer.py:4228] 2025-01-21 12:56:01,801 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:01,801 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▎                                                                                                                                                             | 1445/5160 [36:06<1:04:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:09,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015122217126190662, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.48, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011148033663630486, 'eval_loss_2': 0.0039741843938827515, 'eval_loss_3': -18.25701141357422, 'eval_loss_4': 3.2783443927764893, 'epoch': 8.37}
{'loss': 0.0253, 'grad_norm': 10.094955444335938, 'learning_rate': 2.1645348837209302e-05, 'loss_1': 0.023123236373066902, 'loss_2': 0.002155303955078125, 'loss_3': -16.09703826904297, 'loss_4': 3.237278461456299, 'epoch': 8.38}
{'loss': 0.015, 'grad_norm': 5.333169460296631, 'learning_rate': 2.163953488372093e-05, 'loss_1': 0.01293751411139965, 'loss_2': 0.002071380615234375, 'loss_3': -16.28689956665039, 'loss_4': 3.287792921066284, 'epoch': 8.38}
{'loss': 0.0099, 'grad_norm': 5.225734233856201, 'learning_rate': 2.163372093023256e-05, 'loss_1': 0.009060658514499664, 'loss_2': 0.0008664131164550781, 'loss_3': -16.174955368041992, 'loss_4': 3.620175361633301, 'epoch': 8.39}
{'loss': 0.016, 'grad_norm': 5.2440185546875, 'learning_rate': 2.1627906976744184e-05, 'loss_1': 0.012383466586470604, 'loss_2': 0.0036525726318359375, 'loss_3': -16.370075225830078, 'loss_4': 3.3469769954681396, 'epoch': 8.4}
{'loss': 0.0253, 'grad_norm': 6.6675801277160645, 'learning_rate': 2.1622093023255816e-05, 'loss_1': 0.013017041608691216, 'loss_2': 0.012298583984375, 'loss_3': -16.22458267211914, 'loss_4': 3.3408875465393066, 'epoch': 8.4}
[INFO|trainer.py:4228] 2025-01-21 12:56:09,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:09,177 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:13<1:04:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:16,551 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012106883339583874, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.739, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007655905559659004, 'eval_loss_2': 0.004450976848602295, 'eval_loss_3': -18.265026092529297, 'eval_loss_4': 3.345987319946289, 'epoch': 8.4}
{'loss': 0.015, 'grad_norm': 6.694738864898682, 'learning_rate': 2.1616279069767442e-05, 'loss_1': 0.013793105259537697, 'loss_2': 0.0011625289916992188, 'loss_3': -16.272796630859375, 'loss_4': 3.6937813758850098, 'epoch': 8.41}
{'loss': 0.0342, 'grad_norm': 6.5315961837768555, 'learning_rate': 2.161046511627907e-05, 'loss_1': 0.019555192440748215, 'loss_2': 0.0146026611328125, 'loss_3': -16.20687484741211, 'loss_4': 3.550511598587036, 'epoch': 8.41}
{'loss': 0.0326, 'grad_norm': 12.716547012329102, 'learning_rate': 2.1604651162790696e-05, 'loss_1': 0.030467065051198006, 'loss_2': 0.0021114349365234375, 'loss_3': -16.281509399414062, 'loss_4': 3.6381473541259766, 'epoch': 8.42}
{'loss': 0.0106, 'grad_norm': 5.285276412963867, 'learning_rate': 2.1598837209302324e-05, 'loss_1': 0.009034431539475918, 'loss_2': 0.00151824951171875, 'loss_3': -16.01565933227539, 'loss_4': 3.3109092712402344, 'epoch': 8.42}
{'loss': 0.0132, 'grad_norm': 4.936660289764404, 'learning_rate': 2.1593023255813956e-05, 'loss_1': 0.008413786068558693, 'loss_2': 0.004791259765625, 'loss_3': -16.34210205078125, 'loss_4': 3.5288071632385254, 'epoch': 8.43}
[INFO|trainer.py:4228] 2025-01-21 12:56:16,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:16,551 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▌                                                                                                                                                             | 1450/5160 [36:17<1:04:23,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:56:20,372 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1450
[INFO|configuration_utils.py:420] 2025-01-21 12:56:20,373 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1450/config.json                                                                            
{'eval_loss': 0.009212661534547806, 'eval_runtime': 3.8192, 'eval_samples_per_second': 268.117, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.006145122926682234, 'eval_loss_2': 0.0030675381422042847, 'eval_loss_3': -18.26720428466797, 'eval_loss_4': 3.301362991333008, 'epoch': 8.43}
[INFO|modeling_utils.py:2988] 2025-01-21 12:56:20,893 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1450/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:56:20,895 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1450/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:56:20,895 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1450/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:56:21,840 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1215] due to args.save_total_limit
 28%|█████████████████████████████████████████████████████████████▊                                                                                                                                                             | 1455/5160 [36:22<1:11:13,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:56:25,490 >>
{'loss': 0.0181, 'grad_norm': 6.397920608520508, 'learning_rate': 2.158720930232558e-05, 'loss_1': 0.0125274034217, 'loss_2': 0.00557708740234375, 'loss_3': -16.32202911376953, 'loss_4': 3.656078815460205, 'epoch': 8.44}
{'loss': 0.0166, 'grad_norm': 6.332648754119873, 'learning_rate': 2.158139534883721e-05, 'loss_1': 0.014168646186590195, 'loss_2': 0.00247955322265625, 'loss_3': -16.23273468017578, 'loss_4': 3.4032351970672607, 'epoch': 8.44}
{'loss': 0.0219, 'grad_norm': 6.977664947509766, 'learning_rate': 2.1575581395348835e-05, 'loss_1': 0.01869138889014721, 'loss_2': 0.003170013427734375, 'loss_3': -15.936525344848633, 'loss_4': 2.9827537536621094, 'epoch': 8.45}
{'loss': 0.011, 'grad_norm': 6.955153942108154, 'learning_rate': 2.1569767441860464e-05, 'loss_1': 0.009015712887048721, 'loss_2': 0.002025604248046875, 'loss_3': -16.243677139282227, 'loss_4': 3.6021695137023926, 'epoch': 8.45}
{'loss': 0.0179, 'grad_norm': 4.976255416870117, 'learning_rate': 2.1563953488372096e-05, 'loss_1': 0.007816683501005173, 'loss_2': 0.0101318359375, 'loss_3': -16.432594299316406, 'loss_4': 3.3673899173736572, 'epoch': 8.46}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:56:25,490 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:25,491 >>   Batch size = 64
 28%|█████████████████████████████████████████████████████████████▉                                                                                                                                                             | 1460/5160 [36:30<1:05:26,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:56:32,865 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015341266989707947, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.631, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0068181599490344524, 'eval_loss_2': 0.008523106575012207, 'eval_loss_3': -18.245513916015625, 'eval_loss_4': 2.95845890045166, 'epoch': 8.46}
{'loss': 0.0268, 'grad_norm': 9.355325698852539, 'learning_rate': 2.155813953488372e-05, 'loss_1': 0.020177118480205536, 'loss_2': 0.006622314453125, 'loss_3': -15.982897758483887, 'loss_4': 3.3813018798828125, 'epoch': 8.47}
{'loss': 0.0274, 'grad_norm': 6.754410266876221, 'learning_rate': 2.155232558139535e-05, 'loss_1': 0.012075134553015232, 'loss_2': 0.015350341796875, 'loss_3': -16.209054946899414, 'loss_4': 3.488494396209717, 'epoch': 8.47}
{'loss': 0.0272, 'grad_norm': 11.489977836608887, 'learning_rate': 2.1546511627906975e-05, 'loss_1': 0.02088414877653122, 'loss_2': 0.0062713623046875, 'loss_3': -16.142807006835938, 'loss_4': 2.844980478286743, 'epoch': 8.48}
{'loss': 0.0841, 'grad_norm': 31.474454879760742, 'learning_rate': 2.1540697674418607e-05, 'loss_1': 0.06954921036958694, 'loss_2': 0.0145111083984375, 'loss_3': -16.189308166503906, 'loss_4': 3.0434675216674805, 'epoch': 8.48}
{'loss': 0.0328, 'grad_norm': 9.669187545776367, 'learning_rate': 2.1534883720930232e-05, 'loss_1': 0.0209889505058527, 'loss_2': 0.0118560791015625, 'loss_3': -16.315332412719727, 'loss_4': 2.733696460723877, 'epoch': 8.49}
[INFO|trainer.py:4228] 2025-01-21 12:56:32,865 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:32,865 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▏                                                                                                                                                            | 1465/5160 [36:37<1:04:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:40,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01196420006453991, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.739, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005423425231128931, 'eval_loss_2': 0.006540775299072266, 'eval_loss_3': -18.257577896118164, 'eval_loss_4': 2.3281424045562744, 'epoch': 8.49}
{'loss': 0.0145, 'grad_norm': 7.940051555633545, 'learning_rate': 2.152906976744186e-05, 'loss_1': 0.009693281725049019, 'loss_2': 0.00478363037109375, 'loss_3': -16.100679397583008, 'loss_4': 2.7341716289520264, 'epoch': 8.49}
{'loss': 0.0299, 'grad_norm': 7.372683048248291, 'learning_rate': 2.152325581395349e-05, 'loss_1': 0.019221564754843712, 'loss_2': 0.01068878173828125, 'loss_3': -16.09002685546875, 'loss_4': 2.1032750606536865, 'epoch': 8.5}
{'loss': 0.0115, 'grad_norm': 6.338807582855225, 'learning_rate': 2.1517441860465115e-05, 'loss_1': 0.01130387932062149, 'loss_2': 0.000209808349609375, 'loss_3': -16.15914535522461, 'loss_4': 2.5561037063598633, 'epoch': 8.51}
{'loss': 0.0178, 'grad_norm': 8.2439603805542, 'learning_rate': 2.1511627906976747e-05, 'loss_1': 0.015933623537421227, 'loss_2': 0.00188446044921875, 'loss_3': -16.26834487915039, 'loss_4': 2.3116679191589355, 'epoch': 8.51}
{'loss': 0.0199, 'grad_norm': 10.6135835647583, 'learning_rate': 2.1505813953488372e-05, 'loss_1': 0.01783435232937336, 'loss_2': 0.002044677734375, 'loss_3': -16.36749267578125, 'loss_4': 2.6877808570861816, 'epoch': 8.52}
[INFO|trainer.py:4228] 2025-01-21 12:56:40,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:40,236 >>   Batch size = 64
 28%|██████████████████████████████████████████████████████████████▍                                                                                                                                                            | 1470/5160 [36:44<1:04:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:47,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009900499135255814, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.679, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0061917053535580635, 'eval_loss_2': 0.0037087947130203247, 'eval_loss_3': -18.255517959594727, 'eval_loss_4': 1.7939707040786743, 'epoch': 8.52}
{'loss': 0.0139, 'grad_norm': 5.174487590789795, 'learning_rate': 2.15e-05, 'loss_1': 0.008053036406636238, 'loss_2': 0.00585174560546875, 'loss_3': -16.162336349487305, 'loss_4': 2.093709707260132, 'epoch': 8.52}
{'loss': 0.0166, 'grad_norm': 5.375646114349365, 'learning_rate': 2.149418604651163e-05, 'loss_1': 0.008461566641926765, 'loss_2': 0.00811767578125, 'loss_3': -16.449810028076172, 'loss_4': 1.9282482862472534, 'epoch': 8.53}
{'loss': 0.0161, 'grad_norm': 5.557826042175293, 'learning_rate': 2.1488372093023255e-05, 'loss_1': 0.01122987549751997, 'loss_2': 0.0048370361328125, 'loss_3': -16.1849365234375, 'loss_4': 1.878164291381836, 'epoch': 8.53}
{'loss': 0.0174, 'grad_norm': 9.524511337280273, 'learning_rate': 2.1482558139534887e-05, 'loss_1': 0.016827547922730446, 'loss_2': 0.0005445480346679688, 'loss_3': -16.2375545501709, 'loss_4': 0.8663637638092041, 'epoch': 8.54}
{'loss': 0.0432, 'grad_norm': 13.676664352416992, 'learning_rate': 2.1476744186046512e-05, 'loss_1': 0.034164924174547195, 'loss_2': 0.00904083251953125, 'loss_3': -16.007293701171875, 'loss_4': 0.836777925491333, 'epoch': 8.55}
[INFO|trainer.py:4228] 2025-01-21 12:56:47,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:47,601 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▌                                                                                                                                                            | 1475/5160 [36:52<1:03:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:56:54,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014542454853653908, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.651, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0070930360816419125, 'eval_loss_2': 0.007449418306350708, 'eval_loss_3': -18.253223419189453, 'eval_loss_4': 1.0910474061965942, 'epoch': 8.55}
{'loss': 0.0157, 'grad_norm': 5.779147148132324, 'learning_rate': 2.147093023255814e-05, 'loss_1': 0.012756713666021824, 'loss_2': 0.0029582977294921875, 'loss_3': -16.167354583740234, 'loss_4': 1.0260064601898193, 'epoch': 8.55}
{'loss': 0.0688, 'grad_norm': 33.282447814941406, 'learning_rate': 2.1465116279069766e-05, 'loss_1': 0.058513037860393524, 'loss_2': 0.0102691650390625, 'loss_3': -16.089609146118164, 'loss_4': 1.1807650327682495, 'epoch': 8.56}
{'loss': 0.0245, 'grad_norm': 9.371949195861816, 'learning_rate': 2.1459302325581394e-05, 'loss_1': 0.019886787980794907, 'loss_2': 0.00463104248046875, 'loss_3': -16.009780883789062, 'loss_4': 1.1221401691436768, 'epoch': 8.56}
{'loss': 0.0263, 'grad_norm': 7.080039978027344, 'learning_rate': 2.1453488372093026e-05, 'loss_1': 0.017046693712472916, 'loss_2': 0.0092620849609375, 'loss_3': -16.433956146240234, 'loss_4': 1.0513067245483398, 'epoch': 8.57}
{'loss': 0.0622, 'grad_norm': 11.09587574005127, 'learning_rate': 2.1447674418604652e-05, 'loss_1': 0.0565473847091198, 'loss_2': 0.00569915771484375, 'loss_3': -16.2232608795166, 'loss_4': 1.626524567604065, 'epoch': 8.58}
[INFO|trainer.py:4228] 2025-01-21 12:56:54,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:56:54,964 >>   Batch size = 64
 29%|██████████████████████████████████████████████████████████████▊                                                                                                                                                            | 1480/5160 [36:59<1:03:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:02,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010935617610812187, 'eval_runtime': 3.8221, 'eval_samples_per_second': 267.917, 'eval_steps_per_second': 4.186, 'eval_loss_1': 0.006516947411000729, 'eval_loss_2': 0.004418671131134033, 'eval_loss_3': -18.24246597290039, 'eval_loss_4': 0.8481593132019043, 'epoch': 8.58}
{'loss': 0.0196, 'grad_norm': 10.101811408996582, 'learning_rate': 2.144186046511628e-05, 'loss_1': 0.015288147144019604, 'loss_2': 0.004306793212890625, 'loss_3': -16.293800354003906, 'loss_4': 0.9959785342216492, 'epoch': 8.58}
{'loss': 0.0356, 'grad_norm': 17.27032470703125, 'learning_rate': 2.1436046511627906e-05, 'loss_1': 0.027942026033997536, 'loss_2': 0.007640838623046875, 'loss_3': -16.248031616210938, 'loss_4': 1.2703673839569092, 'epoch': 8.59}
{'loss': 0.0143, 'grad_norm': 8.56640625, 'learning_rate': 2.1430232558139534e-05, 'loss_1': 0.014141381718218327, 'loss_2': 0.00017654895782470703, 'loss_3': -16.276391983032227, 'loss_4': 1.2103136777877808, 'epoch': 8.59}
{'loss': 0.0185, 'grad_norm': 6.34032678604126, 'learning_rate': 2.1424418604651166e-05, 'loss_1': 0.013918227516114712, 'loss_2': 0.00455474853515625, 'loss_3': -16.37384033203125, 'loss_4': 0.7823350429534912, 'epoch': 8.6}
{'loss': 0.0087, 'grad_norm': 6.032248497009277, 'learning_rate': 2.141860465116279e-05, 'loss_1': 0.008424226194620132, 'loss_2': 0.00028705596923828125, 'loss_3': -16.2900390625, 'loss_4': 0.8391486406326294, 'epoch': 8.6}
[INFO|trainer.py:4228] 2025-01-21 12:57:02,346 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:02,346 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████                                                                                                                                                            | 1485/5160 [37:06<1:03:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:09,717 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010086826980113983, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.645, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005210630130022764, 'eval_loss_2': 0.004876196384429932, 'eval_loss_3': -18.280603408813477, 'eval_loss_4': 0.9755213260650635, 'epoch': 8.6}
{'loss': 0.0223, 'grad_norm': 8.0392484664917, 'learning_rate': 2.141279069767442e-05, 'loss_1': 0.018253639340400696, 'loss_2': 0.004070281982421875, 'loss_3': -16.27379035949707, 'loss_4': 0.8165902495384216, 'epoch': 8.61}
{'loss': 0.0188, 'grad_norm': 7.325686931610107, 'learning_rate': 2.1406976744186045e-05, 'loss_1': 0.011808804236352444, 'loss_2': 0.00695037841796875, 'loss_3': -16.2128963470459, 'loss_4': 1.1844841241836548, 'epoch': 8.62}
{'loss': 0.0188, 'grad_norm': 8.007759094238281, 'learning_rate': 2.1401162790697674e-05, 'loss_1': 0.01751439832150936, 'loss_2': 0.0012912750244140625, 'loss_3': -15.957042694091797, 'loss_4': 1.4008615016937256, 'epoch': 8.62}
{'loss': 0.0187, 'grad_norm': 5.64884090423584, 'learning_rate': 2.1395348837209303e-05, 'loss_1': 0.01237280759960413, 'loss_2': 0.0063629150390625, 'loss_3': -16.182519912719727, 'loss_4': 1.6376620531082153, 'epoch': 8.63}
{'loss': 0.0132, 'grad_norm': 5.195627212524414, 'learning_rate': 2.138953488372093e-05, 'loss_1': 0.010685439221560955, 'loss_2': 0.00247955322265625, 'loss_3': -16.227535247802734, 'loss_4': 1.408655047416687, 'epoch': 8.63}
[INFO|trainer.py:4228] 2025-01-21 12:57:09,717 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:09,717 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:14<1:03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:17,092 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009564938955008984, 'eval_runtime': 3.8169, 'eval_samples_per_second': 268.279, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005838306155055761, 'eval_loss_2': 0.0037266314029693604, 'eval_loss_3': -18.27378273010254, 'eval_loss_4': 1.1051740646362305, 'epoch': 8.63}
{'loss': 0.0461, 'grad_norm': 25.185916900634766, 'learning_rate': 2.138372093023256e-05, 'loss_1': 0.04395795986056328, 'loss_2': 0.0021152496337890625, 'loss_3': -16.150867462158203, 'loss_4': 1.8283939361572266, 'epoch': 8.64}
{'loss': 0.0103, 'grad_norm': 5.835447311401367, 'learning_rate': 2.1377906976744185e-05, 'loss_1': 0.010123749263584614, 'loss_2': 0.00016057491302490234, 'loss_3': -16.163557052612305, 'loss_4': 0.926205575466156, 'epoch': 8.65}
{'loss': 0.0214, 'grad_norm': 8.117158889770508, 'learning_rate': 2.1372093023255814e-05, 'loss_1': 0.015188624151051044, 'loss_2': 0.00620269775390625, 'loss_3': -16.134105682373047, 'loss_4': 0.8823857307434082, 'epoch': 8.65}
{'loss': 0.0256, 'grad_norm': 8.798316955566406, 'learning_rate': 2.1366279069767442e-05, 'loss_1': 0.02273056097328663, 'loss_2': 0.0028400421142578125, 'loss_3': -16.111454010009766, 'loss_4': 1.0303524732589722, 'epoch': 8.66}
{'loss': 0.0246, 'grad_norm': 7.3287882804870605, 'learning_rate': 2.136046511627907e-05, 'loss_1': 0.022614097222685814, 'loss_2': 0.002025604248046875, 'loss_3': -15.98631477355957, 'loss_4': 1.1324290037155151, 'epoch': 8.66}
[INFO|trainer.py:4228] 2025-01-21 12:57:17,092 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:17,092 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▏                                                                                                                                                           | 1490/5160 [37:18<1:03:43,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 12:57:20,902 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1490
[INFO|configuration_utils.py:420] 2025-01-21 12:57:20,903 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1490/config.json                                                                            
{'eval_loss': 0.009035165421664715, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.852, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006307097151875496, 'eval_loss_2': 0.0027280673384666443, 'eval_loss_3': -18.238584518432617, 'eval_loss_4': 1.0859076976776123, 'epoch': 8.66}
[INFO|modeling_utils.py:2988] 2025-01-21 12:57:21,382 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1490/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:57:21,383 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1490/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:57:21,384 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1490/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:57:22,386 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1450] due to args.save_total_limit
 29%|███████████████████████████████████████████████████████████████▍                                                                                                                                                           | 1495/5160 [37:23<1:10:34,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 12:57:26,040 >>
{'loss': 0.0235, 'grad_norm': 7.621665954589844, 'learning_rate': 2.13546511627907e-05, 'loss_1': 0.015293153002858162, 'loss_2': 0.0081634521484375, 'loss_3': -16.17661476135254, 'loss_4': 1.037846565246582, 'epoch': 8.67}
{'loss': 0.0193, 'grad_norm': 8.776060104370117, 'learning_rate': 2.1348837209302325e-05, 'loss_1': 0.019071243703365326, 'loss_2': 0.00026035308837890625, 'loss_3': -16.10284996032715, 'loss_4': 0.6309322714805603, 'epoch': 8.67}
{'loss': 0.034, 'grad_norm': 14.21591567993164, 'learning_rate': 2.1343023255813954e-05, 'loss_1': 0.030925707891583443, 'loss_2': 0.003082275390625, 'loss_3': -16.189659118652344, 'loss_4': 1.1049530506134033, 'epoch': 8.68}
{'loss': 0.0122, 'grad_norm': 7.051182746887207, 'learning_rate': 2.1337209302325582e-05, 'loss_1': 0.01061737909913063, 'loss_2': 0.0015430450439453125, 'loss_3': -16.13082504272461, 'loss_4': 1.1078003644943237, 'epoch': 8.69}
{'loss': 0.0212, 'grad_norm': 6.959752082824707, 'learning_rate': 2.133139534883721e-05, 'loss_1': 0.014081086963415146, 'loss_2': 0.007110595703125, 'loss_3': -16.396991729736328, 'loss_4': 1.3363771438598633, 'epoch': 8.69}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:57:26,040 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:26,040 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▋                                                                                                                                                           | 1500/5160 [37:30<1:04:46,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:57:33,416 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011409730650484562, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.605, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009186597540974617, 'eval_loss_2': 0.0022231340408325195, 'eval_loss_3': -18.201221466064453, 'eval_loss_4': 1.1217613220214844, 'epoch': 8.69}
{'loss': 0.0128, 'grad_norm': 7.942962169647217, 'learning_rate': 2.1325581395348836e-05, 'loss_1': 0.012110135518014431, 'loss_2': 0.0006647109985351562, 'loss_3': -16.13762664794922, 'loss_4': 1.3162446022033691, 'epoch': 8.7}
{'loss': 0.0224, 'grad_norm': 9.991826057434082, 'learning_rate': 2.1319767441860465e-05, 'loss_1': 0.016170553863048553, 'loss_2': 0.0062713623046875, 'loss_3': -16.03965950012207, 'loss_4': 1.0494462251663208, 'epoch': 8.7}
{'loss': 0.028, 'grad_norm': 14.269600868225098, 'learning_rate': 2.1313953488372093e-05, 'loss_1': 0.022937418892979622, 'loss_2': 0.0050506591796875, 'loss_3': -16.047218322753906, 'loss_4': 1.277830719947815, 'epoch': 8.71}
{'loss': 0.0166, 'grad_norm': 6.642749309539795, 'learning_rate': 2.1308139534883722e-05, 'loss_1': 0.011873504146933556, 'loss_2': 0.00476837158203125, 'loss_3': -16.02420997619629, 'loss_4': 1.1864902973175049, 'epoch': 8.72}
{'loss': 0.0224, 'grad_norm': 8.814717292785645, 'learning_rate': 2.130232558139535e-05, 'loss_1': 0.02240130305290222, 'loss_2': 1.2755393981933594e-05, 'loss_3': -15.94517707824707, 'loss_4': 1.3147070407867432, 'epoch': 8.72}
[INFO|trainer.py:4228] 2025-01-21 12:57:33,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:33,417 >>   Batch size = 64
 29%|███████████████████████████████████████████████████████████████▉                                                                                                                                                           | 1505/5160 [37:37<1:03:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:40,783 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010670093819499016, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.313, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007378687616437674, 'eval_loss_2': 0.003291405737400055, 'eval_loss_3': -18.18355941772461, 'eval_loss_4': 1.3004990816116333, 'epoch': 8.72}
{'loss': 0.0191, 'grad_norm': 9.603853225708008, 'learning_rate': 2.1296511627906976e-05, 'loss_1': 0.01600550301373005, 'loss_2': 0.003082275390625, 'loss_3': -16.136465072631836, 'loss_4': 0.8891129493713379, 'epoch': 8.73}
{'loss': 0.0086, 'grad_norm': 4.743762493133545, 'learning_rate': 2.1290697674418604e-05, 'loss_1': 0.003889592131599784, 'loss_2': 0.004730224609375, 'loss_3': -16.211198806762695, 'loss_4': 1.3372509479522705, 'epoch': 8.73}
{'loss': 0.0101, 'grad_norm': 5.0933074951171875, 'learning_rate': 2.1284883720930233e-05, 'loss_1': 0.007496876176446676, 'loss_2': 0.002651214599609375, 'loss_3': -16.162351608276367, 'loss_4': 0.9404542446136475, 'epoch': 8.74}
{'loss': 0.0121, 'grad_norm': 7.646763801574707, 'learning_rate': 2.1279069767441862e-05, 'loss_1': 0.011775095947086811, 'loss_2': 0.0002760887145996094, 'loss_3': -16.27861785888672, 'loss_4': 1.3531389236450195, 'epoch': 8.74}
{'loss': 0.0169, 'grad_norm': 5.847867012023926, 'learning_rate': 2.127325581395349e-05, 'loss_1': 0.009274010546505451, 'loss_2': 0.007579803466796875, 'loss_3': -16.159507751464844, 'loss_4': 1.5784770250320435, 'epoch': 8.75}
[INFO|trainer.py:4228] 2025-01-21 12:57:40,783 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:40,783 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████                                                                                                                                                           | 1510/5160 [37:45<1:03:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:48,156 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011542638763785362, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.326, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.006326561328023672, 'eval_loss_2': 0.005216076970100403, 'eval_loss_3': -18.218212127685547, 'eval_loss_4': 1.5715750455856323, 'epoch': 8.75}
{'loss': 0.018, 'grad_norm': 6.487542629241943, 'learning_rate': 2.1267441860465116e-05, 'loss_1': 0.011155466549098492, 'loss_2': 0.006809234619140625, 'loss_3': -16.12761688232422, 'loss_4': 1.2997264862060547, 'epoch': 8.76}
{'loss': 0.0255, 'grad_norm': 7.538881778717041, 'learning_rate': 2.1261627906976744e-05, 'loss_1': 0.018427375704050064, 'loss_2': 0.00708770751953125, 'loss_3': -16.23708152770996, 'loss_4': 2.055941581726074, 'epoch': 8.76}
{'loss': 0.0092, 'grad_norm': 5.442379951477051, 'learning_rate': 2.125581395348837e-05, 'loss_1': 0.008204546757042408, 'loss_2': 0.0009565353393554688, 'loss_3': -15.981019020080566, 'loss_4': 1.9911127090454102, 'epoch': 8.77}
{'loss': 0.0191, 'grad_norm': 8.274175643920898, 'learning_rate': 2.125e-05, 'loss_1': 0.01585402525961399, 'loss_2': 0.0032520294189453125, 'loss_3': -16.224843978881836, 'loss_4': 1.8732995986938477, 'epoch': 8.77}
{'loss': 0.0148, 'grad_norm': 7.001480579376221, 'learning_rate': 2.124418604651163e-05, 'loss_1': 0.012223201803863049, 'loss_2': 0.00255584716796875, 'loss_3': -16.225067138671875, 'loss_4': 1.8003647327423096, 'epoch': 8.78}
[INFO|trainer.py:4228] 2025-01-21 12:57:48,156 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:48,157 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▎                                                                                                                                                          | 1515/5160 [37:52<1:03:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:57:55,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01053179707378149, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.7, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006800452712923288, 'eval_loss_2': 0.0037313438951969147, 'eval_loss_3': -18.19086456298828, 'eval_loss_4': 1.882800817489624, 'epoch': 8.78}
{'loss': 0.0096, 'grad_norm': 5.35512638092041, 'learning_rate': 2.1238372093023255e-05, 'loss_1': 0.006360937841236591, 'loss_2': 0.003261566162109375, 'loss_3': -15.987077713012695, 'loss_4': 1.7142510414123535, 'epoch': 8.78}
{'loss': 0.0154, 'grad_norm': 7.243194103240967, 'learning_rate': 2.1232558139534884e-05, 'loss_1': 0.009794339537620544, 'loss_2': 0.00560760498046875, 'loss_3': -16.02252197265625, 'loss_4': 1.5976474285125732, 'epoch': 8.79}
{'loss': 0.0214, 'grad_norm': 7.887458324432373, 'learning_rate': 2.122674418604651e-05, 'loss_1': 0.019272223114967346, 'loss_2': 0.002109527587890625, 'loss_3': -15.994668960571289, 'loss_4': 2.4035534858703613, 'epoch': 8.8}
{'loss': 0.0214, 'grad_norm': 6.078408241271973, 'learning_rate': 2.122093023255814e-05, 'loss_1': 0.014851194806396961, 'loss_2': 0.006561279296875, 'loss_3': -16.292984008789062, 'loss_4': 2.3018505573272705, 'epoch': 8.8}
{'loss': 0.0175, 'grad_norm': 6.079614162445068, 'learning_rate': 2.121511627906977e-05, 'loss_1': 0.01361950021237135, 'loss_2': 0.003925323486328125, 'loss_3': -16.160911560058594, 'loss_4': 2.2211825847625732, 'epoch': 8.81}
[INFO|trainer.py:4228] 2025-01-21 12:57:55,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:57:55,527 >>   Batch size = 64
 29%|████████████████████████████████████████████████████████████████▌                                                                                                                                                          | 1520/5160 [38:00<1:03:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:02,895 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012099217623472214, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.862, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007854174822568893, 'eval_loss_2': 0.00424504280090332, 'eval_loss_3': -18.194000244140625, 'eval_loss_4': 1.9776052236557007, 'epoch': 8.81}
{'loss': 0.0683, 'grad_norm': 17.7940616607666, 'learning_rate': 2.1209302325581395e-05, 'loss_1': 0.06655824184417725, 'loss_2': 0.00174713134765625, 'loss_3': -16.233423233032227, 'loss_4': 1.8781120777130127, 'epoch': 8.81}
{'loss': 0.016, 'grad_norm': 5.501132488250732, 'learning_rate': 2.1203488372093024e-05, 'loss_1': 0.014037858694791794, 'loss_2': 0.0019893646240234375, 'loss_3': -15.888976097106934, 'loss_4': 1.8869270086288452, 'epoch': 8.82}
{'loss': 0.0167, 'grad_norm': 4.57363224029541, 'learning_rate': 2.119767441860465e-05, 'loss_1': 0.007081122137606144, 'loss_2': 0.0096435546875, 'loss_3': -15.942028045654297, 'loss_4': 1.5253965854644775, 'epoch': 8.83}
{'loss': 0.0181, 'grad_norm': 8.63457202911377, 'learning_rate': 2.119186046511628e-05, 'loss_1': 0.014034638181328773, 'loss_2': 0.004058837890625, 'loss_3': -16.176246643066406, 'loss_4': 2.222654104232788, 'epoch': 8.83}
{'loss': 0.0241, 'grad_norm': 11.627427101135254, 'learning_rate': 2.1186046511627906e-05, 'loss_1': 0.01715659536421299, 'loss_2': 0.006938934326171875, 'loss_3': -15.805415153503418, 'loss_4': 1.6104387044906616, 'epoch': 8.84}
[INFO|trainer.py:4228] 2025-01-21 12:58:02,895 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:02,896 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▋                                                                                                                                                          | 1525/5160 [38:07<1:03:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:10,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015455590561032295, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.778, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00869782455265522, 'eval_loss_2': 0.006757766008377075, 'eval_loss_3': -18.187572479248047, 'eval_loss_4': 1.635741949081421, 'epoch': 8.84}
{'loss': 0.0153, 'grad_norm': 4.933884620666504, 'learning_rate': 2.1180232558139535e-05, 'loss_1': 0.00515588466078043, 'loss_2': 0.0101776123046875, 'loss_3': -16.241912841796875, 'loss_4': 1.8245341777801514, 'epoch': 8.84}
{'loss': 0.0248, 'grad_norm': 12.590831756591797, 'learning_rate': 2.1174418604651164e-05, 'loss_1': 0.018543697893619537, 'loss_2': 0.00627899169921875, 'loss_3': -16.114238739013672, 'loss_4': 1.2636672258377075, 'epoch': 8.85}
{'loss': 0.0834, 'grad_norm': 27.708229064941406, 'learning_rate': 2.1168604651162792e-05, 'loss_1': 0.07719050347805023, 'loss_2': 0.00624847412109375, 'loss_3': -15.94298267364502, 'loss_4': 1.7743843793869019, 'epoch': 8.85}
{'loss': 0.0162, 'grad_norm': 7.925416469573975, 'learning_rate': 2.116279069767442e-05, 'loss_1': 0.015618331730365753, 'loss_2': 0.0005922317504882812, 'loss_3': -16.099687576293945, 'loss_4': 1.512287974357605, 'epoch': 8.86}
{'loss': 0.0152, 'grad_norm': 5.696119785308838, 'learning_rate': 2.1156976744186046e-05, 'loss_1': 0.010788047686219215, 'loss_2': 0.0043792724609375, 'loss_3': -16.231834411621094, 'loss_4': 1.848857045173645, 'epoch': 8.87}
[INFO|trainer.py:4228] 2025-01-21 12:58:10,263 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:10,263 >>   Batch size = 64
 30%|████████████████████████████████████████████████████████████████▉                                                                                                                                                          | 1530/5160 [38:14<1:03:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:17,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013300475664436817, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009020608849823475, 'eval_loss_2': 0.004279866814613342, 'eval_loss_3': -18.185239791870117, 'eval_loss_4': 1.5794346332550049, 'epoch': 8.87}
{'loss': 0.0138, 'grad_norm': 5.143429756164551, 'learning_rate': 2.1151162790697675e-05, 'loss_1': 0.005499220918864012, 'loss_2': 0.008270263671875, 'loss_3': -16.154447555541992, 'loss_4': 1.7410250902175903, 'epoch': 8.87}
{'loss': 0.0151, 'grad_norm': 6.71256160736084, 'learning_rate': 2.1145348837209303e-05, 'loss_1': 0.011830979958176613, 'loss_2': 0.003284454345703125, 'loss_3': -16.02775001525879, 'loss_4': 1.8084311485290527, 'epoch': 8.88}
{'loss': 0.0578, 'grad_norm': 10.497528076171875, 'learning_rate': 2.1139534883720932e-05, 'loss_1': 0.05595112964510918, 'loss_2': 0.0018329620361328125, 'loss_3': -16.302921295166016, 'loss_4': 2.149712085723877, 'epoch': 8.88}
{'loss': 0.0364, 'grad_norm': 11.14778995513916, 'learning_rate': 2.113372093023256e-05, 'loss_1': 0.02198091521859169, 'loss_2': 0.014434814453125, 'loss_3': -16.024566650390625, 'loss_4': 1.6047296524047852, 'epoch': 8.89}
{'loss': 0.0161, 'grad_norm': 4.528158664703369, 'learning_rate': 2.1127906976744186e-05, 'loss_1': 0.0039034197106957436, 'loss_2': 0.01220703125, 'loss_3': -16.154088973999023, 'loss_4': 1.8681156635284424, 'epoch': 8.9}
[INFO|trainer.py:4228] 2025-01-21 12:58:17,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:17,637 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▏                                                                                                                                                         | 1535/5160 [38:22<1:02:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:25,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018146241083741188, 'eval_runtime': 3.8229, 'eval_samples_per_second': 267.858, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.007559978403151035, 'eval_loss_2': 0.010586261749267578, 'eval_loss_3': -18.169170379638672, 'eval_loss_4': 1.617424726486206, 'epoch': 8.9}
{'loss': 0.0153, 'grad_norm': 5.002030372619629, 'learning_rate': 2.1122093023255814e-05, 'loss_1': 0.0049735624343156815, 'loss_2': 0.0103607177734375, 'loss_3': -16.080121994018555, 'loss_4': 1.7015717029571533, 'epoch': 8.9}
{'loss': 0.0197, 'grad_norm': 7.274220943450928, 'learning_rate': 2.111627906976744e-05, 'loss_1': 0.01083698682487011, 'loss_2': 0.00885009765625, 'loss_3': -16.10225486755371, 'loss_4': 1.675534725189209, 'epoch': 8.91}
{'loss': 0.007, 'grad_norm': 5.371051788330078, 'learning_rate': 2.1110465116279072e-05, 'loss_1': 0.005388050805777311, 'loss_2': 0.001567840576171875, 'loss_3': -16.020315170288086, 'loss_4': 1.2581350803375244, 'epoch': 8.91}
{'loss': 0.0182, 'grad_norm': 11.246780395507812, 'learning_rate': 2.11046511627907e-05, 'loss_1': 0.015776127576828003, 'loss_2': 0.002460479736328125, 'loss_3': -16.21426010131836, 'loss_4': 1.6564478874206543, 'epoch': 8.92}
{'loss': 0.0144, 'grad_norm': 6.517955780029297, 'learning_rate': 2.1098837209302326e-05, 'loss_1': 0.0089814318343997, 'loss_2': 0.00545501708984375, 'loss_3': -16.092044830322266, 'loss_4': 1.6975454092025757, 'epoch': 8.92}
[INFO|trainer.py:4228] 2025-01-21 12:58:25,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:25,018 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▎                                                                                                                                                         | 1540/5160 [38:29<1:02:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:32,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009829297661781311, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.627, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0067113786935806274, 'eval_loss_2': 0.0031179189682006836, 'eval_loss_3': -18.166709899902344, 'eval_loss_4': 1.5585154294967651, 'epoch': 8.92}
{'loss': 0.059, 'grad_norm': 26.062755584716797, 'learning_rate': 2.1093023255813954e-05, 'loss_1': 0.05009407177567482, 'loss_2': 0.008880615234375, 'loss_3': -16.30392837524414, 'loss_4': 1.8293864727020264, 'epoch': 8.93}
{'loss': 0.0602, 'grad_norm': 20.87775993347168, 'learning_rate': 2.108720930232558e-05, 'loss_1': 0.05342274159193039, 'loss_2': 0.006786346435546875, 'loss_3': -16.307939529418945, 'loss_4': 2.439803123474121, 'epoch': 8.94}
{'loss': 0.0089, 'grad_norm': 5.401026725769043, 'learning_rate': 2.108139534883721e-05, 'loss_1': 0.008314468897879124, 'loss_2': 0.0005464553833007812, 'loss_3': -16.234752655029297, 'loss_4': 1.6198432445526123, 'epoch': 8.94}
{'loss': 0.0112, 'grad_norm': 5.825778007507324, 'learning_rate': 2.107558139534884e-05, 'loss_1': 0.010377028957009315, 'loss_2': 0.0007762908935546875, 'loss_3': -16.04555892944336, 'loss_4': 1.5284452438354492, 'epoch': 8.95}
{'loss': 0.051, 'grad_norm': 9.336742401123047, 'learning_rate': 2.1069767441860465e-05, 'loss_1': 0.05023866519331932, 'loss_2': 0.000759124755859375, 'loss_3': -16.371078491210938, 'loss_4': 2.0280425548553467, 'epoch': 8.95}
[INFO|trainer.py:4228] 2025-01-21 12:58:32,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:32,393 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▌                                                                                                                                                         | 1545/5160 [38:36<1:02:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:58:39,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011419393122196198, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.41, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.004643239546567202, 'eval_loss_2': 0.006776154041290283, 'eval_loss_3': -18.199596405029297, 'eval_loss_4': 1.703871488571167, 'epoch': 8.95}
{'loss': 0.0165, 'grad_norm': 7.987024307250977, 'learning_rate': 2.1063953488372094e-05, 'loss_1': 0.011583356186747551, 'loss_2': 0.00492095947265625, 'loss_3': -16.103586196899414, 'loss_4': 1.8178715705871582, 'epoch': 8.96}
{'loss': 0.0639, 'grad_norm': 18.931734085083008, 'learning_rate': 2.105813953488372e-05, 'loss_1': 0.05320262908935547, 'loss_2': 0.010711669921875, 'loss_3': -15.987140655517578, 'loss_4': 1.7327967882156372, 'epoch': 8.97}
{'loss': 0.0135, 'grad_norm': 5.027601718902588, 'learning_rate': 2.105232558139535e-05, 'loss_1': 0.00472923181951046, 'loss_2': 0.00876617431640625, 'loss_3': -16.14487648010254, 'loss_4': 1.5236153602600098, 'epoch': 8.97}
{'loss': 0.0233, 'grad_norm': 10.070555686950684, 'learning_rate': 2.1046511627906977e-05, 'loss_1': 0.015918351709842682, 'loss_2': 0.007415771484375, 'loss_3': -16.248092651367188, 'loss_4': 1.5520858764648438, 'epoch': 8.98}
{'loss': 0.012, 'grad_norm': 5.364232063293457, 'learning_rate': 2.1040697674418605e-05, 'loss_1': 0.005133325234055519, 'loss_2': 0.006824493408203125, 'loss_3': -16.132986068725586, 'loss_4': 1.4783296585083008, 'epoch': 8.98}
[INFO|trainer.py:4228] 2025-01-21 12:58:39,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:39,768 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▊                                                                                                                                                         | 1550/5160 [38:43<1:00:07,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 12:58:46,833 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010048727504909039, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.216, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.00488809822127223, 'eval_loss_2': 0.005160629749298096, 'eval_loss_3': -18.217750549316406, 'eval_loss_4': 1.6351076364517212, 'epoch': 8.98}
{'loss': 0.0066, 'grad_norm': 4.99137020111084, 'learning_rate': 2.1034883720930234e-05, 'loss_1': 0.004487762227654457, 'loss_2': 0.00213623046875, 'loss_3': -16.089075088500977, 'loss_4': 1.5797312259674072, 'epoch': 8.99}
{'loss': 0.0064, 'grad_norm': 6.179739952087402, 'learning_rate': 2.102906976744186e-05, 'loss_1': 0.006323270499706268, 'loss_2': 5.5670738220214844e-05, 'loss_3': -16.101709365844727, 'loss_4': 1.345308542251587, 'epoch': 8.99}
{'loss': 0.0016, 'grad_norm': 5.7947001457214355, 'learning_rate': 2.102325581395349e-05, 'loss_1': 0.0010049615520983934, 'loss_2': 0.0005731582641601562, 'loss_3': -16.20281982421875, 'loss_4': 0.7583376169204712, 'epoch': 9.0}
{'loss': 0.0155, 'grad_norm': 9.447051048278809, 'learning_rate': 2.1017441860465116e-05, 'loss_1': 0.012081829831004143, 'loss_2': 0.0034332275390625, 'loss_3': -16.216217041015625, 'loss_4': 1.3012478351593018, 'epoch': 9.01}
{'loss': 0.0169, 'grad_norm': 5.9780659675598145, 'learning_rate': 2.1011627906976745e-05, 'loss_1': 0.009860704652965069, 'loss_2': 0.00708770751953125, 'loss_3': -16.32965850830078, 'loss_4': 1.6554135084152222, 'epoch': 9.01}
[INFO|trainer.py:4228] 2025-01-21 12:58:46,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:46,834 >>   Batch size = 64
 30%|█████████████████████████████████████████████████████████████████▊                                                                                                                                                         | 1550/5160 [38:47<1:00:07,  1.00it/s][INFO|trainer.py:3910] 2025-01-21 12:58:50,649 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1550
[INFO|configuration_utils.py:420] 2025-01-21 12:58:50,651 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1550/config.json                                                                            
{'eval_loss': 0.008375490084290504, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.435, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.004729287698864937, 'eval_loss_2': 0.0036462023854255676, 'eval_loss_3': -18.21126937866211, 'eval_loss_4': 1.5758178234100342, 'epoch': 9.01}
[INFO|modeling_utils.py:2988] 2025-01-21 12:58:51,133 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1550/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 12:58:51,134 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1550/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 12:58:51,135 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1550/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 12:58:52,088 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1490] due to args.save_total_limit
 30%|█████████████████████████████████████████████████████████████████▉                                                                                                                                                         | 1555/5160 [38:52<1:08:48,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 12:58:55,745 >>
{'loss': 0.012, 'grad_norm': 6.873034477233887, 'learning_rate': 2.1005813953488374e-05, 'loss_1': 0.011496804654598236, 'loss_2': 0.0005030632019042969, 'loss_3': -16.013107299804688, 'loss_4': 1.3561532497406006, 'epoch': 9.02}
{'loss': 0.0106, 'grad_norm': 4.958120822906494, 'learning_rate': 2.1e-05, 'loss_1': 0.008010263554751873, 'loss_2': 0.0025615692138671875, 'loss_3': -16.309825897216797, 'loss_4': 1.3863611221313477, 'epoch': 9.02}
{'loss': 0.0086, 'grad_norm': 5.744731903076172, 'learning_rate': 2.099418604651163e-05, 'loss_1': 0.0062894863076508045, 'loss_2': 0.00235748291015625, 'loss_3': -16.183349609375, 'loss_4': 1.6229393482208252, 'epoch': 9.03}
{'loss': 0.0138, 'grad_norm': 7.262004852294922, 'learning_rate': 2.0988372093023256e-05, 'loss_1': 0.013606217689812183, 'loss_2': 0.0001900196075439453, 'loss_3': -16.13391876220703, 'loss_4': 1.5990307331085205, 'epoch': 9.03}
{'loss': 0.0709, 'grad_norm': 12.088769912719727, 'learning_rate': 2.0982558139534885e-05, 'loss_1': 0.06834730505943298, 'loss_2': 0.002536773681640625, 'loss_3': -16.208110809326172, 'loss_4': 1.9565434455871582, 'epoch': 9.04}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 12:58:55,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:58:55,745 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▏                                                                                                                                                        | 1560/5160 [39:00<1:03:40,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 12:59:03,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009438740089535713, 'eval_runtime': 3.8244, 'eval_samples_per_second': 267.752, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.004691311623901129, 'eval_loss_2': 0.004747427999973297, 'eval_loss_3': -18.219398498535156, 'eval_loss_4': 1.440453290939331, 'epoch': 9.04}
{'loss': 0.0183, 'grad_norm': 9.490958213806152, 'learning_rate': 2.097674418604651e-05, 'loss_1': 0.013613303191959858, 'loss_2': 0.0046844482421875, 'loss_3': -16.225929260253906, 'loss_4': 1.4129774570465088, 'epoch': 9.05}
{'loss': 0.017, 'grad_norm': 5.688610076904297, 'learning_rate': 2.097093023255814e-05, 'loss_1': 0.009250613860785961, 'loss_2': 0.00775146484375, 'loss_3': -16.280906677246094, 'loss_4': 1.4074277877807617, 'epoch': 9.05}
{'loss': 0.0091, 'grad_norm': 5.088902473449707, 'learning_rate': 2.096511627906977e-05, 'loss_1': 0.005466381087899208, 'loss_2': 0.00360870361328125, 'loss_3': -16.056114196777344, 'loss_4': 1.479198694229126, 'epoch': 9.06}
{'loss': 0.0126, 'grad_norm': 5.969407558441162, 'learning_rate': 2.0959302325581396e-05, 'loss_1': 0.007073972839862108, 'loss_2': 0.005481719970703125, 'loss_3': -16.15878677368164, 'loss_4': 1.5299103260040283, 'epoch': 9.06}
{'loss': 0.0191, 'grad_norm': 5.039216041564941, 'learning_rate': 2.0953488372093025e-05, 'loss_1': 0.004107646644115448, 'loss_2': 0.01496124267578125, 'loss_3': -16.355751037597656, 'loss_4': 1.26022207736969, 'epoch': 9.07}
[INFO|trainer.py:4228] 2025-01-21 12:59:03,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:03,136 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▍                                                                                                                                                        | 1565/5160 [39:07<1:02:37,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 12:59:10,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011464711278676987, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.55, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0057480596005916595, 'eval_loss_2': 0.005716651678085327, 'eval_loss_3': -18.246397018432617, 'eval_loss_4': 1.2426525354385376, 'epoch': 9.07}
{'loss': 0.0218, 'grad_norm': 13.329008102416992, 'learning_rate': 2.094767441860465e-05, 'loss_1': 0.01815216802060604, 'loss_2': 0.003692626953125, 'loss_3': -16.368366241455078, 'loss_4': 0.7609995603561401, 'epoch': 9.08}
{'loss': 0.0197, 'grad_norm': 6.092755317687988, 'learning_rate': 2.094186046511628e-05, 'loss_1': 0.016778351739048958, 'loss_2': 0.002872467041015625, 'loss_3': -16.26643943786621, 'loss_4': 1.1092729568481445, 'epoch': 9.08}
{'loss': 0.016, 'grad_norm': 7.470716953277588, 'learning_rate': 2.093604651162791e-05, 'loss_1': 0.015664154663681984, 'loss_2': 0.0003094673156738281, 'loss_3': -16.314544677734375, 'loss_4': 0.9892851710319519, 'epoch': 9.09}
{'loss': 0.0114, 'grad_norm': 4.283162593841553, 'learning_rate': 2.0930232558139536e-05, 'loss_1': 0.007658843416720629, 'loss_2': 0.003726959228515625, 'loss_3': -16.353208541870117, 'loss_4': 1.067352294921875, 'epoch': 9.09}
{'loss': 0.0101, 'grad_norm': 4.791934967041016, 'learning_rate': 2.0924418604651164e-05, 'loss_1': 0.00683020381256938, 'loss_2': 0.00325775146484375, 'loss_3': -16.366493225097656, 'loss_4': 1.4136042594909668, 'epoch': 9.1}
[INFO|trainer.py:4228] 2025-01-21 12:59:10,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:10,508 >>   Batch size = 64
 30%|██████████████████████████████████████████████████████████████████▋                                                                                                                                                        | 1570/5160 [39:15<1:02:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:17,881 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014822406694293022, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.822, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009195951744914055, 'eval_loss_2': 0.005626454949378967, 'eval_loss_3': -18.260517120361328, 'eval_loss_4': 1.2371143102645874, 'epoch': 9.1}
{'loss': 0.0324, 'grad_norm': 8.194141387939453, 'learning_rate': 2.091860465116279e-05, 'loss_1': 0.023036306723952293, 'loss_2': 0.0093841552734375, 'loss_3': -16.16514015197754, 'loss_4': 1.0313767194747925, 'epoch': 9.1}
{'loss': 0.0464, 'grad_norm': 17.38714599609375, 'learning_rate': 2.0912790697674418e-05, 'loss_1': 0.03862012177705765, 'loss_2': 0.0078125, 'loss_3': -16.55801010131836, 'loss_4': 1.0179753303527832, 'epoch': 9.11}
{'loss': 0.011, 'grad_norm': 7.016225814819336, 'learning_rate': 2.0906976744186047e-05, 'loss_1': 0.009128781966865063, 'loss_2': 0.00189971923828125, 'loss_3': -16.505489349365234, 'loss_4': 1.6763911247253418, 'epoch': 9.12}
{'loss': 0.0178, 'grad_norm': 5.471200942993164, 'learning_rate': 2.0901162790697675e-05, 'loss_1': 0.007921210490167141, 'loss_2': 0.00983428955078125, 'loss_3': -16.32798194885254, 'loss_4': 1.8786771297454834, 'epoch': 9.12}
{'loss': 0.0234, 'grad_norm': 6.427019119262695, 'learning_rate': 2.0895348837209304e-05, 'loss_1': 0.015513278543949127, 'loss_2': 0.00787353515625, 'loss_3': -16.194765090942383, 'loss_4': 1.307342767715454, 'epoch': 9.13}
[INFO|trainer.py:4228] 2025-01-21 12:59:17,881 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:17,881 >>   Batch size = 64
 31%|██████████████████████████████████████████████████████████████████▊                                                                                                                                                        | 1575/5160 [39:22<1:02:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:25,255 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011565973050892353, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.538, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008001795038580894, 'eval_loss_2': 0.003564178943634033, 'eval_loss_3': -18.29485321044922, 'eval_loss_4': 1.4440250396728516, 'epoch': 9.13}
{'loss': 0.0305, 'grad_norm': 11.974961280822754, 'learning_rate': 2.088953488372093e-05, 'loss_1': 0.028982656076550484, 'loss_2': 0.001491546630859375, 'loss_3': -16.372159957885742, 'loss_4': 1.024262547492981, 'epoch': 9.13}
{'loss': 0.0222, 'grad_norm': 6.817082405090332, 'learning_rate': 2.0883720930232558e-05, 'loss_1': 0.01869947649538517, 'loss_2': 0.0034942626953125, 'loss_3': -16.031248092651367, 'loss_4': 1.5091443061828613, 'epoch': 9.14}
{'loss': 0.031, 'grad_norm': 10.757575988769531, 'learning_rate': 2.0877906976744187e-05, 'loss_1': 0.029524462297558784, 'loss_2': 0.001445770263671875, 'loss_3': -16.318279266357422, 'loss_4': 1.7998026609420776, 'epoch': 9.15}
{'loss': 0.019, 'grad_norm': 6.85774040222168, 'learning_rate': 2.0872093023255815e-05, 'loss_1': 0.017790857702493668, 'loss_2': 0.0011968612670898438, 'loss_3': -16.279691696166992, 'loss_4': 1.5004574060440063, 'epoch': 9.15}
{'loss': 0.0371, 'grad_norm': 10.476818084716797, 'learning_rate': 2.0866279069767444e-05, 'loss_1': 0.03520730882883072, 'loss_2': 0.0018939971923828125, 'loss_3': -16.407636642456055, 'loss_4': 1.7126526832580566, 'epoch': 9.16}
[INFO|trainer.py:4228] 2025-01-21 12:59:25,255 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:25,255 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████                                                                                                                                                        | 1580/5160 [39:29<1:02:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:32,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01261198241263628, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.532, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008884456939995289, 'eval_loss_2': 0.003727525472640991, 'eval_loss_3': -18.311935424804688, 'eval_loss_4': 1.8259103298187256, 'epoch': 9.16}
{'loss': 0.0264, 'grad_norm': 8.75417709350586, 'learning_rate': 2.086046511627907e-05, 'loss_1': 0.02301366999745369, 'loss_2': 0.003368377685546875, 'loss_3': -16.414382934570312, 'loss_4': 1.778445839881897, 'epoch': 9.16}
{'loss': 0.0362, 'grad_norm': 8.758515357971191, 'learning_rate': 2.0854651162790698e-05, 'loss_1': 0.03351055085659027, 'loss_2': 0.002658843994140625, 'loss_3': -16.21176528930664, 'loss_4': 2.223982334136963, 'epoch': 9.17}
{'loss': 0.0143, 'grad_norm': 5.6477460861206055, 'learning_rate': 2.0848837209302326e-05, 'loss_1': 0.011202219873666763, 'loss_2': 0.003093719482421875, 'loss_3': -16.38616180419922, 'loss_4': 1.83217453956604, 'epoch': 9.17}
{'loss': 0.024, 'grad_norm': 5.988999366760254, 'learning_rate': 2.0843023255813955e-05, 'loss_1': 0.01500194426625967, 'loss_2': 0.009002685546875, 'loss_3': -16.326168060302734, 'loss_4': 2.1502227783203125, 'epoch': 9.18}
{'loss': 0.085, 'grad_norm': 19.07054901123047, 'learning_rate': 2.083720930232558e-05, 'loss_1': 0.08379362523555756, 'loss_2': 0.001178741455078125, 'loss_3': -16.35944938659668, 'loss_4': 2.1106882095336914, 'epoch': 9.19}
[INFO|trainer.py:4228] 2025-01-21 12:59:32,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:32,631 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▎                                                                                                                                                       | 1585/5160 [39:37<1:02:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:39,997 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00970040075480938, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.573, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007847463712096214, 'eval_loss_2': 0.0018529370427131653, 'eval_loss_3': -18.296247482299805, 'eval_loss_4': 1.9264285564422607, 'epoch': 9.19}
{'loss': 0.0389, 'grad_norm': 10.818013191223145, 'learning_rate': 2.083139534883721e-05, 'loss_1': 0.03287751227617264, 'loss_2': 0.00606536865234375, 'loss_3': -16.205158233642578, 'loss_4': 1.6636162996292114, 'epoch': 9.19}
{'loss': 0.0275, 'grad_norm': 10.606422424316406, 'learning_rate': 2.0825581395348837e-05, 'loss_1': 0.025951731950044632, 'loss_2': 0.0015201568603515625, 'loss_3': -16.175304412841797, 'loss_4': 1.6420254707336426, 'epoch': 9.2}
{'loss': 0.0166, 'grad_norm': 6.036485195159912, 'learning_rate': 2.0819767441860466e-05, 'loss_1': 0.014651898294687271, 'loss_2': 0.0019378662109375, 'loss_3': -16.202157974243164, 'loss_4': 2.175910711288452, 'epoch': 9.2}
{'loss': 0.0179, 'grad_norm': 6.895373344421387, 'learning_rate': 2.0813953488372095e-05, 'loss_1': 0.017840979620814323, 'loss_2': 6.812810897827148e-05, 'loss_3': -16.263492584228516, 'loss_4': 2.0179290771484375, 'epoch': 9.21}
{'loss': 0.0211, 'grad_norm': 10.812503814697266, 'learning_rate': 2.080813953488372e-05, 'loss_1': 0.019166499376296997, 'loss_2': 0.001922607421875, 'loss_3': -16.295536041259766, 'loss_4': 1.6634521484375, 'epoch': 9.22}
[INFO|trainer.py:4228] 2025-01-21 12:59:39,997 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:39,997 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▍                                                                                                                                                       | 1590/5160 [39:44<1:01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:47,372 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009147431701421738, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.45, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.006628807634115219, 'eval_loss_2': 0.0025186240673065186, 'eval_loss_3': -18.273529052734375, 'eval_loss_4': 1.7659717798233032, 'epoch': 9.22}
{'loss': 0.0189, 'grad_norm': 8.018836975097656, 'learning_rate': 2.080232558139535e-05, 'loss_1': 0.013427850790321827, 'loss_2': 0.005504608154296875, 'loss_3': -16.413562774658203, 'loss_4': 2.316211700439453, 'epoch': 9.22}
{'loss': 0.0259, 'grad_norm': 9.672714233398438, 'learning_rate': 2.0796511627906977e-05, 'loss_1': 0.019923655316233635, 'loss_2': 0.005992889404296875, 'loss_3': -16.243061065673828, 'loss_4': 1.378400444984436, 'epoch': 9.23}
{'loss': 0.0262, 'grad_norm': 6.7310662269592285, 'learning_rate': 2.0790697674418606e-05, 'loss_1': 0.01800788938999176, 'loss_2': 0.008209228515625, 'loss_3': -16.264612197875977, 'loss_4': 1.8502392768859863, 'epoch': 9.23}
{'loss': 0.0165, 'grad_norm': 6.498538494110107, 'learning_rate': 2.0784883720930235e-05, 'loss_1': 0.012731557711958885, 'loss_2': 0.0037441253662109375, 'loss_3': -16.284387588500977, 'loss_4': 1.4259657859802246, 'epoch': 9.24}
{'loss': 0.0117, 'grad_norm': 5.990331649780273, 'learning_rate': 2.077906976744186e-05, 'loss_1': 0.008923678658902645, 'loss_2': 0.00279998779296875, 'loss_3': -16.320180892944336, 'loss_4': 1.4761240482330322, 'epoch': 9.24}
[INFO|trainer.py:4228] 2025-01-21 12:59:47,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:47,373 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▋                                                                                                                                                       | 1595/5160 [39:51<1:01:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 12:59:54,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01072738878428936, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.89, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00669567845761776, 'eval_loss_2': 0.0040317103266716, 'eval_loss_3': -18.235570907592773, 'eval_loss_4': 1.4160151481628418, 'epoch': 9.24}
{'loss': 0.0311, 'grad_norm': 10.191512107849121, 'learning_rate': 2.077325581395349e-05, 'loss_1': 0.02948235347867012, 'loss_2': 0.001644134521484375, 'loss_3': -16.29530906677246, 'loss_4': 1.4012458324432373, 'epoch': 9.25}
{'loss': 0.0391, 'grad_norm': 11.815320014953613, 'learning_rate': 2.0767441860465117e-05, 'loss_1': 0.028475787490606308, 'loss_2': 0.01062774658203125, 'loss_3': -16.35611343383789, 'loss_4': 1.5302543640136719, 'epoch': 9.26}
{'loss': 0.0133, 'grad_norm': 5.087551593780518, 'learning_rate': 2.0761627906976746e-05, 'loss_1': 0.009753274731338024, 'loss_2': 0.003528594970703125, 'loss_3': -16.442026138305664, 'loss_4': 1.4099886417388916, 'epoch': 9.26}
{'loss': 0.0185, 'grad_norm': 6.174467086791992, 'learning_rate': 2.0755813953488374e-05, 'loss_1': 0.011735163629055023, 'loss_2': 0.006748199462890625, 'loss_3': -16.289691925048828, 'loss_4': 1.3929898738861084, 'epoch': 9.27}
{'loss': 0.0104, 'grad_norm': 5.029368877410889, 'learning_rate': 2.075e-05, 'loss_1': 0.006334904581308365, 'loss_2': 0.004055023193359375, 'loss_3': -16.454458236694336, 'loss_4': 0.8835045099258423, 'epoch': 9.27}
[INFO|trainer.py:4228] 2025-01-21 12:59:54,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 12:59:54,748 >>   Batch size = 64
 31%|███████████████████████████████████████████████████████████████████▉                                                                                                                                                       | 1600/5160 [39:59<1:01:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:02,126 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009194033220410347, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.387, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006030396092683077, 'eval_loss_2': 0.003163635730743408, 'eval_loss_3': -18.2067813873291, 'eval_loss_4': 1.0429868698120117, 'epoch': 9.27}
{'loss': 0.0397, 'grad_norm': 15.550986289978027, 'learning_rate': 2.0744186046511628e-05, 'loss_1': 0.030253810808062553, 'loss_2': 0.0093994140625, 'loss_3': -16.320785522460938, 'loss_4': 0.858914852142334, 'epoch': 9.28}
{'loss': 0.0377, 'grad_norm': 13.791961669921875, 'learning_rate': 2.0738372093023257e-05, 'loss_1': 0.030100218951702118, 'loss_2': 0.00756072998046875, 'loss_3': -16.360776901245117, 'loss_4': 0.7172942161560059, 'epoch': 9.28}
{'loss': 0.0243, 'grad_norm': 6.730046272277832, 'learning_rate': 2.0732558139534885e-05, 'loss_1': 0.01359033677726984, 'loss_2': 0.01074981689453125, 'loss_3': -16.072715759277344, 'loss_4': 0.9548535943031311, 'epoch': 9.29}
{'loss': 0.0234, 'grad_norm': 9.576693534851074, 'learning_rate': 2.072674418604651e-05, 'loss_1': 0.019217481836676598, 'loss_2': 0.00417327880859375, 'loss_3': -16.38954734802246, 'loss_4': 1.1181919574737549, 'epoch': 9.3}
{'loss': 0.0118, 'grad_norm': 5.571520805358887, 'learning_rate': 2.072093023255814e-05, 'loss_1': 0.006946275010704994, 'loss_2': 0.0048675537109375, 'loss_3': -16.42081069946289, 'loss_4': 0.9692688584327698, 'epoch': 9.3}
[INFO|trainer.py:4228] 2025-01-21 13:00:02,126 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:02,126 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████                                                                                                                                                       | 1605/5160 [40:06<1:01:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:09,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009462782181799412, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.803, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006215215660631657, 'eval_loss_2': 0.003247566521167755, 'eval_loss_3': -18.225418090820312, 'eval_loss_4': 0.9988492727279663, 'epoch': 9.3}
{'loss': 0.0248, 'grad_norm': 7.748085975646973, 'learning_rate': 2.0715116279069768e-05, 'loss_1': 0.02364565245807171, 'loss_2': 0.00110626220703125, 'loss_3': -16.497406005859375, 'loss_4': 0.7862837314605713, 'epoch': 9.31}
{'loss': 0.0216, 'grad_norm': 10.261582374572754, 'learning_rate': 2.0709302325581397e-05, 'loss_1': 0.01696208491921425, 'loss_2': 0.00463104248046875, 'loss_3': -16.519805908203125, 'loss_4': 0.9493560791015625, 'epoch': 9.31}
{'loss': 0.0153, 'grad_norm': 6.64510440826416, 'learning_rate': 2.0703488372093025e-05, 'loss_1': 0.015021227300167084, 'loss_2': 0.00029587745666503906, 'loss_3': -16.335983276367188, 'loss_4': 0.8207259178161621, 'epoch': 9.32}
{'loss': 0.0163, 'grad_norm': 5.668426990509033, 'learning_rate': 2.069767441860465e-05, 'loss_1': 0.012095865793526173, 'loss_2': 0.004199981689453125, 'loss_3': -16.723438262939453, 'loss_4': 1.823188304901123, 'epoch': 9.33}
{'loss': 0.0117, 'grad_norm': 5.733211517333984, 'learning_rate': 2.069186046511628e-05, 'loss_1': 0.010030918754637241, 'loss_2': 0.0016918182373046875, 'loss_3': -16.450908660888672, 'loss_4': 0.9591220021247864, 'epoch': 9.33}
[INFO|trainer.py:4228] 2025-01-21 13:00:09,496 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:09,496 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▎                                                                                                                                                      | 1610/5160 [40:14<1:01:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:16,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010833740234375, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.333, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.00760318199172616, 'eval_loss_2': 0.003230556845664978, 'eval_loss_3': -18.216121673583984, 'eval_loss_4': 1.0464591979980469, 'epoch': 9.33}
{'loss': 0.0331, 'grad_norm': 15.770773887634277, 'learning_rate': 2.0686046511627908e-05, 'loss_1': 0.027690822258591652, 'loss_2': 0.005443572998046875, 'loss_3': -16.278118133544922, 'loss_4': 0.9890687465667725, 'epoch': 9.34}
{'loss': 0.0311, 'grad_norm': 9.312731742858887, 'learning_rate': 2.0680232558139536e-05, 'loss_1': 0.025812849402427673, 'loss_2': 0.0052947998046875, 'loss_3': -16.295923233032227, 'loss_4': 1.2765851020812988, 'epoch': 9.34}
{'loss': 0.0217, 'grad_norm': 8.060851097106934, 'learning_rate': 2.0674418604651165e-05, 'loss_1': 0.020641973242163658, 'loss_2': 0.0011043548583984375, 'loss_3': -16.467811584472656, 'loss_4': 0.6992173790931702, 'epoch': 9.35}
{'loss': 0.0457, 'grad_norm': 12.443621635437012, 'learning_rate': 2.066860465116279e-05, 'loss_1': 0.03969959914684296, 'loss_2': 0.006011962890625, 'loss_3': -16.412294387817383, 'loss_4': 0.8226866722106934, 'epoch': 9.35}
{'loss': 0.0124, 'grad_norm': 5.334690093994141, 'learning_rate': 2.066279069767442e-05, 'loss_1': 0.006187522318214178, 'loss_2': 0.0062408447265625, 'loss_3': -16.517433166503906, 'loss_4': 0.9197701215744019, 'epoch': 9.36}
[INFO|trainer.py:4228] 2025-01-21 13:00:16,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:16,856 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▌                                                                                                                                                      | 1615/5160 [40:21<1:01:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:24,219 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012685738503932953, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.7, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008668892085552216, 'eval_loss_2': 0.004016846418380737, 'eval_loss_3': -18.22571563720703, 'eval_loss_4': 1.07248055934906, 'epoch': 9.36}
{'loss': 0.0127, 'grad_norm': 5.705688953399658, 'learning_rate': 2.0656976744186044e-05, 'loss_1': 0.010219746269285679, 'loss_2': 0.0024814605712890625, 'loss_3': -16.32318115234375, 'loss_4': 1.0284032821655273, 'epoch': 9.37}
{'loss': 0.0115, 'grad_norm': 5.527316093444824, 'learning_rate': 2.0651162790697676e-05, 'loss_1': 0.009833328425884247, 'loss_2': 0.0016956329345703125, 'loss_3': -16.537647247314453, 'loss_4': 1.188320517539978, 'epoch': 9.37}
{'loss': 0.0169, 'grad_norm': 6.914963245391846, 'learning_rate': 2.0645348837209305e-05, 'loss_1': 0.012270809151232243, 'loss_2': 0.004657745361328125, 'loss_3': -16.72495460510254, 'loss_4': 0.9716504812240601, 'epoch': 9.38}
{'loss': 0.0142, 'grad_norm': 5.610936641693115, 'learning_rate': 2.063953488372093e-05, 'loss_1': 0.011259843595325947, 'loss_2': 0.00293731689453125, 'loss_3': -16.397411346435547, 'loss_4': 1.169024109840393, 'epoch': 9.38}
{'loss': 0.0107, 'grad_norm': 5.73745584487915, 'learning_rate': 2.063372093023256e-05, 'loss_1': 0.008646546863019466, 'loss_2': 0.0020923614501953125, 'loss_3': -16.502511978149414, 'loss_4': 1.4223650693893433, 'epoch': 9.39}
[INFO|trainer.py:4228] 2025-01-21 13:00:24,220 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:24,220 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▊                                                                                                                                                      | 1620/5160 [40:28<1:01:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:31,599 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013738533481955528, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.401, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009411107748746872, 'eval_loss_2': 0.004327423870563507, 'eval_loss_3': -18.243263244628906, 'eval_loss_4': 1.2168751955032349, 'epoch': 9.39}
{'loss': 0.0271, 'grad_norm': 10.250170707702637, 'learning_rate': 2.0627906976744184e-05, 'loss_1': 0.02343498356640339, 'loss_2': 0.003711700439453125, 'loss_3': -16.30557632446289, 'loss_4': 1.0739847421646118, 'epoch': 9.4}
{'loss': 0.0136, 'grad_norm': 7.037008285522461, 'learning_rate': 2.0622093023255816e-05, 'loss_1': 0.01360156387090683, 'loss_2': 4.792213439941406e-05, 'loss_3': -16.473299026489258, 'loss_4': 1.0868198871612549, 'epoch': 9.4}
{'loss': 0.0177, 'grad_norm': 6.2312703132629395, 'learning_rate': 2.0616279069767445e-05, 'loss_1': 0.008989350870251656, 'loss_2': 0.00875091552734375, 'loss_3': -16.504535675048828, 'loss_4': 1.8846399784088135, 'epoch': 9.41}
{'loss': 0.0177, 'grad_norm': 9.918503761291504, 'learning_rate': 2.061046511627907e-05, 'loss_1': 0.014882533811032772, 'loss_2': 0.0028533935546875, 'loss_3': -16.459896087646484, 'loss_4': 1.2961522340774536, 'epoch': 9.41}
{'loss': 0.0202, 'grad_norm': 8.593342781066895, 'learning_rate': 2.06046511627907e-05, 'loss_1': 0.018217841163277626, 'loss_2': 0.0019435882568359375, 'loss_3': -16.392074584960938, 'loss_4': 1.6923736333847046, 'epoch': 9.42}
[INFO|trainer.py:4228] 2025-01-21 13:00:31,599 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:31,599 >>   Batch size = 64
 31%|████████████████████████████████████████████████████████████████████▉                                                                                                                                                      | 1625/5160 [40:36<1:01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:38,971 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01529320515692234, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00978284515440464, 'eval_loss_2': 0.0055103600025177, 'eval_loss_3': -18.251707077026367, 'eval_loss_4': 1.6634795665740967, 'epoch': 9.42}
{'loss': 0.0323, 'grad_norm': 13.600167274475098, 'learning_rate': 2.0598837209302324e-05, 'loss_1': 0.024218855425715446, 'loss_2': 0.00811004638671875, 'loss_3': -16.448810577392578, 'loss_4': 1.3293863534927368, 'epoch': 9.42}
{'loss': 0.0131, 'grad_norm': 4.865777015686035, 'learning_rate': 2.0593023255813956e-05, 'loss_1': 0.007164407521486282, 'loss_2': 0.005950927734375, 'loss_3': -16.593017578125, 'loss_4': 1.853827953338623, 'epoch': 9.43}
{'loss': 0.013, 'grad_norm': 5.866272449493408, 'learning_rate': 2.058720930232558e-05, 'loss_1': 0.007909750565886497, 'loss_2': 0.005054473876953125, 'loss_3': -16.44271469116211, 'loss_4': 1.5882458686828613, 'epoch': 9.44}
{'loss': 0.0153, 'grad_norm': 5.3009138107299805, 'learning_rate': 2.058139534883721e-05, 'loss_1': 0.005965773481875658, 'loss_2': 0.00928497314453125, 'loss_3': -16.297344207763672, 'loss_4': 1.8452675342559814, 'epoch': 9.44}
{'loss': 0.0217, 'grad_norm': 5.211969375610352, 'learning_rate': 2.0575581395348838e-05, 'loss_1': 0.007233615033328533, 'loss_2': 0.01442718505859375, 'loss_3': -16.61611557006836, 'loss_4': 1.7007025480270386, 'epoch': 9.45}
[INFO|trainer.py:4228] 2025-01-21 13:00:38,972 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:38,972 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▏                                                                                                                                                     | 1630/5160 [40:43<1:01:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:46,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012761794961988926, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.686, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00840922724455595, 'eval_loss_2': 0.004352569580078125, 'eval_loss_3': -18.248353958129883, 'eval_loss_4': 1.6913552284240723, 'epoch': 9.45}
{'loss': 0.016, 'grad_norm': 4.8009538650512695, 'learning_rate': 2.0569767441860463e-05, 'loss_1': 0.009569368325173855, 'loss_2': 0.00643157958984375, 'loss_3': -16.355573654174805, 'loss_4': 1.5010658502578735, 'epoch': 9.45}
{'loss': 0.0215, 'grad_norm': 7.695774078369141, 'learning_rate': 2.0563953488372095e-05, 'loss_1': 0.015557128004729748, 'loss_2': 0.005985260009765625, 'loss_3': -16.312938690185547, 'loss_4': 1.4131138324737549, 'epoch': 9.46}
{'loss': 0.0472, 'grad_norm': 14.16894817352295, 'learning_rate': 2.055813953488372e-05, 'loss_1': 0.04692550748586655, 'loss_2': 0.0002810955047607422, 'loss_3': -16.20138931274414, 'loss_4': 1.6770472526550293, 'epoch': 9.47}
{'loss': 0.0116, 'grad_norm': 6.553319931030273, 'learning_rate': 2.055232558139535e-05, 'loss_1': 0.01094945427030325, 'loss_2': 0.0006761550903320312, 'loss_3': -16.45374298095703, 'loss_4': 1.4142882823944092, 'epoch': 9.47}
{'loss': 0.0191, 'grad_norm': 5.092061519622803, 'learning_rate': 2.0546511627906978e-05, 'loss_1': 0.008333204314112663, 'loss_2': 0.0107879638671875, 'loss_3': -16.295148849487305, 'loss_4': 1.3860831260681152, 'epoch': 9.48}
[INFO|trainer.py:4228] 2025-01-21 13:00:46,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:46,342 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 1635/5160 [40:50<1:01:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:00:53,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01878964900970459, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007755160331726074, 'eval_loss_2': 0.011034488677978516, 'eval_loss_3': -18.28845977783203, 'eval_loss_4': 1.5625485181808472, 'epoch': 9.48}
{'loss': 0.0367, 'grad_norm': 11.697518348693848, 'learning_rate': 2.0540697674418603e-05, 'loss_1': 0.027465488761663437, 'loss_2': 0.0092010498046875, 'loss_3': -16.488536834716797, 'loss_4': 1.9085960388183594, 'epoch': 9.48}
{'loss': 0.0262, 'grad_norm': 10.876054763793945, 'learning_rate': 2.0534883720930235e-05, 'loss_1': 0.020687207579612732, 'loss_2': 0.00547027587890625, 'loss_3': -16.668807983398438, 'loss_4': 1.2632362842559814, 'epoch': 9.49}
{'loss': 0.0225, 'grad_norm': 5.391366958618164, 'learning_rate': 2.052906976744186e-05, 'loss_1': 0.009303557686507702, 'loss_2': 0.013153076171875, 'loss_3': -16.477359771728516, 'loss_4': 2.1166818141937256, 'epoch': 9.49}
{'loss': 0.0263, 'grad_norm': 7.5769877433776855, 'learning_rate': 2.052325581395349e-05, 'loss_1': 0.010714857839047909, 'loss_2': 0.0156097412109375, 'loss_3': -16.334911346435547, 'loss_4': 1.5798733234405518, 'epoch': 9.5}
{'loss': 0.0186, 'grad_norm': 5.498702049255371, 'learning_rate': 2.0517441860465114e-05, 'loss_1': 0.009190920740365982, 'loss_2': 0.009368896484375, 'loss_3': -16.395288467407227, 'loss_4': 1.3902075290679932, 'epoch': 9.51}
[INFO|trainer.py:4228] 2025-01-21 13:00:53,715 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:00:53,715 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▌                                                                                                                                                     | 1640/5160 [40:58<1:01:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:01,078 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0147958192974329, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.936, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006796042434871197, 'eval_loss_2': 0.007999777793884277, 'eval_loss_3': -18.290529251098633, 'eval_loss_4': 1.4495344161987305, 'epoch': 9.51}
{'loss': 0.0269, 'grad_norm': 8.87375259399414, 'learning_rate': 2.0511627906976743e-05, 'loss_1': 0.015788095071911812, 'loss_2': 0.011138916015625, 'loss_3': -16.207263946533203, 'loss_4': 1.4398844242095947, 'epoch': 9.51}
{'loss': 0.0259, 'grad_norm': 13.547039031982422, 'learning_rate': 2.0505813953488375e-05, 'loss_1': 0.01930665411055088, 'loss_2': 0.00656890869140625, 'loss_3': -16.396968841552734, 'loss_4': 1.7726364135742188, 'epoch': 9.52}
{'loss': 0.0347, 'grad_norm': 14.151145935058594, 'learning_rate': 2.05e-05, 'loss_1': 0.026981528848409653, 'loss_2': 0.0077056884765625, 'loss_3': -16.239030838012695, 'loss_4': 2.0068249702453613, 'epoch': 9.52}
{'loss': 0.017, 'grad_norm': 6.058363437652588, 'learning_rate': 2.049418604651163e-05, 'loss_1': 0.012603497132658958, 'loss_2': 0.004436492919921875, 'loss_3': -16.392452239990234, 'loss_4': 0.8678145408630371, 'epoch': 9.53}
{'loss': 0.0156, 'grad_norm': 8.497870445251465, 'learning_rate': 2.0488372093023254e-05, 'loss_1': 0.014208915643393993, 'loss_2': 0.00135040283203125, 'loss_3': -16.406984329223633, 'loss_4': 1.631303310394287, 'epoch': 9.53}
[INFO|trainer.py:4228] 2025-01-21 13:01:01,079 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:01,079 >>   Batch size = 64
 32%|█████████████████████████████████████████████████████████████████████▊                                                                                                                                                     | 1645/5160 [41:05<1:01:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:08,462 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014003901742398739, 'eval_runtime': 3.8227, 'eval_samples_per_second': 267.87, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.006201206240803003, 'eval_loss_2': 0.007802695035934448, 'eval_loss_3': -18.27368927001953, 'eval_loss_4': 1.2963895797729492, 'epoch': 9.53}
{'loss': 0.0123, 'grad_norm': 5.267436981201172, 'learning_rate': 2.0482558139534883e-05, 'loss_1': 0.008530438877642155, 'loss_2': 0.0037364959716796875, 'loss_3': -16.312950134277344, 'loss_4': 1.4813165664672852, 'epoch': 9.54}
{'loss': 0.0194, 'grad_norm': 8.807812690734863, 'learning_rate': 2.0476744186046515e-05, 'loss_1': 0.011125215329229832, 'loss_2': 0.00827789306640625, 'loss_3': -16.18775177001953, 'loss_4': 1.1013150215148926, 'epoch': 9.55}
{'loss': 0.0318, 'grad_norm': 9.5331392288208, 'learning_rate': 2.047093023255814e-05, 'loss_1': 0.02422909438610077, 'loss_2': 0.007537841796875, 'loss_3': -16.129226684570312, 'loss_4': 1.653441071510315, 'epoch': 9.55}
{'loss': 0.0265, 'grad_norm': 7.728107929229736, 'learning_rate': 2.046511627906977e-05, 'loss_1': 0.015337727963924408, 'loss_2': 0.0111541748046875, 'loss_3': -16.37582015991211, 'loss_4': 0.8182202577590942, 'epoch': 9.56}
{'loss': 0.0248, 'grad_norm': 5.799582481384277, 'learning_rate': 2.0459302325581394e-05, 'loss_1': 0.011658643372356892, 'loss_2': 0.01318359375, 'loss_3': -16.223480224609375, 'loss_4': 1.3485914468765259, 'epoch': 9.56}
[INFO|trainer.py:4228] 2025-01-21 13:01:08,462 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:08,462 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████                                                                                                                                                     | 1650/5160 [41:12<1:00:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:15,839 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01644079200923443, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.752, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006243627984076738, 'eval_loss_2': 0.010197162628173828, 'eval_loss_3': -18.270954132080078, 'eval_loss_4': 1.0017497539520264, 'epoch': 9.56}
{'loss': 0.032, 'grad_norm': 10.809765815734863, 'learning_rate': 2.0453488372093023e-05, 'loss_1': 0.01854535937309265, 'loss_2': 0.0134735107421875, 'loss_3': -16.19409942626953, 'loss_4': 1.1137676239013672, 'epoch': 9.57}
{'loss': 0.0201, 'grad_norm': 5.593985080718994, 'learning_rate': 2.044767441860465e-05, 'loss_1': 0.00944061391055584, 'loss_2': 0.01061248779296875, 'loss_3': -16.439912796020508, 'loss_4': 0.8423991203308105, 'epoch': 9.58}
{'loss': 0.0367, 'grad_norm': 12.913945198059082, 'learning_rate': 2.044186046511628e-05, 'loss_1': 0.03212335705757141, 'loss_2': 0.004611968994140625, 'loss_3': -16.23858642578125, 'loss_4': 1.0546133518218994, 'epoch': 9.58}
{'loss': 0.0302, 'grad_norm': 13.492830276489258, 'learning_rate': 2.043604651162791e-05, 'loss_1': 0.028230931609869003, 'loss_2': 0.0019989013671875, 'loss_3': -16.401016235351562, 'loss_4': 1.6305313110351562, 'epoch': 9.59}
{'loss': 0.0189, 'grad_norm': 7.852917194366455, 'learning_rate': 2.0430232558139534e-05, 'loss_1': 0.014687079936265945, 'loss_2': 0.00423431396484375, 'loss_3': -16.40213966369629, 'loss_4': 1.0745772123336792, 'epoch': 9.59}
[INFO|trainer.py:4228] 2025-01-21 13:01:15,839 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:15,840 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▏                                                                                                                                                    | 1655/5160 [41:20<1:00:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:23,212 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008722910657525063, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.757, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006213273387402296, 'eval_loss_2': 0.0025096386671066284, 'eval_loss_3': -18.3044490814209, 'eval_loss_4': 0.7929248809814453, 'epoch': 9.59}
{'loss': 0.0445, 'grad_norm': 21.1016902923584, 'learning_rate': 2.0424418604651166e-05, 'loss_1': 0.04168355464935303, 'loss_2': 0.002834320068359375, 'loss_3': -15.967039108276367, 'loss_4': 1.0545299053192139, 'epoch': 9.6}
{'loss': 0.0135, 'grad_norm': 5.961318492889404, 'learning_rate': 2.041860465116279e-05, 'loss_1': 0.008435219526290894, 'loss_2': 0.005031585693359375, 'loss_3': -16.416933059692383, 'loss_4': 1.1086399555206299, 'epoch': 9.6}
{'loss': 0.0355, 'grad_norm': 12.645493507385254, 'learning_rate': 2.041279069767442e-05, 'loss_1': 0.02571912854909897, 'loss_2': 0.00977325439453125, 'loss_3': -16.451213836669922, 'loss_4': 0.7365822196006775, 'epoch': 9.61}
{'loss': 0.0225, 'grad_norm': 5.993489742279053, 'learning_rate': 2.0406976744186048e-05, 'loss_1': 0.010934926569461823, 'loss_2': 0.01153564453125, 'loss_3': -16.283605575561523, 'loss_4': 0.21747252345085144, 'epoch': 9.62}
{'loss': 0.0222, 'grad_norm': 6.899158000946045, 'learning_rate': 2.0401162790697673e-05, 'loss_1': 0.01785026118159294, 'loss_2': 0.00434112548828125, 'loss_3': -16.351455688476562, 'loss_4': 0.43155795335769653, 'epoch': 9.62}
[INFO|trainer.py:4228] 2025-01-21 13:01:23,212 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:23,212 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▍                                                                                                                                                    | 1660/5160 [41:27<1:00:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:30,578 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01411399431526661, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.911, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007700893562287092, 'eval_loss_2': 0.006413102149963379, 'eval_loss_3': -18.335613250732422, 'eval_loss_4': 0.630060076713562, 'epoch': 9.62}
{'loss': 0.0161, 'grad_norm': 6.201386451721191, 'learning_rate': 2.0395348837209305e-05, 'loss_1': 0.013175848871469498, 'loss_2': 0.002887725830078125, 'loss_3': -16.418506622314453, 'loss_4': 0.8159759640693665, 'epoch': 9.63}
{'loss': 0.0178, 'grad_norm': 7.344379425048828, 'learning_rate': 2.038953488372093e-05, 'loss_1': 0.01186684425920248, 'loss_2': 0.00592803955078125, 'loss_3': -16.409313201904297, 'loss_4': 0.5219094753265381, 'epoch': 9.63}
{'loss': 0.0299, 'grad_norm': 11.747573852539062, 'learning_rate': 2.038372093023256e-05, 'loss_1': 0.021506881341338158, 'loss_2': 0.008392333984375, 'loss_3': -16.268463134765625, 'loss_4': 0.5820877552032471, 'epoch': 9.64}
{'loss': 0.0335, 'grad_norm': 15.755681991577148, 'learning_rate': 2.0377906976744185e-05, 'loss_1': 0.02706931158900261, 'loss_2': 0.006404876708984375, 'loss_3': -16.344858169555664, 'loss_4': 0.7996239066123962, 'epoch': 9.65}
{'loss': 0.0171, 'grad_norm': 6.22802209854126, 'learning_rate': 2.0372093023255813e-05, 'loss_1': 0.012741782702505589, 'loss_2': 0.00439453125, 'loss_3': -16.1693115234375, 'loss_4': 0.5785770416259766, 'epoch': 9.65}
[INFO|trainer.py:4228] 2025-01-21 13:01:30,578 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:30,578 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▋                                                                                                                                                    | 1665/5160 [41:35<1:01:28,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 13:01:38,138 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017400003969669342, 'eval_runtime': 3.9983, 'eval_samples_per_second': 256.112, 'eval_steps_per_second': 4.002, 'eval_loss_1': 0.012557484209537506, 'eval_loss_2': 0.004842519760131836, 'eval_loss_3': -18.27060317993164, 'eval_loss_4': 0.9820495843887329, 'epoch': 9.65}
{'loss': 0.0309, 'grad_norm': 10.857572555541992, 'learning_rate': 2.0366279069767445e-05, 'loss_1': 0.02130919136106968, 'loss_2': 0.00958251953125, 'loss_3': -16.247161865234375, 'loss_4': 0.49817177653312683, 'epoch': 9.66}
{'loss': 0.0287, 'grad_norm': 8.395726203918457, 'learning_rate': 2.036046511627907e-05, 'loss_1': 0.017590640112757683, 'loss_2': 0.01110076904296875, 'loss_3': -16.329936981201172, 'loss_4': 1.3333559036254883, 'epoch': 9.66}
{'loss': 0.0537, 'grad_norm': 23.687362670898438, 'learning_rate': 2.03546511627907e-05, 'loss_1': 0.04889808967709541, 'loss_2': 0.00479888916015625, 'loss_3': -16.23486328125, 'loss_4': 1.3004965782165527, 'epoch': 9.67}
{'loss': 0.0447, 'grad_norm': 12.991082191467285, 'learning_rate': 2.0348837209302324e-05, 'loss_1': 0.0380890853703022, 'loss_2': 0.00661468505859375, 'loss_3': -16.296913146972656, 'loss_4': 2.1051955223083496, 'epoch': 9.67}
{'loss': 0.0514, 'grad_norm': 17.077003479003906, 'learning_rate': 2.0343023255813953e-05, 'loss_1': 0.046509310603141785, 'loss_2': 0.0048980712890625, 'loss_3': -16.31395149230957, 'loss_4': 0.5804771184921265, 'epoch': 9.68}
[INFO|trainer.py:4228] 2025-01-21 13:01:38,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:38,139 >>   Batch size = 64
 32%|██████████████████████████████████████████████████████████████████████▉                                                                                                                                                    | 1670/5160 [41:42<1:00:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:45,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.025979548692703247, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.624, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01472189836204052, 'eval_loss_2': 0.011257648468017578, 'eval_loss_3': -18.248023986816406, 'eval_loss_4': 1.4813356399536133, 'epoch': 9.68}
{'loss': 0.0185, 'grad_norm': 5.726398468017578, 'learning_rate': 2.0337209302325585e-05, 'loss_1': 0.012183169834315777, 'loss_2': 0.00632476806640625, 'loss_3': -16.303508758544922, 'loss_4': 1.2255704402923584, 'epoch': 9.69}
{'loss': 0.0136, 'grad_norm': 5.55098295211792, 'learning_rate': 2.033139534883721e-05, 'loss_1': 0.011311754584312439, 'loss_2': 0.002300262451171875, 'loss_3': -16.305824279785156, 'loss_4': 1.902832269668579, 'epoch': 9.69}
{'loss': 0.0196, 'grad_norm': 8.932120323181152, 'learning_rate': 2.032558139534884e-05, 'loss_1': 0.01571701653301716, 'loss_2': 0.00388336181640625, 'loss_3': -16.322708129882812, 'loss_4': 1.4755406379699707, 'epoch': 9.7}
{'loss': 0.0443, 'grad_norm': 19.47541046142578, 'learning_rate': 2.0319767441860464e-05, 'loss_1': 0.03702296316623688, 'loss_2': 0.0073089599609375, 'loss_3': -16.116924285888672, 'loss_4': 1.460861325263977, 'epoch': 9.7}
{'loss': 0.0381, 'grad_norm': 10.148872375488281, 'learning_rate': 2.0313953488372093e-05, 'loss_1': 0.026638228446245193, 'loss_2': 0.0114898681640625, 'loss_3': -16.30970001220703, 'loss_4': 1.7932915687561035, 'epoch': 9.71}
[INFO|trainer.py:4228] 2025-01-21 13:01:45,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:45,508 >>   Batch size = 64
 32%|███████████████████████████████████████████████████████████████████████                                                                                                                                                    | 1675/5160 [41:50<1:00:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:01:52,877 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01814102753996849, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.43, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.012419101782143116, 'eval_loss_2': 0.005721926689147949, 'eval_loss_3': -18.260223388671875, 'eval_loss_4': 1.729848027229309, 'epoch': 9.71}
{'loss': 0.0242, 'grad_norm': 7.177229881286621, 'learning_rate': 2.030813953488372e-05, 'loss_1': 0.019551414996385574, 'loss_2': 0.00463104248046875, 'loss_3': -16.474660873413086, 'loss_4': 1.519858956336975, 'epoch': 9.72}
{'loss': 0.0297, 'grad_norm': 8.486645698547363, 'learning_rate': 2.030232558139535e-05, 'loss_1': 0.022919010370969772, 'loss_2': 0.00678253173828125, 'loss_3': -16.07149887084961, 'loss_4': 1.7551660537719727, 'epoch': 9.72}
{'loss': 0.0203, 'grad_norm': 16.733720779418945, 'learning_rate': 2.029651162790698e-05, 'loss_1': 0.020114419981837273, 'loss_2': 0.0002052783966064453, 'loss_3': -16.167299270629883, 'loss_4': 1.5003314018249512, 'epoch': 9.73}
{'loss': 0.0321, 'grad_norm': 7.624488830566406, 'learning_rate': 2.0290697674418604e-05, 'loss_1': 0.022793076932430267, 'loss_2': 0.0092926025390625, 'loss_3': -16.27484130859375, 'loss_4': 2.132018804550171, 'epoch': 9.73}
{'loss': 0.0164, 'grad_norm': 5.337775707244873, 'learning_rate': 2.0284883720930233e-05, 'loss_1': 0.010134818963706493, 'loss_2': 0.006256103515625, 'loss_3': -16.371694564819336, 'loss_4': 1.9302623271942139, 'epoch': 9.74}
[INFO|trainer.py:4228] 2025-01-21 13:01:52,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:01:52,877 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▎                                                                                                                                                   | 1680/5160 [41:57<1:00:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:00,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013365601189434528, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.742, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00951919425278902, 'eval_loss_2': 0.003846406936645508, 'eval_loss_3': -18.261207580566406, 'eval_loss_4': 1.5708540678024292, 'epoch': 9.74}
{'loss': 0.0166, 'grad_norm': 6.546624660491943, 'learning_rate': 2.027906976744186e-05, 'loss_1': 0.01363551989197731, 'loss_2': 0.003002166748046875, 'loss_3': -15.963873863220215, 'loss_4': 1.4767851829528809, 'epoch': 9.74}
{'loss': 0.0164, 'grad_norm': 6.248051643371582, 'learning_rate': 2.027325581395349e-05, 'loss_1': 0.01381692010909319, 'loss_2': 0.00258636474609375, 'loss_3': -16.25051498413086, 'loss_4': 1.7167766094207764, 'epoch': 9.75}
{'loss': 0.0295, 'grad_norm': 15.002684593200684, 'learning_rate': 2.026744186046512e-05, 'loss_1': 0.026471218094229698, 'loss_2': 0.002979278564453125, 'loss_3': -16.19574737548828, 'loss_4': 1.1338735818862915, 'epoch': 9.76}
{'loss': 0.0158, 'grad_norm': 7.555305480957031, 'learning_rate': 2.0261627906976744e-05, 'loss_1': 0.015363303944468498, 'loss_2': 0.0004076957702636719, 'loss_3': -16.050434112548828, 'loss_4': 1.976422667503357, 'epoch': 9.76}
{'loss': 0.0129, 'grad_norm': 6.094862937927246, 'learning_rate': 2.0255813953488372e-05, 'loss_1': 0.011767796240746975, 'loss_2': 0.0011749267578125, 'loss_3': -16.31369400024414, 'loss_4': 1.158600926399231, 'epoch': 9.77}
[INFO|trainer.py:4228] 2025-01-21 13:02:00,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:00,246 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▌                                                                                                                                                   | 1685/5160 [42:04<1:00:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:07,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010029925964772701, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.502, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005291266832500696, 'eval_loss_2': 0.004738658666610718, 'eval_loss_3': -18.2958984375, 'eval_loss_4': 1.4516575336456299, 'epoch': 9.77}
{'loss': 0.0082, 'grad_norm': 4.753003120422363, 'learning_rate': 2.025e-05, 'loss_1': 0.007614929229021072, 'loss_2': 0.0006251335144042969, 'loss_3': -16.306720733642578, 'loss_4': 1.1556340456008911, 'epoch': 9.77}
{'loss': 0.0172, 'grad_norm': 5.604491710662842, 'learning_rate': 2.024418604651163e-05, 'loss_1': 0.013836529105901718, 'loss_2': 0.0033512115478515625, 'loss_3': -16.39134979248047, 'loss_4': 1.6419848203659058, 'epoch': 9.78}
{'loss': 0.0509, 'grad_norm': 9.840685844421387, 'learning_rate': 2.0238372093023255e-05, 'loss_1': 0.03486210107803345, 'loss_2': 0.0160064697265625, 'loss_3': -16.303157806396484, 'loss_4': 0.8390308618545532, 'epoch': 9.78}
{'loss': 0.019, 'grad_norm': 6.724599838256836, 'learning_rate': 2.0232558139534883e-05, 'loss_1': 0.01712125912308693, 'loss_2': 0.0019245147705078125, 'loss_3': -15.822118759155273, 'loss_4': 1.4907808303833008, 'epoch': 9.79}
{'loss': 0.0162, 'grad_norm': 13.214079856872559, 'learning_rate': 2.0226744186046512e-05, 'loss_1': 0.01530255377292633, 'loss_2': 0.0009331703186035156, 'loss_3': -16.463520050048828, 'loss_4': 1.6843295097351074, 'epoch': 9.8}
[INFO|trainer.py:4228] 2025-01-21 13:02:07,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:07,624 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1690/5160 [42:12<1:00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:14,996 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009774135425686836, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.939, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005114489234983921, 'eval_loss_2': 0.004659645259380341, 'eval_loss_3': -18.2928466796875, 'eval_loss_4': 1.547003984451294, 'epoch': 9.8}
{'loss': 0.0106, 'grad_norm': 4.768826961517334, 'learning_rate': 2.022093023255814e-05, 'loss_1': 0.00906298216432333, 'loss_2': 0.0015106201171875, 'loss_3': -16.35218048095703, 'loss_4': 0.951969563961029, 'epoch': 9.8}
{'loss': 0.0142, 'grad_norm': 5.306248664855957, 'learning_rate': 2.021511627906977e-05, 'loss_1': 0.008998612873256207, 'loss_2': 0.00518035888671875, 'loss_3': -16.33019256591797, 'loss_4': 1.909522294998169, 'epoch': 9.81}
{'loss': 0.0251, 'grad_norm': 10.80628490447998, 'learning_rate': 2.0209302325581395e-05, 'loss_1': 0.01324637420475483, 'loss_2': 0.0118255615234375, 'loss_3': -16.406021118164062, 'loss_4': 1.9923512935638428, 'epoch': 9.81}
{'loss': 0.0371, 'grad_norm': 13.284505844116211, 'learning_rate': 2.0203488372093023e-05, 'loss_1': 0.02596069499850273, 'loss_2': 0.0111846923828125, 'loss_3': -16.383804321289062, 'loss_4': 1.6782596111297607, 'epoch': 9.82}
{'loss': 0.0213, 'grad_norm': 5.079087734222412, 'learning_rate': 2.0197674418604652e-05, 'loss_1': 0.010617496445775032, 'loss_2': 0.0106353759765625, 'loss_3': -16.087873458862305, 'loss_4': 2.3723037242889404, 'epoch': 9.83}
[INFO|trainer.py:4228] 2025-01-21 13:02:14,996 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:14,996 >>   Batch size = 64
 33%|███████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1695/5160 [42:19<1:00:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:22,361 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01170269399881363, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0049413517117500305, 'eval_loss_2': 0.006761342287063599, 'eval_loss_3': -18.267919540405273, 'eval_loss_4': 1.4155718088150024, 'epoch': 9.83}
{'loss': 0.0179, 'grad_norm': 5.9072747230529785, 'learning_rate': 2.019186046511628e-05, 'loss_1': 0.010294963605701923, 'loss_2': 0.00756072998046875, 'loss_3': -16.060203552246094, 'loss_4': 1.9271554946899414, 'epoch': 9.83}
{'loss': 0.0196, 'grad_norm': 9.897210121154785, 'learning_rate': 2.018604651162791e-05, 'loss_1': 0.015002269297838211, 'loss_2': 0.004642486572265625, 'loss_3': -16.28084373474121, 'loss_4': 1.7954552173614502, 'epoch': 9.84}
{'loss': 0.0264, 'grad_norm': 10.69880199432373, 'learning_rate': 2.0180232558139534e-05, 'loss_1': 0.023134518414735794, 'loss_2': 0.0032291412353515625, 'loss_3': -16.055952072143555, 'loss_4': 1.5103654861450195, 'epoch': 9.84}
{'loss': 0.0342, 'grad_norm': 9.382522583007812, 'learning_rate': 2.0174418604651163e-05, 'loss_1': 0.03408198431134224, 'loss_2': 9.268522262573242e-05, 'loss_3': -16.149850845336914, 'loss_4': 1.2521979808807373, 'epoch': 9.85}
{'loss': 0.0137, 'grad_norm': 6.454437255859375, 'learning_rate': 2.0168604651162788e-05, 'loss_1': 0.011590028181672096, 'loss_2': 0.002063751220703125, 'loss_3': -16.146926879882812, 'loss_4': 1.2710983753204346, 'epoch': 9.85}
[INFO|trainer.py:4228] 2025-01-21 13:02:22,362 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:22,362 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▏                                                                                                                                                  | 1700/5160 [42:26<1:00:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:29,745 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0092239398509264, 'eval_runtime': 3.8216, 'eval_samples_per_second': 267.953, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.005716295447200537, 'eval_loss_2': 0.003507643938064575, 'eval_loss_3': -18.235885620117188, 'eval_loss_4': 1.0104241371154785, 'epoch': 9.85}
{'loss': 0.0102, 'grad_norm': 5.5833740234375, 'learning_rate': 2.016279069767442e-05, 'loss_1': 0.005435498896986246, 'loss_2': 0.0047760009765625, 'loss_3': -16.53986358642578, 'loss_4': 1.168949007987976, 'epoch': 9.86}
{'loss': 0.0557, 'grad_norm': 32.78200149536133, 'learning_rate': 2.015697674418605e-05, 'loss_1': 0.05040702968835831, 'loss_2': 0.005279541015625, 'loss_3': -16.33199691772461, 'loss_4': 0.8981539011001587, 'epoch': 9.87}
{'loss': 0.0142, 'grad_norm': 6.579134941101074, 'learning_rate': 2.0151162790697674e-05, 'loss_1': 0.009878957644104958, 'loss_2': 0.004352569580078125, 'loss_3': -16.24211883544922, 'loss_4': 1.5957897901535034, 'epoch': 9.87}
{'loss': 0.0121, 'grad_norm': 6.76425313949585, 'learning_rate': 2.0145348837209303e-05, 'loss_1': 0.008518990129232407, 'loss_2': 0.003536224365234375, 'loss_3': -16.077404022216797, 'loss_4': 1.285827875137329, 'epoch': 9.88}
{'loss': 0.0382, 'grad_norm': 23.434555053710938, 'learning_rate': 2.0139534883720928e-05, 'loss_1': 0.034071892499923706, 'loss_2': 0.00415802001953125, 'loss_3': -16.381221771240234, 'loss_4': 1.0238466262817383, 'epoch': 9.88}
[INFO|trainer.py:4228] 2025-01-21 13:02:29,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:29,745 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▏                                                                                                                                                  | 1700/5160 [42:30<1:00:07,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 13:02:33,559 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1700
[INFO|configuration_utils.py:420] 2025-01-21 13:02:33,561 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1700/config.json                                                                            
{'eval_loss': 0.008207464590668678, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.593, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005396904423832893, 'eval_loss_2': 0.002810560166835785, 'eval_loss_3': -18.236278533935547, 'eval_loss_4': 1.0104610919952393, 'epoch': 9.88}
[INFO|modeling_utils.py:2988] 2025-01-21 13:02:34,045 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1700/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 13:02:34,046 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1700/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 13:02:34,046 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1700/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 13:02:34,980 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1550] due to args.save_total_limit
 33%|████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1705/5160 [42:35<1:06:12,  1.15s/it][INFO|trainer.py:4226] 2025-01-21 13:02:38,624 >>
{'loss': 0.0152, 'grad_norm': 6.6397528648376465, 'learning_rate': 2.013372093023256e-05, 'loss_1': 0.011787453666329384, 'loss_2': 0.003452301025390625, 'loss_3': -16.135848999023438, 'loss_4': 1.2582865953445435, 'epoch': 9.89}
{'loss': 0.0188, 'grad_norm': 7.7289042472839355, 'learning_rate': 2.012790697674419e-05, 'loss_1': 0.01735934428870678, 'loss_2': 0.001392364501953125, 'loss_3': -15.931583404541016, 'loss_4': 1.0614798069000244, 'epoch': 9.9}
{'loss': 0.014, 'grad_norm': 6.115549564361572, 'learning_rate': 2.0122093023255814e-05, 'loss_1': 0.01040467619895935, 'loss_2': 0.00356292724609375, 'loss_3': -16.093910217285156, 'loss_4': 1.581974983215332, 'epoch': 9.9}
{'loss': 0.0156, 'grad_norm': 8.637163162231445, 'learning_rate': 2.0116279069767443e-05, 'loss_1': 0.013737753033638, 'loss_2': 0.001873016357421875, 'loss_3': -16.016185760498047, 'loss_4': 1.5908998250961304, 'epoch': 9.91}
{'loss': 0.0303, 'grad_norm': 16.64055824279785, 'learning_rate': 2.0110465116279068e-05, 'loss_1': 0.030215973034501076, 'loss_2': 3.886222839355469e-05, 'loss_3': -16.178150177001953, 'loss_4': 1.1769992113113403, 'epoch': 9.91}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 13:02:38,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:38,624 >>   Batch size = 64
 33%|████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1710/5160 [42:43<1:00:52,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 13:02:45,984 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009275540709495544, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.165, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006402439903467894, 'eval_loss_2': 0.0028731003403663635, 'eval_loss_3': -18.24663734436035, 'eval_loss_4': 1.0912004709243774, 'epoch': 9.91}
{'loss': 0.0109, 'grad_norm': 6.420286178588867, 'learning_rate': 2.01046511627907e-05, 'loss_1': 0.00860512349754572, 'loss_2': 0.0022945404052734375, 'loss_3': -16.085647583007812, 'loss_4': 1.7084004878997803, 'epoch': 9.92}
{'loss': 0.0217, 'grad_norm': 6.463123798370361, 'learning_rate': 2.0098837209302325e-05, 'loss_1': 0.011779485270380974, 'loss_2': 0.00991058349609375, 'loss_3': -16.147172927856445, 'loss_4': 1.1753181219100952, 'epoch': 9.92}
{'loss': 0.0093, 'grad_norm': 6.05076789855957, 'learning_rate': 2.0093023255813954e-05, 'loss_1': 0.006605995818972588, 'loss_2': 0.00267791748046875, 'loss_3': -15.995611190795898, 'loss_4': 1.0153753757476807, 'epoch': 9.93}
{'loss': 0.0803, 'grad_norm': 23.776714324951172, 'learning_rate': 2.0087209302325582e-05, 'loss_1': 0.07251796871423721, 'loss_2': 0.00775146484375, 'loss_3': -16.15966033935547, 'loss_4': 1.754319429397583, 'epoch': 9.94}
{'loss': 0.0181, 'grad_norm': 10.045694351196289, 'learning_rate': 2.0081395348837208e-05, 'loss_1': 0.015944723039865494, 'loss_2': 0.0021648406982421875, 'loss_3': -16.264759063720703, 'loss_4': 0.8441044092178345, 'epoch': 9.94}
[INFO|trainer.py:4228] 2025-01-21 13:02:45,984 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:45,984 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▍                                                                                                                                                   | 1715/5160 [42:50<59:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:02:53,353 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012161863967776299, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.939, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007480985950678587, 'eval_loss_2': 0.0046808794140815735, 'eval_loss_3': -18.258575439453125, 'eval_loss_4': 1.1323648691177368, 'epoch': 9.94}
{'loss': 0.0137, 'grad_norm': 7.54775857925415, 'learning_rate': 2.007558139534884e-05, 'loss_1': 0.012351841665804386, 'loss_2': 0.0013828277587890625, 'loss_3': -16.147994995117188, 'loss_4': 1.7162739038467407, 'epoch': 9.95}
{'loss': 0.0285, 'grad_norm': 11.041152954101562, 'learning_rate': 2.0069767441860465e-05, 'loss_1': 0.01946444623172283, 'loss_2': 0.009063720703125, 'loss_3': -16.180879592895508, 'loss_4': 0.9812180995941162, 'epoch': 9.95}
{'loss': 0.0145, 'grad_norm': 6.531505107879639, 'learning_rate': 2.0063953488372093e-05, 'loss_1': 0.00987330637872219, 'loss_2': 0.004665374755859375, 'loss_3': -16.215547561645508, 'loss_4': 1.0028979778289795, 'epoch': 9.96}
{'loss': 0.0143, 'grad_norm': 7.938858509063721, 'learning_rate': 2.0058139534883722e-05, 'loss_1': 0.012466688640415668, 'loss_2': 0.0018491744995117188, 'loss_3': -16.22609519958496, 'loss_4': 1.4631624221801758, 'epoch': 9.97}
{'loss': 0.0111, 'grad_norm': 5.239205837249756, 'learning_rate': 2.005232558139535e-05, 'loss_1': 0.00836449209600687, 'loss_2': 0.00273895263671875, 'loss_3': -16.086822509765625, 'loss_4': 1.759122371673584, 'epoch': 9.97}
[INFO|trainer.py:4228] 2025-01-21 13:02:53,353 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:02:53,353 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▋                                                                                                                                                   | 1720/5160 [42:57<53:42,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:03:00,368 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012916460633277893, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.757, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009446069598197937, 'eval_loss_2': 0.003470391035079956, 'eval_loss_3': -18.270044326782227, 'eval_loss_4': 1.2037409543991089, 'epoch': 9.97}
{'loss': 0.0232, 'grad_norm': 5.426075458526611, 'learning_rate': 2.004651162790698e-05, 'loss_1': 0.014811285771429539, 'loss_2': 0.0083770751953125, 'loss_3': -16.276872634887695, 'loss_4': 0.5774005651473999, 'epoch': 9.98}
{'loss': 0.0143, 'grad_norm': 5.296535968780518, 'learning_rate': 2.0040697674418605e-05, 'loss_1': 0.009373779408633709, 'loss_2': 0.00492095947265625, 'loss_3': -16.409870147705078, 'loss_4': 1.2038785219192505, 'epoch': 9.98}
{'loss': 0.0246, 'grad_norm': 10.674711227416992, 'learning_rate': 2.0034883720930233e-05, 'loss_1': 0.019984377548098564, 'loss_2': 0.00461578369140625, 'loss_3': -16.319299697875977, 'loss_4': 1.467136263847351, 'epoch': 9.99}
{'loss': 0.0161, 'grad_norm': 5.999992370605469, 'learning_rate': 2.002906976744186e-05, 'loss_1': 0.009368346072733402, 'loss_2': 0.006694793701171875, 'loss_3': -16.30087661743164, 'loss_4': 1.235421061515808, 'epoch': 9.99}
{'loss': 0.0099, 'grad_norm': 5.923095226287842, 'learning_rate': 2.002325581395349e-05, 'loss_1': 0.001189563306979835, 'loss_2': 0.008697509765625, 'loss_3': -16.356019973754883, 'loss_4': 1.6794520616531372, 'epoch': 10.0}
[INFO|trainer.py:4228] 2025-01-21 13:03:00,368 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:00,368 >>   Batch size = 64
 33%|█████████████████████████████████████████████████████████████████████████▉                                                                                                                                                   | 1725/5160 [43:04<58:48,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:03:07,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015809539705514908, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.506, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008556488901376724, 'eval_loss_2': 0.007253050804138184, 'eval_loss_3': -18.267457962036133, 'eval_loss_4': 1.4542135000228882, 'epoch': 10.0}
{'loss': 0.0141, 'grad_norm': 4.892617702484131, 'learning_rate': 2.001744186046512e-05, 'loss_1': 0.007914945483207703, 'loss_2': 0.006214141845703125, 'loss_3': -16.232589721679688, 'loss_4': 1.7226446866989136, 'epoch': 10.01}
{'loss': 0.0137, 'grad_norm': 6.329893112182617, 'learning_rate': 2.0011627906976744e-05, 'loss_1': 0.00966039951890707, 'loss_2': 0.00400543212890625, 'loss_3': -16.23187255859375, 'loss_4': 0.9403766393661499, 'epoch': 10.01}
{'loss': 0.0127, 'grad_norm': 6.756468296051025, 'learning_rate': 2.0005813953488373e-05, 'loss_1': 0.009690841659903526, 'loss_2': 0.003047943115234375, 'loss_3': -16.204986572265625, 'loss_4': 2.2269692420959473, 'epoch': 10.02}
{'loss': 0.0082, 'grad_norm': 4.878065586090088, 'learning_rate': 1.9999999999999998e-05, 'loss_1': 0.007024559658020735, 'loss_2': 0.0011310577392578125, 'loss_3': -16.257694244384766, 'loss_4': 1.4249448776245117, 'epoch': 10.02}
{'loss': 0.0073, 'grad_norm': 5.673156261444092, 'learning_rate': 1.999418604651163e-05, 'loss_1': 0.006428378634154797, 'loss_2': 0.0008258819580078125, 'loss_3': -16.06214141845703, 'loss_4': 1.8857969045639038, 'epoch': 10.03}
[INFO|trainer.py:4228] 2025-01-21 13:03:07,784 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:07,784 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████                                                                                                                                                   | 1730/5160 [43:12<59:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:15,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015119615010917187, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.679, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009570242837071419, 'eval_loss_2': 0.005549371242523193, 'eval_loss_3': -18.23314094543457, 'eval_loss_4': 1.5595157146453857, 'epoch': 10.03}
{'loss': 0.0325, 'grad_norm': 8.060890197753906, 'learning_rate': 1.9988372093023256e-05, 'loss_1': 0.018903186544775963, 'loss_2': 0.01358795166015625, 'loss_3': -16.24333953857422, 'loss_4': 1.2225431203842163, 'epoch': 10.03}
{'loss': 0.0348, 'grad_norm': 13.787801742553711, 'learning_rate': 1.9982558139534884e-05, 'loss_1': 0.032169051468372345, 'loss_2': 0.002666473388671875, 'loss_3': -16.148799896240234, 'loss_4': 1.5790812969207764, 'epoch': 10.04}
{'loss': 0.0186, 'grad_norm': 5.926187038421631, 'learning_rate': 1.9976744186046513e-05, 'loss_1': 0.009551464579999447, 'loss_2': 0.00905609130859375, 'loss_3': -16.256336212158203, 'loss_4': 1.5356122255325317, 'epoch': 10.05}
{'loss': 0.0336, 'grad_norm': 10.495699882507324, 'learning_rate': 1.9970930232558138e-05, 'loss_1': 0.02379118651151657, 'loss_2': 0.0098114013671875, 'loss_3': -16.20992088317871, 'loss_4': 1.5540904998779297, 'epoch': 10.05}
{'loss': 0.0194, 'grad_norm': 6.75405740737915, 'learning_rate': 1.996511627906977e-05, 'loss_1': 0.012094912119209766, 'loss_2': 0.007293701171875, 'loss_3': -16.118282318115234, 'loss_4': 1.3088288307189941, 'epoch': 10.06}
[INFO|trainer.py:4228] 2025-01-21 13:03:15,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:15,161 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▎                                                                                                                                                  | 1735/5160 [43:19<59:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:22,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013218804262578487, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.206, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.007672524079680443, 'eval_loss_2': 0.00554627925157547, 'eval_loss_3': -18.186601638793945, 'eval_loss_4': 1.4417190551757812, 'epoch': 10.06}
{'loss': 0.0088, 'grad_norm': 6.172744274139404, 'learning_rate': 1.9959302325581395e-05, 'loss_1': 0.0087405014783144, 'loss_2': 8.046627044677734e-05, 'loss_3': -16.195205688476562, 'loss_4': 1.4950981140136719, 'epoch': 10.06}
{'loss': 0.0187, 'grad_norm': 7.977062225341797, 'learning_rate': 1.9953488372093024e-05, 'loss_1': 0.017848694697022438, 'loss_2': 0.0008893013000488281, 'loss_3': -16.386180877685547, 'loss_4': 1.451322317123413, 'epoch': 10.07}
{'loss': 0.009, 'grad_norm': 5.538000583648682, 'learning_rate': 1.9947674418604653e-05, 'loss_1': 0.007651207968592644, 'loss_2': 0.0013427734375, 'loss_3': -15.975470542907715, 'loss_4': 1.7912949323654175, 'epoch': 10.08}
{'loss': 0.0182, 'grad_norm': 7.372932434082031, 'learning_rate': 1.9941860465116278e-05, 'loss_1': 0.012177408672869205, 'loss_2': 0.006000518798828125, 'loss_3': -16.189329147338867, 'loss_4': 1.4179537296295166, 'epoch': 10.08}
{'loss': 0.0114, 'grad_norm': 7.009561061859131, 'learning_rate': 1.993604651162791e-05, 'loss_1': 0.00965755246579647, 'loss_2': 0.0017528533935546875, 'loss_3': -16.35436248779297, 'loss_4': 1.301337480545044, 'epoch': 10.09}
[INFO|trainer.py:4228] 2025-01-21 13:03:22,545 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:22,545 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                  | 1740/5160 [43:27<59:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:29,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01055563148111105, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.523, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006967431865632534, 'eval_loss_2': 0.0035881996154785156, 'eval_loss_3': -18.223983764648438, 'eval_loss_4': 1.2508465051651, 'epoch': 10.09}
{'loss': 0.0121, 'grad_norm': 5.306723117828369, 'learning_rate': 1.9930232558139535e-05, 'loss_1': 0.008012307807803154, 'loss_2': 0.004116058349609375, 'loss_3': -16.22925567626953, 'loss_4': 1.2372751235961914, 'epoch': 10.09}
{'loss': 0.0173, 'grad_norm': 11.147993087768555, 'learning_rate': 1.9924418604651164e-05, 'loss_1': 0.0168851800262928, 'loss_2': 0.0003991127014160156, 'loss_3': -16.091398239135742, 'loss_4': 1.3777254819869995, 'epoch': 10.1}
{'loss': 0.0105, 'grad_norm': 5.347160816192627, 'learning_rate': 1.991860465116279e-05, 'loss_1': 0.006475239526480436, 'loss_2': 0.0040740966796875, 'loss_3': -15.884993553161621, 'loss_4': 1.2610559463500977, 'epoch': 10.1}
{'loss': 0.0133, 'grad_norm': 6.170380115509033, 'learning_rate': 1.9912790697674418e-05, 'loss_1': 0.012510930188000202, 'loss_2': 0.0008268356323242188, 'loss_3': -16.374267578125, 'loss_4': 1.6410553455352783, 'epoch': 10.11}
{'loss': 0.0298, 'grad_norm': 10.467923164367676, 'learning_rate': 1.990697674418605e-05, 'loss_1': 0.02410954236984253, 'loss_2': 0.005706787109375, 'loss_3': -16.074020385742188, 'loss_4': 1.4552347660064697, 'epoch': 10.12}
[INFO|trainer.py:4228] 2025-01-21 13:03:29,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:29,917 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                                                  | 1745/5160 [43:34<59:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:37,289 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011438025161623955, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.64, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007857848890125751, 'eval_loss_2': 0.0035801753401756287, 'eval_loss_3': -18.229734420776367, 'eval_loss_4': 1.0731048583984375, 'epoch': 10.12}
{'loss': 0.007, 'grad_norm': 5.192305564880371, 'learning_rate': 1.9901162790697675e-05, 'loss_1': 0.004622629843652248, 'loss_2': 0.0023555755615234375, 'loss_3': -16.11665916442871, 'loss_4': 1.3470357656478882, 'epoch': 10.12}
{'loss': 0.0209, 'grad_norm': 8.852705001831055, 'learning_rate': 1.9895348837209303e-05, 'loss_1': 0.018524235114455223, 'loss_2': 0.00238037109375, 'loss_3': -16.206968307495117, 'loss_4': 1.443142294883728, 'epoch': 10.13}
{'loss': 0.0092, 'grad_norm': 4.514227867126465, 'learning_rate': 1.988953488372093e-05, 'loss_1': 0.006038795690983534, 'loss_2': 0.003131866455078125, 'loss_3': -16.25162124633789, 'loss_4': 0.7124297618865967, 'epoch': 10.13}
{'loss': 0.0135, 'grad_norm': 5.098280906677246, 'learning_rate': 1.9883720930232557e-05, 'loss_1': 0.005581296514719725, 'loss_2': 0.0078887939453125, 'loss_3': -16.39377212524414, 'loss_4': 1.2115678787231445, 'epoch': 10.14}
{'loss': 0.0133, 'grad_norm': 4.720665454864502, 'learning_rate': 1.987790697674419e-05, 'loss_1': 0.007439581211656332, 'loss_2': 0.0058441162109375, 'loss_3': -16.2501163482666, 'loss_4': 1.343433141708374, 'epoch': 10.15}
[INFO|trainer.py:4228] 2025-01-21 13:03:37,289 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:37,289 >>   Batch size = 64
 34%|██████████████████████████████████████████████████████████████████████████▉                                                                                                                                                  | 1750/5160 [43:41<59:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:44,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012046885676681995, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.964, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008081238716840744, 'eval_loss_2': 0.003965646028518677, 'eval_loss_3': -18.19679832458496, 'eval_loss_4': 1.2332764863967896, 'epoch': 10.15}
{'loss': 0.0171, 'grad_norm': 7.712181091308594, 'learning_rate': 1.9872093023255815e-05, 'loss_1': 0.01348869502544403, 'loss_2': 0.00362396240234375, 'loss_3': -15.911127090454102, 'loss_4': 1.3284966945648193, 'epoch': 10.15}
{'loss': 0.011, 'grad_norm': 5.099035739898682, 'learning_rate': 1.9866279069767443e-05, 'loss_1': 0.008210779167711735, 'loss_2': 0.002758026123046875, 'loss_3': -16.18764877319336, 'loss_4': 1.4499517679214478, 'epoch': 10.16}
{'loss': 0.0126, 'grad_norm': 5.486199378967285, 'learning_rate': 1.986046511627907e-05, 'loss_1': 0.012335485778748989, 'loss_2': 0.0002646446228027344, 'loss_3': -16.264272689819336, 'loss_4': 0.8842766880989075, 'epoch': 10.16}
{'loss': 0.0091, 'grad_norm': 5.4550065994262695, 'learning_rate': 1.9854651162790697e-05, 'loss_1': 0.006455293390899897, 'loss_2': 0.00264739990234375, 'loss_3': -16.142044067382812, 'loss_4': 0.9794926047325134, 'epoch': 10.17}
{'loss': 0.065, 'grad_norm': 17.795732498168945, 'learning_rate': 1.9848837209302326e-05, 'loss_1': 0.06314447522163391, 'loss_2': 0.0018215179443359375, 'loss_3': -16.28173828125, 'loss_4': 1.074352741241455, 'epoch': 10.17}
[INFO|trainer.py:4228] 2025-01-21 13:03:44,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:44,655 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▏                                                                                                                                                 | 1755/5160 [43:49<59:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:52,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010293100029230118, 'eval_runtime': 3.8199, 'eval_samples_per_second': 268.067, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.006229284685105085, 'eval_loss_2': 0.004063814878463745, 'eval_loss_3': -18.184467315673828, 'eval_loss_4': 1.386295199394226, 'epoch': 10.17}
{'loss': 0.0108, 'grad_norm': 5.188502788543701, 'learning_rate': 1.9843023255813954e-05, 'loss_1': 0.007371094543486834, 'loss_2': 0.003429412841796875, 'loss_3': -16.430139541625977, 'loss_4': 1.5575926303863525, 'epoch': 10.18}
{'loss': 0.0146, 'grad_norm': 8.142036437988281, 'learning_rate': 1.9837209302325583e-05, 'loss_1': 0.013639561831951141, 'loss_2': 0.0009417533874511719, 'loss_3': -16.228515625, 'loss_4': 1.4899966716766357, 'epoch': 10.19}
{'loss': 0.016, 'grad_norm': 7.083489894866943, 'learning_rate': 1.9831395348837208e-05, 'loss_1': 0.010748451575636864, 'loss_2': 0.0052337646484375, 'loss_3': -16.25210189819336, 'loss_4': 1.2219774723052979, 'epoch': 10.19}
{'loss': 0.012, 'grad_norm': 4.682210445404053, 'learning_rate': 1.9825581395348837e-05, 'loss_1': 0.007841650396585464, 'loss_2': 0.0041961669921875, 'loss_3': -16.292165756225586, 'loss_4': 1.193231463432312, 'epoch': 10.2}
{'loss': 0.0102, 'grad_norm': 4.928096294403076, 'learning_rate': 1.9819767441860466e-05, 'loss_1': 0.008924921974539757, 'loss_2': 0.001323699951171875, 'loss_3': -16.21796417236328, 'loss_4': 1.3669373989105225, 'epoch': 10.2}
[INFO|trainer.py:4228] 2025-01-21 13:03:52,034 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:52,034 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▍                                                                                                                                                 | 1760/5160 [43:56<58:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:03:59,397 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010891731828451157, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.576, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006814118474721909, 'eval_loss_2': 0.004077613353729248, 'eval_loss_3': -18.192262649536133, 'eval_loss_4': 1.2209951877593994, 'epoch': 10.2}
{'loss': 0.0148, 'grad_norm': 5.510352611541748, 'learning_rate': 1.9813953488372094e-05, 'loss_1': 0.011011351831257343, 'loss_2': 0.00380706787109375, 'loss_3': -16.233491897583008, 'loss_4': 1.0118649005889893, 'epoch': 10.21}
{'loss': 0.0134, 'grad_norm': 8.45187759399414, 'learning_rate': 1.9808139534883723e-05, 'loss_1': 0.011106183752417564, 'loss_2': 0.00229644775390625, 'loss_3': -16.033077239990234, 'loss_4': 1.3896065950393677, 'epoch': 10.22}
{'loss': 0.0209, 'grad_norm': 10.676776885986328, 'learning_rate': 1.9802325581395348e-05, 'loss_1': 0.017204878851771355, 'loss_2': 0.003658294677734375, 'loss_3': -16.215126037597656, 'loss_4': 1.1109544038772583, 'epoch': 10.22}
{'loss': 0.0114, 'grad_norm': 6.959781169891357, 'learning_rate': 1.9796511627906977e-05, 'loss_1': 0.009275548160076141, 'loss_2': 0.0020751953125, 'loss_3': -16.283905029296875, 'loss_4': 1.1868690252304077, 'epoch': 10.23}
{'loss': 0.0164, 'grad_norm': 5.972928524017334, 'learning_rate': 1.9790697674418605e-05, 'loss_1': 0.011697167530655861, 'loss_2': 0.0047454833984375, 'loss_3': -16.208494186401367, 'loss_4': 1.2208333015441895, 'epoch': 10.23}
[INFO|trainer.py:4228] 2025-01-21 13:03:59,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:03:59,398 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▌                                                                                                                                                 | 1765/5160 [44:03<58:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:06,766 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01256614364683628, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.772, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006230408791452646, 'eval_loss_2': 0.006335735321044922, 'eval_loss_3': -18.20934295654297, 'eval_loss_4': 1.1326066255569458, 'epoch': 10.23}
{'loss': 0.0197, 'grad_norm': 5.911672592163086, 'learning_rate': 1.9784883720930234e-05, 'loss_1': 0.011036333627998829, 'loss_2': 0.0086212158203125, 'loss_3': -16.12749481201172, 'loss_4': 1.3059695959091187, 'epoch': 10.24}
{'loss': 0.013, 'grad_norm': 5.912894248962402, 'learning_rate': 1.977906976744186e-05, 'loss_1': 0.008672221563756466, 'loss_2': 0.0043182373046875, 'loss_3': -16.12387466430664, 'loss_4': 1.0899039506912231, 'epoch': 10.24}
{'loss': 0.024, 'grad_norm': 6.2514238357543945, 'learning_rate': 1.9773255813953488e-05, 'loss_1': 0.007719001267105341, 'loss_2': 0.01629638671875, 'loss_3': -16.123598098754883, 'loss_4': 1.1072355508804321, 'epoch': 10.25}
{'loss': 0.0252, 'grad_norm': 12.4635591506958, 'learning_rate': 1.9767441860465116e-05, 'loss_1': 0.01769287697970867, 'loss_2': 0.007476806640625, 'loss_3': -16.257007598876953, 'loss_4': 1.4503448009490967, 'epoch': 10.26}
{'loss': 0.0237, 'grad_norm': 9.270537376403809, 'learning_rate': 1.9761627906976745e-05, 'loss_1': 0.019818084314465523, 'loss_2': 0.00383758544921875, 'loss_3': -16.35698699951172, 'loss_4': 1.6249059438705444, 'epoch': 10.26}
[INFO|trainer.py:4228] 2025-01-21 13:04:06,766 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:06,767 >>   Batch size = 64
 34%|███████████████████████████████████████████████████████████████████████████▊                                                                                                                                                 | 1770/5160 [44:11<58:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:14,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011278478428721428, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.883, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0064392369240522385, 'eval_loss_2': 0.0048392415046691895, 'eval_loss_3': -18.203060150146484, 'eval_loss_4': 1.1511940956115723, 'epoch': 10.26}
{'loss': 0.0131, 'grad_norm': 4.858443260192871, 'learning_rate': 1.9755813953488374e-05, 'loss_1': 0.007120245601981878, 'loss_2': 0.00600433349609375, 'loss_3': -16.344268798828125, 'loss_4': 1.5306551456451416, 'epoch': 10.27}
{'loss': 0.0282, 'grad_norm': 7.35068941116333, 'learning_rate': 1.975e-05, 'loss_1': 0.018635446205735207, 'loss_2': 0.00958251953125, 'loss_3': -16.403413772583008, 'loss_4': 1.7773714065551758, 'epoch': 10.27}
{'loss': 0.0116, 'grad_norm': 5.037213325500488, 'learning_rate': 1.9744186046511628e-05, 'loss_1': 0.006545434705913067, 'loss_2': 0.0050048828125, 'loss_3': -16.225210189819336, 'loss_4': 1.215841293334961, 'epoch': 10.28}
{'loss': 0.0133, 'grad_norm': 6.976687908172607, 'learning_rate': 1.9738372093023256e-05, 'loss_1': 0.013042439706623554, 'loss_2': 0.0002880096435546875, 'loss_3': -16.008649826049805, 'loss_4': 1.0388844013214111, 'epoch': 10.28}
{'loss': 0.0161, 'grad_norm': 7.834029197692871, 'learning_rate': 1.9732558139534885e-05, 'loss_1': 0.013975286856293678, 'loss_2': 0.0020809173583984375, 'loss_3': -16.22574234008789, 'loss_4': 1.952317476272583, 'epoch': 10.29}
[INFO|trainer.py:4228] 2025-01-21 13:04:14,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:14,137 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████                                                                                                                                                 | 1775/5160 [44:18<58:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:21,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00971037708222866, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.596, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005894368514418602, 'eval_loss_2': 0.0038160085678100586, 'eval_loss_3': -18.238370895385742, 'eval_loss_4': 1.1630103588104248, 'epoch': 10.29}
{'loss': 0.0135, 'grad_norm': 5.634562015533447, 'learning_rate': 1.9726744186046513e-05, 'loss_1': 0.00839795172214508, 'loss_2': 0.00514984130859375, 'loss_3': -16.251752853393555, 'loss_4': 0.6760498285293579, 'epoch': 10.3}
{'loss': 0.0149, 'grad_norm': 7.379377841949463, 'learning_rate': 1.972093023255814e-05, 'loss_1': 0.013591266237199306, 'loss_2': 0.0012836456298828125, 'loss_3': -16.377548217773438, 'loss_4': 1.6491724252700806, 'epoch': 10.3}
{'loss': 0.0167, 'grad_norm': 9.892708778381348, 'learning_rate': 1.9715116279069767e-05, 'loss_1': 0.015413164161145687, 'loss_2': 0.00131988525390625, 'loss_3': -16.27171516418457, 'loss_4': 1.4130566120147705, 'epoch': 10.31}
{'loss': 0.0152, 'grad_norm': 6.94211483001709, 'learning_rate': 1.9709302325581393e-05, 'loss_1': 0.01471361517906189, 'loss_2': 0.0004968643188476562, 'loss_3': -16.22339630126953, 'loss_4': 1.2434611320495605, 'epoch': 10.31}
{'loss': 0.0212, 'grad_norm': 8.602409362792969, 'learning_rate': 1.9703488372093025e-05, 'loss_1': 0.018497077748179436, 'loss_2': 0.0026702880859375, 'loss_3': -16.490251541137695, 'loss_4': 0.6499402523040771, 'epoch': 10.32}
[INFO|trainer.py:4228] 2025-01-21 13:04:21,505 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:21,505 >>   Batch size = 64
 34%|████████████████████████████████████████████████████████████████████████████▏                                                                                                                                                | 1780/5160 [44:26<58:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:28,873 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010805010795593262, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.137, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.007122808136045933, 'eval_loss_2': 0.0036822035908699036, 'eval_loss_3': -18.242900848388672, 'eval_loss_4': 1.1483736038208008, 'epoch': 10.32}
{'loss': 0.0173, 'grad_norm': 10.014913558959961, 'learning_rate': 1.9697674418604653e-05, 'loss_1': 0.015530580654740334, 'loss_2': 0.0017986297607421875, 'loss_3': -16.24738883972168, 'loss_4': 1.418257474899292, 'epoch': 10.33}
{'loss': 0.0307, 'grad_norm': 14.819596290588379, 'learning_rate': 1.969186046511628e-05, 'loss_1': 0.03029806911945343, 'loss_2': 0.0004000663757324219, 'loss_3': -16.22046661376953, 'loss_4': 1.0432915687561035, 'epoch': 10.33}
{'loss': 0.0174, 'grad_norm': 11.745898246765137, 'learning_rate': 1.9686046511627907e-05, 'loss_1': 0.017171526327729225, 'loss_2': 0.0002536773681640625, 'loss_3': -16.448265075683594, 'loss_4': 1.1140285730361938, 'epoch': 10.34}
{'loss': 0.0096, 'grad_norm': 5.140864372253418, 'learning_rate': 1.9680232558139536e-05, 'loss_1': 0.005478695500642061, 'loss_2': 0.00408172607421875, 'loss_3': -16.24368667602539, 'loss_4': 1.3504223823547363, 'epoch': 10.34}
{'loss': 0.0103, 'grad_norm': 6.278583526611328, 'learning_rate': 1.9674418604651164e-05, 'loss_1': 0.009355324320495129, 'loss_2': 0.0009145736694335938, 'loss_3': -16.078380584716797, 'loss_4': 1.2501636743545532, 'epoch': 10.35}
[INFO|trainer.py:4228] 2025-01-21 13:04:28,873 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:28,873 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                | 1785/5160 [44:33<58:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:36,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01444051880389452, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.716, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009161754511296749, 'eval_loss_2': 0.00527876615524292, 'eval_loss_3': -18.211286544799805, 'eval_loss_4': 1.2139626741409302, 'epoch': 10.35}
{'loss': 0.0122, 'grad_norm': 5.461650371551514, 'learning_rate': 1.9668604651162793e-05, 'loss_1': 0.0071613984182477, 'loss_2': 0.00504302978515625, 'loss_3': -16.21404266357422, 'loss_4': 1.6964846849441528, 'epoch': 10.35}
{'loss': 0.0239, 'grad_norm': 6.141101360321045, 'learning_rate': 1.9662790697674418e-05, 'loss_1': 0.016239561140537262, 'loss_2': 0.00762176513671875, 'loss_3': -16.18629264831543, 'loss_4': 1.2430799007415771, 'epoch': 10.36}
{'loss': 0.0325, 'grad_norm': 15.936362266540527, 'learning_rate': 1.9656976744186047e-05, 'loss_1': 0.029251577332615852, 'loss_2': 0.003265380859375, 'loss_3': -16.40851402282715, 'loss_4': 1.3228546380996704, 'epoch': 10.37}
{'loss': 0.0259, 'grad_norm': 10.38615894317627, 'learning_rate': 1.9651162790697676e-05, 'loss_1': 0.024328982457518578, 'loss_2': 0.0015735626220703125, 'loss_3': -16.14822769165039, 'loss_4': 1.1929136514663696, 'epoch': 10.37}
{'loss': 0.0253, 'grad_norm': 6.743485927581787, 'learning_rate': 1.9645348837209304e-05, 'loss_1': 0.01381381880491972, 'loss_2': 0.0114593505859375, 'loss_3': -16.411787033081055, 'loss_4': 1.4987413883209229, 'epoch': 10.38}
[INFO|trainer.py:4228] 2025-01-21 13:04:36,244 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:36,244 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                | 1790/5160 [44:40<58:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:43,621 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01790359988808632, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013825925998389721, 'eval_loss_2': 0.0040776729583740234, 'eval_loss_3': -18.210737228393555, 'eval_loss_4': 1.2891227006912231, 'epoch': 10.38}
{'loss': 0.0243, 'grad_norm': 8.808486938476562, 'learning_rate': 1.963953488372093e-05, 'loss_1': 0.016971459612250328, 'loss_2': 0.00737762451171875, 'loss_3': -16.25933265686035, 'loss_4': 1.3572118282318115, 'epoch': 10.38}
{'loss': 0.0146, 'grad_norm': 6.493552207946777, 'learning_rate': 1.9633720930232558e-05, 'loss_1': 0.011563128791749477, 'loss_2': 0.002994537353515625, 'loss_3': -16.319217681884766, 'loss_4': 1.8548882007598877, 'epoch': 10.39}
{'loss': 0.0103, 'grad_norm': 5.022851467132568, 'learning_rate': 1.9627906976744187e-05, 'loss_1': 0.00798096228390932, 'loss_2': 0.00229644775390625, 'loss_3': -16.16376495361328, 'loss_4': 1.549487829208374, 'epoch': 10.4}
{'loss': 0.0214, 'grad_norm': 8.216651916503906, 'learning_rate': 1.9622093023255815e-05, 'loss_1': 0.01354481652379036, 'loss_2': 0.007843017578125, 'loss_3': -16.100065231323242, 'loss_4': 1.3763158321380615, 'epoch': 10.4}
{'loss': 0.016, 'grad_norm': 11.397603034973145, 'learning_rate': 1.9616279069767444e-05, 'loss_1': 0.013938717544078827, 'loss_2': 0.002079010009765625, 'loss_3': -16.263816833496094, 'loss_4': 1.874911904335022, 'epoch': 10.41}
[INFO|trainer.py:4228] 2025-01-21 13:04:43,621 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:43,621 >>   Batch size = 64
 35%|████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 1795/5160 [44:48<58:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:50,991 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018769709393382072, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.029, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.013655751943588257, 'eval_loss_2': 0.005113959312438965, 'eval_loss_3': -18.183494567871094, 'eval_loss_4': 1.6008206605911255, 'epoch': 10.41}
{'loss': 0.0223, 'grad_norm': 15.121048927307129, 'learning_rate': 1.961046511627907e-05, 'loss_1': 0.02005751058459282, 'loss_2': 0.0022430419921875, 'loss_3': -16.20724868774414, 'loss_4': 1.4889938831329346, 'epoch': 10.41}
{'loss': 0.0283, 'grad_norm': 9.497845649719238, 'learning_rate': 1.9604651162790698e-05, 'loss_1': 0.021364254876971245, 'loss_2': 0.00696563720703125, 'loss_3': -16.050804138183594, 'loss_4': 0.992145836353302, 'epoch': 10.42}
{'loss': 0.0224, 'grad_norm': 6.189539909362793, 'learning_rate': 1.9598837209302326e-05, 'loss_1': 0.010904067195951939, 'loss_2': 0.011505126953125, 'loss_3': -16.195009231567383, 'loss_4': 2.0722012519836426, 'epoch': 10.42}
{'loss': 0.0529, 'grad_norm': 20.32180404663086, 'learning_rate': 1.9593023255813955e-05, 'loss_1': 0.050666291266679764, 'loss_2': 0.002208709716796875, 'loss_3': -16.049732208251953, 'loss_4': 1.721937894821167, 'epoch': 10.43}
{'loss': 0.0155, 'grad_norm': 7.600459575653076, 'learning_rate': 1.9587209302325584e-05, 'loss_1': 0.010792242363095284, 'loss_2': 0.00472259521484375, 'loss_3': -16.362668991088867, 'loss_4': 1.802835464477539, 'epoch': 10.44}
[INFO|trainer.py:4228] 2025-01-21 13:04:50,991 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:50,991 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                | 1800/5160 [44:55<58:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:04:58,366 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01749316044151783, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.45, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01317442674189806, 'eval_loss_2': 0.0043187327682971954, 'eval_loss_3': -18.209909439086914, 'eval_loss_4': 1.6945568323135376, 'epoch': 10.44}
{'loss': 0.0227, 'grad_norm': 8.12576675415039, 'learning_rate': 1.958139534883721e-05, 'loss_1': 0.02078077383339405, 'loss_2': 0.0019397735595703125, 'loss_3': -16.0076847076416, 'loss_4': 1.63826584815979, 'epoch': 10.44}
{'loss': 0.0148, 'grad_norm': 5.5049285888671875, 'learning_rate': 1.9575581395348838e-05, 'loss_1': 0.01270598266273737, 'loss_2': 0.0020961761474609375, 'loss_3': -16.074573516845703, 'loss_4': 1.1318893432617188, 'epoch': 10.45}
{'loss': 0.0104, 'grad_norm': 6.440258502960205, 'learning_rate': 1.9569767441860463e-05, 'loss_1': 0.009924842044711113, 'loss_2': 0.0004436969757080078, 'loss_3': -16.258758544921875, 'loss_4': 1.407482385635376, 'epoch': 10.45}
{'loss': 0.0137, 'grad_norm': 6.333527565002441, 'learning_rate': 1.9563953488372095e-05, 'loss_1': 0.012238126248121262, 'loss_2': 0.001453399658203125, 'loss_3': -16.225004196166992, 'loss_4': 1.943466067314148, 'epoch': 10.46}
{'loss': 0.0113, 'grad_norm': 4.6697611808776855, 'learning_rate': 1.9558139534883723e-05, 'loss_1': 0.008713314309716225, 'loss_2': 0.00254058837890625, 'loss_3': -16.422042846679688, 'loss_4': 2.2174124717712402, 'epoch': 10.47}
[INFO|trainer.py:4228] 2025-01-21 13:04:58,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:04:58,367 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▎                                                                                                                                               | 1805/5160 [45:02<58:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:05,742 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016601596027612686, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.685, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.011886398307979107, 'eval_loss_2': 0.004715196788311005, 'eval_loss_3': -18.212827682495117, 'eval_loss_4': 1.737046480178833, 'epoch': 10.47}
{'loss': 0.0087, 'grad_norm': 5.162413120269775, 'learning_rate': 1.955232558139535e-05, 'loss_1': 0.006741305813193321, 'loss_2': 0.0019855499267578125, 'loss_3': -16.368104934692383, 'loss_4': 1.843802571296692, 'epoch': 10.47}
{'loss': 0.0099, 'grad_norm': 4.83601713180542, 'learning_rate': 1.9546511627906977e-05, 'loss_1': 0.007545644883066416, 'loss_2': 0.00240325927734375, 'loss_3': -16.133447647094727, 'loss_4': 2.2575132846832275, 'epoch': 10.48}
{'loss': 0.0264, 'grad_norm': 10.001215934753418, 'learning_rate': 1.9540697674418603e-05, 'loss_1': 0.02107219584286213, 'loss_2': 0.0052947998046875, 'loss_3': -16.182636260986328, 'loss_4': 1.5392793416976929, 'epoch': 10.48}
{'loss': 0.0395, 'grad_norm': 18.461503982543945, 'learning_rate': 1.9534883720930235e-05, 'loss_1': 0.03137287497520447, 'loss_2': 0.00811767578125, 'loss_3': -16.480300903320312, 'loss_4': 1.7814445495605469, 'epoch': 10.49}
{'loss': 0.0214, 'grad_norm': 5.235758304595947, 'learning_rate': 1.9529069767441863e-05, 'loss_1': 0.010568290948867798, 'loss_2': 0.0108184814453125, 'loss_3': -16.170625686645508, 'loss_4': 1.9165397882461548, 'epoch': 10.49}
[INFO|trainer.py:4228] 2025-01-21 13:05:05,742 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:05,743 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▌                                                                                                                                               | 1810/5160 [45:10<58:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:13,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016969412565231323, 'eval_runtime': 3.8216, 'eval_samples_per_second': 267.951, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.01070126798003912, 'eval_loss_2': 0.006268143653869629, 'eval_loss_3': -18.224544525146484, 'eval_loss_4': 1.7782613039016724, 'epoch': 10.49}
{'loss': 0.0311, 'grad_norm': 10.497780799865723, 'learning_rate': 1.952325581395349e-05, 'loss_1': 0.03007359616458416, 'loss_2': 0.0010318756103515625, 'loss_3': -16.1879825592041, 'loss_4': 0.9796033501625061, 'epoch': 10.5}
{'loss': 0.0115, 'grad_norm': 4.7793989181518555, 'learning_rate': 1.9517441860465117e-05, 'loss_1': 0.007866594940423965, 'loss_2': 0.0036773681640625, 'loss_3': -16.397459030151367, 'loss_4': 2.121532917022705, 'epoch': 10.51}
{'loss': 0.0174, 'grad_norm': 5.938838958740234, 'learning_rate': 1.9511627906976742e-05, 'loss_1': 0.011102558113634586, 'loss_2': 0.0063323974609375, 'loss_3': -16.323402404785156, 'loss_4': 2.0800600051879883, 'epoch': 10.51}
{'loss': 0.0125, 'grad_norm': 7.05664587020874, 'learning_rate': 1.9505813953488374e-05, 'loss_1': 0.011310695670545101, 'loss_2': 0.0011806488037109375, 'loss_3': -16.20823097229004, 'loss_4': 1.913375973701477, 'epoch': 10.52}
{'loss': 0.007, 'grad_norm': 5.6546630859375, 'learning_rate': 1.95e-05, 'loss_1': 0.006588560063391924, 'loss_2': 0.0004203319549560547, 'loss_3': -16.119709014892578, 'loss_4': 2.082181930541992, 'epoch': 10.52}
[INFO|trainer.py:4228] 2025-01-21 13:05:13,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:13,129 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▋                                                                                                                                               | 1815/5160 [45:17<58:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:20,495 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012406459078192711, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.901, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009217904880642891, 'eval_loss_2': 0.00318855419754982, 'eval_loss_3': -18.235958099365234, 'eval_loss_4': 1.7181402444839478, 'epoch': 10.52}
{'loss': 0.0114, 'grad_norm': 5.238957405090332, 'learning_rate': 1.9494186046511628e-05, 'loss_1': 0.009208264760673046, 'loss_2': 0.00222015380859375, 'loss_3': -16.065858840942383, 'loss_4': 1.7254102230072021, 'epoch': 10.53}
{'loss': 0.0201, 'grad_norm': 5.316769599914551, 'learning_rate': 1.9488372093023257e-05, 'loss_1': 0.00944766029715538, 'loss_2': 0.0106658935546875, 'loss_3': -16.177616119384766, 'loss_4': 1.9074516296386719, 'epoch': 10.53}
{'loss': 0.0444, 'grad_norm': 13.258858680725098, 'learning_rate': 1.9482558139534882e-05, 'loss_1': 0.032277029007673264, 'loss_2': 0.01214599609375, 'loss_3': -16.260665893554688, 'loss_4': 2.37182879447937, 'epoch': 10.54}
{'loss': 0.0202, 'grad_norm': 8.98892593383789, 'learning_rate': 1.9476744186046514e-05, 'loss_1': 0.020122293382883072, 'loss_2': 0.00012218952178955078, 'loss_3': -16.22232437133789, 'loss_4': 1.308822512626648, 'epoch': 10.55}
{'loss': 0.013, 'grad_norm': 5.5292253494262695, 'learning_rate': 1.947093023255814e-05, 'loss_1': 0.007162468042224646, 'loss_2': 0.00580596923828125, 'loss_3': -16.319076538085938, 'loss_4': 1.8704745769500732, 'epoch': 10.55}
[INFO|trainer.py:4228] 2025-01-21 13:05:20,495 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:20,495 >>   Batch size = 64
 35%|█████████████████████████████████████████████████████████████████████████████▉                                                                                                                                               | 1820/5160 [45:25<57:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:27,861 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012472396716475487, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.064, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009274987503886223, 'eval_loss_2': 0.003197409212589264, 'eval_loss_3': -18.24433708190918, 'eval_loss_4': 1.7435067892074585, 'epoch': 10.55}
{'loss': 0.0129, 'grad_norm': 4.940969944000244, 'learning_rate': 1.9465116279069768e-05, 'loss_1': 0.012138263322412968, 'loss_2': 0.0007886886596679688, 'loss_3': -16.222871780395508, 'loss_4': 2.422593593597412, 'epoch': 10.56}
{'loss': 0.0227, 'grad_norm': 6.439106464385986, 'learning_rate': 1.9459302325581397e-05, 'loss_1': 0.014715688303112984, 'loss_2': 0.008026123046875, 'loss_3': -16.35296630859375, 'loss_4': 2.423323631286621, 'epoch': 10.56}
{'loss': 0.0172, 'grad_norm': 6.502178192138672, 'learning_rate': 1.9453488372093022e-05, 'loss_1': 0.013685562647879124, 'loss_2': 0.003543853759765625, 'loss_3': -16.290687561035156, 'loss_4': 2.1414973735809326, 'epoch': 10.57}
{'loss': 0.0348, 'grad_norm': 15.6129150390625, 'learning_rate': 1.9447674418604654e-05, 'loss_1': 0.0318051278591156, 'loss_2': 0.0030155181884765625, 'loss_3': -16.10227394104004, 'loss_4': 1.5196890830993652, 'epoch': 10.58}
{'loss': 0.0172, 'grad_norm': 9.18832015991211, 'learning_rate': 1.944186046511628e-05, 'loss_1': 0.012769012711942196, 'loss_2': 0.004436492919921875, 'loss_3': -16.327083587646484, 'loss_4': 1.8094227313995361, 'epoch': 10.58}
[INFO|trainer.py:4228] 2025-01-21 13:05:27,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:27,862 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▏                                                                                                                                              | 1825/5160 [45:32<57:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:35,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01800559088587761, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.638, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00948296021670103, 'eval_loss_2': 0.008522629737854004, 'eval_loss_3': -18.25969696044922, 'eval_loss_4': 1.7731739282608032, 'epoch': 10.58}
{'loss': 0.022, 'grad_norm': 7.485236644744873, 'learning_rate': 1.9436046511627908e-05, 'loss_1': 0.01123865321278572, 'loss_2': 0.01078033447265625, 'loss_3': -16.33193016052246, 'loss_4': 1.635145902633667, 'epoch': 10.59}
{'loss': 0.0139, 'grad_norm': 5.1414923667907715, 'learning_rate': 1.9430232558139533e-05, 'loss_1': 0.006668708752840757, 'loss_2': 0.0072174072265625, 'loss_3': -16.385047912597656, 'loss_4': 1.9799659252166748, 'epoch': 10.59}
{'loss': 0.0236, 'grad_norm': 8.374554634094238, 'learning_rate': 1.9424418604651162e-05, 'loss_1': 0.015886975452303886, 'loss_2': 0.00775909423828125, 'loss_3': -16.167940139770508, 'loss_4': 2.085855007171631, 'epoch': 10.6}
{'loss': 0.015, 'grad_norm': 5.326418876647949, 'learning_rate': 1.9418604651162794e-05, 'loss_1': 0.007746199145913124, 'loss_2': 0.0072174072265625, 'loss_3': -16.08453369140625, 'loss_4': 1.910831093788147, 'epoch': 10.6}
{'loss': 0.0319, 'grad_norm': 11.457367897033691, 'learning_rate': 1.941279069767442e-05, 'loss_1': 0.021257098764181137, 'loss_2': 0.0106658935546875, 'loss_3': -15.971146583557129, 'loss_4': 1.8632380962371826, 'epoch': 10.61}
[INFO|trainer.py:4228] 2025-01-21 13:05:35,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:35,240 >>   Batch size = 64
 35%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                                                              | 1830/5160 [45:39<57:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:42,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015837596729397774, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.019, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00846028607338667, 'eval_loss_2': 0.007377311587333679, 'eval_loss_3': -18.25887107849121, 'eval_loss_4': 1.8731474876403809, 'epoch': 10.61}
{'loss': 0.0214, 'grad_norm': 7.611781120300293, 'learning_rate': 1.9406976744186048e-05, 'loss_1': 0.011520245112478733, 'loss_2': 0.00989532470703125, 'loss_3': -16.519451141357422, 'loss_4': 2.3941268920898438, 'epoch': 10.62}
{'loss': 0.0235, 'grad_norm': 6.809321403503418, 'learning_rate': 1.9401162790697673e-05, 'loss_1': 0.012837010435760021, 'loss_2': 0.0106964111328125, 'loss_3': -16.096160888671875, 'loss_4': 1.8356019258499146, 'epoch': 10.62}
{'loss': 0.0396, 'grad_norm': 24.499420166015625, 'learning_rate': 1.93953488372093e-05, 'loss_1': 0.03601129725575447, 'loss_2': 0.00359344482421875, 'loss_3': -16.290782928466797, 'loss_4': 1.5762779712677002, 'epoch': 10.63}
{'loss': 0.0208, 'grad_norm': 6.77936315536499, 'learning_rate': 1.9389534883720933e-05, 'loss_1': 0.013231894932687283, 'loss_2': 0.007595062255859375, 'loss_3': -16.03656768798828, 'loss_4': 2.0525074005126953, 'epoch': 10.63}
{'loss': 0.0142, 'grad_norm': 5.4635748863220215, 'learning_rate': 1.938372093023256e-05, 'loss_1': 0.013353158719837666, 'loss_2': 0.0008931159973144531, 'loss_3': -16.230680465698242, 'loss_4': 2.395484209060669, 'epoch': 10.64}
[INFO|trainer.py:4228] 2025-01-21 13:05:42,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:42,607 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 1835/5160 [45:47<57:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:49,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010061750188469887, 'eval_runtime': 3.8179, 'eval_samples_per_second': 268.213, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.007369085215032101, 'eval_loss_2': 0.0026926659047603607, 'eval_loss_3': -18.27048110961914, 'eval_loss_4': 1.9010908603668213, 'epoch': 10.64}
{'loss': 0.0289, 'grad_norm': 11.104155540466309, 'learning_rate': 1.9377906976744187e-05, 'loss_1': 0.022189820185303688, 'loss_2': 0.00673675537109375, 'loss_3': -16.148815155029297, 'loss_4': 2.440983295440674, 'epoch': 10.65}
{'loss': 0.0174, 'grad_norm': 9.066925048828125, 'learning_rate': 1.9372093023255813e-05, 'loss_1': 0.016902552917599678, 'loss_2': 0.0005340576171875, 'loss_3': -16.148754119873047, 'loss_4': 2.2155511379241943, 'epoch': 10.65}
{'loss': 0.0495, 'grad_norm': 15.838808059692383, 'learning_rate': 1.936627906976744e-05, 'loss_1': 0.04892827942967415, 'loss_2': 0.0006022453308105469, 'loss_3': -16.14042854309082, 'loss_4': 2.3310506343841553, 'epoch': 10.66}
{'loss': 0.0217, 'grad_norm': 10.826215744018555, 'learning_rate': 1.936046511627907e-05, 'loss_1': 0.020735150203108788, 'loss_2': 0.0009908676147460938, 'loss_3': -16.106388092041016, 'loss_4': 2.04232120513916, 'epoch': 10.66}
{'loss': 0.0167, 'grad_norm': 6.525904655456543, 'learning_rate': 1.93546511627907e-05, 'loss_1': 0.013648610562086105, 'loss_2': 0.003086090087890625, 'loss_3': -16.310909271240234, 'loss_4': 2.615774631500244, 'epoch': 10.67}
[INFO|trainer.py:4228] 2025-01-21 13:05:49,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:49,982 >>   Batch size = 64
 36%|██████████████████████████████████████████████████████████████████████████████▊                                                                                                                                              | 1840/5160 [45:54<57:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:05:57,355 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012639250606298447, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.365, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.0074213347397744656, 'eval_loss_2': 0.005217917263507843, 'eval_loss_3': -18.30782127380371, 'eval_loss_4': 1.9457300901412964, 'epoch': 10.67}
{'loss': 0.0196, 'grad_norm': 15.767910957336426, 'learning_rate': 1.9348837209302327e-05, 'loss_1': 0.017510082572698593, 'loss_2': 0.0020427703857421875, 'loss_3': -16.058732986450195, 'loss_4': 1.942452311515808, 'epoch': 10.67}
{'loss': 0.0416, 'grad_norm': 9.257767677307129, 'learning_rate': 1.9343023255813952e-05, 'loss_1': 0.0334603525698185, 'loss_2': 0.0081329345703125, 'loss_3': -16.000904083251953, 'loss_4': 2.166787624359131, 'epoch': 10.68}
{'loss': 0.0254, 'grad_norm': 8.426112174987793, 'learning_rate': 1.933720930232558e-05, 'loss_1': 0.0216151662170887, 'loss_2': 0.00374603271484375, 'loss_3': -16.353439331054688, 'loss_4': 2.1865570545196533, 'epoch': 10.69}
{'loss': 0.0107, 'grad_norm': 5.431588172912598, 'learning_rate': 1.933139534883721e-05, 'loss_1': 0.00808953307569027, 'loss_2': 0.002651214599609375, 'loss_3': -16.135210037231445, 'loss_4': 2.3663883209228516, 'epoch': 10.69}
{'loss': 0.0099, 'grad_norm': 4.845659255981445, 'learning_rate': 1.9325581395348838e-05, 'loss_1': 0.007459576707333326, 'loss_2': 0.0024871826171875, 'loss_3': -16.306026458740234, 'loss_4': 2.2236413955688477, 'epoch': 10.7}
[INFO|trainer.py:4228] 2025-01-21 13:05:57,355 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:05:57,355 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████                                                                                                                                              | 1845/5160 [46:01<57:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:04,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012725704349577427, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.645, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008891025558114052, 'eval_loss_2': 0.0038346797227859497, 'eval_loss_3': -18.301918029785156, 'eval_loss_4': 1.8537293672561646, 'epoch': 10.7}
{'loss': 0.0077, 'grad_norm': 5.16489839553833, 'learning_rate': 1.9319767441860467e-05, 'loss_1': 0.0075370799750089645, 'loss_2': 0.00016498565673828125, 'loss_3': -16.359813690185547, 'loss_4': 1.7413357496261597, 'epoch': 10.7}
{'loss': 0.0173, 'grad_norm': 7.598604202270508, 'learning_rate': 1.9313953488372092e-05, 'loss_1': 0.01593770459294319, 'loss_2': 0.001392364501953125, 'loss_3': -16.134191513061523, 'loss_4': 1.8028676509857178, 'epoch': 10.71}
{'loss': 0.0112, 'grad_norm': 4.798932075500488, 'learning_rate': 1.9308139534883724e-05, 'loss_1': 0.008190544322133064, 'loss_2': 0.003032684326171875, 'loss_3': -16.339847564697266, 'loss_4': 1.6676170825958252, 'epoch': 10.72}
{'loss': 0.0505, 'grad_norm': 48.04210662841797, 'learning_rate': 1.930232558139535e-05, 'loss_1': 0.041796308010816574, 'loss_2': 0.0087432861328125, 'loss_3': -16.144718170166016, 'loss_4': 1.6412127017974854, 'epoch': 10.72}
{'loss': 0.0213, 'grad_norm': 9.440796852111816, 'learning_rate': 1.9296511627906978e-05, 'loss_1': 0.015226416289806366, 'loss_2': 0.00604248046875, 'loss_3': -16.348831176757812, 'loss_4': 2.3291592597961426, 'epoch': 10.73}
[INFO|trainer.py:4228] 2025-01-21 13:06:04,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:04,733 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▏                                                                                                                                             | 1850/5160 [46:09<57:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:12,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02343440055847168, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008099796250462532, 'eval_loss_2': 0.015334606170654297, 'eval_loss_3': -18.322479248046875, 'eval_loss_4': 1.7963589429855347, 'epoch': 10.73}
{'loss': 0.0389, 'grad_norm': 15.607357025146484, 'learning_rate': 1.9290697674418603e-05, 'loss_1': 0.023221801966428757, 'loss_2': 0.01568603515625, 'loss_3': -16.194644927978516, 'loss_4': 2.2574257850646973, 'epoch': 10.73}
{'loss': 0.0355, 'grad_norm': 6.154271125793457, 'learning_rate': 1.9284883720930232e-05, 'loss_1': 0.013986933045089245, 'loss_2': 0.0215301513671875, 'loss_3': -16.492332458496094, 'loss_4': 2.794772148132324, 'epoch': 10.74}
{'loss': 0.048, 'grad_norm': 8.01961612701416, 'learning_rate': 1.9279069767441864e-05, 'loss_1': 0.03256579488515854, 'loss_2': 0.0154571533203125, 'loss_3': -16.346006393432617, 'loss_4': 1.9382050037384033, 'epoch': 10.74}
{'loss': 0.0332, 'grad_norm': 7.343425750732422, 'learning_rate': 1.927325581395349e-05, 'loss_1': 0.01705462485551834, 'loss_2': 0.0161285400390625, 'loss_3': -16.272035598754883, 'loss_4': 2.1345067024230957, 'epoch': 10.75}
{'loss': 0.0877, 'grad_norm': 23.815696716308594, 'learning_rate': 1.9267441860465118e-05, 'loss_1': 0.06842992454767227, 'loss_2': 0.019287109375, 'loss_3': -16.30682373046875, 'loss_4': 2.3817367553710938, 'epoch': 10.76}
[INFO|trainer.py:4228] 2025-01-21 13:06:12,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:12,096 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                                             | 1855/5160 [46:16<57:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:19,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023227423429489136, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.743, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008835048414766788, 'eval_loss_2': 0.014392375946044922, 'eval_loss_3': -18.326183319091797, 'eval_loss_4': 1.6558232307434082, 'epoch': 10.76}
{'loss': 0.0216, 'grad_norm': 5.177365303039551, 'learning_rate': 1.9261627906976743e-05, 'loss_1': 0.005946051329374313, 'loss_2': 0.015625, 'loss_3': -16.293094635009766, 'loss_4': 2.069550037384033, 'epoch': 10.76}
{'loss': 0.0188, 'grad_norm': 5.813928604125977, 'learning_rate': 1.9255813953488372e-05, 'loss_1': 0.011034986935555935, 'loss_2': 0.0077667236328125, 'loss_3': -16.378158569335938, 'loss_4': 1.3784793615341187, 'epoch': 10.77}
{'loss': 0.0213, 'grad_norm': 6.7564496994018555, 'learning_rate': 1.9250000000000004e-05, 'loss_1': 0.015614185482263565, 'loss_2': 0.005641937255859375, 'loss_3': -16.240745544433594, 'loss_4': 1.9026768207550049, 'epoch': 10.77}
{'loss': 0.0203, 'grad_norm': 5.1595001220703125, 'learning_rate': 1.924418604651163e-05, 'loss_1': 0.007487988565117121, 'loss_2': 0.012847900390625, 'loss_3': -16.383594512939453, 'loss_4': 2.1123316287994385, 'epoch': 10.78}
{'loss': 0.0148, 'grad_norm': 5.560762405395508, 'learning_rate': 1.9238372093023258e-05, 'loss_1': 0.00900037307292223, 'loss_2': 0.0057525634765625, 'loss_3': -16.33790397644043, 'loss_4': 1.6418304443359375, 'epoch': 10.78}
[INFO|trainer.py:4228] 2025-01-21 13:06:19,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:19,461 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▋                                                                                                                                             | 1860/5160 [46:23<57:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:26,835 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014006208628416061, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.738, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008919847197830677, 'eval_loss_2': 0.005086362361907959, 'eval_loss_3': -18.312984466552734, 'eval_loss_4': 1.5853317975997925, 'epoch': 10.78}
{'loss': 0.0122, 'grad_norm': 5.177640438079834, 'learning_rate': 1.9232558139534883e-05, 'loss_1': 0.008158876560628414, 'loss_2': 0.00400543212890625, 'loss_3': -16.36827850341797, 'loss_4': 1.7852909564971924, 'epoch': 10.79}
{'loss': 0.012, 'grad_norm': 5.7875142097473145, 'learning_rate': 1.922674418604651e-05, 'loss_1': 0.011950653046369553, 'loss_2': 8.106231689453125e-06, 'loss_3': -16.19158935546875, 'loss_4': 2.1622252464294434, 'epoch': 10.8}
{'loss': 0.0132, 'grad_norm': 6.020989894866943, 'learning_rate': 1.922093023255814e-05, 'loss_1': 0.01226518303155899, 'loss_2': 0.0009069442749023438, 'loss_3': -16.53430938720703, 'loss_4': 1.493238925933838, 'epoch': 10.8}
{'loss': 0.0222, 'grad_norm': 5.969219207763672, 'learning_rate': 1.921511627906977e-05, 'loss_1': 0.011621156707406044, 'loss_2': 0.0105438232421875, 'loss_3': -16.223224639892578, 'loss_4': 1.4314792156219482, 'epoch': 10.81}
{'loss': 0.0128, 'grad_norm': 6.3081231117248535, 'learning_rate': 1.9209302325581397e-05, 'loss_1': 0.012020633555948734, 'loss_2': 0.00078582763671875, 'loss_3': -16.386962890625, 'loss_4': 1.1778044700622559, 'epoch': 10.81}
[INFO|trainer.py:4228] 2025-01-21 13:06:26,835 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:26,835 >>   Batch size = 64
 36%|███████████████████████████████████████████████████████████████████████████████▉                                                                                                                                             | 1865/5160 [46:31<57:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:34,219 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01463159266859293, 'eval_runtime': 3.8169, 'eval_samples_per_second': 268.277, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.010191387496888638, 'eval_loss_2': 0.004440203309059143, 'eval_loss_3': -18.30450439453125, 'eval_loss_4': 1.6224901676177979, 'epoch': 10.81}
{'loss': 0.0261, 'grad_norm': 6.016249656677246, 'learning_rate': 1.9203488372093023e-05, 'loss_1': 0.01283179223537445, 'loss_2': 0.01329803466796875, 'loss_3': -16.09496307373047, 'loss_4': 1.8112270832061768, 'epoch': 10.82}
{'loss': 0.014, 'grad_norm': 5.093620777130127, 'learning_rate': 1.919767441860465e-05, 'loss_1': 0.008540905080735683, 'loss_2': 0.0054473876953125, 'loss_3': -16.45522689819336, 'loss_4': 1.5984820127487183, 'epoch': 10.83}
{'loss': 0.0136, 'grad_norm': 7.308303356170654, 'learning_rate': 1.919186046511628e-05, 'loss_1': 0.009405452758073807, 'loss_2': 0.004154205322265625, 'loss_3': -16.222332000732422, 'loss_4': 1.5113695859909058, 'epoch': 10.83}
{'loss': 0.0161, 'grad_norm': 6.1424431800842285, 'learning_rate': 1.918604651162791e-05, 'loss_1': 0.014234215952455997, 'loss_2': 0.0018310546875, 'loss_3': -16.165109634399414, 'loss_4': 1.4340404272079468, 'epoch': 10.84}
{'loss': 0.0136, 'grad_norm': 6.556893348693848, 'learning_rate': 1.9180232558139537e-05, 'loss_1': 0.011751030571758747, 'loss_2': 0.0018367767333984375, 'loss_3': -16.368940353393555, 'loss_4': 1.20125150680542, 'epoch': 10.84}
[INFO|trainer.py:4228] 2025-01-21 13:06:34,219 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:34,219 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████                                                                                                                                             | 1870/5160 [46:38<57:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:41,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016657575964927673, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012292786501348019, 'eval_loss_2': 0.00436478853225708, 'eval_loss_3': -18.291566848754883, 'eval_loss_4': 1.4281007051467896, 'epoch': 10.84}
{'loss': 0.014, 'grad_norm': 6.597074508666992, 'learning_rate': 1.9174418604651162e-05, 'loss_1': 0.010430566035211086, 'loss_2': 0.0035762786865234375, 'loss_3': -16.354881286621094, 'loss_4': 1.332385540008545, 'epoch': 10.85}
{'loss': 0.0102, 'grad_norm': 5.423391819000244, 'learning_rate': 1.916860465116279e-05, 'loss_1': 0.0086731668561697, 'loss_2': 0.0015716552734375, 'loss_3': -16.204317092895508, 'loss_4': 1.3809715509414673, 'epoch': 10.85}
{'loss': 0.0171, 'grad_norm': 6.5707807540893555, 'learning_rate': 1.916279069767442e-05, 'loss_1': 0.011595471762120724, 'loss_2': 0.0055389404296875, 'loss_3': -16.226741790771484, 'loss_4': 1.3171322345733643, 'epoch': 10.86}
{'loss': 0.0353, 'grad_norm': 9.193343162536621, 'learning_rate': 1.9156976744186048e-05, 'loss_1': 0.02898990735411644, 'loss_2': 0.00628662109375, 'loss_3': -16.454599380493164, 'loss_4': 1.7189960479736328, 'epoch': 10.87}
{'loss': 0.0125, 'grad_norm': 5.341820240020752, 'learning_rate': 1.9151162790697674e-05, 'loss_1': 0.00997843686491251, 'loss_2': 0.0025653839111328125, 'loss_3': -16.185924530029297, 'loss_4': 1.448810338973999, 'epoch': 10.87}
[INFO|trainer.py:4228] 2025-01-21 13:06:41,587 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:41,587 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                            | 1875/5160 [46:46<57:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:48,961 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0165930837392807, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.502, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01275803241878748, 'eval_loss_2': 0.003835052251815796, 'eval_loss_3': -18.26746940612793, 'eval_loss_4': 1.2772849798202515, 'epoch': 10.87}
{'loss': 0.0158, 'grad_norm': 5.320642948150635, 'learning_rate': 1.9145348837209302e-05, 'loss_1': 0.012677328661084175, 'loss_2': 0.0030975341796875, 'loss_3': -16.398258209228516, 'loss_4': 1.3758600950241089, 'epoch': 10.88}
{'loss': 0.0197, 'grad_norm': 8.581388473510742, 'learning_rate': 1.913953488372093e-05, 'loss_1': 0.01878213882446289, 'loss_2': 0.0009417533874511719, 'loss_3': -16.13324546813965, 'loss_4': 1.8244097232818604, 'epoch': 10.88}
{'loss': 0.0283, 'grad_norm': 9.379902839660645, 'learning_rate': 1.913372093023256e-05, 'loss_1': 0.027684617787599564, 'loss_2': 0.0006046295166015625, 'loss_3': -16.233129501342773, 'loss_4': 1.664381504058838, 'epoch': 10.89}
{'loss': 0.0134, 'grad_norm': 4.991721153259277, 'learning_rate': 1.9127906976744188e-05, 'loss_1': 0.009602890349924564, 'loss_2': 0.0038299560546875, 'loss_3': -16.324695587158203, 'loss_4': 0.6330713629722595, 'epoch': 10.9}
{'loss': 0.0164, 'grad_norm': 6.48356819152832, 'learning_rate': 1.9122093023255813e-05, 'loss_1': 0.014385427348315716, 'loss_2': 0.0020198822021484375, 'loss_3': -16.344314575195312, 'loss_4': 1.6906781196594238, 'epoch': 10.9}
[INFO|trainer.py:4228] 2025-01-21 13:06:48,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:48,962 >>   Batch size = 64
 36%|████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                            | 1880/5160 [46:53<56:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:06:56,327 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016632629558444023, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.84, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012249993160367012, 'eval_loss_2': 0.00438264012336731, 'eval_loss_3': -18.262062072753906, 'eval_loss_4': 1.0704632997512817, 'epoch': 10.9}
{'loss': 0.0231, 'grad_norm': 11.673666954040527, 'learning_rate': 1.9116279069767442e-05, 'loss_1': 0.020006146281957626, 'loss_2': 0.0031414031982421875, 'loss_3': -16.33030891418457, 'loss_4': 1.3192195892333984, 'epoch': 10.91}
{'loss': 0.0128, 'grad_norm': 6.0122599601745605, 'learning_rate': 1.911046511627907e-05, 'loss_1': 0.012315066531300545, 'loss_2': 0.0005054473876953125, 'loss_3': -16.20258140563965, 'loss_4': 1.0714480876922607, 'epoch': 10.91}
{'loss': 0.0237, 'grad_norm': 6.118830680847168, 'learning_rate': 1.91046511627907e-05, 'loss_1': 0.01050450000911951, 'loss_2': 0.013214111328125, 'loss_3': -16.432292938232422, 'loss_4': 0.8743834495544434, 'epoch': 10.92}
{'loss': 0.0125, 'grad_norm': 6.426581859588623, 'learning_rate': 1.9098837209302328e-05, 'loss_1': 0.011318824253976345, 'loss_2': 0.0011510848999023438, 'loss_3': -16.258453369140625, 'loss_4': 0.6993352174758911, 'epoch': 10.92}
{'loss': 0.0238, 'grad_norm': 6.987051963806152, 'learning_rate': 1.9093023255813953e-05, 'loss_1': 0.017346106469631195, 'loss_2': 0.00644683837890625, 'loss_3': -16.472885131835938, 'loss_4': 0.5233430862426758, 'epoch': 10.93}
[INFO|trainer.py:4228] 2025-01-21 13:06:56,327 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:06:56,327 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                            | 1885/5160 [47:00<56:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:03,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014782794751226902, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.96, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011540466919541359, 'eval_loss_2': 0.0032423287630081177, 'eval_loss_3': -18.29018783569336, 'eval_loss_4': 0.7947440147399902, 'epoch': 10.93}
{'loss': 0.0116, 'grad_norm': 5.188889980316162, 'learning_rate': 1.9087209302325582e-05, 'loss_1': 0.007200164254754782, 'loss_2': 0.004436492919921875, 'loss_3': -16.496601104736328, 'loss_4': 0.881251335144043, 'epoch': 10.94}
{'loss': 0.0723, 'grad_norm': 25.68735694885254, 'learning_rate': 1.9081395348837207e-05, 'loss_1': 0.07147755473852158, 'loss_2': 0.0008687973022460938, 'loss_3': -16.236108779907227, 'loss_4': 0.30956506729125977, 'epoch': 10.94}
{'loss': 0.044, 'grad_norm': 15.125492095947266, 'learning_rate': 1.907558139534884e-05, 'loss_1': 0.03969905897974968, 'loss_2': 0.00432586669921875, 'loss_3': -16.307050704956055, 'loss_4': 0.7983838319778442, 'epoch': 10.95}
{'loss': 0.0092, 'grad_norm': 4.081284999847412, 'learning_rate': 1.9069767441860468e-05, 'loss_1': 0.005195926409214735, 'loss_2': 0.004001617431640625, 'loss_3': -16.371540069580078, 'loss_4': 1.0063560009002686, 'epoch': 10.95}
{'loss': 0.0204, 'grad_norm': 9.225037574768066, 'learning_rate': 1.9063953488372093e-05, 'loss_1': 0.014024271629750729, 'loss_2': 0.00640869140625, 'loss_3': -16.44158935546875, 'loss_4': 0.90418541431427, 'epoch': 10.96}
[INFO|trainer.py:4228] 2025-01-21 13:07:03,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:03,695 >>   Batch size = 64
 37%|████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                            | 1890/5160 [47:08<56:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:11,062 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018657026812434196, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.478, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.012275516986846924, 'eval_loss_2': 0.006381511688232422, 'eval_loss_3': -18.324689865112305, 'eval_loss_4': 0.6173954010009766, 'epoch': 10.96}
{'loss': 0.0325, 'grad_norm': 12.45352554321289, 'learning_rate': 1.905813953488372e-05, 'loss_1': 0.02779591828584671, 'loss_2': 0.004688262939453125, 'loss_3': -16.068340301513672, 'loss_4': 0.6991201639175415, 'epoch': 10.97}
{'loss': 0.0315, 'grad_norm': 19.402671813964844, 'learning_rate': 1.9052325581395347e-05, 'loss_1': 0.02266640216112137, 'loss_2': 0.0087890625, 'loss_3': -16.285282135009766, 'loss_4': 0.7087281942367554, 'epoch': 10.97}
{'loss': 0.0225, 'grad_norm': 6.650862216949463, 'learning_rate': 1.904651162790698e-05, 'loss_1': 0.013659090735018253, 'loss_2': 0.00885009765625, 'loss_3': -16.26076316833496, 'loss_4': 0.588913083076477, 'epoch': 10.98}
{'loss': 0.0282, 'grad_norm': 10.191797256469727, 'learning_rate': 1.9040697674418604e-05, 'loss_1': 0.020740272477269173, 'loss_2': 0.0074615478515625, 'loss_3': -16.429039001464844, 'loss_4': 0.42242008447647095, 'epoch': 10.98}
{'loss': 0.0173, 'grad_norm': 10.780129432678223, 'learning_rate': 1.9034883720930233e-05, 'loss_1': 0.016247712075710297, 'loss_2': 0.001003265380859375, 'loss_3': -16.192615509033203, 'loss_4': 0.5543098449707031, 'epoch': 10.99}
[INFO|trainer.py:4228] 2025-01-21 13:07:11,062 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:11,062 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                           | 1895/5160 [47:15<54:59,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:07:18,118 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017686018720269203, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.23, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.012138552963733673, 'eval_loss_2': 0.005547463893890381, 'eval_loss_3': -18.345718383789062, 'eval_loss_4': 0.7890918254852295, 'epoch': 10.99}
{'loss': 0.0173, 'grad_norm': 5.9245476722717285, 'learning_rate': 1.902906976744186e-05, 'loss_1': 0.010601041838526726, 'loss_2': 0.0066986083984375, 'loss_3': -16.278583526611328, 'loss_4': 1.2134627103805542, 'epoch': 10.99}
{'loss': 0.0079, 'grad_norm': 6.114573955535889, 'learning_rate': 1.9023255813953487e-05, 'loss_1': 0.0028484491631388664, 'loss_2': 0.00505828857421875, 'loss_3': -16.641408920288086, 'loss_4': 0.9347954988479614, 'epoch': 11.0}
{'loss': 0.0224, 'grad_norm': 5.668770790100098, 'learning_rate': 1.901744186046512e-05, 'loss_1': 0.012462729588150978, 'loss_2': 0.0098876953125, 'loss_3': -16.387788772583008, 'loss_4': 1.385541319847107, 'epoch': 11.01}
{'loss': 0.0157, 'grad_norm': 6.33016300201416, 'learning_rate': 1.9011627906976744e-05, 'loss_1': 0.011324238032102585, 'loss_2': 0.00433349609375, 'loss_3': -16.48052978515625, 'loss_4': 0.991408109664917, 'epoch': 11.01}
{'loss': 0.0209, 'grad_norm': 5.846979141235352, 'learning_rate': 1.9005813953488372e-05, 'loss_1': 0.01161214243620634, 'loss_2': 0.0093231201171875, 'loss_3': -16.356836318969727, 'loss_4': 0.7181299924850464, 'epoch': 11.02}
[INFO|trainer.py:4228] 2025-01-21 13:07:18,118 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:18,118 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                           | 1900/5160 [47:22<56:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:25,487 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019234418869018555, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.878, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01210629940032959, 'eval_loss_2': 0.007128119468688965, 'eval_loss_3': -18.33913803100586, 'eval_loss_4': 0.8452511429786682, 'epoch': 11.02}
{'loss': 0.0165, 'grad_norm': 5.938644886016846, 'learning_rate': 1.9e-05, 'loss_1': 0.01278012990951538, 'loss_2': 0.0037689208984375, 'loss_3': -16.25069808959961, 'loss_4': 0.47154319286346436, 'epoch': 11.02}
{'loss': 0.0291, 'grad_norm': 5.787740707397461, 'learning_rate': 1.8994186046511626e-05, 'loss_1': 0.012082697823643684, 'loss_2': 0.017059326171875, 'loss_3': -16.41201400756836, 'loss_4': 0.4546397626399994, 'epoch': 11.03}
{'loss': 0.0149, 'grad_norm': 4.997069358825684, 'learning_rate': 1.898837209302326e-05, 'loss_1': 0.00590348057448864, 'loss_2': 0.0089874267578125, 'loss_3': -16.334392547607422, 'loss_4': 0.928005576133728, 'epoch': 11.03}
{'loss': 0.0231, 'grad_norm': 8.973021507263184, 'learning_rate': 1.8982558139534884e-05, 'loss_1': 0.011362115852534771, 'loss_2': 0.01175689697265625, 'loss_3': -16.30687713623047, 'loss_4': 1.1972639560699463, 'epoch': 11.04}
{'loss': 0.0235, 'grad_norm': 8.766520500183105, 'learning_rate': 1.8976744186046512e-05, 'loss_1': 0.014553310349583626, 'loss_2': 0.0089263916015625, 'loss_3': -16.467321395874023, 'loss_4': 0.8939929008483887, 'epoch': 11.05}
[INFO|trainer.py:4228] 2025-01-21 13:07:25,487 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:25,487 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                           | 1905/5160 [47:29<56:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:32,851 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020275063812732697, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.918, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012993164360523224, 'eval_loss_2': 0.007281899452209473, 'eval_loss_3': -18.352642059326172, 'eval_loss_4': 0.9538998007774353, 'epoch': 11.05}
{'loss': 0.021, 'grad_norm': 9.41426944732666, 'learning_rate': 1.8970930232558137e-05, 'loss_1': 0.017827067524194717, 'loss_2': 0.003162384033203125, 'loss_3': -16.378097534179688, 'loss_4': 1.395188331604004, 'epoch': 11.05}
{'loss': 0.026, 'grad_norm': 7.568663597106934, 'learning_rate': 1.8965116279069766e-05, 'loss_1': 0.017599616199731827, 'loss_2': 0.00844573974609375, 'loss_3': -16.467681884765625, 'loss_4': 1.559857726097107, 'epoch': 11.06}
{'loss': 0.0191, 'grad_norm': 7.568228244781494, 'learning_rate': 1.8959302325581398e-05, 'loss_1': 0.013632071204483509, 'loss_2': 0.005462646484375, 'loss_3': -16.394197463989258, 'loss_4': 1.0202959775924683, 'epoch': 11.06}
{'loss': 0.0183, 'grad_norm': 7.37364387512207, 'learning_rate': 1.8953488372093023e-05, 'loss_1': 0.014899474568665028, 'loss_2': 0.003368377685546875, 'loss_3': -16.556467056274414, 'loss_4': 0.9876195192337036, 'epoch': 11.07}
{'loss': 0.0155, 'grad_norm': 6.441492557525635, 'learning_rate': 1.8947674418604652e-05, 'loss_1': 0.012494899332523346, 'loss_2': 0.002971649169921875, 'loss_3': -16.57916259765625, 'loss_4': 0.950246274471283, 'epoch': 11.08}
[INFO|trainer.py:4228] 2025-01-21 13:07:32,851 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:32,851 >>   Batch size = 64
 37%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                           | 1910/5160 [47:37<56:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:40,222 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015692584216594696, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.89, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011666323989629745, 'eval_loss_2': 0.0040262602269649506, 'eval_loss_3': -18.352413177490234, 'eval_loss_4': 1.0750735998153687, 'epoch': 11.08}
{'loss': 0.0281, 'grad_norm': 12.343873977661133, 'learning_rate': 1.8941860465116277e-05, 'loss_1': 0.02775038592517376, 'loss_2': 0.0003275871276855469, 'loss_3': -16.34728240966797, 'loss_4': 0.9087510108947754, 'epoch': 11.08}
{'loss': 0.0181, 'grad_norm': 5.676667213439941, 'learning_rate': 1.893604651162791e-05, 'loss_1': 0.009948397055268288, 'loss_2': 0.0081329345703125, 'loss_3': -16.362361907958984, 'loss_4': 1.0833642482757568, 'epoch': 11.09}
{'loss': 0.0163, 'grad_norm': 6.718128204345703, 'learning_rate': 1.8930232558139538e-05, 'loss_1': 0.01175854355096817, 'loss_2': 0.00455474853515625, 'loss_3': -16.522977828979492, 'loss_4': 1.3275368213653564, 'epoch': 11.09}
{'loss': 0.045, 'grad_norm': 17.17972755432129, 'learning_rate': 1.8924418604651163e-05, 'loss_1': 0.033155255019664764, 'loss_2': 0.011871337890625, 'loss_3': -16.464956283569336, 'loss_4': 0.9758837819099426, 'epoch': 11.1}
{'loss': 0.0619, 'grad_norm': 17.526269912719727, 'learning_rate': 1.8918604651162792e-05, 'loss_1': 0.0431688018143177, 'loss_2': 0.018707275390625, 'loss_3': -16.32880401611328, 'loss_4': 1.1487114429473877, 'epoch': 11.1}
[INFO|trainer.py:4228] 2025-01-21 13:07:40,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:40,222 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████                                                                                                                                           | 1915/5160 [47:44<56:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:47,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02203870564699173, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01306110993027687, 'eval_loss_2': 0.00897759199142456, 'eval_loss_3': -18.36115264892578, 'eval_loss_4': 1.1953952312469482, 'epoch': 11.1}
{'loss': 0.0289, 'grad_norm': 7.109522342681885, 'learning_rate': 1.8912790697674417e-05, 'loss_1': 0.018245862796902657, 'loss_2': 0.0106658935546875, 'loss_3': -16.505294799804688, 'loss_4': 0.9454870820045471, 'epoch': 11.11}
{'loss': 0.0288, 'grad_norm': 10.105206489562988, 'learning_rate': 1.890697674418605e-05, 'loss_1': 0.019112994894385338, 'loss_2': 0.00966644287109375, 'loss_3': -16.512210845947266, 'loss_4': 1.2390717267990112, 'epoch': 11.12}
{'loss': 0.0265, 'grad_norm': 6.1802659034729, 'learning_rate': 1.8901162790697674e-05, 'loss_1': 0.013428793288767338, 'loss_2': 0.0130462646484375, 'loss_3': -16.231277465820312, 'loss_4': 1.0962926149368286, 'epoch': 11.12}
{'loss': 0.0244, 'grad_norm': 7.7149434089660645, 'learning_rate': 1.8895348837209303e-05, 'loss_1': 0.01623297855257988, 'loss_2': 0.00811767578125, 'loss_3': -16.549232482910156, 'loss_4': 1.3337956666946411, 'epoch': 11.13}
{'loss': 0.0407, 'grad_norm': 14.505903244018555, 'learning_rate': 1.888953488372093e-05, 'loss_1': 0.03082996793091297, 'loss_2': 0.00984954833984375, 'loss_3': -16.463499069213867, 'loss_4': 1.1601303815841675, 'epoch': 11.13}
[INFO|trainer.py:4228] 2025-01-21 13:07:47,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:47,585 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                          | 1920/5160 [47:52<56:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:07:54,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020266178995370865, 'eval_runtime': 3.82, 'eval_samples_per_second': 268.06, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.014859025366604328, 'eval_loss_2': 0.005407154560089111, 'eval_loss_3': -18.374126434326172, 'eval_loss_4': 1.1569502353668213, 'epoch': 11.13}
{'loss': 0.0199, 'grad_norm': 5.892231464385986, 'learning_rate': 1.8883720930232557e-05, 'loss_1': 0.013041209429502487, 'loss_2': 0.006885528564453125, 'loss_3': -16.613750457763672, 'loss_4': 1.708243727684021, 'epoch': 11.14}
{'loss': 0.0238, 'grad_norm': 8.491070747375488, 'learning_rate': 1.887790697674419e-05, 'loss_1': 0.014793764799833298, 'loss_2': 0.0090484619140625, 'loss_3': -16.53514862060547, 'loss_4': 1.0953474044799805, 'epoch': 11.15}
{'loss': 0.0129, 'grad_norm': 5.8767476081848145, 'learning_rate': 1.8872093023255814e-05, 'loss_1': 0.012124776840209961, 'loss_2': 0.0007605552673339844, 'loss_3': -16.4116268157959, 'loss_4': 1.190940260887146, 'epoch': 11.15}
{'loss': 0.0186, 'grad_norm': 7.017951965332031, 'learning_rate': 1.8866279069767443e-05, 'loss_1': 0.014804425649344921, 'loss_2': 0.003757476806640625, 'loss_3': -16.595199584960938, 'loss_4': 0.9449121356010437, 'epoch': 11.16}
{'loss': 0.0347, 'grad_norm': 13.23262882232666, 'learning_rate': 1.886046511627907e-05, 'loss_1': 0.03208804130554199, 'loss_2': 0.0026187896728515625, 'loss_3': -16.324810028076172, 'loss_4': 1.5004172325134277, 'epoch': 11.16}
[INFO|trainer.py:4228] 2025-01-21 13:07:54,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:07:54,963 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                          | 1925/5160 [47:59<56:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:02,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019424906000494957, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.129, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.014825813472270966, 'eval_loss_2': 0.004599094390869141, 'eval_loss_3': -18.37678337097168, 'eval_loss_4': 1.1826353073120117, 'epoch': 11.16}
{'loss': 0.0121, 'grad_norm': 4.936509609222412, 'learning_rate': 1.8854651162790697e-05, 'loss_1': 0.007503288798034191, 'loss_2': 0.0046234130859375, 'loss_3': -16.66400146484375, 'loss_4': 1.7272756099700928, 'epoch': 11.17}
{'loss': 0.0162, 'grad_norm': 8.75494384765625, 'learning_rate': 1.884883720930233e-05, 'loss_1': 0.015207797288894653, 'loss_2': 0.0010395050048828125, 'loss_3': -16.617671966552734, 'loss_4': 1.6215438842773438, 'epoch': 11.17}
{'loss': 0.0145, 'grad_norm': 5.304553508758545, 'learning_rate': 1.8843023255813954e-05, 'loss_1': 0.010728556662797928, 'loss_2': 0.0037746429443359375, 'loss_3': -16.572586059570312, 'loss_4': 1.179290533065796, 'epoch': 11.18}
{'loss': 0.012, 'grad_norm': 5.838515758514404, 'learning_rate': 1.8837209302325582e-05, 'loss_1': 0.00986632239073515, 'loss_2': 0.002170562744140625, 'loss_3': -16.500774383544922, 'loss_4': 1.344994068145752, 'epoch': 11.19}
{'loss': 0.0316, 'grad_norm': 5.9595746994018555, 'learning_rate': 1.8831395348837208e-05, 'loss_1': 0.019356554374098778, 'loss_2': 0.01221466064453125, 'loss_3': -16.591026306152344, 'loss_4': 1.5593490600585938, 'epoch': 11.19}
[INFO|trainer.py:4228] 2025-01-21 13:08:02,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:02,330 >>   Batch size = 64
 37%|██████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                          | 1930/5160 [48:06<56:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:09,695 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017992179840803146, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.804, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.015637751668691635, 'eval_loss_2': 0.0023544281721115112, 'eval_loss_3': -18.356769561767578, 'eval_loss_4': 1.1729786396026611, 'epoch': 11.19}
{'loss': 0.0224, 'grad_norm': 6.461826324462891, 'learning_rate': 1.8825581395348836e-05, 'loss_1': 0.016000429168343544, 'loss_2': 0.006439208984375, 'loss_3': -16.6596622467041, 'loss_4': 1.2453639507293701, 'epoch': 11.2}
{'loss': 0.0176, 'grad_norm': 6.318818092346191, 'learning_rate': 1.881976744186047e-05, 'loss_1': 0.014244201593101025, 'loss_2': 0.003383636474609375, 'loss_3': -16.51002311706543, 'loss_4': 1.2383673191070557, 'epoch': 11.2}
{'loss': 0.0232, 'grad_norm': 8.232897758483887, 'learning_rate': 1.8813953488372094e-05, 'loss_1': 0.01831887848675251, 'loss_2': 0.004856109619140625, 'loss_3': -16.396350860595703, 'loss_4': 1.545541524887085, 'epoch': 11.21}
{'loss': 0.0116, 'grad_norm': 4.612865924835205, 'learning_rate': 1.8808139534883722e-05, 'loss_1': 0.0066948262974619865, 'loss_2': 0.00485992431640625, 'loss_3': -16.581148147583008, 'loss_4': 1.3567447662353516, 'epoch': 11.22}
{'loss': 0.0212, 'grad_norm': 6.7832183837890625, 'learning_rate': 1.8802325581395347e-05, 'loss_1': 0.017455706372857094, 'loss_2': 0.00377655029296875, 'loss_3': -16.488332748413086, 'loss_4': 1.3758162260055542, 'epoch': 11.22}
[INFO|trainer.py:4228] 2025-01-21 13:08:09,695 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:09,695 >>   Batch size = 64
 38%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                          | 1935/5160 [48:14<55:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:17,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019102785736322403, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.702, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.015698183327913284, 'eval_loss_2': 0.0034046024084091187, 'eval_loss_3': -18.337718963623047, 'eval_loss_4': 1.3073817491531372, 'epoch': 11.22}
{'loss': 0.012, 'grad_norm': 5.822260856628418, 'learning_rate': 1.8796511627906976e-05, 'loss_1': 0.007647824473679066, 'loss_2': 0.004364013671875, 'loss_3': -16.42165756225586, 'loss_4': 1.4806385040283203, 'epoch': 11.23}
{'loss': 0.0155, 'grad_norm': 7.962296485900879, 'learning_rate': 1.8790697674418608e-05, 'loss_1': 0.010493098758161068, 'loss_2': 0.004985809326171875, 'loss_3': -16.5094051361084, 'loss_4': 1.431766152381897, 'epoch': 11.23}
{'loss': 0.0162, 'grad_norm': 6.143674850463867, 'learning_rate': 1.8784883720930233e-05, 'loss_1': 0.01154653076082468, 'loss_2': 0.00466156005859375, 'loss_3': -16.389516830444336, 'loss_4': 1.2490897178649902, 'epoch': 11.24}
{'loss': 0.0113, 'grad_norm': 5.742641448974609, 'learning_rate': 1.8779069767441862e-05, 'loss_1': 0.010865982621908188, 'loss_2': 0.0004315376281738281, 'loss_3': -16.64044189453125, 'loss_4': 1.3467636108398438, 'epoch': 11.24}
{'loss': 0.0146, 'grad_norm': 5.5591654777526855, 'learning_rate': 1.8773255813953487e-05, 'loss_1': 0.011708524078130722, 'loss_2': 0.00292205810546875, 'loss_3': -16.43539047241211, 'loss_4': 1.5172414779663086, 'epoch': 11.25}
[INFO|trainer.py:4228] 2025-01-21 13:08:17,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:17,070 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████                                                                                                                                          | 1940/5160 [48:21<55:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:24,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01867607608437538, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.83, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01572183147072792, 'eval_loss_2': 0.002954244613647461, 'eval_loss_3': -18.311233520507812, 'eval_loss_4': 1.1345794200897217, 'epoch': 11.25}
{'loss': 0.0155, 'grad_norm': 5.171621322631836, 'learning_rate': 1.8767441860465116e-05, 'loss_1': 0.01144544780254364, 'loss_2': 0.004055023193359375, 'loss_3': -16.393951416015625, 'loss_4': 1.3656647205352783, 'epoch': 11.26}
{'loss': 0.0117, 'grad_norm': 5.283670425415039, 'learning_rate': 1.8761627906976744e-05, 'loss_1': 0.011290176771581173, 'loss_2': 0.0004451274871826172, 'loss_3': -16.508155822753906, 'loss_4': 1.4146511554718018, 'epoch': 11.26}
{'loss': 0.0196, 'grad_norm': 5.7975053787231445, 'learning_rate': 1.8755813953488373e-05, 'loss_1': 0.011195223778486252, 'loss_2': 0.00836181640625, 'loss_3': -16.23773193359375, 'loss_4': 1.273900032043457, 'epoch': 11.27}
{'loss': 0.0155, 'grad_norm': 5.429664134979248, 'learning_rate': 1.8750000000000002e-05, 'loss_1': 0.008770886808633804, 'loss_2': 0.006687164306640625, 'loss_3': -16.452865600585938, 'loss_4': 1.5641118288040161, 'epoch': 11.27}
{'loss': 0.0216, 'grad_norm': 4.843776702880859, 'learning_rate': 1.8744186046511627e-05, 'loss_1': 0.00914402212947607, 'loss_2': 0.0124664306640625, 'loss_3': -16.215335845947266, 'loss_4': 1.5202468633651733, 'epoch': 11.28}
[INFO|trainer.py:4228] 2025-01-21 13:08:24,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:24,439 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                         | 1945/5160 [48:28<55:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:31,810 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024203168228268623, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.395, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01769905723631382, 'eval_loss_2': 0.0065041109919548035, 'eval_loss_3': -18.266672134399414, 'eval_loss_4': 1.042744755744934, 'epoch': 11.28}
{'loss': 0.0197, 'grad_norm': 6.039204120635986, 'learning_rate': 1.8738372093023256e-05, 'loss_1': 0.010253064334392548, 'loss_2': 0.00940704345703125, 'loss_3': -16.51757049560547, 'loss_4': 0.8369690775871277, 'epoch': 11.28}
{'loss': 0.0277, 'grad_norm': 11.356107711791992, 'learning_rate': 1.8732558139534884e-05, 'loss_1': 0.01843351498246193, 'loss_2': 0.00928497314453125, 'loss_3': -16.30841827392578, 'loss_4': 0.9138197898864746, 'epoch': 11.29}
{'loss': 0.0652, 'grad_norm': 20.659767150878906, 'learning_rate': 1.8726744186046513e-05, 'loss_1': 0.05488477274775505, 'loss_2': 0.01027679443359375, 'loss_3': -16.271068572998047, 'loss_4': 1.522526741027832, 'epoch': 11.3}
{'loss': 0.1114, 'grad_norm': 30.547637939453125, 'learning_rate': 1.872093023255814e-05, 'loss_1': 0.10913597047328949, 'loss_2': 0.002223968505859375, 'loss_3': -16.19738006591797, 'loss_4': 0.7745004296302795, 'epoch': 11.3}
{'loss': 0.0112, 'grad_norm': 4.978879451751709, 'learning_rate': 1.8715116279069767e-05, 'loss_1': 0.007855571806430817, 'loss_2': 0.003299713134765625, 'loss_3': -16.404178619384766, 'loss_4': 1.1211824417114258, 'epoch': 11.31}
[INFO|trainer.py:4228] 2025-01-21 13:08:31,811 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:31,811 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                         | 1950/5160 [48:36<55:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:39,176 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022721415385603905, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.806, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.019611602649092674, 'eval_loss_2': 0.0031098127365112305, 'eval_loss_3': -18.25909423828125, 'eval_loss_4': 1.2498223781585693, 'epoch': 11.31}
{'loss': 0.0102, 'grad_norm': 9.198953628540039, 'learning_rate': 1.8709302325581395e-05, 'loss_1': 0.009025992825627327, 'loss_2': 0.0011348724365234375, 'loss_3': -16.33746337890625, 'loss_4': 1.267122745513916, 'epoch': 11.31}
{'loss': 0.0167, 'grad_norm': 5.154211044311523, 'learning_rate': 1.8703488372093024e-05, 'loss_1': 0.011639517731964588, 'loss_2': 0.00501251220703125, 'loss_3': -16.10483741760254, 'loss_4': 1.3253380060195923, 'epoch': 11.32}
{'loss': 0.0093, 'grad_norm': 6.450347423553467, 'learning_rate': 1.8697674418604653e-05, 'loss_1': 0.007043151184916496, 'loss_2': 0.002285003662109375, 'loss_3': -16.636747360229492, 'loss_4': 1.409597396850586, 'epoch': 11.33}
{'loss': 0.0209, 'grad_norm': 6.024662017822266, 'learning_rate': 1.8691860465116278e-05, 'loss_1': 0.009950880892574787, 'loss_2': 0.01091766357421875, 'loss_3': -16.411895751953125, 'loss_4': 0.8151388168334961, 'epoch': 11.33}
{'loss': 0.0124, 'grad_norm': 8.606745719909668, 'learning_rate': 1.8686046511627907e-05, 'loss_1': 0.011013658717274666, 'loss_2': 0.0013408660888671875, 'loss_3': -16.393308639526367, 'loss_4': 1.22957444190979, 'epoch': 11.34}
[INFO|trainer.py:4228] 2025-01-21 13:08:39,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:39,176 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                         | 1955/5160 [48:43<55:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:46,541 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026543227955698967, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0182186346501112, 'eval_loss_2': 0.008324593305587769, 'eval_loss_3': -18.251041412353516, 'eval_loss_4': 1.2753674983978271, 'epoch': 11.34}
{'loss': 0.0724, 'grad_norm': 20.340991973876953, 'learning_rate': 1.8680232558139535e-05, 'loss_1': 0.07167594134807587, 'loss_2': 0.0007500648498535156, 'loss_3': -16.381418228149414, 'loss_4': 1.3740237951278687, 'epoch': 11.34}
{'loss': 0.0224, 'grad_norm': 7.305171489715576, 'learning_rate': 1.8674418604651164e-05, 'loss_1': 0.012178964912891388, 'loss_2': 0.01021575927734375, 'loss_3': -16.36905288696289, 'loss_4': 1.6728767156600952, 'epoch': 11.35}
{'loss': 0.0189, 'grad_norm': 9.366501808166504, 'learning_rate': 1.8668604651162792e-05, 'loss_1': 0.014802074059844017, 'loss_2': 0.00408172607421875, 'loss_3': -15.99090576171875, 'loss_4': 1.3133821487426758, 'epoch': 11.35}
{'loss': 0.0189, 'grad_norm': 4.579603672027588, 'learning_rate': 1.8662790697674418e-05, 'loss_1': 0.0036317778285592794, 'loss_2': 0.01522064208984375, 'loss_3': -16.536718368530273, 'loss_4': 0.6723052263259888, 'epoch': 11.36}
{'loss': 0.0166, 'grad_norm': 5.390953540802002, 'learning_rate': 1.8656976744186046e-05, 'loss_1': 0.0039403703995049, 'loss_2': 0.0126953125, 'loss_3': -16.40851593017578, 'loss_4': 1.4740855693817139, 'epoch': 11.37}
[INFO|trainer.py:4228] 2025-01-21 13:08:46,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:46,542 >>   Batch size = 64
 38%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                         | 1960/5160 [48:51<55:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:08:53,898 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027103804051876068, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.146, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020464206114411354, 'eval_loss_2': 0.006639599800109863, 'eval_loss_3': -18.234691619873047, 'eval_loss_4': 1.15542471408844, 'epoch': 11.37}
{'loss': 0.0122, 'grad_norm': 4.837191581726074, 'learning_rate': 1.8651162790697675e-05, 'loss_1': 0.006702482234686613, 'loss_2': 0.00550079345703125, 'loss_3': -16.509628295898438, 'loss_4': 1.9440194368362427, 'epoch': 11.37}
{'loss': 0.0074, 'grad_norm': 4.779387950897217, 'learning_rate': 1.8645348837209304e-05, 'loss_1': 0.006456836126744747, 'loss_2': 0.0009317398071289062, 'loss_3': -16.370155334472656, 'loss_4': 1.1270787715911865, 'epoch': 11.38}
{'loss': 0.0188, 'grad_norm': 5.456669330596924, 'learning_rate': 1.8639534883720932e-05, 'loss_1': 0.009504824876785278, 'loss_2': 0.00927734375, 'loss_3': -16.46067237854004, 'loss_4': 0.8377957344055176, 'epoch': 11.38}
{'loss': 0.02, 'grad_norm': 9.9220609664917, 'learning_rate': 1.8633720930232557e-05, 'loss_1': 0.014640646986663342, 'loss_2': 0.0053558349609375, 'loss_3': -16.186525344848633, 'loss_4': 1.1825947761535645, 'epoch': 11.39}
{'loss': 0.0163, 'grad_norm': 8.130863189697266, 'learning_rate': 1.8627906976744186e-05, 'loss_1': 0.015529362484812737, 'loss_2': 0.0007772445678710938, 'loss_3': -16.250064849853516, 'loss_4': 0.8798548579216003, 'epoch': 11.4}
[INFO|trainer.py:4228] 2025-01-21 13:08:53,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:08:53,898 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                        | 1965/5160 [48:58<55:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:01,268 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02652904950082302, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.02070162259042263, 'eval_loss_2': 0.005827426910400391, 'eval_loss_3': -18.24115753173828, 'eval_loss_4': 1.2034075260162354, 'epoch': 11.4}
{'loss': 0.0096, 'grad_norm': 5.32936429977417, 'learning_rate': 1.862209302325581e-05, 'loss_1': 0.005234264302998781, 'loss_2': 0.00433349609375, 'loss_3': -16.43059539794922, 'loss_4': 1.315543532371521, 'epoch': 11.4}
{'loss': 0.0888, 'grad_norm': 10.209835052490234, 'learning_rate': 1.8616279069767443e-05, 'loss_1': 0.07864905148744583, 'loss_2': 0.0101470947265625, 'loss_3': -16.360321044921875, 'loss_4': 1.6669069528579712, 'epoch': 11.41}
{'loss': 0.0136, 'grad_norm': 8.485339164733887, 'learning_rate': 1.8610465116279072e-05, 'loss_1': 0.013220003806054592, 'loss_2': 0.0003552436828613281, 'loss_3': -16.42556381225586, 'loss_4': 1.5569980144500732, 'epoch': 11.41}
{'loss': 0.0275, 'grad_norm': 10.56805419921875, 'learning_rate': 1.8604651162790697e-05, 'loss_1': 0.023673897609114647, 'loss_2': 0.00382232666015625, 'loss_3': -16.470874786376953, 'loss_4': 1.2276899814605713, 'epoch': 11.42}
{'loss': 0.0097, 'grad_norm': 5.592279434204102, 'learning_rate': 1.8598837209302326e-05, 'loss_1': 0.007101400755345821, 'loss_2': 0.002590179443359375, 'loss_3': -16.31261444091797, 'loss_4': 1.3196780681610107, 'epoch': 11.42}
[INFO|trainer.py:4228] 2025-01-21 13:09:01,268 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:01,268 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                        | 1970/5160 [49:05<55:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:08,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04351648688316345, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03854397311806679, 'eval_loss_2': 0.004972517490386963, 'eval_loss_3': -18.16400146484375, 'eval_loss_4': 1.4028431177139282, 'epoch': 11.42}
{'loss': 0.0208, 'grad_norm': 9.375642776489258, 'learning_rate': 1.859302325581395e-05, 'loss_1': 0.015382866375148296, 'loss_2': 0.005462646484375, 'loss_3': -16.337928771972656, 'loss_4': 1.2980451583862305, 'epoch': 11.43}
{'loss': 0.0222, 'grad_norm': 13.352783203125, 'learning_rate': 1.8587209302325583e-05, 'loss_1': 0.019941816106438637, 'loss_2': 0.0022907257080078125, 'loss_3': -16.463722229003906, 'loss_4': 1.3247342109680176, 'epoch': 11.44}
{'loss': 0.0195, 'grad_norm': 8.934696197509766, 'learning_rate': 1.8581395348837212e-05, 'loss_1': 0.011749322526156902, 'loss_2': 0.007740020751953125, 'loss_3': -16.255489349365234, 'loss_4': 1.2886641025543213, 'epoch': 11.44}
{'loss': 0.0108, 'grad_norm': 4.388455867767334, 'learning_rate': 1.8575581395348837e-05, 'loss_1': 0.005303813610225916, 'loss_2': 0.0055084228515625, 'loss_3': -16.29798126220703, 'loss_4': 1.4498664140701294, 'epoch': 11.45}
{'loss': 0.0154, 'grad_norm': 8.069381713867188, 'learning_rate': 1.8569767441860466e-05, 'loss_1': 0.015185121446847916, 'loss_2': 0.0002193450927734375, 'loss_3': -16.46143341064453, 'loss_4': 1.309286117553711, 'epoch': 11.45}
[INFO|trainer.py:4228] 2025-01-21 13:09:08,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:08,637 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                        | 1975/5160 [49:13<55:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:16,022 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.09318052232265472, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.407, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.08953028917312622, 'eval_loss_2': 0.003650229424238205, 'eval_loss_3': -18.03651237487793, 'eval_loss_4': 1.5293245315551758, 'epoch': 11.45}
{'loss': 0.0303, 'grad_norm': 8.666278839111328, 'learning_rate': 1.856395348837209e-05, 'loss_1': 0.024457110092043877, 'loss_2': 0.00586700439453125, 'loss_3': -16.43889617919922, 'loss_4': 1.967844009399414, 'epoch': 11.46}
{'loss': 0.0103, 'grad_norm': 5.050801753997803, 'learning_rate': 1.8558139534883723e-05, 'loss_1': 0.004264025948941708, 'loss_2': 0.0060272216796875, 'loss_3': -16.194183349609375, 'loss_4': 1.3032267093658447, 'epoch': 11.47}
{'loss': 0.0154, 'grad_norm': 5.489818572998047, 'learning_rate': 1.8552325581395348e-05, 'loss_1': 0.012165759690105915, 'loss_2': 0.003261566162109375, 'loss_3': -16.266155242919922, 'loss_4': 1.4137306213378906, 'epoch': 11.47}
{'loss': 0.0277, 'grad_norm': 8.301469802856445, 'learning_rate': 1.8546511627906977e-05, 'loss_1': 0.01951345056295395, 'loss_2': 0.00815582275390625, 'loss_3': -16.27566909790039, 'loss_4': 1.2633687257766724, 'epoch': 11.48}
{'loss': 0.0166, 'grad_norm': 5.385910511016846, 'learning_rate': 1.8540697674418605e-05, 'loss_1': 0.0065657454542815685, 'loss_2': 0.010009765625, 'loss_3': -16.18735694885254, 'loss_4': 1.6475346088409424, 'epoch': 11.48}
[INFO|trainer.py:4228] 2025-01-21 13:09:16,022 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:16,022 >>   Batch size = 64
 38%|████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                        | 1980/5160 [49:20<55:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:23,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.10911154747009277, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.736, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.10416722297668457, 'eval_loss_2': 0.004944309592247009, 'eval_loss_3': -17.999353408813477, 'eval_loss_4': 1.5416401624679565, 'epoch': 11.48}
{'loss': 0.0215, 'grad_norm': 12.5797700881958, 'learning_rate': 1.8534883720930234e-05, 'loss_1': 0.014706483110785484, 'loss_2': 0.00679779052734375, 'loss_3': -16.237672805786133, 'loss_4': 1.4160104990005493, 'epoch': 11.49}
{'loss': 0.0187, 'grad_norm': 5.073192119598389, 'learning_rate': 1.8529069767441863e-05, 'loss_1': 0.00834417250007391, 'loss_2': 0.0103302001953125, 'loss_3': -16.435943603515625, 'loss_4': 1.68170964717865, 'epoch': 11.49}
{'loss': 0.0113, 'grad_norm': 5.032137393951416, 'learning_rate': 1.8523255813953488e-05, 'loss_1': 0.008256394416093826, 'loss_2': 0.0030517578125, 'loss_3': -16.337783813476562, 'loss_4': 1.4977571964263916, 'epoch': 11.5}
{'loss': 0.0136, 'grad_norm': 6.278480529785156, 'learning_rate': 1.8517441860465117e-05, 'loss_1': 0.01304943859577179, 'loss_2': 0.0005221366882324219, 'loss_3': -16.275379180908203, 'loss_4': 1.6434698104858398, 'epoch': 11.51}
{'loss': 0.0128, 'grad_norm': 9.808989524841309, 'learning_rate': 1.8511627906976745e-05, 'loss_1': 0.010000607930123806, 'loss_2': 0.0028018951416015625, 'loss_3': -16.208471298217773, 'loss_4': 1.6944257020950317, 'epoch': 11.51}
[INFO|trainer.py:4228] 2025-01-21 13:09:23,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:23,395 >>   Batch size = 64
 38%|█████████████████████████████████████████████████████████████████████████████████████                                                                                                                                        | 1985/5160 [49:27<55:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:30,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.051103003323078156, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.171, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.04650658741593361, 'eval_loss_2': 0.004596412181854248, 'eval_loss_3': -18.132604598999023, 'eval_loss_4': 1.4424057006835938, 'epoch': 11.51}
{'loss': 0.0194, 'grad_norm': 8.62089729309082, 'learning_rate': 1.8505813953488374e-05, 'loss_1': 0.013727355748414993, 'loss_2': 0.005695343017578125, 'loss_3': -16.34762191772461, 'loss_4': 1.6063294410705566, 'epoch': 11.52}
{'loss': 0.0226, 'grad_norm': 8.616896629333496, 'learning_rate': 1.8500000000000002e-05, 'loss_1': 0.01109401136636734, 'loss_2': 0.01153564453125, 'loss_3': -16.202022552490234, 'loss_4': 1.1312963962554932, 'epoch': 11.52}
{'loss': 0.0095, 'grad_norm': 4.466790676116943, 'learning_rate': 1.8494186046511628e-05, 'loss_1': 0.0066360062919557095, 'loss_2': 0.002838134765625, 'loss_3': -16.340131759643555, 'loss_4': 1.5813241004943848, 'epoch': 11.53}
{'loss': 0.0208, 'grad_norm': 7.520228385925293, 'learning_rate': 1.8488372093023256e-05, 'loss_1': 0.013433941639959812, 'loss_2': 0.00736236572265625, 'loss_3': -16.162506103515625, 'loss_4': 1.5224645137786865, 'epoch': 11.53}
{'loss': 0.0285, 'grad_norm': 5.633534908294678, 'learning_rate': 1.848255813953488e-05, 'loss_1': 0.015056353993713856, 'loss_2': 0.01342010498046875, 'loss_3': -16.352893829345703, 'loss_4': 2.022052526473999, 'epoch': 11.54}
[INFO|trainer.py:4228] 2025-01-21 13:09:30,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:30,757 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                       | 1990/5160 [49:35<55:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:38,127 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027905192226171494, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02364959754049778, 'eval_loss_2': 0.0042555928230285645, 'eval_loss_3': -18.22377586364746, 'eval_loss_4': 1.4801931381225586, 'epoch': 11.54}
{'loss': 0.0125, 'grad_norm': 5.850826263427734, 'learning_rate': 1.8476744186046514e-05, 'loss_1': 0.010300133377313614, 'loss_2': 0.0022182464599609375, 'loss_3': -16.231761932373047, 'loss_4': 2.147146701812744, 'epoch': 11.55}
{'loss': 0.0101, 'grad_norm': 7.49714994430542, 'learning_rate': 1.8470930232558142e-05, 'loss_1': 0.008582951501011848, 'loss_2': 0.0015239715576171875, 'loss_3': -16.248126983642578, 'loss_4': 1.4130779504776, 'epoch': 11.55}
{'loss': 0.0089, 'grad_norm': 5.364156246185303, 'learning_rate': 1.8465116279069767e-05, 'loss_1': 0.006819106638431549, 'loss_2': 0.0020904541015625, 'loss_3': -16.29245948791504, 'loss_4': 1.7709667682647705, 'epoch': 11.56}
{'loss': 0.0265, 'grad_norm': 8.33013916015625, 'learning_rate': 1.8459302325581396e-05, 'loss_1': 0.017367301508784294, 'loss_2': 0.0091705322265625, 'loss_3': -16.319141387939453, 'loss_4': 1.5762706995010376, 'epoch': 11.56}
{'loss': 0.0531, 'grad_norm': 18.92840576171875, 'learning_rate': 1.845348837209302e-05, 'loss_1': 0.04234079644083977, 'loss_2': 0.0107269287109375, 'loss_3': -16.13143539428711, 'loss_4': 1.6343417167663574, 'epoch': 11.57}
[INFO|trainer.py:4228] 2025-01-21 13:09:38,127 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:38,127 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                       | 1995/5160 [49:42<54:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:45,494 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017754334956407547, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014124518260359764, 'eval_loss_2': 0.003629818558692932, 'eval_loss_3': -18.232778549194336, 'eval_loss_4': 1.730045199394226, 'epoch': 11.57}
{'loss': 0.0259, 'grad_norm': 9.859576225280762, 'learning_rate': 1.8447674418604653e-05, 'loss_1': 0.021635903045535088, 'loss_2': 0.0042877197265625, 'loss_3': -16.293792724609375, 'loss_4': 1.8208214044570923, 'epoch': 11.58}
{'loss': 0.0126, 'grad_norm': 5.681700229644775, 'learning_rate': 1.8441860465116282e-05, 'loss_1': 0.010169699788093567, 'loss_2': 0.002422332763671875, 'loss_3': -16.37455940246582, 'loss_4': 2.1190989017486572, 'epoch': 11.58}
{'loss': 0.021, 'grad_norm': 9.673487663269043, 'learning_rate': 1.8436046511627907e-05, 'loss_1': 0.02007533423602581, 'loss_2': 0.0009245872497558594, 'loss_3': -16.341474533081055, 'loss_4': 1.8490086793899536, 'epoch': 11.59}
{'loss': 0.0178, 'grad_norm': 7.980844974517822, 'learning_rate': 1.8430232558139536e-05, 'loss_1': 0.01740475557744503, 'loss_2': 0.00035858154296875, 'loss_3': -16.567310333251953, 'loss_4': 1.9209409952163696, 'epoch': 11.59}
{'loss': 0.0092, 'grad_norm': 4.5264410972595215, 'learning_rate': 1.842441860465116e-05, 'loss_1': 0.006125257816165686, 'loss_2': 0.0030670166015625, 'loss_3': -16.172019958496094, 'loss_4': 1.8696725368499756, 'epoch': 11.6}
[INFO|trainer.py:4228] 2025-01-21 13:09:45,494 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:45,494 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                       | 2000/5160 [49:50<54:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:09:52,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017645012587308884, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.83, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.013661572709679604, 'eval_loss_2': 0.003983438014984131, 'eval_loss_3': -18.28249740600586, 'eval_loss_4': 2.1109461784362793, 'epoch': 11.6}
{'loss': 0.0118, 'grad_norm': 4.855664253234863, 'learning_rate': 1.8418604651162793e-05, 'loss_1': 0.008382068015635014, 'loss_2': 0.0034389495849609375, 'loss_3': -16.30742835998535, 'loss_4': 2.16741943359375, 'epoch': 11.6}
{'loss': 0.0035, 'grad_norm': 4.959463596343994, 'learning_rate': 1.841279069767442e-05, 'loss_1': 0.0030148879159241915, 'loss_2': 0.0004968643188476562, 'loss_3': -16.371641159057617, 'loss_4': 2.4176583290100098, 'epoch': 11.61}
{'loss': 0.0268, 'grad_norm': 8.481170654296875, 'learning_rate': 1.8406976744186047e-05, 'loss_1': 0.022660234943032265, 'loss_2': 0.0041046142578125, 'loss_3': -16.38416290283203, 'loss_4': 1.873528003692627, 'epoch': 11.62}
{'loss': 0.0202, 'grad_norm': 7.130134582519531, 'learning_rate': 1.8401162790697676e-05, 'loss_1': 0.014105675742030144, 'loss_2': 0.006053924560546875, 'loss_3': -16.4895076751709, 'loss_4': 2.3098793029785156, 'epoch': 11.62}
{'loss': 0.0078, 'grad_norm': 4.858542442321777, 'learning_rate': 1.83953488372093e-05, 'loss_1': 0.006671414710581303, 'loss_2': 0.0011510848999023438, 'loss_3': -16.250612258911133, 'loss_4': 2.882485866546631, 'epoch': 11.63}
[INFO|trainer.py:4228] 2025-01-21 13:09:52,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:09:52,862 >>   Batch size = 64
 39%|█████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                       | 2005/5160 [49:57<54:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:00,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017221050336956978, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.894, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01337646134197712, 'eval_loss_2': 0.0038445889949798584, 'eval_loss_3': -18.328821182250977, 'eval_loss_4': 2.5742251873016357, 'epoch': 11.63}
{'loss': 0.017, 'grad_norm': 5.066920280456543, 'learning_rate': 1.8389534883720933e-05, 'loss_1': 0.010361782275140285, 'loss_2': 0.0066070556640625, 'loss_3': -16.550695419311523, 'loss_4': 2.6459059715270996, 'epoch': 11.63}
{'loss': 0.0238, 'grad_norm': 9.217519760131836, 'learning_rate': 1.8383720930232558e-05, 'loss_1': 0.01700194552540779, 'loss_2': 0.00681304931640625, 'loss_3': -16.389671325683594, 'loss_4': 2.9123501777648926, 'epoch': 11.64}
{'loss': 0.0224, 'grad_norm': 9.953763008117676, 'learning_rate': 1.8377906976744187e-05, 'loss_1': 0.018069230020046234, 'loss_2': 0.00429534912109375, 'loss_3': -16.34920883178711, 'loss_4': 2.574585437774658, 'epoch': 11.65}
{'loss': 0.0164, 'grad_norm': 9.182618141174316, 'learning_rate': 1.8372093023255815e-05, 'loss_1': 0.013862056657671928, 'loss_2': 0.00250244140625, 'loss_3': -16.190889358520508, 'loss_4': 2.8312950134277344, 'epoch': 11.65}
{'loss': 0.0189, 'grad_norm': 5.832427024841309, 'learning_rate': 1.836627906976744e-05, 'loss_1': 0.00939884688705206, 'loss_2': 0.00949859619140625, 'loss_3': -16.269710540771484, 'loss_4': 2.2870988845825195, 'epoch': 11.66}
[INFO|trainer.py:4228] 2025-01-21 13:10:00,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:00,241 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████                                                                                                                                       | 2010/5160 [50:04<54:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:07,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01834063045680523, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.448, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.014575219713151455, 'eval_loss_2': 0.003765411674976349, 'eval_loss_3': -18.297576904296875, 'eval_loss_4': 2.60672664642334, 'epoch': 11.66}
{'loss': 0.0118, 'grad_norm': 8.034184455871582, 'learning_rate': 1.8360465116279073e-05, 'loss_1': 0.010993926785886288, 'loss_2': 0.0007996559143066406, 'loss_3': -16.413955688476562, 'loss_4': 2.3280134201049805, 'epoch': 11.66}
{'loss': 0.0208, 'grad_norm': 6.546727180480957, 'learning_rate': 1.8354651162790698e-05, 'loss_1': 0.017121583223342896, 'loss_2': 0.00370025634765625, 'loss_3': -16.628477096557617, 'loss_4': 3.192967414855957, 'epoch': 11.67}
{'loss': 0.0072, 'grad_norm': 4.974788665771484, 'learning_rate': 1.8348837209302327e-05, 'loss_1': 0.006729197688400745, 'loss_2': 0.00044345855712890625, 'loss_3': -16.53180694580078, 'loss_4': 2.3127870559692383, 'epoch': 11.67}
{'loss': 0.0238, 'grad_norm': 8.627223014831543, 'learning_rate': 1.8343023255813952e-05, 'loss_1': 0.01685146614909172, 'loss_2': 0.0069732666015625, 'loss_3': -16.483306884765625, 'loss_4': 2.674948215484619, 'epoch': 11.68}
{'loss': 0.02, 'grad_norm': 6.098959445953369, 'learning_rate': 1.833720930232558e-05, 'loss_1': 0.013869911432266235, 'loss_2': 0.0061492919921875, 'loss_3': -16.42566680908203, 'loss_4': 2.776963233947754, 'epoch': 11.69}
[INFO|trainer.py:4228] 2025-01-21 13:10:07,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:07,618 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 2015/5160 [50:12<55:18,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 13:10:15,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022672755643725395, 'eval_runtime': 4.0001, 'eval_samples_per_second': 255.993, 'eval_steps_per_second': 4.0, 'eval_loss_1': 0.017354415729641914, 'eval_loss_2': 0.005318343639373779, 'eval_loss_3': -18.260921478271484, 'eval_loss_4': 2.532353162765503, 'epoch': 11.69}
{'loss': 0.0164, 'grad_norm': 6.1948323249816895, 'learning_rate': 1.8331395348837212e-05, 'loss_1': 0.014192464761435986, 'loss_2': 0.002239227294921875, 'loss_3': -16.219532012939453, 'loss_4': 2.5860366821289062, 'epoch': 11.69}
{'loss': 0.0129, 'grad_norm': 6.036291122436523, 'learning_rate': 1.8325581395348838e-05, 'loss_1': 0.012710129842162132, 'loss_2': 0.00023293495178222656, 'loss_3': -16.471389770507812, 'loss_4': 2.2374267578125, 'epoch': 11.7}
{'loss': 0.018, 'grad_norm': 5.9741973876953125, 'learning_rate': 1.8319767441860466e-05, 'loss_1': 0.008541393093764782, 'loss_2': 0.00948333740234375, 'loss_3': -16.217910766601562, 'loss_4': 2.379075765609741, 'epoch': 11.7}
{'loss': 0.0131, 'grad_norm': 5.069860935211182, 'learning_rate': 1.831395348837209e-05, 'loss_1': 0.006702931132167578, 'loss_2': 0.0063934326171875, 'loss_3': -16.483001708984375, 'loss_4': 2.692187786102295, 'epoch': 11.71}
{'loss': 0.0156, 'grad_norm': 5.681510925292969, 'learning_rate': 1.830813953488372e-05, 'loss_1': 0.008482060395181179, 'loss_2': 0.00710296630859375, 'loss_3': -16.336353302001953, 'loss_4': 2.5531885623931885, 'epoch': 11.72}
[INFO|trainer.py:4228] 2025-01-21 13:10:15,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:15,177 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                      | 2020/5160 [50:19<54:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:22,547 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02406718023121357, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.826, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.020289426669478416, 'eval_loss_2': 0.0037777498364448547, 'eval_loss_3': -18.229419708251953, 'eval_loss_4': 2.28598690032959, 'epoch': 11.72}
{'loss': 0.0102, 'grad_norm': 4.693806171417236, 'learning_rate': 1.830232558139535e-05, 'loss_1': 0.005196446552872658, 'loss_2': 0.004985809326171875, 'loss_3': -16.23038101196289, 'loss_4': 2.2441744804382324, 'epoch': 11.72}
{'loss': 0.0227, 'grad_norm': 9.564247131347656, 'learning_rate': 1.8296511627906977e-05, 'loss_1': 0.017346512526273727, 'loss_2': 0.00536346435546875, 'loss_3': -16.643375396728516, 'loss_4': 2.561063289642334, 'epoch': 11.73}
{'loss': 0.0201, 'grad_norm': 5.571023464202881, 'learning_rate': 1.8290697674418606e-05, 'loss_1': 0.014098545536398888, 'loss_2': 0.0059967041015625, 'loss_3': -16.10742950439453, 'loss_4': 2.5401721000671387, 'epoch': 11.73}
{'loss': 0.0185, 'grad_norm': 8.423572540283203, 'learning_rate': 1.828488372093023e-05, 'loss_1': 0.016847757622599602, 'loss_2': 0.0016450881958007812, 'loss_3': -16.554180145263672, 'loss_4': 2.542642116546631, 'epoch': 11.74}
{'loss': 0.0256, 'grad_norm': 6.742727756500244, 'learning_rate': 1.827906976744186e-05, 'loss_1': 0.017717394977808, 'loss_2': 0.00787353515625, 'loss_3': -16.301910400390625, 'loss_4': 2.179424285888672, 'epoch': 11.74}
[INFO|trainer.py:4228] 2025-01-21 13:10:22,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:22,548 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                      | 2025/5160 [50:27<54:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:29,923 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.030666625127196312, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.304, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.026901625096797943, 'eval_loss_2': 0.003765001893043518, 'eval_loss_3': -18.213808059692383, 'eval_loss_4': 1.900341272354126, 'epoch': 11.74}
{'loss': 0.0206, 'grad_norm': 8.446592330932617, 'learning_rate': 1.827325581395349e-05, 'loss_1': 0.017107971012592316, 'loss_2': 0.00348663330078125, 'loss_3': -16.446735382080078, 'loss_4': 2.027987480163574, 'epoch': 11.75}
{'loss': 0.0194, 'grad_norm': 9.26054859161377, 'learning_rate': 1.8267441860465117e-05, 'loss_1': 0.014975050464272499, 'loss_2': 0.004390716552734375, 'loss_3': -16.115938186645508, 'loss_4': 2.0111591815948486, 'epoch': 11.76}
{'loss': 0.0177, 'grad_norm': 6.212997913360596, 'learning_rate': 1.8261627906976746e-05, 'loss_1': 0.01328869815915823, 'loss_2': 0.00444793701171875, 'loss_3': -16.456470489501953, 'loss_4': 1.5332701206207275, 'epoch': 11.76}
{'loss': 0.0144, 'grad_norm': 6.8798604011535645, 'learning_rate': 1.825581395348837e-05, 'loss_1': 0.014297900721430779, 'loss_2': 0.0001512765884399414, 'loss_3': -16.31119155883789, 'loss_4': 2.3226542472839355, 'epoch': 11.77}
{'loss': 0.0184, 'grad_norm': 4.904802322387695, 'learning_rate': 1.825e-05, 'loss_1': 0.010733230039477348, 'loss_2': 0.0076751708984375, 'loss_3': -16.468307495117188, 'loss_4': 1.9239503145217896, 'epoch': 11.77}
[INFO|trainer.py:4228] 2025-01-21 13:10:29,923 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:29,923 >>   Batch size = 64
 39%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 2030/5160 [50:34<54:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:37,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03598276153206825, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.358, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.03312106058001518, 'eval_loss_2': 0.00286170095205307, 'eval_loss_3': -18.177278518676758, 'eval_loss_4': 1.7850769758224487, 'epoch': 11.77}
{'loss': 0.0184, 'grad_norm': 6.887700080871582, 'learning_rate': 1.824418604651163e-05, 'loss_1': 0.016025278717279434, 'loss_2': 0.002330780029296875, 'loss_3': -16.342422485351562, 'loss_4': 2.3638381958007812, 'epoch': 11.78}
{'loss': 0.0433, 'grad_norm': 8.622756004333496, 'learning_rate': 1.8238372093023257e-05, 'loss_1': 0.03503100946545601, 'loss_2': 0.00829315185546875, 'loss_3': -16.3663272857666, 'loss_4': 2.093780517578125, 'epoch': 11.78}
{'loss': 0.0324, 'grad_norm': 8.074912071228027, 'learning_rate': 1.8232558139534882e-05, 'loss_1': 0.02721390500664711, 'loss_2': 0.00518035888671875, 'loss_3': -16.43497657775879, 'loss_4': 2.054232358932495, 'epoch': 11.79}
{'loss': 0.0125, 'grad_norm': 5.323010444641113, 'learning_rate': 1.822674418604651e-05, 'loss_1': 0.009812732227146626, 'loss_2': 0.0026416778564453125, 'loss_3': -16.279335021972656, 'loss_4': 1.5565720796585083, 'epoch': 11.8}
{'loss': 0.0143, 'grad_norm': 8.417118072509766, 'learning_rate': 1.822093023255814e-05, 'loss_1': 0.012302727438509464, 'loss_2': 0.0020046234130859375, 'loss_3': -16.389019012451172, 'loss_4': 2.294564723968506, 'epoch': 11.8}
[INFO|trainer.py:4228] 2025-01-21 13:10:37,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:37,307 >>   Batch size = 64
 39%|███████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                     | 2035/5160 [50:41<54:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:44,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04084894061088562, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.907, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.036980655044317245, 'eval_loss_2': 0.003868281841278076, 'eval_loss_3': -18.151100158691406, 'eval_loss_4': 1.7461062669754028, 'epoch': 11.8}
{'loss': 0.0135, 'grad_norm': 5.729538917541504, 'learning_rate': 1.8215116279069768e-05, 'loss_1': 0.00753196282312274, 'loss_2': 0.0059967041015625, 'loss_3': -16.351701736450195, 'loss_4': 1.6743426322937012, 'epoch': 11.81}
{'loss': 0.024, 'grad_norm': 11.231264114379883, 'learning_rate': 1.8209302325581397e-05, 'loss_1': 0.022006778046488762, 'loss_2': 0.0019855499267578125, 'loss_3': -16.39670753479004, 'loss_4': 1.7710225582122803, 'epoch': 11.81}
{'loss': 0.0683, 'grad_norm': 22.925588607788086, 'learning_rate': 1.8203488372093022e-05, 'loss_1': 0.06706178933382034, 'loss_2': 0.001247406005859375, 'loss_3': -16.246715545654297, 'loss_4': 2.0265614986419678, 'epoch': 11.82}
{'loss': 0.0109, 'grad_norm': 6.063388347625732, 'learning_rate': 1.819767441860465e-05, 'loss_1': 0.008946416899561882, 'loss_2': 0.00194549560546875, 'loss_3': -16.323406219482422, 'loss_4': 1.8464823961257935, 'epoch': 11.83}
{'loss': 0.0084, 'grad_norm': 5.203388690948486, 'learning_rate': 1.819186046511628e-05, 'loss_1': 0.00655196700245142, 'loss_2': 0.0018215179443359375, 'loss_3': -16.376689910888672, 'loss_4': 2.1199588775634766, 'epoch': 11.83}
[INFO|trainer.py:4228] 2025-01-21 13:10:44,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:44,677 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                     | 2040/5160 [50:49<54:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:52,041 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04018534719944, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.97, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.036119986325502396, 'eval_loss_2': 0.004065364599227905, 'eval_loss_3': -18.134122848510742, 'eval_loss_4': 1.7710614204406738, 'epoch': 11.83}
{'loss': 0.0135, 'grad_norm': 6.188819408416748, 'learning_rate': 1.8186046511627908e-05, 'loss_1': 0.01277604978531599, 'loss_2': 0.0007195472717285156, 'loss_3': -16.228286743164062, 'loss_4': 1.9665741920471191, 'epoch': 11.84}
{'loss': 0.0188, 'grad_norm': 9.423331260681152, 'learning_rate': 1.8180232558139537e-05, 'loss_1': 0.018403980880975723, 'loss_2': 0.000370025634765625, 'loss_3': -16.27034568786621, 'loss_4': 1.7986928224563599, 'epoch': 11.84}
{'loss': 0.0125, 'grad_norm': 5.829015254974365, 'learning_rate': 1.8174418604651162e-05, 'loss_1': 0.00818044412881136, 'loss_2': 0.00429534912109375, 'loss_3': -16.533275604248047, 'loss_4': 2.2588694095611572, 'epoch': 11.85}
{'loss': 0.0327, 'grad_norm': 16.407773971557617, 'learning_rate': 1.816860465116279e-05, 'loss_1': 0.032627079635858536, 'loss_2': 0.00010722875595092773, 'loss_3': -16.292160034179688, 'loss_4': 1.8913317918777466, 'epoch': 11.85}
{'loss': 0.0128, 'grad_norm': 7.870199203491211, 'learning_rate': 1.816279069767442e-05, 'loss_1': 0.012639540247619152, 'loss_2': 0.00012183189392089844, 'loss_3': -16.37495994567871, 'loss_4': 1.5713424682617188, 'epoch': 11.86}
[INFO|trainer.py:4228] 2025-01-21 13:10:52,041 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:52,041 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                     | 2045/5160 [50:56<54:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:10:59,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03722691535949707, 'eval_runtime': 3.8253, 'eval_samples_per_second': 267.692, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.03365262225270271, 'eval_loss_2': 0.0035742931067943573, 'eval_loss_3': -18.14453125, 'eval_loss_4': 1.8541579246520996, 'epoch': 11.86}
{'loss': 0.0089, 'grad_norm': 4.728720188140869, 'learning_rate': 1.8156976744186048e-05, 'loss_1': 0.007401513401418924, 'loss_2': 0.0014972686767578125, 'loss_3': -16.267065048217773, 'loss_4': 1.8936169147491455, 'epoch': 11.87}
{'loss': 0.0511, 'grad_norm': 28.884822845458984, 'learning_rate': 1.8151162790697676e-05, 'loss_1': 0.045471616089344025, 'loss_2': 0.0056610107421875, 'loss_3': -16.293973922729492, 'loss_4': 1.7994353771209717, 'epoch': 11.87}
{'loss': 0.0159, 'grad_norm': 7.022961616516113, 'learning_rate': 1.81453488372093e-05, 'loss_1': 0.014392698183655739, 'loss_2': 0.0014934539794921875, 'loss_3': -16.009143829345703, 'loss_4': 1.716259241104126, 'epoch': 11.88}
{'loss': 0.007, 'grad_norm': 4.467131614685059, 'learning_rate': 1.813953488372093e-05, 'loss_1': 0.0058091687969863415, 'loss_2': 0.0011463165283203125, 'loss_3': -16.449161529541016, 'loss_4': 1.7819265127182007, 'epoch': 11.88}
{'loss': 0.0182, 'grad_norm': 7.179595947265625, 'learning_rate': 1.813372093023256e-05, 'loss_1': 0.016883790493011475, 'loss_2': 0.0012826919555664062, 'loss_3': -16.37186050415039, 'loss_4': 2.1581552028656006, 'epoch': 11.89}
[INFO|trainer.py:4228] 2025-01-21 13:10:59,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:10:59,423 >>   Batch size = 64
 40%|███████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                     | 2050/5160 [51:03<53:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:06,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03967517614364624, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.436, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.03478684276342392, 'eval_loss_2': 0.004888325929641724, 'eval_loss_3': -18.141887664794922, 'eval_loss_4': 1.8172099590301514, 'epoch': 11.89}
{'loss': 0.0239, 'grad_norm': 10.360957145690918, 'learning_rate': 1.8127906976744187e-05, 'loss_1': 0.01802617497742176, 'loss_2': 0.00585174560546875, 'loss_3': -16.202800750732422, 'loss_4': 1.9500008821487427, 'epoch': 11.9}
{'loss': 0.0244, 'grad_norm': 6.852203845977783, 'learning_rate': 1.8122093023255816e-05, 'loss_1': 0.015707720071077347, 'loss_2': 0.0086822509765625, 'loss_3': -16.430044174194336, 'loss_4': 1.502850890159607, 'epoch': 11.9}
{'loss': 0.0255, 'grad_norm': 10.180155754089355, 'learning_rate': 1.811627906976744e-05, 'loss_1': 0.023766053840517998, 'loss_2': 0.0017156600952148438, 'loss_3': -16.508045196533203, 'loss_4': 2.018423557281494, 'epoch': 11.91}
{'loss': 0.0174, 'grad_norm': 7.029443740844727, 'learning_rate': 1.811046511627907e-05, 'loss_1': 0.012490752153098583, 'loss_2': 0.00489044189453125, 'loss_3': -16.27984619140625, 'loss_4': 1.3311984539031982, 'epoch': 11.91}
{'loss': 0.011, 'grad_norm': 5.602048397064209, 'learning_rate': 1.81046511627907e-05, 'loss_1': 0.008019061759114265, 'loss_2': 0.002948760986328125, 'loss_3': -16.419178009033203, 'loss_4': 1.8088009357452393, 'epoch': 11.92}
[INFO|trainer.py:4228] 2025-01-21 13:11:06,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:06,793 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                     | 2055/5160 [51:11<53:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:14,171 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.039188921451568604, 'eval_runtime': 3.8208, 'eval_samples_per_second': 268.007, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.03501814603805542, 'eval_loss_2': 0.004170775413513184, 'eval_loss_3': -18.130273818969727, 'eval_loss_4': 1.6255221366882324, 'epoch': 11.92}
{'loss': 0.0137, 'grad_norm': 4.984699726104736, 'learning_rate': 1.8098837209302327e-05, 'loss_1': 0.012439325451850891, 'loss_2': 0.0012178421020507812, 'loss_3': -16.369504928588867, 'loss_4': 2.02551531791687, 'epoch': 11.92}
{'loss': 0.021, 'grad_norm': 11.850783348083496, 'learning_rate': 1.8093023255813953e-05, 'loss_1': 0.016805410385131836, 'loss_2': 0.004222869873046875, 'loss_3': -16.37617301940918, 'loss_4': 0.9819334745407104, 'epoch': 11.93}
{'loss': 0.0099, 'grad_norm': 5.792394638061523, 'learning_rate': 1.808720930232558e-05, 'loss_1': 0.009719092398881912, 'loss_2': 0.00018799304962158203, 'loss_3': -16.168106079101562, 'loss_4': 1.609763503074646, 'epoch': 11.94}
{'loss': 0.0139, 'grad_norm': 7.879602909088135, 'learning_rate': 1.808139534883721e-05, 'loss_1': 0.013326290994882584, 'loss_2': 0.0005741119384765625, 'loss_3': -16.429061889648438, 'loss_4': 1.628547191619873, 'epoch': 11.94}
{'loss': 0.0154, 'grad_norm': 6.646278381347656, 'learning_rate': 1.807558139534884e-05, 'loss_1': 0.012592512182891369, 'loss_2': 0.0028476715087890625, 'loss_3': -16.277795791625977, 'loss_4': 1.326440453529358, 'epoch': 11.95}
[INFO|trainer.py:4228] 2025-01-21 13:11:14,171 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:14,172 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                    | 2060/5160 [51:18<53:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:21,539 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03863426297903061, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.567, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.033775053918361664, 'eval_loss_2': 0.004859209060668945, 'eval_loss_3': -18.168167114257812, 'eval_loss_4': 1.2421934604644775, 'epoch': 11.95}
{'loss': 0.0134, 'grad_norm': 5.2229390144348145, 'learning_rate': 1.8069767441860467e-05, 'loss_1': 0.013276739045977592, 'loss_2': 7.808208465576172e-05, 'loss_3': -16.385421752929688, 'loss_4': 1.462862253189087, 'epoch': 11.95}
{'loss': 0.0111, 'grad_norm': 5.654594421386719, 'learning_rate': 1.8063953488372092e-05, 'loss_1': 0.008334415964782238, 'loss_2': 0.0027256011962890625, 'loss_3': -16.228179931640625, 'loss_4': 1.0440322160720825, 'epoch': 11.96}
{'loss': 0.0195, 'grad_norm': 8.904731750488281, 'learning_rate': 1.805813953488372e-05, 'loss_1': 0.017643678933382034, 'loss_2': 0.0018939971923828125, 'loss_3': -16.42007827758789, 'loss_4': 1.2498693466186523, 'epoch': 11.97}
{'loss': 0.0107, 'grad_norm': 5.4070515632629395, 'learning_rate': 1.805232558139535e-05, 'loss_1': 0.007941904477775097, 'loss_2': 0.0028076171875, 'loss_3': -16.29656219482422, 'loss_4': 0.9156350493431091, 'epoch': 11.97}
{'loss': 0.0172, 'grad_norm': 5.94448709487915, 'learning_rate': 1.8046511627906978e-05, 'loss_1': 0.009488556534051895, 'loss_2': 0.00775909423828125, 'loss_3': -16.45266342163086, 'loss_4': 0.8576408624649048, 'epoch': 11.98}
[INFO|trainer.py:4228] 2025-01-21 13:11:21,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:21,539 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                    | 2065/5160 [51:25<50:30,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 13:11:28,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03335786610841751, 'eval_runtime': 3.8131, 'eval_samples_per_second': 268.55, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.028750238940119743, 'eval_loss_2': 0.004607629030942917, 'eval_loss_3': -18.168838500976562, 'eval_loss_4': 1.026046872138977, 'epoch': 11.98}
{'loss': 0.1704, 'grad_norm': 22.791902542114258, 'learning_rate': 1.8040697674418607e-05, 'loss_1': 0.1696675568819046, 'loss_2': 0.0007486343383789062, 'loss_3': -16.275836944580078, 'loss_4': 1.2459516525268555, 'epoch': 11.98}
{'loss': 0.0151, 'grad_norm': 6.605932712554932, 'learning_rate': 1.8034883720930232e-05, 'loss_1': 0.008897914551198483, 'loss_2': 0.00617218017578125, 'loss_3': -16.4276065826416, 'loss_4': 0.8668517470359802, 'epoch': 11.99}
{'loss': 0.0324, 'grad_norm': 14.219752311706543, 'learning_rate': 1.802906976744186e-05, 'loss_1': 0.031698815524578094, 'loss_2': 0.0007028579711914062, 'loss_3': -16.436702728271484, 'loss_4': 0.9281603097915649, 'epoch': 11.99}
{'loss': 0.009, 'grad_norm': 8.56131362915039, 'learning_rate': 1.8023255813953486e-05, 'loss_1': 0.008877883665263653, 'loss_2': 0.000125885009765625, 'loss_3': -16.38698959350586, 'loss_4': 1.2782702445983887, 'epoch': 12.0}
{'loss': 0.0168, 'grad_norm': 5.554904937744141, 'learning_rate': 1.8017441860465118e-05, 'loss_1': 0.007900848984718323, 'loss_2': 0.0089263916015625, 'loss_3': -16.290842056274414, 'loss_4': 1.3434946537017822, 'epoch': 12.01}
[INFO|trainer.py:4228] 2025-01-21 13:11:28,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:28,589 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                    | 2070/5160 [51:33<53:01,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:11:35,952 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0335693359375, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.566, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.02931702323257923, 'eval_loss_2': 0.004252314567565918, 'eval_loss_3': -18.159055709838867, 'eval_loss_4': 1.131502389907837, 'epoch': 12.01}
{'loss': 0.0198, 'grad_norm': 5.519954204559326, 'learning_rate': 1.8011627906976747e-05, 'loss_1': 0.009257052093744278, 'loss_2': 0.010498046875, 'loss_3': -16.354278564453125, 'loss_4': 1.4327714443206787, 'epoch': 12.01}
{'loss': 0.0112, 'grad_norm': 5.476034641265869, 'learning_rate': 1.8005813953488372e-05, 'loss_1': 0.01039830967783928, 'loss_2': 0.0008139610290527344, 'loss_3': -16.29435920715332, 'loss_4': 1.6530418395996094, 'epoch': 12.02}
{'loss': 0.0086, 'grad_norm': 5.192275047302246, 'learning_rate': 1.8e-05, 'loss_1': 0.005960814189165831, 'loss_2': 0.002674102783203125, 'loss_3': -16.17087745666504, 'loss_4': 1.5250344276428223, 'epoch': 12.02}
{'loss': 0.0159, 'grad_norm': 5.703657627105713, 'learning_rate': 1.7994186046511626e-05, 'loss_1': 0.012431164272129536, 'loss_2': 0.0034618377685546875, 'loss_3': -16.542871475219727, 'loss_4': 0.8419548869132996, 'epoch': 12.03}
{'loss': 0.0235, 'grad_norm': 9.50234317779541, 'learning_rate': 1.7988372093023258e-05, 'loss_1': 0.015060813166201115, 'loss_2': 0.0084381103515625, 'loss_3': -16.299697875976562, 'loss_4': 1.2626994848251343, 'epoch': 12.03}
[INFO|trainer.py:4228] 2025-01-21 13:11:35,952 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:35,953 >>   Batch size = 64
 40%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                    | 2075/5160 [51:40<53:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:43,317 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03655882924795151, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.03306858614087105, 'eval_loss_2': 0.003490246832370758, 'eval_loss_3': -18.14923858642578, 'eval_loss_4': 1.1580817699432373, 'epoch': 12.03}
{'loss': 0.0105, 'grad_norm': 8.033951759338379, 'learning_rate': 1.7982558139534886e-05, 'loss_1': 0.0102250836789608, 'loss_2': 0.0002956390380859375, 'loss_3': -16.52532958984375, 'loss_4': 1.3555302619934082, 'epoch': 12.04}
{'loss': 0.0072, 'grad_norm': 4.52842378616333, 'learning_rate': 1.797674418604651e-05, 'loss_1': 0.004272001795470715, 'loss_2': 0.002899169921875, 'loss_3': -16.471752166748047, 'loss_4': 1.2962450981140137, 'epoch': 12.05}
{'loss': 0.0144, 'grad_norm': 7.457597732543945, 'learning_rate': 1.797093023255814e-05, 'loss_1': 0.012912949547171593, 'loss_2': 0.0015010833740234375, 'loss_3': -16.320613861083984, 'loss_4': 1.215530276298523, 'epoch': 12.05}
{'loss': 0.0283, 'grad_norm': 13.812104225158691, 'learning_rate': 1.7965116279069765e-05, 'loss_1': 0.02495557628571987, 'loss_2': 0.003376007080078125, 'loss_3': -16.3912353515625, 'loss_4': 1.541568636894226, 'epoch': 12.06}
{'loss': 0.011, 'grad_norm': 5.696653366088867, 'learning_rate': 1.7959302325581397e-05, 'loss_1': 0.006719965022057295, 'loss_2': 0.004306793212890625, 'loss_3': -16.36827850341797, 'loss_4': 1.461703896522522, 'epoch': 12.06}
[INFO|trainer.py:4228] 2025-01-21 13:11:43,317 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:43,318 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                    | 2080/5160 [51:47<53:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:50,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03293230012059212, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.75, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.029647372663021088, 'eval_loss_2': 0.003284931182861328, 'eval_loss_3': -18.148937225341797, 'eval_loss_4': 1.152745246887207, 'epoch': 12.06}
{'loss': 0.0209, 'grad_norm': 7.629878044128418, 'learning_rate': 1.7953488372093023e-05, 'loss_1': 0.01357068121433258, 'loss_2': 0.0073394775390625, 'loss_3': -16.245243072509766, 'loss_4': 1.5635758638381958, 'epoch': 12.07}
{'loss': 0.0124, 'grad_norm': 5.608914375305176, 'learning_rate': 1.794767441860465e-05, 'loss_1': 0.009678599424660206, 'loss_2': 0.00267791748046875, 'loss_3': -16.22026824951172, 'loss_4': 1.5674831867218018, 'epoch': 12.08}
{'loss': 0.0191, 'grad_norm': 7.143929958343506, 'learning_rate': 1.794186046511628e-05, 'loss_1': 0.012884345836937428, 'loss_2': 0.006195068359375, 'loss_3': -16.30492401123047, 'loss_4': 0.6711803078651428, 'epoch': 12.08}
{'loss': 0.0246, 'grad_norm': 11.498881340026855, 'learning_rate': 1.7936046511627905e-05, 'loss_1': 0.02029469609260559, 'loss_2': 0.004344940185546875, 'loss_3': -16.165023803710938, 'loss_4': 1.2837127447128296, 'epoch': 12.09}
{'loss': 0.0267, 'grad_norm': 12.5615234375, 'learning_rate': 1.7930232558139537e-05, 'loss_1': 0.021889708936214447, 'loss_2': 0.004779815673828125, 'loss_3': -16.37411117553711, 'loss_4': 1.1570587158203125, 'epoch': 12.09}
[INFO|trainer.py:4228] 2025-01-21 13:11:50,683 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:50,683 >>   Batch size = 64
 40%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                   | 2085/5160 [51:55<53:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:11:58,050 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027838177978992462, 'eval_runtime': 3.8196, 'eval_samples_per_second': 268.089, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.023255832493305206, 'eval_loss_2': 0.004582345485687256, 'eval_loss_3': -18.170724868774414, 'eval_loss_4': 1.1159402132034302, 'epoch': 12.09}
{'loss': 0.0062, 'grad_norm': 4.300674915313721, 'learning_rate': 1.7924418604651163e-05, 'loss_1': 0.004216993227601051, 'loss_2': 0.001983642578125, 'loss_3': -16.607711791992188, 'loss_4': 1.140536904335022, 'epoch': 12.1}
{'loss': 0.0141, 'grad_norm': 5.492016315460205, 'learning_rate': 1.791860465116279e-05, 'loss_1': 0.006230626720935106, 'loss_2': 0.0079193115234375, 'loss_3': -16.41233253479004, 'loss_4': 1.154388427734375, 'epoch': 12.1}
{'loss': 0.0111, 'grad_norm': 4.994042873382568, 'learning_rate': 1.791279069767442e-05, 'loss_1': 0.005216089077293873, 'loss_2': 0.0058746337890625, 'loss_3': -16.55267333984375, 'loss_4': 1.452329158782959, 'epoch': 12.11}
{'loss': 0.0096, 'grad_norm': 5.202404022216797, 'learning_rate': 1.7906976744186045e-05, 'loss_1': 0.004118294920772314, 'loss_2': 0.00547027587890625, 'loss_3': -16.42158317565918, 'loss_4': 1.4102098941802979, 'epoch': 12.12}
{'loss': 0.0133, 'grad_norm': 5.814456939697266, 'learning_rate': 1.7901162790697677e-05, 'loss_1': 0.006764426827430725, 'loss_2': 0.006542205810546875, 'loss_3': -16.503887176513672, 'loss_4': 1.0717904567718506, 'epoch': 12.12}
[INFO|trainer.py:4228] 2025-01-21 13:11:58,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:11:58,051 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                   | 2090/5160 [52:02<53:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:05,407 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02055615931749344, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.863, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.01555696688592434, 'eval_loss_2': 0.00499919056892395, 'eval_loss_3': -18.21588897705078, 'eval_loss_4': 1.025713324546814, 'epoch': 12.12}
{'loss': 0.0084, 'grad_norm': 4.977168560028076, 'learning_rate': 1.7895348837209302e-05, 'loss_1': 0.004964056424796581, 'loss_2': 0.003391265869140625, 'loss_3': -16.628055572509766, 'loss_4': 0.6327616572380066, 'epoch': 12.13}
{'loss': 0.0102, 'grad_norm': 5.480329513549805, 'learning_rate': 1.788953488372093e-05, 'loss_1': 0.007411055266857147, 'loss_2': 0.00276947021484375, 'loss_3': -16.296634674072266, 'loss_4': 0.5382748246192932, 'epoch': 12.13}
{'loss': 0.0098, 'grad_norm': 4.126989841461182, 'learning_rate': 1.7883720930232556e-05, 'loss_1': 0.0023109198082238436, 'loss_2': 0.0074462890625, 'loss_3': -16.49538803100586, 'loss_4': 0.6295197606086731, 'epoch': 12.14}
{'loss': 0.0106, 'grad_norm': 5.268143177032471, 'learning_rate': 1.7877906976744185e-05, 'loss_1': 0.004926773719489574, 'loss_2': 0.005645751953125, 'loss_3': -16.47224235534668, 'loss_4': 1.1180791854858398, 'epoch': 12.15}
{'loss': 0.0134, 'grad_norm': 5.798586368560791, 'learning_rate': 1.7872093023255817e-05, 'loss_1': 0.01022830419242382, 'loss_2': 0.0031585693359375, 'loss_3': -16.385631561279297, 'loss_4': 0.7415158152580261, 'epoch': 12.15}
[INFO|trainer.py:4228] 2025-01-21 13:12:05,407 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:05,407 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                   | 2095/5160 [52:09<53:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:12,768 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015703298151493073, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.806, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009880638681352139, 'eval_loss_2': 0.005822658538818359, 'eval_loss_3': -18.25719451904297, 'eval_loss_4': 0.954582929611206, 'epoch': 12.15}
{'loss': 0.03, 'grad_norm': 6.805741310119629, 'learning_rate': 1.7866279069767442e-05, 'loss_1': 0.01834845542907715, 'loss_2': 0.0116729736328125, 'loss_3': -16.656835556030273, 'loss_4': 1.0793778896331787, 'epoch': 12.16}
{'loss': 0.0102, 'grad_norm': 5.769435882568359, 'learning_rate': 1.786046511627907e-05, 'loss_1': 0.00922469887882471, 'loss_2': 0.0009403228759765625, 'loss_3': -16.493358612060547, 'loss_4': 1.101754903793335, 'epoch': 12.16}
{'loss': 0.0162, 'grad_norm': 5.7814764976501465, 'learning_rate': 1.7854651162790696e-05, 'loss_1': 0.010236742906272411, 'loss_2': 0.00595855712890625, 'loss_3': -16.370594024658203, 'loss_4': 0.7542059421539307, 'epoch': 12.17}
{'loss': 0.0118, 'grad_norm': 6.891265392303467, 'learning_rate': 1.7848837209302325e-05, 'loss_1': 0.010732901282608509, 'loss_2': 0.0010547637939453125, 'loss_3': -16.392566680908203, 'loss_4': 0.9255608320236206, 'epoch': 12.17}
{'loss': 0.0291, 'grad_norm': 10.09178638458252, 'learning_rate': 1.7843023255813957e-05, 'loss_1': 0.019359294325113297, 'loss_2': 0.0097503662109375, 'loss_3': -16.386741638183594, 'loss_4': 1.6305561065673828, 'epoch': 12.18}
[INFO|trainer.py:4228] 2025-01-21 13:12:12,768 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:12,768 >>   Batch size = 64
 41%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                   | 2100/5160 [52:17<53:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:20,128 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01875164732336998, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.839, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009493614546954632, 'eval_loss_2': 0.009258031845092773, 'eval_loss_3': -18.285003662109375, 'eval_loss_4': 0.8897301554679871, 'epoch': 12.18}
{'loss': 0.0173, 'grad_norm': 5.718810558319092, 'learning_rate': 1.7837209302325582e-05, 'loss_1': 0.014540685340762138, 'loss_2': 0.002803802490234375, 'loss_3': -16.577220916748047, 'loss_4': 0.6008921265602112, 'epoch': 12.19}
{'loss': 0.0143, 'grad_norm': 5.456420421600342, 'learning_rate': 1.783139534883721e-05, 'loss_1': 0.007500625681132078, 'loss_2': 0.0067901611328125, 'loss_3': -16.291473388671875, 'loss_4': 0.7841947674751282, 'epoch': 12.19}
{'loss': 0.0149, 'grad_norm': 5.029832363128662, 'learning_rate': 1.7825581395348836e-05, 'loss_1': 0.006140204146504402, 'loss_2': 0.00876617431640625, 'loss_3': -16.326717376708984, 'loss_4': 0.7849054336547852, 'epoch': 12.2}
{'loss': 0.0212, 'grad_norm': 11.570054054260254, 'learning_rate': 1.7819767441860464e-05, 'loss_1': 0.020399076864123344, 'loss_2': 0.0007739067077636719, 'loss_3': -16.47810173034668, 'loss_4': 1.5108165740966797, 'epoch': 12.2}
{'loss': 0.0138, 'grad_norm': 5.724723815917969, 'learning_rate': 1.7813953488372093e-05, 'loss_1': 0.010229373350739479, 'loss_2': 0.003574371337890625, 'loss_3': -16.41836166381836, 'loss_4': 0.8490724563598633, 'epoch': 12.21}
[INFO|trainer.py:4228] 2025-01-21 13:12:20,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:20,129 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                  | 2105/5160 [52:24<52:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:27,493 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013406826183199883, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.584, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010419324971735477, 'eval_loss_2': 0.0029875002801418304, 'eval_loss_3': -18.2912540435791, 'eval_loss_4': 1.019779920578003, 'epoch': 12.21}
{'loss': 0.0119, 'grad_norm': 4.580657958984375, 'learning_rate': 1.780813953488372e-05, 'loss_1': 0.00847671553492546, 'loss_2': 0.0034027099609375, 'loss_3': -16.50802993774414, 'loss_4': 0.6829770803451538, 'epoch': 12.22}
{'loss': 0.0168, 'grad_norm': 7.032975673675537, 'learning_rate': 1.780232558139535e-05, 'loss_1': 0.015126262791454792, 'loss_2': 0.00162506103515625, 'loss_3': -16.479434967041016, 'loss_4': 1.0298666954040527, 'epoch': 12.22}
{'loss': 0.0146, 'grad_norm': 7.191895484924316, 'learning_rate': 1.7796511627906975e-05, 'loss_1': 0.008855251595377922, 'loss_2': 0.0057525634765625, 'loss_3': -16.43235969543457, 'loss_4': 0.8398340940475464, 'epoch': 12.23}
{'loss': 0.0222, 'grad_norm': 11.366540908813477, 'learning_rate': 1.7790697674418608e-05, 'loss_1': 0.019719291478395462, 'loss_2': 0.0025196075439453125, 'loss_3': -16.13093376159668, 'loss_4': 1.2321062088012695, 'epoch': 12.23}
{'loss': 0.0185, 'grad_norm': 7.683167457580566, 'learning_rate': 1.7784883720930233e-05, 'loss_1': 0.015244399197399616, 'loss_2': 0.0032405853271484375, 'loss_3': -16.59711456298828, 'loss_4': 1.0526903867721558, 'epoch': 12.24}
[INFO|trainer.py:4228] 2025-01-21 13:12:27,493 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:27,493 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                  | 2110/5160 [52:32<52:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:34,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01638585515320301, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.04, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.01004891935735941, 'eval_loss_2': 0.006336934864521027, 'eval_loss_3': -18.242687225341797, 'eval_loss_4': 1.1796702146530151, 'epoch': 12.24}
{'loss': 0.0122, 'grad_norm': 6.0933918952941895, 'learning_rate': 1.777906976744186e-05, 'loss_1': 0.010990861803293228, 'loss_2': 0.0012483596801757812, 'loss_3': -16.340225219726562, 'loss_4': 1.2176425457000732, 'epoch': 12.24}
{'loss': 0.0115, 'grad_norm': 4.733649730682373, 'learning_rate': 1.777325581395349e-05, 'loss_1': 0.004889179486781359, 'loss_2': 0.006591796875, 'loss_3': -16.404085159301758, 'loss_4': 1.286545753479004, 'epoch': 12.25}
{'loss': 0.0589, 'grad_norm': 20.658584594726562, 'learning_rate': 1.7767441860465115e-05, 'loss_1': 0.0453835129737854, 'loss_2': 0.0135345458984375, 'loss_3': -16.52579116821289, 'loss_4': 1.8974428176879883, 'epoch': 12.26}
{'loss': 0.0108, 'grad_norm': 4.901292324066162, 'learning_rate': 1.7761627906976747e-05, 'loss_1': 0.0070277308113873005, 'loss_2': 0.003757476806640625, 'loss_3': -16.321392059326172, 'loss_4': 1.579974889755249, 'epoch': 12.26}
{'loss': 0.0115, 'grad_norm': 5.055803298950195, 'learning_rate': 1.7755813953488373e-05, 'loss_1': 0.0066654272377491, 'loss_2': 0.004852294921875, 'loss_3': -16.4952392578125, 'loss_4': 1.187726378440857, 'epoch': 12.27}
[INFO|trainer.py:4228] 2025-01-21 13:12:34,876 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:34,876 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                  | 2115/5160 [52:39<52:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:42,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015414847061038017, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.635, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01124537456780672, 'eval_loss_2': 0.004169471561908722, 'eval_loss_3': -18.24627113342285, 'eval_loss_4': 1.2580113410949707, 'epoch': 12.27}
{'loss': 0.0182, 'grad_norm': 11.68078327178955, 'learning_rate': 1.775e-05, 'loss_1': 0.01730009913444519, 'loss_2': 0.0009355545043945312, 'loss_3': -16.594030380249023, 'loss_4': 1.1301326751708984, 'epoch': 12.27}
{'loss': 0.0118, 'grad_norm': 5.000906467437744, 'learning_rate': 1.7744186046511626e-05, 'loss_1': 0.009697230532765388, 'loss_2': 0.00208282470703125, 'loss_3': -16.60228729248047, 'loss_4': 0.5758087635040283, 'epoch': 12.28}
{'loss': 0.028, 'grad_norm': 8.580852508544922, 'learning_rate': 1.7738372093023255e-05, 'loss_1': 0.023617472499608994, 'loss_2': 0.004344940185546875, 'loss_3': -16.35826873779297, 'loss_4': 1.7620208263397217, 'epoch': 12.28}
{'loss': 0.0134, 'grad_norm': 4.4865264892578125, 'learning_rate': 1.7732558139534887e-05, 'loss_1': 0.008293465711176395, 'loss_2': 0.0051116943359375, 'loss_3': -16.467348098754883, 'loss_4': 1.198218822479248, 'epoch': 12.29}
{'loss': 0.0069, 'grad_norm': 4.893322467803955, 'learning_rate': 1.7726744186046512e-05, 'loss_1': 0.005950281862169504, 'loss_2': 0.000988006591796875, 'loss_3': -16.649749755859375, 'loss_4': 1.2946922779083252, 'epoch': 12.3}
[INFO|trainer.py:4228] 2025-01-21 13:12:42,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:42,240 >>   Batch size = 64
 41%|██████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                  | 2120/5160 [52:46<52:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:49,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01726190187036991, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.529, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012600521557033062, 'eval_loss_2': 0.004661381244659424, 'eval_loss_3': -18.24527931213379, 'eval_loss_4': 1.3090946674346924, 'epoch': 12.3}
{'loss': 0.0135, 'grad_norm': 5.3475661277771, 'learning_rate': 1.772093023255814e-05, 'loss_1': 0.00820207316428423, 'loss_2': 0.00531005859375, 'loss_3': -16.674991607666016, 'loss_4': 1.0778591632843018, 'epoch': 12.3}
{'loss': 0.0299, 'grad_norm': 13.430802345275879, 'learning_rate': 1.7715116279069766e-05, 'loss_1': 0.02838064171373844, 'loss_2': 0.001529693603515625, 'loss_3': -16.608779907226562, 'loss_4': 1.3649905920028687, 'epoch': 12.31}
{'loss': 0.0147, 'grad_norm': 8.876959800720215, 'learning_rate': 1.7709302325581395e-05, 'loss_1': 0.010977215133607388, 'loss_2': 0.0037078857421875, 'loss_3': -16.51639175415039, 'loss_4': 1.1526963710784912, 'epoch': 12.31}
{'loss': 0.0327, 'grad_norm': 13.162041664123535, 'learning_rate': 1.7703488372093027e-05, 'loss_1': 0.02940485067665577, 'loss_2': 0.003292083740234375, 'loss_3': -16.536380767822266, 'loss_4': 1.8916560411453247, 'epoch': 12.32}
{'loss': 0.0137, 'grad_norm': 6.067975044250488, 'learning_rate': 1.7697674418604652e-05, 'loss_1': 0.011264104396104813, 'loss_2': 0.00246429443359375, 'loss_3': -16.472822189331055, 'loss_4': 1.4689409732818604, 'epoch': 12.33}
[INFO|trainer.py:4228] 2025-01-21 13:12:49,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:49,617 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                  | 2125/5160 [52:54<52:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:12:56,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015983421355485916, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.065, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01101613324135542, 'eval_loss_2': 0.004967290908098221, 'eval_loss_3': -18.29171371459961, 'eval_loss_4': 1.3295814990997314, 'epoch': 12.33}
{'loss': 0.014, 'grad_norm': 5.222020626068115, 'learning_rate': 1.769186046511628e-05, 'loss_1': 0.006217648275196552, 'loss_2': 0.00775146484375, 'loss_3': -16.595930099487305, 'loss_4': 1.4409747123718262, 'epoch': 12.33}
{'loss': 0.0155, 'grad_norm': 4.951228618621826, 'learning_rate': 1.7686046511627906e-05, 'loss_1': 0.00893697515130043, 'loss_2': 0.00659942626953125, 'loss_3': -16.552303314208984, 'loss_4': 1.0085500478744507, 'epoch': 12.34}
{'loss': 0.0116, 'grad_norm': 5.863384246826172, 'learning_rate': 1.7680232558139535e-05, 'loss_1': 0.00870174914598465, 'loss_2': 0.0029430389404296875, 'loss_3': -16.50243377685547, 'loss_4': 1.1194837093353271, 'epoch': 12.34}
{'loss': 0.0165, 'grad_norm': 6.268644332885742, 'learning_rate': 1.7674418604651163e-05, 'loss_1': 0.011459304951131344, 'loss_2': 0.005077362060546875, 'loss_3': -16.386852264404297, 'loss_4': 1.3931610584259033, 'epoch': 12.35}
{'loss': 0.0144, 'grad_norm': 6.5156168937683105, 'learning_rate': 1.7668604651162792e-05, 'loss_1': 0.010363521054387093, 'loss_2': 0.00406646728515625, 'loss_3': -16.509899139404297, 'loss_4': 0.7245603799819946, 'epoch': 12.35}
[INFO|trainer.py:4228] 2025-01-21 13:12:56,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:12:56,986 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                                 | 2130/5160 [53:01<52:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:04,357 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01865292154252529, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.294, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.01217598281800747, 'eval_loss_2': 0.006476938724517822, 'eval_loss_3': -18.312620162963867, 'eval_loss_4': 1.0897750854492188, 'epoch': 12.35}
{'loss': 0.0236, 'grad_norm': 10.558225631713867, 'learning_rate': 1.766279069767442e-05, 'loss_1': 0.01946907676756382, 'loss_2': 0.004119873046875, 'loss_3': -16.568115234375, 'loss_4': 1.3743984699249268, 'epoch': 12.36}
{'loss': 0.0254, 'grad_norm': 7.256489276885986, 'learning_rate': 1.7656976744186046e-05, 'loss_1': 0.017371123656630516, 'loss_2': 0.00799560546875, 'loss_3': -16.575834274291992, 'loss_4': 1.0523974895477295, 'epoch': 12.37}
{'loss': 0.0204, 'grad_norm': 5.855543613433838, 'learning_rate': 1.7651162790697674e-05, 'loss_1': 0.010981041938066483, 'loss_2': 0.00939178466796875, 'loss_3': -16.641101837158203, 'loss_4': 1.087006688117981, 'epoch': 12.37}
{'loss': 0.0216, 'grad_norm': 9.343826293945312, 'learning_rate': 1.7645348837209303e-05, 'loss_1': 0.017756858840584755, 'loss_2': 0.00384521484375, 'loss_3': -16.445926666259766, 'loss_4': 1.2622878551483154, 'epoch': 12.38}
{'loss': 0.0262, 'grad_norm': 5.226988315582275, 'learning_rate': 1.763953488372093e-05, 'loss_1': 0.0119674913585186, 'loss_2': 0.01425933837890625, 'loss_3': -16.42178726196289, 'loss_4': 1.062760829925537, 'epoch': 12.38}
[INFO|trainer.py:4228] 2025-01-21 13:13:04,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:04,357 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                 | 2135/5160 [53:08<52:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:11,737 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01783640868961811, 'eval_runtime': 3.8204, 'eval_samples_per_second': 268.033, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.01174129731953144, 'eval_loss_2': 0.00609511137008667, 'eval_loss_3': -18.325788497924805, 'eval_loss_4': 0.9155017733573914, 'epoch': 12.38}
{'loss': 0.0175, 'grad_norm': 8.298832893371582, 'learning_rate': 1.763372093023256e-05, 'loss_1': 0.015089042484760284, 'loss_2': 0.002452850341796875, 'loss_3': -16.62853240966797, 'loss_4': 0.41042640805244446, 'epoch': 12.39}
{'loss': 0.0096, 'grad_norm': 6.188076496124268, 'learning_rate': 1.7627906976744185e-05, 'loss_1': 0.009491032920777798, 'loss_2': 8.803606033325195e-05, 'loss_3': -16.485755920410156, 'loss_4': 0.7284826040267944, 'epoch': 12.4}
{'loss': 0.0217, 'grad_norm': 5.987249851226807, 'learning_rate': 1.7622093023255814e-05, 'loss_1': 0.014620604924857616, 'loss_2': 0.00704193115234375, 'loss_3': -16.273296356201172, 'loss_4': 0.8840727806091309, 'epoch': 12.4}
{'loss': 0.0323, 'grad_norm': 10.747962951660156, 'learning_rate': 1.7616279069767443e-05, 'loss_1': 0.03216078504920006, 'loss_2': 0.0001327991485595703, 'loss_3': -16.493680953979492, 'loss_4': 1.5320301055908203, 'epoch': 12.41}
{'loss': 0.0105, 'grad_norm': 6.245964050292969, 'learning_rate': 1.761046511627907e-05, 'loss_1': 0.008464432321488857, 'loss_2': 0.002017974853515625, 'loss_3': -16.70792579650879, 'loss_4': 0.8158255815505981, 'epoch': 12.41}
[INFO|trainer.py:4228] 2025-01-21 13:13:11,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:11,738 >>   Batch size = 64
 41%|███████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                 | 2140/5160 [53:16<52:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:19,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015319667756557465, 'eval_runtime': 3.8248, 'eval_samples_per_second': 267.724, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.010034821927547455, 'eval_loss_2': 0.00528484582901001, 'eval_loss_3': -18.283906936645508, 'eval_loss_4': 0.7835568785667419, 'epoch': 12.41}
{'loss': 0.0185, 'grad_norm': 5.362898826599121, 'learning_rate': 1.7604651162790697e-05, 'loss_1': 0.012937578372657299, 'loss_2': 0.00557708740234375, 'loss_3': -16.54854965209961, 'loss_4': 0.48569199442863464, 'epoch': 12.42}
{'loss': 0.0142, 'grad_norm': 5.8689470291137695, 'learning_rate': 1.7598837209302325e-05, 'loss_1': 0.009924829937517643, 'loss_2': 0.00424957275390625, 'loss_3': -16.427379608154297, 'loss_4': 0.7366889119148254, 'epoch': 12.42}
{'loss': 0.0676, 'grad_norm': 15.570413589477539, 'learning_rate': 1.7593023255813954e-05, 'loss_1': 0.06758471578359604, 'loss_2': 2.384185791015625e-05, 'loss_3': -16.39022445678711, 'loss_4': 1.1098506450653076, 'epoch': 12.43}
{'loss': 0.0576, 'grad_norm': 10.313017845153809, 'learning_rate': 1.7587209302325583e-05, 'loss_1': 0.054005760699510574, 'loss_2': 0.003589630126953125, 'loss_3': -16.44516372680664, 'loss_4': 0.6617943644523621, 'epoch': 12.44}
{'loss': 0.0262, 'grad_norm': 10.078415870666504, 'learning_rate': 1.758139534883721e-05, 'loss_1': 0.01732437126338482, 'loss_2': 0.0088653564453125, 'loss_3': -16.455211639404297, 'loss_4': 0.4964715838432312, 'epoch': 12.44}
[INFO|trainer.py:4228] 2025-01-21 13:13:19,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:19,110 >>   Batch size = 64
 42%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 2145/5160 [53:23<52:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:26,472 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016132794320583344, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.688, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010471037589013577, 'eval_loss_2': 0.005661755800247192, 'eval_loss_3': -18.27349090576172, 'eval_loss_4': 0.4846743941307068, 'epoch': 12.44}
{'loss': 0.0138, 'grad_norm': 5.104462623596191, 'learning_rate': 1.7575581395348836e-05, 'loss_1': 0.006624355912208557, 'loss_2': 0.00717926025390625, 'loss_3': -16.53058624267578, 'loss_4': 0.112339086830616, 'epoch': 12.45}
{'loss': 0.0207, 'grad_norm': 5.3320183753967285, 'learning_rate': 1.7569767441860465e-05, 'loss_1': 0.012069831602275372, 'loss_2': 0.0086669921875, 'loss_3': -16.544103622436523, 'loss_4': -0.04795560985803604, 'epoch': 12.45}
{'loss': 0.029, 'grad_norm': 12.081596374511719, 'learning_rate': 1.7563953488372094e-05, 'loss_1': 0.025954751297831535, 'loss_2': 0.0030670166015625, 'loss_3': -16.21672248840332, 'loss_4': 0.6286051273345947, 'epoch': 12.46}
{'loss': 0.0183, 'grad_norm': 6.117859840393066, 'learning_rate': 1.7558139534883722e-05, 'loss_1': 0.015220049768686295, 'loss_2': 0.003124237060546875, 'loss_3': -16.499032974243164, 'loss_4': 0.1270281821489334, 'epoch': 12.47}
{'loss': 0.0179, 'grad_norm': 6.293691635131836, 'learning_rate': 1.755232558139535e-05, 'loss_1': 0.010550969280302525, 'loss_2': 0.007373809814453125, 'loss_3': -16.616493225097656, 'loss_4': 0.03568849712610245, 'epoch': 12.47}
[INFO|trainer.py:4228] 2025-01-21 13:13:26,473 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:26,473 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                                 | 2150/5160 [53:30<52:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:33,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01509392261505127, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.856, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009484573267400265, 'eval_loss_2': 0.00560934841632843, 'eval_loss_3': -18.254558563232422, 'eval_loss_4': 0.4212811589241028, 'epoch': 12.47}
{'loss': 0.0183, 'grad_norm': 7.592658519744873, 'learning_rate': 1.7546511627906976e-05, 'loss_1': 0.015748867765069008, 'loss_2': 0.0025539398193359375, 'loss_3': -16.51599884033203, 'loss_4': -0.16601203382015228, 'epoch': 12.48}
{'loss': 0.0214, 'grad_norm': 5.692872047424316, 'learning_rate': 1.7540697674418605e-05, 'loss_1': 0.011325488798320293, 'loss_2': 0.0100250244140625, 'loss_3': -16.541608810424805, 'loss_4': 0.18717357516288757, 'epoch': 12.48}
{'loss': 0.0261, 'grad_norm': 10.608376502990723, 'learning_rate': 1.753488372093023e-05, 'loss_1': 0.020273679867386818, 'loss_2': 0.005855560302734375, 'loss_3': -16.4935359954834, 'loss_4': 0.4129081964492798, 'epoch': 12.49}
{'loss': 0.0303, 'grad_norm': 9.403021812438965, 'learning_rate': 1.7529069767441862e-05, 'loss_1': 0.013347629457712173, 'loss_2': 0.0169830322265625, 'loss_3': -16.35759925842285, 'loss_4': 0.07375442981719971, 'epoch': 12.49}
{'loss': 0.0248, 'grad_norm': 5.176526069641113, 'learning_rate': 1.752325581395349e-05, 'loss_1': 0.009884378872811794, 'loss_2': 0.0149078369140625, 'loss_3': -16.399295806884766, 'loss_4': 0.7771962881088257, 'epoch': 12.5}
[INFO|trainer.py:4228] 2025-01-21 13:13:33,835 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:33,835 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                | 2155/5160 [53:38<52:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:41,198 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.022494962438941002, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.628, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009710273705422878, 'eval_loss_2': 0.012784689664840698, 'eval_loss_3': -18.291255950927734, 'eval_loss_4': 0.6101800203323364, 'epoch': 12.5}
{'loss': 0.0193, 'grad_norm': 5.763026237487793, 'learning_rate': 1.7517441860465116e-05, 'loss_1': 0.010681431740522385, 'loss_2': 0.0086669921875, 'loss_3': -16.397245407104492, 'loss_4': 0.860981822013855, 'epoch': 12.51}
{'loss': 0.0303, 'grad_norm': 7.409707546234131, 'learning_rate': 1.7511627906976745e-05, 'loss_1': 0.022323457524180412, 'loss_2': 0.00794219970703125, 'loss_3': -16.624637603759766, 'loss_4': 0.8466706275939941, 'epoch': 12.51}
{'loss': 0.0127, 'grad_norm': 4.960326671600342, 'learning_rate': 1.750581395348837e-05, 'loss_1': 0.005164034198969603, 'loss_2': 0.007518768310546875, 'loss_3': -16.57906723022461, 'loss_4': 1.2628934383392334, 'epoch': 12.52}
{'loss': 0.0302, 'grad_norm': 9.391222953796387, 'learning_rate': 1.7500000000000002e-05, 'loss_1': 0.018116503953933716, 'loss_2': 0.0120697021484375, 'loss_3': -16.4345645904541, 'loss_4': -0.04292869567871094, 'epoch': 12.52}
{'loss': 0.0226, 'grad_norm': 5.687272548675537, 'learning_rate': 1.7494186046511627e-05, 'loss_1': 0.013369148597121239, 'loss_2': 0.009185791015625, 'loss_3': -16.359968185424805, 'loss_4': 0.7596787810325623, 'epoch': 12.53}
[INFO|trainer.py:4228] 2025-01-21 13:13:41,198 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:41,198 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                | 2160/5160 [53:45<52:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:48,564 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01415042020380497, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.754, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00852535106241703, 'eval_loss_2': 0.0056250691413879395, 'eval_loss_3': -18.295366287231445, 'eval_loss_4': 0.7792903184890747, 'epoch': 12.53}
{'loss': 0.0121, 'grad_norm': 5.234248638153076, 'learning_rate': 1.7488372093023256e-05, 'loss_1': 0.008467132225632668, 'loss_2': 0.003665924072265625, 'loss_3': -16.36481475830078, 'loss_4': 0.9451602101325989, 'epoch': 12.53}
{'loss': 0.018, 'grad_norm': 7.89333963394165, 'learning_rate': 1.7482558139534884e-05, 'loss_1': 0.017131149768829346, 'loss_2': 0.0008535385131835938, 'loss_3': -16.44295883178711, 'loss_4': 1.324586272239685, 'epoch': 12.54}
{'loss': 0.0077, 'grad_norm': 4.934215545654297, 'learning_rate': 1.747674418604651e-05, 'loss_1': 0.00494528328999877, 'loss_2': 0.0027828216552734375, 'loss_3': -16.464340209960938, 'loss_4': 1.1702455282211304, 'epoch': 12.55}
{'loss': 0.0207, 'grad_norm': 6.591616153717041, 'learning_rate': 1.747093023255814e-05, 'loss_1': 0.013796393759548664, 'loss_2': 0.006885528564453125, 'loss_3': -16.655540466308594, 'loss_4': 0.9527926445007324, 'epoch': 12.55}
{'loss': 0.0151, 'grad_norm': 5.131894588470459, 'learning_rate': 1.7465116279069767e-05, 'loss_1': 0.009941911324858665, 'loss_2': 0.0051116943359375, 'loss_3': -16.379070281982422, 'loss_4': 1.085331678390503, 'epoch': 12.56}
[INFO|trainer.py:4228] 2025-01-21 13:13:48,565 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:48,565 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                | 2165/5160 [53:53<51:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:13:55,940 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012061009183526039, 'eval_runtime': 3.8189, 'eval_samples_per_second': 268.142, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.00841120257973671, 'eval_loss_2': 0.0036498084664344788, 'eval_loss_3': -18.32086181640625, 'eval_loss_4': 1.1173980236053467, 'epoch': 12.56}
{'loss': 0.0121, 'grad_norm': 6.042959690093994, 'learning_rate': 1.7459302325581396e-05, 'loss_1': 0.008972393348813057, 'loss_2': 0.0030975341796875, 'loss_3': -16.62689781188965, 'loss_4': 1.2840081453323364, 'epoch': 12.56}
{'loss': 0.0298, 'grad_norm': 11.755155563354492, 'learning_rate': 1.7453488372093024e-05, 'loss_1': 0.024460192769765854, 'loss_2': 0.00530242919921875, 'loss_3': -16.487592697143555, 'loss_4': 1.5333530902862549, 'epoch': 12.57}
{'loss': 0.0068, 'grad_norm': 4.8776092529296875, 'learning_rate': 1.744767441860465e-05, 'loss_1': 0.006448916159570217, 'loss_2': 0.0003609657287597656, 'loss_3': -16.337961196899414, 'loss_4': 1.2182440757751465, 'epoch': 12.58}
{'loss': 0.0116, 'grad_norm': 6.537811279296875, 'learning_rate': 1.744186046511628e-05, 'loss_1': 0.011550708673894405, 'loss_2': 8.046627044677734e-05, 'loss_3': -16.564098358154297, 'loss_4': 1.3646996021270752, 'epoch': 12.58}
{'loss': 0.0484, 'grad_norm': 15.997696876525879, 'learning_rate': 1.7436046511627907e-05, 'loss_1': 0.04686400294303894, 'loss_2': 0.0015001296997070312, 'loss_3': -16.422122955322266, 'loss_4': 1.8217551708221436, 'epoch': 12.59}
[INFO|trainer.py:4228] 2025-01-21 13:13:55,940 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:13:55,940 >>   Batch size = 64
 42%|████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                | 2170/5160 [54:00<51:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:03,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012066924944519997, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.533, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008317450061440468, 'eval_loss_2': 0.003749474883079529, 'eval_loss_3': -18.314496994018555, 'eval_loss_4': 1.2782230377197266, 'epoch': 12.59}
{'loss': 0.0261, 'grad_norm': 8.388677597045898, 'learning_rate': 1.7430232558139535e-05, 'loss_1': 0.022832021117210388, 'loss_2': 0.0033168792724609375, 'loss_3': -16.221149444580078, 'loss_4': 1.2274630069732666, 'epoch': 12.59}
{'loss': 0.0122, 'grad_norm': 5.3632588386535645, 'learning_rate': 1.742441860465116e-05, 'loss_1': 0.00964152067899704, 'loss_2': 0.0025653839111328125, 'loss_3': -16.595306396484375, 'loss_4': 1.3257524967193604, 'epoch': 12.6}
{'loss': 0.0057, 'grad_norm': 5.295350551605225, 'learning_rate': 1.7418604651162793e-05, 'loss_1': 0.005580478813499212, 'loss_2': 0.00011408329010009766, 'loss_3': -16.577146530151367, 'loss_4': 1.5954041481018066, 'epoch': 12.6}
{'loss': 0.015, 'grad_norm': 6.664037227630615, 'learning_rate': 1.741279069767442e-05, 'loss_1': 0.013827422633767128, 'loss_2': 0.0011463165283203125, 'loss_3': -16.280048370361328, 'loss_4': 1.417022943496704, 'epoch': 12.61}
{'loss': 0.1005, 'grad_norm': 24.007841110229492, 'learning_rate': 1.7406976744186046e-05, 'loss_1': 0.09491045027971268, 'loss_2': 0.00563812255859375, 'loss_3': -16.31816864013672, 'loss_4': 1.8054015636444092, 'epoch': 12.62}
[INFO|trainer.py:4228] 2025-01-21 13:14:03,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:03,306 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                               | 2175/5160 [54:07<51:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:10,676 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01109137013554573, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.379, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007533404976129532, 'eval_loss_2': 0.0035579651594161987, 'eval_loss_3': -18.302448272705078, 'eval_loss_4': 1.335493803024292, 'epoch': 12.62}
{'loss': 0.0172, 'grad_norm': 6.97175931930542, 'learning_rate': 1.7401162790697675e-05, 'loss_1': 0.01451794058084488, 'loss_2': 0.002685546875, 'loss_3': -16.653411865234375, 'loss_4': 1.3627030849456787, 'epoch': 12.62}
{'loss': 0.0167, 'grad_norm': 8.407912254333496, 'learning_rate': 1.73953488372093e-05, 'loss_1': 0.016516229137778282, 'loss_2': 0.00015735626220703125, 'loss_3': -16.476524353027344, 'loss_4': 1.0677118301391602, 'epoch': 12.63}
{'loss': 0.0157, 'grad_norm': 6.118267059326172, 'learning_rate': 1.7389534883720932e-05, 'loss_1': 0.014603487215936184, 'loss_2': 0.001117706298828125, 'loss_3': -16.569400787353516, 'loss_4': 1.1892220973968506, 'epoch': 12.63}
{'loss': 0.0253, 'grad_norm': 19.00787353515625, 'learning_rate': 1.738372093023256e-05, 'loss_1': 0.02196434512734413, 'loss_2': 0.00333404541015625, 'loss_3': -16.395551681518555, 'loss_4': 1.7057374715805054, 'epoch': 12.64}
{'loss': 0.0073, 'grad_norm': 4.889951705932617, 'learning_rate': 1.7377906976744186e-05, 'loss_1': 0.004835471510887146, 'loss_2': 0.00243377685546875, 'loss_3': -16.425167083740234, 'loss_4': 1.6327643394470215, 'epoch': 12.65}
[INFO|trainer.py:4228] 2025-01-21 13:14:10,676 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:10,676 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                               | 2180/5160 [54:15<51:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:18,037 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01099337823688984, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.532, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0077879298478364944, 'eval_loss_2': 0.0032054483890533447, 'eval_loss_3': -18.29549789428711, 'eval_loss_4': 1.368267297744751, 'epoch': 12.65}
{'loss': 0.0125, 'grad_norm': 4.99423885345459, 'learning_rate': 1.7372093023255815e-05, 'loss_1': 0.00792617630213499, 'loss_2': 0.004608154296875, 'loss_3': -16.453994750976562, 'loss_4': 1.4365313053131104, 'epoch': 12.65}
{'loss': 0.0101, 'grad_norm': 4.277298450469971, 'learning_rate': 1.736627906976744e-05, 'loss_1': 0.005066882353276014, 'loss_2': 0.0050811767578125, 'loss_3': -16.505733489990234, 'loss_4': 1.713829755783081, 'epoch': 12.66}
{'loss': 0.015, 'grad_norm': 6.098889350891113, 'learning_rate': 1.7360465116279072e-05, 'loss_1': 0.013621965423226357, 'loss_2': 0.0013828277587890625, 'loss_3': -16.459697723388672, 'loss_4': 1.3640415668487549, 'epoch': 12.66}
{'loss': 0.0364, 'grad_norm': 8.162528038024902, 'learning_rate': 1.7354651162790697e-05, 'loss_1': 0.024090386927127838, 'loss_2': 0.012298583984375, 'loss_3': -16.587997436523438, 'loss_4': 1.108081340789795, 'epoch': 12.67}
{'loss': 0.0148, 'grad_norm': 4.923851013183594, 'learning_rate': 1.7348837209302326e-05, 'loss_1': 0.008167700842022896, 'loss_2': 0.0066375732421875, 'loss_3': -16.527063369750977, 'loss_4': 1.112027883529663, 'epoch': 12.67}
[INFO|trainer.py:4228] 2025-01-21 13:14:18,037 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:18,037 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                               | 2185/5160 [54:22<51:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:25,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016180288046598434, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.532, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008879254572093487, 'eval_loss_2': 0.007301032543182373, 'eval_loss_3': -18.275955200195312, 'eval_loss_4': 1.4562385082244873, 'epoch': 12.67}
{'loss': 0.0126, 'grad_norm': 5.144998073577881, 'learning_rate': 1.7343023255813955e-05, 'loss_1': 0.008789679035544395, 'loss_2': 0.003810882568359375, 'loss_3': -16.53571319580078, 'loss_4': 2.037163257598877, 'epoch': 12.68}
{'loss': 0.0212, 'grad_norm': 9.375225067138672, 'learning_rate': 1.733720930232558e-05, 'loss_1': 0.020797191187739372, 'loss_2': 0.00038242340087890625, 'loss_3': -16.366207122802734, 'loss_4': 1.2875207662582397, 'epoch': 12.69}
{'loss': 0.0137, 'grad_norm': 5.5630645751953125, 'learning_rate': 1.7331395348837212e-05, 'loss_1': 0.007781552150845528, 'loss_2': 0.0059051513671875, 'loss_3': -16.65286636352539, 'loss_4': 1.3016915321350098, 'epoch': 12.69}
{'loss': 0.0059, 'grad_norm': 4.7911858558654785, 'learning_rate': 1.7325581395348837e-05, 'loss_1': 0.005347839556634426, 'loss_2': 0.000514984130859375, 'loss_3': -16.431175231933594, 'loss_4': 1.5705230236053467, 'epoch': 12.7}
{'loss': 0.0091, 'grad_norm': 5.135134220123291, 'learning_rate': 1.7319767441860466e-05, 'loss_1': 0.006884640082716942, 'loss_2': 0.002254486083984375, 'loss_3': -16.4543399810791, 'loss_4': 0.8684808611869812, 'epoch': 12.7}
[INFO|trainer.py:4228] 2025-01-21 13:14:25,399 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:25,399 >>   Batch size = 64
 42%|█████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                               | 2190/5160 [54:29<51:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:32,761 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013909107074141502, 'eval_runtime': 3.8136, 'eval_samples_per_second': 268.514, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008413081057369709, 'eval_loss_2': 0.005496025085449219, 'eval_loss_3': -18.22821617126465, 'eval_loss_4': 1.48773193359375, 'epoch': 12.7}
{'loss': 0.0112, 'grad_norm': 5.753467559814453, 'learning_rate': 1.7313953488372094e-05, 'loss_1': 0.010988620109856129, 'loss_2': 0.0002123117446899414, 'loss_3': -16.540054321289062, 'loss_4': 1.174660563468933, 'epoch': 12.71}
{'loss': 0.0115, 'grad_norm': 6.721275329589844, 'learning_rate': 1.730813953488372e-05, 'loss_1': 0.010979656130075455, 'loss_2': 0.0005526542663574219, 'loss_3': -16.26420021057129, 'loss_4': 1.6487804651260376, 'epoch': 12.72}
{'loss': 0.0173, 'grad_norm': 6.027011871337891, 'learning_rate': 1.730232558139535e-05, 'loss_1': 0.010730069130659103, 'loss_2': 0.006591796875, 'loss_3': -16.57819175720215, 'loss_4': 1.3815627098083496, 'epoch': 12.72}
{'loss': 0.0369, 'grad_norm': 14.902359962463379, 'learning_rate': 1.7296511627906977e-05, 'loss_1': 0.022657549008727074, 'loss_2': 0.0142822265625, 'loss_3': -16.250463485717773, 'loss_4': 1.6131772994995117, 'epoch': 12.73}
{'loss': 0.0099, 'grad_norm': 5.952933311462402, 'learning_rate': 1.7290697674418606e-05, 'loss_1': 0.008619293570518494, 'loss_2': 0.0012350082397460938, 'loss_3': -16.331392288208008, 'loss_4': 1.466009259223938, 'epoch': 12.73}
[INFO|trainer.py:4228] 2025-01-21 13:14:32,761 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:32,761 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                               | 2195/5160 [54:37<51:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:40,108 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01801442727446556, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.063, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.01268291100859642, 'eval_loss_2': 0.005331516265869141, 'eval_loss_3': -18.189218521118164, 'eval_loss_4': 1.6632441282272339, 'epoch': 12.73}
{'loss': 0.0709, 'grad_norm': 15.948546409606934, 'learning_rate': 1.728488372093023e-05, 'loss_1': 0.06486465781927109, 'loss_2': 0.00598907470703125, 'loss_3': -16.364225387573242, 'loss_4': 1.7457640171051025, 'epoch': 12.74}
{'loss': 0.0775, 'grad_norm': 12.380282402038574, 'learning_rate': 1.727906976744186e-05, 'loss_1': 0.0708727166056633, 'loss_2': 0.006664276123046875, 'loss_3': -16.211421966552734, 'loss_4': 1.7486659288406372, 'epoch': 12.74}
{'loss': 0.018, 'grad_norm': 4.885216236114502, 'learning_rate': 1.727325581395349e-05, 'loss_1': 0.007090077269822359, 'loss_2': 0.0109405517578125, 'loss_3': -16.459880828857422, 'loss_4': 1.684123158454895, 'epoch': 12.75}
{'loss': 0.0143, 'grad_norm': 5.723629951477051, 'learning_rate': 1.7267441860465117e-05, 'loss_1': 0.007925288751721382, 'loss_2': 0.00632476806640625, 'loss_3': -16.48817253112793, 'loss_4': 1.7552213668823242, 'epoch': 12.76}
{'loss': 0.0253, 'grad_norm': 14.314903259277344, 'learning_rate': 1.7261627906976745e-05, 'loss_1': 0.0225672647356987, 'loss_2': 0.002742767333984375, 'loss_3': -16.326900482177734, 'loss_4': 1.833711862564087, 'epoch': 12.76}
[INFO|trainer.py:4228] 2025-01-21 13:14:40,109 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:40,109 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                              | 2200/5160 [54:44<51:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:47,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0180975254625082, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010830763727426529, 'eval_loss_2': 0.0072667598724365234, 'eval_loss_3': -18.199796676635742, 'eval_loss_4': 1.913582682609558, 'epoch': 12.76}
{'loss': 0.0152, 'grad_norm': 6.657665252685547, 'learning_rate': 1.725581395348837e-05, 'loss_1': 0.014181544072926044, 'loss_2': 0.000980377197265625, 'loss_3': -16.419689178466797, 'loss_4': 2.2785775661468506, 'epoch': 12.77}
{'loss': 0.0167, 'grad_norm': 5.466150760650635, 'learning_rate': 1.725e-05, 'loss_1': 0.010022543370723724, 'loss_2': 0.006683349609375, 'loss_3': -16.390953063964844, 'loss_4': 1.5731396675109863, 'epoch': 12.77}
{'loss': 0.0407, 'grad_norm': 20.014577865600586, 'learning_rate': 1.724418604651163e-05, 'loss_1': 0.038202736526727676, 'loss_2': 0.0025119781494140625, 'loss_3': -16.446870803833008, 'loss_4': 2.385781764984131, 'epoch': 12.78}
{'loss': 0.083, 'grad_norm': 26.229087829589844, 'learning_rate': 1.7238372093023256e-05, 'loss_1': 0.07396987080574036, 'loss_2': 0.00899505615234375, 'loss_3': -16.289337158203125, 'loss_4': 1.8955984115600586, 'epoch': 12.78}
{'loss': 0.0147, 'grad_norm': 6.044122219085693, 'learning_rate': 1.7232558139534885e-05, 'loss_1': 0.013245128095149994, 'loss_2': 0.0014095306396484375, 'loss_3': -16.36127281188965, 'loss_4': 2.4175562858581543, 'epoch': 12.79}
[INFO|trainer.py:4228] 2025-01-21 13:14:47,468 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:47,468 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                              | 2205/5160 [54:51<51:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:14:54,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012580559588968754, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.671, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009878205135464668, 'eval_loss_2': 0.00270235538482666, 'eval_loss_3': -18.2143611907959, 'eval_loss_4': 2.0732600688934326, 'epoch': 12.79}
{'loss': 0.0099, 'grad_norm': 5.2748332023620605, 'learning_rate': 1.722674418604651e-05, 'loss_1': 0.00637726578861475, 'loss_2': 0.00350189208984375, 'loss_3': -16.341209411621094, 'loss_4': 2.009127140045166, 'epoch': 12.8}
{'loss': 0.014, 'grad_norm': 6.216012954711914, 'learning_rate': 1.722093023255814e-05, 'loss_1': 0.01215100847184658, 'loss_2': 0.0018157958984375, 'loss_3': -16.38395118713379, 'loss_4': 2.293130397796631, 'epoch': 12.8}
{'loss': 0.0148, 'grad_norm': 5.87812614440918, 'learning_rate': 1.7215116279069768e-05, 'loss_1': 0.008155644871294498, 'loss_2': 0.006641387939453125, 'loss_3': -16.437267303466797, 'loss_4': 2.4263124465942383, 'epoch': 12.81}
{'loss': 0.0138, 'grad_norm': 6.755276679992676, 'learning_rate': 1.7209302325581396e-05, 'loss_1': 0.008199954405426979, 'loss_2': 0.00555419921875, 'loss_3': -16.427021026611328, 'loss_4': 1.9903755187988281, 'epoch': 12.81}
{'loss': 0.0432, 'grad_norm': 14.348822593688965, 'learning_rate': 1.7203488372093025e-05, 'loss_1': 0.03657730668783188, 'loss_2': 0.006610870361328125, 'loss_3': -16.36025619506836, 'loss_4': 2.084110975265503, 'epoch': 12.82}
[INFO|trainer.py:4228] 2025-01-21 13:14:54,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:14:54,836 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                              | 2210/5160 [54:59<51:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:02,188 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014996630139648914, 'eval_runtime': 3.8024, 'eval_samples_per_second': 269.306, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008075457997620106, 'eval_loss_2': 0.006921172142028809, 'eval_loss_3': -18.22130584716797, 'eval_loss_4': 2.1487865447998047, 'epoch': 12.82}
{'loss': 0.0277, 'grad_norm': 13.701696395874023, 'learning_rate': 1.719767441860465e-05, 'loss_1': 0.01767873950302601, 'loss_2': 0.0100250244140625, 'loss_3': -16.100488662719727, 'loss_4': 2.381767749786377, 'epoch': 12.83}
{'loss': 0.0081, 'grad_norm': 4.704097270965576, 'learning_rate': 1.719186046511628e-05, 'loss_1': 0.007126055657863617, 'loss_2': 0.0009613037109375, 'loss_3': -16.38726806640625, 'loss_4': 2.259885311126709, 'epoch': 12.83}
{'loss': 0.0205, 'grad_norm': 5.1959991455078125, 'learning_rate': 1.7186046511627907e-05, 'loss_1': 0.011472102254629135, 'loss_2': 0.009063720703125, 'loss_3': -16.54383087158203, 'loss_4': 2.208756446838379, 'epoch': 12.84}
{'loss': 0.0084, 'grad_norm': 5.4807939529418945, 'learning_rate': 1.7180232558139536e-05, 'loss_1': 0.007538151927292347, 'loss_2': 0.0008535385131835938, 'loss_3': -16.316238403320312, 'loss_4': 2.4168105125427246, 'epoch': 12.84}
{'loss': 0.0072, 'grad_norm': 4.841042995452881, 'learning_rate': 1.7174418604651165e-05, 'loss_1': 0.006506240926682949, 'loss_2': 0.0007295608520507812, 'loss_3': -16.437637329101562, 'loss_4': 2.409749984741211, 'epoch': 12.85}
[INFO|trainer.py:4228] 2025-01-21 13:15:02,188 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:02,188 >>   Batch size = 64
 43%|██████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                              | 2215/5160 [55:06<51:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:09,554 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008983824402093887, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006696701981127262, 'eval_loss_2': 0.0022871233522892, 'eval_loss_3': -18.24123191833496, 'eval_loss_4': 2.1782803535461426, 'epoch': 12.85}
{'loss': 0.0144, 'grad_norm': 4.4208984375, 'learning_rate': 1.716860465116279e-05, 'loss_1': 0.006878731772303581, 'loss_2': 0.0075531005859375, 'loss_3': -16.57645606994629, 'loss_4': 2.105828285217285, 'epoch': 12.85}
{'loss': 0.0118, 'grad_norm': 5.232168197631836, 'learning_rate': 1.716279069767442e-05, 'loss_1': 0.005732627585530281, 'loss_2': 0.00601959228515625, 'loss_3': -16.475479125976562, 'loss_4': 2.0983142852783203, 'epoch': 12.86}
{'loss': 0.011, 'grad_norm': 5.0952959060668945, 'learning_rate': 1.7156976744186047e-05, 'loss_1': 0.004521880764514208, 'loss_2': 0.006500244140625, 'loss_3': -16.441234588623047, 'loss_4': 2.0746231079101562, 'epoch': 12.87}
{'loss': 0.0108, 'grad_norm': 4.632570743560791, 'learning_rate': 1.7151162790697676e-05, 'loss_1': 0.004865416791290045, 'loss_2': 0.005886077880859375, 'loss_3': -16.55746841430664, 'loss_4': 2.4986393451690674, 'epoch': 12.87}
{'loss': 0.0108, 'grad_norm': 5.11851167678833, 'learning_rate': 1.71453488372093e-05, 'loss_1': 0.008108681067824364, 'loss_2': 0.002681732177734375, 'loss_3': -16.26089859008789, 'loss_4': 2.473827838897705, 'epoch': 12.88}
[INFO|trainer.py:4228] 2025-01-21 13:15:09,554 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:09,554 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                              | 2220/5160 [55:14<50:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:16,916 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011180003173649311, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.77, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006748427636921406, 'eval_loss_2': 0.004431575536727905, 'eval_loss_3': -18.23880386352539, 'eval_loss_4': 2.212695837020874, 'epoch': 12.88}
{'loss': 0.0253, 'grad_norm': 7.794713973999023, 'learning_rate': 1.713953488372093e-05, 'loss_1': 0.014372749254107475, 'loss_2': 0.010894775390625, 'loss_3': -16.21400260925293, 'loss_4': 2.449955940246582, 'epoch': 12.88}
{'loss': 0.0155, 'grad_norm': 6.457338333129883, 'learning_rate': 1.7133720930232558e-05, 'loss_1': 0.00816377718001604, 'loss_2': 0.00732421875, 'loss_3': -16.377317428588867, 'loss_4': 2.470043420791626, 'epoch': 12.89}
{'loss': 0.0129, 'grad_norm': 5.862253665924072, 'learning_rate': 1.7127906976744187e-05, 'loss_1': 0.011289630085229874, 'loss_2': 0.0016040802001953125, 'loss_3': -16.208141326904297, 'loss_4': 2.059396266937256, 'epoch': 12.9}
{'loss': 0.0097, 'grad_norm': 5.025389194488525, 'learning_rate': 1.7122093023255816e-05, 'loss_1': 0.008315768092870712, 'loss_2': 0.00140380859375, 'loss_3': -16.226152420043945, 'loss_4': 2.294166326522827, 'epoch': 12.9}
{'loss': 0.0131, 'grad_norm': 6.973873615264893, 'learning_rate': 1.711627906976744e-05, 'loss_1': 0.011262631043791771, 'loss_2': 0.0018672943115234375, 'loss_3': -16.585092544555664, 'loss_4': 2.0219497680664062, 'epoch': 12.91}
[INFO|trainer.py:4228] 2025-01-21 13:15:16,916 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:16,917 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                             | 2225/5160 [55:21<50:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:24,276 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009412916377186775, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.043, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006931828334927559, 'eval_loss_2': 0.0024810880422592163, 'eval_loss_3': -18.240631103515625, 'eval_loss_4': 1.963388204574585, 'epoch': 12.91}
{'loss': 0.0124, 'grad_norm': 5.314245700836182, 'learning_rate': 1.711046511627907e-05, 'loss_1': 0.008720728568732738, 'loss_2': 0.0036487579345703125, 'loss_3': -16.464296340942383, 'loss_4': 2.0280728340148926, 'epoch': 12.91}
{'loss': 0.0066, 'grad_norm': 4.706789493560791, 'learning_rate': 1.7104651162790698e-05, 'loss_1': 0.004482199437916279, 'loss_2': 0.00211334228515625, 'loss_3': -16.222801208496094, 'loss_4': 2.1734185218811035, 'epoch': 12.92}
{'loss': 0.0116, 'grad_norm': 4.8209733963012695, 'learning_rate': 1.7098837209302327e-05, 'loss_1': 0.008153489790856838, 'loss_2': 0.003482818603515625, 'loss_3': -16.352622985839844, 'loss_4': 1.7617524862289429, 'epoch': 12.92}
{'loss': 0.017, 'grad_norm': 6.080935478210449, 'learning_rate': 1.7093023255813955e-05, 'loss_1': 0.011359605006873608, 'loss_2': 0.005672454833984375, 'loss_3': -16.106903076171875, 'loss_4': 2.0992088317871094, 'epoch': 12.93}
{'loss': 0.0198, 'grad_norm': 11.274394035339355, 'learning_rate': 1.708720930232558e-05, 'loss_1': 0.019111596047878265, 'loss_2': 0.0007228851318359375, 'loss_3': -16.36027717590332, 'loss_4': 1.8779995441436768, 'epoch': 12.94}
[INFO|trainer.py:4228] 2025-01-21 13:15:24,276 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:24,276 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 2230/5160 [55:28<50:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:31,630 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012370304204523563, 'eval_runtime': 3.8037, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007465079892426729, 'eval_loss_2': 0.004905223846435547, 'eval_loss_3': -18.25434112548828, 'eval_loss_4': 1.7427151203155518, 'epoch': 12.94}
{'loss': 0.0486, 'grad_norm': 27.650104522705078, 'learning_rate': 1.708139534883721e-05, 'loss_1': 0.03857274353504181, 'loss_2': 0.0100250244140625, 'loss_3': -16.338642120361328, 'loss_4': 1.7615184783935547, 'epoch': 12.94}
{'loss': 0.0124, 'grad_norm': 5.988054275512695, 'learning_rate': 1.7075581395348834e-05, 'loss_1': 0.01219642162322998, 'loss_2': 0.00023472309112548828, 'loss_3': -16.24154281616211, 'loss_4': 1.8798015117645264, 'epoch': 12.95}
{'loss': 0.0279, 'grad_norm': 19.28228187561035, 'learning_rate': 1.7069767441860466e-05, 'loss_1': 0.026663456112146378, 'loss_2': 0.0012416839599609375, 'loss_3': -16.230350494384766, 'loss_4': 1.4410134553909302, 'epoch': 12.95}
{'loss': 0.0129, 'grad_norm': 9.739591598510742, 'learning_rate': 1.7063953488372095e-05, 'loss_1': 0.012647224590182304, 'loss_2': 0.0002961158752441406, 'loss_3': -16.294862747192383, 'loss_4': 1.8899353742599487, 'epoch': 12.96}
{'loss': 0.02, 'grad_norm': 7.893655300140381, 'learning_rate': 1.705813953488372e-05, 'loss_1': 0.013776333071291447, 'loss_2': 0.0061798095703125, 'loss_3': -16.309459686279297, 'loss_4': 1.6841256618499756, 'epoch': 12.97}
[INFO|trainer.py:4228] 2025-01-21 13:15:31,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:31,631 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 2235/5160 [55:36<50:22,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:15:38,961 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011962956748902798, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006669401656836271, 'eval_loss_2': 0.005293555557727814, 'eval_loss_3': -18.258197784423828, 'eval_loss_4': 1.6006988286972046, 'epoch': 12.97}
{'loss': 0.0204, 'grad_norm': 6.709909439086914, 'learning_rate': 1.705232558139535e-05, 'loss_1': 0.00990205816924572, 'loss_2': 0.010498046875, 'loss_3': -16.42327880859375, 'loss_4': 1.640499234199524, 'epoch': 12.97}
{'loss': 0.0189, 'grad_norm': 7.791339874267578, 'learning_rate': 1.7046511627906978e-05, 'loss_1': 0.013802563771605492, 'loss_2': 0.00508880615234375, 'loss_3': -16.294422149658203, 'loss_4': 1.7777628898620605, 'epoch': 12.98}
{'loss': 0.0107, 'grad_norm': 4.98146915435791, 'learning_rate': 1.7040697674418606e-05, 'loss_1': 0.008268407545983791, 'loss_2': 0.00246429443359375, 'loss_3': -16.132633209228516, 'loss_4': 1.777719497680664, 'epoch': 12.98}
{'loss': 0.0256, 'grad_norm': 9.724149703979492, 'learning_rate': 1.7034883720930235e-05, 'loss_1': 0.016704032197594643, 'loss_2': 0.0088958740234375, 'loss_3': -16.280494689941406, 'loss_4': 1.919456958770752, 'epoch': 12.99}
{'loss': 0.0145, 'grad_norm': 10.983492851257324, 'learning_rate': 1.702906976744186e-05, 'loss_1': 0.014359654858708382, 'loss_2': 0.00013172626495361328, 'loss_3': -16.218852996826172, 'loss_4': 1.2702648639678955, 'epoch': 12.99}
[INFO|trainer.py:4228] 2025-01-21 13:15:38,961 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:38,961 >>   Batch size = 64
 43%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                             | 2240/5160 [55:43<49:32,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:15:46,023 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012475194409489632, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.745, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006709136534482241, 'eval_loss_2': 0.005766056478023529, 'eval_loss_3': -18.271949768066406, 'eval_loss_4': 1.2601076364517212, 'epoch': 12.99}
{'loss': 0.0118, 'grad_norm': 6.624820232391357, 'learning_rate': 1.702325581395349e-05, 'loss_1': 0.0028236648067831993, 'loss_2': 0.00897979736328125, 'loss_3': -16.19536018371582, 'loss_4': 0.6808163523674011, 'epoch': 13.0}
{'loss': 0.0158, 'grad_norm': 6.206968784332275, 'learning_rate': 1.7017441860465117e-05, 'loss_1': 0.013364477083086967, 'loss_2': 0.0024089813232421875, 'loss_3': -16.41908073425293, 'loss_4': 1.3815748691558838, 'epoch': 13.01}
{'loss': 0.0268, 'grad_norm': 14.176262855529785, 'learning_rate': 1.7011627906976746e-05, 'loss_1': 0.026768619194626808, 'loss_2': 7.18832015991211e-05, 'loss_3': -16.271419525146484, 'loss_4': 1.366973638534546, 'epoch': 13.01}
{'loss': 0.012, 'grad_norm': 5.750159740447998, 'learning_rate': 1.700581395348837e-05, 'loss_1': 0.010561078786849976, 'loss_2': 0.0014438629150390625, 'loss_3': -16.40509033203125, 'loss_4': 1.1194992065429688, 'epoch': 13.02}
{'loss': 0.0167, 'grad_norm': 5.026904106140137, 'learning_rate': 1.7e-05, 'loss_1': 0.011641189455986023, 'loss_2': 0.0050811767578125, 'loss_3': -16.587371826171875, 'loss_4': 0.8706339001655579, 'epoch': 13.02}
[INFO|trainer.py:4228] 2025-01-21 13:15:46,024 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:46,024 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                            | 2245/5160 [55:50<50:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:15:53,386 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010638918727636337, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.495, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005747582763433456, 'eval_loss_2': 0.004891335964202881, 'eval_loss_3': -18.27791404724121, 'eval_loss_4': 1.007042646408081, 'epoch': 13.02}
{'loss': 0.0175, 'grad_norm': 8.231276512145996, 'learning_rate': 1.699418604651163e-05, 'loss_1': 0.01325293816626072, 'loss_2': 0.0042724609375, 'loss_3': -16.301454544067383, 'loss_4': 1.1739178895950317, 'epoch': 13.03}
{'loss': 0.0109, 'grad_norm': 4.631706237792969, 'learning_rate': 1.6988372093023257e-05, 'loss_1': 0.008616073988378048, 'loss_2': 0.00229644775390625, 'loss_3': -16.426124572753906, 'loss_4': 0.8665976524353027, 'epoch': 13.03}
{'loss': 0.007, 'grad_norm': 4.372131824493408, 'learning_rate': 1.6982558139534886e-05, 'loss_1': 0.003456598613411188, 'loss_2': 0.003559112548828125, 'loss_3': -16.42083168029785, 'loss_4': 0.5990596413612366, 'epoch': 13.04}
{'loss': 0.0083, 'grad_norm': 5.235349178314209, 'learning_rate': 1.697674418604651e-05, 'loss_1': 0.00811685062944889, 'loss_2': 0.00021350383758544922, 'loss_3': -16.397804260253906, 'loss_4': 0.5333952903747559, 'epoch': 13.05}
{'loss': 0.015, 'grad_norm': 5.970122337341309, 'learning_rate': 1.697093023255814e-05, 'loss_1': 0.009432800114154816, 'loss_2': 0.00556182861328125, 'loss_3': -16.422069549560547, 'loss_4': 0.5095526576042175, 'epoch': 13.05}
[INFO|trainer.py:4228] 2025-01-21 13:15:53,386 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:15:53,386 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                            | 2250/5160 [55:57<50:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:00,729 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009061331860721111, 'eval_runtime': 3.8027, 'eval_samples_per_second': 269.279, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005642774514853954, 'eval_loss_2': 0.003418557345867157, 'eval_loss_3': -18.29901695251465, 'eval_loss_4': 0.7605521082878113, 'epoch': 13.05}
{'loss': 0.0668, 'grad_norm': 14.901674270629883, 'learning_rate': 1.6965116279069768e-05, 'loss_1': 0.06657078117132187, 'loss_2': 0.000263214111328125, 'loss_3': -16.23005485534668, 'loss_4': 0.8291797637939453, 'epoch': 13.06}
{'loss': 0.0114, 'grad_norm': 5.388392448425293, 'learning_rate': 1.6959302325581397e-05, 'loss_1': 0.006817189510911703, 'loss_2': 0.00457763671875, 'loss_3': -16.450246810913086, 'loss_4': 0.39838671684265137, 'epoch': 13.06}
{'loss': 0.0098, 'grad_norm': 5.464986801147461, 'learning_rate': 1.6953488372093026e-05, 'loss_1': 0.006702151149511337, 'loss_2': 0.003086090087890625, 'loss_3': -16.37371253967285, 'loss_4': 0.7089241743087769, 'epoch': 13.07}
{'loss': 0.0191, 'grad_norm': 9.8433837890625, 'learning_rate': 1.694767441860465e-05, 'loss_1': 0.01708235964179039, 'loss_2': 0.0020599365234375, 'loss_3': -16.509105682373047, 'loss_4': 1.098200798034668, 'epoch': 13.08}
{'loss': 0.0106, 'grad_norm': 5.65904426574707, 'learning_rate': 1.694186046511628e-05, 'loss_1': 0.00663662888109684, 'loss_2': 0.003917694091796875, 'loss_3': -16.39736557006836, 'loss_4': 0.6656945943832397, 'epoch': 13.08}
[INFO|trainer.py:4228] 2025-01-21 13:16:00,730 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:00,730 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                            | 2255/5160 [56:05<50:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:08,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01003392692655325, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0066566308960318565, 'eval_loss_2': 0.003377296030521393, 'eval_loss_3': -18.31821060180664, 'eval_loss_4': 0.5172494649887085, 'epoch': 13.08}
{'loss': 0.0183, 'grad_norm': 7.0963215827941895, 'learning_rate': 1.6936046511627905e-05, 'loss_1': 0.017828498035669327, 'loss_2': 0.0004832744598388672, 'loss_3': -16.19045639038086, 'loss_4': 0.9068362712860107, 'epoch': 13.09}
{'loss': 0.0156, 'grad_norm': 6.275871276855469, 'learning_rate': 1.6930232558139537e-05, 'loss_1': 0.015021390281617641, 'loss_2': 0.0005946159362792969, 'loss_3': -16.452125549316406, 'loss_4': 1.4168221950531006, 'epoch': 13.09}
{'loss': 0.0134, 'grad_norm': 4.95929479598999, 'learning_rate': 1.6924418604651165e-05, 'loss_1': 0.00698927603662014, 'loss_2': 0.006439208984375, 'loss_3': -16.447595596313477, 'loss_4': 0.3753437101840973, 'epoch': 13.1}
{'loss': 0.0168, 'grad_norm': 6.384043216705322, 'learning_rate': 1.691860465116279e-05, 'loss_1': 0.016549665480852127, 'loss_2': 0.0002875328063964844, 'loss_3': -16.464569091796875, 'loss_4': 0.7032742500305176, 'epoch': 13.1}
{'loss': 0.015, 'grad_norm': 8.268607139587402, 'learning_rate': 1.691279069767442e-05, 'loss_1': 0.014569719322025776, 'loss_2': 0.0004329681396484375, 'loss_3': -16.46000862121582, 'loss_4': 0.5582652688026428, 'epoch': 13.11}
[INFO|trainer.py:4228] 2025-01-21 13:16:08,080 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:08,080 >>   Batch size = 64
 44%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                            | 2260/5160 [56:12<50:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:15,437 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00921916589140892, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006350423209369183, 'eval_loss_2': 0.002868741750717163, 'eval_loss_3': -18.321504592895508, 'eval_loss_4': 0.22188283503055573, 'epoch': 13.11}
{'loss': 0.02, 'grad_norm': 9.10561752319336, 'learning_rate': 1.6906976744186044e-05, 'loss_1': 0.019400399178266525, 'loss_2': 0.00064849853515625, 'loss_3': -16.55891990661621, 'loss_4': 0.45664629340171814, 'epoch': 13.12}
{'loss': 0.0215, 'grad_norm': 7.8508992195129395, 'learning_rate': 1.6901162790697676e-05, 'loss_1': 0.018618958070874214, 'loss_2': 0.002910614013671875, 'loss_3': -16.580432891845703, 'loss_4': 0.25701722502708435, 'epoch': 13.12}
{'loss': 0.0081, 'grad_norm': 4.805485725402832, 'learning_rate': 1.6895348837209305e-05, 'loss_1': 0.006789693608880043, 'loss_2': 0.001316070556640625, 'loss_3': -16.515413284301758, 'loss_4': 0.24631106853485107, 'epoch': 13.13}
{'loss': 0.0283, 'grad_norm': 15.392274856567383, 'learning_rate': 1.688953488372093e-05, 'loss_1': 0.025891873985528946, 'loss_2': 0.0024013519287109375, 'loss_3': -16.62522315979004, 'loss_4': -0.2382550835609436, 'epoch': 13.13}
{'loss': 0.0121, 'grad_norm': 5.952301025390625, 'learning_rate': 1.688372093023256e-05, 'loss_1': 0.010908334515988827, 'loss_2': 0.0012054443359375, 'loss_3': -16.63880729675293, 'loss_4': 0.476476788520813, 'epoch': 13.14}
[INFO|trainer.py:4228] 2025-01-21 13:16:15,437 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:15,437 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 2265/5160 [56:19<50:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:22,792 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008790023624897003, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006355427671223879, 'eval_loss_2': 0.0024345964193344116, 'eval_loss_3': -18.31502914428711, 'eval_loss_4': 0.2315407395362854, 'epoch': 13.14}
{'loss': 0.0315, 'grad_norm': 13.60483455657959, 'learning_rate': 1.6877906976744184e-05, 'loss_1': 0.02850341796875, 'loss_2': 0.00302886962890625, 'loss_3': -16.453330993652344, 'loss_4': 0.2315053641796112, 'epoch': 13.15}
{'loss': 0.0147, 'grad_norm': 6.670440196990967, 'learning_rate': 1.6872093023255816e-05, 'loss_1': 0.012738320976495743, 'loss_2': 0.0019779205322265625, 'loss_3': -16.349252700805664, 'loss_4': 0.6467912197113037, 'epoch': 13.15}
{'loss': 0.0088, 'grad_norm': 5.136130332946777, 'learning_rate': 1.686627906976744e-05, 'loss_1': 0.007066345773637295, 'loss_2': 0.0017557144165039062, 'loss_3': -16.574968338012695, 'loss_4': 0.43097519874572754, 'epoch': 13.16}
{'loss': 0.0205, 'grad_norm': 7.826012134552002, 'learning_rate': 1.686046511627907e-05, 'loss_1': 0.01667381078004837, 'loss_2': 0.003818511962890625, 'loss_3': -16.60608673095703, 'loss_4': 0.5388491153717041, 'epoch': 13.16}
{'loss': 0.0076, 'grad_norm': 4.889020919799805, 'learning_rate': 1.68546511627907e-05, 'loss_1': 0.006747375708073378, 'loss_2': 0.000881195068359375, 'loss_3': -16.63219451904297, 'loss_4': 0.19464749097824097, 'epoch': 13.17}
[INFO|trainer.py:4228] 2025-01-21 13:16:22,792 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:22,793 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                           | 2270/5160 [56:27<50:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:30,155 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010246142745018005, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006107420194894075, 'eval_loss_2': 0.004138723015785217, 'eval_loss_3': -18.316570281982422, 'eval_loss_4': 0.46063482761383057, 'epoch': 13.17}
{'loss': 0.0286, 'grad_norm': 10.715850830078125, 'learning_rate': 1.6848837209302324e-05, 'loss_1': 0.02664441242814064, 'loss_2': 0.001964569091796875, 'loss_3': -16.650671005249023, 'loss_4': 0.20762445032596588, 'epoch': 13.17}
{'loss': 0.0185, 'grad_norm': 5.959663391113281, 'learning_rate': 1.6843023255813956e-05, 'loss_1': 0.013634257949888706, 'loss_2': 0.00482177734375, 'loss_3': -16.4044189453125, 'loss_4': 0.06734946370124817, 'epoch': 13.18}
{'loss': 0.0473, 'grad_norm': 20.461252212524414, 'learning_rate': 1.683720930232558e-05, 'loss_1': 0.04145606607198715, 'loss_2': 0.005840301513671875, 'loss_3': -16.305320739746094, 'loss_4': 0.23954574763774872, 'epoch': 13.19}
{'loss': 0.0134, 'grad_norm': 5.092993259429932, 'learning_rate': 1.683139534883721e-05, 'loss_1': 0.005859635304659605, 'loss_2': 0.0074920654296875, 'loss_3': -16.451627731323242, 'loss_4': 0.8114715814590454, 'epoch': 13.19}
{'loss': 0.0122, 'grad_norm': 5.997775554656982, 'learning_rate': 1.682558139534884e-05, 'loss_1': 0.0094602070748806, 'loss_2': 0.0027561187744140625, 'loss_3': -16.62455177307129, 'loss_4': 1.0457420349121094, 'epoch': 13.2}
[INFO|trainer.py:4228] 2025-01-21 13:16:30,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:30,155 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                           | 2275/5160 [56:34<50:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:37,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009844918735325336, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.231, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.006639559753239155, 'eval_loss_2': 0.0032053589820861816, 'eval_loss_3': -18.312782287597656, 'eval_loss_4': 0.7475785613059998, 'epoch': 13.2}
{'loss': 0.0099, 'grad_norm': 5.929039001464844, 'learning_rate': 1.6819767441860464e-05, 'loss_1': 0.0064901565201580524, 'loss_2': 0.003448486328125, 'loss_3': -16.577831268310547, 'loss_4': 1.0097692012786865, 'epoch': 13.2}
{'loss': 0.0114, 'grad_norm': 5.79619836807251, 'learning_rate': 1.6813953488372096e-05, 'loss_1': 0.0084989657625556, 'loss_2': 0.00289154052734375, 'loss_3': -16.548019409179688, 'loss_4': 1.163309931755066, 'epoch': 13.21}
{'loss': 0.0079, 'grad_norm': 6.256190299987793, 'learning_rate': 1.680813953488372e-05, 'loss_1': 0.007507070433348417, 'loss_2': 0.0003867149353027344, 'loss_3': -16.363821029663086, 'loss_4': 0.9891061186790466, 'epoch': 13.22}
{'loss': 0.0082, 'grad_norm': 4.852926254272461, 'learning_rate': 1.680232558139535e-05, 'loss_1': 0.007236500736325979, 'loss_2': 0.0009479522705078125, 'loss_3': -16.238876342773438, 'loss_4': 0.5918728113174438, 'epoch': 13.22}
{'loss': 0.02, 'grad_norm': 5.163429260253906, 'learning_rate': 1.6796511627906975e-05, 'loss_1': 0.00949432235211134, 'loss_2': 0.010498046875, 'loss_3': -16.44766616821289, 'loss_4': 0.770661473274231, 'epoch': 13.23}
[INFO|trainer.py:4228] 2025-01-21 13:16:37,526 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:37,526 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 2280/5160 [56:42<49:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:44,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016077155247330666, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.83, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007095528766512871, 'eval_loss_2': 0.008981626480817795, 'eval_loss_3': -18.314441680908203, 'eval_loss_4': 1.0047835111618042, 'epoch': 13.23}
{'loss': 0.0197, 'grad_norm': 7.658499717712402, 'learning_rate': 1.6790697674418604e-05, 'loss_1': 0.013840553350746632, 'loss_2': 0.00586700439453125, 'loss_3': -16.43136978149414, 'loss_4': 0.9412704110145569, 'epoch': 13.23}
{'loss': 0.0157, 'grad_norm': 5.1599202156066895, 'learning_rate': 1.6784883720930236e-05, 'loss_1': 0.009014151059091091, 'loss_2': 0.0066375732421875, 'loss_3': -16.543045043945312, 'loss_4': 0.9386432766914368, 'epoch': 13.24}
{'loss': 0.0175, 'grad_norm': 5.18060302734375, 'learning_rate': 1.677906976744186e-05, 'loss_1': 0.006665494758635759, 'loss_2': 0.01080322265625, 'loss_3': -16.38269805908203, 'loss_4': 1.136387586593628, 'epoch': 13.24}
{'loss': 0.0293, 'grad_norm': 6.841059684753418, 'learning_rate': 1.677325581395349e-05, 'loss_1': 0.015656355768442154, 'loss_2': 0.0136566162109375, 'loss_3': -16.441442489624023, 'loss_4': 1.09727144241333, 'epoch': 13.25}
{'loss': 0.0208, 'grad_norm': 5.091179370880127, 'learning_rate': 1.6767441860465115e-05, 'loss_1': 0.009280405007302761, 'loss_2': 0.01152801513671875, 'loss_3': -16.22865104675293, 'loss_4': 1.219607949256897, 'epoch': 13.26}
[INFO|trainer.py:4228] 2025-01-21 13:16:44,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:44,891 >>   Batch size = 64
 44%|█████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 2285/5160 [56:49<49:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:52,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013515928760170937, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.659, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007841386832296848, 'eval_loss_2': 0.005674540996551514, 'eval_loss_3': -18.324920654296875, 'eval_loss_4': 1.2826660871505737, 'epoch': 13.26}
{'loss': 0.0136, 'grad_norm': 4.990811824798584, 'learning_rate': 1.6761627906976743e-05, 'loss_1': 0.007481715176254511, 'loss_2': 0.00612640380859375, 'loss_3': -16.3125, 'loss_4': 0.7337646484375, 'epoch': 13.26}
{'loss': 0.0117, 'grad_norm': 7.028046607971191, 'learning_rate': 1.6755813953488375e-05, 'loss_1': 0.010819464921951294, 'loss_2': 0.0008358955383300781, 'loss_3': -16.47875213623047, 'loss_4': 1.19614577293396, 'epoch': 13.27}
{'loss': 0.0142, 'grad_norm': 5.244203567504883, 'learning_rate': 1.675e-05, 'loss_1': 0.006955650169402361, 'loss_2': 0.00727081298828125, 'loss_3': -16.470046997070312, 'loss_4': 1.0094645023345947, 'epoch': 13.27}
{'loss': 0.0079, 'grad_norm': 4.948575496673584, 'learning_rate': 1.674418604651163e-05, 'loss_1': 0.007452569901943207, 'loss_2': 0.00041294097900390625, 'loss_3': -16.708911895751953, 'loss_4': 0.9563760161399841, 'epoch': 13.28}
{'loss': 0.0501, 'grad_norm': 10.808399200439453, 'learning_rate': 1.6738372093023254e-05, 'loss_1': 0.049125686287879944, 'loss_2': 0.0009965896606445312, 'loss_3': -16.448511123657227, 'loss_4': 1.3855440616607666, 'epoch': 13.28}
[INFO|trainer.py:4228] 2025-01-21 13:16:52,248 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:52,248 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                           | 2290/5160 [56:56<49:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:16:59,604 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013647440820932388, 'eval_runtime': 3.802, 'eval_samples_per_second': 269.329, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.007727387361228466, 'eval_loss_2': 0.005920052528381348, 'eval_loss_3': -18.295194625854492, 'eval_loss_4': 1.4308176040649414, 'epoch': 13.28}
{'loss': 0.0087, 'grad_norm': 5.335977554321289, 'learning_rate': 1.6732558139534883e-05, 'loss_1': 0.00812880415469408, 'loss_2': 0.0006003379821777344, 'loss_3': -16.475515365600586, 'loss_4': 1.3316092491149902, 'epoch': 13.29}
{'loss': 0.0144, 'grad_norm': 5.699338436126709, 'learning_rate': 1.6726744186046512e-05, 'loss_1': 0.007337953429669142, 'loss_2': 0.007061004638671875, 'loss_3': -16.370861053466797, 'loss_4': 1.7655119895935059, 'epoch': 13.3}
{'loss': 0.0398, 'grad_norm': 10.74506664276123, 'learning_rate': 1.672093023255814e-05, 'loss_1': 0.02756032720208168, 'loss_2': 0.0121917724609375, 'loss_3': -16.240161895751953, 'loss_4': 1.5066226720809937, 'epoch': 13.3}
{'loss': 0.008, 'grad_norm': 4.940756320953369, 'learning_rate': 1.671511627906977e-05, 'loss_1': 0.00706322630867362, 'loss_2': 0.00089263916015625, 'loss_3': -16.363218307495117, 'loss_4': 1.6466338634490967, 'epoch': 13.31}
{'loss': 0.0223, 'grad_norm': 12.57845401763916, 'learning_rate': 1.6709302325581394e-05, 'loss_1': 0.017666973173618317, 'loss_2': 0.00464630126953125, 'loss_3': -16.482088088989258, 'loss_4': 1.8450181484222412, 'epoch': 13.31}
[INFO|trainer.py:4228] 2025-01-21 13:16:59,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:16:59,604 >>   Batch size = 64
 44%|██████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                          | 2295/5160 [57:04<49:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:06,965 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014319300651550293, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008924276567995548, 'eval_loss_2': 0.005395025014877319, 'eval_loss_3': -18.29609489440918, 'eval_loss_4': 1.460022211074829, 'epoch': 13.31}
{'loss': 0.0264, 'grad_norm': 9.63021469116211, 'learning_rate': 1.6703488372093023e-05, 'loss_1': 0.021924862638115883, 'loss_2': 0.004436492919921875, 'loss_3': -16.567792892456055, 'loss_4': 1.2519354820251465, 'epoch': 13.32}
{'loss': 0.0194, 'grad_norm': 5.382153034210205, 'learning_rate': 1.669767441860465e-05, 'loss_1': 0.011262979358434677, 'loss_2': 0.0081329345703125, 'loss_3': -16.275577545166016, 'loss_4': 1.6007215976715088, 'epoch': 13.33}
{'loss': 0.0214, 'grad_norm': 8.012933731079102, 'learning_rate': 1.669186046511628e-05, 'loss_1': 0.017114588990807533, 'loss_2': 0.0042877197265625, 'loss_3': -16.3721923828125, 'loss_4': 1.6715847253799438, 'epoch': 13.33}
{'loss': 0.0063, 'grad_norm': 4.051050186157227, 'learning_rate': 1.668604651162791e-05, 'loss_1': 0.005346805788576603, 'loss_2': 0.0009775161743164062, 'loss_3': -16.581375122070312, 'loss_4': 1.4155133962631226, 'epoch': 13.34}
{'loss': 0.0105, 'grad_norm': 4.7414631843566895, 'learning_rate': 1.6680232558139534e-05, 'loss_1': 0.006585550960153341, 'loss_2': 0.00388336181640625, 'loss_3': -16.60335350036621, 'loss_4': 0.8848386406898499, 'epoch': 13.34}
[INFO|trainer.py:4228] 2025-01-21 13:17:06,965 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:06,965 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                          | 2300/5160 [57:11<49:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:14,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015208421275019646, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.637, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009578167460858822, 'eval_loss_2': 0.0056302547454833984, 'eval_loss_3': -18.289730072021484, 'eval_loss_4': 1.2148866653442383, 'epoch': 13.34}
{'loss': 0.0193, 'grad_norm': 8.166947364807129, 'learning_rate': 1.6674418604651166e-05, 'loss_1': 0.015243785455822945, 'loss_2': 0.0040435791015625, 'loss_3': -16.433761596679688, 'loss_4': 1.0374813079833984, 'epoch': 13.35}
{'loss': 0.0195, 'grad_norm': 4.967023849487305, 'learning_rate': 1.666860465116279e-05, 'loss_1': 0.010679869912564754, 'loss_2': 0.00881195068359375, 'loss_3': -16.650432586669922, 'loss_4': 0.6905251145362854, 'epoch': 13.35}
{'loss': 0.0108, 'grad_norm': 6.0829081535339355, 'learning_rate': 1.666279069767442e-05, 'loss_1': 0.008191539905965328, 'loss_2': 0.00263214111328125, 'loss_3': -16.339941024780273, 'loss_4': 1.109220027923584, 'epoch': 13.36}
{'loss': 0.0143, 'grad_norm': 4.983697414398193, 'learning_rate': 1.6656976744186045e-05, 'loss_1': 0.008676359429955482, 'loss_2': 0.00557708740234375, 'loss_3': -16.367385864257812, 'loss_4': 1.1080577373504639, 'epoch': 13.37}
{'loss': 0.0453, 'grad_norm': 15.702269554138184, 'learning_rate': 1.6651162790697674e-05, 'loss_1': 0.038177333772182465, 'loss_2': 0.007080078125, 'loss_3': -16.541656494140625, 'loss_4': 0.8454381227493286, 'epoch': 13.37}
[INFO|trainer.py:4228] 2025-01-21 13:17:14,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:14,328 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 2305/5160 [57:18<49:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:21,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01704494282603264, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.387, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.012748448178172112, 'eval_loss_2': 0.004296496510505676, 'eval_loss_3': -18.27922248840332, 'eval_loss_4': 1.197680950164795, 'epoch': 13.37}
{'loss': 0.0091, 'grad_norm': 5.044054985046387, 'learning_rate': 1.6645348837209306e-05, 'loss_1': 0.006742313038557768, 'loss_2': 0.002346038818359375, 'loss_3': -16.284215927124023, 'loss_4': 1.537421703338623, 'epoch': 13.38}
{'loss': 0.021, 'grad_norm': 9.815079689025879, 'learning_rate': 1.663953488372093e-05, 'loss_1': 0.02026159130036831, 'loss_2': 0.0007123947143554688, 'loss_3': -16.295211791992188, 'loss_4': 0.7623788714408875, 'epoch': 13.38}
{'loss': 0.0128, 'grad_norm': 6.380758762359619, 'learning_rate': 1.663372093023256e-05, 'loss_1': 0.011952572502195835, 'loss_2': 0.0008625984191894531, 'loss_3': -16.53914451599121, 'loss_4': 0.846845269203186, 'epoch': 13.39}
{'loss': 0.0227, 'grad_norm': 7.097646713256836, 'learning_rate': 1.6627906976744185e-05, 'loss_1': 0.022492971271276474, 'loss_2': 0.00017273426055908203, 'loss_3': -16.496536254882812, 'loss_4': 1.4170578718185425, 'epoch': 13.4}
{'loss': 0.0204, 'grad_norm': 6.76043701171875, 'learning_rate': 1.6622093023255814e-05, 'loss_1': 0.017434298992156982, 'loss_2': 0.002925872802734375, 'loss_3': -16.374345779418945, 'loss_4': 1.0277926921844482, 'epoch': 13.4}
[INFO|trainer.py:4228] 2025-01-21 13:17:21,680 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:21,680 >>   Batch size = 64
 45%|██████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                          | 2310/5160 [57:26<49:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:29,042 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016007132828235626, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.807, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.012725192122161388, 'eval_loss_2': 0.003281939774751663, 'eval_loss_3': -18.270702362060547, 'eval_loss_4': 1.1728861331939697, 'epoch': 13.4}
{'loss': 0.0105, 'grad_norm': 6.043721675872803, 'learning_rate': 1.6616279069767442e-05, 'loss_1': 0.010393938980996609, 'loss_2': 9.769201278686523e-05, 'loss_3': -16.441768646240234, 'loss_4': 1.2278178930282593, 'epoch': 13.41}
{'loss': 0.0134, 'grad_norm': 6.361818313598633, 'learning_rate': 1.661046511627907e-05, 'loss_1': 0.008637990802526474, 'loss_2': 0.0047454833984375, 'loss_3': -16.351390838623047, 'loss_4': 1.3634291887283325, 'epoch': 13.41}
{'loss': 0.0149, 'grad_norm': 6.917562484741211, 'learning_rate': 1.66046511627907e-05, 'loss_1': 0.012034216895699501, 'loss_2': 0.002838134765625, 'loss_3': -16.55453872680664, 'loss_4': 1.4118452072143555, 'epoch': 13.42}
{'loss': 0.0184, 'grad_norm': 6.212596416473389, 'learning_rate': 1.6598837209302325e-05, 'loss_1': 0.01372874341905117, 'loss_2': 0.0046844482421875, 'loss_3': -16.516550064086914, 'loss_4': 1.1970945596694946, 'epoch': 13.42}
{'loss': 0.0111, 'grad_norm': 5.336551666259766, 'learning_rate': 1.6593023255813953e-05, 'loss_1': 0.008647122420370579, 'loss_2': 0.0024814605712890625, 'loss_3': -16.2878360748291, 'loss_4': 1.4840940237045288, 'epoch': 13.43}
[INFO|trainer.py:4228] 2025-01-21 13:17:29,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:29,043 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                         | 2315/5160 [57:33<49:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:36,398 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016172271221876144, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.925, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013001900166273117, 'eval_loss_2': 0.0031703710556030273, 'eval_loss_3': -18.280052185058594, 'eval_loss_4': 1.112593650817871, 'epoch': 13.43}
{'loss': 0.0342, 'grad_norm': 18.6489315032959, 'learning_rate': 1.6587209302325582e-05, 'loss_1': 0.02893400378525257, 'loss_2': 0.005279541015625, 'loss_3': -16.468732833862305, 'loss_4': 0.77437824010849, 'epoch': 13.44}
{'loss': 0.0133, 'grad_norm': 6.181410312652588, 'learning_rate': 1.658139534883721e-05, 'loss_1': 0.013244672678411007, 'loss_2': 6.312131881713867e-05, 'loss_3': -16.35008430480957, 'loss_4': 1.0178364515304565, 'epoch': 13.44}
{'loss': 0.0378, 'grad_norm': 22.72539520263672, 'learning_rate': 1.657558139534884e-05, 'loss_1': 0.036906979978084564, 'loss_2': 0.0008807182312011719, 'loss_3': -16.406404495239258, 'loss_4': 1.0900516510009766, 'epoch': 13.45}
{'loss': 0.0124, 'grad_norm': 5.1579389572143555, 'learning_rate': 1.6569767441860464e-05, 'loss_1': 0.012026360258460045, 'loss_2': 0.00037384033203125, 'loss_3': -16.49227523803711, 'loss_4': 1.1614153385162354, 'epoch': 13.45}
{'loss': 0.0115, 'grad_norm': 5.409257888793945, 'learning_rate': 1.6563953488372093e-05, 'loss_1': 0.009910785593092442, 'loss_2': 0.0016222000122070312, 'loss_3': -16.381996154785156, 'loss_4': 1.3096046447753906, 'epoch': 13.46}
[INFO|trainer.py:4228] 2025-01-21 13:17:36,398 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:36,399 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                         | 2320/5160 [57:40<49:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:43,752 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01271631196141243, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.875, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00920303538441658, 'eval_loss_2': 0.0035132765769958496, 'eval_loss_3': -18.256271362304688, 'eval_loss_4': 1.225043773651123, 'epoch': 13.46}
{'loss': 0.0412, 'grad_norm': 13.519020080566406, 'learning_rate': 1.6558139534883722e-05, 'loss_1': 0.03929583355784416, 'loss_2': 0.0019378662109375, 'loss_3': -16.54088592529297, 'loss_4': 1.390093445777893, 'epoch': 13.47}
{'loss': 0.0162, 'grad_norm': 7.15971040725708, 'learning_rate': 1.655232558139535e-05, 'loss_1': 0.01197861973196268, 'loss_2': 0.0042572021484375, 'loss_3': -16.543045043945312, 'loss_4': 1.1139776706695557, 'epoch': 13.47}
{'loss': 0.0201, 'grad_norm': 6.202243804931641, 'learning_rate': 1.6546511627906976e-05, 'loss_1': 0.011964603327214718, 'loss_2': 0.0081329345703125, 'loss_3': -16.435394287109375, 'loss_4': 1.154343605041504, 'epoch': 13.48}
{'loss': 0.0141, 'grad_norm': 5.3945393562316895, 'learning_rate': 1.6540697674418604e-05, 'loss_1': 0.011112124659121037, 'loss_2': 0.0029449462890625, 'loss_3': -16.50307846069336, 'loss_4': 1.3219836950302124, 'epoch': 13.48}
{'loss': 0.0119, 'grad_norm': 5.972884178161621, 'learning_rate': 1.6534883720930233e-05, 'loss_1': 0.0113224470987916, 'loss_2': 0.0005459785461425781, 'loss_3': -16.485258102416992, 'loss_4': 1.894083857536316, 'epoch': 13.49}
[INFO|trainer.py:4228] 2025-01-21 13:17:43,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:43,753 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                         | 2325/5160 [57:48<49:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:51,119 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010246749967336655, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.611, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007575075142085552, 'eval_loss_2': 0.002671673893928528, 'eval_loss_3': -18.274036407470703, 'eval_loss_4': 1.349596381187439, 'epoch': 13.49}
{'loss': 0.0143, 'grad_norm': 9.943254470825195, 'learning_rate': 1.652906976744186e-05, 'loss_1': 0.01405419409275055, 'loss_2': 0.0002181529998779297, 'loss_3': -16.32999038696289, 'loss_4': 1.3729044198989868, 'epoch': 13.49}
{'loss': 0.0118, 'grad_norm': 5.560726165771484, 'learning_rate': 1.652325581395349e-05, 'loss_1': 0.005896256770938635, 'loss_2': 0.0058746337890625, 'loss_3': -16.556236267089844, 'loss_4': 1.3682938814163208, 'epoch': 13.5}
{'loss': 0.0147, 'grad_norm': 6.947310924530029, 'learning_rate': 1.6517441860465115e-05, 'loss_1': 0.014321022666990757, 'loss_2': 0.0004124641418457031, 'loss_3': -16.515060424804688, 'loss_4': 1.1939449310302734, 'epoch': 13.51}
{'loss': 0.0191, 'grad_norm': 7.578463554382324, 'learning_rate': 1.6511627906976744e-05, 'loss_1': 0.012072865851223469, 'loss_2': 0.00701141357421875, 'loss_3': -16.35089874267578, 'loss_4': 1.3638060092926025, 'epoch': 13.51}
{'loss': 0.0121, 'grad_norm': 5.855085849761963, 'learning_rate': 1.6505813953488373e-05, 'loss_1': 0.010072516277432442, 'loss_2': 0.00202178955078125, 'loss_3': -16.533605575561523, 'loss_4': 1.4097585678100586, 'epoch': 13.52}
[INFO|trainer.py:4228] 2025-01-21 13:17:51,119 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:51,119 >>   Batch size = 64
 45%|███████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                         | 2330/5160 [57:55<49:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:17:58,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011501479893922806, 'eval_runtime': 3.8158, 'eval_samples_per_second': 268.359, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.008348222821950912, 'eval_loss_2': 0.0031532570719718933, 'eval_loss_3': -18.278640747070312, 'eval_loss_4': 1.5070278644561768, 'epoch': 13.52}
{'loss': 0.0148, 'grad_norm': 6.067917346954346, 'learning_rate': 1.65e-05, 'loss_1': 0.01267180498689413, 'loss_2': 0.00211334228515625, 'loss_3': -16.360183715820312, 'loss_4': 1.493037223815918, 'epoch': 13.52}
{'loss': 0.0337, 'grad_norm': 10.832767486572266, 'learning_rate': 1.649418604651163e-05, 'loss_1': 0.029462706297636032, 'loss_2': 0.00418853759765625, 'loss_3': -16.317626953125, 'loss_4': 1.483309030532837, 'epoch': 13.53}
{'loss': 0.0122, 'grad_norm': 6.977916717529297, 'learning_rate': 1.6488372093023255e-05, 'loss_1': 0.01105676032602787, 'loss_2': 0.001110076904296875, 'loss_3': -16.41533088684082, 'loss_4': 1.8170320987701416, 'epoch': 13.53}
{'loss': 0.0148, 'grad_norm': 6.4075517654418945, 'learning_rate': 1.6482558139534884e-05, 'loss_1': 0.012432695366442204, 'loss_2': 0.002399444580078125, 'loss_3': -16.498430252075195, 'loss_4': 1.732771396636963, 'epoch': 13.54}
{'loss': 0.0159, 'grad_norm': 7.492280960083008, 'learning_rate': 1.647674418604651e-05, 'loss_1': 0.013953211717307568, 'loss_2': 0.001979827880859375, 'loss_3': -16.42313003540039, 'loss_4': 1.5149774551391602, 'epoch': 13.55}
[INFO|trainer.py:4228] 2025-01-21 13:17:58,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:17:58,484 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                         | 2335/5160 [58:02<48:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:05,834 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011436850763857365, 'eval_runtime': 3.8018, 'eval_samples_per_second': 269.343, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.008132092654705048, 'eval_loss_2': 0.0033047571778297424, 'eval_loss_3': -18.265567779541016, 'eval_loss_4': 1.663591742515564, 'epoch': 13.55}
{'loss': 0.0139, 'grad_norm': 5.7031450271606445, 'learning_rate': 1.647093023255814e-05, 'loss_1': 0.011494762264192104, 'loss_2': 0.00238037109375, 'loss_3': -16.339645385742188, 'loss_4': 1.449256181716919, 'epoch': 13.55}
{'loss': 0.0138, 'grad_norm': 5.157100200653076, 'learning_rate': 1.646511627906977e-05, 'loss_1': 0.008173364214599133, 'loss_2': 0.00567626953125, 'loss_3': -16.460317611694336, 'loss_4': 1.4256116151809692, 'epoch': 13.56}
{'loss': 0.0261, 'grad_norm': 9.585027694702148, 'learning_rate': 1.6459302325581395e-05, 'loss_1': 0.02595158852636814, 'loss_2': 0.0001423358917236328, 'loss_3': -16.596614837646484, 'loss_4': 1.6138744354248047, 'epoch': 13.56}
{'loss': 0.0449, 'grad_norm': 24.43726348876953, 'learning_rate': 1.6453488372093024e-05, 'loss_1': 0.04199111834168434, 'loss_2': 0.002910614013671875, 'loss_3': -16.51523780822754, 'loss_4': 1.5921612977981567, 'epoch': 13.57}
{'loss': 0.0269, 'grad_norm': 7.167184352874756, 'learning_rate': 1.644767441860465e-05, 'loss_1': 0.017109191045165062, 'loss_2': 0.00982666015625, 'loss_3': -16.56240463256836, 'loss_4': 1.3032383918762207, 'epoch': 13.58}
[INFO|trainer.py:4228] 2025-01-21 13:18:05,834 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:05,834 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                        | 2340/5160 [58:10<48:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:13,186 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013019796460866928, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.181, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008570577949285507, 'eval_loss_2': 0.004449218511581421, 'eval_loss_3': -18.24694061279297, 'eval_loss_4': 1.7231191396713257, 'epoch': 13.58}
{'loss': 0.0136, 'grad_norm': 5.077913284301758, 'learning_rate': 1.644186046511628e-05, 'loss_1': 0.009166327305138111, 'loss_2': 0.0044708251953125, 'loss_3': -16.587997436523438, 'loss_4': 1.9736664295196533, 'epoch': 13.58}
{'loss': 0.0146, 'grad_norm': 5.494669437408447, 'learning_rate': 1.643604651162791e-05, 'loss_1': 0.00896078534424305, 'loss_2': 0.0056304931640625, 'loss_3': -16.39944839477539, 'loss_4': 1.4194583892822266, 'epoch': 13.59}
{'loss': 0.0216, 'grad_norm': 6.776088237762451, 'learning_rate': 1.6430232558139535e-05, 'loss_1': 0.015180947259068489, 'loss_2': 0.006458282470703125, 'loss_3': -16.341135025024414, 'loss_4': 1.4970779418945312, 'epoch': 13.59}
{'loss': 0.0192, 'grad_norm': 8.144415855407715, 'learning_rate': 1.6424418604651163e-05, 'loss_1': 0.018044060096144676, 'loss_2': 0.00118255615234375, 'loss_3': -16.352035522460938, 'loss_4': 1.4033652544021606, 'epoch': 13.6}
{'loss': 0.0322, 'grad_norm': 10.313071250915527, 'learning_rate': 1.641860465116279e-05, 'loss_1': 0.025231607258319855, 'loss_2': 0.0069427490234375, 'loss_3': -16.34463882446289, 'loss_4': 1.8244550228118896, 'epoch': 13.6}
[INFO|trainer.py:4228] 2025-01-21 13:18:13,186 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:13,186 >>   Batch size = 64
 45%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                        | 2345/5160 [58:17<48:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:20,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013558359816670418, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010394331067800522, 'eval_loss_2': 0.003164030611515045, 'eval_loss_3': -18.220491409301758, 'eval_loss_4': 1.8943305015563965, 'epoch': 13.6}
{'loss': 0.025, 'grad_norm': 14.696436882019043, 'learning_rate': 1.641279069767442e-05, 'loss_1': 0.02305115945637226, 'loss_2': 0.0019779205322265625, 'loss_3': -16.214921951293945, 'loss_4': 1.796755075454712, 'epoch': 13.61}
{'loss': 0.0093, 'grad_norm': 4.903584957122803, 'learning_rate': 1.6406976744186046e-05, 'loss_1': 0.006879267282783985, 'loss_2': 0.002414703369140625, 'loss_3': -16.595802307128906, 'loss_4': 1.702839970588684, 'epoch': 13.62}
{'loss': 0.0164, 'grad_norm': 6.692275047302246, 'learning_rate': 1.6401162790697674e-05, 'loss_1': 0.015425700694322586, 'loss_2': 0.0010089874267578125, 'loss_3': -16.404510498046875, 'loss_4': 2.266739845275879, 'epoch': 13.62}
{'loss': 0.0231, 'grad_norm': 12.808405876159668, 'learning_rate': 1.6395348837209303e-05, 'loss_1': 0.022225119173526764, 'loss_2': 0.000827789306640625, 'loss_3': -16.1491756439209, 'loss_4': 1.7818008661270142, 'epoch': 13.63}
{'loss': 0.0144, 'grad_norm': 7.512789726257324, 'learning_rate': 1.638953488372093e-05, 'loss_1': 0.012224317528307438, 'loss_2': 0.002147674560546875, 'loss_3': -16.38825225830078, 'loss_4': 2.6349897384643555, 'epoch': 13.63}
[INFO|trainer.py:4228] 2025-01-21 13:18:20,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:20,539 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                        | 2350/5160 [58:25<48:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:27,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012471936643123627, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.217, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.009684987366199493, 'eval_loss_2': 0.0027869492769241333, 'eval_loss_3': -18.201171875, 'eval_loss_4': 2.00026535987854, 'epoch': 13.63}
{'loss': 0.0129, 'grad_norm': 5.248021602630615, 'learning_rate': 1.638372093023256e-05, 'loss_1': 0.008450346998870373, 'loss_2': 0.004405975341796875, 'loss_3': -16.38020133972168, 'loss_4': 2.1992039680480957, 'epoch': 13.64}
{'loss': 0.0503, 'grad_norm': 19.917545318603516, 'learning_rate': 1.6377906976744186e-05, 'loss_1': 0.04157153144478798, 'loss_2': 0.0087127685546875, 'loss_3': -16.482295989990234, 'loss_4': 1.9086503982543945, 'epoch': 13.65}
{'loss': 0.0174, 'grad_norm': 8.926408767700195, 'learning_rate': 1.6372093023255814e-05, 'loss_1': 0.01688365451991558, 'loss_2': 0.00047779083251953125, 'loss_3': -16.46857261657715, 'loss_4': 2.1405227184295654, 'epoch': 13.65}
{'loss': 0.0169, 'grad_norm': 8.129880905151367, 'learning_rate': 1.6366279069767443e-05, 'loss_1': 0.016655439510941505, 'loss_2': 0.00019812583923339844, 'loss_3': -16.49383544921875, 'loss_4': 1.8447092771530151, 'epoch': 13.66}
{'loss': 0.0182, 'grad_norm': 6.120075225830078, 'learning_rate': 1.6360465116279068e-05, 'loss_1': 0.01303199864923954, 'loss_2': 0.005153656005859375, 'loss_3': -16.63501739501953, 'loss_4': 1.9993821382522583, 'epoch': 13.66}
[INFO|trainer.py:4228] 2025-01-21 13:18:27,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:27,890 >>   Batch size = 64
 46%|████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                        | 2355/5160 [58:32<48:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:35,267 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013765545561909676, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.275, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.009900729171931744, 'eval_loss_2': 0.0038648173213005066, 'eval_loss_3': -18.193500518798828, 'eval_loss_4': 2.0456762313842773, 'epoch': 13.66}
{'loss': 0.0195, 'grad_norm': 8.267285346984863, 'learning_rate': 1.63546511627907e-05, 'loss_1': 0.018557652831077576, 'loss_2': 0.0009899139404296875, 'loss_3': -16.38420295715332, 'loss_4': 1.8909001350402832, 'epoch': 13.67}
{'loss': 0.0195, 'grad_norm': 13.042497634887695, 'learning_rate': 1.6348837209302325e-05, 'loss_1': 0.018408194184303284, 'loss_2': 0.00104522705078125, 'loss_3': -16.4641056060791, 'loss_4': 1.89229416847229, 'epoch': 13.67}
{'loss': 0.0205, 'grad_norm': 5.370525360107422, 'learning_rate': 1.6343023255813954e-05, 'loss_1': 0.013174834661185741, 'loss_2': 0.00736236572265625, 'loss_3': -16.405559539794922, 'loss_4': 2.3544721603393555, 'epoch': 13.68}
{'loss': 0.0149, 'grad_norm': 6.391389846801758, 'learning_rate': 1.633720930232558e-05, 'loss_1': 0.013045141473412514, 'loss_2': 0.0018491744995117188, 'loss_3': -16.57716178894043, 'loss_4': 2.2252871990203857, 'epoch': 13.69}
{'loss': 0.0171, 'grad_norm': 5.463768482208252, 'learning_rate': 1.6331395348837208e-05, 'loss_1': 0.010908915661275387, 'loss_2': 0.00618743896484375, 'loss_3': -16.454792022705078, 'loss_4': 1.7299225330352783, 'epoch': 13.69}
[INFO|trainer.py:4228] 2025-01-21 13:18:35,267 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:35,267 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                        | 2360/5160 [58:39<48:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:42,623 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012642212212085724, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009512312710285187, 'eval_loss_2': 0.003129899501800537, 'eval_loss_3': -18.20325469970703, 'eval_loss_4': 2.0826263427734375, 'epoch': 13.69}
{'loss': 0.0164, 'grad_norm': 6.0117573738098145, 'learning_rate': 1.632558139534884e-05, 'loss_1': 0.012151230126619339, 'loss_2': 0.00421142578125, 'loss_3': -16.361461639404297, 'loss_4': 2.4138262271881104, 'epoch': 13.7}
{'loss': 0.0157, 'grad_norm': 11.108826637268066, 'learning_rate': 1.6319767441860465e-05, 'loss_1': 0.012792136520147324, 'loss_2': 0.0029125213623046875, 'loss_3': -16.33330726623535, 'loss_4': 1.566455364227295, 'epoch': 13.7}
{'loss': 0.0165, 'grad_norm': 5.302854061126709, 'learning_rate': 1.6313953488372094e-05, 'loss_1': 0.009490332566201687, 'loss_2': 0.006984710693359375, 'loss_3': -16.53986358642578, 'loss_4': 1.871348261833191, 'epoch': 13.71}
{'loss': 0.0172, 'grad_norm': 9.159659385681152, 'learning_rate': 1.630813953488372e-05, 'loss_1': 0.01501055434346199, 'loss_2': 0.0021839141845703125, 'loss_3': -16.277324676513672, 'loss_4': 1.9193120002746582, 'epoch': 13.72}
{'loss': 0.0313, 'grad_norm': 16.46993064880371, 'learning_rate': 1.630232558139535e-05, 'loss_1': 0.02220364287495613, 'loss_2': 0.009124755859375, 'loss_3': -16.485017776489258, 'loss_4': 1.9198832511901855, 'epoch': 13.72}
[INFO|trainer.py:4228] 2025-01-21 13:18:42,623 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:42,623 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                       | 2365/5160 [58:47<48:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:18:49,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012662544846534729, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.053, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009041860699653625, 'eval_loss_2': 0.0036206841468811035, 'eval_loss_3': -18.21757698059082, 'eval_loss_4': 1.8176268339157104, 'epoch': 13.72}
{'loss': 0.0148, 'grad_norm': 7.492110252380371, 'learning_rate': 1.629651162790698e-05, 'loss_1': 0.014348641037940979, 'loss_2': 0.0004649162292480469, 'loss_3': -16.276575088500977, 'loss_4': 1.8145203590393066, 'epoch': 13.73}
{'loss': 0.0127, 'grad_norm': 5.665097713470459, 'learning_rate': 1.6290697674418605e-05, 'loss_1': 0.00812881626188755, 'loss_2': 0.0045318603515625, 'loss_3': -16.50775909423828, 'loss_4': 1.7879040241241455, 'epoch': 13.73}
{'loss': 0.0104, 'grad_norm': 5.319136619567871, 'learning_rate': 1.6284883720930234e-05, 'loss_1': 0.009609539993107319, 'loss_2': 0.0007762908935546875, 'loss_3': -16.51579475402832, 'loss_4': 1.6930632591247559, 'epoch': 13.74}
{'loss': 0.0125, 'grad_norm': 5.565026760101318, 'learning_rate': 1.627906976744186e-05, 'loss_1': 0.009768599644303322, 'loss_2': 0.00270843505859375, 'loss_3': -16.534122467041016, 'loss_4': 1.5935752391815186, 'epoch': 13.74}
{'loss': 0.0269, 'grad_norm': 7.225582599639893, 'learning_rate': 1.627325581395349e-05, 'loss_1': 0.014737853780388832, 'loss_2': 0.0121307373046875, 'loss_3': -16.567020416259766, 'loss_4': 1.6048502922058105, 'epoch': 13.75}
[INFO|trainer.py:4228] 2025-01-21 13:18:49,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:49,985 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                       | 2370/5160 [58:54<49:03,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:18:57,540 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015976300463080406, 'eval_runtime': 3.9976, 'eval_samples_per_second': 256.152, 'eval_steps_per_second': 4.002, 'eval_loss_1': 0.01017086673527956, 'eval_loss_2': 0.0058054327964782715, 'eval_loss_3': -18.26761817932129, 'eval_loss_4': 1.5347795486450195, 'epoch': 13.75}
{'loss': 0.0237, 'grad_norm': 8.548100471496582, 'learning_rate': 1.6267441860465116e-05, 'loss_1': 0.01821451634168625, 'loss_2': 0.00551605224609375, 'loss_3': -16.52841567993164, 'loss_4': 1.2732843160629272, 'epoch': 13.76}
{'loss': 0.0154, 'grad_norm': 6.922048091888428, 'learning_rate': 1.6261627906976745e-05, 'loss_1': 0.013670545071363449, 'loss_2': 0.001689910888671875, 'loss_3': -16.422393798828125, 'loss_4': 2.1983702182769775, 'epoch': 13.76}
{'loss': 0.0193, 'grad_norm': 6.924238681793213, 'learning_rate': 1.6255813953488373e-05, 'loss_1': 0.015335054136812687, 'loss_2': 0.0040130615234375, 'loss_3': -16.437238693237305, 'loss_4': 1.268108606338501, 'epoch': 13.77}
{'loss': 0.0627, 'grad_norm': 21.34248924255371, 'learning_rate': 1.625e-05, 'loss_1': 0.05622617527842522, 'loss_2': 0.006511688232421875, 'loss_3': -16.58926010131836, 'loss_4': 1.7028900384902954, 'epoch': 13.77}
{'loss': 0.0253, 'grad_norm': 9.23749828338623, 'learning_rate': 1.624418604651163e-05, 'loss_1': 0.022754544392228127, 'loss_2': 0.0025634765625, 'loss_3': -16.610279083251953, 'loss_4': 1.279177188873291, 'epoch': 13.78}
[INFO|trainer.py:4228] 2025-01-21 13:18:57,540 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:18:57,540 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                       | 2375/5160 [59:02<48:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:04,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014407151378691196, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.785, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009316974319517612, 'eval_loss_2': 0.005090177059173584, 'eval_loss_3': -18.28061866760254, 'eval_loss_4': 1.263751745223999, 'epoch': 13.78}
{'loss': 0.0162, 'grad_norm': 5.914576053619385, 'learning_rate': 1.6238372093023256e-05, 'loss_1': 0.009686182253062725, 'loss_2': 0.006526947021484375, 'loss_3': -16.768199920654297, 'loss_4': 1.0524020195007324, 'epoch': 13.78}
{'loss': 0.0162, 'grad_norm': 5.567996025085449, 'learning_rate': 1.6232558139534884e-05, 'loss_1': 0.01253341231495142, 'loss_2': 0.003692626953125, 'loss_3': -16.350215911865234, 'loss_4': 0.8095669150352478, 'epoch': 13.79}
{'loss': 0.0197, 'grad_norm': 6.550518989562988, 'learning_rate': 1.6226744186046513e-05, 'loss_1': 0.016554033383727074, 'loss_2': 0.0030975341796875, 'loss_3': -16.58208656311035, 'loss_4': 1.2070298194885254, 'epoch': 13.8}
{'loss': 0.024, 'grad_norm': 7.631294250488281, 'learning_rate': 1.622093023255814e-05, 'loss_1': 0.01732300966978073, 'loss_2': 0.00662994384765625, 'loss_3': -16.608713150024414, 'loss_4': 1.0839588642120361, 'epoch': 13.8}
{'loss': 0.0135, 'grad_norm': 5.513067722320557, 'learning_rate': 1.621511627906977e-05, 'loss_1': 0.009813092648983002, 'loss_2': 0.0036716461181640625, 'loss_3': -16.608543395996094, 'loss_4': 1.589064121246338, 'epoch': 13.81}
[INFO|trainer.py:4228] 2025-01-21 13:19:04,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:04,904 >>   Batch size = 64
 46%|█████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                       | 2380/5160 [59:09<48:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:12,299 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013628360815346241, 'eval_runtime': 3.8371, 'eval_samples_per_second': 266.871, 'eval_steps_per_second': 4.17, 'eval_loss_1': 0.009285175241529942, 'eval_loss_2': 0.0043431855738162994, 'eval_loss_3': -18.238876342773438, 'eval_loss_4': 1.1910825967788696, 'epoch': 13.81}
{'loss': 0.0181, 'grad_norm': 6.545724868774414, 'learning_rate': 1.6209302325581396e-05, 'loss_1': 0.014329689554870129, 'loss_2': 0.003818511962890625, 'loss_3': -16.612079620361328, 'loss_4': 1.7330024242401123, 'epoch': 13.81}
{'loss': 0.0215, 'grad_norm': 11.414329528808594, 'learning_rate': 1.6203488372093024e-05, 'loss_1': 0.021494222804903984, 'loss_2': 8.940696716308594e-06, 'loss_3': -16.575279235839844, 'loss_4': 1.343135118484497, 'epoch': 13.82}
{'loss': 0.0198, 'grad_norm': 6.005786895751953, 'learning_rate': 1.619767441860465e-05, 'loss_1': 0.013684522360563278, 'loss_2': 0.006069183349609375, 'loss_3': -16.427684783935547, 'loss_4': 0.6615641713142395, 'epoch': 13.83}
{'loss': 0.025, 'grad_norm': 10.518675804138184, 'learning_rate': 1.6191860465116278e-05, 'loss_1': 0.01850302703678608, 'loss_2': 0.0064697265625, 'loss_3': -16.553489685058594, 'loss_4': 0.9717034101486206, 'epoch': 13.83}
{'loss': 0.0162, 'grad_norm': 7.448098182678223, 'learning_rate': 1.618604651162791e-05, 'loss_1': 0.01495257206261158, 'loss_2': 0.0012149810791015625, 'loss_3': -16.380443572998047, 'loss_4': 0.9260303378105164, 'epoch': 13.84}
[INFO|trainer.py:4228] 2025-01-21 13:19:12,299 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:12,299 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                      | 2385/5160 [59:16<48:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:19,681 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014475181698799133, 'eval_runtime': 3.8271, 'eval_samples_per_second': 267.567, 'eval_steps_per_second': 4.181, 'eval_loss_1': 0.01061093807220459, 'eval_loss_2': 0.0038642436265945435, 'eval_loss_3': -18.229164123535156, 'eval_loss_4': 1.0426698923110962, 'epoch': 13.84}
{'loss': 0.015, 'grad_norm': 5.751062870025635, 'learning_rate': 1.6180232558139535e-05, 'loss_1': 0.012538818642497063, 'loss_2': 0.0024852752685546875, 'loss_3': -16.436399459838867, 'loss_4': 0.9169896841049194, 'epoch': 13.84}
{'loss': 0.0143, 'grad_norm': 5.64218807220459, 'learning_rate': 1.6174418604651164e-05, 'loss_1': 0.013191782869398594, 'loss_2': 0.0011339187622070312, 'loss_3': -16.44260025024414, 'loss_4': 1.2839601039886475, 'epoch': 13.85}
{'loss': 0.014, 'grad_norm': 6.812154293060303, 'learning_rate': 1.616860465116279e-05, 'loss_1': 0.013442558236420155, 'loss_2': 0.0005478858947753906, 'loss_3': -16.33088493347168, 'loss_4': 1.1716647148132324, 'epoch': 13.85}
{'loss': 0.0063, 'grad_norm': 4.741469383239746, 'learning_rate': 1.6162790697674418e-05, 'loss_1': 0.006125848274677992, 'loss_2': 0.00017583370208740234, 'loss_3': -16.40317726135254, 'loss_4': 1.1783082485198975, 'epoch': 13.86}
{'loss': 0.0256, 'grad_norm': 8.158422470092773, 'learning_rate': 1.615697674418605e-05, 'loss_1': 0.020388945937156677, 'loss_2': 0.005218505859375, 'loss_3': -16.32522201538086, 'loss_4': 0.9311542510986328, 'epoch': 13.87}
[INFO|trainer.py:4228] 2025-01-21 13:19:19,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:19,681 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                      | 2390/5160 [59:24<48:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:27,049 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015803273767232895, 'eval_runtime': 3.8163, 'eval_samples_per_second': 268.322, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.011636223644018173, 'eval_loss_2': 0.004167050123214722, 'eval_loss_3': -18.208911895751953, 'eval_loss_4': 0.9581364393234253, 'epoch': 13.87}
{'loss': 0.0169, 'grad_norm': 6.1585373878479, 'learning_rate': 1.6151162790697675e-05, 'loss_1': 0.01583768054842949, 'loss_2': 0.0010538101196289062, 'loss_3': -16.4447021484375, 'loss_4': 0.3608438968658447, 'epoch': 13.87}
{'loss': 0.0385, 'grad_norm': 14.80115795135498, 'learning_rate': 1.6145348837209304e-05, 'loss_1': 0.03333296626806259, 'loss_2': 0.00518035888671875, 'loss_3': -16.442638397216797, 'loss_4': 0.9235060811042786, 'epoch': 13.88}
{'loss': 0.0164, 'grad_norm': 5.2404961585998535, 'learning_rate': 1.613953488372093e-05, 'loss_1': 0.010941960848867893, 'loss_2': 0.005496978759765625, 'loss_3': -16.42268180847168, 'loss_4': 0.9509216547012329, 'epoch': 13.88}
{'loss': 0.0154, 'grad_norm': 9.062161445617676, 'learning_rate': 1.6133720930232558e-05, 'loss_1': 0.013586938381195068, 'loss_2': 0.00182342529296875, 'loss_3': -16.428674697875977, 'loss_4': 0.9889715313911438, 'epoch': 13.89}
{'loss': 0.039, 'grad_norm': 17.254749298095703, 'learning_rate': 1.6127906976744186e-05, 'loss_1': 0.03605420142412186, 'loss_2': 0.0029048919677734375, 'loss_3': -16.311952590942383, 'loss_4': 1.0085186958312988, 'epoch': 13.9}
[INFO|trainer.py:4228] 2025-01-21 13:19:27,049 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:27,049 >>   Batch size = 64
 46%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                      | 2395/5160 [59:31<47:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:34,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015438834205269814, 'eval_runtime': 3.8165, 'eval_samples_per_second': 268.309, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.011782758869230747, 'eval_loss_2': 0.0036560744047164917, 'eval_loss_3': -18.19650650024414, 'eval_loss_4': 0.8515443205833435, 'epoch': 13.9}
{'loss': 0.0184, 'grad_norm': 5.465961456298828, 'learning_rate': 1.6122093023255815e-05, 'loss_1': 0.013282066211104393, 'loss_2': 0.005084991455078125, 'loss_3': -16.34467315673828, 'loss_4': 0.500433623790741, 'epoch': 13.9}
{'loss': 0.0178, 'grad_norm': 6.869323253631592, 'learning_rate': 1.6116279069767444e-05, 'loss_1': 0.014452778734266758, 'loss_2': 0.00333404541015625, 'loss_3': -16.556644439697266, 'loss_4': 1.0843422412872314, 'epoch': 13.91}
{'loss': 0.0068, 'grad_norm': 4.669571399688721, 'learning_rate': 1.611046511627907e-05, 'loss_1': 0.005665356293320656, 'loss_2': 0.0010976791381835938, 'loss_3': -16.47740936279297, 'loss_4': 0.555065393447876, 'epoch': 13.91}
{'loss': 0.0203, 'grad_norm': 12.951424598693848, 'learning_rate': 1.6104651162790697e-05, 'loss_1': 0.019042782485485077, 'loss_2': 0.0012264251708984375, 'loss_3': -16.27916717529297, 'loss_4': 0.7710472345352173, 'epoch': 13.92}
{'loss': 0.0345, 'grad_norm': 14.616734504699707, 'learning_rate': 1.6098837209302326e-05, 'loss_1': 0.03382885083556175, 'loss_2': 0.0006666183471679688, 'loss_3': -16.457595825195312, 'loss_4': 0.7191664576530457, 'epoch': 13.92}
[INFO|trainer.py:4228] 2025-01-21 13:19:34,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:34,419 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                      | 2400/5160 [59:38<47:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:41,787 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015214192681014538, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.573, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.01096258033066988, 'eval_loss_2': 0.004251614212989807, 'eval_loss_3': -18.208723068237305, 'eval_loss_4': 0.734167754650116, 'epoch': 13.92}
{'loss': 0.013, 'grad_norm': 5.382984638214111, 'learning_rate': 1.6093023255813955e-05, 'loss_1': 0.009563901461660862, 'loss_2': 0.0034027099609375, 'loss_3': -16.476781845092773, 'loss_4': 0.6340150833129883, 'epoch': 13.93}
{'loss': 0.018, 'grad_norm': 5.953342914581299, 'learning_rate': 1.6087209302325583e-05, 'loss_1': 0.011262515559792519, 'loss_2': 0.00677490234375, 'loss_3': -16.366823196411133, 'loss_4': 0.9247090220451355, 'epoch': 13.94}
{'loss': 0.0123, 'grad_norm': 5.711022853851318, 'learning_rate': 1.608139534883721e-05, 'loss_1': 0.01070439163595438, 'loss_2': 0.00159454345703125, 'loss_3': -16.47988510131836, 'loss_4': 0.2946711778640747, 'epoch': 13.94}
{'loss': 0.012, 'grad_norm': 5.2231764793396, 'learning_rate': 1.6075581395348837e-05, 'loss_1': 0.008414741605520248, 'loss_2': 0.003551483154296875, 'loss_3': -16.35186767578125, 'loss_4': 0.582420825958252, 'epoch': 13.95}
{'loss': 0.0082, 'grad_norm': 4.5466742515563965, 'learning_rate': 1.6069767441860466e-05, 'loss_1': 0.006017829291522503, 'loss_2': 0.002208709716796875, 'loss_3': -16.547409057617188, 'loss_4': 0.5207219123840332, 'epoch': 13.95}
[INFO|trainer.py:4228] 2025-01-21 13:19:41,788 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:41,788 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                      | 2405/5160 [59:46<47:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:19:49,160 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01492326334118843, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.535, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.011574272997677326, 'eval_loss_2': 0.003348991274833679, 'eval_loss_3': -18.253021240234375, 'eval_loss_4': 0.5501409769058228, 'epoch': 13.95}
{'loss': 0.0109, 'grad_norm': 8.968306541442871, 'learning_rate': 1.6063953488372094e-05, 'loss_1': 0.010537966154515743, 'loss_2': 0.00039267539978027344, 'loss_3': -16.35572052001953, 'loss_4': 0.867810845375061, 'epoch': 13.96}
{'loss': 0.0099, 'grad_norm': 5.255393981933594, 'learning_rate': 1.605813953488372e-05, 'loss_1': 0.007020059507340193, 'loss_2': 0.002910614013671875, 'loss_3': -16.382761001586914, 'loss_4': 0.41096949577331543, 'epoch': 13.97}
{'loss': 0.0146, 'grad_norm': 5.363927364349365, 'learning_rate': 1.605232558139535e-05, 'loss_1': 0.007602331694215536, 'loss_2': 0.006988525390625, 'loss_3': -16.481586456298828, 'loss_4': 0.003605462610721588, 'epoch': 13.97}
{'loss': 0.0176, 'grad_norm': 7.62666654586792, 'learning_rate': 1.6046511627906977e-05, 'loss_1': 0.01301809586584568, 'loss_2': 0.0045928955078125, 'loss_3': -16.512800216674805, 'loss_4': 0.5220748782157898, 'epoch': 13.98}
{'loss': 0.0286, 'grad_norm': 8.00475025177002, 'learning_rate': 1.6040697674418606e-05, 'loss_1': 0.02610940858721733, 'loss_2': 0.0024929046630859375, 'loss_3': -16.341228485107422, 'loss_4': 0.5822716951370239, 'epoch': 13.98}
[INFO|trainer.py:4228] 2025-01-21 13:19:49,160 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:49,160 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                     | 2410/5160 [59:53<45:52,  1.00s/it][INFO|trainer.py:4226] 2025-01-21 13:19:56,235 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015003283508121967, 'eval_runtime': 3.8238, 'eval_samples_per_second': 267.796, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.011130264028906822, 'eval_loss_2': 0.0038730204105377197, 'eval_loss_3': -18.27349090576172, 'eval_loss_4': 0.6816067695617676, 'epoch': 13.98}
{'loss': 0.0261, 'grad_norm': 7.891085147857666, 'learning_rate': 1.6034883720930234e-05, 'loss_1': 0.016347844153642654, 'loss_2': 0.00970458984375, 'loss_3': -16.41943359375, 'loss_4': 0.5891532897949219, 'epoch': 13.99}
{'loss': 0.0194, 'grad_norm': 11.0894136428833, 'learning_rate': 1.602906976744186e-05, 'loss_1': 0.019313780590891838, 'loss_2': 9.268522262573242e-05, 'loss_3': -16.38681411743164, 'loss_4': 0.7442477941513062, 'epoch': 13.99}
{'loss': 0.0103, 'grad_norm': 5.703372955322266, 'learning_rate': 1.6023255813953488e-05, 'loss_1': 0.002957223216071725, 'loss_2': 0.0073394775390625, 'loss_3': -16.49890899658203, 'loss_4': 0.7489099502563477, 'epoch': 14.0}
{'loss': 0.0148, 'grad_norm': 6.148523330688477, 'learning_rate': 1.6017441860465117e-05, 'loss_1': 0.011079717427492142, 'loss_2': 0.0037631988525390625, 'loss_3': -16.553489685058594, 'loss_4': 0.34413808584213257, 'epoch': 14.01}
{'loss': 0.0385, 'grad_norm': 15.688450813293457, 'learning_rate': 1.6011627906976745e-05, 'loss_1': 0.03421931713819504, 'loss_2': 0.004302978515625, 'loss_3': -16.605205535888672, 'loss_4': 0.8528313040733337, 'epoch': 14.01}
[INFO|trainer.py:4228] 2025-01-21 13:19:56,235 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:19:56,236 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                    | 2415/5160 [1:00:00<47:18,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:20:03,604 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013740208931267262, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.206, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.011254070326685905, 'eval_loss_2': 0.0024861395359039307, 'eval_loss_3': -18.29102897644043, 'eval_loss_4': 0.8455578088760376, 'epoch': 14.01}
{'loss': 0.0196, 'grad_norm': 4.5240678787231445, 'learning_rate': 1.6005813953488374e-05, 'loss_1': 0.00870951171964407, 'loss_2': 0.01088714599609375, 'loss_3': -16.394428253173828, 'loss_4': 1.0290979146957397, 'epoch': 14.02}
{'loss': 0.0169, 'grad_norm': 10.759528160095215, 'learning_rate': 1.6e-05, 'loss_1': 0.011308387853205204, 'loss_2': 0.0056304931640625, 'loss_3': -16.437515258789062, 'loss_4': 1.2115733623504639, 'epoch': 14.02}
{'loss': 0.0246, 'grad_norm': 5.791182518005371, 'learning_rate': 1.5994186046511628e-05, 'loss_1': 0.01628061570227146, 'loss_2': 0.00829315185546875, 'loss_3': -16.429283142089844, 'loss_4': 1.221222996711731, 'epoch': 14.03}
{'loss': 0.0526, 'grad_norm': 21.618053436279297, 'learning_rate': 1.5988372093023253e-05, 'loss_1': 0.043732285499572754, 'loss_2': 0.00882720947265625, 'loss_3': -16.319639205932617, 'loss_4': 1.7896709442138672, 'epoch': 14.03}
{'loss': 0.0195, 'grad_norm': 5.940989017486572, 'learning_rate': 1.5982558139534885e-05, 'loss_1': 0.013356334529817104, 'loss_2': 0.00617218017578125, 'loss_3': -16.634998321533203, 'loss_4': 1.5486252307891846, 'epoch': 14.04}
[INFO|trainer.py:4228] 2025-01-21 13:20:03,604 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:03,604 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                    | 2420/5160 [1:00:08<47:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:10,970 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014028016477823257, 'eval_runtime': 3.8132, 'eval_samples_per_second': 268.541, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.010301236063241959, 'eval_loss_2': 0.003726780414581299, 'eval_loss_3': -18.307601928710938, 'eval_loss_4': 1.2268561124801636, 'epoch': 14.04}
{'loss': 0.0253, 'grad_norm': 11.071333885192871, 'learning_rate': 1.5976744186046514e-05, 'loss_1': 0.01906074583530426, 'loss_2': 0.0062103271484375, 'loss_3': -16.504453659057617, 'loss_4': 1.302617073059082, 'epoch': 14.05}
{'loss': 0.0159, 'grad_norm': 5.754908084869385, 'learning_rate': 1.597093023255814e-05, 'loss_1': 0.013771899975836277, 'loss_2': 0.0020885467529296875, 'loss_3': -16.409202575683594, 'loss_4': 1.0054807662963867, 'epoch': 14.05}
{'loss': 0.0151, 'grad_norm': 9.426342010498047, 'learning_rate': 1.5965116279069768e-05, 'loss_1': 0.014575527980923653, 'loss_2': 0.0005350112915039062, 'loss_3': -16.348312377929688, 'loss_4': 1.280461072921753, 'epoch': 14.06}
{'loss': 0.0183, 'grad_norm': 8.800414085388184, 'learning_rate': 1.5959302325581393e-05, 'loss_1': 0.01788877695798874, 'loss_2': 0.0004096031188964844, 'loss_3': -16.521387100219727, 'loss_4': 1.411476969718933, 'epoch': 14.06}
{'loss': 0.0196, 'grad_norm': 6.2653679847717285, 'learning_rate': 1.5953488372093025e-05, 'loss_1': 0.014407764188945293, 'loss_2': 0.005218505859375, 'loss_3': -16.19379425048828, 'loss_4': 1.6515190601348877, 'epoch': 14.07}
[INFO|trainer.py:4228] 2025-01-21 13:20:10,971 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:10,971 >>   Batch size = 64
 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                    | 2425/5160 [1:00:15<47:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:18,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016751524060964584, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.632, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009435291402041912, 'eval_loss_2': 0.007316231727600098, 'eval_loss_3': -18.310991287231445, 'eval_loss_4': 1.5312581062316895, 'epoch': 14.07}
{'loss': 0.0159, 'grad_norm': 6.120246410369873, 'learning_rate': 1.5947674418604654e-05, 'loss_1': 0.011016209609806538, 'loss_2': 0.00492095947265625, 'loss_3': -16.541826248168945, 'loss_4': 1.5821688175201416, 'epoch': 14.08}
{'loss': 0.0236, 'grad_norm': 6.986705780029297, 'learning_rate': 1.594186046511628e-05, 'loss_1': 0.014585211873054504, 'loss_2': 0.0090179443359375, 'loss_3': -16.379783630371094, 'loss_4': 1.7654143571853638, 'epoch': 14.08}
{'loss': 0.0207, 'grad_norm': 9.382936477661133, 'learning_rate': 1.5936046511627907e-05, 'loss_1': 0.0190743338316679, 'loss_2': 0.001644134521484375, 'loss_3': -16.557754516601562, 'loss_4': 1.8788825273513794, 'epoch': 14.09}
{'loss': 0.0139, 'grad_norm': 5.519535541534424, 'learning_rate': 1.5930232558139536e-05, 'loss_1': 0.011987646110355854, 'loss_2': 0.001956939697265625, 'loss_3': -16.503965377807617, 'loss_4': 1.8598450422286987, 'epoch': 14.09}
{'loss': 0.025, 'grad_norm': 11.171658515930176, 'learning_rate': 1.5924418604651165e-05, 'loss_1': 0.02155301347374916, 'loss_2': 0.00341033935546875, 'loss_3': -16.33504867553711, 'loss_4': 1.3652760982513428, 'epoch': 14.1}
[INFO|trainer.py:4228] 2025-01-21 13:20:18,344 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:18,344 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                   | 2430/5160 [1:00:22<47:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:25,702 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013432873412966728, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0091982027515769, 'eval_loss_2': 0.004234671592712402, 'eval_loss_3': -18.29128646850586, 'eval_loss_4': 1.5930296182632446, 'epoch': 14.1}
{'loss': 0.0773, 'grad_norm': 22.09272575378418, 'learning_rate': 1.591860465116279e-05, 'loss_1': 0.06652574986219406, 'loss_2': 0.0107421875, 'loss_3': -16.166362762451172, 'loss_4': 2.2681541442871094, 'epoch': 14.1}
{'loss': 0.0206, 'grad_norm': 7.335583686828613, 'learning_rate': 1.591279069767442e-05, 'loss_1': 0.018858300521969795, 'loss_2': 0.0016994476318359375, 'loss_3': -16.504114151000977, 'loss_4': 1.7226167917251587, 'epoch': 14.11}
{'loss': 0.009, 'grad_norm': 4.8285932540893555, 'learning_rate': 1.5906976744186047e-05, 'loss_1': 0.00814888160675764, 'loss_2': 0.000881195068359375, 'loss_3': -16.496063232421875, 'loss_4': 2.1230950355529785, 'epoch': 14.12}
{'loss': 0.0097, 'grad_norm': 5.205536365509033, 'learning_rate': 1.5901162790697676e-05, 'loss_1': 0.007538647390902042, 'loss_2': 0.002197265625, 'loss_3': -16.438232421875, 'loss_4': 1.7562090158462524, 'epoch': 14.12}
{'loss': 0.0115, 'grad_norm': 5.0798726081848145, 'learning_rate': 1.5895348837209304e-05, 'loss_1': 0.007043149322271347, 'loss_2': 0.0045013427734375, 'loss_3': -16.408435821533203, 'loss_4': 1.4895297288894653, 'epoch': 14.13}
[INFO|trainer.py:4228] 2025-01-21 13:20:25,702 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:25,702 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                   | 2435/5160 [1:00:30<47:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:33,064 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013107108883559704, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.716, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009996163658797741, 'eval_loss_2': 0.003110945224761963, 'eval_loss_3': -18.285442352294922, 'eval_loss_4': 1.5533686876296997, 'epoch': 14.13}
{'loss': 0.0079, 'grad_norm': 4.493080139160156, 'learning_rate': 1.588953488372093e-05, 'loss_1': 0.007490829098969698, 'loss_2': 0.00038743019104003906, 'loss_3': -16.563800811767578, 'loss_4': 1.6038367748260498, 'epoch': 14.13}
{'loss': 0.0103, 'grad_norm': 6.721627235412598, 'learning_rate': 1.588372093023256e-05, 'loss_1': 0.010156136937439442, 'loss_2': 0.0001169443130493164, 'loss_3': -16.40734100341797, 'loss_4': 2.069394111633301, 'epoch': 14.14}
{'loss': 0.0225, 'grad_norm': 7.502107620239258, 'learning_rate': 1.5877906976744187e-05, 'loss_1': 0.01706720143556595, 'loss_2': 0.0054473876953125, 'loss_3': -16.29209327697754, 'loss_4': 2.0590438842773438, 'epoch': 14.15}
{'loss': 0.0583, 'grad_norm': 27.01252555847168, 'learning_rate': 1.5872093023255816e-05, 'loss_1': 0.05607246235013008, 'loss_2': 0.002231597900390625, 'loss_3': -16.653833389282227, 'loss_4': 1.896824836730957, 'epoch': 14.15}
{'loss': 0.0154, 'grad_norm': 5.550180435180664, 'learning_rate': 1.5866279069767444e-05, 'loss_1': 0.0094208475202322, 'loss_2': 0.006008148193359375, 'loss_3': -16.169403076171875, 'loss_4': 1.3540691137313843, 'epoch': 14.16}
[INFO|trainer.py:4228] 2025-01-21 13:20:33,064 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:33,064 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                   | 2440/5160 [1:00:37<47:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:40,439 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012459933757781982, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.276, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.009067774750292301, 'eval_loss_2': 0.003392159938812256, 'eval_loss_3': -18.27886390686035, 'eval_loss_4': 1.5752487182617188, 'epoch': 14.16}
{'loss': 0.0166, 'grad_norm': 5.67158842086792, 'learning_rate': 1.586046511627907e-05, 'loss_1': 0.011891791597008705, 'loss_2': 0.00466156005859375, 'loss_3': -16.346254348754883, 'loss_4': 1.2848814725875854, 'epoch': 14.16}
{'loss': 0.0158, 'grad_norm': 8.222156524658203, 'learning_rate': 1.5854651162790698e-05, 'loss_1': 0.015381988137960434, 'loss_2': 0.00040149688720703125, 'loss_3': -16.396839141845703, 'loss_4': 1.582503318786621, 'epoch': 14.17}
{'loss': 0.012, 'grad_norm': 5.454702377319336, 'learning_rate': 1.5848837209302323e-05, 'loss_1': 0.011240522377192974, 'loss_2': 0.0007295608520507812, 'loss_3': -16.447851181030273, 'loss_4': 1.1401090621948242, 'epoch': 14.17}
{'loss': 0.0094, 'grad_norm': 5.911545276641846, 'learning_rate': 1.5843023255813955e-05, 'loss_1': 0.007761305198073387, 'loss_2': 0.001605987548828125, 'loss_3': -16.480419158935547, 'loss_4': 1.6339097023010254, 'epoch': 14.18}
{'loss': 0.0123, 'grad_norm': 4.4017839431762695, 'learning_rate': 1.5837209302325584e-05, 'loss_1': 0.004634718410670757, 'loss_2': 0.00765228271484375, 'loss_3': -16.50411605834961, 'loss_4': 1.661048173904419, 'epoch': 14.19}
[INFO|trainer.py:4228] 2025-01-21 13:20:40,439 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:40,439 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 2445/5160 [1:00:44<47:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:47,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012050292454659939, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.727, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008524431847035885, 'eval_loss_2': 0.003525860607624054, 'eval_loss_3': -18.276500701904297, 'eval_loss_4': 1.6632204055786133, 'epoch': 14.19}
{'loss': 0.0187, 'grad_norm': 5.943717956542969, 'learning_rate': 1.583139534883721e-05, 'loss_1': 0.010893797501921654, 'loss_2': 0.00785064697265625, 'loss_3': -16.356739044189453, 'loss_4': 1.3753879070281982, 'epoch': 14.19}
{'loss': 0.0087, 'grad_norm': 5.048569679260254, 'learning_rate': 1.5825581395348838e-05, 'loss_1': 0.008326919749379158, 'loss_2': 0.0003781318664550781, 'loss_3': -16.554828643798828, 'loss_4': 1.3585376739501953, 'epoch': 14.2}
{'loss': 0.0255, 'grad_norm': 12.405454635620117, 'learning_rate': 1.5819767441860463e-05, 'loss_1': 0.021050604060292244, 'loss_2': 0.004486083984375, 'loss_3': -16.387418746948242, 'loss_4': 1.8685237169265747, 'epoch': 14.2}
{'loss': 0.0213, 'grad_norm': 7.1505961418151855, 'learning_rate': 1.5813953488372095e-05, 'loss_1': 0.012325301766395569, 'loss_2': 0.00894927978515625, 'loss_3': -16.347936630249023, 'loss_4': 2.185276746749878, 'epoch': 14.21}
{'loss': 0.0166, 'grad_norm': 5.73328971862793, 'learning_rate': 1.580813953488372e-05, 'loss_1': 0.011408424004912376, 'loss_2': 0.0052337646484375, 'loss_3': -16.45627212524414, 'loss_4': 1.8219780921936035, 'epoch': 14.22}
[INFO|trainer.py:4228] 2025-01-21 13:20:47,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:47,803 >>   Batch size = 64
 47%|███████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                   | 2450/5160 [1:00:52<47:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:20:55,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012239104136824608, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.572, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008387391455471516, 'eval_loss_2': 0.0038517117500305176, 'eval_loss_3': -18.28974151611328, 'eval_loss_4': 1.7443612813949585, 'epoch': 14.22}
{'loss': 0.0079, 'grad_norm': 4.662467956542969, 'learning_rate': 1.580232558139535e-05, 'loss_1': 0.005393913947045803, 'loss_2': 0.00254058837890625, 'loss_3': -16.4121150970459, 'loss_4': 1.7472093105316162, 'epoch': 14.22}
{'loss': 0.0216, 'grad_norm': 7.09921407699585, 'learning_rate': 1.5796511627906978e-05, 'loss_1': 0.01167470682412386, 'loss_2': 0.009918212890625, 'loss_3': -16.60256004333496, 'loss_4': 1.9714372158050537, 'epoch': 14.23}
{'loss': 0.0121, 'grad_norm': 6.684602737426758, 'learning_rate': 1.5790697674418603e-05, 'loss_1': 0.011324412189424038, 'loss_2': 0.0007543563842773438, 'loss_3': -16.454872131347656, 'loss_4': 1.1662529706954956, 'epoch': 14.23}
{'loss': 0.0327, 'grad_norm': 12.319740295410156, 'learning_rate': 1.5784883720930235e-05, 'loss_1': 0.0233156755566597, 'loss_2': 0.0093994140625, 'loss_3': -16.527359008789062, 'loss_4': 2.0658035278320312, 'epoch': 14.24}
{'loss': 0.015, 'grad_norm': 7.3098978996276855, 'learning_rate': 1.577906976744186e-05, 'loss_1': 0.013420920819044113, 'loss_2': 0.0016040802001953125, 'loss_3': -16.67367935180664, 'loss_4': 2.0286617279052734, 'epoch': 14.24}
[INFO|trainer.py:4228] 2025-01-21 13:20:55,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:20:55,178 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 2455/5160 [1:00:59<46:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:02,543 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012617552652955055, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.654, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00869420450180769, 'eval_loss_2': 0.00392334908246994, 'eval_loss_3': -18.283723831176758, 'eval_loss_4': 1.6178267002105713, 'epoch': 14.24}
{'loss': 0.006, 'grad_norm': 4.751643657684326, 'learning_rate': 1.577325581395349e-05, 'loss_1': 0.005485279019922018, 'loss_2': 0.0005559921264648438, 'loss_3': -16.557662963867188, 'loss_4': 1.6857709884643555, 'epoch': 14.25}
{'loss': 0.0113, 'grad_norm': 7.736510753631592, 'learning_rate': 1.5767441860465117e-05, 'loss_1': 0.010116434656083584, 'loss_2': 0.001148223876953125, 'loss_3': -16.444034576416016, 'loss_4': 1.8513052463531494, 'epoch': 14.26}
{'loss': 0.0199, 'grad_norm': 9.872435569763184, 'learning_rate': 1.5761627906976743e-05, 'loss_1': 0.018789194524288177, 'loss_2': 0.0010833740234375, 'loss_3': -16.443859100341797, 'loss_4': 1.9769357442855835, 'epoch': 14.26}
{'loss': 0.0101, 'grad_norm': 5.268613815307617, 'learning_rate': 1.5755813953488375e-05, 'loss_1': 0.00683194026350975, 'loss_2': 0.00325775146484375, 'loss_3': -16.570194244384766, 'loss_4': 1.7380712032318115, 'epoch': 14.27}
{'loss': 0.0118, 'grad_norm': 4.900335311889648, 'learning_rate': 1.575e-05, 'loss_1': 0.0063086324371397495, 'loss_2': 0.005535125732421875, 'loss_3': -16.39669418334961, 'loss_4': 1.5136929750442505, 'epoch': 14.27}
[INFO|trainer.py:4228] 2025-01-21 13:21:02,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:02,543 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                  | 2460/5160 [1:01:07<46:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:09,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011197153478860855, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.644, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007771376054733992, 'eval_loss_2': 0.003425776958465576, 'eval_loss_3': -18.27774429321289, 'eval_loss_4': 1.387662410736084, 'epoch': 14.27}
{'loss': 0.0102, 'grad_norm': 5.2889018058776855, 'learning_rate': 1.574418604651163e-05, 'loss_1': 0.006304142996668816, 'loss_2': 0.00394439697265625, 'loss_3': -16.552749633789062, 'loss_4': 1.5630006790161133, 'epoch': 14.28}
{'loss': 0.0295, 'grad_norm': 7.3808207511901855, 'learning_rate': 1.5738372093023254e-05, 'loss_1': 0.02578798308968544, 'loss_2': 0.0037288665771484375, 'loss_3': -16.56865119934082, 'loss_4': 1.3969008922576904, 'epoch': 14.28}
{'loss': 0.0213, 'grad_norm': 6.613824367523193, 'learning_rate': 1.5732558139534882e-05, 'loss_1': 0.013426011428236961, 'loss_2': 0.0078887939453125, 'loss_3': -16.302894592285156, 'loss_4': 1.7150490283966064, 'epoch': 14.29}
{'loss': 0.0195, 'grad_norm': 7.146934986114502, 'learning_rate': 1.5726744186046515e-05, 'loss_1': 0.015299798920750618, 'loss_2': 0.004245758056640625, 'loss_3': -16.5333194732666, 'loss_4': 1.0382978916168213, 'epoch': 14.3}
{'loss': 0.0256, 'grad_norm': 7.250362873077393, 'learning_rate': 1.572093023255814e-05, 'loss_1': 0.010612825863063335, 'loss_2': 0.0149688720703125, 'loss_3': -16.694292068481445, 'loss_4': 0.7325258851051331, 'epoch': 14.3}
[INFO|trainer.py:4228] 2025-01-21 13:21:09,909 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:09,909 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                  | 2465/5160 [1:01:14<46:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:17,280 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013578010722994804, 'eval_runtime': 3.8179, 'eval_samples_per_second': 268.208, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.006827338598668575, 'eval_loss_2': 0.006750673055648804, 'eval_loss_3': -18.271923065185547, 'eval_loss_4': 1.098266363143921, 'epoch': 14.3}
{'loss': 0.0254, 'grad_norm': 5.502830505371094, 'learning_rate': 1.571511627906977e-05, 'loss_1': 0.011452006176114082, 'loss_2': 0.0139007568359375, 'loss_3': -16.509521484375, 'loss_4': 1.062908411026001, 'epoch': 14.31}
{'loss': 0.0206, 'grad_norm': 16.011140823364258, 'learning_rate': 1.5709302325581394e-05, 'loss_1': 0.014893511310219765, 'loss_2': 0.00568389892578125, 'loss_3': -16.55014419555664, 'loss_4': 1.019932746887207, 'epoch': 14.31}
{'loss': 0.0115, 'grad_norm': 4.8656721115112305, 'learning_rate': 1.5703488372093022e-05, 'loss_1': 0.005361422896385193, 'loss_2': 0.0061492919921875, 'loss_3': -16.482019424438477, 'loss_4': 0.9554293155670166, 'epoch': 14.32}
{'loss': 0.0212, 'grad_norm': 6.373829364776611, 'learning_rate': 1.5697674418604654e-05, 'loss_1': 0.01384213101118803, 'loss_2': 0.00738525390625, 'loss_3': -16.375141143798828, 'loss_4': 0.4848199486732483, 'epoch': 14.33}
{'loss': 0.0145, 'grad_norm': 5.9815449714660645, 'learning_rate': 1.569186046511628e-05, 'loss_1': 0.008645541034638882, 'loss_2': 0.005889892578125, 'loss_3': -16.608234405517578, 'loss_4': 0.4650084972381592, 'epoch': 14.33}
[INFO|trainer.py:4228] 2025-01-21 13:21:17,281 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:17,281 >>   Batch size = 64
 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                  | 2470/5160 [1:01:21<46:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:24,654 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009740890935063362, 'eval_runtime': 3.8186, 'eval_samples_per_second': 268.162, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006623493041843176, 'eval_loss_2': 0.003117397427558899, 'eval_loss_3': -18.275976181030273, 'eval_loss_4': 0.7006382942199707, 'epoch': 14.33}
{'loss': 0.0132, 'grad_norm': 8.693910598754883, 'learning_rate': 1.5686046511627908e-05, 'loss_1': 0.010694267228245735, 'loss_2': 0.0024662017822265625, 'loss_3': -16.384765625, 'loss_4': 0.9405355453491211, 'epoch': 14.34}
{'loss': 0.005, 'grad_norm': 4.778837203979492, 'learning_rate': 1.5680232558139533e-05, 'loss_1': 0.003274176036939025, 'loss_2': 0.0017232894897460938, 'loss_3': -16.534406661987305, 'loss_4': 0.929089367389679, 'epoch': 14.34}
{'loss': 0.0153, 'grad_norm': 6.9181365966796875, 'learning_rate': 1.5674418604651162e-05, 'loss_1': 0.009513096883893013, 'loss_2': 0.00579071044921875, 'loss_3': -16.58885955810547, 'loss_4': 1.0188312530517578, 'epoch': 14.35}
{'loss': 0.006, 'grad_norm': 5.053766250610352, 'learning_rate': 1.566860465116279e-05, 'loss_1': 0.005965362302958965, 'loss_2': 5.519390106201172e-05, 'loss_3': -16.56121826171875, 'loss_4': 0.7708871364593506, 'epoch': 14.35}
{'loss': 0.0118, 'grad_norm': 5.909356117248535, 'learning_rate': 1.566279069767442e-05, 'loss_1': 0.010697492398321629, 'loss_2': 0.0010957717895507812, 'loss_3': -16.370281219482422, 'loss_4': 0.7164963483810425, 'epoch': 14.36}
[INFO|trainer.py:4228] 2025-01-21 13:21:24,654 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:24,654 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                  | 2475/5160 [1:01:29<46:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:32,025 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01007907371968031, 'eval_runtime': 3.8186, 'eval_samples_per_second': 268.161, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006947014480829239, 'eval_loss_2': 0.003132060170173645, 'eval_loss_3': -18.288509368896484, 'eval_loss_4': 0.4528559148311615, 'epoch': 14.36}
{'loss': 0.0094, 'grad_norm': 5.799798488616943, 'learning_rate': 1.5656976744186048e-05, 'loss_1': 0.006085285451263189, 'loss_2': 0.003292083740234375, 'loss_3': -16.284753799438477, 'loss_4': 0.41349729895591736, 'epoch': 14.37}
{'loss': 0.0205, 'grad_norm': 11.472786903381348, 'learning_rate': 1.5651162790697673e-05, 'loss_1': 0.010855120606720448, 'loss_2': 0.0095977783203125, 'loss_3': -16.416095733642578, 'loss_4': 0.34925469756126404, 'epoch': 14.37}
{'loss': 0.0188, 'grad_norm': 5.520702838897705, 'learning_rate': 1.5645348837209302e-05, 'loss_1': 0.008058937266469002, 'loss_2': 0.01071929931640625, 'loss_3': -16.43920135498047, 'loss_4': 0.35118138790130615, 'epoch': 14.38}
{'loss': 0.0162, 'grad_norm': 6.958195686340332, 'learning_rate': 1.563953488372093e-05, 'loss_1': 0.011128383688628674, 'loss_2': 0.005054473876953125, 'loss_3': -16.48280143737793, 'loss_4': 0.5181761980056763, 'epoch': 14.38}
{'loss': 0.0114, 'grad_norm': 7.298870086669922, 'learning_rate': 1.563372093023256e-05, 'loss_1': 0.009021233767271042, 'loss_2': 0.002407073974609375, 'loss_3': -16.575132369995117, 'loss_4': 0.4255863428115845, 'epoch': 14.39}
[INFO|trainer.py:4228] 2025-01-21 13:21:32,026 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:32,026 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                 | 2480/5160 [1:01:36<46:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:39,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011825120076537132, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.601, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008233590982854366, 'eval_loss_2': 0.0035915300250053406, 'eval_loss_3': -18.285898208618164, 'eval_loss_4': 0.409112811088562, 'epoch': 14.39}
{'loss': 0.0103, 'grad_norm': 4.519433498382568, 'learning_rate': 1.5627906976744188e-05, 'loss_1': 0.006097783800214529, 'loss_2': 0.00421142578125, 'loss_3': -16.53961753845215, 'loss_4': 0.37064483761787415, 'epoch': 14.4}
{'loss': 0.0071, 'grad_norm': 5.202084064483643, 'learning_rate': 1.5622093023255813e-05, 'loss_1': 0.006928848568350077, 'loss_2': 0.0001709461212158203, 'loss_3': -16.461605072021484, 'loss_4': 0.6928175687789917, 'epoch': 14.4}
{'loss': 0.009, 'grad_norm': 5.352212429046631, 'learning_rate': 1.561627906976744e-05, 'loss_1': 0.006955034099519253, 'loss_2': 0.0020503997802734375, 'loss_3': -16.38779640197754, 'loss_4': 0.6919723153114319, 'epoch': 14.41}
{'loss': 0.0088, 'grad_norm': 4.9111552238464355, 'learning_rate': 1.561046511627907e-05, 'loss_1': 0.00826386921107769, 'loss_2': 0.0004973411560058594, 'loss_3': -16.552724838256836, 'loss_4': 0.828362226486206, 'epoch': 14.41}
{'loss': 0.0146, 'grad_norm': 4.63495397567749, 'learning_rate': 1.56046511627907e-05, 'loss_1': 0.00709226168692112, 'loss_2': 0.007488250732421875, 'loss_3': -16.366310119628906, 'loss_4': 1.0962786674499512, 'epoch': 14.42}
[INFO|trainer.py:4228] 2025-01-21 13:21:39,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:39,391 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                 | 2485/5160 [1:01:43<46:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:46,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011371085420250893, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.671, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008034714497625828, 'eval_loss_2': 0.0033363699913024902, 'eval_loss_3': -18.279903411865234, 'eval_loss_4': 0.4748876094818115, 'epoch': 14.42}
{'loss': 0.0251, 'grad_norm': 12.438384056091309, 'learning_rate': 1.5598837209302324e-05, 'loss_1': 0.024876900017261505, 'loss_2': 0.0002181529998779297, 'loss_3': -16.48069953918457, 'loss_4': -0.07140770554542542, 'epoch': 14.42}
{'loss': 0.0164, 'grad_norm': 8.501885414123535, 'learning_rate': 1.5593023255813953e-05, 'loss_1': 0.014379167929291725, 'loss_2': 0.00201416015625, 'loss_3': -16.593151092529297, 'loss_4': 0.9866378307342529, 'epoch': 14.43}
{'loss': 0.022, 'grad_norm': 11.039693832397461, 'learning_rate': 1.558720930232558e-05, 'loss_1': 0.01643388718366623, 'loss_2': 0.00560760498046875, 'loss_3': -16.667133331298828, 'loss_4': 0.4375079870223999, 'epoch': 14.44}
{'loss': 0.0119, 'grad_norm': 5.95396614074707, 'learning_rate': 1.558139534883721e-05, 'loss_1': 0.010873526334762573, 'loss_2': 0.0010509490966796875, 'loss_3': -16.28232765197754, 'loss_4': 0.3976738154888153, 'epoch': 14.44}
{'loss': 0.0137, 'grad_norm': 6.755617618560791, 'learning_rate': 1.557558139534884e-05, 'loss_1': 0.012519064359366894, 'loss_2': 0.0011386871337890625, 'loss_3': -16.511863708496094, 'loss_4': 1.3055980205535889, 'epoch': 14.45}
[INFO|trainer.py:4228] 2025-01-21 13:21:46,758 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:46,758 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 2490/5160 [1:01:51<46:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:21:54,132 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011596981436014175, 'eval_runtime': 3.8161, 'eval_samples_per_second': 268.336, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.007762732915580273, 'eval_loss_2': 0.003834247589111328, 'eval_loss_3': -18.281356811523438, 'eval_loss_4': 0.48995864391326904, 'epoch': 14.45}
{'loss': 0.008, 'grad_norm': 6.343332767486572, 'learning_rate': 1.5569767441860464e-05, 'loss_1': 0.006383291911333799, 'loss_2': 0.0016384124755859375, 'loss_3': -16.46491241455078, 'loss_4': 0.6866562366485596, 'epoch': 14.45}
{'loss': 0.0092, 'grad_norm': 5.233592510223389, 'learning_rate': 1.5563953488372092e-05, 'loss_1': 0.0074222637340426445, 'loss_2': 0.001819610595703125, 'loss_3': -16.176992416381836, 'loss_4': 0.41950392723083496, 'epoch': 14.46}
{'loss': 0.0165, 'grad_norm': 8.500031471252441, 'learning_rate': 1.5558139534883725e-05, 'loss_1': 0.014067495241761208, 'loss_2': 0.0024738311767578125, 'loss_3': -16.350061416625977, 'loss_4': 0.563164234161377, 'epoch': 14.47}
{'loss': 0.0206, 'grad_norm': 14.040351867675781, 'learning_rate': 1.555232558139535e-05, 'loss_1': 0.020506950095295906, 'loss_2': 7.545948028564453e-05, 'loss_3': -16.45160675048828, 'loss_4': 0.40018144249916077, 'epoch': 14.47}
{'loss': 0.0104, 'grad_norm': 5.6338701248168945, 'learning_rate': 1.554651162790698e-05, 'loss_1': 0.00856067705899477, 'loss_2': 0.0018100738525390625, 'loss_3': -16.630664825439453, 'loss_4': 0.9293079376220703, 'epoch': 14.48}
[INFO|trainer.py:4228] 2025-01-21 13:21:54,132 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:21:54,132 >>   Batch size = 64
 48%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                 | 2495/5160 [1:01:58<46:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:01,507 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012495975941419601, 'eval_runtime': 3.8228, 'eval_samples_per_second': 267.864, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.008695344440639019, 'eval_loss_2': 0.003800630569458008, 'eval_loss_3': -18.271520614624023, 'eval_loss_4': 0.5092881321907043, 'epoch': 14.48}
{'loss': 0.0162, 'grad_norm': 5.693206310272217, 'learning_rate': 1.5540697674418604e-05, 'loss_1': 0.009051570668816566, 'loss_2': 0.007152557373046875, 'loss_3': -16.188838958740234, 'loss_4': 0.4257535934448242, 'epoch': 14.48}
{'loss': 0.019, 'grad_norm': 5.576021194458008, 'learning_rate': 1.5534883720930232e-05, 'loss_1': 0.009842423722147942, 'loss_2': 0.00917816162109375, 'loss_3': -16.438295364379883, 'loss_4': 0.5049152970314026, 'epoch': 14.49}
{'loss': 0.009, 'grad_norm': 5.0486249923706055, 'learning_rate': 1.552906976744186e-05, 'loss_1': 0.006337715312838554, 'loss_2': 0.0026836395263671875, 'loss_3': -16.138450622558594, 'loss_4': 0.5670824646949768, 'epoch': 14.49}
{'loss': 0.0136, 'grad_norm': 5.644271373748779, 'learning_rate': 1.552325581395349e-05, 'loss_1': 0.007647223304957151, 'loss_2': 0.005985260009765625, 'loss_3': -16.548385620117188, 'loss_4': 0.3025779724121094, 'epoch': 14.5}
{'loss': 0.014, 'grad_norm': 5.6605448722839355, 'learning_rate': 1.5517441860465118e-05, 'loss_1': 0.006649025250226259, 'loss_2': 0.0073089599609375, 'loss_3': -16.393939971923828, 'loss_4': 0.8768531084060669, 'epoch': 14.51}
[INFO|trainer.py:4228] 2025-01-21 13:22:01,507 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:01,507 >>   Batch size = 64
 48%|██████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 2500/5160 [1:02:06<46:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:08,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01317674946039915, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.618, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007704924326390028, 'eval_loss_2': 0.00547182559967041, 'eval_loss_3': -18.260204315185547, 'eval_loss_4': 0.5246537327766418, 'epoch': 14.51}
{'loss': 0.0198, 'grad_norm': 16.153644561767578, 'learning_rate': 1.5511627906976743e-05, 'loss_1': 0.01739259995520115, 'loss_2': 0.00243377685546875, 'loss_3': -16.435251235961914, 'loss_4': 0.8638381361961365, 'epoch': 14.51}
{'loss': 0.0201, 'grad_norm': 7.50383996963501, 'learning_rate': 1.5505813953488372e-05, 'loss_1': 0.016228042542934418, 'loss_2': 0.00384521484375, 'loss_3': -16.322586059570312, 'loss_4': 0.7877284288406372, 'epoch': 14.52}
{'loss': 0.017, 'grad_norm': 6.361918926239014, 'learning_rate': 1.55e-05, 'loss_1': 0.011863699182868004, 'loss_2': 0.00511932373046875, 'loss_3': -16.345966339111328, 'loss_4': 0.44556280970573425, 'epoch': 14.52}
{'loss': 0.0136, 'grad_norm': 5.308969497680664, 'learning_rate': 1.549418604651163e-05, 'loss_1': 0.007088786922395229, 'loss_2': 0.0065460205078125, 'loss_3': -16.540084838867188, 'loss_4': 0.48313039541244507, 'epoch': 14.53}
{'loss': 0.0116, 'grad_norm': 6.1308417320251465, 'learning_rate': 1.5488372093023258e-05, 'loss_1': 0.010697702877223492, 'loss_2': 0.0008668899536132812, 'loss_3': -16.44226837158203, 'loss_4': 0.13765683770179749, 'epoch': 14.53}
[INFO|trainer.py:4228] 2025-01-21 13:22:08,870 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:08,870 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                | 2505/5160 [1:02:13<46:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:16,231 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011564168147742748, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.727, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.00820845551788807, 'eval_loss_2': 0.0033557116985321045, 'eval_loss_3': -18.229890823364258, 'eval_loss_4': 0.5865997672080994, 'epoch': 14.53}
{'loss': 0.0106, 'grad_norm': 5.489112854003906, 'learning_rate': 1.5482558139534883e-05, 'loss_1': 0.008182215504348278, 'loss_2': 0.002407073974609375, 'loss_3': -16.44188117980957, 'loss_4': 0.08192218095064163, 'epoch': 14.54}
{'loss': 0.0224, 'grad_norm': 14.543325424194336, 'learning_rate': 1.5476744186046512e-05, 'loss_1': 0.021532976999878883, 'loss_2': 0.0008678436279296875, 'loss_3': -16.244564056396484, 'loss_4': 0.4766252338886261, 'epoch': 14.55}
{'loss': 0.0222, 'grad_norm': 13.488601684570312, 'learning_rate': 1.547093023255814e-05, 'loss_1': 0.019215276464819908, 'loss_2': 0.0030002593994140625, 'loss_3': -16.27203369140625, 'loss_4': 0.6639479398727417, 'epoch': 14.55}
{'loss': 0.0106, 'grad_norm': 5.368776321411133, 'learning_rate': 1.546511627906977e-05, 'loss_1': 0.009563908912241459, 'loss_2': 0.00104522705078125, 'loss_3': -16.360000610351562, 'loss_4': 0.5971351861953735, 'epoch': 14.56}
{'loss': 0.008, 'grad_norm': 4.867980003356934, 'learning_rate': 1.5459302325581394e-05, 'loss_1': 0.006598495878279209, 'loss_2': 0.0013561248779296875, 'loss_3': -16.49974250793457, 'loss_4': 0.8654815554618835, 'epoch': 14.56}
[INFO|trainer.py:4228] 2025-01-21 13:22:16,231 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:16,231 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                | 2510/5160 [1:02:20<45:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:23,595 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015010764822363853, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.571, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008412530645728111, 'eval_loss_2': 0.006598234176635742, 'eval_loss_3': -18.20595359802246, 'eval_loss_4': 0.6560869216918945, 'epoch': 14.56}
{'loss': 0.0416, 'grad_norm': 10.643550872802734, 'learning_rate': 1.5453488372093023e-05, 'loss_1': 0.03833350911736488, 'loss_2': 0.003253936767578125, 'loss_3': -16.36056900024414, 'loss_4': 0.7337719202041626, 'epoch': 14.57}
{'loss': 0.0197, 'grad_norm': 7.374570369720459, 'learning_rate': 1.544767441860465e-05, 'loss_1': 0.013045388273894787, 'loss_2': 0.006610870361328125, 'loss_3': -16.327999114990234, 'loss_4': 0.9652416706085205, 'epoch': 14.58}
{'loss': 0.0164, 'grad_norm': 5.689086437225342, 'learning_rate': 1.544186046511628e-05, 'loss_1': 0.010168032720685005, 'loss_2': 0.0062713623046875, 'loss_3': -16.369609832763672, 'loss_4': 0.5907474756240845, 'epoch': 14.58}
{'loss': 0.0197, 'grad_norm': 11.030982971191406, 'learning_rate': 1.543604651162791e-05, 'loss_1': 0.018193548545241356, 'loss_2': 0.0015249252319335938, 'loss_3': -16.342483520507812, 'loss_4': 0.9335985779762268, 'epoch': 14.59}
{'loss': 0.016, 'grad_norm': 5.775768280029297, 'learning_rate': 1.5430232558139534e-05, 'loss_1': 0.009931601583957672, 'loss_2': 0.00601959228515625, 'loss_3': -16.270570755004883, 'loss_4': 0.7693908214569092, 'epoch': 14.59}
[INFO|trainer.py:4228] 2025-01-21 13:22:23,595 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:23,595 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                | 2515/5160 [1:02:28<45:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:30,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014051873236894608, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.982, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006983716506510973, 'eval_loss_2': 0.007068157196044922, 'eval_loss_3': -18.211265563964844, 'eval_loss_4': 0.8612308502197266, 'epoch': 14.59}
{'loss': 0.0201, 'grad_norm': 5.6646952629089355, 'learning_rate': 1.5424418604651163e-05, 'loss_1': 0.008998728357255459, 'loss_2': 0.0111236572265625, 'loss_3': -16.410280227661133, 'loss_4': 1.560490608215332, 'epoch': 14.6}
{'loss': 0.0109, 'grad_norm': 5.909268856048584, 'learning_rate': 1.541860465116279e-05, 'loss_1': 0.010742188431322575, 'loss_2': 0.00014221668243408203, 'loss_3': -16.326919555664062, 'loss_4': 0.561811089515686, 'epoch': 14.6}
{'loss': 0.016, 'grad_norm': 6.69256591796875, 'learning_rate': 1.541279069767442e-05, 'loss_1': 0.011434728279709816, 'loss_2': 0.00457000732421875, 'loss_3': -16.448070526123047, 'loss_4': 0.9877135753631592, 'epoch': 14.61}
{'loss': 0.0113, 'grad_norm': 5.525475978851318, 'learning_rate': 1.540697674418605e-05, 'loss_1': 0.010925831273198128, 'loss_2': 0.00035572052001953125, 'loss_3': -16.359819412231445, 'loss_4': 0.6434777975082397, 'epoch': 14.62}
{'loss': 0.0159, 'grad_norm': 7.298801422119141, 'learning_rate': 1.5401162790697674e-05, 'loss_1': 0.014952408149838448, 'loss_2': 0.0009088516235351562, 'loss_3': -16.490184783935547, 'loss_4': 0.9016009569168091, 'epoch': 14.62}
[INFO|trainer.py:4228] 2025-01-21 13:22:30,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:30,962 >>   Batch size = 64
 49%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                | 2520/5160 [1:02:35<45:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:38,342 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011413980275392532, 'eval_runtime': 3.8208, 'eval_samples_per_second': 268.007, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.008732575923204422, 'eval_loss_2': 0.0026814043521881104, 'eval_loss_3': -18.205177307128906, 'eval_loss_4': 0.747592568397522, 'epoch': 14.62}
{'loss': 0.0175, 'grad_norm': 7.4591145515441895, 'learning_rate': 1.5395348837209303e-05, 'loss_1': 0.014392264187335968, 'loss_2': 0.003147125244140625, 'loss_3': -16.661672592163086, 'loss_4': 1.1983482837677002, 'epoch': 14.63}
{'loss': 0.0209, 'grad_norm': 10.723422050476074, 'learning_rate': 1.5389534883720928e-05, 'loss_1': 0.015511239878833294, 'loss_2': 0.005390167236328125, 'loss_3': -16.284942626953125, 'loss_4': 0.8346726894378662, 'epoch': 14.63}
{'loss': 0.0082, 'grad_norm': 5.185124397277832, 'learning_rate': 1.538372093023256e-05, 'loss_1': 0.005863306112587452, 'loss_2': 0.00235748291015625, 'loss_3': -16.43285369873047, 'loss_4': 0.5031375885009766, 'epoch': 14.64}
{'loss': 0.0163, 'grad_norm': 11.100062370300293, 'learning_rate': 1.537790697674419e-05, 'loss_1': 0.013686437159776688, 'loss_2': 0.0026378631591796875, 'loss_3': -16.407394409179688, 'loss_4': 0.5717747211456299, 'epoch': 14.65}
{'loss': 0.0101, 'grad_norm': 5.450611114501953, 'learning_rate': 1.5372093023255814e-05, 'loss_1': 0.008326426148414612, 'loss_2': 0.00173187255859375, 'loss_3': -16.566326141357422, 'loss_4': 0.5672109723091125, 'epoch': 14.65}
[INFO|trainer.py:4228] 2025-01-21 13:22:38,343 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:38,343 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                               | 2525/5160 [1:02:42<45:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:45,706 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012471716850996017, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.81, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00933956727385521, 'eval_loss_2': 0.003132149577140808, 'eval_loss_3': -18.193870544433594, 'eval_loss_4': 0.5517202615737915, 'epoch': 14.65}
{'loss': 0.0302, 'grad_norm': 11.407515525817871, 'learning_rate': 1.5366279069767442e-05, 'loss_1': 0.02657192386686802, 'loss_2': 0.003643035888671875, 'loss_3': -16.538543701171875, 'loss_4': 0.33449581265449524, 'epoch': 14.66}
{'loss': 0.0235, 'grad_norm': 7.312622547149658, 'learning_rate': 1.5360465116279068e-05, 'loss_1': 0.012215346097946167, 'loss_2': 0.0113067626953125, 'loss_3': -16.4481143951416, 'loss_4': 0.8638765811920166, 'epoch': 14.66}
{'loss': 0.0112, 'grad_norm': 7.262515068054199, 'learning_rate': 1.53546511627907e-05, 'loss_1': 0.010084846056997776, 'loss_2': 0.0011453628540039062, 'loss_3': -16.43988800048828, 'loss_4': 0.6459383368492126, 'epoch': 14.67}
{'loss': 0.0127, 'grad_norm': 5.506414413452148, 'learning_rate': 1.5348837209302328e-05, 'loss_1': 0.009142671711742878, 'loss_2': 0.00360107421875, 'loss_3': -16.332868576049805, 'loss_4': 0.44671544432640076, 'epoch': 14.67}
{'loss': 0.0119, 'grad_norm': 5.4109883308410645, 'learning_rate': 1.5343023255813953e-05, 'loss_1': 0.007551340851932764, 'loss_2': 0.00433349609375, 'loss_3': -16.381179809570312, 'loss_4': 0.35868576169013977, 'epoch': 14.68}
[INFO|trainer.py:4228] 2025-01-21 13:22:45,707 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:45,707 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                               | 2530/5160 [1:02:50<45:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:22:53,069 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011711698025465012, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008200090378522873, 'eval_loss_2': 0.0035116076469421387, 'eval_loss_3': -18.196584701538086, 'eval_loss_4': 0.4339762330055237, 'epoch': 14.68}
{'loss': 0.0068, 'grad_norm': 4.795211315155029, 'learning_rate': 1.5337209302325582e-05, 'loss_1': 0.005444529931992292, 'loss_2': 0.001308441162109375, 'loss_3': -16.47489356994629, 'loss_4': 0.5731207728385925, 'epoch': 14.69}
{'loss': 0.0151, 'grad_norm': 5.033344268798828, 'learning_rate': 1.5331395348837207e-05, 'loss_1': 0.009791094809770584, 'loss_2': 0.00534820556640625, 'loss_3': -16.430381774902344, 'loss_4': 0.4990535378456116, 'epoch': 14.69}
{'loss': 0.0128, 'grad_norm': 8.837545394897461, 'learning_rate': 1.532558139534884e-05, 'loss_1': 0.011522491462528706, 'loss_2': 0.0012502670288085938, 'loss_3': -16.397722244262695, 'loss_4': 0.17479495704174042, 'epoch': 14.7}
{'loss': 0.0169, 'grad_norm': 9.045781135559082, 'learning_rate': 1.5319767441860465e-05, 'loss_1': 0.015734625980257988, 'loss_2': 0.00115203857421875, 'loss_3': -16.377925872802734, 'loss_4': 0.6047415733337402, 'epoch': 14.7}
{'loss': 0.0069, 'grad_norm': 4.61991024017334, 'learning_rate': 1.5313953488372093e-05, 'loss_1': 0.005122005008161068, 'loss_2': 0.0017681121826171875, 'loss_3': -16.338054656982422, 'loss_4': 1.1955198049545288, 'epoch': 14.71}
[INFO|trainer.py:4228] 2025-01-21 13:22:53,070 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:22:53,070 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                               | 2535/5160 [1:02:57<45:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:00,426 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013329676352441311, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.933, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009816458448767662, 'eval_loss_2': 0.0035132169723510742, 'eval_loss_3': -18.197513580322266, 'eval_loss_4': 0.348863810300827, 'epoch': 14.71}
{'loss': 0.0095, 'grad_norm': 6.0786027908325195, 'learning_rate': 1.5308139534883722e-05, 'loss_1': 0.008483713492751122, 'loss_2': 0.0010395050048828125, 'loss_3': -16.47513771057129, 'loss_4': 0.3909519612789154, 'epoch': 14.72}
{'loss': 0.0089, 'grad_norm': 5.120029926300049, 'learning_rate': 1.5302325581395347e-05, 'loss_1': 0.005256528500467539, 'loss_2': 0.003681182861328125, 'loss_3': -16.303611755371094, 'loss_4': 0.3954926133155823, 'epoch': 14.72}
{'loss': 0.0165, 'grad_norm': 6.027239799499512, 'learning_rate': 1.529651162790698e-05, 'loss_1': 0.012699997052550316, 'loss_2': 0.00383758544921875, 'loss_3': -16.4057559967041, 'loss_4': -0.12189188599586487, 'epoch': 14.73}
{'loss': 0.0087, 'grad_norm': 4.96382999420166, 'learning_rate': 1.5290697674418604e-05, 'loss_1': 0.005883669015020132, 'loss_2': 0.0028533935546875, 'loss_3': -16.51042938232422, 'loss_4': 0.4695170521736145, 'epoch': 14.73}
{'loss': 0.0073, 'grad_norm': 5.147375106811523, 'learning_rate': 1.5284883720930233e-05, 'loss_1': 0.006337151397019625, 'loss_2': 0.0009975433349609375, 'loss_3': -16.410852432250977, 'loss_4': 0.8529419898986816, 'epoch': 14.74}
[INFO|trainer.py:4228] 2025-01-21 13:23:00,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:00,426 >>   Batch size = 64
 49%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                               | 2540/5160 [1:03:04<45:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:07,790 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013643844053149223, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.448, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.009991571307182312, 'eval_loss_2': 0.0036522746086120605, 'eval_loss_3': -18.199541091918945, 'eval_loss_4': 0.36132729053497314, 'epoch': 14.74}
{'loss': 0.0192, 'grad_norm': 7.150533676147461, 'learning_rate': 1.527906976744186e-05, 'loss_1': 0.016759006306529045, 'loss_2': 0.0024356842041015625, 'loss_3': -16.27281951904297, 'loss_4': 0.4418732821941376, 'epoch': 14.74}
{'loss': 0.0056, 'grad_norm': 4.637537002563477, 'learning_rate': 1.5273255813953487e-05, 'loss_1': 0.0053883814252913, 'loss_2': 0.0002593994140625, 'loss_3': -16.541053771972656, 'loss_4': 0.32032933831214905, 'epoch': 14.75}
{'loss': 0.0121, 'grad_norm': 8.131142616271973, 'learning_rate': 1.526744186046512e-05, 'loss_1': 0.012025360018014908, 'loss_2': 0.00012385845184326172, 'loss_3': -16.144580841064453, 'loss_4': 0.096711665391922, 'epoch': 14.76}
{'loss': 0.0115, 'grad_norm': 6.933825969696045, 'learning_rate': 1.5261627906976744e-05, 'loss_1': 0.01114631351083517, 'loss_2': 0.0003592967987060547, 'loss_3': -16.361007690429688, 'loss_4': 0.8715031147003174, 'epoch': 14.76}
{'loss': 0.0122, 'grad_norm': 5.292660236358643, 'learning_rate': 1.5255813953488373e-05, 'loss_1': 0.006722724065184593, 'loss_2': 0.005504608154296875, 'loss_3': -16.590957641601562, 'loss_4': 0.269297331571579, 'epoch': 14.77}
[INFO|trainer.py:4228] 2025-01-21 13:23:07,790 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:07,790 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                               | 2545/5160 [1:03:12<45:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:15,158 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017173901200294495, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.606, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.011322216130793095, 'eval_loss_2': 0.005851686000823975, 'eval_loss_3': -18.18096351623535, 'eval_loss_4': 0.30695825815200806, 'epoch': 14.77}
{'loss': 0.0858, 'grad_norm': 26.930402755737305, 'learning_rate': 1.525e-05, 'loss_1': 0.08352469652891159, 'loss_2': 0.002227783203125, 'loss_3': -16.320053100585938, 'loss_4': 0.7138963341712952, 'epoch': 14.77}
{'loss': 0.0099, 'grad_norm': 4.412115573883057, 'learning_rate': 1.5244186046511627e-05, 'loss_1': 0.0026279548183083534, 'loss_2': 0.00725555419921875, 'loss_3': -16.395511627197266, 'loss_4': 0.23145242035388947, 'epoch': 14.78}
{'loss': 0.0167, 'grad_norm': 7.108194351196289, 'learning_rate': 1.5238372093023257e-05, 'loss_1': 0.009059211239218712, 'loss_2': 0.007678985595703125, 'loss_3': -16.344284057617188, 'loss_4': 0.6556234359741211, 'epoch': 14.78}
{'loss': 0.0144, 'grad_norm': 6.409487247467041, 'learning_rate': 1.5232558139534884e-05, 'loss_1': 0.01098478864878416, 'loss_2': 0.003444671630859375, 'loss_3': -16.31705093383789, 'loss_4': 0.024064823985099792, 'epoch': 14.79}
{'loss': 0.0175, 'grad_norm': 5.566341876983643, 'learning_rate': 1.5226744186046513e-05, 'loss_1': 0.008536518551409245, 'loss_2': 0.00897216796875, 'loss_3': -16.421382904052734, 'loss_4': 0.5355987548828125, 'epoch': 14.8}
[INFO|trainer.py:4228] 2025-01-21 13:23:15,158 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:15,158 >>   Batch size = 64
 49%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                              | 2550/5160 [1:03:19<45:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:22,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01857823133468628, 'eval_runtime': 3.8204, 'eval_samples_per_second': 268.034, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.012228837236762047, 'eval_loss_2': 0.006349392235279083, 'eval_loss_3': -18.171428680419922, 'eval_loss_4': 0.5206002593040466, 'epoch': 14.8}
{'loss': 0.0151, 'grad_norm': 5.122288703918457, 'learning_rate': 1.522093023255814e-05, 'loss_1': 0.009095462039113045, 'loss_2': 0.005992889404296875, 'loss_3': -16.425148010253906, 'loss_4': 0.3391697108745575, 'epoch': 14.8}
{'loss': 0.0131, 'grad_norm': 7.635335445404053, 'learning_rate': 1.5215116279069766e-05, 'loss_1': 0.007372705731540918, 'loss_2': 0.00577545166015625, 'loss_3': -16.473962783813477, 'loss_4': 0.9725576639175415, 'epoch': 14.81}
{'loss': 0.0104, 'grad_norm': 4.878524303436279, 'learning_rate': 1.5209302325581397e-05, 'loss_1': 0.006752289831638336, 'loss_2': 0.003612518310546875, 'loss_3': -16.444412231445312, 'loss_4': 0.5153520703315735, 'epoch': 14.81}
{'loss': 0.0169, 'grad_norm': 9.234624862670898, 'learning_rate': 1.5203488372093024e-05, 'loss_1': 0.015036927536129951, 'loss_2': 0.001903533935546875, 'loss_3': -16.51219367980957, 'loss_4': 0.9221845865249634, 'epoch': 14.82}
{'loss': 0.0094, 'grad_norm': 5.432426929473877, 'learning_rate': 1.519767441860465e-05, 'loss_1': 0.004786998499184847, 'loss_2': 0.00466156005859375, 'loss_3': -16.326004028320312, 'loss_4': 0.6469632983207703, 'epoch': 14.83}
[INFO|trainer.py:4228] 2025-01-21 13:23:22,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:22,530 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 2555/5160 [1:03:27<45:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:29,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015786187723279, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01209975965321064, 'eval_loss_2': 0.0036864280700683594, 'eval_loss_3': -18.16885757446289, 'eval_loss_4': 0.6499677896499634, 'epoch': 14.83}
{'loss': 0.0066, 'grad_norm': 4.4310760498046875, 'learning_rate': 1.519186046511628e-05, 'loss_1': 0.0038352881092578173, 'loss_2': 0.002719879150390625, 'loss_3': -16.406936645507812, 'loss_4': 0.5407343506813049, 'epoch': 14.83}
{'loss': 0.013, 'grad_norm': 5.615990161895752, 'learning_rate': 1.518604651162791e-05, 'loss_1': 0.006492847576737404, 'loss_2': 0.00649261474609375, 'loss_3': -16.27109146118164, 'loss_4': 0.8311565518379211, 'epoch': 14.84}
{'loss': 0.0121, 'grad_norm': 5.241344928741455, 'learning_rate': 1.5180232558139536e-05, 'loss_1': 0.005225341767072678, 'loss_2': 0.00684356689453125, 'loss_3': -16.38177490234375, 'loss_4': 0.7281334400177002, 'epoch': 14.84}
{'loss': 0.0189, 'grad_norm': 5.699746608734131, 'learning_rate': 1.5174418604651163e-05, 'loss_1': 0.008494568057358265, 'loss_2': 0.0103759765625, 'loss_3': -16.263025283813477, 'loss_4': 0.48913031816482544, 'epoch': 14.85}
{'loss': 0.0207, 'grad_norm': 5.653163433074951, 'learning_rate': 1.516860465116279e-05, 'loss_1': 0.010037773288786411, 'loss_2': 0.01067352294921875, 'loss_3': -16.42413330078125, 'loss_4': 0.17566008865833282, 'epoch': 14.85}
[INFO|trainer.py:4228] 2025-01-21 13:23:29,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:29,889 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                              | 2560/5160 [1:03:34<45:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:37,244 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01612020470201969, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.693, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0128401480615139, 'eval_loss_2': 0.0032800547778606415, 'eval_loss_3': -18.146709442138672, 'eval_loss_4': 0.5387446880340576, 'epoch': 14.85}
{'loss': 0.0204, 'grad_norm': 11.797593116760254, 'learning_rate': 1.5162790697674417e-05, 'loss_1': 0.01967945322394371, 'loss_2': 0.0006885528564453125, 'loss_3': -16.395591735839844, 'loss_4': 0.5653896331787109, 'epoch': 14.86}
{'loss': 0.0092, 'grad_norm': 5.155735969543457, 'learning_rate': 1.515697674418605e-05, 'loss_1': 0.008112207055091858, 'loss_2': 0.00104522705078125, 'loss_3': -16.40357208251953, 'loss_4': 0.5450923442840576, 'epoch': 14.87}
{'loss': 0.012, 'grad_norm': 6.075043201446533, 'learning_rate': 1.5151162790697676e-05, 'loss_1': 0.00910415779799223, 'loss_2': 0.002918243408203125, 'loss_3': -16.52124786376953, 'loss_4': -0.3288198411464691, 'epoch': 14.87}
{'loss': 0.0366, 'grad_norm': 12.773310661315918, 'learning_rate': 1.5145348837209303e-05, 'loss_1': 0.030491022393107414, 'loss_2': 0.006130218505859375, 'loss_3': -16.28596305847168, 'loss_4': 0.22606948018074036, 'epoch': 14.88}
{'loss': 0.0106, 'grad_norm': 4.825788497924805, 'learning_rate': 1.513953488372093e-05, 'loss_1': 0.005303412210196257, 'loss_2': 0.00525665283203125, 'loss_3': -16.136249542236328, 'loss_4': 0.18019187450408936, 'epoch': 14.88}
[INFO|trainer.py:4228] 2025-01-21 13:23:37,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:37,245 >>   Batch size = 64
 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                              | 2565/5160 [1:03:41<44:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:44,601 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01600414328277111, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.846, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012048332020640373, 'eval_loss_2': 0.003955811262130737, 'eval_loss_3': -18.15784454345703, 'eval_loss_4': 0.5538738369941711, 'epoch': 14.88}
{'loss': 0.0111, 'grad_norm': 6.546018600463867, 'learning_rate': 1.5133720930232557e-05, 'loss_1': 0.01013601291924715, 'loss_2': 0.0009579658508300781, 'loss_3': -16.274513244628906, 'loss_4': 0.5540676116943359, 'epoch': 14.89}
{'loss': 0.0053, 'grad_norm': 5.018081188201904, 'learning_rate': 1.5127906976744187e-05, 'loss_1': 0.005213536322116852, 'loss_2': 0.00013494491577148438, 'loss_3': -16.209016799926758, 'loss_4': 0.22477233409881592, 'epoch': 14.9}
{'loss': 0.0179, 'grad_norm': 5.832193374633789, 'learning_rate': 1.5122093023255816e-05, 'loss_1': 0.012652823701500893, 'loss_2': 0.005218505859375, 'loss_3': -16.099380493164062, 'loss_4': 0.24383442103862762, 'epoch': 14.9}
{'loss': 0.0134, 'grad_norm': 5.114224433898926, 'learning_rate': 1.5116279069767443e-05, 'loss_1': 0.009466470219194889, 'loss_2': 0.00396728515625, 'loss_3': -16.42713165283203, 'loss_4': 0.5880062580108643, 'epoch': 14.91}
{'loss': 0.0136, 'grad_norm': 6.4550395011901855, 'learning_rate': 1.511046511627907e-05, 'loss_1': 0.009772088378667831, 'loss_2': 0.0037975311279296875, 'loss_3': -16.13238525390625, 'loss_4': 0.41295677423477173, 'epoch': 14.91}
[INFO|trainer.py:4228] 2025-01-21 13:23:44,601 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:44,602 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                              | 2570/5160 [1:03:49<44:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:51,956 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013863159343600273, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.886, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010373994708061218, 'eval_loss_2': 0.0034891627728939056, 'eval_loss_3': -18.180089950561523, 'eval_loss_4': 0.7440482378005981, 'epoch': 14.91}
{'loss': 0.0088, 'grad_norm': 4.810146808624268, 'learning_rate': 1.5104651162790697e-05, 'loss_1': 0.007160082459449768, 'loss_2': 0.0016660690307617188, 'loss_3': -16.461612701416016, 'loss_4': 0.2749183177947998, 'epoch': 14.92}
{'loss': 0.0111, 'grad_norm': 5.281871318817139, 'learning_rate': 1.5098837209302327e-05, 'loss_1': 0.006445044185966253, 'loss_2': 0.0046234130859375, 'loss_3': -16.32469940185547, 'loss_4': 0.7499686479568481, 'epoch': 14.92}
{'loss': 0.0109, 'grad_norm': 4.883498191833496, 'learning_rate': 1.5093023255813954e-05, 'loss_1': 0.009738107211887836, 'loss_2': 0.0011167526245117188, 'loss_3': -16.507061004638672, 'loss_4': 0.6902672648429871, 'epoch': 14.93}
{'loss': 0.0237, 'grad_norm': 9.296916961669922, 'learning_rate': 1.5087209302325583e-05, 'loss_1': 0.019642066210508347, 'loss_2': 0.0040435791015625, 'loss_3': -16.48375701904297, 'loss_4': 0.9067136645317078, 'epoch': 14.94}
{'loss': 0.0139, 'grad_norm': 4.967836380004883, 'learning_rate': 1.508139534883721e-05, 'loss_1': 0.004804706666618586, 'loss_2': 0.0091400146484375, 'loss_3': -16.2576904296875, 'loss_4': 1.0076041221618652, 'epoch': 14.94}
[INFO|trainer.py:4228] 2025-01-21 13:23:51,956 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:51,956 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                             | 2575/5160 [1:03:56<44:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:23:59,313 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01352511253207922, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.636, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009787287563085556, 'eval_loss_2': 0.0037378259003162384, 'eval_loss_3': -18.225744247436523, 'eval_loss_4': 0.7740828990936279, 'epoch': 14.94}
{'loss': 0.0078, 'grad_norm': 4.651152610778809, 'learning_rate': 1.5075581395348837e-05, 'loss_1': 0.006052831653505564, 'loss_2': 0.001781463623046875, 'loss_3': -16.409915924072266, 'loss_4': 1.0784460306167603, 'epoch': 14.95}
{'loss': 0.0088, 'grad_norm': 4.96713399887085, 'learning_rate': 1.5069767441860467e-05, 'loss_1': 0.008355646394193172, 'loss_2': 0.00046825408935546875, 'loss_3': -16.30333137512207, 'loss_4': 0.5889205932617188, 'epoch': 14.95}
{'loss': 0.0145, 'grad_norm': 5.92027473449707, 'learning_rate': 1.5063953488372094e-05, 'loss_1': 0.013875934295356274, 'loss_2': 0.0006556510925292969, 'loss_3': -16.183448791503906, 'loss_4': 1.1583532094955444, 'epoch': 14.96}
{'loss': 0.0137, 'grad_norm': 5.293532371520996, 'learning_rate': 1.505813953488372e-05, 'loss_1': 0.012460130266845226, 'loss_2': 0.001201629638671875, 'loss_3': -16.46649932861328, 'loss_4': 0.8593249320983887, 'epoch': 14.97}
{'loss': 0.0181, 'grad_norm': 7.650533676147461, 'learning_rate': 1.505232558139535e-05, 'loss_1': 0.014137325808405876, 'loss_2': 0.003940582275390625, 'loss_3': -16.76929473876953, 'loss_4': 0.5906292200088501, 'epoch': 14.97}
[INFO|trainer.py:4228] 2025-01-21 13:23:59,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:23:59,313 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                             | 2580/5160 [1:04:03<40:12,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:24:06,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01423679105937481, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.584, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009382798336446285, 'eval_loss_2': 0.004853993654251099, 'eval_loss_3': -18.23896026611328, 'eval_loss_4': 0.8381294012069702, 'epoch': 14.97}
{'loss': 0.0129, 'grad_norm': 6.845813751220703, 'learning_rate': 1.5046511627906976e-05, 'loss_1': 0.011760089546442032, 'loss_2': 0.0011157989501953125, 'loss_3': -16.344911575317383, 'loss_4': 0.3690187335014343, 'epoch': 14.98}
{'loss': 0.0194, 'grad_norm': 6.029095649719238, 'learning_rate': 1.5040697674418607e-05, 'loss_1': 0.01211069617420435, 'loss_2': 0.00731658935546875, 'loss_3': -16.311519622802734, 'loss_4': 1.2148478031158447, 'epoch': 14.98}
{'loss': 0.0156, 'grad_norm': 6.533028602600098, 'learning_rate': 1.5034883720930234e-05, 'loss_1': 0.011827834881842136, 'loss_2': 0.003787994384765625, 'loss_3': -16.307056427001953, 'loss_4': 0.6711965799331665, 'epoch': 14.99}
{'loss': 0.0243, 'grad_norm': 9.226115226745605, 'learning_rate': 1.502906976744186e-05, 'loss_1': 0.015657713636755943, 'loss_2': 0.0086212158203125, 'loss_3': -16.296276092529297, 'loss_4': 0.3537508249282837, 'epoch': 14.99}
{'loss': 0.0316, 'grad_norm': 11.43140983581543, 'learning_rate': 1.5023255813953488e-05, 'loss_1': 0.01655668579041958, 'loss_2': 0.0150604248046875, 'loss_3': -16.348350524902344, 'loss_4': 1.2530288696289062, 'epoch': 15.0}
[INFO|trainer.py:4228] 2025-01-21 13:24:06,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:06,325 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                             | 2585/5160 [1:04:10<43:57,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:24:13,721 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012922839261591434, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.884, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009073810651898384, 'eval_loss_2': 0.003849029541015625, 'eval_loss_3': -18.243606567382812, 'eval_loss_4': 0.9821425676345825, 'epoch': 15.0}
{'loss': 0.0248, 'grad_norm': 6.514134407043457, 'learning_rate': 1.5017441860465116e-05, 'loss_1': 0.014063580892980099, 'loss_2': 0.0107574462890625, 'loss_3': -16.44352912902832, 'loss_4': 0.16864371299743652, 'epoch': 15.01}
{'loss': 0.0219, 'grad_norm': 7.2356085777282715, 'learning_rate': 1.5011627906976747e-05, 'loss_1': 0.015298246406018734, 'loss_2': 0.00662994384765625, 'loss_3': -16.424808502197266, 'loss_4': 1.2154568433761597, 'epoch': 15.01}
{'loss': 0.0138, 'grad_norm': 5.247828006744385, 'learning_rate': 1.5005813953488373e-05, 'loss_1': 0.009977016597986221, 'loss_2': 0.00380706787109375, 'loss_3': -16.709373474121094, 'loss_4': 1.0318872928619385, 'epoch': 15.02}
{'loss': 0.0149, 'grad_norm': 4.7476725578308105, 'learning_rate': 1.5e-05, 'loss_1': 0.008818130008876324, 'loss_2': 0.006061553955078125, 'loss_3': -16.191017150878906, 'loss_4': 1.13301420211792, 'epoch': 15.02}
{'loss': 0.0113, 'grad_norm': 6.592936038970947, 'learning_rate': 1.4994186046511627e-05, 'loss_1': 0.009485983289778233, 'loss_2': 0.0018157958984375, 'loss_3': -16.55071449279785, 'loss_4': 1.8488155603408813, 'epoch': 15.03}
[INFO|trainer.py:4228] 2025-01-21 13:24:13,721 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:13,721 >>   Batch size = 64
 50%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                             | 2590/5160 [1:04:18<44:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:21,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012481187470257282, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.139, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008795169182121754, 'eval_loss_2': 0.0036860182881355286, 'eval_loss_3': -18.254371643066406, 'eval_loss_4': 1.057706356048584, 'epoch': 15.03}
{'loss': 0.007, 'grad_norm': 5.344000339508057, 'learning_rate': 1.4988372093023256e-05, 'loss_1': 0.005891686771064997, 'loss_2': 0.0010662078857421875, 'loss_3': -16.329200744628906, 'loss_4': 0.30648040771484375, 'epoch': 15.03}
{'loss': 0.0061, 'grad_norm': 5.299163818359375, 'learning_rate': 1.4982558139534885e-05, 'loss_1': 0.004942126106470823, 'loss_2': 0.0011138916015625, 'loss_3': -16.324501037597656, 'loss_4': 0.8570221662521362, 'epoch': 15.04}
{'loss': 0.0161, 'grad_norm': 6.552606582641602, 'learning_rate': 1.4976744186046513e-05, 'loss_1': 0.012889022938907146, 'loss_2': 0.003223419189453125, 'loss_3': -16.099864959716797, 'loss_4': 1.4629430770874023, 'epoch': 15.05}
{'loss': 0.0128, 'grad_norm': 5.763606548309326, 'learning_rate': 1.497093023255814e-05, 'loss_1': 0.010954329743981361, 'loss_2': 0.0018033981323242188, 'loss_3': -16.39853858947754, 'loss_4': 0.9177290797233582, 'epoch': 15.05}
{'loss': 0.0113, 'grad_norm': 5.549582481384277, 'learning_rate': 1.4965116279069767e-05, 'loss_1': 0.008559397421777248, 'loss_2': 0.002727508544921875, 'loss_3': -16.246912002563477, 'loss_4': 0.760811448097229, 'epoch': 15.06}
[INFO|trainer.py:4228] 2025-01-21 13:24:21,073 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:21,073 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                            | 2595/5160 [1:04:25<44:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:28,433 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013643339276313782, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009669973514974117, 'eval_loss_2': 0.00397336483001709, 'eval_loss_3': -18.265457153320312, 'eval_loss_4': 0.9392001628875732, 'epoch': 15.06}
{'loss': 0.0068, 'grad_norm': 5.619583606719971, 'learning_rate': 1.4959302325581396e-05, 'loss_1': 0.006679933052510023, 'loss_2': 0.00012993812561035156, 'loss_3': -16.489688873291016, 'loss_4': 1.1625919342041016, 'epoch': 15.06}
{'loss': 0.0072, 'grad_norm': 5.280913829803467, 'learning_rate': 1.4953488372093023e-05, 'loss_1': 0.0054407198913395405, 'loss_2': 0.0017299652099609375, 'loss_3': -16.488571166992188, 'loss_4': 0.5811289548873901, 'epoch': 15.07}
{'loss': 0.0138, 'grad_norm': 5.989193916320801, 'learning_rate': 1.4947674418604651e-05, 'loss_1': 0.0082945441827178, 'loss_2': 0.005523681640625, 'loss_3': -16.433095932006836, 'loss_4': 1.196990966796875, 'epoch': 15.08}
{'loss': 0.012, 'grad_norm': 5.962833404541016, 'learning_rate': 1.494186046511628e-05, 'loss_1': 0.008369960822165012, 'loss_2': 0.003620147705078125, 'loss_3': -16.49150848388672, 'loss_4': 0.5188915729522705, 'epoch': 15.08}
{'loss': 0.0148, 'grad_norm': 8.528961181640625, 'learning_rate': 1.4936046511627907e-05, 'loss_1': 0.01246180385351181, 'loss_2': 0.002384185791015625, 'loss_3': -16.38846778869629, 'loss_4': 1.2497663497924805, 'epoch': 15.09}
[INFO|trainer.py:4228] 2025-01-21 13:24:28,433 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:28,433 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                            | 2600/5160 [1:04:32<44:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:35,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013164177536964417, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.888, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010344102047383785, 'eval_loss_2': 0.0028200745582580566, 'eval_loss_3': -18.24073028564453, 'eval_loss_4': 0.9111955761909485, 'epoch': 15.09}
{'loss': 0.0189, 'grad_norm': 10.760610580444336, 'learning_rate': 1.4930232558139535e-05, 'loss_1': 0.018046531826257706, 'loss_2': 0.0008058547973632812, 'loss_3': -16.33224868774414, 'loss_4': 1.4656901359558105, 'epoch': 15.09}
{'loss': 0.0108, 'grad_norm': 5.526605606079102, 'learning_rate': 1.4924418604651162e-05, 'loss_1': 0.007909437641501427, 'loss_2': 0.0028629302978515625, 'loss_3': -16.28923225402832, 'loss_4': 0.9954004883766174, 'epoch': 15.1}
{'loss': 0.0116, 'grad_norm': 5.464028835296631, 'learning_rate': 1.4918604651162791e-05, 'loss_1': 0.006121882703155279, 'loss_2': 0.00545501708984375, 'loss_3': -16.42890167236328, 'loss_4': 0.596142053604126, 'epoch': 15.1}
{'loss': 0.0072, 'grad_norm': 6.580076217651367, 'learning_rate': 1.4912790697674418e-05, 'loss_1': 0.007073304615914822, 'loss_2': 0.0001386404037475586, 'loss_3': -16.395112991333008, 'loss_4': 1.2555558681488037, 'epoch': 15.11}
{'loss': 0.0153, 'grad_norm': 5.129615306854248, 'learning_rate': 1.4906976744186047e-05, 'loss_1': 0.0049706255085766315, 'loss_2': 0.010345458984375, 'loss_3': -16.20244026184082, 'loss_4': 0.7328602075576782, 'epoch': 15.12}
[INFO|trainer.py:4228] 2025-01-21 13:24:35,800 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:35,800 >>   Batch size = 64
 50%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                            | 2605/5160 [1:04:40<44:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:43,164 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013610545545816422, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.462, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.01026860997080803, 'eval_loss_2': 0.0033419355750083923, 'eval_loss_3': -18.20463752746582, 'eval_loss_4': 0.7949331402778625, 'epoch': 15.12}
{'loss': 0.0143, 'grad_norm': 4.940983295440674, 'learning_rate': 1.4901162790697675e-05, 'loss_1': 0.0057701305486261845, 'loss_2': 0.00853729248046875, 'loss_3': -16.355262756347656, 'loss_4': 0.572742760181427, 'epoch': 15.12}
{'loss': 0.0133, 'grad_norm': 8.666728973388672, 'learning_rate': 1.4895348837209302e-05, 'loss_1': 0.0132680032402277, 'loss_2': 5.364418029785156e-06, 'loss_3': -16.28980255126953, 'loss_4': 0.8183609247207642, 'epoch': 15.13}
{'loss': 0.0147, 'grad_norm': 5.219930648803711, 'learning_rate': 1.488953488372093e-05, 'loss_1': 0.008429858833551407, 'loss_2': 0.006290435791015625, 'loss_3': -16.400861740112305, 'loss_4': 0.5917678475379944, 'epoch': 15.13}
{'loss': 0.0149, 'grad_norm': 4.429430961608887, 'learning_rate': 1.4883720930232558e-05, 'loss_1': 0.004305129870772362, 'loss_2': 0.01055145263671875, 'loss_3': -16.13656997680664, 'loss_4': 0.8176475167274475, 'epoch': 15.14}
{'loss': 0.0097, 'grad_norm': 5.228094577789307, 'learning_rate': 1.4877906976744186e-05, 'loss_1': 0.0050855581648647785, 'loss_2': 0.0046539306640625, 'loss_3': -16.344152450561523, 'loss_4': 0.9163590669631958, 'epoch': 15.15}
[INFO|trainer.py:4228] 2025-01-21 13:24:43,164 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:43,164 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 2610/5160 [1:04:47<44:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:50,518 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01800858974456787, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.113, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013979017734527588, 'eval_loss_2': 0.004029572010040283, 'eval_loss_3': -18.17603302001953, 'eval_loss_4': 0.8153302073478699, 'epoch': 15.15}
{'loss': 0.0086, 'grad_norm': 4.4711527824401855, 'learning_rate': 1.4872093023255815e-05, 'loss_1': 0.0050561982207000256, 'loss_2': 0.0035247802734375, 'loss_3': -16.524219512939453, 'loss_4': 1.0397498607635498, 'epoch': 15.15}
{'loss': 0.0128, 'grad_norm': 7.93257474899292, 'learning_rate': 1.4866279069767442e-05, 'loss_1': 0.011187403462827206, 'loss_2': 0.001605987548828125, 'loss_3': -16.231468200683594, 'loss_4': 0.5105590224266052, 'epoch': 15.16}
{'loss': 0.0175, 'grad_norm': 5.970731735229492, 'learning_rate': 1.486046511627907e-05, 'loss_1': 0.01374350767582655, 'loss_2': 0.003757476806640625, 'loss_3': -16.335891723632812, 'loss_4': 0.7179930210113525, 'epoch': 15.16}
{'loss': 0.039, 'grad_norm': 15.376627922058105, 'learning_rate': 1.4854651162790698e-05, 'loss_1': 0.03887146711349487, 'loss_2': 0.00016617774963378906, 'loss_3': -16.503583908081055, 'loss_4': 1.1010408401489258, 'epoch': 15.17}
{'loss': 0.0189, 'grad_norm': 9.734455108642578, 'learning_rate': 1.4848837209302326e-05, 'loss_1': 0.015867816284298897, 'loss_2': 0.003040313720703125, 'loss_3': -16.591474533081055, 'loss_4': 1.1038962602615356, 'epoch': 15.17}
[INFO|trainer.py:4228] 2025-01-21 13:24:50,519 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:50,519 >>   Batch size = 64
 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                            | 2615/5160 [1:04:55<44:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:24:57,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.023911431431770325, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.72, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01889432966709137, 'eval_loss_2': 0.005017101764678955, 'eval_loss_3': -18.159748077392578, 'eval_loss_4': 0.9030723571777344, 'epoch': 15.17}
{'loss': 0.0155, 'grad_norm': 5.36305570602417, 'learning_rate': 1.4843023255813953e-05, 'loss_1': 0.01091013103723526, 'loss_2': 0.004558563232421875, 'loss_3': -16.265487670898438, 'loss_4': 1.4217976331710815, 'epoch': 15.18}
{'loss': 0.0088, 'grad_norm': 5.280126094818115, 'learning_rate': 1.4837209302325582e-05, 'loss_1': 0.008557900786399841, 'loss_2': 0.00022149085998535156, 'loss_3': -16.301145553588867, 'loss_4': 0.8976813554763794, 'epoch': 15.19}
{'loss': 0.0164, 'grad_norm': 6.55566930770874, 'learning_rate': 1.483139534883721e-05, 'loss_1': 0.01103243324905634, 'loss_2': 0.005401611328125, 'loss_3': -16.22960662841797, 'loss_4': 1.1062798500061035, 'epoch': 15.19}
{'loss': 0.0135, 'grad_norm': 4.658382415771484, 'learning_rate': 1.4825581395348837e-05, 'loss_1': 0.006396934390068054, 'loss_2': 0.00710296630859375, 'loss_3': -16.350849151611328, 'loss_4': 0.5573341846466064, 'epoch': 15.2}
{'loss': 0.017, 'grad_norm': 5.452754974365234, 'learning_rate': 1.4819767441860466e-05, 'loss_1': 0.012181557714939117, 'loss_2': 0.0048370361328125, 'loss_3': -16.429271697998047, 'loss_4': 1.3037554025650024, 'epoch': 15.2}
[INFO|trainer.py:4228] 2025-01-21 13:24:57,884 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:24:57,884 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                           | 2620/5160 [1:05:02<44:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:05,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020590465515851974, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.913, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.015250727534294128, 'eval_loss_2': 0.005339734256267548, 'eval_loss_3': -18.195499420166016, 'eval_loss_4': 0.7529611587524414, 'epoch': 15.2}
{'loss': 0.0084, 'grad_norm': 5.080729961395264, 'learning_rate': 1.4813953488372093e-05, 'loss_1': 0.00789864081889391, 'loss_2': 0.00051116943359375, 'loss_3': -16.42981719970703, 'loss_4': 0.64401775598526, 'epoch': 15.21}
{'loss': 0.0121, 'grad_norm': 6.07227087020874, 'learning_rate': 1.480813953488372e-05, 'loss_1': 0.007492239587008953, 'loss_2': 0.004642486572265625, 'loss_3': -16.49359703063965, 'loss_4': -0.05197908729314804, 'epoch': 15.22}
{'loss': 0.0517, 'grad_norm': 15.12573528289795, 'learning_rate': 1.480232558139535e-05, 'loss_1': 0.04125657677650452, 'loss_2': 0.0104217529296875, 'loss_3': -16.385387420654297, 'loss_4': 0.6032770276069641, 'epoch': 15.22}
{'loss': 0.0148, 'grad_norm': 6.42318058013916, 'learning_rate': 1.4796511627906977e-05, 'loss_1': 0.008097203448414803, 'loss_2': 0.006748199462890625, 'loss_3': -16.335433959960938, 'loss_4': 1.375138282775879, 'epoch': 15.23}
{'loss': 0.0169, 'grad_norm': 5.388320446014404, 'learning_rate': 1.4790697674418606e-05, 'loss_1': 0.008547663688659668, 'loss_2': 0.00838470458984375, 'loss_3': -16.328880310058594, 'loss_4': 1.0643699169158936, 'epoch': 15.23}
[INFO|trainer.py:4228] 2025-01-21 13:25:05,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:05,246 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                           | 2625/5160 [1:05:09<43:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:12,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018691470846533775, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.015232076868414879, 'eval_loss_2': 0.0034593939781188965, 'eval_loss_3': -18.18108367919922, 'eval_loss_4': 0.6781290173530579, 'epoch': 15.23}
{'loss': 0.0599, 'grad_norm': 13.7629976272583, 'learning_rate': 1.4784883720930233e-05, 'loss_1': 0.05152066797018051, 'loss_2': 0.00838470458984375, 'loss_3': -16.163827896118164, 'loss_4': 0.6600253582000732, 'epoch': 15.24}
{'loss': 0.0131, 'grad_norm': 5.459765434265137, 'learning_rate': 1.477906976744186e-05, 'loss_1': 0.007995115593075752, 'loss_2': 0.00513458251953125, 'loss_3': -16.47500228881836, 'loss_4': 0.8332163095474243, 'epoch': 15.24}
{'loss': 0.0076, 'grad_norm': 5.354763984680176, 'learning_rate': 1.4773255813953488e-05, 'loss_1': 0.0069204880855977535, 'loss_2': 0.0006480216979980469, 'loss_3': -16.283714294433594, 'loss_4': 0.5105794072151184, 'epoch': 15.25}
{'loss': 0.0033, 'grad_norm': 4.709174156188965, 'learning_rate': 1.4767441860465117e-05, 'loss_1': 0.003263099817559123, 'loss_2': 1.4483928680419922e-05, 'loss_3': -16.637603759765625, 'loss_4': 0.9313324689865112, 'epoch': 15.26}
{'loss': 0.0184, 'grad_norm': 8.117315292358398, 'learning_rate': 1.4761627906976746e-05, 'loss_1': 0.017144279554486275, 'loss_2': 0.0012531280517578125, 'loss_3': -16.448740005493164, 'loss_4': 0.382798969745636, 'epoch': 15.26}
[INFO|trainer.py:4228] 2025-01-21 13:25:12,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:12,607 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                           | 2630/5160 [1:05:17<43:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:19,977 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017804469913244247, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.168, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.014705878682434559, 'eval_loss_2': 0.003098592162132263, 'eval_loss_3': -18.17615509033203, 'eval_loss_4': 0.5058718323707581, 'epoch': 15.26}
{'loss': 0.019, 'grad_norm': 6.375973701477051, 'learning_rate': 1.4755813953488372e-05, 'loss_1': 0.015989897772669792, 'loss_2': 0.002960205078125, 'loss_3': -16.348297119140625, 'loss_4': 0.4682665467262268, 'epoch': 15.27}
{'loss': 0.0103, 'grad_norm': 5.758228302001953, 'learning_rate': 1.475e-05, 'loss_1': 0.008057923056185246, 'loss_2': 0.00226593017578125, 'loss_3': -16.328821182250977, 'loss_4': 0.5828229784965515, 'epoch': 15.27}
{'loss': 0.0101, 'grad_norm': 4.843160629272461, 'learning_rate': 1.4744186046511628e-05, 'loss_1': 0.006290714722126722, 'loss_2': 0.003849029541015625, 'loss_3': -16.31068229675293, 'loss_4': 0.6638513207435608, 'epoch': 15.28}
{'loss': 0.0061, 'grad_norm': 4.490984916687012, 'learning_rate': 1.4738372093023255e-05, 'loss_1': 0.005229238420724869, 'loss_2': 0.0008764266967773438, 'loss_3': -16.59893035888672, 'loss_4': 0.7742561101913452, 'epoch': 15.28}
{'loss': 0.0086, 'grad_norm': 4.810027599334717, 'learning_rate': 1.4732558139534885e-05, 'loss_1': 0.004979175981134176, 'loss_2': 0.003643035888671875, 'loss_3': -16.476181030273438, 'loss_4': 0.48716261982917786, 'epoch': 15.29}
[INFO|trainer.py:4228] 2025-01-21 13:25:19,977 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:19,977 >>   Batch size = 64
 51%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                           | 2635/5160 [1:05:24<43:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:27,346 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015688762068748474, 'eval_runtime': 3.8201, 'eval_samples_per_second': 268.056, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.012237699702382088, 'eval_loss_2': 0.0034510642290115356, 'eval_loss_3': -18.196352005004883, 'eval_loss_4': 0.40339207649230957, 'epoch': 15.29}
{'loss': 0.0111, 'grad_norm': 4.896803379058838, 'learning_rate': 1.4726744186046512e-05, 'loss_1': 0.006911094766110182, 'loss_2': 0.0041656494140625, 'loss_3': -16.45210838317871, 'loss_4': 0.8849589824676514, 'epoch': 15.3}
{'loss': 0.011, 'grad_norm': 6.2165350914001465, 'learning_rate': 1.472093023255814e-05, 'loss_1': 0.007600067183375359, 'loss_2': 0.00337982177734375, 'loss_3': -16.34490394592285, 'loss_4': 0.08173424005508423, 'epoch': 15.3}
{'loss': 0.0123, 'grad_norm': 6.360184192657471, 'learning_rate': 1.4715116279069768e-05, 'loss_1': 0.010256948880851269, 'loss_2': 0.0020294189453125, 'loss_3': -16.365802764892578, 'loss_4': 0.5216939449310303, 'epoch': 15.31}
{'loss': 0.0101, 'grad_norm': 6.2688307762146, 'learning_rate': 1.4709302325581395e-05, 'loss_1': 0.007749394979327917, 'loss_2': 0.002307891845703125, 'loss_3': -16.700510025024414, 'loss_4': 0.8806620836257935, 'epoch': 15.31}
{'loss': 0.0178, 'grad_norm': 5.251828193664551, 'learning_rate': 1.4703488372093023e-05, 'loss_1': 0.00814705528318882, 'loss_2': 0.009613037109375, 'loss_3': -16.302562713623047, 'loss_4': 0.3143913149833679, 'epoch': 15.32}
[INFO|trainer.py:4228] 2025-01-21 13:25:27,347 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:27,347 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                           | 2640/5160 [1:05:31<43:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:34,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013623266480863094, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.529, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.010172441601753235, 'eval_loss_2': 0.003450825810432434, 'eval_loss_3': -18.199777603149414, 'eval_loss_4': 0.4399157166481018, 'epoch': 15.32}
{'loss': 0.0119, 'grad_norm': 5.053746700286865, 'learning_rate': 1.4697674418604652e-05, 'loss_1': 0.006463102530688047, 'loss_2': 0.0054473876953125, 'loss_3': -16.510536193847656, 'loss_4': 0.9014040231704712, 'epoch': 15.33}
{'loss': 0.0123, 'grad_norm': 6.383367538452148, 'learning_rate': 1.469186046511628e-05, 'loss_1': 0.00982701126486063, 'loss_2': 0.0024394989013671875, 'loss_3': -16.498382568359375, 'loss_4': 0.3144250810146332, 'epoch': 15.33}
{'loss': 0.0149, 'grad_norm': 5.905726909637451, 'learning_rate': 1.4686046511627908e-05, 'loss_1': 0.005761140026152134, 'loss_2': 0.0091552734375, 'loss_3': -16.409231185913086, 'loss_4': 0.878879189491272, 'epoch': 15.34}
{'loss': 0.0079, 'grad_norm': 5.151292324066162, 'learning_rate': 1.4680232558139535e-05, 'loss_1': 0.0044351788237690926, 'loss_2': 0.0034770965576171875, 'loss_3': -16.523239135742188, 'loss_4': 0.6995933651924133, 'epoch': 15.34}
{'loss': 0.0215, 'grad_norm': 13.337538719177246, 'learning_rate': 1.4674418604651163e-05, 'loss_1': 0.017625141888856888, 'loss_2': 0.003902435302734375, 'loss_3': -16.48455810546875, 'loss_4': 0.48576658964157104, 'epoch': 15.35}
[INFO|trainer.py:4228] 2025-01-21 13:25:34,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:34,714 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                          | 2645/5160 [1:05:39<43:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:42,075 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013141023926436901, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.682, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0092916963621974, 'eval_loss_2': 0.003849327564239502, 'eval_loss_3': -18.205673217773438, 'eval_loss_4': 0.6620341539382935, 'epoch': 15.35}
{'loss': 0.049, 'grad_norm': 18.199254989624023, 'learning_rate': 1.466860465116279e-05, 'loss_1': 0.04815972223877907, 'loss_2': 0.0008821487426757812, 'loss_3': -16.506908416748047, 'loss_4': 0.647831380367279, 'epoch': 15.35}
{'loss': 0.0166, 'grad_norm': 6.279655933380127, 'learning_rate': 1.466279069767442e-05, 'loss_1': 0.01331885065883398, 'loss_2': 0.00328826904296875, 'loss_3': -16.336589813232422, 'loss_4': 0.5228316783905029, 'epoch': 15.36}
{'loss': 0.0043, 'grad_norm': 4.879800319671631, 'learning_rate': 1.4656976744186047e-05, 'loss_1': 0.004040529951453209, 'loss_2': 0.0002982616424560547, 'loss_3': -16.46983528137207, 'loss_4': 1.1457816362380981, 'epoch': 15.37}
{'loss': 0.0127, 'grad_norm': 8.050686836242676, 'learning_rate': 1.4651162790697674e-05, 'loss_1': 0.007462200243026018, 'loss_2': 0.005199432373046875, 'loss_3': -16.407161712646484, 'loss_4': 0.7107166647911072, 'epoch': 15.37}
{'loss': 0.0345, 'grad_norm': 21.298114776611328, 'learning_rate': 1.4645348837209303e-05, 'loss_1': 0.03347846865653992, 'loss_2': 0.0009717941284179688, 'loss_3': -16.447586059570312, 'loss_4': 0.9431115984916687, 'epoch': 15.38}
[INFO|trainer.py:4228] 2025-01-21 13:25:42,075 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:42,076 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                          | 2650/5160 [1:05:46<43:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:49,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014848032034933567, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.715, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010172566398978233, 'eval_loss_2': 0.004675466567277908, 'eval_loss_3': -18.194690704345703, 'eval_loss_4': 0.8333022594451904, 'epoch': 15.38}
{'loss': 0.0238, 'grad_norm': 8.683286666870117, 'learning_rate': 1.463953488372093e-05, 'loss_1': 0.01750342920422554, 'loss_2': 0.006256103515625, 'loss_3': -16.515451431274414, 'loss_4': 0.6408820748329163, 'epoch': 15.38}
{'loss': 0.0128, 'grad_norm': 6.58630895614624, 'learning_rate': 1.4633720930232558e-05, 'loss_1': 0.01198562141507864, 'loss_2': 0.00080108642578125, 'loss_3': -16.603946685791016, 'loss_4': 0.5441524386405945, 'epoch': 15.39}
{'loss': 0.0186, 'grad_norm': 5.1430816650390625, 'learning_rate': 1.4627906976744187e-05, 'loss_1': 0.0073766689747571945, 'loss_2': 0.0112152099609375, 'loss_3': -16.43313980102539, 'loss_4': 1.0493888854980469, 'epoch': 15.4}
{'loss': 0.0253, 'grad_norm': 10.888185501098633, 'learning_rate': 1.4622093023255814e-05, 'loss_1': 0.02122090756893158, 'loss_2': 0.004119873046875, 'loss_3': -16.288162231445312, 'loss_4': 0.7846946716308594, 'epoch': 15.4}
{'loss': 0.0173, 'grad_norm': 6.247105121612549, 'learning_rate': 1.4616279069767443e-05, 'loss_1': 0.015414657071232796, 'loss_2': 0.0019216537475585938, 'loss_3': -16.198440551757812, 'loss_4': 1.438421607017517, 'epoch': 15.41}
[INFO|trainer.py:4228] 2025-01-21 13:25:49,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:49,445 >>   Batch size = 64
 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                          | 2655/5160 [1:05:53<43:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:25:56,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01588382199406624, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.808, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01106974296271801, 'eval_loss_2': 0.004814080893993378, 'eval_loss_3': -18.19473648071289, 'eval_loss_4': 0.959871768951416, 'epoch': 15.41}
{'loss': 0.0125, 'grad_norm': 5.912288188934326, 'learning_rate': 1.461046511627907e-05, 'loss_1': 0.010310499928891659, 'loss_2': 0.002231597900390625, 'loss_3': -16.499183654785156, 'loss_4': 1.3891690969467163, 'epoch': 15.41}
{'loss': 0.0189, 'grad_norm': 8.408646583557129, 'learning_rate': 1.4604651162790698e-05, 'loss_1': 0.014718648977577686, 'loss_2': 0.00414276123046875, 'loss_3': -16.595964431762695, 'loss_4': 1.4334505796432495, 'epoch': 15.42}
{'loss': 0.0088, 'grad_norm': 4.573764801025391, 'learning_rate': 1.4598837209302325e-05, 'loss_1': 0.004685761872678995, 'loss_2': 0.00412750244140625, 'loss_3': -16.429615020751953, 'loss_4': 1.2464367151260376, 'epoch': 15.42}
{'loss': 0.0109, 'grad_norm': 5.24965238571167, 'learning_rate': 1.4593023255813954e-05, 'loss_1': 0.00961741991341114, 'loss_2': 0.001285552978515625, 'loss_3': -16.502826690673828, 'loss_4': 0.7619722485542297, 'epoch': 15.43}
{'loss': 0.0159, 'grad_norm': 5.885365962982178, 'learning_rate': 1.4587209302325582e-05, 'loss_1': 0.012930614873766899, 'loss_2': 0.003002166748046875, 'loss_3': -16.626544952392578, 'loss_4': 0.7369234561920166, 'epoch': 15.44}
[INFO|trainer.py:4228] 2025-01-21 13:25:56,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:25:56,809 >>   Batch size = 64
 52%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                          | 2660/5160 [1:06:01<43:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:04,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012630745768547058, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.415, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.00851719081401825, 'eval_loss_2': 0.004113554954528809, 'eval_loss_3': -18.211994171142578, 'eval_loss_4': 1.0248937606811523, 'epoch': 15.44}
{'loss': 0.0081, 'grad_norm': 5.258760452270508, 'learning_rate': 1.458139534883721e-05, 'loss_1': 0.00620648730546236, 'loss_2': 0.0018472671508789062, 'loss_3': -16.25962257385254, 'loss_4': 1.241908073425293, 'epoch': 15.44}
{'loss': 0.0193, 'grad_norm': 6.787829399108887, 'learning_rate': 1.4575581395348838e-05, 'loss_1': 0.015819739550352097, 'loss_2': 0.003452301025390625, 'loss_3': -16.46735954284668, 'loss_4': 1.2859340906143188, 'epoch': 15.45}
{'loss': 0.0172, 'grad_norm': 6.868313312530518, 'learning_rate': 1.4569767441860465e-05, 'loss_1': 0.013280415907502174, 'loss_2': 0.0039005279541015625, 'loss_3': -16.30569839477539, 'loss_4': 0.5584505796432495, 'epoch': 15.45}
{'loss': 0.0055, 'grad_norm': 4.918906211853027, 'learning_rate': 1.4563953488372092e-05, 'loss_1': 0.005291677545756102, 'loss_2': 0.00017309188842773438, 'loss_3': -16.3875732421875, 'loss_4': 1.210944652557373, 'epoch': 15.46}
{'loss': 0.0143, 'grad_norm': 5.7599711418151855, 'learning_rate': 1.4558139534883722e-05, 'loss_1': 0.009969744831323624, 'loss_2': 0.00433349609375, 'loss_3': -16.467327117919922, 'loss_4': 1.4630696773529053, 'epoch': 15.47}
[INFO|trainer.py:4228] 2025-01-21 13:26:04,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:04,182 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 2665/5160 [1:06:08<43:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:11,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01069329772144556, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.763, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007333857007324696, 'eval_loss_2': 0.003359440714120865, 'eval_loss_3': -18.229490280151367, 'eval_loss_4': 1.0975240468978882, 'epoch': 15.47}
{'loss': 0.0107, 'grad_norm': 5.42844820022583, 'learning_rate': 1.455232558139535e-05, 'loss_1': 0.006677248980849981, 'loss_2': 0.00405120849609375, 'loss_3': -16.416990280151367, 'loss_4': 0.8603103160858154, 'epoch': 15.47}
{'loss': 0.0115, 'grad_norm': 5.735010147094727, 'learning_rate': 1.4546511627906978e-05, 'loss_1': 0.00946548581123352, 'loss_2': 0.0019989013671875, 'loss_3': -16.336509704589844, 'loss_4': 1.0086312294006348, 'epoch': 15.48}
{'loss': 0.012, 'grad_norm': 6.540003776550293, 'learning_rate': 1.4540697674418605e-05, 'loss_1': 0.011340909637510777, 'loss_2': 0.0006895065307617188, 'loss_3': -16.506790161132812, 'loss_4': 0.9225115776062012, 'epoch': 15.48}
{'loss': 0.0061, 'grad_norm': 4.518045425415039, 'learning_rate': 1.4534883720930232e-05, 'loss_1': 0.005498513579368591, 'loss_2': 0.0005726814270019531, 'loss_3': -16.32819366455078, 'loss_4': 1.0020886659622192, 'epoch': 15.49}
{'loss': 0.0278, 'grad_norm': 12.980018615722656, 'learning_rate': 1.452906976744186e-05, 'loss_1': 0.02242226153612137, 'loss_2': 0.005401611328125, 'loss_3': -16.5112361907959, 'loss_4': 1.100550889968872, 'epoch': 15.49}
[INFO|trainer.py:4228] 2025-01-21 13:26:11,543 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:11,543 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                         | 2670/5160 [1:06:16<43:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:18,911 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011237923055887222, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.668, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.0076090204529464245, 'eval_loss_2': 0.0036289021372795105, 'eval_loss_3': -18.242965698242188, 'eval_loss_4': 1.0312144756317139, 'epoch': 15.49}
{'loss': 0.0097, 'grad_norm': 5.620471954345703, 'learning_rate': 1.4523255813953489e-05, 'loss_1': 0.007678563706576824, 'loss_2': 0.0019741058349609375, 'loss_3': -16.08929443359375, 'loss_4': 1.3435389995574951, 'epoch': 15.5}
{'loss': 0.012, 'grad_norm': 5.722011089324951, 'learning_rate': 1.4517441860465118e-05, 'loss_1': 0.007643407676368952, 'loss_2': 0.004364013671875, 'loss_3': -16.38787078857422, 'loss_4': 1.0491421222686768, 'epoch': 15.51}
{'loss': 0.0148, 'grad_norm': 6.9018940925598145, 'learning_rate': 1.4511627906976745e-05, 'loss_1': 0.014269986189901829, 'loss_2': 0.0004916191101074219, 'loss_3': -16.434253692626953, 'loss_4': 1.1954259872436523, 'epoch': 15.51}
{'loss': 0.0128, 'grad_norm': 5.533036231994629, 'learning_rate': 1.4505813953488373e-05, 'loss_1': 0.00884641520678997, 'loss_2': 0.0039520263671875, 'loss_3': -16.603485107421875, 'loss_4': 1.1184556484222412, 'epoch': 15.52}
{'loss': 0.0109, 'grad_norm': 4.5889997482299805, 'learning_rate': 1.45e-05, 'loss_1': 0.006279618479311466, 'loss_2': 0.00466156005859375, 'loss_3': -16.52029800415039, 'loss_4': 1.6226556301116943, 'epoch': 15.52}
[INFO|trainer.py:4228] 2025-01-21 13:26:18,911 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:18,911 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                         | 2675/5160 [1:06:23<43:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:26,283 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012192968279123306, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.616, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008467544801533222, 'eval_loss_2': 0.0037254244089126587, 'eval_loss_3': -18.254491806030273, 'eval_loss_4': 1.092799186706543, 'epoch': 15.52}
{'loss': 0.0079, 'grad_norm': 4.253332614898682, 'learning_rate': 1.4494186046511627e-05, 'loss_1': 0.0053268661722540855, 'loss_2': 0.002559661865234375, 'loss_3': -16.561416625976562, 'loss_4': 0.9281437397003174, 'epoch': 15.53}
{'loss': 0.0085, 'grad_norm': 5.248104572296143, 'learning_rate': 1.4488372093023257e-05, 'loss_1': 0.007004063576459885, 'loss_2': 0.0015430450439453125, 'loss_3': -16.534610748291016, 'loss_4': 1.354074478149414, 'epoch': 15.53}
{'loss': 0.0233, 'grad_norm': 8.667652130126953, 'learning_rate': 1.4482558139534884e-05, 'loss_1': 0.020335786044597626, 'loss_2': 0.002941131591796875, 'loss_3': -16.51228904724121, 'loss_4': 1.449750542640686, 'epoch': 15.54}
{'loss': 0.0188, 'grad_norm': 10.69227123260498, 'learning_rate': 1.4476744186046513e-05, 'loss_1': 0.017542414367198944, 'loss_2': 0.0012865066528320312, 'loss_3': -16.352737426757812, 'loss_4': 1.3367207050323486, 'epoch': 15.55}
{'loss': 0.0156, 'grad_norm': 6.992639064788818, 'learning_rate': 1.447093023255814e-05, 'loss_1': 0.013680520467460155, 'loss_2': 0.0019321441650390625, 'loss_3': -16.389991760253906, 'loss_4': 0.9907474517822266, 'epoch': 15.55}
[INFO|trainer.py:4228] 2025-01-21 13:26:26,283 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:26,283 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                         | 2680/5160 [1:06:30<43:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:33,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012958495877683163, 'eval_runtime': 3.813, 'eval_samples_per_second': 268.555, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0087373536080122, 'eval_loss_2': 0.004221141338348389, 'eval_loss_3': -18.27596092224121, 'eval_loss_4': 1.1716341972351074, 'epoch': 15.55}
{'loss': 0.0129, 'grad_norm': 5.30717134475708, 'learning_rate': 1.4465116279069767e-05, 'loss_1': 0.01078089140355587, 'loss_2': 0.0020732879638671875, 'loss_3': -16.394624710083008, 'loss_4': 1.0595835447311401, 'epoch': 15.56}
{'loss': 0.0508, 'grad_norm': 14.440549850463867, 'learning_rate': 1.4459302325581395e-05, 'loss_1': 0.04769669473171234, 'loss_2': 0.0030994415283203125, 'loss_3': -16.286293029785156, 'loss_4': 1.2125067710876465, 'epoch': 15.56}
{'loss': 0.0196, 'grad_norm': 5.710206031799316, 'learning_rate': 1.4453488372093024e-05, 'loss_1': 0.011579293757677078, 'loss_2': 0.008056640625, 'loss_3': -16.492345809936523, 'loss_4': 1.2169060707092285, 'epoch': 15.57}
{'loss': 0.0208, 'grad_norm': 4.685136795043945, 'learning_rate': 1.4447674418604653e-05, 'loss_1': 0.005035580601543188, 'loss_2': 0.015716552734375, 'loss_3': -16.634193420410156, 'loss_4': 0.7762886881828308, 'epoch': 15.58}
{'loss': 0.0086, 'grad_norm': 4.709644317626953, 'learning_rate': 1.444186046511628e-05, 'loss_1': 0.007050628773868084, 'loss_2': 0.0015697479248046875, 'loss_3': -16.598249435424805, 'loss_4': 1.3387548923492432, 'epoch': 15.58}
[INFO|trainer.py:4228] 2025-01-21 13:26:33,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:33,655 >>   Batch size = 64
 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                         | 2685/5160 [1:06:38<42:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:41,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014265162870287895, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.829, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009112242609262466, 'eval_loss_2': 0.0051529183983802795, 'eval_loss_3': -18.300996780395508, 'eval_loss_4': 1.3462719917297363, 'epoch': 15.58}
{'loss': 0.014, 'grad_norm': 5.247883319854736, 'learning_rate': 1.4436046511627907e-05, 'loss_1': 0.009394259192049503, 'loss_2': 0.0045928955078125, 'loss_3': -16.631980895996094, 'loss_4': 0.9245914220809937, 'epoch': 15.59}
{'loss': 0.0079, 'grad_norm': 4.652583122253418, 'learning_rate': 1.4430232558139535e-05, 'loss_1': 0.005231612361967564, 'loss_2': 0.0027008056640625, 'loss_3': -16.36516571044922, 'loss_4': 1.1187297105789185, 'epoch': 15.59}
{'loss': 0.0099, 'grad_norm': 4.594878673553467, 'learning_rate': 1.4424418604651162e-05, 'loss_1': 0.006803660187870264, 'loss_2': 0.0030994415283203125, 'loss_3': -16.65506362915039, 'loss_4': 1.326540470123291, 'epoch': 15.6}
{'loss': 0.0176, 'grad_norm': 8.030632972717285, 'learning_rate': 1.4418604651162792e-05, 'loss_1': 0.013906118459999561, 'loss_2': 0.0037403106689453125, 'loss_3': -16.347671508789062, 'loss_4': 1.7980302572250366, 'epoch': 15.6}
{'loss': 0.0288, 'grad_norm': 6.48239803314209, 'learning_rate': 1.441279069767442e-05, 'loss_1': 0.023640582337975502, 'loss_2': 0.005126953125, 'loss_3': -16.438440322875977, 'loss_4': 1.497749924659729, 'epoch': 15.61}
[INFO|trainer.py:4228] 2025-01-21 13:26:41,025 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:41,025 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                        | 2690/5160 [1:06:45<42:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:48,389 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013850999064743519, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.364, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.010147732682526112, 'eval_loss_2': 0.0037032663822174072, 'eval_loss_3': -18.300289154052734, 'eval_loss_4': 1.2876888513565063, 'epoch': 15.61}
{'loss': 0.009, 'grad_norm': 5.530368804931641, 'learning_rate': 1.4406976744186046e-05, 'loss_1': 0.0085282688960433, 'loss_2': 0.0005016326904296875, 'loss_3': -16.619094848632812, 'loss_4': 0.9846578240394592, 'epoch': 15.62}
{'loss': 0.0125, 'grad_norm': 6.117887020111084, 'learning_rate': 1.4401162790697675e-05, 'loss_1': 0.01001135352998972, 'loss_2': 0.00250244140625, 'loss_3': -16.5291805267334, 'loss_4': 1.645559310913086, 'epoch': 15.62}
{'loss': 0.0071, 'grad_norm': 5.2390055656433105, 'learning_rate': 1.4395348837209302e-05, 'loss_1': 0.005112895742058754, 'loss_2': 0.001964569091796875, 'loss_3': -16.665576934814453, 'loss_4': 1.1680032014846802, 'epoch': 15.63}
{'loss': 0.0127, 'grad_norm': 6.752162933349609, 'learning_rate': 1.438953488372093e-05, 'loss_1': 0.011959121562540531, 'loss_2': 0.0007581710815429688, 'loss_3': -16.752300262451172, 'loss_4': 1.4270833730697632, 'epoch': 15.63}
{'loss': 0.0167, 'grad_norm': 7.31188440322876, 'learning_rate': 1.438372093023256e-05, 'loss_1': 0.011102552525699139, 'loss_2': 0.005584716796875, 'loss_3': -16.624792098999023, 'loss_4': 1.3988174200057983, 'epoch': 15.64}
[INFO|trainer.py:4228] 2025-01-21 13:26:48,390 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:48,390 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                        | 2695/5160 [1:06:52<42:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:26:55,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015332160517573357, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.936, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.01002335362136364, 'eval_loss_2': 0.005308806896209717, 'eval_loss_3': -18.307235717773438, 'eval_loss_4': 1.1685110330581665, 'epoch': 15.64}
{'loss': 0.0166, 'grad_norm': 5.898137092590332, 'learning_rate': 1.4377906976744186e-05, 'loss_1': 0.012563568539917469, 'loss_2': 0.00399017333984375, 'loss_3': -16.54020881652832, 'loss_4': 1.1671180725097656, 'epoch': 15.65}
{'loss': 0.0216, 'grad_norm': 8.83696460723877, 'learning_rate': 1.4372093023255815e-05, 'loss_1': 0.019956005737185478, 'loss_2': 0.00165557861328125, 'loss_3': -16.423282623291016, 'loss_4': 1.2386784553527832, 'epoch': 15.65}
{'loss': 0.0106, 'grad_norm': 4.933619022369385, 'learning_rate': 1.4366279069767442e-05, 'loss_1': 0.004227827303111553, 'loss_2': 0.00640106201171875, 'loss_3': -16.39393424987793, 'loss_4': 1.1758530139923096, 'epoch': 15.66}
{'loss': 0.029, 'grad_norm': 10.674915313720703, 'learning_rate': 1.436046511627907e-05, 'loss_1': 0.021077262237668037, 'loss_2': 0.007965087890625, 'loss_3': -16.367507934570312, 'loss_4': 1.0932033061981201, 'epoch': 15.66}
{'loss': 0.0112, 'grad_norm': 5.516439437866211, 'learning_rate': 1.4354651162790697e-05, 'loss_1': 0.007753351237624884, 'loss_2': 0.003437042236328125, 'loss_3': -16.394001007080078, 'loss_4': 1.096337914466858, 'epoch': 15.67}
[INFO|trainer.py:4228] 2025-01-21 13:26:55,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:26:55,748 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                        | 2700/5160 [1:07:00<42:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:03,107 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01353171095252037, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.074, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00886588729918003, 'eval_loss_2': 0.00466582179069519, 'eval_loss_3': -18.314373016357422, 'eval_loss_4': 1.0160293579101562, 'epoch': 15.67}
{'loss': 0.0143, 'grad_norm': 5.503272533416748, 'learning_rate': 1.4348837209302326e-05, 'loss_1': 0.00820300355553627, 'loss_2': 0.006069183349609375, 'loss_3': -16.344654083251953, 'loss_4': 1.5112072229385376, 'epoch': 15.67}
{'loss': 0.0102, 'grad_norm': 5.18803071975708, 'learning_rate': 1.4343023255813955e-05, 'loss_1': 0.00542677566409111, 'loss_2': 0.00478363037109375, 'loss_3': -16.499248504638672, 'loss_4': 1.3478505611419678, 'epoch': 15.68}
{'loss': 0.0066, 'grad_norm': 4.973647117614746, 'learning_rate': 1.4337209302325581e-05, 'loss_1': 0.006052724551409483, 'loss_2': 0.0005445480346679688, 'loss_3': -16.662246704101562, 'loss_4': 0.675176739692688, 'epoch': 15.69}
{'loss': 0.0102, 'grad_norm': 5.1142096519470215, 'learning_rate': 1.433139534883721e-05, 'loss_1': 0.00748789357021451, 'loss_2': 0.0027332305908203125, 'loss_3': -16.771892547607422, 'loss_4': 1.2472374439239502, 'epoch': 15.69}
{'loss': 0.0406, 'grad_norm': 13.556564331054688, 'learning_rate': 1.4325581395348837e-05, 'loss_1': 0.03294070065021515, 'loss_2': 0.0076904296875, 'loss_3': -16.579814910888672, 'loss_4': 0.932937502861023, 'epoch': 15.7}
[INFO|trainer.py:4228] 2025-01-21 13:27:03,108 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:03,108 >>   Batch size = 64
 52%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                        | 2705/5160 [1:07:07<42:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:10,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013369277119636536, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009704023599624634, 'eval_loss_2': 0.003665253520011902, 'eval_loss_3': -18.293960571289062, 'eval_loss_4': 0.8411148190498352, 'epoch': 15.7}
{'loss': 0.0143, 'grad_norm': 6.011028289794922, 'learning_rate': 1.4319767441860466e-05, 'loss_1': 0.008401964791119099, 'loss_2': 0.00594329833984375, 'loss_3': -16.5623779296875, 'loss_4': 1.0994640588760376, 'epoch': 15.7}
{'loss': 0.0078, 'grad_norm': 5.37723445892334, 'learning_rate': 1.4313953488372094e-05, 'loss_1': 0.003695964813232422, 'loss_2': 0.00414276123046875, 'loss_3': -16.54561424255371, 'loss_4': 0.5969284772872925, 'epoch': 15.71}
{'loss': 0.008, 'grad_norm': 4.822103500366211, 'learning_rate': 1.4308139534883721e-05, 'loss_1': 0.005867099389433861, 'loss_2': 0.002117156982421875, 'loss_3': -16.545549392700195, 'loss_4': 0.6667457818984985, 'epoch': 15.72}
{'loss': 0.0132, 'grad_norm': 9.896592140197754, 'learning_rate': 1.430232558139535e-05, 'loss_1': 0.010489272885024548, 'loss_2': 0.002719879150390625, 'loss_3': -16.60352325439453, 'loss_4': 0.5823438763618469, 'epoch': 15.72}
{'loss': 0.0134, 'grad_norm': 6.385101318359375, 'learning_rate': 1.4296511627906977e-05, 'loss_1': 0.008779115974903107, 'loss_2': 0.0046234130859375, 'loss_3': -16.70961570739746, 'loss_4': 0.49992072582244873, 'epoch': 15.73}
[INFO|trainer.py:4228] 2025-01-21 13:27:10,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:10,467 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                        | 2710/5160 [1:07:14<42:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:17,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011483713053166866, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.008254989050328732, 'eval_loss_2': 0.0032287240028381348, 'eval_loss_3': -18.285400390625, 'eval_loss_4': 0.5721330642700195, 'epoch': 15.73}
{'loss': 0.0552, 'grad_norm': 15.661551475524902, 'learning_rate': 1.4290697674418605e-05, 'loss_1': 0.05408133193850517, 'loss_2': 0.0011615753173828125, 'loss_3': -16.531620025634766, 'loss_4': 0.5138295292854309, 'epoch': 15.73}
{'loss': 0.0082, 'grad_norm': 5.575870037078857, 'learning_rate': 1.4284883720930232e-05, 'loss_1': 0.006411498412489891, 'loss_2': 0.0018100738525390625, 'loss_3': -16.480266571044922, 'loss_4': 0.6120995283126831, 'epoch': 15.74}
{'loss': 0.0137, 'grad_norm': 7.0726728439331055, 'learning_rate': 1.4279069767441861e-05, 'loss_1': 0.013551316224038601, 'loss_2': 0.00016307830810546875, 'loss_3': -16.590560913085938, 'loss_4': 1.0667939186096191, 'epoch': 15.74}
{'loss': 0.0208, 'grad_norm': 8.631847381591797, 'learning_rate': 1.427325581395349e-05, 'loss_1': 0.01795179583132267, 'loss_2': 0.002841949462890625, 'loss_3': -16.409015655517578, 'loss_4': 0.5191487073898315, 'epoch': 15.75}
{'loss': 0.0105, 'grad_norm': 4.418002128601074, 'learning_rate': 1.4267441860465117e-05, 'loss_1': 0.005809093825519085, 'loss_2': 0.00469207763671875, 'loss_3': -16.60055923461914, 'loss_4': 0.4743524193763733, 'epoch': 15.76}
[INFO|trainer.py:4228] 2025-01-21 13:27:17,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:17,819 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                       | 2715/5160 [1:07:22<42:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:25,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010570021346211433, 'eval_runtime': 3.817, 'eval_samples_per_second': 268.276, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.007527918554842472, 'eval_loss_2': 0.0030421018600463867, 'eval_loss_3': -18.283967971801758, 'eval_loss_4': 0.39702799916267395, 'epoch': 15.76}
{'loss': 0.0146, 'grad_norm': 6.937224388122559, 'learning_rate': 1.4261627906976745e-05, 'loss_1': 0.013105222955346107, 'loss_2': 0.00147247314453125, 'loss_3': -16.586933135986328, 'loss_4': 0.2919290065765381, 'epoch': 15.76}
{'loss': 0.0122, 'grad_norm': 5.4586181640625, 'learning_rate': 1.4255813953488372e-05, 'loss_1': 0.0100287776440382, 'loss_2': 0.0022182464599609375, 'loss_3': -16.35064697265625, 'loss_4': 0.24273677170276642, 'epoch': 15.77}
{'loss': 0.0092, 'grad_norm': 5.458877086639404, 'learning_rate': 1.4249999999999999e-05, 'loss_1': 0.00783510971814394, 'loss_2': 0.0013952255249023438, 'loss_3': -16.545635223388672, 'loss_4': 0.6697896718978882, 'epoch': 15.77}
{'loss': 0.0164, 'grad_norm': 6.431218147277832, 'learning_rate': 1.424418604651163e-05, 'loss_1': 0.01090568583458662, 'loss_2': 0.00551605224609375, 'loss_3': -16.491601943969727, 'loss_4': 0.09374521672725677, 'epoch': 15.78}
{'loss': 0.0075, 'grad_norm': 5.592123031616211, 'learning_rate': 1.4238372093023256e-05, 'loss_1': 0.007432045880705118, 'loss_2': 9.679794311523438e-05, 'loss_3': -16.52806854248047, 'loss_4': 0.4699939489364624, 'epoch': 15.78}
[INFO|trainer.py:4228] 2025-01-21 13:27:25,187 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:25,187 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                       | 2720/5160 [1:07:29<42:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:32,545 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012595539912581444, 'eval_runtime': 3.8138, 'eval_samples_per_second': 268.501, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.009380749426782131, 'eval_loss_2': 0.003214791417121887, 'eval_loss_3': -18.265573501586914, 'eval_loss_4': 0.2987178564071655, 'epoch': 15.78}
{'loss': 0.0131, 'grad_norm': 5.7155351638793945, 'learning_rate': 1.4232558139534885e-05, 'loss_1': 0.007513398304581642, 'loss_2': 0.00554656982421875, 'loss_3': -16.749794006347656, 'loss_4': 0.4164066016674042, 'epoch': 15.79}
{'loss': 0.0336, 'grad_norm': 12.948657035827637, 'learning_rate': 1.4226744186046512e-05, 'loss_1': 0.027750752866268158, 'loss_2': 0.005828857421875, 'loss_3': -16.629085540771484, 'loss_4': 0.7150634527206421, 'epoch': 15.8}
{'loss': 0.012, 'grad_norm': 4.9543867111206055, 'learning_rate': 1.4220930232558139e-05, 'loss_1': 0.003558497875928879, 'loss_2': 0.00846099853515625, 'loss_3': -16.595767974853516, 'loss_4': 0.6633228063583374, 'epoch': 15.8}
{'loss': 0.0089, 'grad_norm': 4.811957836151123, 'learning_rate': 1.4215116279069767e-05, 'loss_1': 0.006579768843948841, 'loss_2': 0.0023593902587890625, 'loss_3': -16.304277420043945, 'loss_4': 0.3119488060474396, 'epoch': 15.81}
{'loss': 0.0099, 'grad_norm': 5.382999420166016, 'learning_rate': 1.4209302325581396e-05, 'loss_1': 0.007141897454857826, 'loss_2': 0.002765655517578125, 'loss_3': -16.542247772216797, 'loss_4': 0.24676045775413513, 'epoch': 15.81}
[INFO|trainer.py:4228] 2025-01-21 13:27:32,545 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:32,545 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                       | 2725/5160 [1:07:37<42:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:39,903 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01267852634191513, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.791, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01005794107913971, 'eval_loss_2': 0.002620585262775421, 'eval_loss_3': -18.264225006103516, 'eval_loss_4': 0.2749249339103699, 'epoch': 15.81}
{'loss': 0.0126, 'grad_norm': 4.983087062835693, 'learning_rate': 1.4203488372093025e-05, 'loss_1': 0.009146000258624554, 'loss_2': 0.0034809112548828125, 'loss_3': -16.445173263549805, 'loss_4': 0.17345228791236877, 'epoch': 15.82}
{'loss': 0.0185, 'grad_norm': 6.826885223388672, 'learning_rate': 1.4197674418604652e-05, 'loss_1': 0.014017581939697266, 'loss_2': 0.00445556640625, 'loss_3': -16.388362884521484, 'loss_4': 0.08800520747900009, 'epoch': 15.83}
{'loss': 0.0351, 'grad_norm': 13.276384353637695, 'learning_rate': 1.4191860465116279e-05, 'loss_1': 0.034366123378276825, 'loss_2': 0.0007729530334472656, 'loss_3': -16.473854064941406, 'loss_4': 0.40358322858810425, 'epoch': 15.83}
{'loss': 0.0191, 'grad_norm': 7.618813514709473, 'learning_rate': 1.4186046511627907e-05, 'loss_1': 0.01152143906801939, 'loss_2': 0.0075531005859375, 'loss_3': -16.796539306640625, 'loss_4': 0.17026779055595398, 'epoch': 15.84}
{'loss': 0.0136, 'grad_norm': 5.655580043792725, 'learning_rate': 1.4180232558139534e-05, 'loss_1': 0.00963312853127718, 'loss_2': 0.0039825439453125, 'loss_3': -16.470130920410156, 'loss_4': 0.30447497963905334, 'epoch': 15.84}
[INFO|trainer.py:4228] 2025-01-21 13:27:39,903 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:39,903 >>   Batch size = 64
 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                       | 2730/5160 [1:07:44<42:35,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:27:47,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014036057516932487, 'eval_runtime': 4.0028, 'eval_samples_per_second': 255.822, 'eval_steps_per_second': 3.997, 'eval_loss_1': 0.009418560191988945, 'eval_loss_2': 0.0046174973249435425, 'eval_loss_3': -18.260404586791992, 'eval_loss_4': 0.3711419403553009, 'epoch': 15.84}
{'loss': 0.0288, 'grad_norm': 9.920291900634766, 'learning_rate': 1.4174418604651163e-05, 'loss_1': 0.023701339960098267, 'loss_2': 0.0050506591796875, 'loss_3': -16.65304946899414, 'loss_4': 0.45235657691955566, 'epoch': 15.85}
{'loss': 0.0107, 'grad_norm': 5.410999298095703, 'learning_rate': 1.4168604651162791e-05, 'loss_1': 0.009998846799135208, 'loss_2': 0.00067901611328125, 'loss_3': -16.66781234741211, 'loss_4': 0.41361311078071594, 'epoch': 15.85}
{'loss': 0.0122, 'grad_norm': 6.748252868652344, 'learning_rate': 1.4162790697674418e-05, 'loss_1': 0.009366041980683804, 'loss_2': 0.0028095245361328125, 'loss_3': -16.699413299560547, 'loss_4': 0.38234174251556396, 'epoch': 15.86}
{'loss': 0.0088, 'grad_norm': 4.726587772369385, 'learning_rate': 1.4156976744186047e-05, 'loss_1': 0.008144622668623924, 'loss_2': 0.0006084442138671875, 'loss_3': -16.683475494384766, 'loss_4': 0.7150768041610718, 'epoch': 15.87}
{'loss': 0.0109, 'grad_norm': 4.499354362487793, 'learning_rate': 1.4151162790697674e-05, 'loss_1': 0.006438012700527906, 'loss_2': 0.004451751708984375, 'loss_3': -16.495342254638672, 'loss_4': 0.4453214406967163, 'epoch': 15.87}
[INFO|trainer.py:4228] 2025-01-21 13:27:47,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:47,446 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                       | 2735/5160 [1:07:51<42:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:27:54,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017712321132421494, 'eval_runtime': 3.8107, 'eval_samples_per_second': 268.714, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.010256614536046982, 'eval_loss_2': 0.007455706596374512, 'eval_loss_3': -18.27469253540039, 'eval_loss_4': 0.4334462583065033, 'epoch': 15.87}
{'loss': 0.0635, 'grad_norm': 33.165836334228516, 'learning_rate': 1.4145348837209303e-05, 'loss_1': 0.059274058789014816, 'loss_2': 0.00423431396484375, 'loss_3': -16.487285614013672, 'loss_4': 0.7066504955291748, 'epoch': 15.88}
{'loss': 0.01, 'grad_norm': 6.289407253265381, 'learning_rate': 1.413953488372093e-05, 'loss_1': 0.007320066448301077, 'loss_2': 0.0027065277099609375, 'loss_3': -16.637319564819336, 'loss_4': 0.619986891746521, 'epoch': 15.88}
{'loss': 0.0184, 'grad_norm': 7.167553901672363, 'learning_rate': 1.413372093023256e-05, 'loss_1': 0.013425411656498909, 'loss_2': 0.005008697509765625, 'loss_3': -16.41849708557129, 'loss_4': 0.5998753309249878, 'epoch': 15.89}
{'loss': 0.0232, 'grad_norm': 15.277566909790039, 'learning_rate': 1.4127906976744187e-05, 'loss_1': 0.017542216926813126, 'loss_2': 0.005634307861328125, 'loss_3': -16.626569747924805, 'loss_4': 0.7578246593475342, 'epoch': 15.9}
{'loss': 0.0146, 'grad_norm': 5.120361328125, 'learning_rate': 1.4122093023255814e-05, 'loss_1': 0.008286289870738983, 'loss_2': 0.006275177001953125, 'loss_3': -16.55008316040039, 'loss_4': 0.28773224353790283, 'epoch': 15.9}
[INFO|trainer.py:4228] 2025-01-21 13:27:54,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:27:54,808 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                      | 2740/5160 [1:07:59<41:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:02,163 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01530264038592577, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.836, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010176461189985275, 'eval_loss_2': 0.00512617826461792, 'eval_loss_3': -18.296960830688477, 'eval_loss_4': 0.5653740167617798, 'epoch': 15.9}
{'loss': 0.0119, 'grad_norm': 4.874209403991699, 'learning_rate': 1.4116279069767442e-05, 'loss_1': 0.005715424194931984, 'loss_2': 0.00614166259765625, 'loss_3': -16.503028869628906, 'loss_4': 0.7078949213027954, 'epoch': 15.91}
{'loss': 0.012, 'grad_norm': 5.5278520584106445, 'learning_rate': 1.411046511627907e-05, 'loss_1': 0.011171151883900166, 'loss_2': 0.0008196830749511719, 'loss_3': -16.680068969726562, 'loss_4': 0.5124951004981995, 'epoch': 15.91}
{'loss': 0.012, 'grad_norm': 6.95825719833374, 'learning_rate': 1.4104651162790698e-05, 'loss_1': 0.01119132712483406, 'loss_2': 0.0007839202880859375, 'loss_3': -16.50271224975586, 'loss_4': 0.7727918028831482, 'epoch': 15.92}
{'loss': 0.0147, 'grad_norm': 6.269366264343262, 'learning_rate': 1.4098837209302327e-05, 'loss_1': 0.01289324276149273, 'loss_2': 0.0017976760864257812, 'loss_3': -16.478429794311523, 'loss_4': 0.30399835109710693, 'epoch': 15.92}
{'loss': 0.0073, 'grad_norm': 4.603275775909424, 'learning_rate': 1.4093023255813954e-05, 'loss_1': 0.006779935210943222, 'loss_2': 0.0005340576171875, 'loss_3': -16.71124839782715, 'loss_4': 0.720982551574707, 'epoch': 15.93}
[INFO|trainer.py:4228] 2025-01-21 13:28:02,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:02,163 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                      | 2745/5160 [1:08:06<41:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:09,527 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01344864908605814, 'eval_runtime': 3.8156, 'eval_samples_per_second': 268.372, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.00992121547460556, 'eval_loss_2': 0.003527432680130005, 'eval_loss_3': -18.28423500061035, 'eval_loss_4': 0.6910595297813416, 'epoch': 15.93}
{'loss': 0.0141, 'grad_norm': 6.5251946449279785, 'learning_rate': 1.4087209302325582e-05, 'loss_1': 0.013262428343296051, 'loss_2': 0.000881195068359375, 'loss_3': -16.453269958496094, 'loss_4': 0.564889132976532, 'epoch': 15.94}
{'loss': 0.0109, 'grad_norm': 5.807159900665283, 'learning_rate': 1.4081395348837209e-05, 'loss_1': 0.007959536276757717, 'loss_2': 0.0029201507568359375, 'loss_3': -16.529266357421875, 'loss_4': 1.0724952220916748, 'epoch': 15.94}
{'loss': 0.0109, 'grad_norm': 6.234005928039551, 'learning_rate': 1.4075581395348838e-05, 'loss_1': 0.010489125736057758, 'loss_2': 0.000423431396484375, 'loss_3': -16.58731460571289, 'loss_4': 1.0916378498077393, 'epoch': 15.95}
{'loss': 0.0104, 'grad_norm': 4.7247633934021, 'learning_rate': 1.4069767441860465e-05, 'loss_1': 0.006678737699985504, 'loss_2': 0.0037384033203125, 'loss_3': -16.741025924682617, 'loss_4': 1.198481559753418, 'epoch': 15.95}
{'loss': 0.0096, 'grad_norm': 5.6114115715026855, 'learning_rate': 1.4063953488372093e-05, 'loss_1': 0.008970324881374836, 'loss_2': 0.0006222724914550781, 'loss_3': -16.474655151367188, 'loss_4': 0.6316527128219604, 'epoch': 15.96}
[INFO|trainer.py:4228] 2025-01-21 13:28:09,527 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:09,527 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 2750/5160 [1:08:14<41:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:16,887 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013977299444377422, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.976, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.01037655584514141, 'eval_loss_2': 0.003600742667913437, 'eval_loss_3': -18.283559799194336, 'eval_loss_4': 0.7065057754516602, 'epoch': 15.96}
{'loss': 0.0266, 'grad_norm': 7.8934855461120605, 'learning_rate': 1.4058139534883722e-05, 'loss_1': 0.02302851527929306, 'loss_2': 0.003551483154296875, 'loss_3': -16.427799224853516, 'loss_4': 0.6542155742645264, 'epoch': 15.97}
{'loss': 0.0139, 'grad_norm': 6.144518852233887, 'learning_rate': 1.4052325581395349e-05, 'loss_1': 0.01117962971329689, 'loss_2': 0.002696990966796875, 'loss_3': -16.541067123413086, 'loss_4': 0.8958795070648193, 'epoch': 15.97}
{'loss': 0.0268, 'grad_norm': 6.891726970672607, 'learning_rate': 1.4046511627906978e-05, 'loss_1': 0.01757051981985569, 'loss_2': 0.00927734375, 'loss_3': -16.7144775390625, 'loss_4': 1.222253680229187, 'epoch': 15.98}
{'loss': 0.0071, 'grad_norm': 4.728939056396484, 'learning_rate': 1.4040697674418604e-05, 'loss_1': 0.005716895218938589, 'loss_2': 0.0013599395751953125, 'loss_3': -16.458301544189453, 'loss_4': 0.6257704496383667, 'epoch': 15.98}
{'loss': 0.0114, 'grad_norm': 5.6680402755737305, 'learning_rate': 1.4034883720930231e-05, 'loss_1': 0.00810533668845892, 'loss_2': 0.003253936767578125, 'loss_3': -16.612499237060547, 'loss_4': 0.5316505432128906, 'epoch': 15.99}
[INFO|trainer.py:4228] 2025-01-21 13:28:16,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:16,888 >>   Batch size = 64
 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                      | 2755/5160 [1:08:21<40:27,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:28:23,932 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013758240267634392, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.768, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009911535307765007, 'eval_loss_2': 0.0038467049598693848, 'eval_loss_3': -18.275054931640625, 'eval_loss_4': 0.6495256423950195, 'epoch': 15.99}
{'loss': 0.0171, 'grad_norm': 5.896729469299316, 'learning_rate': 1.4029069767441862e-05, 'loss_1': 0.012157903052866459, 'loss_2': 0.00493621826171875, 'loss_3': -16.563602447509766, 'loss_4': 1.0484191179275513, 'epoch': 15.99}
{'loss': 0.0152, 'grad_norm': 6.659114360809326, 'learning_rate': 1.4023255813953489e-05, 'loss_1': 0.003394140163436532, 'loss_2': 0.01181793212890625, 'loss_3': -16.507442474365234, 'loss_4': 0.5188988447189331, 'epoch': 16.0}
{'loss': 0.0138, 'grad_norm': 5.706420421600342, 'learning_rate': 1.4017441860465117e-05, 'loss_1': 0.012728428468108177, 'loss_2': 0.0011148452758789062, 'loss_3': -16.63626480102539, 'loss_4': 0.46343398094177246, 'epoch': 16.01}
{'loss': 0.0156, 'grad_norm': 6.427445411682129, 'learning_rate': 1.4011627906976744e-05, 'loss_1': 0.013841274194419384, 'loss_2': 0.001728057861328125, 'loss_3': -16.243017196655273, 'loss_4': 0.39444851875305176, 'epoch': 16.01}
{'loss': 0.0107, 'grad_norm': 7.612513542175293, 'learning_rate': 1.4005813953488371e-05, 'loss_1': 0.010582860559225082, 'loss_2': 7.337331771850586e-05, 'loss_3': -16.699262619018555, 'loss_4': 0.4254390597343445, 'epoch': 16.02}
[INFO|trainer.py:4228] 2025-01-21 13:28:23,932 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:23,933 >>   Batch size = 64
 53%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                     | 2760/5160 [1:08:28<41:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:28:31,286 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012461058795452118, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.878, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00886595994234085, 'eval_loss_2': 0.003595098853111267, 'eval_loss_3': -18.29836082458496, 'eval_loss_4': 0.5164496302604675, 'epoch': 16.02}
{'loss': 0.0358, 'grad_norm': 14.85771656036377, 'learning_rate': 1.4e-05, 'loss_1': 0.02961924485862255, 'loss_2': 0.006134033203125, 'loss_3': -16.687705993652344, 'loss_4': 1.4269248247146606, 'epoch': 16.02}
{'loss': 0.0155, 'grad_norm': 9.332855224609375, 'learning_rate': 1.3994186046511628e-05, 'loss_1': 0.012609659694135189, 'loss_2': 0.0029144287109375, 'loss_3': -16.431453704833984, 'loss_4': 0.5042015314102173, 'epoch': 16.03}
{'loss': 0.019, 'grad_norm': 5.418469429016113, 'learning_rate': 1.3988372093023257e-05, 'loss_1': 0.01055773627012968, 'loss_2': 0.008392333984375, 'loss_3': -16.32996368408203, 'loss_4': 0.5636796951293945, 'epoch': 16.03}
{'loss': 0.0385, 'grad_norm': 16.224109649658203, 'learning_rate': 1.3982558139534884e-05, 'loss_1': 0.035951606929302216, 'loss_2': 0.002552032470703125, 'loss_3': -16.45294189453125, 'loss_4': 0.7852031588554382, 'epoch': 16.04}
{'loss': 0.0767, 'grad_norm': 27.877037048339844, 'learning_rate': 1.3976744186046511e-05, 'loss_1': 0.07633776217699051, 'loss_2': 0.0003952980041503906, 'loss_3': -16.745323181152344, 'loss_4': 1.1491672992706299, 'epoch': 16.05}
[INFO|trainer.py:4228] 2025-01-21 13:28:31,286 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:31,286 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                     | 2765/5160 [1:08:35<41:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:38,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011843817308545113, 'eval_runtime': 3.8115, 'eval_samples_per_second': 268.663, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00888664461672306, 'eval_loss_2': 0.002957172691822052, 'eval_loss_3': -18.29253578186035, 'eval_loss_4': 0.4286566972732544, 'epoch': 16.05}
{'loss': 0.0273, 'grad_norm': 19.652006149291992, 'learning_rate': 1.397093023255814e-05, 'loss_1': 0.024607185274362564, 'loss_2': 0.002681732177734375, 'loss_3': -16.555070877075195, 'loss_4': 0.9403194189071655, 'epoch': 16.05}
{'loss': 0.0067, 'grad_norm': 5.185577392578125, 'learning_rate': 1.3965116279069767e-05, 'loss_1': 0.006475651636719704, 'loss_2': 0.00021064281463623047, 'loss_3': -16.483903884887695, 'loss_4': 0.5544739961624146, 'epoch': 16.06}
{'loss': 0.0126, 'grad_norm': 4.723396301269531, 'learning_rate': 1.3959302325581397e-05, 'loss_1': 0.00876759085804224, 'loss_2': 0.00386810302734375, 'loss_3': -16.591978073120117, 'loss_4': 0.5848507881164551, 'epoch': 16.06}
{'loss': 0.0104, 'grad_norm': 5.084778308868408, 'learning_rate': 1.3953488372093024e-05, 'loss_1': 0.006034217309206724, 'loss_2': 0.00440216064453125, 'loss_3': -16.63190460205078, 'loss_4': 0.26401227712631226, 'epoch': 16.07}
{'loss': 0.0236, 'grad_norm': 12.290178298950195, 'learning_rate': 1.3947674418604652e-05, 'loss_1': 0.014513315632939339, 'loss_2': 0.00913238525390625, 'loss_3': -16.63787078857422, 'loss_4': 1.099890947341919, 'epoch': 16.08}
[INFO|trainer.py:4228] 2025-01-21 13:28:38,651 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:38,651 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 2770/5160 [1:08:43<41:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:46,018 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011348092928528786, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.633, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007969641126692295, 'eval_loss_2': 0.003378450870513916, 'eval_loss_3': -18.301128387451172, 'eval_loss_4': 0.4734620451927185, 'epoch': 16.08}
{'loss': 0.0111, 'grad_norm': 5.309886932373047, 'learning_rate': 1.394186046511628e-05, 'loss_1': 0.007687784731388092, 'loss_2': 0.0033664703369140625, 'loss_3': -16.496854782104492, 'loss_4': 0.826063871383667, 'epoch': 16.08}
{'loss': 0.0095, 'grad_norm': 4.989896297454834, 'learning_rate': 1.3936046511627906e-05, 'loss_1': 0.008667049929499626, 'loss_2': 0.0008063316345214844, 'loss_3': -16.554264068603516, 'loss_4': 0.882807731628418, 'epoch': 16.09}
{'loss': 0.0174, 'grad_norm': 4.3520073890686035, 'learning_rate': 1.3930232558139535e-05, 'loss_1': 0.004987136926501989, 'loss_2': 0.01236724853515625, 'loss_3': -16.531360626220703, 'loss_4': 0.9860900044441223, 'epoch': 16.09}
{'loss': 0.0279, 'grad_norm': 13.467464447021484, 'learning_rate': 1.3924418604651164e-05, 'loss_1': 0.026142746210098267, 'loss_2': 0.001781463623046875, 'loss_3': -16.527606964111328, 'loss_4': 0.8523062467575073, 'epoch': 16.1}
{'loss': 0.0099, 'grad_norm': 4.983947277069092, 'learning_rate': 1.3918604651162792e-05, 'loss_1': 0.009293985553085804, 'loss_2': 0.000568389892578125, 'loss_3': -16.54489517211914, 'loss_4': 0.36905497312545776, 'epoch': 16.1}
[INFO|trainer.py:4228] 2025-01-21 13:28:46,018 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:46,018 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                     | 2775/5160 [1:08:50<41:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:28:53,377 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011593694798648357, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.242, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.008545663207769394, 'eval_loss_2': 0.003048032522201538, 'eval_loss_3': -18.30286407470703, 'eval_loss_4': 0.6126647591590881, 'epoch': 16.1}
{'loss': 0.0064, 'grad_norm': 4.9902801513671875, 'learning_rate': 1.3912790697674419e-05, 'loss_1': 0.006244756747037172, 'loss_2': 0.0001678466796875, 'loss_3': -16.59214973449707, 'loss_4': 0.3343995213508606, 'epoch': 16.11}
{'loss': 0.0166, 'grad_norm': 5.933137893676758, 'learning_rate': 1.3906976744186046e-05, 'loss_1': 0.010962321422994137, 'loss_2': 0.005615234375, 'loss_3': -16.54730987548828, 'loss_4': 1.0669140815734863, 'epoch': 16.12}
{'loss': 0.0034, 'grad_norm': 4.7715373039245605, 'learning_rate': 1.3901162790697675e-05, 'loss_1': 0.0033484993036836386, 'loss_2': 6.198883056640625e-05, 'loss_3': -16.69852066040039, 'loss_4': 1.100189447402954, 'epoch': 16.12}
{'loss': 0.0109, 'grad_norm': 5.875950336456299, 'learning_rate': 1.3895348837209302e-05, 'loss_1': 0.009408080950379372, 'loss_2': 0.0014495849609375, 'loss_3': -16.545734405517578, 'loss_4': 0.1933242380619049, 'epoch': 16.13}
{'loss': 0.0105, 'grad_norm': 6.302862644195557, 'learning_rate': 1.3889534883720932e-05, 'loss_1': 0.008837769739329815, 'loss_2': 0.0016613006591796875, 'loss_3': -16.450428009033203, 'loss_4': 0.3302006125450134, 'epoch': 16.13}
[INFO|trainer.py:4228] 2025-01-21 13:28:53,378 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:28:53,378 >>   Batch size = 64
 54%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                     | 2780/5160 [1:08:57<41:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:00,738 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010883284732699394, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.77, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007439849432557821, 'eval_loss_2': 0.0034434348344802856, 'eval_loss_3': -18.275718688964844, 'eval_loss_4': 0.7203565239906311, 'epoch': 16.13}
{'loss': 0.0131, 'grad_norm': 5.189072608947754, 'learning_rate': 1.3883720930232559e-05, 'loss_1': 0.006550891790539026, 'loss_2': 0.0065460205078125, 'loss_3': -16.584653854370117, 'loss_4': 0.4513077735900879, 'epoch': 16.14}
{'loss': 0.0057, 'grad_norm': 5.457817077636719, 'learning_rate': 1.3877906976744186e-05, 'loss_1': 0.00523890508338809, 'loss_2': 0.0005025863647460938, 'loss_3': -16.50457191467285, 'loss_4': 0.46277159452438354, 'epoch': 16.15}
{'loss': 0.017, 'grad_norm': 6.109267234802246, 'learning_rate': 1.3872093023255814e-05, 'loss_1': 0.00981385912746191, 'loss_2': 0.007171630859375, 'loss_3': -16.690128326416016, 'loss_4': 0.8627088069915771, 'epoch': 16.15}
{'loss': 0.0162, 'grad_norm': 5.416237831115723, 'learning_rate': 1.3866279069767441e-05, 'loss_1': 0.011278356425464153, 'loss_2': 0.004924774169921875, 'loss_3': -16.535594940185547, 'loss_4': 1.052040457725525, 'epoch': 16.16}
{'loss': 0.0134, 'grad_norm': 9.456281661987305, 'learning_rate': 1.386046511627907e-05, 'loss_1': 0.011661744676530361, 'loss_2': 0.0017538070678710938, 'loss_3': -16.594833374023438, 'loss_4': 1.3553581237792969, 'epoch': 16.16}
[INFO|trainer.py:4228] 2025-01-21 13:29:00,738 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:00,738 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                    | 2785/5160 [1:09:05<41:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:08,096 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01206764206290245, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.669, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00903554167598486, 'eval_loss_2': 0.0030320994555950165, 'eval_loss_3': -18.261930465698242, 'eval_loss_4': 0.6823863983154297, 'epoch': 16.16}
{'loss': 0.01, 'grad_norm': 4.8633503913879395, 'learning_rate': 1.3854651162790699e-05, 'loss_1': 0.0050968267023563385, 'loss_2': 0.00494384765625, 'loss_3': -16.698434829711914, 'loss_4': 0.9004177451133728, 'epoch': 16.17}
{'loss': 0.0145, 'grad_norm': 8.599285125732422, 'learning_rate': 1.3848837209302326e-05, 'loss_1': 0.014399594627320766, 'loss_2': 0.00013136863708496094, 'loss_3': -16.535202026367188, 'loss_4': 0.6474366784095764, 'epoch': 16.17}
{'loss': 0.0191, 'grad_norm': 8.99991512298584, 'learning_rate': 1.3843023255813954e-05, 'loss_1': 0.016828348860144615, 'loss_2': 0.0022602081298828125, 'loss_3': -16.344623565673828, 'loss_4': 0.6685880422592163, 'epoch': 16.18}
{'loss': 0.0119, 'grad_norm': 5.909536361694336, 'learning_rate': 1.3837209302325581e-05, 'loss_1': 0.007805985864251852, 'loss_2': 0.00408935546875, 'loss_3': -16.442777633666992, 'loss_4': 0.19307225942611694, 'epoch': 16.19}
{'loss': 0.0114, 'grad_norm': 4.798717498779297, 'learning_rate': 1.383139534883721e-05, 'loss_1': 0.0054596480913460255, 'loss_2': 0.0059814453125, 'loss_3': -16.54534149169922, 'loss_4': 0.6229385733604431, 'epoch': 16.19}
[INFO|trainer.py:4228] 2025-01-21 13:29:08,096 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:08,096 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 2790/5160 [1:09:12<41:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:15,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013188733719289303, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.98, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009653061628341675, 'eval_loss_2': 0.0035356730222702026, 'eval_loss_3': -18.247053146362305, 'eval_loss_4': 0.5768844485282898, 'epoch': 16.19}
{'loss': 0.0199, 'grad_norm': 7.024197101593018, 'learning_rate': 1.3825581395348837e-05, 'loss_1': 0.014219743199646473, 'loss_2': 0.005672454833984375, 'loss_3': -16.441984176635742, 'loss_4': 0.6625442504882812, 'epoch': 16.2}
{'loss': 0.0127, 'grad_norm': 4.531227111816406, 'learning_rate': 1.3819767441860465e-05, 'loss_1': 0.004860919434577227, 'loss_2': 0.00780487060546875, 'loss_3': -16.519878387451172, 'loss_4': 0.5846102237701416, 'epoch': 16.2}
{'loss': 0.0271, 'grad_norm': 19.644107818603516, 'learning_rate': 1.3813953488372094e-05, 'loss_1': 0.022974515333771706, 'loss_2': 0.0041046142578125, 'loss_3': -16.35106658935547, 'loss_4': 0.41368138790130615, 'epoch': 16.21}
{'loss': 0.0189, 'grad_norm': 5.009912490844727, 'learning_rate': 1.3808139534883721e-05, 'loss_1': 0.0074371639639139175, 'loss_2': 0.0114898681640625, 'loss_3': -16.614959716796875, 'loss_4': -0.05116449296474457, 'epoch': 16.22}
{'loss': 0.0164, 'grad_norm': 10.260958671569824, 'learning_rate': 1.380232558139535e-05, 'loss_1': 0.0115233538672328, 'loss_2': 0.004913330078125, 'loss_3': -16.402721405029297, 'loss_4': 0.3694424033164978, 'epoch': 16.22}
[INFO|trainer.py:4228] 2025-01-21 13:29:15,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:15,453 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 2795/5160 [1:09:19<40:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:22,821 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01411339920014143, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.435, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01103493757545948, 'eval_loss_2': 0.003078460693359375, 'eval_loss_3': -18.242515563964844, 'eval_loss_4': 0.4108368754386902, 'epoch': 16.22}
{'loss': 0.0121, 'grad_norm': 5.289830207824707, 'learning_rate': 1.3796511627906977e-05, 'loss_1': 0.008839016780257225, 'loss_2': 0.0032520294189453125, 'loss_3': -16.499176025390625, 'loss_4': 0.26382532715797424, 'epoch': 16.23}
{'loss': 0.014, 'grad_norm': 5.529023170471191, 'learning_rate': 1.3790697674418603e-05, 'loss_1': 0.007201173342764378, 'loss_2': 0.006824493408203125, 'loss_3': -16.394927978515625, 'loss_4': 0.5082010626792908, 'epoch': 16.23}
{'loss': 0.0065, 'grad_norm': 4.877132415771484, 'learning_rate': 1.3784883720930234e-05, 'loss_1': 0.004843594040721655, 'loss_2': 0.001705169677734375, 'loss_3': -16.675464630126953, 'loss_4': 0.2798236310482025, 'epoch': 16.24}
{'loss': 0.0085, 'grad_norm': 6.286531925201416, 'learning_rate': 1.377906976744186e-05, 'loss_1': 0.0073966835625469685, 'loss_2': 0.0011425018310546875, 'loss_3': -16.399330139160156, 'loss_4': 0.7857852578163147, 'epoch': 16.24}
{'loss': 0.0081, 'grad_norm': 4.538866996765137, 'learning_rate': 1.377325581395349e-05, 'loss_1': 0.00568151893094182, 'loss_2': 0.0024261474609375, 'loss_3': -16.4461612701416, 'loss_4': 0.2746424376964569, 'epoch': 16.25}
[INFO|trainer.py:4228] 2025-01-21 13:29:22,821 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:22,821 >>   Batch size = 64
 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                    | 2800/5160 [1:09:27<40:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:30,182 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015659604221582413, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.313, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.011691546067595482, 'eval_loss_2': 0.00396806001663208, 'eval_loss_3': -18.237455368041992, 'eval_loss_4': 0.1442776620388031, 'epoch': 16.25}
{'loss': 0.0068, 'grad_norm': 5.540496826171875, 'learning_rate': 1.3767441860465116e-05, 'loss_1': 0.004880187101662159, 'loss_2': 0.0019483566284179688, 'loss_3': -16.447879791259766, 'loss_4': 0.3365369439125061, 'epoch': 16.26}
{'loss': 0.0317, 'grad_norm': 14.27435302734375, 'learning_rate': 1.3761627906976745e-05, 'loss_1': 0.02575133554637432, 'loss_2': 0.00592041015625, 'loss_3': -16.51986312866211, 'loss_4': -0.562546968460083, 'epoch': 16.26}
{'loss': 0.0163, 'grad_norm': 8.716129302978516, 'learning_rate': 1.3755813953488372e-05, 'loss_1': 0.014410894364118576, 'loss_2': 0.0019311904907226562, 'loss_3': -16.413509368896484, 'loss_4': 0.08076310157775879, 'epoch': 16.27}
{'loss': 0.0104, 'grad_norm': 4.6611833572387695, 'learning_rate': 1.375e-05, 'loss_1': 0.004373371601104736, 'loss_2': 0.00601959228515625, 'loss_3': -16.39752960205078, 'loss_4': -0.6338679194450378, 'epoch': 16.27}
{'loss': 0.0089, 'grad_norm': 4.510852336883545, 'learning_rate': 1.3744186046511629e-05, 'loss_1': 0.0034484167117625475, 'loss_2': 0.0054168701171875, 'loss_3': -16.550193786621094, 'loss_4': -0.37243837118148804, 'epoch': 16.28}
[INFO|trainer.py:4228] 2025-01-21 13:29:30,182 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:30,182 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                    | 2805/5160 [1:09:34<40:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:37,536 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015449434518814087, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.954, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012293609790503979, 'eval_loss_2': 0.003155827522277832, 'eval_loss_3': -18.195913314819336, 'eval_loss_4': -0.19686728715896606, 'epoch': 16.28}
{'loss': 0.0104, 'grad_norm': 5.102289199829102, 'learning_rate': 1.3738372093023256e-05, 'loss_1': 0.00594683364033699, 'loss_2': 0.0044097900390625, 'loss_3': -16.622446060180664, 'loss_4': 0.19348439574241638, 'epoch': 16.28}
{'loss': 0.0206, 'grad_norm': 6.358413219451904, 'learning_rate': 1.3732558139534885e-05, 'loss_1': 0.011776737868785858, 'loss_2': 0.0087738037109375, 'loss_3': -16.607952117919922, 'loss_4': -0.14786291122436523, 'epoch': 16.29}
{'loss': 0.0108, 'grad_norm': 6.549539566040039, 'learning_rate': 1.3726744186046512e-05, 'loss_1': 0.007049974519759417, 'loss_2': 0.0037994384765625, 'loss_3': -16.514644622802734, 'loss_4': -0.31632083654403687, 'epoch': 16.3}
{'loss': 0.0061, 'grad_norm': 4.771419048309326, 'learning_rate': 1.3720930232558139e-05, 'loss_1': 0.004814725834876299, 'loss_2': 0.0012683868408203125, 'loss_3': -16.441864013671875, 'loss_4': -0.34349578619003296, 'epoch': 16.3}
{'loss': 0.0096, 'grad_norm': 5.51936149597168, 'learning_rate': 1.3715116279069769e-05, 'loss_1': 0.008325370028614998, 'loss_2': 0.0013027191162109375, 'loss_3': -16.598628997802734, 'loss_4': -0.430800199508667, 'epoch': 16.31}
[INFO|trainer.py:4228] 2025-01-21 13:29:37,536 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:37,536 >>   Batch size = 64
 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                   | 2810/5160 [1:09:42<40:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:44,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013969585299491882, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.079, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011449658311903477, 'eval_loss_2': 0.0025199279189109802, 'eval_loss_3': -18.19601058959961, 'eval_loss_4': -0.33284297585487366, 'epoch': 16.31}
{'loss': 0.0175, 'grad_norm': 8.456672668457031, 'learning_rate': 1.3709302325581396e-05, 'loss_1': 0.014302670024335384, 'loss_2': 0.00322723388671875, 'loss_3': -16.499052047729492, 'loss_4': -0.33323365449905396, 'epoch': 16.31}
{'loss': 0.0132, 'grad_norm': 5.775940895080566, 'learning_rate': 1.3703488372093024e-05, 'loss_1': 0.010510125197470188, 'loss_2': 0.00267791748046875, 'loss_3': -16.5394287109375, 'loss_4': -0.43982136249542236, 'epoch': 16.32}
{'loss': 0.0185, 'grad_norm': 5.12012243270874, 'learning_rate': 1.3697674418604651e-05, 'loss_1': 0.007434926927089691, 'loss_2': 0.0110626220703125, 'loss_3': -16.535478591918945, 'loss_4': -0.0641162246465683, 'epoch': 16.33}
{'loss': 0.0176, 'grad_norm': 7.6273627281188965, 'learning_rate': 1.3691860465116278e-05, 'loss_1': 0.015233932062983513, 'loss_2': 0.0023708343505859375, 'loss_3': -16.443378448486328, 'loss_4': -0.9896417260169983, 'epoch': 16.33}
{'loss': 0.0397, 'grad_norm': 12.618634223937988, 'learning_rate': 1.3686046511627907e-05, 'loss_1': 0.03447892516851425, 'loss_2': 0.00524139404296875, 'loss_3': -16.457517623901367, 'loss_4': -0.7016159296035767, 'epoch': 16.34}
[INFO|trainer.py:4228] 2025-01-21 13:29:44,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:44,888 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                   | 2815/5160 [1:09:49<40:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:52,246 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014130196534097195, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.894, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011174298822879791, 'eval_loss_2': 0.002955898642539978, 'eval_loss_3': -18.209938049316406, 'eval_loss_4': -0.3490932881832123, 'epoch': 16.34}
{'loss': 0.0154, 'grad_norm': 5.607179164886475, 'learning_rate': 1.3680232558139536e-05, 'loss_1': 0.008184212259948254, 'loss_2': 0.0071868896484375, 'loss_3': -16.433130264282227, 'loss_4': -0.754746675491333, 'epoch': 16.34}
{'loss': 0.0131, 'grad_norm': 10.079119682312012, 'learning_rate': 1.3674418604651164e-05, 'loss_1': 0.012318190187215805, 'loss_2': 0.0008144378662109375, 'loss_3': -16.373592376708984, 'loss_4': -0.636975884437561, 'epoch': 16.35}
{'loss': 0.0536, 'grad_norm': 19.470531463623047, 'learning_rate': 1.3668604651162791e-05, 'loss_1': 0.05168568342924118, 'loss_2': 0.001934051513671875, 'loss_3': -16.46724510192871, 'loss_4': -0.37654727697372437, 'epoch': 16.35}
{'loss': 0.0225, 'grad_norm': 9.73039722442627, 'learning_rate': 1.3662790697674418e-05, 'loss_1': 0.01919707842171192, 'loss_2': 0.003337860107421875, 'loss_3': -16.5098876953125, 'loss_4': -0.30753129720687866, 'epoch': 16.36}
{'loss': 0.0134, 'grad_norm': 5.314488887786865, 'learning_rate': 1.3656976744186047e-05, 'loss_1': 0.009623867459595203, 'loss_2': 0.003810882568359375, 'loss_3': -16.4652156829834, 'loss_4': -0.3405950665473938, 'epoch': 16.37}
[INFO|trainer.py:4228] 2025-01-21 13:29:52,246 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:52,246 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                   | 2820/5160 [1:09:56<40:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:29:59,604 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014725465327501297, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.742, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.011466780677437782, 'eval_loss_2': 0.0032586827874183655, 'eval_loss_3': -18.20881462097168, 'eval_loss_4': -0.34856098890304565, 'epoch': 16.37}
{'loss': 0.0124, 'grad_norm': 6.991250038146973, 'learning_rate': 1.3651162790697674e-05, 'loss_1': 0.010942068882286549, 'loss_2': 0.0014553070068359375, 'loss_3': -16.444690704345703, 'loss_4': -0.5224306583404541, 'epoch': 16.37}
{'loss': 0.0091, 'grad_norm': 5.104065418243408, 'learning_rate': 1.3645348837209304e-05, 'loss_1': 0.008253355510532856, 'loss_2': 0.0008883476257324219, 'loss_3': -16.561843872070312, 'loss_4': -0.7312371730804443, 'epoch': 16.38}
{'loss': 0.0112, 'grad_norm': 5.7945146560668945, 'learning_rate': 1.3639534883720931e-05, 'loss_1': 0.00927084032446146, 'loss_2': 0.00196075439453125, 'loss_3': -16.60451316833496, 'loss_4': -0.4064294695854187, 'epoch': 16.38}
{'loss': 0.039, 'grad_norm': 16.37348175048828, 'learning_rate': 1.3633720930232558e-05, 'loss_1': 0.03514961525797844, 'loss_2': 0.003875732421875, 'loss_3': -16.453598022460938, 'loss_4': -0.7700303196907043, 'epoch': 16.39}
{'loss': 0.0215, 'grad_norm': 11.518003463745117, 'learning_rate': 1.3627906976744187e-05, 'loss_1': 0.018872519955039024, 'loss_2': 0.002635955810546875, 'loss_3': -16.4188232421875, 'loss_4': -0.06113030016422272, 'epoch': 16.4}
[INFO|trainer.py:4228] 2025-01-21 13:29:59,605 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:29:59,605 >>   Batch size = 64
 55%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 2825/5160 [1:10:04<40:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:06,967 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017676059156656265, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.418, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011256711557507515, 'eval_loss_2': 0.006419345736503601, 'eval_loss_3': -18.18756103515625, 'eval_loss_4': -0.2592601776123047, 'epoch': 16.4}
{'loss': 0.0144, 'grad_norm': 10.026870727539062, 'learning_rate': 1.3622093023255813e-05, 'loss_1': 0.013935910537838936, 'loss_2': 0.0004825592041015625, 'loss_3': -16.394832611083984, 'loss_4': -0.403317391872406, 'epoch': 16.4}
{'loss': 0.0089, 'grad_norm': 5.654507637023926, 'learning_rate': 1.3616279069767442e-05, 'loss_1': 0.006183722522109747, 'loss_2': 0.0027313232421875, 'loss_3': -16.307401657104492, 'loss_4': -0.3287498354911804, 'epoch': 16.41}
{'loss': 0.0068, 'grad_norm': 4.80850887298584, 'learning_rate': 1.361046511627907e-05, 'loss_1': 0.003916403744369745, 'loss_2': 0.002849578857421875, 'loss_3': -16.49471664428711, 'loss_4': -0.5107676982879639, 'epoch': 16.41}
{'loss': 0.0169, 'grad_norm': 8.103041648864746, 'learning_rate': 1.3604651162790698e-05, 'loss_1': 0.008428085595369339, 'loss_2': 0.008453369140625, 'loss_3': -16.444072723388672, 'loss_4': -0.08941046893596649, 'epoch': 16.42}
{'loss': 0.0284, 'grad_norm': 9.63464069366455, 'learning_rate': 1.3598837209302326e-05, 'loss_1': 0.014085196889936924, 'loss_2': 0.01433563232421875, 'loss_3': -16.25687599182129, 'loss_4': -0.21361078321933746, 'epoch': 16.42}
[INFO|trainer.py:4228] 2025-01-21 13:30:06,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:06,968 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                   | 2830/5160 [1:10:11<40:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:14,322 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019859375432133675, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.414, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01016253512352705, 'eval_loss_2': 0.0096968412399292, 'eval_loss_3': -18.193750381469727, 'eval_loss_4': -0.23358097672462463, 'epoch': 16.42}
{'loss': 0.0184, 'grad_norm': 8.30354118347168, 'learning_rate': 1.3593023255813953e-05, 'loss_1': 0.008336258120834827, 'loss_2': 0.01006317138671875, 'loss_3': -16.43095588684082, 'loss_4': -0.25391340255737305, 'epoch': 16.43}
{'loss': 0.0087, 'grad_norm': 4.4136152267456055, 'learning_rate': 1.3587209302325582e-05, 'loss_1': 0.004328876733779907, 'loss_2': 0.00437164306640625, 'loss_3': -16.445903778076172, 'loss_4': -0.16817118227481842, 'epoch': 16.44}
{'loss': 0.014, 'grad_norm': 5.524428844451904, 'learning_rate': 1.3581395348837209e-05, 'loss_1': 0.005290933884680271, 'loss_2': 0.0087127685546875, 'loss_3': -16.45037078857422, 'loss_4': -0.25421249866485596, 'epoch': 16.44}
{'loss': 0.0099, 'grad_norm': 5.121391773223877, 'learning_rate': 1.3575581395348839e-05, 'loss_1': 0.006506582722067833, 'loss_2': 0.003345489501953125, 'loss_3': -16.37211799621582, 'loss_4': -0.14102086424827576, 'epoch': 16.45}
{'loss': 0.0199, 'grad_norm': 20.50993537902832, 'learning_rate': 1.3569767441860466e-05, 'loss_1': 0.01987231709063053, 'loss_2': 5.245208740234375e-05, 'loss_3': -16.33681869506836, 'loss_4': -0.40401187539100647, 'epoch': 16.45}
[INFO|trainer.py:4228] 2025-01-21 13:30:14,323 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:14,323 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                  | 2835/5160 [1:10:18<40:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:21,671 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016436323523521423, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009749213233590126, 'eval_loss_2': 0.0066871121525764465, 'eval_loss_3': -18.195117950439453, 'eval_loss_4': -0.15540046989917755, 'epoch': 16.45}
{'loss': 0.0071, 'grad_norm': 5.004108905792236, 'learning_rate': 1.3563953488372093e-05, 'loss_1': 0.005816303193569183, 'loss_2': 0.0012559890747070312, 'loss_3': -16.52191734313965, 'loss_4': -0.224591925740242, 'epoch': 16.46}
{'loss': 0.0145, 'grad_norm': 9.02075481414795, 'learning_rate': 1.3558139534883722e-05, 'loss_1': 0.01219471637159586, 'loss_2': 0.002346038818359375, 'loss_3': -16.317806243896484, 'loss_4': -0.1305391788482666, 'epoch': 16.47}
{'loss': 0.0104, 'grad_norm': 4.8000664710998535, 'learning_rate': 1.3552325581395349e-05, 'loss_1': 0.003410797566175461, 'loss_2': 0.00699615478515625, 'loss_3': -16.537242889404297, 'loss_4': -0.12976357340812683, 'epoch': 16.47}
{'loss': 0.0152, 'grad_norm': 6.24545955657959, 'learning_rate': 1.3546511627906977e-05, 'loss_1': 0.008450024761259556, 'loss_2': 0.006744384765625, 'loss_3': -16.353057861328125, 'loss_4': -0.2308257520198822, 'epoch': 16.48}
{'loss': 0.0107, 'grad_norm': 8.874661445617676, 'learning_rate': 1.3540697674418606e-05, 'loss_1': 0.008852280676364899, 'loss_2': 0.0018110275268554688, 'loss_3': -16.452625274658203, 'loss_4': -0.2536911070346832, 'epoch': 16.48}
[INFO|trainer.py:4228] 2025-01-21 13:30:21,672 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:21,672 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 2840/5160 [1:10:26<40:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:29,029 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01255546323955059, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.655, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00894288718700409, 'eval_loss_2': 0.0036125779151916504, 'eval_loss_3': -18.227087020874023, 'eval_loss_4': -0.0743296891450882, 'epoch': 16.48}
{'loss': 0.0124, 'grad_norm': 7.129520893096924, 'learning_rate': 1.3534883720930233e-05, 'loss_1': 0.009702547453343868, 'loss_2': 0.002685546875, 'loss_3': -16.52896499633789, 'loss_4': -0.11501062661409378, 'epoch': 16.49}
{'loss': 0.0085, 'grad_norm': 4.943362712860107, 'learning_rate': 1.3529069767441861e-05, 'loss_1': 0.005069999024271965, 'loss_2': 0.003467559814453125, 'loss_3': -16.47283935546875, 'loss_4': 0.3368915915489197, 'epoch': 16.49}
{'loss': 0.0151, 'grad_norm': 7.406914234161377, 'learning_rate': 1.3523255813953488e-05, 'loss_1': 0.013259140774607658, 'loss_2': 0.00185394287109375, 'loss_3': -16.386619567871094, 'loss_4': -0.1931990534067154, 'epoch': 16.5}
{'loss': 0.0141, 'grad_norm': 4.783650875091553, 'learning_rate': 1.3517441860465117e-05, 'loss_1': 0.0031515881419181824, 'loss_2': 0.010955810546875, 'loss_3': -16.54153060913086, 'loss_4': -0.05420665442943573, 'epoch': 16.51}
{'loss': 0.0088, 'grad_norm': 4.6396870613098145, 'learning_rate': 1.3511627906976744e-05, 'loss_1': 0.004504728596657515, 'loss_2': 0.00424957275390625, 'loss_3': -16.501012802124023, 'loss_4': 0.2923166751861572, 'epoch': 16.51}
[INFO|trainer.py:4228] 2025-01-21 13:30:29,029 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:29,030 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                  | 2845/5160 [1:10:33<40:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:36,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011594654992222786, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.901, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009200887754559517, 'eval_loss_2': 0.002393767237663269, 'eval_loss_3': -18.240785598754883, 'eval_loss_4': 0.06804205477237701, 'epoch': 16.51}
{'loss': 0.008, 'grad_norm': 5.249696254730225, 'learning_rate': 1.3505813953488373e-05, 'loss_1': 0.00695340009406209, 'loss_2': 0.0010404586791992188, 'loss_3': -16.58252716064453, 'loss_4': -0.0872906818985939, 'epoch': 16.52}
{'loss': 0.0191, 'grad_norm': 6.19020414352417, 'learning_rate': 1.3500000000000001e-05, 'loss_1': 0.009679940529167652, 'loss_2': 0.0093841552734375, 'loss_3': -16.380577087402344, 'loss_4': 0.6403435468673706, 'epoch': 16.52}
{'loss': 0.01, 'grad_norm': 5.008854866027832, 'learning_rate': 1.3494186046511628e-05, 'loss_1': 0.004173241090029478, 'loss_2': 0.005863189697265625, 'loss_3': -16.51140594482422, 'loss_4': -0.10707125067710876, 'epoch': 16.53}
{'loss': 0.0056, 'grad_norm': 4.905495643615723, 'learning_rate': 1.3488372093023257e-05, 'loss_1': 0.0055723306722939014, 'loss_2': 6.306171417236328e-05, 'loss_3': -16.576839447021484, 'loss_4': 0.24571728706359863, 'epoch': 16.53}
{'loss': 0.0406, 'grad_norm': 28.329816818237305, 'learning_rate': 1.3482558139534884e-05, 'loss_1': 0.037119023501873016, 'loss_2': 0.003509521484375, 'loss_3': -16.44860076904297, 'loss_4': 0.6937851309776306, 'epoch': 16.54}
[INFO|trainer.py:4228] 2025-01-21 13:30:36,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:36,385 >>   Batch size = 64
 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 2850/5160 [1:10:40<40:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:43,743 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013003646396100521, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.844, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009039578959345818, 'eval_loss_2': 0.003964066505432129, 'eval_loss_3': -18.284629821777344, 'eval_loss_4': 0.2407069206237793, 'epoch': 16.54}
{'loss': 0.0077, 'grad_norm': 4.763193607330322, 'learning_rate': 1.347674418604651e-05, 'loss_1': 0.005923437420278788, 'loss_2': 0.0017843246459960938, 'loss_3': -16.50589370727539, 'loss_4': 0.3184468150138855, 'epoch': 16.55}
{'loss': 0.0089, 'grad_norm': 5.263351917266846, 'learning_rate': 1.3470930232558141e-05, 'loss_1': 0.005340028554201126, 'loss_2': 0.00354766845703125, 'loss_3': -16.395496368408203, 'loss_4': -0.5025593042373657, 'epoch': 16.55}
{'loss': 0.0073, 'grad_norm': 5.120388507843018, 'learning_rate': 1.3465116279069768e-05, 'loss_1': 0.007066913414746523, 'loss_2': 0.0002484321594238281, 'loss_3': -16.40264892578125, 'loss_4': 0.548852264881134, 'epoch': 16.56}
{'loss': 0.0116, 'grad_norm': 4.851836204528809, 'learning_rate': 1.3459302325581397e-05, 'loss_1': 0.004358732141554356, 'loss_2': 0.0072174072265625, 'loss_3': -16.41410255432129, 'loss_4': 0.37827685475349426, 'epoch': 16.56}
{'loss': 0.007, 'grad_norm': 5.140161514282227, 'learning_rate': 1.3453488372093023e-05, 'loss_1': 0.004316950216889381, 'loss_2': 0.002696990966796875, 'loss_3': -16.339040756225586, 'loss_4': 0.6686490774154663, 'epoch': 16.57}
[INFO|trainer.py:4228] 2025-01-21 13:30:43,743 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:43,743 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                 | 2855/5160 [1:10:48<39:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:51,104 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012168444693088531, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.449, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008864334784448147, 'eval_loss_2': 0.00330410897731781, 'eval_loss_3': -18.27995491027832, 'eval_loss_4': 0.29245641827583313, 'epoch': 16.57}
{'loss': 0.0057, 'grad_norm': 5.012871265411377, 'learning_rate': 1.344767441860465e-05, 'loss_1': 0.005011382512748241, 'loss_2': 0.0007381439208984375, 'loss_3': -16.517763137817383, 'loss_4': 0.5446203351020813, 'epoch': 16.58}
{'loss': 0.0089, 'grad_norm': 5.270205497741699, 'learning_rate': 1.3441860465116279e-05, 'loss_1': 0.005479073151946068, 'loss_2': 0.0033893585205078125, 'loss_3': -16.407442092895508, 'loss_4': 0.10283417999744415, 'epoch': 16.58}
{'loss': 0.0191, 'grad_norm': 8.067160606384277, 'learning_rate': 1.3436046511627908e-05, 'loss_1': 0.01686733216047287, 'loss_2': 0.002197265625, 'loss_3': -16.480817794799805, 'loss_4': 0.06314089894294739, 'epoch': 16.59}
{'loss': 0.0047, 'grad_norm': 4.79979944229126, 'learning_rate': 1.3430232558139536e-05, 'loss_1': 0.00433234591037035, 'loss_2': 0.000377655029296875, 'loss_3': -16.516468048095703, 'loss_4': 0.23815232515335083, 'epoch': 16.59}
{'loss': 0.0054, 'grad_norm': 4.6461076736450195, 'learning_rate': 1.3424418604651163e-05, 'loss_1': 0.004635105840861797, 'loss_2': 0.000766754150390625, 'loss_3': -16.647090911865234, 'loss_4': 1.0146684646606445, 'epoch': 16.6}
[INFO|trainer.py:4228] 2025-01-21 13:30:51,104 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:51,104 >>   Batch size = 64
 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 2860/5160 [1:10:55<39:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:30:58,461 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011619392782449722, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008277211338281631, 'eval_loss_2': 0.003342181444168091, 'eval_loss_3': -18.296432495117188, 'eval_loss_4': 0.35273948311805725, 'epoch': 16.6}
{'loss': 0.0161, 'grad_norm': 5.215487480163574, 'learning_rate': 1.341860465116279e-05, 'loss_1': 0.004382625222206116, 'loss_2': 0.0116729736328125, 'loss_3': -16.088224411010742, 'loss_4': 0.45396333932876587, 'epoch': 16.6}
{'loss': 0.0149, 'grad_norm': 6.352804183959961, 'learning_rate': 1.3412790697674419e-05, 'loss_1': 0.006678407080471516, 'loss_2': 0.0082244873046875, 'loss_3': -16.57037925720215, 'loss_4': 0.08151090890169144, 'epoch': 16.61}
{'loss': 0.0165, 'grad_norm': 6.326902866363525, 'learning_rate': 1.3406976744186046e-05, 'loss_1': 0.011802288703620434, 'loss_2': 0.004726409912109375, 'loss_3': -16.563762664794922, 'loss_4': 0.13014331459999084, 'epoch': 16.62}
{'loss': 0.0136, 'grad_norm': 5.507962703704834, 'learning_rate': 1.3401162790697676e-05, 'loss_1': 0.009372205473482609, 'loss_2': 0.004230499267578125, 'loss_3': -16.55954360961914, 'loss_4': 0.5081710815429688, 'epoch': 16.62}
{'loss': 0.0077, 'grad_norm': 4.7041239738464355, 'learning_rate': 1.3395348837209303e-05, 'loss_1': 0.00577253894880414, 'loss_2': 0.0019168853759765625, 'loss_3': -16.403188705444336, 'loss_4': 0.2706020176410675, 'epoch': 16.63}
[INFO|trainer.py:4228] 2025-01-21 13:30:58,461 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:30:58,461 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                 | 2865/5160 [1:11:02<39:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:05,824 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012064885348081589, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.623, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008558642119169235, 'eval_loss_2': 0.0035062432289123535, 'eval_loss_3': -18.288597106933594, 'eval_loss_4': 0.2201131135225296, 'epoch': 16.63}
{'loss': 0.0099, 'grad_norm': 5.421298980712891, 'learning_rate': 1.3389534883720932e-05, 'loss_1': 0.006948612630367279, 'loss_2': 0.002986907958984375, 'loss_3': -16.427385330200195, 'loss_4': -0.27024853229522705, 'epoch': 16.63}
{'loss': 0.0096, 'grad_norm': 5.038636207580566, 'learning_rate': 1.3383720930232559e-05, 'loss_1': 0.006167403422296047, 'loss_2': 0.0034160614013671875, 'loss_3': -16.46381950378418, 'loss_4': 0.3479135036468506, 'epoch': 16.64}
{'loss': 0.0266, 'grad_norm': 19.797107696533203, 'learning_rate': 1.3377906976744186e-05, 'loss_1': 0.025072423741221428, 'loss_2': 0.00152587890625, 'loss_3': -16.58156967163086, 'loss_4': -0.04844997823238373, 'epoch': 16.65}
{'loss': 0.0185, 'grad_norm': 5.431605815887451, 'learning_rate': 1.3372093023255814e-05, 'loss_1': 0.007155200000852346, 'loss_2': 0.011322021484375, 'loss_3': -16.485275268554688, 'loss_4': 0.024668104946613312, 'epoch': 16.65}
{'loss': 0.0075, 'grad_norm': 4.78813362121582, 'learning_rate': 1.3366279069767443e-05, 'loss_1': 0.005482741165906191, 'loss_2': 0.0020313262939453125, 'loss_3': -16.38707160949707, 'loss_4': 0.21368885040283203, 'epoch': 16.66}
[INFO|trainer.py:4228] 2025-01-21 13:31:05,824 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:05,824 >>   Batch size = 64
 56%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                 | 2870/5160 [1:11:10<39:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:13,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011485626921057701, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008494740352034569, 'eval_loss_2': 0.0029908865690231323, 'eval_loss_3': -18.267799377441406, 'eval_loss_4': 0.2230646312236786, 'epoch': 16.66}
{'loss': 0.0094, 'grad_norm': 6.078312873840332, 'learning_rate': 1.3360465116279071e-05, 'loss_1': 0.007779163774102926, 'loss_2': 0.00160980224609375, 'loss_3': -16.50750160217285, 'loss_4': 0.34030354022979736, 'epoch': 16.66}
{'loss': 0.0109, 'grad_norm': 4.854137897491455, 'learning_rate': 1.3354651162790698e-05, 'loss_1': 0.004989021457731724, 'loss_2': 0.0059356689453125, 'loss_3': -16.51817512512207, 'loss_4': -0.030460260808467865, 'epoch': 16.67}
{'loss': 0.0112, 'grad_norm': 7.021551132202148, 'learning_rate': 1.3348837209302325e-05, 'loss_1': 0.008648185059428215, 'loss_2': 0.002513885498046875, 'loss_3': -16.536386489868164, 'loss_4': 0.21493789553642273, 'epoch': 16.67}
{'loss': 0.0134, 'grad_norm': 5.212066650390625, 'learning_rate': 1.3343023255813954e-05, 'loss_1': 0.011469188146293163, 'loss_2': 0.0019092559814453125, 'loss_3': -16.566787719726562, 'loss_4': 0.22005407512187958, 'epoch': 16.68}
{'loss': 0.0121, 'grad_norm': 4.727865695953369, 'learning_rate': 1.3337209302325581e-05, 'loss_1': 0.006436582189053297, 'loss_2': 0.005695343017578125, 'loss_3': -16.515012741088867, 'loss_4': 0.43893513083457947, 'epoch': 16.69}
[INFO|trainer.py:4228] 2025-01-21 13:31:13,187 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:13,187 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                 | 2875/5160 [1:11:17<39:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:20,544 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011136774905025959, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008161019533872604, 'eval_loss_2': 0.00297575443983078, 'eval_loss_3': -18.254758834838867, 'eval_loss_4': 0.1953595131635666, 'epoch': 16.69}
{'loss': 0.0157, 'grad_norm': 4.46896505355835, 'learning_rate': 1.333139534883721e-05, 'loss_1': 0.007505317684262991, 'loss_2': 0.008148193359375, 'loss_3': -16.482341766357422, 'loss_4': 0.4765208065509796, 'epoch': 16.69}
{'loss': 0.0158, 'grad_norm': 5.857580184936523, 'learning_rate': 1.3325581395348838e-05, 'loss_1': 0.011200934648513794, 'loss_2': 0.00463104248046875, 'loss_3': -16.38094711303711, 'loss_4': 0.3440242409706116, 'epoch': 16.7}
{'loss': 0.0077, 'grad_norm': 4.933441162109375, 'learning_rate': 1.3319767441860465e-05, 'loss_1': 0.007462771609425545, 'loss_2': 0.00024509429931640625, 'loss_3': -16.302322387695312, 'loss_4': -0.05102991312742233, 'epoch': 16.7}
{'loss': 0.0126, 'grad_norm': 5.922018051147461, 'learning_rate': 1.3313953488372094e-05, 'loss_1': 0.007840663194656372, 'loss_2': 0.004749298095703125, 'loss_3': -16.335084915161133, 'loss_4': -0.2006186544895172, 'epoch': 16.71}
{'loss': 0.0104, 'grad_norm': 5.088250637054443, 'learning_rate': 1.330813953488372e-05, 'loss_1': 0.006850490812212229, 'loss_2': 0.003509521484375, 'loss_3': -16.758329391479492, 'loss_4': -0.1796056628227234, 'epoch': 16.72}
[INFO|trainer.py:4228] 2025-01-21 13:31:20,544 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:20,544 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                | 2880/5160 [1:11:25<39:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:27,918 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01257738284766674, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.175, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.008196201175451279, 'eval_loss_2': 0.0043811798095703125, 'eval_loss_3': -18.276643753051758, 'eval_loss_4': 0.04031900316476822, 'epoch': 16.72}
{'loss': 0.0066, 'grad_norm': 4.44276237487793, 'learning_rate': 1.330232558139535e-05, 'loss_1': 0.0021109378430992365, 'loss_2': 0.00452423095703125, 'loss_3': -16.631267547607422, 'loss_4': -0.05926071107387543, 'epoch': 16.72}
{'loss': 0.01, 'grad_norm': 5.049239158630371, 'learning_rate': 1.3296511627906976e-05, 'loss_1': 0.005893748719245195, 'loss_2': 0.004150390625, 'loss_3': -16.662281036376953, 'loss_4': 0.14478753507137299, 'epoch': 16.73}
{'loss': 0.008, 'grad_norm': 5.981502532958984, 'learning_rate': 1.3290697674418605e-05, 'loss_1': 0.00784403458237648, 'loss_2': 0.0001575946807861328, 'loss_3': -16.523197174072266, 'loss_4': -0.34532108902931213, 'epoch': 16.73}
{'loss': 0.0084, 'grad_norm': 4.707808494567871, 'learning_rate': 1.3284883720930233e-05, 'loss_1': 0.006506678182631731, 'loss_2': 0.0018711090087890625, 'loss_3': -16.32691764831543, 'loss_4': 0.30821067094802856, 'epoch': 16.74}
{'loss': 0.0102, 'grad_norm': 5.020496845245361, 'learning_rate': 1.327906976744186e-05, 'loss_1': 0.007994523271918297, 'loss_2': 0.002185821533203125, 'loss_3': -16.502117156982422, 'loss_4': -0.5419728755950928, 'epoch': 16.74}
[INFO|trainer.py:4228] 2025-01-21 13:31:27,918 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:27,918 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 2885/5160 [1:11:32<39:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:35,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013929779641330242, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.611, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008242839016020298, 'eval_loss_2': 0.005686938762664795, 'eval_loss_3': -18.280864715576172, 'eval_loss_4': -0.05299060046672821, 'epoch': 16.74}
{'loss': 0.008, 'grad_norm': 4.115353107452393, 'learning_rate': 1.3273255813953489e-05, 'loss_1': 0.003565716091543436, 'loss_2': 0.00445556640625, 'loss_3': -16.55107307434082, 'loss_4': 0.14602027833461761, 'epoch': 16.75}
{'loss': 0.0172, 'grad_norm': 5.397846698760986, 'learning_rate': 1.3267441860465116e-05, 'loss_1': 0.008610484190285206, 'loss_2': 0.008575439453125, 'loss_3': -16.46712875366211, 'loss_4': -0.4194476008415222, 'epoch': 16.76}
{'loss': 0.0132, 'grad_norm': 4.979438304901123, 'learning_rate': 1.3261627906976743e-05, 'loss_1': 0.006079424172639847, 'loss_2': 0.007122039794921875, 'loss_3': -16.532360076904297, 'loss_4': 0.20074054598808289, 'epoch': 16.76}
{'loss': 0.0063, 'grad_norm': 5.515810012817383, 'learning_rate': 1.3255813953488373e-05, 'loss_1': 0.005716913845390081, 'loss_2': 0.0006284713745117188, 'loss_3': -16.63091278076172, 'loss_4': -0.663358211517334, 'epoch': 16.77}
{'loss': 0.005, 'grad_norm': 4.53165864944458, 'learning_rate': 1.325e-05, 'loss_1': 0.0032693641260266304, 'loss_2': 0.00176239013671875, 'loss_3': -16.511682510375977, 'loss_4': 0.24458220601081848, 'epoch': 16.77}
[INFO|trainer.py:4228] 2025-01-21 13:31:35,270 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:35,270 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 2890/5160 [1:11:39<39:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:42,626 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012042393907904625, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008346703834831715, 'eval_loss_2': 0.0036956891417503357, 'eval_loss_3': -18.287059783935547, 'eval_loss_4': -0.21228165924549103, 'epoch': 16.77}
{'loss': 0.0128, 'grad_norm': 5.251089572906494, 'learning_rate': 1.3244186046511629e-05, 'loss_1': 0.008036721497774124, 'loss_2': 0.004802703857421875, 'loss_3': -16.504404067993164, 'loss_4': -0.3948991298675537, 'epoch': 16.78}
{'loss': 0.0068, 'grad_norm': 4.674459934234619, 'learning_rate': 1.3238372093023256e-05, 'loss_1': 0.004842810798436403, 'loss_2': 0.001941680908203125, 'loss_3': -16.65326499938965, 'loss_4': -0.028026096522808075, 'epoch': 16.78}
{'loss': 0.0133, 'grad_norm': 8.1235933303833, 'learning_rate': 1.3232558139534883e-05, 'loss_1': 0.012080494314432144, 'loss_2': 0.0012073516845703125, 'loss_3': -16.54323959350586, 'loss_4': -0.5974708795547485, 'epoch': 16.79}
{'loss': 0.0167, 'grad_norm': 6.955760955810547, 'learning_rate': 1.3226744186046511e-05, 'loss_1': 0.01317342184484005, 'loss_2': 0.00348663330078125, 'loss_3': -16.467636108398438, 'loss_4': -0.7135387063026428, 'epoch': 16.8}
{'loss': 0.0315, 'grad_norm': 12.637713432312012, 'learning_rate': 1.322093023255814e-05, 'loss_1': 0.023961419239640236, 'loss_2': 0.007526397705078125, 'loss_3': -16.470897674560547, 'loss_4': -0.2695962190628052, 'epoch': 16.8}
[INFO|trainer.py:4228] 2025-01-21 13:31:42,626 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:42,626 >>   Batch size = 64
 56%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                | 2895/5160 [1:11:47<39:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:49,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012517084367573261, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.102, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009152820333838463, 'eval_loss_2': 0.003364264965057373, 'eval_loss_3': -18.302431106567383, 'eval_loss_4': -0.41437405347824097, 'epoch': 16.8}
{'loss': 0.0101, 'grad_norm': 4.939743518829346, 'learning_rate': 1.3215116279069769e-05, 'loss_1': 0.008658736944198608, 'loss_2': 0.001445770263671875, 'loss_3': -16.62206268310547, 'loss_4': -0.8530007600784302, 'epoch': 16.81}
{'loss': 0.0107, 'grad_norm': 6.035489559173584, 'learning_rate': 1.3209302325581396e-05, 'loss_1': 0.009508048184216022, 'loss_2': 0.001163482666015625, 'loss_3': -16.74810218811035, 'loss_4': -0.7247791290283203, 'epoch': 16.81}
{'loss': 0.0216, 'grad_norm': 7.500009059906006, 'learning_rate': 1.3203488372093024e-05, 'loss_1': 0.013397892005741596, 'loss_2': 0.008209228515625, 'loss_3': -16.765548706054688, 'loss_4': -0.5589756965637207, 'epoch': 16.82}
{'loss': 0.0065, 'grad_norm': 4.515772342681885, 'learning_rate': 1.3197674418604651e-05, 'loss_1': 0.004026025999337435, 'loss_2': 0.0024261474609375, 'loss_3': -16.57378387451172, 'loss_4': -0.6808007955551147, 'epoch': 16.83}
{'loss': 0.0189, 'grad_norm': 5.77459716796875, 'learning_rate': 1.3191860465116278e-05, 'loss_1': 0.00875880941748619, 'loss_2': 0.010101318359375, 'loss_3': -16.602737426757812, 'loss_4': -0.49311283230781555, 'epoch': 16.83}
[INFO|trainer.py:4228] 2025-01-21 13:31:49,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:49,976 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                | 2900/5160 [1:11:54<39:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:31:57,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011671587824821472, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.964, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00851504597812891, 'eval_loss_2': 0.0031565427780151367, 'eval_loss_3': -18.30890464782715, 'eval_loss_4': -0.545957624912262, 'epoch': 16.83}
{'loss': 0.0066, 'grad_norm': 5.517863750457764, 'learning_rate': 1.3186046511627908e-05, 'loss_1': 0.005624660290777683, 'loss_2': 0.0009450912475585938, 'loss_3': -16.45496368408203, 'loss_4': -0.9151335954666138, 'epoch': 16.84}
{'loss': 0.0188, 'grad_norm': 8.688924789428711, 'learning_rate': 1.3180232558139535e-05, 'loss_1': 0.013448039069771767, 'loss_2': 0.00536346435546875, 'loss_3': -16.49876594543457, 'loss_4': -0.64642333984375, 'epoch': 16.84}
{'loss': 0.0084, 'grad_norm': 4.410372257232666, 'learning_rate': 1.3174418604651164e-05, 'loss_1': 0.003888930194079876, 'loss_2': 0.0045166015625, 'loss_3': -16.56002426147461, 'loss_4': -1.1656830310821533, 'epoch': 16.85}
{'loss': 0.0198, 'grad_norm': 6.219234466552734, 'learning_rate': 1.3168604651162791e-05, 'loss_1': 0.010992108844220638, 'loss_2': 0.00885009765625, 'loss_3': -16.62078285217285, 'loss_4': -1.0923209190368652, 'epoch': 16.85}
{'loss': 0.0207, 'grad_norm': 9.154748916625977, 'learning_rate': 1.3162790697674418e-05, 'loss_1': 0.01156600657850504, 'loss_2': 0.009124755859375, 'loss_3': -16.587764739990234, 'loss_4': -0.16902315616607666, 'epoch': 16.86}
[INFO|trainer.py:4228] 2025-01-21 13:31:57,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:31:57,324 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                               | 2905/5160 [1:12:01<39:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:04,679 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010259466245770454, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.866, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007463427726179361, 'eval_loss_2': 0.0027960389852523804, 'eval_loss_3': -18.31624412536621, 'eval_loss_4': -0.6758293509483337, 'epoch': 16.86}
{'loss': 0.015, 'grad_norm': 5.944269180297852, 'learning_rate': 1.3156976744186046e-05, 'loss_1': 0.013173040933907032, 'loss_2': 0.0018711090087890625, 'loss_3': -16.575260162353516, 'loss_4': -0.617160439491272, 'epoch': 16.87}
{'loss': 0.0163, 'grad_norm': 8.314931869506836, 'learning_rate': 1.3151162790697675e-05, 'loss_1': 0.014222538098692894, 'loss_2': 0.0020809173583984375, 'loss_3': -16.499441146850586, 'loss_4': -0.6380617022514343, 'epoch': 16.87}
{'loss': 0.0222, 'grad_norm': 14.783768653869629, 'learning_rate': 1.3145348837209304e-05, 'loss_1': 0.018742529675364494, 'loss_2': 0.00344085693359375, 'loss_3': -16.735736846923828, 'loss_4': -0.7624002695083618, 'epoch': 16.88}
{'loss': 0.0057, 'grad_norm': 4.90931510925293, 'learning_rate': 1.313953488372093e-05, 'loss_1': 0.005326060578227043, 'loss_2': 0.0004172325134277344, 'loss_3': -16.49302864074707, 'loss_4': -0.7246676683425903, 'epoch': 16.88}
{'loss': 0.0162, 'grad_norm': 5.346859455108643, 'learning_rate': 1.3133720930232558e-05, 'loss_1': 0.007601502817124128, 'loss_2': 0.00855255126953125, 'loss_3': -16.308971405029297, 'loss_4': -0.4737226366996765, 'epoch': 16.89}
[INFO|trainer.py:4228] 2025-01-21 13:32:04,679 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:04,679 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                               | 2910/5160 [1:12:09<38:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:12,039 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010458510369062424, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.534, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007452322170138359, 'eval_loss_2': 0.003006190061569214, 'eval_loss_3': -18.282398223876953, 'eval_loss_4': -0.5606678128242493, 'epoch': 16.89}
{'loss': 0.0076, 'grad_norm': 4.816401958465576, 'learning_rate': 1.3127906976744186e-05, 'loss_1': 0.0045266165398061275, 'loss_2': 0.0030689239501953125, 'loss_3': -16.526660919189453, 'loss_4': -0.6732566356658936, 'epoch': 16.9}
{'loss': 0.0142, 'grad_norm': 5.909330368041992, 'learning_rate': 1.3122093023255813e-05, 'loss_1': 0.009199696592986584, 'loss_2': 0.005016326904296875, 'loss_3': -16.658977508544922, 'loss_4': -0.6335455179214478, 'epoch': 16.9}
{'loss': 0.0082, 'grad_norm': 5.162374496459961, 'learning_rate': 1.3116279069767443e-05, 'loss_1': 0.0074169528670609, 'loss_2': 0.0007419586181640625, 'loss_3': -16.550931930541992, 'loss_4': -0.23136913776397705, 'epoch': 16.91}
{'loss': 0.0062, 'grad_norm': 5.6823272705078125, 'learning_rate': 1.311046511627907e-05, 'loss_1': 0.005588549189269543, 'loss_2': 0.0006175041198730469, 'loss_3': -16.540912628173828, 'loss_4': -0.3184537887573242, 'epoch': 16.91}
{'loss': 0.0135, 'grad_norm': 4.714452743530273, 'learning_rate': 1.3104651162790697e-05, 'loss_1': 0.004786052741110325, 'loss_2': 0.00872039794921875, 'loss_3': -16.400142669677734, 'loss_4': -0.40968137979507446, 'epoch': 16.92}
[INFO|trainer.py:4228] 2025-01-21 13:32:12,039 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:12,039 >>   Batch size = 64
 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                               | 2915/5160 [1:12:16<38:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:19,404 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010648589581251144, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.416, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006941658444702625, 'eval_loss_2': 0.0037069320678710938, 'eval_loss_3': -18.25458526611328, 'eval_loss_4': -0.3311726152896881, 'epoch': 16.92}
{'loss': 0.0127, 'grad_norm': 8.178141593933105, 'learning_rate': 1.3098837209302326e-05, 'loss_1': 0.009795044548809528, 'loss_2': 0.0029315948486328125, 'loss_3': -16.337413787841797, 'loss_4': -0.2923855781555176, 'epoch': 16.92}
{'loss': 0.0122, 'grad_norm': 6.0387282371521, 'learning_rate': 1.3093023255813953e-05, 'loss_1': 0.006534567568451166, 'loss_2': 0.005634307861328125, 'loss_3': -16.403972625732422, 'loss_4': -0.2424325793981552, 'epoch': 16.93}
{'loss': 0.0104, 'grad_norm': 5.866216659545898, 'learning_rate': 1.3087209302325582e-05, 'loss_1': 0.007968107238411903, 'loss_2': 0.00243377685546875, 'loss_3': -16.40186309814453, 'loss_4': 0.2706817388534546, 'epoch': 16.94}
{'loss': 0.0076, 'grad_norm': 4.95081901550293, 'learning_rate': 1.308139534883721e-05, 'loss_1': 0.005529411602765322, 'loss_2': 0.002025604248046875, 'loss_3': -16.559242248535156, 'loss_4': 0.03748396039009094, 'epoch': 16.94}
{'loss': 0.021, 'grad_norm': 7.117696762084961, 'learning_rate': 1.3075581395348837e-05, 'loss_1': 0.013234805315732956, 'loss_2': 0.0077667236328125, 'loss_3': -16.562274932861328, 'loss_4': 0.4502394497394562, 'epoch': 16.95}
[INFO|trainer.py:4228] 2025-01-21 13:32:19,404 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:19,405 >>   Batch size = 64
 57%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 2920/5160 [1:12:23<38:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:26,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011811211705207825, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008193552494049072, 'eval_loss_2': 0.0036176592111587524, 'eval_loss_3': -18.2063045501709, 'eval_loss_4': 0.042812734842300415, 'epoch': 16.95}
{'loss': 0.0058, 'grad_norm': 6.2506422996521, 'learning_rate': 1.3069767441860466e-05, 'loss_1': 0.0051848795264959335, 'loss_2': 0.0006031990051269531, 'loss_3': -16.41533088684082, 'loss_4': -0.08586972951889038, 'epoch': 16.95}
{'loss': 0.0083, 'grad_norm': 5.087759971618652, 'learning_rate': 1.3063953488372093e-05, 'loss_1': 0.006899768952280283, 'loss_2': 0.0014142990112304688, 'loss_3': -16.420867919921875, 'loss_4': 0.1195114329457283, 'epoch': 16.96}
{'loss': 0.0196, 'grad_norm': 7.216433525085449, 'learning_rate': 1.3058139534883721e-05, 'loss_1': 0.014467848464846611, 'loss_2': 0.00510406494140625, 'loss_3': -16.57331085205078, 'loss_4': -0.005637377500534058, 'epoch': 16.97}
{'loss': 0.0338, 'grad_norm': 16.954885482788086, 'learning_rate': 1.3052325581395348e-05, 'loss_1': 0.03231968358159065, 'loss_2': 0.0014514923095703125, 'loss_3': -16.50043487548828, 'loss_4': -0.3165518343448639, 'epoch': 16.97}
{'loss': 0.0222, 'grad_norm': 11.373915672302246, 'learning_rate': 1.3046511627906977e-05, 'loss_1': 0.019458908587694168, 'loss_2': 0.002758026123046875, 'loss_3': -16.580520629882812, 'loss_4': -0.041466422379016876, 'epoch': 16.98}
[INFO|trainer.py:4228] 2025-01-21 13:32:26,753 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:26,753 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                              | 2925/5160 [1:12:30<36:25,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 13:32:33,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011698756366968155, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.753, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009272117167711258, 'eval_loss_2': 0.002426639199256897, 'eval_loss_3': -18.18659210205078, 'eval_loss_4': 0.27552253007888794, 'epoch': 16.98}
{'loss': 0.0137, 'grad_norm': 4.779225826263428, 'learning_rate': 1.3040697674418606e-05, 'loss_1': 0.0058810412883758545, 'loss_2': 0.007843017578125, 'loss_3': -16.419214248657227, 'loss_4': 0.37888625264167786, 'epoch': 16.98}
{'loss': 0.0106, 'grad_norm': 5.510560512542725, 'learning_rate': 1.3034883720930232e-05, 'loss_1': 0.007624107878655195, 'loss_2': 0.002971649169921875, 'loss_3': -16.405941009521484, 'loss_4': 0.6547844409942627, 'epoch': 16.99}
{'loss': 0.0059, 'grad_norm': 4.778146266937256, 'learning_rate': 1.3029069767441861e-05, 'loss_1': 0.0052742986008524895, 'loss_2': 0.0006623268127441406, 'loss_3': -16.658153533935547, 'loss_4': 0.1914200484752655, 'epoch': 16.99}
{'loss': 0.0179, 'grad_norm': 7.681229114532471, 'learning_rate': 1.3023255813953488e-05, 'loss_1': 0.006360239814966917, 'loss_2': 0.01151275634765625, 'loss_3': -16.349897384643555, 'loss_4': 0.7036204934120178, 'epoch': 17.0}
{'loss': 0.0084, 'grad_norm': 6.298847675323486, 'learning_rate': 1.3017441860465117e-05, 'loss_1': 0.007675208617001772, 'loss_2': 0.0007581710815429688, 'loss_3': -16.584564208984375, 'loss_4': 0.7666544914245605, 'epoch': 17.01}
[INFO|trainer.py:4228] 2025-01-21 13:32:33,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:33,795 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                              | 2930/5160 [1:12:38<38:12,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:32:41,147 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011792078614234924, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.823, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.009364322759211063, 'eval_loss_2': 0.0024277567863464355, 'eval_loss_3': -18.19465446472168, 'eval_loss_4': 0.5448102951049805, 'epoch': 17.01}
{'loss': 0.0095, 'grad_norm': 5.45214319229126, 'learning_rate': 1.3011627906976745e-05, 'loss_1': 0.007779357489198446, 'loss_2': 0.0017290115356445312, 'loss_3': -16.659725189208984, 'loss_4': 0.414162814617157, 'epoch': 17.01}
{'loss': 0.0136, 'grad_norm': 5.165417194366455, 'learning_rate': 1.3005813953488372e-05, 'loss_1': 0.007996272295713425, 'loss_2': 0.0055999755859375, 'loss_3': -16.324100494384766, 'loss_4': 0.4451214075088501, 'epoch': 17.02}
{'loss': 0.0101, 'grad_norm': 5.164847373962402, 'learning_rate': 1.3000000000000001e-05, 'loss_1': 0.007012436166405678, 'loss_2': 0.003108978271484375, 'loss_3': -16.500465393066406, 'loss_4': 0.3390832841396332, 'epoch': 17.02}
{'loss': 0.0078, 'grad_norm': 5.494912147521973, 'learning_rate': 1.2994186046511628e-05, 'loss_1': 0.006211649160832167, 'loss_2': 0.0015420913696289062, 'loss_3': -16.430648803710938, 'loss_4': 0.6189825534820557, 'epoch': 17.03}
{'loss': 0.0131, 'grad_norm': 7.574479103088379, 'learning_rate': 1.2988372093023256e-05, 'loss_1': 0.011871876195073128, 'loss_2': 0.0012340545654296875, 'loss_3': -16.556507110595703, 'loss_4': 0.7236069440841675, 'epoch': 17.03}
[INFO|trainer.py:4228] 2025-01-21 13:32:41,147 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:41,147 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                              | 2935/5160 [1:12:45<38:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:48,506 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011632027104496956, 'eval_runtime': 3.8152, 'eval_samples_per_second': 268.4, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.00884977262467146, 'eval_loss_2': 0.0027822554111480713, 'eval_loss_3': -18.20878028869629, 'eval_loss_4': 0.737416684627533, 'epoch': 17.03}
{'loss': 0.0074, 'grad_norm': 4.502514839172363, 'learning_rate': 1.2982558139534883e-05, 'loss_1': 0.007293207570910454, 'loss_2': 6.431341171264648e-05, 'loss_3': -16.575361251831055, 'loss_4': 0.49652308225631714, 'epoch': 17.04}
{'loss': 0.0219, 'grad_norm': 13.66207504272461, 'learning_rate': 1.2976744186046512e-05, 'loss_1': 0.01962362229824066, 'loss_2': 0.002315521240234375, 'loss_3': -16.556564331054688, 'loss_4': 0.927956223487854, 'epoch': 17.05}
{'loss': 0.0183, 'grad_norm': 9.585274696350098, 'learning_rate': 1.297093023255814e-05, 'loss_1': 0.016613218933343887, 'loss_2': 0.00170135498046875, 'loss_3': -16.433963775634766, 'loss_4': 0.9175233840942383, 'epoch': 17.05}
{'loss': 0.0103, 'grad_norm': 6.125456809997559, 'learning_rate': 1.2965116279069768e-05, 'loss_1': 0.007450496777892113, 'loss_2': 0.00279998779296875, 'loss_3': -16.300609588623047, 'loss_4': 0.5853508710861206, 'epoch': 17.06}
{'loss': 0.0295, 'grad_norm': 11.779034614562988, 'learning_rate': 1.2959302325581396e-05, 'loss_1': 0.02216842584311962, 'loss_2': 0.0073089599609375, 'loss_3': -16.38251495361328, 'loss_4': 0.6683345437049866, 'epoch': 17.06}
[INFO|trainer.py:4228] 2025-01-21 13:32:48,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:48,506 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                              | 2940/5160 [1:12:53<38:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:32:55,862 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011231702752411366, 'eval_runtime': 3.812, 'eval_samples_per_second': 268.627, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008446943014860153, 'eval_loss_2': 0.0027847588062286377, 'eval_loss_3': -18.215944290161133, 'eval_loss_4': 0.7995634078979492, 'epoch': 17.06}
{'loss': 0.0148, 'grad_norm': 5.666106700897217, 'learning_rate': 1.2953488372093023e-05, 'loss_1': 0.014008096419274807, 'loss_2': 0.0007753372192382812, 'loss_3': -16.412796020507812, 'loss_4': 0.9989812970161438, 'epoch': 17.07}
{'loss': 0.0155, 'grad_norm': 6.133342266082764, 'learning_rate': 1.294767441860465e-05, 'loss_1': 0.010795273818075657, 'loss_2': 0.00467681884765625, 'loss_3': -16.464717864990234, 'loss_4': 0.723803699016571, 'epoch': 17.08}
{'loss': 0.0086, 'grad_norm': 5.378412246704102, 'learning_rate': 1.294186046511628e-05, 'loss_1': 0.006717469077557325, 'loss_2': 0.0018558502197265625, 'loss_3': -16.590797424316406, 'loss_4': 0.8969289064407349, 'epoch': 17.08}
{'loss': 0.0075, 'grad_norm': 5.951780319213867, 'learning_rate': 1.2936046511627907e-05, 'loss_1': 0.00718707824125886, 'loss_2': 0.00028896331787109375, 'loss_3': -16.49765396118164, 'loss_4': 0.9897652864456177, 'epoch': 17.09}
{'loss': 0.0265, 'grad_norm': 13.788741111755371, 'learning_rate': 1.2930232558139536e-05, 'loss_1': 0.022383200004696846, 'loss_2': 0.0041351318359375, 'loss_3': -16.452585220336914, 'loss_4': 1.2525634765625, 'epoch': 17.09}
[INFO|trainer.py:4228] 2025-01-21 13:32:55,862 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:32:55,862 >>   Batch size = 64
 57%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                              | 2945/5160 [1:13:00<38:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:03,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010431284084916115, 'eval_runtime': 3.8067, 'eval_samples_per_second': 269.0, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007250257767736912, 'eval_loss_2': 0.0031810253858566284, 'eval_loss_3': -18.24535369873047, 'eval_loss_4': 0.9942665696144104, 'epoch': 17.09}
{'loss': 0.0113, 'grad_norm': 6.510885715484619, 'learning_rate': 1.2924418604651163e-05, 'loss_1': 0.009390275925397873, 'loss_2': 0.0019321441650390625, 'loss_3': -16.44493865966797, 'loss_4': 1.316834568977356, 'epoch': 17.1}
{'loss': 0.0085, 'grad_norm': 5.0645341873168945, 'learning_rate': 1.291860465116279e-05, 'loss_1': 0.006940517574548721, 'loss_2': 0.0015869140625, 'loss_3': -16.4294490814209, 'loss_4': 1.0944323539733887, 'epoch': 17.1}
{'loss': 0.0085, 'grad_norm': 4.9784836769104, 'learning_rate': 1.2912790697674419e-05, 'loss_1': 0.006937170866876841, 'loss_2': 0.001605987548828125, 'loss_3': -16.610319137573242, 'loss_4': 1.0376482009887695, 'epoch': 17.11}
{'loss': 0.0145, 'grad_norm': 4.655719757080078, 'learning_rate': 1.2906976744186047e-05, 'loss_1': 0.006468928884714842, 'loss_2': 0.0080413818359375, 'loss_3': -16.698108673095703, 'loss_4': 0.8151402473449707, 'epoch': 17.12}
{'loss': 0.0176, 'grad_norm': 8.682987213134766, 'learning_rate': 1.2901162790697676e-05, 'loss_1': 0.011525223031640053, 'loss_2': 0.0060272216796875, 'loss_3': -16.683101654052734, 'loss_4': 1.2598586082458496, 'epoch': 17.12}
[INFO|trainer.py:4228] 2025-01-21 13:33:03,222 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:03,222 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                             | 2950/5160 [1:13:07<38:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:10,584 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00926992017775774, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.833, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00558143574744463, 'eval_loss_2': 0.0036884844303131104, 'eval_loss_3': -18.23217010498047, 'eval_loss_4': 1.0903396606445312, 'epoch': 17.12}
{'loss': 0.0133, 'grad_norm': 7.398534774780273, 'learning_rate': 1.2895348837209303e-05, 'loss_1': 0.011138515546917915, 'loss_2': 0.00215911865234375, 'loss_3': -16.472335815429688, 'loss_4': 1.2322190999984741, 'epoch': 17.13}
{'loss': 0.0152, 'grad_norm': 8.24943733215332, 'learning_rate': 1.288953488372093e-05, 'loss_1': 0.011507587507367134, 'loss_2': 0.003688812255859375, 'loss_3': -16.487628936767578, 'loss_4': 1.1644704341888428, 'epoch': 17.13}
{'loss': 0.0064, 'grad_norm': 4.506110191345215, 'learning_rate': 1.2883720930232558e-05, 'loss_1': 0.004291859455406666, 'loss_2': 0.0021076202392578125, 'loss_3': -16.488964080810547, 'loss_4': 0.7285369038581848, 'epoch': 17.14}
{'loss': 0.0085, 'grad_norm': 4.644500255584717, 'learning_rate': 1.2877906976744185e-05, 'loss_1': 0.003219147678464651, 'loss_2': 0.005298614501953125, 'loss_3': -16.581315994262695, 'loss_4': 1.0226000547409058, 'epoch': 17.15}
{'loss': 0.0171, 'grad_norm': 10.710514068603516, 'learning_rate': 1.2872093023255816e-05, 'loss_1': 0.01646318845450878, 'loss_2': 0.0006566047668457031, 'loss_3': -16.387958526611328, 'loss_4': 1.1142847537994385, 'epoch': 17.15}
[INFO|trainer.py:4228] 2025-01-21 13:33:10,584 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:10,584 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                             | 2955/5160 [1:13:15<38:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:17,947 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011440460570156574, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.688, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005992269143462181, 'eval_loss_2': 0.005448192358016968, 'eval_loss_3': -18.192184448242188, 'eval_loss_4': 1.1257236003875732, 'epoch': 17.15}
{'loss': 0.0072, 'grad_norm': 5.137881278991699, 'learning_rate': 1.2866279069767442e-05, 'loss_1': 0.005276111885905266, 'loss_2': 0.001956939697265625, 'loss_3': -16.451068878173828, 'loss_4': 0.9309559464454651, 'epoch': 17.16}
{'loss': 0.0175, 'grad_norm': 6.265919208526611, 'learning_rate': 1.286046511627907e-05, 'loss_1': 0.012434354051947594, 'loss_2': 0.0051116943359375, 'loss_3': -16.224313735961914, 'loss_4': 1.0098693370819092, 'epoch': 17.16}
{'loss': 0.0125, 'grad_norm': 5.353211879730225, 'learning_rate': 1.2854651162790698e-05, 'loss_1': 0.004989985376596451, 'loss_2': 0.007541656494140625, 'loss_3': -16.59443473815918, 'loss_4': 0.8181548714637756, 'epoch': 17.17}
{'loss': 0.0074, 'grad_norm': 4.987584590911865, 'learning_rate': 1.2848837209302325e-05, 'loss_1': 0.0057355365715920925, 'loss_2': 0.0016460418701171875, 'loss_3': -16.601139068603516, 'loss_4': 1.3847804069519043, 'epoch': 17.17}
{'loss': 0.0064, 'grad_norm': 4.763200283050537, 'learning_rate': 1.2843023255813954e-05, 'loss_1': 0.0045356000773608685, 'loss_2': 0.00182342529296875, 'loss_3': -16.463550567626953, 'loss_4': 1.1752357482910156, 'epoch': 17.18}
[INFO|trainer.py:4228] 2025-01-21 13:33:17,947 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:17,948 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                             | 2960/5160 [1:13:22<38:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:25,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00937732681632042, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.802, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006489690393209457, 'eval_loss_2': 0.002887636423110962, 'eval_loss_3': -18.175146102905273, 'eval_loss_4': 1.1447317600250244, 'epoch': 17.18}
{'loss': 0.0066, 'grad_norm': 6.103063583374023, 'learning_rate': 1.2837209302325582e-05, 'loss_1': 0.005576105788350105, 'loss_2': 0.0010013580322265625, 'loss_3': -16.52887725830078, 'loss_4': 1.238265872001648, 'epoch': 17.19}
{'loss': 0.0071, 'grad_norm': 5.3592143058776855, 'learning_rate': 1.2831395348837211e-05, 'loss_1': 0.00633399048820138, 'loss_2': 0.0007195472717285156, 'loss_3': -16.392120361328125, 'loss_4': 1.034968614578247, 'epoch': 17.19}
{'loss': 0.0112, 'grad_norm': 4.2599101066589355, 'learning_rate': 1.2825581395348838e-05, 'loss_1': 0.0051822843961417675, 'loss_2': 0.0059814453125, 'loss_3': -16.525733947753906, 'loss_4': 1.542717456817627, 'epoch': 17.2}
{'loss': 0.0065, 'grad_norm': 4.9919047355651855, 'learning_rate': 1.2819767441860465e-05, 'loss_1': 0.004457509610801935, 'loss_2': 0.002025604248046875, 'loss_3': -16.418865203857422, 'loss_4': 1.462828278541565, 'epoch': 17.2}
{'loss': 0.0047, 'grad_norm': 4.619496822357178, 'learning_rate': 1.2813953488372093e-05, 'loss_1': 0.003990806173533201, 'loss_2': 0.0007200241088867188, 'loss_3': -16.300851821899414, 'loss_4': 1.1165934801101685, 'epoch': 17.21}
[INFO|trainer.py:4228] 2025-01-21 13:33:25,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:25,306 >>   Batch size = 64
 57%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                             | 2965/5160 [1:13:29<38:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:32,675 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009956970810890198, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.406, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007084713317453861, 'eval_loss_2': 0.002872258424758911, 'eval_loss_3': -18.163761138916016, 'eval_loss_4': 1.1000049114227295, 'epoch': 17.21}
{'loss': 0.0323, 'grad_norm': 15.660853385925293, 'learning_rate': 1.280813953488372e-05, 'loss_1': 0.030247684568166733, 'loss_2': 0.002025604248046875, 'loss_3': -16.32640838623047, 'loss_4': 1.4685509204864502, 'epoch': 17.22}
{'loss': 0.0734, 'grad_norm': 30.647624969482422, 'learning_rate': 1.280232558139535e-05, 'loss_1': 0.07032562792301178, 'loss_2': 0.0030422210693359375, 'loss_3': -16.356225967407227, 'loss_4': 1.3692868947982788, 'epoch': 17.22}
{'loss': 0.0123, 'grad_norm': 6.002707004547119, 'learning_rate': 1.2796511627906978e-05, 'loss_1': 0.004828884731978178, 'loss_2': 0.00749969482421875, 'loss_3': -16.58796501159668, 'loss_4': 1.0724551677703857, 'epoch': 17.23}
{'loss': 0.0138, 'grad_norm': 6.700972557067871, 'learning_rate': 1.2790697674418605e-05, 'loss_1': 0.010960950516164303, 'loss_2': 0.00286102294921875, 'loss_3': -16.304113388061523, 'loss_4': 1.1585965156555176, 'epoch': 17.23}
{'loss': 0.0105, 'grad_norm': 5.6443681716918945, 'learning_rate': 1.2784883720930233e-05, 'loss_1': 0.007253680378198624, 'loss_2': 0.003238677978515625, 'loss_3': -16.37490463256836, 'loss_4': 1.1040523052215576, 'epoch': 17.24}
[INFO|trainer.py:4228] 2025-01-21 13:33:32,675 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:32,675 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                             | 2970/5160 [1:13:37<37:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:40,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011009272187948227, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.908, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007658417336642742, 'eval_loss_2': 0.00335085391998291, 'eval_loss_3': -18.14376449584961, 'eval_loss_4': 1.1307225227355957, 'epoch': 17.24}
{'loss': 0.0143, 'grad_norm': 8.327020645141602, 'learning_rate': 1.277906976744186e-05, 'loss_1': 0.009967437013983727, 'loss_2': 0.00429534912109375, 'loss_3': -16.36077117919922, 'loss_4': 1.0553466081619263, 'epoch': 17.24}
{'loss': 0.0137, 'grad_norm': 6.9445719718933105, 'learning_rate': 1.2773255813953489e-05, 'loss_1': 0.0075975521467626095, 'loss_2': 0.0060577392578125, 'loss_3': -16.353412628173828, 'loss_4': 1.057129144668579, 'epoch': 17.25}
{'loss': 0.004, 'grad_norm': 4.73890495300293, 'learning_rate': 1.2767441860465117e-05, 'loss_1': 0.0022681972477585077, 'loss_2': 0.0017223358154296875, 'loss_3': -16.46990966796875, 'loss_4': 1.3809632062911987, 'epoch': 17.26}
{'loss': 0.0114, 'grad_norm': 9.069642066955566, 'learning_rate': 1.2761627906976744e-05, 'loss_1': 0.010012457147240639, 'loss_2': 0.0013751983642578125, 'loss_3': -16.417064666748047, 'loss_4': 1.0778552293777466, 'epoch': 17.26}
{'loss': 0.0076, 'grad_norm': 4.543152809143066, 'learning_rate': 1.2755813953488373e-05, 'loss_1': 0.003340227296575904, 'loss_2': 0.00423431396484375, 'loss_3': -16.392662048339844, 'loss_4': 1.1758465766906738, 'epoch': 17.27}
[INFO|trainer.py:4228] 2025-01-21 13:33:40,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:40,033 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                            | 2975/5160 [1:13:44<37:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:47,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011597159318625927, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.825, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007994281128048897, 'eval_loss_2': 0.0036028772592544556, 'eval_loss_3': -18.148910522460938, 'eval_loss_4': 1.1699000597000122, 'epoch': 17.27}
{'loss': 0.0045, 'grad_norm': 5.001229286193848, 'learning_rate': 1.275e-05, 'loss_1': 0.00382841844111681, 'loss_2': 0.0006299018859863281, 'loss_3': -16.460416793823242, 'loss_4': 1.4813792705535889, 'epoch': 17.27}
{'loss': 0.0149, 'grad_norm': 4.778387069702148, 'learning_rate': 1.2744186046511629e-05, 'loss_1': 0.007294114213436842, 'loss_2': 0.0076141357421875, 'loss_3': -16.607425689697266, 'loss_4': 1.0680811405181885, 'epoch': 17.28}
{'loss': 0.0095, 'grad_norm': 4.59901762008667, 'learning_rate': 1.2738372093023255e-05, 'loss_1': 0.006785783916711807, 'loss_2': 0.0027103424072265625, 'loss_3': -16.63722801208496, 'loss_4': 1.4380239248275757, 'epoch': 17.28}
{'loss': 0.0274, 'grad_norm': 13.545378684997559, 'learning_rate': 1.2732558139534884e-05, 'loss_1': 0.020519208163022995, 'loss_2': 0.006927490234375, 'loss_3': -16.260820388793945, 'loss_4': 0.9984482526779175, 'epoch': 17.29}
{'loss': 0.0102, 'grad_norm': 4.65342903137207, 'learning_rate': 1.2726744186046513e-05, 'loss_1': 0.0032980842515826225, 'loss_2': 0.0068817138671875, 'loss_3': -16.414505004882812, 'loss_4': 1.6187152862548828, 'epoch': 17.3}
[INFO|trainer.py:4228] 2025-01-21 13:33:47,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:47,395 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                            | 2980/5160 [1:13:51<37:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:33:54,744 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014012469910085201, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.008446230553090572, 'eval_loss_2': 0.005566239356994629, 'eval_loss_3': -18.121105194091797, 'eval_loss_4': 1.393736481666565, 'epoch': 17.3}
{'loss': 0.0121, 'grad_norm': 5.188784122467041, 'learning_rate': 1.272093023255814e-05, 'loss_1': 0.005864404607564211, 'loss_2': 0.00620269775390625, 'loss_3': -16.48555564880371, 'loss_4': 1.0957618951797485, 'epoch': 17.3}
{'loss': 0.0106, 'grad_norm': 5.463823318481445, 'learning_rate': 1.2715116279069768e-05, 'loss_1': 0.007040088530629873, 'loss_2': 0.0035552978515625, 'loss_3': -16.096303939819336, 'loss_4': 0.9567148089408875, 'epoch': 17.31}
{'loss': 0.0086, 'grad_norm': 4.857099533081055, 'learning_rate': 1.2709302325581395e-05, 'loss_1': 0.004718209151178598, 'loss_2': 0.00386810302734375, 'loss_3': -16.372297286987305, 'loss_4': 1.6512794494628906, 'epoch': 17.31}
{'loss': 0.0371, 'grad_norm': 21.762388229370117, 'learning_rate': 1.2703488372093022e-05, 'loss_1': 0.03460082784295082, 'loss_2': 0.002529144287109375, 'loss_3': -16.308801651000977, 'loss_4': 1.2488179206848145, 'epoch': 17.32}
{'loss': 0.0113, 'grad_norm': 5.108386039733887, 'learning_rate': 1.2697674418604653e-05, 'loss_1': 0.005132191814482212, 'loss_2': 0.006130218505859375, 'loss_3': -16.11663055419922, 'loss_4': 1.8682690858840942, 'epoch': 17.33}
[INFO|trainer.py:4228] 2025-01-21 13:33:54,745 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:33:54,745 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                            | 2985/5160 [1:13:59<37:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:02,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013141249306499958, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.917, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011031617410480976, 'eval_loss_2': 0.002109631896018982, 'eval_loss_3': -18.11069107055664, 'eval_loss_4': 1.541297435760498, 'epoch': 17.33}
{'loss': 0.0119, 'grad_norm': 6.789948463439941, 'learning_rate': 1.269186046511628e-05, 'loss_1': 0.010736319236457348, 'loss_2': 0.001163482666015625, 'loss_3': -16.364055633544922, 'loss_4': 1.6823229789733887, 'epoch': 17.33}
{'loss': 0.0108, 'grad_norm': 6.870518207550049, 'learning_rate': 1.2686046511627908e-05, 'loss_1': 0.01069424394518137, 'loss_2': 8.034706115722656e-05, 'loss_3': -16.423538208007812, 'loss_4': 1.582343578338623, 'epoch': 17.34}
{'loss': 0.0094, 'grad_norm': 5.095813274383545, 'learning_rate': 1.2680232558139535e-05, 'loss_1': 0.00407478678971529, 'loss_2': 0.0052947998046875, 'loss_3': -16.47884178161621, 'loss_4': 1.5207798480987549, 'epoch': 17.34}
{'loss': 0.0215, 'grad_norm': 8.641263008117676, 'learning_rate': 1.2674418604651162e-05, 'loss_1': 0.0165058933198452, 'loss_2': 0.0050201416015625, 'loss_3': -16.184852600097656, 'loss_4': 1.6517131328582764, 'epoch': 17.35}
{'loss': 0.0101, 'grad_norm': 4.694344520568848, 'learning_rate': 1.266860465116279e-05, 'loss_1': 0.003542550839483738, 'loss_2': 0.00656890869140625, 'loss_3': -16.235782623291016, 'loss_4': 1.4689147472381592, 'epoch': 17.35}
[INFO|trainer.py:4228] 2025-01-21 13:34:02,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:02,102 >>   Batch size = 64
 58%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                            | 2990/5160 [1:14:06<37:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:09,457 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016952194273471832, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.955, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013194152154028416, 'eval_loss_2': 0.003758043050765991, 'eval_loss_3': -18.06946563720703, 'eval_loss_4': 1.7668588161468506, 'epoch': 17.35}
{'loss': 0.0235, 'grad_norm': 9.107932090759277, 'learning_rate': 1.266279069767442e-05, 'loss_1': 0.010528672486543655, 'loss_2': 0.0130157470703125, 'loss_3': -16.531274795532227, 'loss_4': 1.7069544792175293, 'epoch': 17.36}
{'loss': 0.028, 'grad_norm': 11.791465759277344, 'learning_rate': 1.2656976744186048e-05, 'loss_1': 0.020503347739577293, 'loss_2': 0.00745391845703125, 'loss_3': -16.485177993774414, 'loss_4': 1.8685832023620605, 'epoch': 17.37}
{'loss': 0.0115, 'grad_norm': 5.819875240325928, 'learning_rate': 1.2651162790697675e-05, 'loss_1': 0.00887070782482624, 'loss_2': 0.002658843994140625, 'loss_3': -16.252948760986328, 'loss_4': 1.7820934057235718, 'epoch': 17.37}
{'loss': 0.005, 'grad_norm': 5.732460021972656, 'learning_rate': 1.2645348837209303e-05, 'loss_1': 0.0026275250129401684, 'loss_2': 0.0023956298828125, 'loss_3': -16.420913696289062, 'loss_4': 1.6686046123504639, 'epoch': 17.38}
{'loss': 0.0081, 'grad_norm': 4.687202453613281, 'learning_rate': 1.263953488372093e-05, 'loss_1': 0.005514776334166527, 'loss_2': 0.00262451171875, 'loss_3': -16.32175064086914, 'loss_4': 1.9923999309539795, 'epoch': 17.38}
[INFO|trainer.py:4228] 2025-01-21 13:34:09,457 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:09,457 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                            | 2995/5160 [1:14:13<37:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:16,823 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02827765792608261, 'eval_runtime': 3.8157, 'eval_samples_per_second': 268.367, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.02533910609781742, 'eval_loss_2': 0.0029385536909103394, 'eval_loss_3': -18.019954681396484, 'eval_loss_4': 1.9974358081817627, 'epoch': 17.38}
{'loss': 0.0074, 'grad_norm': 4.359596252441406, 'learning_rate': 1.2633720930232557e-05, 'loss_1': 0.0037913424894213676, 'loss_2': 0.0036296844482421875, 'loss_3': -16.389530181884766, 'loss_4': 2.355607509613037, 'epoch': 17.39}
{'loss': 0.0075, 'grad_norm': 4.694779396057129, 'learning_rate': 1.2627906976744188e-05, 'loss_1': 0.005822703242301941, 'loss_2': 0.001682281494140625, 'loss_3': -16.380027770996094, 'loss_4': 1.9539835453033447, 'epoch': 17.4}
{'loss': 0.0195, 'grad_norm': 6.576030731201172, 'learning_rate': 1.2622093023255815e-05, 'loss_1': 0.010157594457268715, 'loss_2': 0.009368896484375, 'loss_3': -16.260278701782227, 'loss_4': 2.0465455055236816, 'epoch': 17.4}
{'loss': 0.0114, 'grad_norm': 5.630722522735596, 'learning_rate': 1.2616279069767443e-05, 'loss_1': 0.005939627066254616, 'loss_2': 0.00550079345703125, 'loss_3': -16.151582717895508, 'loss_4': 2.355459690093994, 'epoch': 17.41}
{'loss': 0.0063, 'grad_norm': 5.011369705200195, 'learning_rate': 1.261046511627907e-05, 'loss_1': 0.0047075022011995316, 'loss_2': 0.001636505126953125, 'loss_3': -16.383846282958984, 'loss_4': 2.4373607635498047, 'epoch': 17.41}
[INFO|trainer.py:4228] 2025-01-21 13:34:16,823 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:16,823 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                           | 3000/5160 [1:14:21<37:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:24,176 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0341501384973526, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.081, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.030954230576753616, 'eval_loss_2': 0.0031959079205989838, 'eval_loss_3': -17.994647979736328, 'eval_loss_4': 2.233531951904297, 'epoch': 17.41}
{'loss': 0.0109, 'grad_norm': 4.752516746520996, 'learning_rate': 1.2604651162790697e-05, 'loss_1': 0.0060904137790203094, 'loss_2': 0.004825592041015625, 'loss_3': -16.498828887939453, 'loss_4': 2.198505401611328, 'epoch': 17.42}
{'loss': 0.0202, 'grad_norm': 8.75918197631836, 'learning_rate': 1.2598837209302326e-05, 'loss_1': 0.017916368320584297, 'loss_2': 0.0023021697998046875, 'loss_3': -16.143451690673828, 'loss_4': 2.584733724594116, 'epoch': 17.42}
{'loss': 0.0097, 'grad_norm': 5.014047145843506, 'learning_rate': 1.2593023255813954e-05, 'loss_1': 0.008051020093262196, 'loss_2': 0.0016307830810546875, 'loss_3': -16.462228775024414, 'loss_4': 2.080227851867676, 'epoch': 17.43}
{'loss': 0.0141, 'grad_norm': 5.64629602432251, 'learning_rate': 1.2587209302325583e-05, 'loss_1': 0.009472730569541454, 'loss_2': 0.00460052490234375, 'loss_3': -16.36918067932129, 'loss_4': 2.5808987617492676, 'epoch': 17.44}
{'loss': 0.0071, 'grad_norm': 5.022902965545654, 'learning_rate': 1.258139534883721e-05, 'loss_1': 0.006536880973726511, 'loss_2': 0.0006108283996582031, 'loss_3': -16.30655288696289, 'loss_4': 2.3087007999420166, 'epoch': 17.44}
[INFO|trainer.py:4228] 2025-01-21 13:34:24,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:24,176 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                           | 3005/5160 [1:14:28<37:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:31,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.035868704319000244, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.2, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.032172951847314835, 'eval_loss_2': 0.003695756196975708, 'eval_loss_3': -17.996597290039062, 'eval_loss_4': 2.344635486602783, 'epoch': 17.44}
{'loss': 0.0155, 'grad_norm': 10.069416046142578, 'learning_rate': 1.2575581395348837e-05, 'loss_1': 0.012598628178238869, 'loss_2': 0.00286102294921875, 'loss_3': -16.289939880371094, 'loss_4': 2.744598388671875, 'epoch': 17.45}
{'loss': 0.0207, 'grad_norm': 9.798152923583984, 'learning_rate': 1.2569767441860465e-05, 'loss_1': 0.019938001409173012, 'loss_2': 0.0007944107055664062, 'loss_3': -16.25081443786621, 'loss_4': 2.0076816082000732, 'epoch': 17.45}
{'loss': 0.0235, 'grad_norm': 9.519745826721191, 'learning_rate': 1.2563953488372092e-05, 'loss_1': 0.015709631145000458, 'loss_2': 0.0078277587890625, 'loss_3': -16.36273193359375, 'loss_4': 2.5358729362487793, 'epoch': 17.46}
{'loss': 0.0178, 'grad_norm': 6.1494011878967285, 'learning_rate': 1.2558139534883723e-05, 'loss_1': 0.014843638986349106, 'loss_2': 0.0029888153076171875, 'loss_3': -16.452499389648438, 'loss_4': 2.9461584091186523, 'epoch': 17.47}
{'loss': 0.019, 'grad_norm': 6.077136993408203, 'learning_rate': 1.255232558139535e-05, 'loss_1': 0.012214181013405323, 'loss_2': 0.00678253173828125, 'loss_3': -16.487762451171875, 'loss_4': 2.7195827960968018, 'epoch': 17.47}
[INFO|trainer.py:4228] 2025-01-21 13:34:31,531 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:31,531 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                           | 3010/5160 [1:14:36<37:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:38,887 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04551422595977783, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.04115172103047371, 'eval_loss_2': 0.0043625012040138245, 'eval_loss_3': -17.969257354736328, 'eval_loss_4': 2.554372549057007, 'epoch': 17.47}
{'loss': 0.0234, 'grad_norm': 8.158849716186523, 'learning_rate': 1.2546511627906977e-05, 'loss_1': 0.018494397401809692, 'loss_2': 0.00494384765625, 'loss_3': -16.038087844848633, 'loss_4': 2.659005641937256, 'epoch': 17.48}
{'loss': 0.0082, 'grad_norm': 5.3370280265808105, 'learning_rate': 1.2540697674418605e-05, 'loss_1': 0.0058070276863873005, 'loss_2': 0.002399444580078125, 'loss_3': -16.282100677490234, 'loss_4': 2.5193262100219727, 'epoch': 17.48}
{'loss': 0.0208, 'grad_norm': 6.785991191864014, 'learning_rate': 1.2534883720930232e-05, 'loss_1': 0.011278047226369381, 'loss_2': 0.009490966796875, 'loss_3': -16.281038284301758, 'loss_4': 2.7441892623901367, 'epoch': 17.49}
{'loss': 0.0479, 'grad_norm': 24.262924194335938, 'learning_rate': 1.252906976744186e-05, 'loss_1': 0.04299214482307434, 'loss_2': 0.00487518310546875, 'loss_3': -16.05810546875, 'loss_4': 2.629180908203125, 'epoch': 17.49}
{'loss': 0.0279, 'grad_norm': 12.548199653625488, 'learning_rate': 1.252325581395349e-05, 'loss_1': 0.027115361765027046, 'loss_2': 0.0008263587951660156, 'loss_3': -16.280838012695312, 'loss_4': 3.034122943878174, 'epoch': 17.5}
[INFO|trainer.py:4228] 2025-01-21 13:34:38,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:38,888 >>   Batch size = 64
 58%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                           | 3015/5160 [1:14:43<37:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:46,239 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03749103099107742, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.223, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.03162718564271927, 'eval_loss_2': 0.005863845348358154, 'eval_loss_3': -18.014427185058594, 'eval_loss_4': 2.630561351776123, 'epoch': 17.5}
{'loss': 0.0106, 'grad_norm': 7.089078426361084, 'learning_rate': 1.2517441860465116e-05, 'loss_1': 0.00935675110667944, 'loss_2': 0.001255035400390625, 'loss_3': -16.376445770263672, 'loss_4': 2.5433523654937744, 'epoch': 17.51}
{'loss': 0.012, 'grad_norm': 5.843079090118408, 'learning_rate': 1.2511627906976745e-05, 'loss_1': 0.00867240596562624, 'loss_2': 0.003360748291015625, 'loss_3': -16.422693252563477, 'loss_4': 2.832099437713623, 'epoch': 17.51}
{'loss': 0.0896, 'grad_norm': 24.21016502380371, 'learning_rate': 1.2505813953488372e-05, 'loss_1': 0.08847920596599579, 'loss_2': 0.0011587142944335938, 'loss_3': -16.43217658996582, 'loss_4': 3.3514750003814697, 'epoch': 17.52}
{'loss': 0.017, 'grad_norm': 7.063242435455322, 'learning_rate': 1.25e-05, 'loss_1': 0.015085229650139809, 'loss_2': 0.001888275146484375, 'loss_3': -15.948473930358887, 'loss_4': 2.7196245193481445, 'epoch': 17.52}
{'loss': 0.0223, 'grad_norm': 10.656115531921387, 'learning_rate': 1.2494186046511628e-05, 'loss_1': 0.01738906465470791, 'loss_2': 0.00493621826171875, 'loss_3': -16.353139877319336, 'loss_4': 2.79518723487854, 'epoch': 17.53}
[INFO|trainer.py:4228] 2025-01-21 13:34:46,239 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:46,239 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                          | 3020/5160 [1:14:50<37:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:34:53,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04831637814640999, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.655, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.042814917862415314, 'eval_loss_2': 0.005501460283994675, 'eval_loss_3': -17.989269256591797, 'eval_loss_4': 2.742490291595459, 'epoch': 17.53}
{'loss': 0.0227, 'grad_norm': 13.894689559936523, 'learning_rate': 1.2488372093023256e-05, 'loss_1': 0.022166801616549492, 'loss_2': 0.0005817413330078125, 'loss_3': -16.209491729736328, 'loss_4': 2.861823081970215, 'epoch': 17.53}
{'loss': 0.0097, 'grad_norm': 4.841024398803711, 'learning_rate': 1.2482558139534885e-05, 'loss_1': 0.005068932194262743, 'loss_2': 0.004634857177734375, 'loss_3': -16.525264739990234, 'loss_4': 2.346376419067383, 'epoch': 17.54}
{'loss': 0.0214, 'grad_norm': 6.8573126792907715, 'learning_rate': 1.2476744186046512e-05, 'loss_1': 0.01599935069680214, 'loss_2': 0.00536346435546875, 'loss_3': -16.267261505126953, 'loss_4': 2.715463638305664, 'epoch': 17.55}
{'loss': 0.0087, 'grad_norm': 5.093138694763184, 'learning_rate': 1.247093023255814e-05, 'loss_1': 0.004575891885906458, 'loss_2': 0.0041656494140625, 'loss_3': -16.515365600585938, 'loss_4': 2.60612416267395, 'epoch': 17.55}
{'loss': 0.0149, 'grad_norm': 6.020833492279053, 'learning_rate': 1.2465116279069767e-05, 'loss_1': 0.010287181474268436, 'loss_2': 0.0046539306640625, 'loss_3': -16.29920196533203, 'loss_4': 2.6645545959472656, 'epoch': 17.56}
[INFO|trainer.py:4228] 2025-01-21 13:34:53,609 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:34:53,609 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                          | 3025/5160 [1:14:58<36:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:00,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.046673864126205444, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.361, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.03999296948313713, 'eval_loss_2': 0.006680890917778015, 'eval_loss_3': -18.003087997436523, 'eval_loss_4': 2.5888776779174805, 'epoch': 17.56}
{'loss': 0.0224, 'grad_norm': 16.343059539794922, 'learning_rate': 1.2459302325581396e-05, 'loss_1': 0.01928846165537834, 'loss_2': 0.0031299591064453125, 'loss_3': -16.239330291748047, 'loss_4': 2.887632369995117, 'epoch': 17.56}
{'loss': 0.1469, 'grad_norm': 9.426650047302246, 'learning_rate': 1.2453488372093023e-05, 'loss_1': 0.1402183473110199, 'loss_2': 0.00672149658203125, 'loss_3': -16.187593460083008, 'loss_4': 2.8918824195861816, 'epoch': 17.57}
{'loss': 0.0483, 'grad_norm': 22.77788543701172, 'learning_rate': 1.2447674418604652e-05, 'loss_1': 0.0411636121571064, 'loss_2': 0.00717926025390625, 'loss_3': -16.50196075439453, 'loss_4': 2.7262024879455566, 'epoch': 17.58}
{'loss': 0.01, 'grad_norm': 5.367626190185547, 'learning_rate': 1.244186046511628e-05, 'loss_1': 0.008836142718791962, 'loss_2': 0.001155853271484375, 'loss_3': -16.392005920410156, 'loss_4': 2.2209253311157227, 'epoch': 17.58}
{'loss': 0.0145, 'grad_norm': 5.159560203552246, 'learning_rate': 1.2436046511627907e-05, 'loss_1': 0.009710492566227913, 'loss_2': 0.0047607421875, 'loss_3': -16.52261734008789, 'loss_4': 2.537832260131836, 'epoch': 17.59}
[INFO|trainer.py:4228] 2025-01-21 13:35:00,962 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:00,962 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 3030/5160 [1:15:05<36:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:08,312 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03210720047354698, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.16, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0254661925137043, 'eval_loss_2': 0.006641007959842682, 'eval_loss_3': -18.071550369262695, 'eval_loss_4': 2.3219001293182373, 'epoch': 17.59}
{'loss': 0.0243, 'grad_norm': 12.501023292541504, 'learning_rate': 1.2430232558139536e-05, 'loss_1': 0.01694682613015175, 'loss_2': 0.007328033447265625, 'loss_3': -16.535659790039062, 'loss_4': 2.6809420585632324, 'epoch': 17.59}
{'loss': 0.0273, 'grad_norm': 11.910077095031738, 'learning_rate': 1.2424418604651163e-05, 'loss_1': 0.021465091034770012, 'loss_2': 0.0058135986328125, 'loss_3': -16.17922592163086, 'loss_4': 2.484138011932373, 'epoch': 17.6}
{'loss': 0.0222, 'grad_norm': 8.092010498046875, 'learning_rate': 1.241860465116279e-05, 'loss_1': 0.014566334895789623, 'loss_2': 0.007598876953125, 'loss_3': -16.468788146972656, 'loss_4': 2.6571404933929443, 'epoch': 17.6}
{'loss': 0.0105, 'grad_norm': 5.099276065826416, 'learning_rate': 1.241279069767442e-05, 'loss_1': 0.007233987562358379, 'loss_2': 0.003284454345703125, 'loss_3': -16.451026916503906, 'loss_4': 2.1934635639190674, 'epoch': 17.61}
{'loss': 0.0354, 'grad_norm': 14.537188529968262, 'learning_rate': 1.2406976744186047e-05, 'loss_1': 0.033052653074264526, 'loss_2': 0.0023040771484375, 'loss_3': -16.365449905395508, 'loss_4': 2.627678632736206, 'epoch': 17.62}
[INFO|trainer.py:4228] 2025-01-21 13:35:08,312 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:08,312 >>   Batch size = 64
 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                          | 3035/5160 [1:15:12<36:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:15,672 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020192474126815796, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.117, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.016094356775283813, 'eval_loss_2': 0.004098117351531982, 'eval_loss_3': -18.127864837646484, 'eval_loss_4': 2.1219420433044434, 'epoch': 17.62}
{'loss': 0.0115, 'grad_norm': 5.1184539794921875, 'learning_rate': 1.2401162790697675e-05, 'loss_1': 0.008742757141590118, 'loss_2': 0.0027599334716796875, 'loss_3': -16.43610382080078, 'loss_4': 2.4042437076568604, 'epoch': 17.62}
{'loss': 0.0078, 'grad_norm': 5.207290172576904, 'learning_rate': 1.2395348837209302e-05, 'loss_1': 0.005035752430558205, 'loss_2': 0.002716064453125, 'loss_3': -16.471254348754883, 'loss_4': 2.134549617767334, 'epoch': 17.63}
{'loss': 0.0081, 'grad_norm': 5.090464115142822, 'learning_rate': 1.238953488372093e-05, 'loss_1': 0.006380297709256411, 'loss_2': 0.00176239013671875, 'loss_3': -16.48290252685547, 'loss_4': 2.313174247741699, 'epoch': 17.63}
{'loss': 0.0058, 'grad_norm': 4.9500322341918945, 'learning_rate': 1.2383720930232558e-05, 'loss_1': 0.003982529975473881, 'loss_2': 0.001789093017578125, 'loss_3': -16.37192153930664, 'loss_4': 1.7390329837799072, 'epoch': 17.64}
{'loss': 0.0396, 'grad_norm': 23.26913070678711, 'learning_rate': 1.2377906976744187e-05, 'loss_1': 0.02911480888724327, 'loss_2': 0.0104522705078125, 'loss_3': -16.46846580505371, 'loss_4': 2.0532727241516113, 'epoch': 17.65}
[INFO|trainer.py:4228] 2025-01-21 13:35:15,673 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:15,673 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                          | 3040/5160 [1:15:20<36:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:23,022 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011754755862057209, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.951, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008945142850279808, 'eval_loss_2': 0.0028096139430999756, 'eval_loss_3': -18.15764617919922, 'eval_loss_4': 1.9321988821029663, 'epoch': 17.65}
{'loss': 0.0124, 'grad_norm': 5.6996169090271, 'learning_rate': 1.2372093023255815e-05, 'loss_1': 0.010009583085775375, 'loss_2': 0.002410888671875, 'loss_3': -16.22383689880371, 'loss_4': 1.897352695465088, 'epoch': 17.65}
{'loss': 0.0106, 'grad_norm': 5.731999397277832, 'learning_rate': 1.2366279069767442e-05, 'loss_1': 0.008116157725453377, 'loss_2': 0.00246429443359375, 'loss_3': -16.222246170043945, 'loss_4': 2.183135986328125, 'epoch': 17.66}
{'loss': 0.0099, 'grad_norm': 5.465743541717529, 'learning_rate': 1.2360465116279069e-05, 'loss_1': 0.008460531942546368, 'loss_2': 0.0014820098876953125, 'loss_3': -16.374862670898438, 'loss_4': 2.165125846862793, 'epoch': 17.66}
{'loss': 0.0214, 'grad_norm': 10.321012496948242, 'learning_rate': 1.2354651162790698e-05, 'loss_1': 0.020778551697731018, 'loss_2': 0.0006260871887207031, 'loss_3': -16.503053665161133, 'loss_4': 1.7910653352737427, 'epoch': 17.67}
{'loss': 0.0068, 'grad_norm': 4.804035186767578, 'learning_rate': 1.2348837209302325e-05, 'loss_1': 0.0054451460018754005, 'loss_2': 0.0014019012451171875, 'loss_3': -16.41386604309082, 'loss_4': 1.7925645112991333, 'epoch': 17.67}
[INFO|trainer.py:4228] 2025-01-21 13:35:23,023 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:23,023 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                         | 3045/5160 [1:15:27<36:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:30,384 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010113667696714401, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.129, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006706829182803631, 'eval_loss_2': 0.003406837582588196, 'eval_loss_3': -18.180408477783203, 'eval_loss_4': 1.8261806964874268, 'epoch': 17.67}
{'loss': 0.0197, 'grad_norm': 9.831883430480957, 'learning_rate': 1.2343023255813955e-05, 'loss_1': 0.01751883327960968, 'loss_2': 0.0021991729736328125, 'loss_3': -16.23048210144043, 'loss_4': 1.707460880279541, 'epoch': 17.68}
{'loss': 0.021, 'grad_norm': 9.601011276245117, 'learning_rate': 1.2337209302325582e-05, 'loss_1': 0.012430340051651001, 'loss_2': 0.00856781005859375, 'loss_3': -16.309391021728516, 'loss_4': 2.3208224773406982, 'epoch': 17.69}
{'loss': 0.0113, 'grad_norm': 5.423569202423096, 'learning_rate': 1.2331395348837209e-05, 'loss_1': 0.009958688169717789, 'loss_2': 0.0013408660888671875, 'loss_3': -16.50098419189453, 'loss_4': 1.929548978805542, 'epoch': 17.69}
{'loss': 0.0435, 'grad_norm': 24.589622497558594, 'learning_rate': 1.2325581395348838e-05, 'loss_1': 0.03748209774494171, 'loss_2': 0.0059814453125, 'loss_3': -16.25128173828125, 'loss_4': 2.309018611907959, 'epoch': 17.7}
{'loss': 0.0107, 'grad_norm': 5.103219032287598, 'learning_rate': 1.2319767441860464e-05, 'loss_1': 0.007861213758587837, 'loss_2': 0.002796173095703125, 'loss_3': -16.441911697387695, 'loss_4': 1.9247524738311768, 'epoch': 17.7}
[INFO|trainer.py:4228] 2025-01-21 13:35:30,384 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:30,385 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                         | 3050/5160 [1:15:34<36:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:37,753 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009241226129233837, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.179, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006309645716100931, 'eval_loss_2': 0.0029315799474716187, 'eval_loss_3': -18.212268829345703, 'eval_loss_4': 1.877860426902771, 'epoch': 17.7}
{'loss': 0.0165, 'grad_norm': 6.738409996032715, 'learning_rate': 1.2313953488372093e-05, 'loss_1': 0.013869572430849075, 'loss_2': 0.00261688232421875, 'loss_3': -16.400489807128906, 'loss_4': 1.8637933731079102, 'epoch': 17.71}
{'loss': 0.0066, 'grad_norm': 4.616811275482178, 'learning_rate': 1.2308139534883722e-05, 'loss_1': 0.0053354534320533276, 'loss_2': 0.00127410888671875, 'loss_3': -16.389833450317383, 'loss_4': 2.0851407051086426, 'epoch': 17.72}
{'loss': 0.0181, 'grad_norm': 6.898770809173584, 'learning_rate': 1.2302325581395349e-05, 'loss_1': 0.012584352865815163, 'loss_2': 0.0055084228515625, 'loss_3': -16.376373291015625, 'loss_4': 2.5864481925964355, 'epoch': 17.72}
{'loss': 0.0099, 'grad_norm': 5.102542877197266, 'learning_rate': 1.2296511627906977e-05, 'loss_1': 0.007496025878936052, 'loss_2': 0.002445220947265625, 'loss_3': -16.491682052612305, 'loss_4': 2.2784667015075684, 'epoch': 17.73}
{'loss': 0.013, 'grad_norm': 5.1640543937683105, 'learning_rate': 1.2290697674418604e-05, 'loss_1': 0.006881345063447952, 'loss_2': 0.0061492919921875, 'loss_3': -16.346477508544922, 'loss_4': 2.3108291625976562, 'epoch': 17.73}
[INFO|trainer.py:4228] 2025-01-21 13:35:37,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:37,754 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                         | 3055/5160 [1:15:42<36:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:45,103 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013775225728750229, 'eval_runtime': 3.8016, 'eval_samples_per_second': 269.358, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.007590648718178272, 'eval_loss_2': 0.006184577941894531, 'eval_loss_3': -18.223987579345703, 'eval_loss_4': 1.83879816532135, 'epoch': 17.73}
{'loss': 0.079, 'grad_norm': 15.767195701599121, 'learning_rate': 1.2284883720930233e-05, 'loss_1': 0.06883130967617035, 'loss_2': 0.0101318359375, 'loss_3': -16.526430130004883, 'loss_4': 2.122483491897583, 'epoch': 17.74}
{'loss': 0.017, 'grad_norm': 5.002596855163574, 'learning_rate': 1.227906976744186e-05, 'loss_1': 0.008920609019696712, 'loss_2': 0.00809478759765625, 'loss_3': -16.535995483398438, 'loss_4': 2.165684700012207, 'epoch': 17.74}
{'loss': 0.0127, 'grad_norm': 5.61949348449707, 'learning_rate': 1.227325581395349e-05, 'loss_1': 0.009230753406882286, 'loss_2': 0.003429412841796875, 'loss_3': -16.316478729248047, 'loss_4': 2.121267795562744, 'epoch': 17.75}
{'loss': 0.0256, 'grad_norm': 12.132756233215332, 'learning_rate': 1.2267441860465117e-05, 'loss_1': 0.022005867213010788, 'loss_2': 0.0036373138427734375, 'loss_3': -16.254375457763672, 'loss_4': 2.39231538772583, 'epoch': 17.76}
{'loss': 0.0204, 'grad_norm': 6.035674571990967, 'learning_rate': 1.2261627906976744e-05, 'loss_1': 0.010029231198132038, 'loss_2': 0.0103607177734375, 'loss_3': -16.3314208984375, 'loss_4': 1.825533390045166, 'epoch': 17.76}
[INFO|trainer.py:4228] 2025-01-21 13:35:45,103 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:45,103 >>   Batch size = 64
 59%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                         | 3060/5160 [1:15:49<36:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:52,453 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010422817431390285, 'eval_runtime': 3.8006, 'eval_samples_per_second': 269.433, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.00633918447420001, 'eval_loss_2': 0.0040836334228515625, 'eval_loss_3': -18.212217330932617, 'eval_loss_4': 1.7244796752929688, 'epoch': 17.76}
{'loss': 0.0055, 'grad_norm': 4.932346820831299, 'learning_rate': 1.2255813953488373e-05, 'loss_1': 0.005339421331882477, 'loss_2': 0.00017142295837402344, 'loss_3': -16.27511215209961, 'loss_4': 2.285571336746216, 'epoch': 17.77}
{'loss': 0.0107, 'grad_norm': 4.316515922546387, 'learning_rate': 1.225e-05, 'loss_1': 0.00537127023562789, 'loss_2': 0.005283355712890625, 'loss_3': -16.638063430786133, 'loss_4': 1.9599888324737549, 'epoch': 17.77}
{'loss': 0.0161, 'grad_norm': 5.689343452453613, 'learning_rate': 1.2244186046511628e-05, 'loss_1': 0.00784420408308506, 'loss_2': 0.00821685791015625, 'loss_3': -16.239299774169922, 'loss_4': 1.877598762512207, 'epoch': 17.78}
{'loss': 0.0284, 'grad_norm': 6.586949825286865, 'learning_rate': 1.2238372093023257e-05, 'loss_1': 0.01582886092364788, 'loss_2': 0.0126190185546875, 'loss_3': -16.217430114746094, 'loss_4': 1.6960773468017578, 'epoch': 17.78}
{'loss': 0.0121, 'grad_norm': 5.861259460449219, 'learning_rate': 1.2232558139534884e-05, 'loss_1': 0.009645114652812481, 'loss_2': 0.00241851806640625, 'loss_3': -16.462615966796875, 'loss_4': 1.3022944927215576, 'epoch': 17.79}
[INFO|trainer.py:4228] 2025-01-21 13:35:52,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:52,454 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                         | 3065/5160 [1:15:56<36:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:35:59,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008291858248412609, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.231, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005744699388742447, 'eval_loss_2': 0.002547159790992737, 'eval_loss_3': -18.198030471801758, 'eval_loss_4': 1.5681126117706299, 'epoch': 17.79}
{'loss': 0.0201, 'grad_norm': 11.222874641418457, 'learning_rate': 1.2226744186046512e-05, 'loss_1': 0.013691840693354607, 'loss_2': 0.00637054443359375, 'loss_3': -16.087696075439453, 'loss_4': 1.5977258682250977, 'epoch': 17.8}
{'loss': 0.0203, 'grad_norm': 10.884949684143066, 'learning_rate': 1.222093023255814e-05, 'loss_1': 0.017836764454841614, 'loss_2': 0.0024394989013671875, 'loss_3': -16.29146957397461, 'loss_4': 1.6090056896209717, 'epoch': 17.8}
{'loss': 0.0101, 'grad_norm': 5.603270530700684, 'learning_rate': 1.2215116279069768e-05, 'loss_1': 0.006747473496943712, 'loss_2': 0.0033721923828125, 'loss_3': -16.50326156616211, 'loss_4': 1.9678833484649658, 'epoch': 17.81}
{'loss': 0.0056, 'grad_norm': 4.626414775848389, 'learning_rate': 1.2209302325581395e-05, 'loss_1': 0.004273014143109322, 'loss_2': 0.0013408660888671875, 'loss_3': -16.51105499267578, 'loss_4': 1.8276385068893433, 'epoch': 17.81}
{'loss': 0.0107, 'grad_norm': 4.563558101654053, 'learning_rate': 1.2203488372093024e-05, 'loss_1': 0.004981773439794779, 'loss_2': 0.005725860595703125, 'loss_3': -16.423660278320312, 'loss_4': 1.5919990539550781, 'epoch': 17.82}
[INFO|trainer.py:4228] 2025-01-21 13:35:59,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:35:59,808 >>   Batch size = 64
 59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                        | 3070/5160 [1:16:04<36:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:07,161 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00948561541736126, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.163, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005815452430397272, 'eval_loss_2': 0.0036701634526252747, 'eval_loss_3': -18.161714553833008, 'eval_loss_4': 1.5165436267852783, 'epoch': 17.82}
{'loss': 0.0116, 'grad_norm': 6.027163982391357, 'learning_rate': 1.2197674418604652e-05, 'loss_1': 0.009934680536389351, 'loss_2': 0.0016994476318359375, 'loss_3': -16.157470703125, 'loss_4': 1.5573724508285522, 'epoch': 17.83}
{'loss': 0.0044, 'grad_norm': 4.781100273132324, 'learning_rate': 1.2191860465116279e-05, 'loss_1': 0.0037920139729976654, 'loss_2': 0.0005741119384765625, 'loss_3': -16.348079681396484, 'loss_4': 1.8773986101150513, 'epoch': 17.83}
{'loss': 0.0162, 'grad_norm': 4.965834140777588, 'learning_rate': 1.2186046511627908e-05, 'loss_1': 0.008084003813564777, 'loss_2': 0.008087158203125, 'loss_3': -16.326480865478516, 'loss_4': 1.9825832843780518, 'epoch': 17.84}
{'loss': 0.0048, 'grad_norm': 5.11530876159668, 'learning_rate': 1.2180232558139535e-05, 'loss_1': 0.004485354293137789, 'loss_2': 0.00029659271240234375, 'loss_3': -16.524412155151367, 'loss_4': 1.6109580993652344, 'epoch': 17.84}
{'loss': 0.0074, 'grad_norm': 4.471164226531982, 'learning_rate': 1.2174418604651162e-05, 'loss_1': 0.00392294954508543, 'loss_2': 0.003437042236328125, 'loss_3': -16.235660552978516, 'loss_4': 1.62176513671875, 'epoch': 17.85}
[INFO|trainer.py:4228] 2025-01-21 13:36:07,161 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:07,162 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                        | 3075/5160 [1:16:11<36:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:14,523 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012427346780896187, 'eval_runtime': 3.813, 'eval_samples_per_second': 268.556, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.009087253361940384, 'eval_loss_2': 0.003340095281600952, 'eval_loss_3': -18.1420955657959, 'eval_loss_4': 1.583524227142334, 'epoch': 17.85}
{'loss': 0.0101, 'grad_norm': 5.15187931060791, 'learning_rate': 1.2168604651162792e-05, 'loss_1': 0.005507792811840773, 'loss_2': 0.00455474853515625, 'loss_3': -16.327167510986328, 'loss_4': 1.533318042755127, 'epoch': 17.85}
{'loss': 0.0045, 'grad_norm': 4.8710618019104, 'learning_rate': 1.2162790697674419e-05, 'loss_1': 0.0032055105548352003, 'loss_2': 0.0012722015380859375, 'loss_3': -16.50350570678711, 'loss_4': 1.4317426681518555, 'epoch': 17.86}
{'loss': 0.0181, 'grad_norm': 8.122268676757812, 'learning_rate': 1.2156976744186048e-05, 'loss_1': 0.011839844286441803, 'loss_2': 0.0063018798828125, 'loss_3': -16.231426239013672, 'loss_4': 1.5375549793243408, 'epoch': 17.87}
{'loss': 0.0138, 'grad_norm': 6.4704670906066895, 'learning_rate': 1.2151162790697674e-05, 'loss_1': 0.009591740556061268, 'loss_2': 0.004215240478515625, 'loss_3': -16.22787857055664, 'loss_4': 1.4539695978164673, 'epoch': 17.87}
{'loss': 0.0098, 'grad_norm': 4.786432266235352, 'learning_rate': 1.2145348837209301e-05, 'loss_1': 0.003087652614340186, 'loss_2': 0.006710052490234375, 'loss_3': -16.489089965820312, 'loss_4': 1.8133569955825806, 'epoch': 17.88}
[INFO|trainer.py:4228] 2025-01-21 13:36:14,523 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:14,523 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                        | 3080/5160 [1:16:19<36:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:21,884 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012663825415074825, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.645, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.009089439176023006, 'eval_loss_2': 0.003574386239051819, 'eval_loss_3': -18.146438598632812, 'eval_loss_4': 1.6103850603103638, 'epoch': 17.88}
{'loss': 0.0086, 'grad_norm': 5.174734592437744, 'learning_rate': 1.213953488372093e-05, 'loss_1': 0.007843037135899067, 'loss_2': 0.0007753372192382812, 'loss_3': -16.419239044189453, 'loss_4': 1.475700855255127, 'epoch': 17.88}
{'loss': 0.0114, 'grad_norm': 4.734374046325684, 'learning_rate': 1.2133720930232559e-05, 'loss_1': 0.00378306838683784, 'loss_2': 0.00763702392578125, 'loss_3': -16.432401657104492, 'loss_4': 1.9887981414794922, 'epoch': 17.89}
{'loss': 0.0094, 'grad_norm': 5.34700870513916, 'learning_rate': 1.2127906976744187e-05, 'loss_1': 0.006375113967806101, 'loss_2': 0.002986907958984375, 'loss_3': -16.382610321044922, 'loss_4': 1.8605444431304932, 'epoch': 17.9}
{'loss': 0.0102, 'grad_norm': 5.092308521270752, 'learning_rate': 1.2122093023255814e-05, 'loss_1': 0.004891548305749893, 'loss_2': 0.00527191162109375, 'loss_3': -16.27986717224121, 'loss_4': 1.8820228576660156, 'epoch': 17.9}
{'loss': 0.0252, 'grad_norm': 12.831360816955566, 'learning_rate': 1.2116279069767441e-05, 'loss_1': 0.020810842514038086, 'loss_2': 0.004375457763671875, 'loss_3': -16.376110076904297, 'loss_4': 1.6411170959472656, 'epoch': 17.91}
[INFO|trainer.py:4228] 2025-01-21 13:36:21,885 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:21,885 >>   Batch size = 64
 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 3085/5160 [1:16:26<35:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:29,245 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015192950144410133, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.855, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.010823780670762062, 'eval_loss_2': 0.004369169473648071, 'eval_loss_3': -18.14830780029297, 'eval_loss_4': 1.557404637336731, 'epoch': 17.91}
{'loss': 0.0078, 'grad_norm': 5.172689914703369, 'learning_rate': 1.211046511627907e-05, 'loss_1': 0.0034229287412017584, 'loss_2': 0.004398345947265625, 'loss_3': -16.361330032348633, 'loss_4': 1.4113359451293945, 'epoch': 17.91}
{'loss': 0.0141, 'grad_norm': 5.160037040710449, 'learning_rate': 1.2104651162790697e-05, 'loss_1': 0.004320517648011446, 'loss_2': 0.00982666015625, 'loss_3': -16.638957977294922, 'loss_4': 1.9367680549621582, 'epoch': 17.92}
{'loss': 0.0197, 'grad_norm': 5.415637969970703, 'learning_rate': 1.2098837209302327e-05, 'loss_1': 0.01507522165775299, 'loss_2': 0.004642486572265625, 'loss_3': -16.304763793945312, 'loss_4': 1.4029182195663452, 'epoch': 17.92}
{'loss': 0.0124, 'grad_norm': 5.343308448791504, 'learning_rate': 1.2093023255813954e-05, 'loss_1': 0.009528180584311485, 'loss_2': 0.002841949462890625, 'loss_3': -16.487207412719727, 'loss_4': 1.7691611051559448, 'epoch': 17.93}
{'loss': 0.0247, 'grad_norm': 12.924845695495605, 'learning_rate': 1.2087209302325583e-05, 'loss_1': 0.02275697886943817, 'loss_2': 0.0019130706787109375, 'loss_3': -16.31131935119629, 'loss_4': 1.9066264629364014, 'epoch': 17.94}
[INFO|trainer.py:4228] 2025-01-21 13:36:29,245 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:29,245 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                       | 3090/5160 [1:16:33<36:20,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:36:36,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016217615455389023, 'eval_runtime': 3.999, 'eval_samples_per_second': 256.062, 'eval_steps_per_second': 4.001, 'eval_loss_1': 0.010894324630498886, 'eval_loss_2': 0.005323290824890137, 'eval_loss_3': -18.13225555419922, 'eval_loss_4': 1.5139936208724976, 'epoch': 17.94}
{'loss': 0.0067, 'grad_norm': 4.506597518920898, 'learning_rate': 1.208139534883721e-05, 'loss_1': 0.004859733395278454, 'loss_2': 0.0018854141235351562, 'loss_3': -16.415130615234375, 'loss_4': 1.6139161586761475, 'epoch': 17.94}
{'loss': 0.0073, 'grad_norm': 4.925257682800293, 'learning_rate': 1.2075581395348837e-05, 'loss_1': 0.005177770741283894, 'loss_2': 0.00208282470703125, 'loss_3': -16.314268112182617, 'loss_4': 1.491686224937439, 'epoch': 17.95}
{'loss': 0.2453, 'grad_norm': 28.328323364257812, 'learning_rate': 1.2069767441860465e-05, 'loss_1': 0.24516119062900543, 'loss_2': 0.0001678466796875, 'loss_3': -16.34192657470703, 'loss_4': 1.995086431503296, 'epoch': 17.95}
{'loss': 0.0108, 'grad_norm': 4.669779300689697, 'learning_rate': 1.2063953488372094e-05, 'loss_1': 0.00689614238217473, 'loss_2': 0.0038814544677734375, 'loss_3': -16.48282814025879, 'loss_4': 1.931976079940796, 'epoch': 17.96}
{'loss': 0.0137, 'grad_norm': 9.965432167053223, 'learning_rate': 1.2058139534883722e-05, 'loss_1': 0.01061367429792881, 'loss_2': 0.003124237060546875, 'loss_3': -16.378631591796875, 'loss_4': 1.3320679664611816, 'epoch': 17.97}
[INFO|trainer.py:4228] 2025-01-21 13:36:36,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:36,795 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                       | 3095/5160 [1:16:41<35:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:44,150 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014359522610902786, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.646, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.010997223667800426, 'eval_loss_2': 0.003362298011779785, 'eval_loss_3': -18.1192626953125, 'eval_loss_4': 1.6957985162734985, 'epoch': 17.97}
{'loss': 0.0102, 'grad_norm': 6.172553539276123, 'learning_rate': 1.205232558139535e-05, 'loss_1': 0.010073253884911537, 'loss_2': 0.00016832351684570312, 'loss_3': -16.461517333984375, 'loss_4': 1.932210087776184, 'epoch': 17.97}
{'loss': 0.0051, 'grad_norm': 4.6070051193237305, 'learning_rate': 1.2046511627906976e-05, 'loss_1': 0.004087057430297136, 'loss_2': 0.001056671142578125, 'loss_3': -16.44403839111328, 'loss_4': 2.1309773921966553, 'epoch': 17.98}
{'loss': 0.0379, 'grad_norm': 15.670312881469727, 'learning_rate': 1.2040697674418605e-05, 'loss_1': 0.03365391120314598, 'loss_2': 0.00428009033203125, 'loss_3': -16.131027221679688, 'loss_4': 2.041313409805298, 'epoch': 17.98}
{'loss': 0.011, 'grad_norm': 5.592016696929932, 'learning_rate': 1.2034883720930232e-05, 'loss_1': 0.007175948470830917, 'loss_2': 0.003833770751953125, 'loss_3': -16.318775177001953, 'loss_4': 1.9042463302612305, 'epoch': 17.99}
{'loss': 0.0049, 'grad_norm': 4.7925920486450195, 'learning_rate': 1.2029069767441862e-05, 'loss_1': 0.004158706869930029, 'loss_2': 0.0006947517395019531, 'loss_3': -16.459299087524414, 'loss_4': 2.1514925956726074, 'epoch': 17.99}
[INFO|trainer.py:4228] 2025-01-21 13:36:44,151 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:44,151 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                       | 3100/5160 [1:16:48<35:01,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:36:51,224 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01574314758181572, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.521, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.013324716128408909, 'eval_loss_2': 0.0024184323847293854, 'eval_loss_3': -18.123966217041016, 'eval_loss_4': 1.8785228729248047, 'epoch': 17.99}
{'loss': 0.007, 'grad_norm': 6.373157501220703, 'learning_rate': 1.202325581395349e-05, 'loss_1': 0.004417243413627148, 'loss_2': 0.002544403076171875, 'loss_3': -16.356719970703125, 'loss_4': 1.9744915962219238, 'epoch': 18.0}
{'loss': 0.0252, 'grad_norm': 11.880231857299805, 'learning_rate': 1.2017441860465116e-05, 'loss_1': 0.01915646903216839, 'loss_2': 0.0060882568359375, 'loss_3': -16.224720001220703, 'loss_4': 2.370931625366211, 'epoch': 18.01}
{'loss': 0.0108, 'grad_norm': 5.139427185058594, 'learning_rate': 1.2011627906976745e-05, 'loss_1': 0.005393607076257467, 'loss_2': 0.00540924072265625, 'loss_3': -16.47100830078125, 'loss_4': 1.939070701599121, 'epoch': 18.01}
{'loss': 0.0151, 'grad_norm': 4.987553596496582, 'learning_rate': 1.2005813953488372e-05, 'loss_1': 0.006695807445794344, 'loss_2': 0.00836944580078125, 'loss_3': -16.309791564941406, 'loss_4': 1.9829561710357666, 'epoch': 18.02}
{'loss': 0.0111, 'grad_norm': 5.052989959716797, 'learning_rate': 1.2e-05, 'loss_1': 0.0046765925362706184, 'loss_2': 0.006420135498046875, 'loss_3': -16.302947998046875, 'loss_4': 2.0589890480041504, 'epoch': 18.02}
[INFO|trainer.py:4228] 2025-01-21 13:36:51,224 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:51,224 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                       | 3105/5160 [1:16:55<35:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:36:58,598 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0169861800968647, 'eval_runtime': 3.8174, 'eval_samples_per_second': 268.247, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.014781270176172256, 'eval_loss_2': 0.002204909920692444, 'eval_loss_3': -18.129545211791992, 'eval_loss_4': 1.8348381519317627, 'epoch': 18.02}
{'loss': 0.0097, 'grad_norm': 6.711629390716553, 'learning_rate': 1.1994186046511629e-05, 'loss_1': 0.006013581994920969, 'loss_2': 0.003650665283203125, 'loss_3': -16.53588104248047, 'loss_4': 1.378556489944458, 'epoch': 18.03}
{'loss': 0.0247, 'grad_norm': 13.143106460571289, 'learning_rate': 1.1988372093023256e-05, 'loss_1': 0.020359180867671967, 'loss_2': 0.00429534912109375, 'loss_3': -16.220760345458984, 'loss_4': 1.8194572925567627, 'epoch': 18.03}
{'loss': 0.0048, 'grad_norm': 4.768864154815674, 'learning_rate': 1.1982558139534885e-05, 'loss_1': 0.004635568708181381, 'loss_2': 0.0001996755599975586, 'loss_3': -16.51683807373047, 'loss_4': 1.9239639043807983, 'epoch': 18.04}
{'loss': 0.0193, 'grad_norm': 12.532768249511719, 'learning_rate': 1.1976744186046511e-05, 'loss_1': 0.014696397818624973, 'loss_2': 0.004608154296875, 'loss_3': -16.46290397644043, 'loss_4': 2.2269394397735596, 'epoch': 18.05}
{'loss': 0.0079, 'grad_norm': 4.915349006652832, 'learning_rate': 1.197093023255814e-05, 'loss_1': 0.006096198223531246, 'loss_2': 0.0017843246459960938, 'loss_3': -16.37653160095215, 'loss_4': 1.8920038938522339, 'epoch': 18.05}
[INFO|trainer.py:4228] 2025-01-21 13:36:58,598 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:36:58,598 >>   Batch size = 64
 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                       | 3110/5160 [1:17:03<35:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:05,964 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016958922147750854, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.929, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.013116954825818539, 'eval_loss_2': 0.003841966390609741, 'eval_loss_3': -18.158275604248047, 'eval_loss_4': 1.8387982845306396, 'epoch': 18.05}
{'loss': 0.0087, 'grad_norm': 4.466874122619629, 'learning_rate': 1.1965116279069767e-05, 'loss_1': 0.0034159114584326744, 'loss_2': 0.00525665283203125, 'loss_3': -16.375364303588867, 'loss_4': 2.2324323654174805, 'epoch': 18.06}
{'loss': 0.0106, 'grad_norm': 7.409613132476807, 'learning_rate': 1.1959302325581396e-05, 'loss_1': 0.009330320172011852, 'loss_2': 0.0013074874877929688, 'loss_3': -16.19664764404297, 'loss_4': 1.8557852506637573, 'epoch': 18.06}
{'loss': 0.0058, 'grad_norm': 4.333866119384766, 'learning_rate': 1.1953488372093024e-05, 'loss_1': 0.004452485591173172, 'loss_2': 0.001384735107421875, 'loss_3': -16.43376922607422, 'loss_4': 1.5981290340423584, 'epoch': 18.07}
{'loss': 0.0083, 'grad_norm': 4.925400257110596, 'learning_rate': 1.1947674418604651e-05, 'loss_1': 0.007278622128069401, 'loss_2': 0.0010166168212890625, 'loss_3': -16.263967514038086, 'loss_4': 2.010927677154541, 'epoch': 18.08}
{'loss': 0.0175, 'grad_norm': 6.832740783691406, 'learning_rate': 1.194186046511628e-05, 'loss_1': 0.012032561004161835, 'loss_2': 0.005481719970703125, 'loss_3': -16.490283966064453, 'loss_4': 2.3241140842437744, 'epoch': 18.08}
[INFO|trainer.py:4228] 2025-01-21 13:37:05,964 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:05,965 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                      | 3115/5160 [1:17:10<35:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:13,334 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013285407796502113, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.586, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010689625516533852, 'eval_loss_2': 0.0025957822799682617, 'eval_loss_3': -18.168386459350586, 'eval_loss_4': 1.8264219760894775, 'epoch': 18.08}
{'loss': 0.0168, 'grad_norm': 7.99243688583374, 'learning_rate': 1.1936046511627907e-05, 'loss_1': 0.01209901925176382, 'loss_2': 0.0046539306640625, 'loss_3': -16.30995750427246, 'loss_4': 2.0142931938171387, 'epoch': 18.09}
{'loss': 0.0121, 'grad_norm': 4.609930515289307, 'learning_rate': 1.1930232558139534e-05, 'loss_1': 0.0064189075492322445, 'loss_2': 0.005634307861328125, 'loss_3': -16.480472564697266, 'loss_4': 1.845101237297058, 'epoch': 18.09}
{'loss': 0.0053, 'grad_norm': 4.67084264755249, 'learning_rate': 1.1924418604651164e-05, 'loss_1': 0.003958840388804674, 'loss_2': 0.0013484954833984375, 'loss_3': -16.680896759033203, 'loss_4': 2.1926612854003906, 'epoch': 18.1}
{'loss': 0.0159, 'grad_norm': 9.090439796447754, 'learning_rate': 1.1918604651162791e-05, 'loss_1': 0.011334247887134552, 'loss_2': 0.004608154296875, 'loss_3': -16.590700149536133, 'loss_4': 2.080075740814209, 'epoch': 18.1}
{'loss': 0.0118, 'grad_norm': 10.353775978088379, 'learning_rate': 1.191279069767442e-05, 'loss_1': 0.011757145635783672, 'loss_2': 2.962350845336914e-05, 'loss_3': -16.487987518310547, 'loss_4': 2.2398252487182617, 'epoch': 18.11}
[INFO|trainer.py:4228] 2025-01-21 13:37:13,334 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:13,334 >>   Batch size = 64
 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                      | 3120/5160 [1:17:17<35:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:20,690 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015618334524333477, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.965, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.012178551405668259, 'eval_loss_2': 0.003439784049987793, 'eval_loss_3': -18.179140090942383, 'eval_loss_4': 1.8000571727752686, 'epoch': 18.11}
{'loss': 0.0129, 'grad_norm': 6.2554426193237305, 'learning_rate': 1.1906976744186047e-05, 'loss_1': 0.009794908575713634, 'loss_2': 0.00313568115234375, 'loss_3': -16.56732749938965, 'loss_4': 2.052565574645996, 'epoch': 18.12}
{'loss': 0.0181, 'grad_norm': 5.919094562530518, 'learning_rate': 1.1901162790697675e-05, 'loss_1': 0.010926750488579273, 'loss_2': 0.007171630859375, 'loss_3': -16.385202407836914, 'loss_4': 1.943871259689331, 'epoch': 18.12}
{'loss': 0.0097, 'grad_norm': 4.96515417098999, 'learning_rate': 1.1895348837209302e-05, 'loss_1': 0.007961912080645561, 'loss_2': 0.0017833709716796875, 'loss_3': -16.42795181274414, 'loss_4': 1.8043491840362549, 'epoch': 18.13}
{'loss': 0.013, 'grad_norm': 8.150559425354004, 'learning_rate': 1.188953488372093e-05, 'loss_1': 0.012612572871148586, 'loss_2': 0.00034308433532714844, 'loss_3': -16.411937713623047, 'loss_4': 2.1444311141967773, 'epoch': 18.13}
{'loss': 0.0312, 'grad_norm': 15.44793701171875, 'learning_rate': 1.188372093023256e-05, 'loss_1': 0.028704101219773293, 'loss_2': 0.002498626708984375, 'loss_3': -16.199913024902344, 'loss_4': 1.7380077838897705, 'epoch': 18.14}
[INFO|trainer.py:4228] 2025-01-21 13:37:20,690 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:20,690 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 3125/5160 [1:17:25<35:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:28,055 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013857206329703331, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.892, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009516853839159012, 'eval_loss_2': 0.00434035062789917, 'eval_loss_3': -18.167766571044922, 'eval_loss_4': 1.6626932621002197, 'epoch': 18.14}
{'loss': 0.0121, 'grad_norm': 5.7738447189331055, 'learning_rate': 1.1877906976744186e-05, 'loss_1': 0.006833263207226992, 'loss_2': 0.00530242919921875, 'loss_3': -16.59218978881836, 'loss_4': 1.4711344242095947, 'epoch': 18.15}
{'loss': 0.0075, 'grad_norm': 5.614321231842041, 'learning_rate': 1.1872093023255815e-05, 'loss_1': 0.005959395319223404, 'loss_2': 0.001491546630859375, 'loss_3': -16.563976287841797, 'loss_4': 1.1450204849243164, 'epoch': 18.15}
{'loss': 0.017, 'grad_norm': 7.606696605682373, 'learning_rate': 1.1866279069767442e-05, 'loss_1': 0.01503970380872488, 'loss_2': 0.0019435882568359375, 'loss_3': -16.565975189208984, 'loss_4': 1.9624354839324951, 'epoch': 18.16}
{'loss': 0.0097, 'grad_norm': 4.716668128967285, 'learning_rate': 1.1860465116279069e-05, 'loss_1': 0.006242460571229458, 'loss_2': 0.003482818603515625, 'loss_3': -16.359987258911133, 'loss_4': 1.7130602598190308, 'epoch': 18.16}
{'loss': 0.0116, 'grad_norm': 5.621255397796631, 'learning_rate': 1.18546511627907e-05, 'loss_1': 0.005822247825562954, 'loss_2': 0.00582122802734375, 'loss_3': -16.523242950439453, 'loss_4': 1.038670539855957, 'epoch': 18.17}
[INFO|trainer.py:4228] 2025-01-21 13:37:28,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:28,055 >>   Batch size = 64
 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                      | 3130/5160 [1:17:32<35:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:35,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01170321274548769, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.605, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007495871279388666, 'eval_loss_2': 0.004207342863082886, 'eval_loss_3': -18.16794204711914, 'eval_loss_4': 1.5104944705963135, 'epoch': 18.17}
{'loss': 0.02, 'grad_norm': 9.523832321166992, 'learning_rate': 1.1848837209302326e-05, 'loss_1': 0.013331507332623005, 'loss_2': 0.00667572021484375, 'loss_3': -16.321857452392578, 'loss_4': 1.6278667449951172, 'epoch': 18.17}
{'loss': 0.0077, 'grad_norm': 4.936150550842285, 'learning_rate': 1.1843023255813955e-05, 'loss_1': 0.006907586008310318, 'loss_2': 0.000751495361328125, 'loss_3': -16.443607330322266, 'loss_4': 1.6938703060150146, 'epoch': 18.18}
{'loss': 0.0165, 'grad_norm': 5.410136699676514, 'learning_rate': 1.1837209302325582e-05, 'loss_1': 0.009052230045199394, 'loss_2': 0.007415771484375, 'loss_3': -16.437299728393555, 'loss_4': 1.2244069576263428, 'epoch': 18.19}
{'loss': 0.0186, 'grad_norm': 9.61127758026123, 'learning_rate': 1.1831395348837209e-05, 'loss_1': 0.015494566410779953, 'loss_2': 0.003078460693359375, 'loss_3': -16.379310607910156, 'loss_4': 1.5213288068771362, 'epoch': 18.19}
{'loss': 0.0072, 'grad_norm': 6.331692218780518, 'learning_rate': 1.1825581395348837e-05, 'loss_1': 0.006694828625768423, 'loss_2': 0.0005159378051757812, 'loss_3': -16.373565673828125, 'loss_4': 1.240410327911377, 'epoch': 18.2}
[INFO|trainer.py:4228] 2025-01-21 13:37:35,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:35,418 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                      | 3135/5160 [1:17:39<35:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:42,786 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009942324832081795, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.41, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006846477277576923, 'eval_loss_2': 0.0030958466231822968, 'eval_loss_3': -18.1768798828125, 'eval_loss_4': 1.4149818420410156, 'epoch': 18.2}
{'loss': 0.0089, 'grad_norm': 5.229942321777344, 'learning_rate': 1.1819767441860466e-05, 'loss_1': 0.007014323491603136, 'loss_2': 0.001926422119140625, 'loss_3': -16.371749877929688, 'loss_4': 1.8289068937301636, 'epoch': 18.2}
{'loss': 0.0048, 'grad_norm': 4.652515411376953, 'learning_rate': 1.1813953488372095e-05, 'loss_1': 0.0037240313831716776, 'loss_2': 0.001064300537109375, 'loss_3': -16.271289825439453, 'loss_4': 1.5646510124206543, 'epoch': 18.21}
{'loss': 0.017, 'grad_norm': 4.6922197341918945, 'learning_rate': 1.1808139534883721e-05, 'loss_1': 0.003857842879369855, 'loss_2': 0.01319122314453125, 'loss_3': -16.533462524414062, 'loss_4': 1.1267659664154053, 'epoch': 18.22}
{'loss': 0.0238, 'grad_norm': 8.209807395935059, 'learning_rate': 1.1802325581395348e-05, 'loss_1': 0.017678167670965195, 'loss_2': 0.006134033203125, 'loss_3': -16.389904022216797, 'loss_4': 1.589793086051941, 'epoch': 18.22}
{'loss': 0.0224, 'grad_norm': 6.665871620178223, 'learning_rate': 1.1796511627906977e-05, 'loss_1': 0.012084918096661568, 'loss_2': 0.01031494140625, 'loss_3': -16.50701141357422, 'loss_4': 1.6206345558166504, 'epoch': 18.23}
[INFO|trainer.py:4228] 2025-01-21 13:37:42,786 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:42,786 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 3140/5160 [1:17:47<35:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:50,146 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011815274134278297, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.854, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006548518314957619, 'eval_loss_2': 0.005266755819320679, 'eval_loss_3': -18.19278335571289, 'eval_loss_4': 1.3884010314941406, 'epoch': 18.23}
{'loss': 0.008, 'grad_norm': 5.194828033447266, 'learning_rate': 1.1790697674418604e-05, 'loss_1': 0.007310397922992706, 'loss_2': 0.000682830810546875, 'loss_3': -16.413511276245117, 'loss_4': 1.81010103225708, 'epoch': 18.23}
{'loss': 0.0105, 'grad_norm': 7.393856048583984, 'learning_rate': 1.1784883720930234e-05, 'loss_1': 0.00725886644795537, 'loss_2': 0.003204345703125, 'loss_3': -16.34760284423828, 'loss_4': 1.5990142822265625, 'epoch': 18.24}
{'loss': 0.0162, 'grad_norm': 5.990083694458008, 'learning_rate': 1.1779069767441861e-05, 'loss_1': 0.005065385717898607, 'loss_2': 0.0110931396484375, 'loss_3': -16.491613388061523, 'loss_4': 1.0488431453704834, 'epoch': 18.24}
{'loss': 0.0078, 'grad_norm': 5.741559028625488, 'learning_rate': 1.1773255813953488e-05, 'loss_1': 0.006181903649121523, 'loss_2': 0.0015850067138671875, 'loss_3': -16.43486213684082, 'loss_4': 1.7557296752929688, 'epoch': 18.25}
{'loss': 0.0052, 'grad_norm': 4.942863464355469, 'learning_rate': 1.1767441860465117e-05, 'loss_1': 0.004781943280249834, 'loss_2': 0.000446319580078125, 'loss_3': -16.654708862304688, 'loss_4': 1.7818342447280884, 'epoch': 18.26}
[INFO|trainer.py:4228] 2025-01-21 13:37:50,146 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:50,146 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                     | 3145/5160 [1:17:54<34:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:37:57,511 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011336359195411205, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007668907754123211, 'eval_loss_2': 0.0036674514412879944, 'eval_loss_3': -18.22300148010254, 'eval_loss_4': 1.289084792137146, 'epoch': 18.26}
{'loss': 0.009, 'grad_norm': 4.9524688720703125, 'learning_rate': 1.1761627906976744e-05, 'loss_1': 0.005025437567383051, 'loss_2': 0.003948211669921875, 'loss_3': -16.41259002685547, 'loss_4': 1.6068660020828247, 'epoch': 18.26}
{'loss': 0.013, 'grad_norm': 5.432461261749268, 'learning_rate': 1.1755813953488372e-05, 'loss_1': 0.0056185293942689896, 'loss_2': 0.00736236572265625, 'loss_3': -16.292184829711914, 'loss_4': 1.0445778369903564, 'epoch': 18.27}
{'loss': 0.0199, 'grad_norm': 11.483149528503418, 'learning_rate': 1.1750000000000001e-05, 'loss_1': 0.01881266012787819, 'loss_2': 0.001056671142578125, 'loss_3': -16.59030532836914, 'loss_4': 1.7598854303359985, 'epoch': 18.27}
{'loss': 0.0147, 'grad_norm': 6.397875785827637, 'learning_rate': 1.1744186046511628e-05, 'loss_1': 0.01132678147405386, 'loss_2': 0.003368377685546875, 'loss_3': -16.491912841796875, 'loss_4': 1.5380983352661133, 'epoch': 18.28}
{'loss': 0.0077, 'grad_norm': 4.799464225769043, 'learning_rate': 1.1738372093023257e-05, 'loss_1': 0.005233373027294874, 'loss_2': 0.00251007080078125, 'loss_3': -16.506542205810547, 'loss_4': 1.539790391921997, 'epoch': 18.28}
[INFO|trainer.py:4228] 2025-01-21 13:37:57,511 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:37:57,511 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                     | 3150/5160 [1:18:02<34:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:04,880 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012547779828310013, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.912, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008265572600066662, 'eval_loss_2': 0.004282206296920776, 'eval_loss_3': -18.23017120361328, 'eval_loss_4': 1.153055191040039, 'epoch': 18.28}
{'loss': 0.007, 'grad_norm': 6.738651752471924, 'learning_rate': 1.1732558139534884e-05, 'loss_1': 0.005651583429425955, 'loss_2': 0.0013132095336914062, 'loss_3': -16.502296447753906, 'loss_4': 1.0305626392364502, 'epoch': 18.29}
{'loss': 0.0181, 'grad_norm': 5.404337406158447, 'learning_rate': 1.1726744186046512e-05, 'loss_1': 0.006510212551802397, 'loss_2': 0.011627197265625, 'loss_3': -16.333202362060547, 'loss_4': 0.8962836265563965, 'epoch': 18.3}
{'loss': 0.0114, 'grad_norm': 5.4999871253967285, 'learning_rate': 1.1720930232558139e-05, 'loss_1': 0.00843534991145134, 'loss_2': 0.0030117034912109375, 'loss_3': -16.504310607910156, 'loss_4': 0.6949551701545715, 'epoch': 18.3}
{'loss': 0.0091, 'grad_norm': 5.140006065368652, 'learning_rate': 1.171511627906977e-05, 'loss_1': 0.007458323147147894, 'loss_2': 0.001682281494140625, 'loss_3': -16.341272354125977, 'loss_4': 1.2103568315505981, 'epoch': 18.31}
{'loss': 0.0108, 'grad_norm': 5.885232448577881, 'learning_rate': 1.1709302325581396e-05, 'loss_1': 0.008652451448142529, 'loss_2': 0.0021305084228515625, 'loss_3': -16.487953186035156, 'loss_4': 1.4839528799057007, 'epoch': 18.31}
[INFO|trainer.py:4228] 2025-01-21 13:38:04,880 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:04,880 >>   Batch size = 64
 61%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                     | 3155/5160 [1:18:09<34:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:12,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01231803372502327, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.122, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.008479680866003036, 'eval_loss_2': 0.003838352859020233, 'eval_loss_3': -18.215774536132812, 'eval_loss_4': 1.0845760107040405, 'epoch': 18.31}
{'loss': 0.0075, 'grad_norm': 4.259232044219971, 'learning_rate': 1.1703488372093023e-05, 'loss_1': 0.004641063045710325, 'loss_2': 0.002864837646484375, 'loss_3': -16.53316879272461, 'loss_4': 1.5204050540924072, 'epoch': 18.32}
{'loss': 0.0106, 'grad_norm': 4.772945404052734, 'learning_rate': 1.1697674418604652e-05, 'loss_1': 0.003518748329952359, 'loss_2': 0.007076263427734375, 'loss_3': -16.559284210205078, 'loss_4': 1.288020133972168, 'epoch': 18.33}
{'loss': 0.0104, 'grad_norm': 5.116903305053711, 'learning_rate': 1.1691860465116279e-05, 'loss_1': 0.005684421863406897, 'loss_2': 0.00467681884765625, 'loss_3': -16.41884994506836, 'loss_4': 1.1233470439910889, 'epoch': 18.33}
{'loss': 0.0261, 'grad_norm': 15.243471145629883, 'learning_rate': 1.1686046511627907e-05, 'loss_1': 0.024086637422442436, 'loss_2': 0.0020046234130859375, 'loss_3': -16.34931755065918, 'loss_4': 1.3340542316436768, 'epoch': 18.34}
{'loss': 0.0107, 'grad_norm': 4.57228946685791, 'learning_rate': 1.1680232558139536e-05, 'loss_1': 0.004717860370874405, 'loss_2': 0.00594329833984375, 'loss_3': -16.495319366455078, 'loss_4': 1.2749531269073486, 'epoch': 18.34}
[INFO|trainer.py:4228] 2025-01-21 13:38:12,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:12,241 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 3160/5160 [1:18:16<34:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:19,617 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010913264006376266, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.286, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.0076370094902813435, 'eval_loss_2': 0.0032762549817562103, 'eval_loss_3': -18.194766998291016, 'eval_loss_4': 1.1457912921905518, 'epoch': 18.34}
{'loss': 0.0086, 'grad_norm': 4.945300102233887, 'learning_rate': 1.1674418604651163e-05, 'loss_1': 0.007493179757148027, 'loss_2': 0.0010890960693359375, 'loss_3': -16.428829193115234, 'loss_4': 1.108526587486267, 'epoch': 18.35}
{'loss': 0.0139, 'grad_norm': 6.109433650970459, 'learning_rate': 1.1668604651162792e-05, 'loss_1': 0.0094338059425354, 'loss_2': 0.00447845458984375, 'loss_3': -16.430578231811523, 'loss_4': 1.2855076789855957, 'epoch': 18.35}
{'loss': 0.0071, 'grad_norm': 5.217171669006348, 'learning_rate': 1.1662790697674419e-05, 'loss_1': 0.005199402570724487, 'loss_2': 0.0019235610961914062, 'loss_3': -16.531700134277344, 'loss_4': 1.0409822463989258, 'epoch': 18.36}
{'loss': 0.0228, 'grad_norm': 8.172530174255371, 'learning_rate': 1.1656976744186047e-05, 'loss_1': 0.015271153301000595, 'loss_2': 0.00757598876953125, 'loss_3': -16.67498016357422, 'loss_4': 1.3389077186584473, 'epoch': 18.37}
{'loss': 0.015, 'grad_norm': 4.856907367706299, 'learning_rate': 1.1651162790697674e-05, 'loss_1': 0.009850298054516315, 'loss_2': 0.005146026611328125, 'loss_3': -16.46426010131836, 'loss_4': 1.6420913934707642, 'epoch': 18.37}
[INFO|trainer.py:4228] 2025-01-21 13:38:19,617 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:19,617 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                    | 3165/5160 [1:18:24<34:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:26,980 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00971332285553217, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006578738801181316, 'eval_loss_2': 0.003134585916996002, 'eval_loss_3': -18.189254760742188, 'eval_loss_4': 1.198529839515686, 'epoch': 18.37}
{'loss': 0.0065, 'grad_norm': 5.052501678466797, 'learning_rate': 1.1645348837209303e-05, 'loss_1': 0.0051655238494277, 'loss_2': 0.0013227462768554688, 'loss_3': -16.45828628540039, 'loss_4': 1.4065988063812256, 'epoch': 18.38}
{'loss': 0.0028, 'grad_norm': 4.516639232635498, 'learning_rate': 1.1639534883720931e-05, 'loss_1': 0.0027710224967449903, 'loss_2': 1.5795230865478516e-05, 'loss_3': -16.430727005004883, 'loss_4': 1.4886760711669922, 'epoch': 18.38}
{'loss': 0.0058, 'grad_norm': 4.491501331329346, 'learning_rate': 1.1633720930232558e-05, 'loss_1': 0.00453401543200016, 'loss_2': 0.0012521743774414062, 'loss_3': -16.411142349243164, 'loss_4': 0.9728595018386841, 'epoch': 18.39}
{'loss': 0.0058, 'grad_norm': 5.005100250244141, 'learning_rate': 1.1627906976744187e-05, 'loss_1': 0.004798480309545994, 'loss_2': 0.0010271072387695312, 'loss_3': -16.546607971191406, 'loss_4': 1.3540774583816528, 'epoch': 18.4}
{'loss': 0.0225, 'grad_norm': 15.629026412963867, 'learning_rate': 1.1622093023255814e-05, 'loss_1': 0.01734325662255287, 'loss_2': 0.00513458251953125, 'loss_3': -16.44794464111328, 'loss_4': 1.1033611297607422, 'epoch': 18.4}
[INFO|trainer.py:4228] 2025-01-21 13:38:26,981 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:26,981 >>   Batch size = 64
 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 3170/5160 [1:18:31<34:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:34,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00944493804126978, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.057, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006104817148298025, 'eval_loss_2': 0.0033401213586330414, 'eval_loss_3': -18.218217849731445, 'eval_loss_4': 1.1378065347671509, 'epoch': 18.4}
{'loss': 0.0067, 'grad_norm': 5.380066394805908, 'learning_rate': 1.1616279069767441e-05, 'loss_1': 0.006562376860529184, 'loss_2': 9.810924530029297e-05, 'loss_3': -16.510587692260742, 'loss_4': 1.0452425479888916, 'epoch': 18.41}
{'loss': 0.011, 'grad_norm': 5.506781578063965, 'learning_rate': 1.161046511627907e-05, 'loss_1': 0.007777479477226734, 'loss_2': 0.003177642822265625, 'loss_3': -16.314220428466797, 'loss_4': 1.3523178100585938, 'epoch': 18.41}
{'loss': 0.0117, 'grad_norm': 7.080857753753662, 'learning_rate': 1.1604651162790698e-05, 'loss_1': 0.007464900147169828, 'loss_2': 0.004253387451171875, 'loss_3': -16.27825164794922, 'loss_4': 1.2671599388122559, 'epoch': 18.42}
{'loss': 0.0076, 'grad_norm': 4.7301201820373535, 'learning_rate': 1.1598837209302327e-05, 'loss_1': 0.004056195262819529, 'loss_2': 0.0034961700439453125, 'loss_3': -16.439905166625977, 'loss_4': 1.3241859674453735, 'epoch': 18.42}
{'loss': 0.0098, 'grad_norm': 4.826889991760254, 'learning_rate': 1.1593023255813954e-05, 'loss_1': 0.004886528942734003, 'loss_2': 0.004932403564453125, 'loss_3': -16.452648162841797, 'loss_4': 1.5105725526809692, 'epoch': 18.43}
[INFO|trainer.py:4228] 2025-01-21 13:38:34,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:34,341 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                    | 3175/5160 [1:18:38<34:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:41,701 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011604821309447289, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.925, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0064056869596242905, 'eval_loss_2': 0.005199134349822998, 'eval_loss_3': -18.208110809326172, 'eval_loss_4': 1.2379896640777588, 'epoch': 18.43}
{'loss': 0.0126, 'grad_norm': 4.758269309997559, 'learning_rate': 1.158720930232558e-05, 'loss_1': 0.005444647278636694, 'loss_2': 0.007144927978515625, 'loss_3': -16.402406692504883, 'loss_4': 1.0435128211975098, 'epoch': 18.44}
{'loss': 0.0125, 'grad_norm': 4.490805149078369, 'learning_rate': 1.158139534883721e-05, 'loss_1': 0.0068314941599965096, 'loss_2': 0.00568389892578125, 'loss_3': -16.484901428222656, 'loss_4': 1.2059860229492188, 'epoch': 18.44}
{'loss': 0.0104, 'grad_norm': 5.3831305503845215, 'learning_rate': 1.1575581395348836e-05, 'loss_1': 0.008978251367807388, 'loss_2': 0.0014324188232421875, 'loss_3': -16.392467498779297, 'loss_4': 1.2511610984802246, 'epoch': 18.45}
{'loss': 0.0162, 'grad_norm': 11.319509506225586, 'learning_rate': 1.1569767441860467e-05, 'loss_1': 0.01361724454909563, 'loss_2': 0.002567291259765625, 'loss_3': -16.408451080322266, 'loss_4': 1.3252089023590088, 'epoch': 18.45}
{'loss': 0.0129, 'grad_norm': 6.213372707366943, 'learning_rate': 1.1563953488372094e-05, 'loss_1': 0.011893542483448982, 'loss_2': 0.0010223388671875, 'loss_3': -16.47479820251465, 'loss_4': 1.011315941810608, 'epoch': 18.46}
[INFO|trainer.py:4228] 2025-01-21 13:38:41,701 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:41,701 >>   Batch size = 64
 62%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                    | 3180/5160 [1:18:46<34:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:49,060 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011399311944842339, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.756, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006378900725394487, 'eval_loss_2': 0.005020409822463989, 'eval_loss_3': -18.205646514892578, 'eval_loss_4': 1.3852097988128662, 'epoch': 18.46}
{'loss': 0.0079, 'grad_norm': 7.516744613647461, 'learning_rate': 1.155813953488372e-05, 'loss_1': 0.006094607524573803, 'loss_2': 0.0018482208251953125, 'loss_3': -16.57534408569336, 'loss_4': 1.3633253574371338, 'epoch': 18.47}
{'loss': 0.0061, 'grad_norm': 4.815237522125244, 'learning_rate': 1.1552325581395349e-05, 'loss_1': 0.00498579116538167, 'loss_2': 0.001125335693359375, 'loss_3': -16.431503295898438, 'loss_4': 1.6254057884216309, 'epoch': 18.47}
{'loss': 0.0079, 'grad_norm': 5.535638809204102, 'learning_rate': 1.1546511627906976e-05, 'loss_1': 0.006958688609302044, 'loss_2': 0.0009274482727050781, 'loss_3': -16.488616943359375, 'loss_4': 1.566051721572876, 'epoch': 18.48}
{'loss': 0.069, 'grad_norm': 16.217912673950195, 'learning_rate': 1.1540697674418605e-05, 'loss_1': 0.06484787166118622, 'loss_2': 0.004119873046875, 'loss_3': -16.58818817138672, 'loss_4': 2.303365707397461, 'epoch': 18.48}
{'loss': 0.015, 'grad_norm': 5.505423069000244, 'learning_rate': 1.1534883720930233e-05, 'loss_1': 0.011508632451295853, 'loss_2': 0.00350189208984375, 'loss_3': -16.342044830322266, 'loss_4': 1.432182788848877, 'epoch': 18.49}
[INFO|trainer.py:4228] 2025-01-21 13:38:49,060 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:49,061 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                   | 3185/5160 [1:18:53<34:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:38:56,429 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011630082502961159, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006404484622180462, 'eval_loss_2': 0.0052255988121032715, 'eval_loss_3': -18.214296340942383, 'eval_loss_4': 1.4669758081436157, 'epoch': 18.49}
{'loss': 0.0122, 'grad_norm': 5.760193347930908, 'learning_rate': 1.1529069767441862e-05, 'loss_1': 0.0067510115914046764, 'loss_2': 0.00548553466796875, 'loss_3': -16.49892807006836, 'loss_4': 1.6977695226669312, 'epoch': 18.49}
{'loss': 0.0155, 'grad_norm': 5.702483177185059, 'learning_rate': 1.1523255813953489e-05, 'loss_1': 0.007902992889285088, 'loss_2': 0.007640838623046875, 'loss_3': -16.513389587402344, 'loss_4': 1.5032157897949219, 'epoch': 18.5}
{'loss': 0.0098, 'grad_norm': 5.55450439453125, 'learning_rate': 1.1517441860465116e-05, 'loss_1': 0.006306161172688007, 'loss_2': 0.003536224365234375, 'loss_3': -16.512575149536133, 'loss_4': 2.057914972305298, 'epoch': 18.51}
{'loss': 0.0238, 'grad_norm': 5.900965213775635, 'learning_rate': 1.1511627906976744e-05, 'loss_1': 0.014060097746551037, 'loss_2': 0.00978851318359375, 'loss_3': -16.39645004272461, 'loss_4': 1.239436149597168, 'epoch': 18.51}
{'loss': 0.0125, 'grad_norm': 5.420790195465088, 'learning_rate': 1.1505813953488371e-05, 'loss_1': 0.006018126383423805, 'loss_2': 0.006458282470703125, 'loss_3': -16.637165069580078, 'loss_4': 1.5950068235397339, 'epoch': 18.52}
[INFO|trainer.py:4228] 2025-01-21 13:38:56,429 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:38:56,429 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                   | 3190/5160 [1:19:00<34:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:03,803 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011074420064687729, 'eval_runtime': 3.8181, 'eval_samples_per_second': 268.195, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.006538625806570053, 'eval_loss_2': 0.004535794258117676, 'eval_loss_3': -18.20966148376465, 'eval_loss_4': 1.5107579231262207, 'epoch': 18.52}
{'loss': 0.0143, 'grad_norm': 6.447035789489746, 'learning_rate': 1.1500000000000002e-05, 'loss_1': 0.010839923284947872, 'loss_2': 0.003509521484375, 'loss_3': -16.576915740966797, 'loss_4': 1.6376843452453613, 'epoch': 18.52}
{'loss': 0.0679, 'grad_norm': 19.25126838684082, 'learning_rate': 1.1494186046511629e-05, 'loss_1': 0.05738348886370659, 'loss_2': 0.0105438232421875, 'loss_3': -16.55882453918457, 'loss_4': 1.5516417026519775, 'epoch': 18.53}
{'loss': 0.0162, 'grad_norm': 5.454622268676758, 'learning_rate': 1.1488372093023256e-05, 'loss_1': 0.007161944638937712, 'loss_2': 0.00905609130859375, 'loss_3': -16.63800048828125, 'loss_4': 1.8748879432678223, 'epoch': 18.53}
{'loss': 0.0159, 'grad_norm': 13.372615814208984, 'learning_rate': 1.1482558139534884e-05, 'loss_1': 0.013892182148993015, 'loss_2': 0.0019989013671875, 'loss_3': -16.635360717773438, 'loss_4': 1.555541753768921, 'epoch': 18.54}
{'loss': 0.0154, 'grad_norm': 5.478269577026367, 'learning_rate': 1.1476744186046511e-05, 'loss_1': 0.010284875519573689, 'loss_2': 0.005157470703125, 'loss_3': -16.65018653869629, 'loss_4': 1.6367392539978027, 'epoch': 18.55}
[INFO|trainer.py:4228] 2025-01-21 13:39:03,803 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:03,803 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 3195/5160 [1:19:08<34:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:11,169 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011501764878630638, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007075776811689138, 'eval_loss_2': 0.004425987601280212, 'eval_loss_3': -18.184513092041016, 'eval_loss_4': 1.7600550651550293, 'epoch': 18.55}
{'loss': 0.0264, 'grad_norm': 12.432653427124023, 'learning_rate': 1.147093023255814e-05, 'loss_1': 0.01770775392651558, 'loss_2': 0.0086517333984375, 'loss_3': -16.51247787475586, 'loss_4': 1.5805044174194336, 'epoch': 18.55}
{'loss': 0.0068, 'grad_norm': 5.028239727020264, 'learning_rate': 1.1465116279069768e-05, 'loss_1': 0.004318924155086279, 'loss_2': 0.0025005340576171875, 'loss_3': -16.53238296508789, 'loss_4': 1.5875641107559204, 'epoch': 18.56}
{'loss': 0.0116, 'grad_norm': 5.39499568939209, 'learning_rate': 1.1459302325581395e-05, 'loss_1': 0.007654812186956406, 'loss_2': 0.003910064697265625, 'loss_3': -16.640491485595703, 'loss_4': 1.922798991203308, 'epoch': 18.56}
{'loss': 0.0162, 'grad_norm': 8.24252986907959, 'learning_rate': 1.1453488372093024e-05, 'loss_1': 0.00971267931163311, 'loss_2': 0.00652313232421875, 'loss_3': -16.510005950927734, 'loss_4': 1.7190437316894531, 'epoch': 18.57}
{'loss': 0.0113, 'grad_norm': 5.484258651733398, 'learning_rate': 1.1447674418604651e-05, 'loss_1': 0.007438136730343103, 'loss_2': 0.003902435302734375, 'loss_3': -16.64922523498535, 'loss_4': 1.927945613861084, 'epoch': 18.58}
[INFO|trainer.py:4228] 2025-01-21 13:39:11,169 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:11,169 >>   Batch size = 64
 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                   | 3200/5160 [1:19:15<33:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:18,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012401213869452477, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008100448176264763, 'eval_loss_2': 0.004300765693187714, 'eval_loss_3': -18.166950225830078, 'eval_loss_4': 1.97296142578125, 'epoch': 18.58}
{'loss': 0.0111, 'grad_norm': 5.0116963386535645, 'learning_rate': 1.144186046511628e-05, 'loss_1': 0.007155639585107565, 'loss_2': 0.00395965576171875, 'loss_3': -16.638916015625, 'loss_4': 1.8974367380142212, 'epoch': 18.58}
{'loss': 0.0141, 'grad_norm': 5.23632287979126, 'learning_rate': 1.1436046511627906e-05, 'loss_1': 0.01169003825634718, 'loss_2': 0.00238800048828125, 'loss_3': -16.458145141601562, 'loss_4': 2.128484010696411, 'epoch': 18.59}
{'loss': 0.0116, 'grad_norm': 5.2649407386779785, 'learning_rate': 1.1430232558139535e-05, 'loss_1': 0.007143471855670214, 'loss_2': 0.00447845458984375, 'loss_3': -16.790523529052734, 'loss_4': 1.9447402954101562, 'epoch': 18.59}
{'loss': 0.0158, 'grad_norm': 6.017734527587891, 'learning_rate': 1.1424418604651164e-05, 'loss_1': 0.011945024132728577, 'loss_2': 0.0038299560546875, 'loss_3': -16.494678497314453, 'loss_4': 1.9459192752838135, 'epoch': 18.6}
{'loss': 0.0157, 'grad_norm': 6.535030841827393, 'learning_rate': 1.141860465116279e-05, 'loss_1': 0.00994623638689518, 'loss_2': 0.00579071044921875, 'loss_3': -16.591564178466797, 'loss_4': 1.7935831546783447, 'epoch': 18.6}
[INFO|trainer.py:4228] 2025-01-21 13:39:18,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:18,530 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                   | 3205/5160 [1:19:23<33:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:25,889 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012982867658138275, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.926, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008493668399751186, 'eval_loss_2': 0.004489198327064514, 'eval_loss_3': -18.144800186157227, 'eval_loss_4': 2.0226378440856934, 'epoch': 18.6}
{'loss': 0.069, 'grad_norm': 23.455947875976562, 'learning_rate': 1.141279069767442e-05, 'loss_1': 0.06788410246372223, 'loss_2': 0.0011653900146484375, 'loss_3': -16.32952880859375, 'loss_4': 2.220025062561035, 'epoch': 18.61}
{'loss': 0.0209, 'grad_norm': 8.933591842651367, 'learning_rate': 1.1406976744186046e-05, 'loss_1': 0.013056463561952114, 'loss_2': 0.00780487060546875, 'loss_3': -16.609195709228516, 'loss_4': 1.9490574598312378, 'epoch': 18.62}
{'loss': 0.0112, 'grad_norm': 5.698884963989258, 'learning_rate': 1.1401162790697673e-05, 'loss_1': 0.01033802516758442, 'loss_2': 0.0008535385131835938, 'loss_3': -16.4613037109375, 'loss_4': 2.2663168907165527, 'epoch': 18.62}
{'loss': 0.0086, 'grad_norm': 5.657236576080322, 'learning_rate': 1.1395348837209304e-05, 'loss_1': 0.006455809809267521, 'loss_2': 0.0021877288818359375, 'loss_3': -16.519887924194336, 'loss_4': 1.6766328811645508, 'epoch': 18.63}
{'loss': 0.0173, 'grad_norm': 6.679392337799072, 'learning_rate': 1.138953488372093e-05, 'loss_1': 0.011986769735813141, 'loss_2': 0.0053253173828125, 'loss_3': -16.60694122314453, 'loss_4': 2.01231050491333, 'epoch': 18.63}
[INFO|trainer.py:4228] 2025-01-21 13:39:25,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:25,889 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                  | 3210/5160 [1:19:30<33:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:33,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013822372071444988, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.831, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.010201151482760906, 'eval_loss_2': 0.003621220588684082, 'eval_loss_3': -18.150638580322266, 'eval_loss_4': 2.0913283824920654, 'epoch': 18.63}
{'loss': 0.0192, 'grad_norm': 8.859783172607422, 'learning_rate': 1.1383720930232559e-05, 'loss_1': 0.015837296843528748, 'loss_2': 0.00334930419921875, 'loss_3': -16.455486297607422, 'loss_4': 2.3040099143981934, 'epoch': 18.64}
{'loss': 0.0156, 'grad_norm': 6.457885265350342, 'learning_rate': 1.1377906976744186e-05, 'loss_1': 0.014983274973928928, 'loss_2': 0.0006456375122070312, 'loss_3': -16.643033981323242, 'loss_4': 2.1175951957702637, 'epoch': 18.65}
{'loss': 0.0158, 'grad_norm': 5.25528621673584, 'learning_rate': 1.1372093023255813e-05, 'loss_1': 0.0067530241794884205, 'loss_2': 0.00909423828125, 'loss_3': -16.492475509643555, 'loss_4': 1.80377197265625, 'epoch': 18.65}
{'loss': 0.0094, 'grad_norm': 4.871204376220703, 'learning_rate': 1.1366279069767442e-05, 'loss_1': 0.005504155531525612, 'loss_2': 0.003894805908203125, 'loss_3': -16.383926391601562, 'loss_4': 2.220519781112671, 'epoch': 18.66}
{'loss': 0.01, 'grad_norm': 5.141695499420166, 'learning_rate': 1.136046511627907e-05, 'loss_1': 0.008271720260381699, 'loss_2': 0.0017242431640625, 'loss_3': -16.415679931640625, 'loss_4': 2.027625322341919, 'epoch': 18.66}
[INFO|trainer.py:4228] 2025-01-21 13:39:33,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:33,250 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                  | 3215/5160 [1:19:37<33:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:40,620 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015192234888672829, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.482, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.010902070440351963, 'eval_loss_2': 0.004290163516998291, 'eval_loss_3': -18.144094467163086, 'eval_loss_4': 2.045258045196533, 'epoch': 18.66}
{'loss': 0.0121, 'grad_norm': 4.607504844665527, 'learning_rate': 1.1354651162790699e-05, 'loss_1': 0.004020156338810921, 'loss_2': 0.0080413818359375, 'loss_3': -16.580303192138672, 'loss_4': 1.8522894382476807, 'epoch': 18.67}
{'loss': 0.0195, 'grad_norm': 5.669191837310791, 'learning_rate': 1.1348837209302326e-05, 'loss_1': 0.009082596749067307, 'loss_2': 0.01045989990234375, 'loss_3': -16.569297790527344, 'loss_4': 1.7423105239868164, 'epoch': 18.67}
{'loss': 0.0041, 'grad_norm': 4.756230354309082, 'learning_rate': 1.1343023255813954e-05, 'loss_1': 0.003931619226932526, 'loss_2': 0.00017881393432617188, 'loss_3': -16.6782169342041, 'loss_4': 2.2301979064941406, 'epoch': 18.68}
{'loss': 0.0129, 'grad_norm': 5.072549819946289, 'learning_rate': 1.1337209302325581e-05, 'loss_1': 0.0073479595594108105, 'loss_2': 0.005580902099609375, 'loss_3': -16.44460105895996, 'loss_4': 2.3327879905700684, 'epoch': 18.69}
{'loss': 0.0164, 'grad_norm': 5.374186992645264, 'learning_rate': 1.1331395348837208e-05, 'loss_1': 0.006511752028018236, 'loss_2': 0.00991058349609375, 'loss_3': -16.521085739135742, 'loss_4': 2.139491081237793, 'epoch': 18.69}
[INFO|trainer.py:4228] 2025-01-21 13:39:40,620 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:40,620 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                  | 3220/5160 [1:19:45<33:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:47,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01920565590262413, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.78, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.010666634887456894, 'eval_loss_2': 0.008539021015167236, 'eval_loss_3': -18.117610931396484, 'eval_loss_4': 1.9946691989898682, 'epoch': 18.69}
{'loss': 0.0095, 'grad_norm': 4.676364421844482, 'learning_rate': 1.1325581395348839e-05, 'loss_1': 0.002435049507766962, 'loss_2': 0.007076263427734375, 'loss_3': -16.38188362121582, 'loss_4': 2.1067938804626465, 'epoch': 18.7}
{'loss': 0.008, 'grad_norm': 4.706625461578369, 'learning_rate': 1.1319767441860466e-05, 'loss_1': 0.003493552329018712, 'loss_2': 0.004474639892578125, 'loss_3': -16.51927947998047, 'loss_4': 2.387075901031494, 'epoch': 18.7}
{'loss': 0.0134, 'grad_norm': 4.98568868637085, 'learning_rate': 1.1313953488372094e-05, 'loss_1': 0.004707263316959143, 'loss_2': 0.00872039794921875, 'loss_3': -16.41566276550293, 'loss_4': 1.6450644731521606, 'epoch': 18.71}
{'loss': 0.0166, 'grad_norm': 10.296995162963867, 'learning_rate': 1.1308139534883721e-05, 'loss_1': 0.014668121002614498, 'loss_2': 0.0018901824951171875, 'loss_3': -16.510631561279297, 'loss_4': 2.0079619884490967, 'epoch': 18.72}
{'loss': 0.0113, 'grad_norm': 6.6392011642456055, 'learning_rate': 1.1302325581395348e-05, 'loss_1': 0.006876828148961067, 'loss_2': 0.004375457763671875, 'loss_3': -16.40831756591797, 'loss_4': 1.7745314836502075, 'epoch': 18.72}
[INFO|trainer.py:4228] 2025-01-21 13:39:47,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:47,987 >>   Batch size = 64
 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                  | 3225/5160 [1:19:52<33:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:39:55,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017830871045589447, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.604, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010960360988974571, 'eval_loss_2': 0.0068705081939697266, 'eval_loss_3': -18.093402862548828, 'eval_loss_4': 1.8783740997314453, 'epoch': 18.72}
{'loss': 0.0089, 'grad_norm': 6.103648662567139, 'learning_rate': 1.1296511627906977e-05, 'loss_1': 0.007156106643378735, 'loss_2': 0.0017185211181640625, 'loss_3': -16.45000457763672, 'loss_4': 1.940036416053772, 'epoch': 18.73}
{'loss': 0.0117, 'grad_norm': 5.256279468536377, 'learning_rate': 1.1290697674418605e-05, 'loss_1': 0.009684172458946705, 'loss_2': 0.001983642578125, 'loss_3': -16.291961669921875, 'loss_4': 1.9070713520050049, 'epoch': 18.73}
{'loss': 0.0136, 'grad_norm': 5.45880126953125, 'learning_rate': 1.1284883720930234e-05, 'loss_1': 0.007632241118699312, 'loss_2': 0.00598907470703125, 'loss_3': -16.472394943237305, 'loss_4': 1.7756223678588867, 'epoch': 18.74}
{'loss': 0.0225, 'grad_norm': 14.056379318237305, 'learning_rate': 1.1279069767441861e-05, 'loss_1': 0.02109305001795292, 'loss_2': 0.0014438629150390625, 'loss_3': -16.33654022216797, 'loss_4': 1.873165249824524, 'epoch': 18.74}
{'loss': 0.0047, 'grad_norm': 4.663321495056152, 'learning_rate': 1.1273255813953488e-05, 'loss_1': 0.002430351683869958, 'loss_2': 0.00229644775390625, 'loss_3': -16.6398983001709, 'loss_4': 1.236067295074463, 'epoch': 18.75}
[INFO|trainer.py:4228] 2025-01-21 13:39:55,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:39:55,351 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                  | 3230/5160 [1:19:59<33:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:02,711 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01670292764902115, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.86, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011043108999729156, 'eval_loss_2': 0.005659818649291992, 'eval_loss_3': -18.1005916595459, 'eval_loss_4': 1.7516332864761353, 'epoch': 18.75}
{'loss': 0.0072, 'grad_norm': 4.939073085784912, 'learning_rate': 1.1267441860465117e-05, 'loss_1': 0.006997516844421625, 'loss_2': 0.0002269744873046875, 'loss_3': -16.354671478271484, 'loss_4': 1.8524839878082275, 'epoch': 18.76}
{'loss': 0.0149, 'grad_norm': 6.8005266189575195, 'learning_rate': 1.1261627906976743e-05, 'loss_1': 0.011013010516762733, 'loss_2': 0.003910064697265625, 'loss_3': -16.492542266845703, 'loss_4': 1.7098454236984253, 'epoch': 18.76}
{'loss': 0.0071, 'grad_norm': 4.674147129058838, 'learning_rate': 1.1255813953488374e-05, 'loss_1': 0.004650949500501156, 'loss_2': 0.002498626708984375, 'loss_3': -16.39034652709961, 'loss_4': 1.6172138452529907, 'epoch': 18.77}
{'loss': 0.0145, 'grad_norm': 6.305923938751221, 'learning_rate': 1.125e-05, 'loss_1': 0.010544347576797009, 'loss_2': 0.00391387939453125, 'loss_3': -16.419910430908203, 'loss_4': 1.5510910749435425, 'epoch': 18.77}
{'loss': 0.0053, 'grad_norm': 5.1636457443237305, 'learning_rate': 1.1244186046511628e-05, 'loss_1': 0.004805456846952438, 'loss_2': 0.0004658699035644531, 'loss_3': -16.258750915527344, 'loss_4': 1.7318519353866577, 'epoch': 18.78}
[INFO|trainer.py:4228] 2025-01-21 13:40:02,711 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:02,712 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                 | 3235/5160 [1:20:07<33:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:10,072 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01543500181287527, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.796, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.010125241242349148, 'eval_loss_2': 0.005309760570526123, 'eval_loss_3': -18.094406127929688, 'eval_loss_4': 1.7261306047439575, 'epoch': 18.78}
{'loss': 0.0079, 'grad_norm': 4.979238033294678, 'learning_rate': 1.1238372093023256e-05, 'loss_1': 0.0048190695233643055, 'loss_2': 0.00312042236328125, 'loss_3': -16.453208923339844, 'loss_4': 2.019371509552002, 'epoch': 18.78}
{'loss': 0.0107, 'grad_norm': 5.328164577484131, 'learning_rate': 1.1232558139534883e-05, 'loss_1': 0.004511252511292696, 'loss_2': 0.00620269775390625, 'loss_3': -16.397018432617188, 'loss_4': 1.4712978601455688, 'epoch': 18.79}
{'loss': 0.0128, 'grad_norm': 7.682488441467285, 'learning_rate': 1.1226744186046512e-05, 'loss_1': 0.010580150410532951, 'loss_2': 0.00225067138671875, 'loss_3': -16.27723503112793, 'loss_4': 1.75157630443573, 'epoch': 18.8}
{'loss': 0.0223, 'grad_norm': 5.697908878326416, 'learning_rate': 1.122093023255814e-05, 'loss_1': 0.01172225084155798, 'loss_2': 0.0105743408203125, 'loss_3': -16.401386260986328, 'loss_4': 1.7163934707641602, 'epoch': 18.8}
{'loss': 0.0079, 'grad_norm': 5.336192607879639, 'learning_rate': 1.1215116279069767e-05, 'loss_1': 0.0078027318231761456, 'loss_2': 0.00011324882507324219, 'loss_3': -16.395687103271484, 'loss_4': 2.1267049312591553, 'epoch': 18.81}
[INFO|trainer.py:4228] 2025-01-21 13:40:10,072 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:10,072 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 3240/5160 [1:20:14<33:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:17,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014847933314740658, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.577, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010147270746529102, 'eval_loss_2': 0.004700660705566406, 'eval_loss_3': -18.09663963317871, 'eval_loss_4': 1.7876489162445068, 'epoch': 18.81}
{'loss': 0.0146, 'grad_norm': 6.763370513916016, 'learning_rate': 1.1209302325581396e-05, 'loss_1': 0.01023334451019764, 'loss_2': 0.004398345947265625, 'loss_3': -16.506053924560547, 'loss_4': 2.051891565322876, 'epoch': 18.81}
{'loss': 0.0041, 'grad_norm': 4.653014183044434, 'learning_rate': 1.1203488372093023e-05, 'loss_1': 0.003239499870687723, 'loss_2': 0.0008172988891601562, 'loss_3': -16.475479125976562, 'loss_4': 1.547680377960205, 'epoch': 18.82}
{'loss': 0.0227, 'grad_norm': 9.181979179382324, 'learning_rate': 1.1197674418604652e-05, 'loss_1': 0.013053081929683685, 'loss_2': 0.0096435546875, 'loss_3': -16.390422821044922, 'loss_4': 1.9074022769927979, 'epoch': 18.83}
{'loss': 0.0092, 'grad_norm': 4.716187000274658, 'learning_rate': 1.1191860465116279e-05, 'loss_1': 0.004377616103738546, 'loss_2': 0.004825592041015625, 'loss_3': -16.483837127685547, 'loss_4': 1.953195333480835, 'epoch': 18.83}
{'loss': 0.0095, 'grad_norm': 4.440183162689209, 'learning_rate': 1.1186046511627907e-05, 'loss_1': 0.004258572589606047, 'loss_2': 0.005275726318359375, 'loss_3': -16.281986236572266, 'loss_4': 2.064591884613037, 'epoch': 18.84}
[INFO|trainer.py:4228] 2025-01-21 13:40:17,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:17,434 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                 | 3245/5160 [1:20:21<33:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:24,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012320268899202347, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.591, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008985329419374466, 'eval_loss_2': 0.003334939479827881, 'eval_loss_3': -18.09958267211914, 'eval_loss_4': 1.8985023498535156, 'epoch': 18.84}
{'loss': 0.0075, 'grad_norm': 5.466137409210205, 'learning_rate': 1.1180232558139536e-05, 'loss_1': 0.005840655416250229, 'loss_2': 0.001628875732421875, 'loss_3': -16.430294036865234, 'loss_4': 1.6698938608169556, 'epoch': 18.84}
{'loss': 0.0131, 'grad_norm': 4.938774108886719, 'learning_rate': 1.1174418604651163e-05, 'loss_1': 0.005792615469545126, 'loss_2': 0.007354736328125, 'loss_3': -16.44231414794922, 'loss_4': 2.0066819190979004, 'epoch': 18.85}
{'loss': 0.006, 'grad_norm': 4.672611713409424, 'learning_rate': 1.1168604651162791e-05, 'loss_1': 0.004994689021259546, 'loss_2': 0.0010242462158203125, 'loss_3': -16.452795028686523, 'loss_4': 1.4880932569503784, 'epoch': 18.85}
{'loss': 0.014, 'grad_norm': 9.3626708984375, 'learning_rate': 1.1162790697674418e-05, 'loss_1': 0.010954415425658226, 'loss_2': 0.003032684326171875, 'loss_3': -16.403709411621094, 'loss_4': 1.9343136548995972, 'epoch': 18.86}
{'loss': 0.0084, 'grad_norm': 4.978878974914551, 'learning_rate': 1.1156976744186045e-05, 'loss_1': 0.004724671132862568, 'loss_2': 0.003635406494140625, 'loss_3': -16.40386199951172, 'loss_4': 2.1048617362976074, 'epoch': 18.87}
[INFO|trainer.py:4228] 2025-01-21 13:40:24,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:24,795 >>   Batch size = 64
 63%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                 | 3250/5160 [1:20:29<33:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:32,148 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017057940363883972, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.013463368639349937, 'eval_loss_2': 0.0035945698618888855, 'eval_loss_3': -18.056560516357422, 'eval_loss_4': 2.037923812866211, 'epoch': 18.87}
{'loss': 0.0079, 'grad_norm': 5.529545783996582, 'learning_rate': 1.1151162790697676e-05, 'loss_1': 0.005796988494694233, 'loss_2': 0.0020694732666015625, 'loss_3': -16.45217514038086, 'loss_4': 2.2064409255981445, 'epoch': 18.87}
{'loss': 0.023, 'grad_norm': 9.615673065185547, 'learning_rate': 1.1145348837209303e-05, 'loss_1': 0.021339500322937965, 'loss_2': 0.001708984375, 'loss_3': -16.436532974243164, 'loss_4': 2.2902753353118896, 'epoch': 18.88}
{'loss': 0.0088, 'grad_norm': 5.604774475097656, 'learning_rate': 1.1139534883720931e-05, 'loss_1': 0.006827603559941053, 'loss_2': 0.00199127197265625, 'loss_3': -16.470413208007812, 'loss_4': 1.9163943529129028, 'epoch': 18.88}
{'loss': 0.0181, 'grad_norm': 7.598272800445557, 'learning_rate': 1.1133720930232558e-05, 'loss_1': 0.009302391670644283, 'loss_2': 0.0087738037109375, 'loss_3': -16.323204040527344, 'loss_4': 2.090904712677002, 'epoch': 18.89}
{'loss': 0.019, 'grad_norm': 7.973521709442139, 'learning_rate': 1.1127906976744187e-05, 'loss_1': 0.015052239410579205, 'loss_2': 0.00397491455078125, 'loss_3': -16.310317993164062, 'loss_4': 2.1509809494018555, 'epoch': 18.9}
[INFO|trainer.py:4228] 2025-01-21 13:40:32,148 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:32,148 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                | 3255/5160 [1:20:36<32:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:39,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.027977118268609047, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.828, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.023709677159786224, 'eval_loss_2': 0.004267439246177673, 'eval_loss_3': -18.021156311035156, 'eval_loss_4': 2.1305460929870605, 'epoch': 18.9}
{'loss': 0.02, 'grad_norm': 6.6986260414123535, 'learning_rate': 1.1122093023255814e-05, 'loss_1': 0.010065722279250622, 'loss_2': 0.0099334716796875, 'loss_3': -16.350814819335938, 'loss_4': 2.626605749130249, 'epoch': 18.9}
{'loss': 0.0103, 'grad_norm': 4.245787620544434, 'learning_rate': 1.1116279069767442e-05, 'loss_1': 0.007102189119905233, 'loss_2': 0.003170013427734375, 'loss_3': -16.47939109802246, 'loss_4': 2.1080193519592285, 'epoch': 18.91}
{'loss': 0.0091, 'grad_norm': 8.575443267822266, 'learning_rate': 1.1110465116279071e-05, 'loss_1': 0.009032577276229858, 'loss_2': 5.650520324707031e-05, 'loss_3': -16.403005599975586, 'loss_4': 1.9032928943634033, 'epoch': 18.91}
{'loss': 0.0712, 'grad_norm': 34.47338104248047, 'learning_rate': 1.1104651162790698e-05, 'loss_1': 0.06868024915456772, 'loss_2': 0.002544403076171875, 'loss_3': -16.224821090698242, 'loss_4': 2.036900758743286, 'epoch': 18.92}
{'loss': 0.0092, 'grad_norm': 4.891157150268555, 'learning_rate': 1.1098837209302327e-05, 'loss_1': 0.0028499739710241556, 'loss_2': 0.0063934326171875, 'loss_3': -16.391908645629883, 'loss_4': 2.3061256408691406, 'epoch': 18.92}
[INFO|trainer.py:4228] 2025-01-21 13:40:39,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:39,508 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                | 3260/5160 [1:20:44<32:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:46,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03182403743267059, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.834, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.02736358344554901, 'eval_loss_2': 0.004460453987121582, 'eval_loss_3': -18.01988410949707, 'eval_loss_4': 2.2618680000305176, 'epoch': 18.92}
{'loss': 0.0052, 'grad_norm': 4.717883586883545, 'learning_rate': 1.1093023255813953e-05, 'loss_1': 0.003993217833340168, 'loss_2': 0.0012350082397460938, 'loss_3': -16.361061096191406, 'loss_4': 2.4275550842285156, 'epoch': 18.93}
{'loss': 0.0134, 'grad_norm': 8.493997573852539, 'learning_rate': 1.108720930232558e-05, 'loss_1': 0.012168173678219318, 'loss_2': 0.0012235641479492188, 'loss_3': -16.428348541259766, 'loss_4': 2.321972608566284, 'epoch': 18.94}
{'loss': 0.0178, 'grad_norm': 5.5168890953063965, 'learning_rate': 1.108139534883721e-05, 'loss_1': 0.008030202239751816, 'loss_2': 0.00978851318359375, 'loss_3': -16.385169982910156, 'loss_4': 2.2583723068237305, 'epoch': 18.94}
{'loss': 0.0138, 'grad_norm': 5.867039680480957, 'learning_rate': 1.1075581395348838e-05, 'loss_1': 0.008647764101624489, 'loss_2': 0.0051116943359375, 'loss_3': -16.507034301757812, 'loss_4': 2.212388038635254, 'epoch': 18.95}
{'loss': 0.0057, 'grad_norm': 4.7152934074401855, 'learning_rate': 1.1069767441860466e-05, 'loss_1': 0.0029592730570584536, 'loss_2': 0.0027637481689453125, 'loss_3': -16.437517166137695, 'loss_4': 2.1350739002227783, 'epoch': 18.95}
[INFO|trainer.py:4228] 2025-01-21 13:40:46,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:46,869 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                | 3265/5160 [1:20:51<32:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:40:54,233 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.036682069301605225, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.889, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.03330661728978157, 'eval_loss_2': 0.0033754557371139526, 'eval_loss_3': -18.017234802246094, 'eval_loss_4': 2.284731149673462, 'epoch': 18.95}
{'loss': 0.0207, 'grad_norm': 8.227728843688965, 'learning_rate': 1.1063953488372093e-05, 'loss_1': 0.012903659604489803, 'loss_2': 0.007785797119140625, 'loss_3': -16.454483032226562, 'loss_4': 2.5147299766540527, 'epoch': 18.96}
{'loss': 0.0144, 'grad_norm': 5.102814674377441, 'learning_rate': 1.105813953488372e-05, 'loss_1': 0.005564719904214144, 'loss_2': 0.0087890625, 'loss_3': -16.497920989990234, 'loss_4': 2.8137614727020264, 'epoch': 18.97}
{'loss': 0.0142, 'grad_norm': 6.2104644775390625, 'learning_rate': 1.1052325581395349e-05, 'loss_1': 0.01151924580335617, 'loss_2': 0.00267791748046875, 'loss_3': -16.486783981323242, 'loss_4': 2.3951711654663086, 'epoch': 18.97}
{'loss': 0.0133, 'grad_norm': 5.339423179626465, 'learning_rate': 1.1046511627906977e-05, 'loss_1': 0.007130319718271494, 'loss_2': 0.0061492919921875, 'loss_3': -16.55618667602539, 'loss_4': 2.217054843902588, 'epoch': 18.98}
{'loss': 0.0155, 'grad_norm': 7.896722316741943, 'learning_rate': 1.1040697674418606e-05, 'loss_1': 0.01039152406156063, 'loss_2': 0.005077362060546875, 'loss_3': -16.440784454345703, 'loss_4': 2.5448358058929443, 'epoch': 18.98}
[INFO|trainer.py:4228] 2025-01-21 13:40:54,233 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:40:54,233 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                | 3270/5160 [1:20:58<31:27,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 13:41:01,292 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04077008366584778, 'eval_runtime': 3.8177, 'eval_samples_per_second': 268.225, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.036681775003671646, 'eval_loss_2': 0.004088312387466431, 'eval_loss_3': -18.002330780029297, 'eval_loss_4': 2.197007417678833, 'epoch': 18.98}
{'loss': 0.0102, 'grad_norm': 4.779223442077637, 'learning_rate': 1.1034883720930233e-05, 'loss_1': 0.0030263313092291355, 'loss_2': 0.007171630859375, 'loss_3': -16.485641479492188, 'loss_4': 2.134878158569336, 'epoch': 18.99}
{'loss': 0.0059, 'grad_norm': 4.254005432128906, 'learning_rate': 1.102906976744186e-05, 'loss_1': 0.0057426937855780125, 'loss_2': 0.0002073049545288086, 'loss_3': -16.2413330078125, 'loss_4': 2.2467575073242188, 'epoch': 18.99}
{'loss': 0.0052, 'grad_norm': 6.6577372550964355, 'learning_rate': 1.1023255813953489e-05, 'loss_1': 0.0038837457541376352, 'loss_2': 0.0013256072998046875, 'loss_3': -16.362401962280273, 'loss_4': 1.985014796257019, 'epoch': 19.0}
{'loss': 0.0134, 'grad_norm': 5.044877052307129, 'learning_rate': 1.1017441860465116e-05, 'loss_1': 0.009131011553108692, 'loss_2': 0.00423431396484375, 'loss_3': -16.42537498474121, 'loss_4': 2.1340198516845703, 'epoch': 19.01}
{'loss': 0.0567, 'grad_norm': 14.446111679077148, 'learning_rate': 1.1011627906976746e-05, 'loss_1': 0.04508809745311737, 'loss_2': 0.0115966796875, 'loss_3': -16.43511962890625, 'loss_4': 2.163727283477783, 'epoch': 19.01}
[INFO|trainer.py:4228] 2025-01-21 13:41:01,292 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:01,292 >>   Batch size = 64
 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 3275/5160 [1:21:05<32:27,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:41:08,655 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.04645014926791191, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.802, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.04251644015312195, 'eval_loss_2': 0.003933712840080261, 'eval_loss_3': -18.00283432006836, 'eval_loss_4': 2.083223342895508, 'epoch': 19.01}
{'loss': 0.025, 'grad_norm': 7.960377216339111, 'learning_rate': 1.1005813953488373e-05, 'loss_1': 0.014881803654134274, 'loss_2': 0.01007843017578125, 'loss_3': -16.374698638916016, 'loss_4': 1.8283967971801758, 'epoch': 19.02}
{'loss': 0.0073, 'grad_norm': 4.736671447753906, 'learning_rate': 1.1e-05, 'loss_1': 0.00535473832860589, 'loss_2': 0.0019083023071289062, 'loss_3': -16.457443237304688, 'loss_4': 1.7411060333251953, 'epoch': 19.02}
{'loss': 0.0052, 'grad_norm': 4.955626010894775, 'learning_rate': 1.0994186046511628e-05, 'loss_1': 0.004846818745136261, 'loss_2': 0.0003323554992675781, 'loss_3': -16.482452392578125, 'loss_4': 2.323164463043213, 'epoch': 19.03}
{'loss': 0.0045, 'grad_norm': 4.339627742767334, 'learning_rate': 1.0988372093023255e-05, 'loss_1': 0.00424151960760355, 'loss_2': 0.00030732154846191406, 'loss_3': -16.49089813232422, 'loss_4': 1.52727210521698, 'epoch': 19.03}
{'loss': 0.0068, 'grad_norm': 5.227077960968018, 'learning_rate': 1.0982558139534884e-05, 'loss_1': 0.00664239889010787, 'loss_2': 0.00019311904907226562, 'loss_3': -16.53290557861328, 'loss_4': 2.1064953804016113, 'epoch': 19.04}
[INFO|trainer.py:4228] 2025-01-21 13:41:08,655 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:08,655 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                               | 3280/5160 [1:21:13<32:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:16,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03858538344502449, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.024, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.034993305802345276, 'eval_loss_2': 0.003592073917388916, 'eval_loss_3': -18.002737045288086, 'eval_loss_4': 1.9493861198425293, 'epoch': 19.04}
{'loss': 0.0103, 'grad_norm': 5.2222418785095215, 'learning_rate': 1.0976744186046513e-05, 'loss_1': 0.004469345323741436, 'loss_2': 0.0058441162109375, 'loss_3': -16.639862060546875, 'loss_4': 1.8771471977233887, 'epoch': 19.05}
{'loss': 0.1769, 'grad_norm': 23.543027877807617, 'learning_rate': 1.097093023255814e-05, 'loss_1': 0.17639820277690887, 'loss_2': 0.0005502700805664062, 'loss_3': -16.201061248779297, 'loss_4': 2.6175825595855713, 'epoch': 19.05}
{'loss': 0.0451, 'grad_norm': 25.160091400146484, 'learning_rate': 1.0965116279069768e-05, 'loss_1': 0.043044909834861755, 'loss_2': 0.002033233642578125, 'loss_3': -16.465124130249023, 'loss_4': 2.1924567222595215, 'epoch': 19.06}
{'loss': 0.0136, 'grad_norm': 6.147243976593018, 'learning_rate': 1.0959302325581395e-05, 'loss_1': 0.012819584459066391, 'loss_2': 0.0007600784301757812, 'loss_3': -16.451793670654297, 'loss_4': 2.4445817470550537, 'epoch': 19.06}
{'loss': 0.0113, 'grad_norm': 5.4044880867004395, 'learning_rate': 1.0953488372093024e-05, 'loss_1': 0.00824709516018629, 'loss_2': 0.003017425537109375, 'loss_3': -16.301481246948242, 'loss_4': 2.0934767723083496, 'epoch': 19.07}
[INFO|trainer.py:4228] 2025-01-21 13:41:16,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:16,008 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                               | 3285/5160 [1:21:20<32:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:23,371 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.03410906344652176, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.273, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.029813051223754883, 'eval_loss_2': 0.004296012222766876, 'eval_loss_3': -18.01124382019043, 'eval_loss_4': 1.9061546325683594, 'epoch': 19.07}
{'loss': 0.0103, 'grad_norm': 5.541175842285156, 'learning_rate': 1.094767441860465e-05, 'loss_1': 0.00797264277935028, 'loss_2': 0.002361297607421875, 'loss_3': -16.470623016357422, 'loss_4': 1.8926845788955688, 'epoch': 19.08}
{'loss': 0.0114, 'grad_norm': 5.626745223999023, 'learning_rate': 1.0941860465116281e-05, 'loss_1': 0.007239952217787504, 'loss_2': 0.00418853759765625, 'loss_3': -16.604721069335938, 'loss_4': 2.082902431488037, 'epoch': 19.08}
{'loss': 0.0109, 'grad_norm': 6.679285526275635, 'learning_rate': 1.0936046511627908e-05, 'loss_1': 0.007011818699538708, 'loss_2': 0.00391387939453125, 'loss_3': -16.218963623046875, 'loss_4': 1.7915458679199219, 'epoch': 19.09}
{'loss': 0.0081, 'grad_norm': 4.849886417388916, 'learning_rate': 1.0930232558139535e-05, 'loss_1': 0.004337030928581953, 'loss_2': 0.00379180908203125, 'loss_3': -16.46692657470703, 'loss_4': 1.562103509902954, 'epoch': 19.09}
{'loss': 0.0092, 'grad_norm': 5.010494709014893, 'learning_rate': 1.0924418604651163e-05, 'loss_1': 0.005624074023216963, 'loss_2': 0.0035305023193359375, 'loss_3': -16.347980499267578, 'loss_4': 1.7307233810424805, 'epoch': 19.1}
[INFO|trainer.py:4228] 2025-01-21 13:41:23,371 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:23,371 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                               | 3290/5160 [1:21:27<32:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:30,736 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02677471935749054, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.023491058498620987, 'eval_loss_2': 0.003283664584159851, 'eval_loss_3': -18.028825759887695, 'eval_loss_4': 1.9090664386749268, 'epoch': 19.1}
{'loss': 0.0099, 'grad_norm': 5.129665374755859, 'learning_rate': 1.091860465116279e-05, 'loss_1': 0.003140917746350169, 'loss_2': 0.006778717041015625, 'loss_3': -16.28852081298828, 'loss_4': 1.669367790222168, 'epoch': 19.1}
{'loss': 0.0106, 'grad_norm': 6.587056636810303, 'learning_rate': 1.0912790697674419e-05, 'loss_1': 0.006961997132748365, 'loss_2': 0.00363922119140625, 'loss_3': -16.554189682006836, 'loss_4': 1.9445937871932983, 'epoch': 19.11}
{'loss': 0.0103, 'grad_norm': 5.016012191772461, 'learning_rate': 1.0906976744186048e-05, 'loss_1': 0.006409093737602234, 'loss_2': 0.003879547119140625, 'loss_3': -16.358112335205078, 'loss_4': 1.51788330078125, 'epoch': 19.12}
{'loss': 0.0162, 'grad_norm': 7.175496578216553, 'learning_rate': 1.0901162790697675e-05, 'loss_1': 0.01249120756983757, 'loss_2': 0.0037479400634765625, 'loss_3': -16.434913635253906, 'loss_4': 1.9226139783859253, 'epoch': 19.12}
{'loss': 0.0105, 'grad_norm': 5.943881034851074, 'learning_rate': 1.0895348837209303e-05, 'loss_1': 0.008804717101156712, 'loss_2': 0.001667022705078125, 'loss_3': -16.49770164489746, 'loss_4': 2.2353858947753906, 'epoch': 19.13}
[INFO|trainer.py:4228] 2025-01-21 13:41:30,736 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:30,736 >>   Batch size = 64
 64%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                               | 3295/5160 [1:21:35<32:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:38,102 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.026225384324789047, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.489, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.02306535094976425, 'eval_loss_2': 0.003160029649734497, 'eval_loss_3': -18.02528190612793, 'eval_loss_4': 2.049948215484619, 'epoch': 19.13}
{'loss': 0.0071, 'grad_norm': 4.425867080688477, 'learning_rate': 1.088953488372093e-05, 'loss_1': 0.002106514060869813, 'loss_2': 0.00502777099609375, 'loss_3': -16.38859748840332, 'loss_4': 2.366898536682129, 'epoch': 19.13}
{'loss': 0.0142, 'grad_norm': 7.731546401977539, 'learning_rate': 1.0883720930232559e-05, 'loss_1': 0.009293822571635246, 'loss_2': 0.004932403564453125, 'loss_3': -16.391220092773438, 'loss_4': 2.133437156677246, 'epoch': 19.14}
{'loss': 0.0108, 'grad_norm': 4.740590572357178, 'learning_rate': 1.0877906976744186e-05, 'loss_1': 0.0043044909834861755, 'loss_2': 0.006511688232421875, 'loss_3': -16.246231079101562, 'loss_4': 1.9742364883422852, 'epoch': 19.15}
{'loss': 0.0133, 'grad_norm': 7.4561333656311035, 'learning_rate': 1.0872093023255814e-05, 'loss_1': 0.007861614227294922, 'loss_2': 0.005428314208984375, 'loss_3': -16.3189754486084, 'loss_4': 2.4013452529907227, 'epoch': 19.15}
{'loss': 0.0136, 'grad_norm': 5.8369340896606445, 'learning_rate': 1.0866279069767443e-05, 'loss_1': 0.011626150459051132, 'loss_2': 0.00200653076171875, 'loss_3': -16.520689010620117, 'loss_4': 2.0820116996765137, 'epoch': 19.16}
[INFO|trainer.py:4228] 2025-01-21 13:41:38,102 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:38,102 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                               | 3300/5160 [1:21:42<32:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:45,467 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019125133752822876, 'eval_runtime': 3.8129, 'eval_samples_per_second': 268.565, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.015682710334658623, 'eval_loss_2': 0.003442421555519104, 'eval_loss_3': -18.044090270996094, 'eval_loss_4': 2.1944539546966553, 'epoch': 19.16}
{'loss': 0.009, 'grad_norm': 4.9401750564575195, 'learning_rate': 1.086046511627907e-05, 'loss_1': 0.00582205131649971, 'loss_2': 0.003154754638671875, 'loss_3': -16.399738311767578, 'loss_4': 1.836290955543518, 'epoch': 19.16}
{'loss': 0.0357, 'grad_norm': 9.329794883728027, 'learning_rate': 1.0854651162790699e-05, 'loss_1': 0.028554940596222878, 'loss_2': 0.00711822509765625, 'loss_3': -16.567049026489258, 'loss_4': 2.485038995742798, 'epoch': 19.17}
{'loss': 0.0091, 'grad_norm': 5.714625358581543, 'learning_rate': 1.0848837209302326e-05, 'loss_1': 0.00605734484270215, 'loss_2': 0.0030117034912109375, 'loss_3': -16.24332046508789, 'loss_4': 2.0698111057281494, 'epoch': 19.17}
{'loss': 0.0085, 'grad_norm': 5.088701248168945, 'learning_rate': 1.0843023255813952e-05, 'loss_1': 0.0046312143094837666, 'loss_2': 0.00389862060546875, 'loss_3': -16.511564254760742, 'loss_4': 2.4761338233947754, 'epoch': 19.18}
{'loss': 0.0111, 'grad_norm': 5.448537349700928, 'learning_rate': 1.0837209302325581e-05, 'loss_1': 0.007595823146402836, 'loss_2': 0.00345611572265625, 'loss_3': -16.5790958404541, 'loss_4': 2.28603458404541, 'epoch': 19.19}
[INFO|trainer.py:4228] 2025-01-21 13:41:45,467 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:45,467 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                              | 3305/5160 [1:21:49<32:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:41:52,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01301476452499628, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.914, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.010552704334259033, 'eval_loss_2': 0.002462059259414673, 'eval_loss_3': -18.088958740234375, 'eval_loss_4': 2.2900431156158447, 'epoch': 19.19}
{'loss': 0.0132, 'grad_norm': 6.5850372314453125, 'learning_rate': 1.083139534883721e-05, 'loss_1': 0.010051832534372807, 'loss_2': 0.003131866455078125, 'loss_3': -16.42560386657715, 'loss_4': 2.3489608764648438, 'epoch': 19.19}
{'loss': 0.0097, 'grad_norm': 4.490543365478516, 'learning_rate': 1.0825581395348838e-05, 'loss_1': 0.004685854539275169, 'loss_2': 0.0050048828125, 'loss_3': -16.499814987182617, 'loss_4': 2.425084114074707, 'epoch': 19.2}
{'loss': 0.0095, 'grad_norm': 5.454954624176025, 'learning_rate': 1.0819767441860465e-05, 'loss_1': 0.008309971541166306, 'loss_2': 0.001190185546875, 'loss_3': -16.224994659423828, 'loss_4': 2.4843454360961914, 'epoch': 19.2}
{'loss': 0.0065, 'grad_norm': 5.19597864151001, 'learning_rate': 1.0813953488372092e-05, 'loss_1': 0.0049777342937886715, 'loss_2': 0.001552581787109375, 'loss_3': -16.473121643066406, 'loss_4': 1.928388237953186, 'epoch': 19.21}
{'loss': 0.0119, 'grad_norm': 8.328558921813965, 'learning_rate': 1.0808139534883721e-05, 'loss_1': 0.011402796022593975, 'loss_2': 0.000522613525390625, 'loss_3': -16.462942123413086, 'loss_4': 2.4308109283447266, 'epoch': 19.22}
[INFO|trainer.py:4228] 2025-01-21 13:41:52,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:41:52,826 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 3310/5160 [1:21:57<32:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:00,184 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010983250103890896, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.013, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008304647170007229, 'eval_loss_2': 0.002678602933883667, 'eval_loss_3': -18.119430541992188, 'eval_loss_4': 2.306340217590332, 'epoch': 19.22}
{'loss': 0.0093, 'grad_norm': 5.505617141723633, 'learning_rate': 1.0802325581395348e-05, 'loss_1': 0.009247840382158756, 'loss_2': 7.963180541992188e-05, 'loss_3': -16.358585357666016, 'loss_4': 2.3310599327087402, 'epoch': 19.22}
{'loss': 0.0112, 'grad_norm': 4.931258201599121, 'learning_rate': 1.0796511627906978e-05, 'loss_1': 0.008638814091682434, 'loss_2': 0.0025730133056640625, 'loss_3': -16.348352432250977, 'loss_4': 2.483160972595215, 'epoch': 19.23}
{'loss': 0.0198, 'grad_norm': 8.0457124710083, 'learning_rate': 1.0790697674418605e-05, 'loss_1': 0.011730828322470188, 'loss_2': 0.008087158203125, 'loss_3': -16.598726272583008, 'loss_4': 2.2480411529541016, 'epoch': 19.23}
{'loss': 0.015, 'grad_norm': 7.928214073181152, 'learning_rate': 1.0784883720930232e-05, 'loss_1': 0.01268664002418518, 'loss_2': 0.00226593017578125, 'loss_3': -16.618038177490234, 'loss_4': 2.154995918273926, 'epoch': 19.24}
{'loss': 0.0159, 'grad_norm': 8.379220962524414, 'learning_rate': 1.077906976744186e-05, 'loss_1': 0.009549127891659737, 'loss_2': 0.0063934326171875, 'loss_3': -16.485931396484375, 'loss_4': 2.346064567565918, 'epoch': 19.24}
[INFO|trainer.py:4228] 2025-01-21 13:42:00,184 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:00,184 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 3315/5160 [1:22:04<31:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:07,542 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009925696067512035, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.99, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007171037141233683, 'eval_loss_2': 0.0027546584606170654, 'eval_loss_3': -18.142723083496094, 'eval_loss_4': 2.1874659061431885, 'epoch': 19.24}
{'loss': 0.0118, 'grad_norm': 5.59911584854126, 'learning_rate': 1.0773255813953488e-05, 'loss_1': 0.008926985785365105, 'loss_2': 0.0028858184814453125, 'loss_3': -16.296875, 'loss_4': 2.0947940349578857, 'epoch': 19.25}
{'loss': 0.0111, 'grad_norm': 4.890527248382568, 'learning_rate': 1.0767441860465116e-05, 'loss_1': 0.006017076317220926, 'loss_2': 0.00508880615234375, 'loss_3': -16.411788940429688, 'loss_4': 2.198615550994873, 'epoch': 19.26}
{'loss': 0.0078, 'grad_norm': 5.6260504722595215, 'learning_rate': 1.0761627906976745e-05, 'loss_1': 0.006815656088292599, 'loss_2': 0.0009551048278808594, 'loss_3': -16.3299560546875, 'loss_4': 2.256013870239258, 'epoch': 19.26}
{'loss': 0.0166, 'grad_norm': 7.590616703033447, 'learning_rate': 1.0755813953488373e-05, 'loss_1': 0.013516653329133987, 'loss_2': 0.003108978271484375, 'loss_3': -16.51575469970703, 'loss_4': 2.252016544342041, 'epoch': 19.27}
{'loss': 0.0193, 'grad_norm': 5.770211219787598, 'learning_rate': 1.075e-05, 'loss_1': 0.007933818735182285, 'loss_2': 0.01140594482421875, 'loss_3': -16.38271713256836, 'loss_4': 2.125924587249756, 'epoch': 19.27}
[INFO|trainer.py:4228] 2025-01-21 13:42:07,542 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:07,543 >>   Batch size = 64
 64%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3320/5160 [1:22:12<31:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:14,904 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011122822761535645, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.073, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007479384541511536, 'eval_loss_2': 0.003643438220024109, 'eval_loss_3': -18.153423309326172, 'eval_loss_4': 2.105964183807373, 'epoch': 19.27}
{'loss': 0.0152, 'grad_norm': 5.777890205383301, 'learning_rate': 1.0744186046511627e-05, 'loss_1': 0.011483308859169483, 'loss_2': 0.0037441253662109375, 'loss_3': -16.43274688720703, 'loss_4': 2.4132633209228516, 'epoch': 19.28}
{'loss': 0.0092, 'grad_norm': 5.345221519470215, 'learning_rate': 1.0738372093023256e-05, 'loss_1': 0.005806255619972944, 'loss_2': 0.003353118896484375, 'loss_3': -16.48982810974121, 'loss_4': 1.9748425483703613, 'epoch': 19.28}
{'loss': 0.0129, 'grad_norm': 4.901806831359863, 'learning_rate': 1.0732558139534883e-05, 'loss_1': 0.006550895050168037, 'loss_2': 0.00632476806640625, 'loss_3': -16.303861618041992, 'loss_4': 2.4102678298950195, 'epoch': 19.29}
{'loss': 0.0165, 'grad_norm': 8.618125915527344, 'learning_rate': 1.0726744186046513e-05, 'loss_1': 0.01107283215969801, 'loss_2': 0.005413055419921875, 'loss_3': -16.261507034301758, 'loss_4': 1.6670756340026855, 'epoch': 19.3}
{'loss': 0.024, 'grad_norm': 9.263131141662598, 'learning_rate': 1.072093023255814e-05, 'loss_1': 0.02084246650338173, 'loss_2': 0.00311279296875, 'loss_3': -16.327789306640625, 'loss_4': 2.3314273357391357, 'epoch': 19.3}
[INFO|trainer.py:4228] 2025-01-21 13:42:14,904 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:14,905 >>   Batch size = 64
 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                              | 3325/5160 [1:22:19<31:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:22,277 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011381365358829498, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.206, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.007844215258955956, 'eval_loss_2': 0.0035371482372283936, 'eval_loss_3': -18.15665054321289, 'eval_loss_4': 1.9820626974105835, 'epoch': 19.3}
{'loss': 0.0127, 'grad_norm': 6.296910285949707, 'learning_rate': 1.0715116279069767e-05, 'loss_1': 0.010826529935002327, 'loss_2': 0.0018253326416015625, 'loss_3': -16.495149612426758, 'loss_4': 2.1475329399108887, 'epoch': 19.31}
{'loss': 0.012, 'grad_norm': 5.45908784866333, 'learning_rate': 1.0709302325581396e-05, 'loss_1': 0.00689207948744297, 'loss_2': 0.00508880615234375, 'loss_3': -16.60641860961914, 'loss_4': 1.831974983215332, 'epoch': 19.31}
{'loss': 0.0106, 'grad_norm': 7.645157337188721, 'learning_rate': 1.0703488372093023e-05, 'loss_1': 0.008936162106692791, 'loss_2': 0.00170135498046875, 'loss_3': -16.629549026489258, 'loss_4': 2.057426929473877, 'epoch': 19.32}
{'loss': 0.01, 'grad_norm': 5.454920768737793, 'learning_rate': 1.0697674418604651e-05, 'loss_1': 0.006786597426980734, 'loss_2': 0.0031890869140625, 'loss_3': -16.46810531616211, 'loss_4': 2.2939019203186035, 'epoch': 19.33}
{'loss': 0.0047, 'grad_norm': 4.620665550231934, 'learning_rate': 1.069186046511628e-05, 'loss_1': 0.0033702272921800613, 'loss_2': 0.0013637542724609375, 'loss_3': -16.424901962280273, 'loss_4': 2.217250347137451, 'epoch': 19.33}
[INFO|trainer.py:4228] 2025-01-21 13:42:22,277 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:22,277 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                             | 3330/5160 [1:22:26<31:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:29,638 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010758127085864544, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.081, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007653883192688227, 'eval_loss_2': 0.00310424342751503, 'eval_loss_3': -18.158218383789062, 'eval_loss_4': 1.854994773864746, 'epoch': 19.33}
{'loss': 0.007, 'grad_norm': 5.226629257202148, 'learning_rate': 1.0686046511627907e-05, 'loss_1': 0.006083116866648197, 'loss_2': 0.0009646415710449219, 'loss_3': -16.35387420654297, 'loss_4': 2.2662031650543213, 'epoch': 19.34}
{'loss': 0.007, 'grad_norm': 4.8242902755737305, 'learning_rate': 1.0680232558139536e-05, 'loss_1': 0.006918157450854778, 'loss_2': 3.6656856536865234e-05, 'loss_3': -16.6561279296875, 'loss_4': 1.663053035736084, 'epoch': 19.34}
{'loss': 0.0104, 'grad_norm': 4.7764458656311035, 'learning_rate': 1.0674418604651162e-05, 'loss_1': 0.004901975393295288, 'loss_2': 0.005462646484375, 'loss_3': -16.4564151763916, 'loss_4': 1.7757350206375122, 'epoch': 19.35}
{'loss': 0.0071, 'grad_norm': 4.73106575012207, 'learning_rate': 1.0668604651162791e-05, 'loss_1': 0.0035959752276539803, 'loss_2': 0.00347900390625, 'loss_3': -16.55556869506836, 'loss_4': 2.02323842048645, 'epoch': 19.35}
{'loss': 0.0075, 'grad_norm': 4.423216819763184, 'learning_rate': 1.0662790697674418e-05, 'loss_1': 0.005663977470248938, 'loss_2': 0.0018672943115234375, 'loss_3': -16.381694793701172, 'loss_4': 1.2430760860443115, 'epoch': 19.36}
[INFO|trainer.py:4228] 2025-01-21 13:42:29,638 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:29,638 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                             | 3335/5160 [1:22:34<31:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:37,002 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011189082637429237, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.838, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007128322497010231, 'eval_loss_2': 0.004060760140419006, 'eval_loss_3': -18.124921798706055, 'eval_loss_4': 1.6740422248840332, 'epoch': 19.36}
{'loss': 0.0212, 'grad_norm': 11.19855785369873, 'learning_rate': 1.0656976744186047e-05, 'loss_1': 0.020520901307463646, 'loss_2': 0.0007128715515136719, 'loss_3': -16.37588119506836, 'loss_4': 1.4964985847473145, 'epoch': 19.37}
{'loss': 0.0157, 'grad_norm': 5.203909397125244, 'learning_rate': 1.0651162790697675e-05, 'loss_1': 0.004799830727279186, 'loss_2': 0.01085662841796875, 'loss_3': -16.340784072875977, 'loss_4': 1.5669782161712646, 'epoch': 19.37}
{'loss': 0.018, 'grad_norm': 7.894351482391357, 'learning_rate': 1.0645348837209302e-05, 'loss_1': 0.01612604781985283, 'loss_2': 0.001827239990234375, 'loss_3': -16.24291229248047, 'loss_4': 1.712606430053711, 'epoch': 19.38}
{'loss': 0.0099, 'grad_norm': 8.220569610595703, 'learning_rate': 1.0639534883720931e-05, 'loss_1': 0.006918579339981079, 'loss_2': 0.0029964447021484375, 'loss_3': -16.519977569580078, 'loss_4': 1.969670057296753, 'epoch': 19.38}
{'loss': 0.0059, 'grad_norm': 4.275471210479736, 'learning_rate': 1.0633720930232558e-05, 'loss_1': 0.003981021232903004, 'loss_2': 0.0018939971923828125, 'loss_3': -16.651838302612305, 'loss_4': 1.6907241344451904, 'epoch': 19.39}
[INFO|trainer.py:4228] 2025-01-21 13:42:37,002 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:37,002 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 3340/5160 [1:22:41<31:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:44,367 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010582417249679565, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.641, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007118611596524715, 'eval_loss_2': 0.0034638047218322754, 'eval_loss_3': -18.141502380371094, 'eval_loss_4': 1.4440492391586304, 'epoch': 19.39}
{'loss': 0.0085, 'grad_norm': 4.185428619384766, 'learning_rate': 1.0627906976744185e-05, 'loss_1': 0.004498783964663744, 'loss_2': 0.00403594970703125, 'loss_3': -16.363248825073242, 'loss_4': 1.8719360828399658, 'epoch': 19.4}
{'loss': 0.0064, 'grad_norm': 5.156157970428467, 'learning_rate': 1.0622093023255815e-05, 'loss_1': 0.004527868237346411, 'loss_2': 0.0018520355224609375, 'loss_3': -16.321765899658203, 'loss_4': 1.4941339492797852, 'epoch': 19.4}
{'loss': 0.0228, 'grad_norm': 16.98077392578125, 'learning_rate': 1.0616279069767442e-05, 'loss_1': 0.021821364760398865, 'loss_2': 0.0010051727294921875, 'loss_3': -16.325349807739258, 'loss_4': 1.6203346252441406, 'epoch': 19.41}
{'loss': 0.0145, 'grad_norm': 5.369741439819336, 'learning_rate': 1.061046511627907e-05, 'loss_1': 0.008701483719050884, 'loss_2': 0.00579833984375, 'loss_3': -16.35279083251953, 'loss_4': 0.9368815422058105, 'epoch': 19.41}
{'loss': 0.0153, 'grad_norm': 5.568655967712402, 'learning_rate': 1.0604651162790698e-05, 'loss_1': 0.007709256839007139, 'loss_2': 0.007549285888671875, 'loss_3': -16.449378967285156, 'loss_4': 1.251549482345581, 'epoch': 19.42}
[INFO|trainer.py:4228] 2025-01-21 13:42:44,367 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:44,367 >>   Batch size = 64
 65%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                             | 3345/5160 [1:22:48<31:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:51,719 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011463888920843601, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.158, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.007180371321737766, 'eval_loss_2': 0.004283517599105835, 'eval_loss_3': -18.167011260986328, 'eval_loss_4': 1.2494471073150635, 'epoch': 19.42}
{'loss': 0.0176, 'grad_norm': 7.500831127166748, 'learning_rate': 1.0598837209302325e-05, 'loss_1': 0.015216462314128876, 'loss_2': 0.00235748291015625, 'loss_3': -16.3856258392334, 'loss_4': 1.2629027366638184, 'epoch': 19.42}
{'loss': 0.0278, 'grad_norm': 14.433723449707031, 'learning_rate': 1.0593023255813953e-05, 'loss_1': 0.022900760173797607, 'loss_2': 0.00485992431640625, 'loss_3': -16.405548095703125, 'loss_4': 1.0949437618255615, 'epoch': 19.43}
{'loss': 0.0178, 'grad_norm': 5.138487339019775, 'learning_rate': 1.0587209302325582e-05, 'loss_1': 0.009887310676276684, 'loss_2': 0.00794219970703125, 'loss_3': -16.20098114013672, 'loss_4': 1.353349208831787, 'epoch': 19.44}
{'loss': 0.0085, 'grad_norm': 4.550114154815674, 'learning_rate': 1.058139534883721e-05, 'loss_1': 0.005558731034398079, 'loss_2': 0.002910614013671875, 'loss_3': -16.527799606323242, 'loss_4': 1.5801820755004883, 'epoch': 19.44}
{'loss': 0.0053, 'grad_norm': 4.463446617126465, 'learning_rate': 1.0575581395348837e-05, 'loss_1': 0.005231142044067383, 'loss_2': 5.936622619628906e-05, 'loss_3': -16.68937873840332, 'loss_4': 1.4769313335418701, 'epoch': 19.45}
[INFO|trainer.py:4228] 2025-01-21 13:42:51,719 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:51,719 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                            | 3350/5160 [1:22:56<31:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:42:59,087 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012045320123434067, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.606, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00812124740332365, 'eval_loss_2': 0.003924071788787842, 'eval_loss_3': -18.18137550354004, 'eval_loss_4': 1.2231930494308472, 'epoch': 19.45}
{'loss': 0.0135, 'grad_norm': 4.799251079559326, 'learning_rate': 1.0569767441860466e-05, 'loss_1': 0.004404133651405573, 'loss_2': 0.0090484619140625, 'loss_3': -16.45313262939453, 'loss_4': 1.6442344188690186, 'epoch': 19.45}
{'loss': 0.0066, 'grad_norm': 5.124185562133789, 'learning_rate': 1.0563953488372093e-05, 'loss_1': 0.006420632358640432, 'loss_2': 0.0002040863037109375, 'loss_3': -16.50395965576172, 'loss_4': 1.5905731916427612, 'epoch': 19.46}
{'loss': 0.0116, 'grad_norm': 5.654534816741943, 'learning_rate': 1.055813953488372e-05, 'loss_1': 0.0066427499987185, 'loss_2': 0.00498199462890625, 'loss_3': -16.45116424560547, 'loss_4': 1.3611547946929932, 'epoch': 19.47}
{'loss': 0.0203, 'grad_norm': 13.798810005187988, 'learning_rate': 1.055232558139535e-05, 'loss_1': 0.017084931954741478, 'loss_2': 0.0031681060791015625, 'loss_3': -16.37285614013672, 'loss_4': 1.2419946193695068, 'epoch': 19.47}
{'loss': 0.0141, 'grad_norm': 7.182326793670654, 'learning_rate': 1.0546511627906977e-05, 'loss_1': 0.014079179614782333, 'loss_2': 1.8835067749023438e-05, 'loss_3': -16.675426483154297, 'loss_4': 1.0952837467193604, 'epoch': 19.48}
[INFO|trainer.py:4228] 2025-01-21 13:42:59,087 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:42:59,087 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 3355/5160 [1:23:03<31:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:06,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012585563585162163, 'eval_runtime': 3.819, 'eval_samples_per_second': 268.132, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.009217565879225731, 'eval_loss_2': 0.003367997705936432, 'eval_loss_3': -18.208723068237305, 'eval_loss_4': 1.1933062076568604, 'epoch': 19.48}
{'loss': 0.0151, 'grad_norm': 6.96604061126709, 'learning_rate': 1.0540697674418606e-05, 'loss_1': 0.01217871904373169, 'loss_2': 0.002941131591796875, 'loss_3': -16.367645263671875, 'loss_4': 1.431706190109253, 'epoch': 19.48}
{'loss': 0.0065, 'grad_norm': 4.751269340515137, 'learning_rate': 1.0534883720930233e-05, 'loss_1': 0.003827923210337758, 'loss_2': 0.002704620361328125, 'loss_3': -16.377609252929688, 'loss_4': 1.1727683544158936, 'epoch': 19.49}
{'loss': 0.0134, 'grad_norm': 8.142929077148438, 'learning_rate': 1.052906976744186e-05, 'loss_1': 0.01076485775411129, 'loss_2': 0.0025920867919921875, 'loss_3': -16.543289184570312, 'loss_4': 1.3959522247314453, 'epoch': 19.49}
{'loss': 0.0076, 'grad_norm': 4.9432501792907715, 'learning_rate': 1.0523255813953488e-05, 'loss_1': 0.005247167777270079, 'loss_2': 0.00237274169921875, 'loss_3': -16.452564239501953, 'loss_4': 1.094197154045105, 'epoch': 19.5}
{'loss': 0.0347, 'grad_norm': 30.4493408203125, 'learning_rate': 1.0517441860465117e-05, 'loss_1': 0.030631467700004578, 'loss_2': 0.0041046142578125, 'loss_3': -16.340015411376953, 'loss_4': 1.475135326385498, 'epoch': 19.51}
[INFO|trainer.py:4228] 2025-01-21 13:43:06,454 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:06,454 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                            | 3360/5160 [1:23:10<31:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:13,819 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013287055306136608, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.705, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.009659875184297562, 'eval_loss_2': 0.003627181053161621, 'eval_loss_3': -18.192062377929688, 'eval_loss_4': 1.3060615062713623, 'epoch': 19.51}
{'loss': 0.0117, 'grad_norm': 5.351633071899414, 'learning_rate': 1.0511627906976746e-05, 'loss_1': 0.0068041421473026276, 'loss_2': 0.004913330078125, 'loss_3': -16.43195915222168, 'loss_4': 1.0142364501953125, 'epoch': 19.51}
{'loss': 0.0125, 'grad_norm': 4.366696357727051, 'learning_rate': 1.0505813953488372e-05, 'loss_1': 0.0060113780200481415, 'loss_2': 0.00653839111328125, 'loss_3': -16.386505126953125, 'loss_4': 1.0605454444885254, 'epoch': 19.52}
{'loss': 0.0078, 'grad_norm': 5.61126708984375, 'learning_rate': 1.05e-05, 'loss_1': 0.0046793133951723576, 'loss_2': 0.0030727386474609375, 'loss_3': -16.400951385498047, 'loss_4': 1.1234543323516846, 'epoch': 19.52}
{'loss': 0.0146, 'grad_norm': 6.084317207336426, 'learning_rate': 1.0494186046511628e-05, 'loss_1': 0.009311339817941189, 'loss_2': 0.005283355712890625, 'loss_3': -16.491741180419922, 'loss_4': 1.9671860933303833, 'epoch': 19.53}
{'loss': 0.0112, 'grad_norm': 4.514578819274902, 'learning_rate': 1.0488372093023255e-05, 'loss_1': 0.004865822847932577, 'loss_2': 0.006317138671875, 'loss_3': -16.387348175048828, 'loss_4': 1.249489665031433, 'epoch': 19.53}
[INFO|trainer.py:4228] 2025-01-21 13:43:13,819 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:13,819 >>   Batch size = 64
 65%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 3365/5160 [1:23:18<31:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:21,191 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01252182200551033, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.621, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.009557309560477734, 'eval_loss_2': 0.002964511513710022, 'eval_loss_3': -18.197406768798828, 'eval_loss_4': 1.3672945499420166, 'epoch': 19.53}
{'loss': 0.0065, 'grad_norm': 4.7436370849609375, 'learning_rate': 1.0482558139534885e-05, 'loss_1': 0.006404001731425524, 'loss_2': 5.84721565246582e-05, 'loss_3': -16.438278198242188, 'loss_4': 1.2328886985778809, 'epoch': 19.54}
{'loss': 0.0083, 'grad_norm': 4.84463357925415, 'learning_rate': 1.0476744186046512e-05, 'loss_1': 0.004723934456706047, 'loss_2': 0.003604888916015625, 'loss_3': -16.45449447631836, 'loss_4': 1.0378904342651367, 'epoch': 19.55}
{'loss': 0.0082, 'grad_norm': 5.328752517700195, 'learning_rate': 1.047093023255814e-05, 'loss_1': 0.0057885791175067425, 'loss_2': 0.0023746490478515625, 'loss_3': -16.515836715698242, 'loss_4': 1.4218307733535767, 'epoch': 19.55}
{'loss': 0.0103, 'grad_norm': 6.1909356117248535, 'learning_rate': 1.0465116279069768e-05, 'loss_1': 0.005837452597916126, 'loss_2': 0.0044403076171875, 'loss_3': -16.45733642578125, 'loss_4': 1.7471938133239746, 'epoch': 19.56}
{'loss': 0.0067, 'grad_norm': 4.810965538024902, 'learning_rate': 1.0459302325581395e-05, 'loss_1': 0.004650870803743601, 'loss_2': 0.002033233642578125, 'loss_3': -16.36821937561035, 'loss_4': 0.9052110314369202, 'epoch': 19.56}
[INFO|trainer.py:4228] 2025-01-21 13:43:21,191 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:21,191 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                            | 3370/5160 [1:23:25<31:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:28,550 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01259572058916092, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.778, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008773364126682281, 'eval_loss_2': 0.0038223564624786377, 'eval_loss_3': -18.195056915283203, 'eval_loss_4': 1.436684012413025, 'epoch': 19.56}
{'loss': 0.0069, 'grad_norm': 4.878878116607666, 'learning_rate': 1.0453488372093023e-05, 'loss_1': 0.0060449158772826195, 'loss_2': 0.0008916854858398438, 'loss_3': -16.296798706054688, 'loss_4': 1.5529847145080566, 'epoch': 19.57}
{'loss': 0.0218, 'grad_norm': 5.380498886108398, 'learning_rate': 1.0447674418604652e-05, 'loss_1': 0.009402217343449593, 'loss_2': 0.01239013671875, 'loss_3': -16.458499908447266, 'loss_4': 1.4486318826675415, 'epoch': 19.58}
{'loss': 0.0119, 'grad_norm': 6.859663009643555, 'learning_rate': 1.0441860465116279e-05, 'loss_1': 0.010925793088972569, 'loss_2': 0.0010051727294921875, 'loss_3': -16.621313095092773, 'loss_4': 1.355031132698059, 'epoch': 19.58}
{'loss': 0.0112, 'grad_norm': 5.386418342590332, 'learning_rate': 1.0436046511627908e-05, 'loss_1': 0.007165559101849794, 'loss_2': 0.004070281982421875, 'loss_3': -16.379810333251953, 'loss_4': 1.2502577304840088, 'epoch': 19.59}
{'loss': 0.0059, 'grad_norm': 4.990268230438232, 'learning_rate': 1.0430232558139535e-05, 'loss_1': 0.00400177389383316, 'loss_2': 0.0018587112426757812, 'loss_3': -16.440330505371094, 'loss_4': 1.7034053802490234, 'epoch': 19.59}
[INFO|trainer.py:4228] 2025-01-21 13:43:28,551 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:28,551 >>   Batch size = 64
 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                           | 3375/5160 [1:23:33<30:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:35,913 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011644147336483002, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.114, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007933401502668858, 'eval_loss_2': 0.0037107467651367188, 'eval_loss_3': -18.2096004486084, 'eval_loss_4': 1.4268832206726074, 'epoch': 19.59}
{'loss': 0.009, 'grad_norm': 7.801070690155029, 'learning_rate': 1.0424418604651163e-05, 'loss_1': 0.007371686864644289, 'loss_2': 0.00167083740234375, 'loss_3': -16.46764373779297, 'loss_4': 1.5576715469360352, 'epoch': 19.6}
{'loss': 0.0119, 'grad_norm': 5.431852340698242, 'learning_rate': 1.041860465116279e-05, 'loss_1': 0.005875164642930031, 'loss_2': 0.00598907470703125, 'loss_3': -16.44122886657715, 'loss_4': 1.7422486543655396, 'epoch': 19.6}
{'loss': 0.0093, 'grad_norm': 4.469554901123047, 'learning_rate': 1.0412790697674419e-05, 'loss_1': 0.004897471982985735, 'loss_2': 0.00441741943359375, 'loss_3': -16.397319793701172, 'loss_4': 1.6660053730010986, 'epoch': 19.61}
{'loss': 0.0121, 'grad_norm': 7.259799003601074, 'learning_rate': 1.0406976744186047e-05, 'loss_1': 0.010228162631392479, 'loss_2': 0.0018720626831054688, 'loss_3': -16.57870101928711, 'loss_4': 1.430543065071106, 'epoch': 19.62}
{'loss': 0.0088, 'grad_norm': 5.186304569244385, 'learning_rate': 1.0401162790697674e-05, 'loss_1': 0.006852141115814447, 'loss_2': 0.00197601318359375, 'loss_3': -16.239553451538086, 'loss_4': 1.580910563468933, 'epoch': 19.62}
[INFO|trainer.py:4228] 2025-01-21 13:43:35,913 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:35,913 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                           | 3380/5160 [1:23:40<30:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:43,271 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011781005188822746, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.761, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007914988324046135, 'eval_loss_2': 0.0038660168647766113, 'eval_loss_3': -18.141613006591797, 'eval_loss_4': 1.4521006345748901, 'epoch': 19.62}
{'loss': 0.0082, 'grad_norm': 5.306619644165039, 'learning_rate': 1.0395348837209303e-05, 'loss_1': 0.00652961153537035, 'loss_2': 0.001644134521484375, 'loss_3': -16.439735412597656, 'loss_4': 2.0568606853485107, 'epoch': 19.63}
{'loss': 0.0113, 'grad_norm': 5.681311130523682, 'learning_rate': 1.038953488372093e-05, 'loss_1': 0.008639024570584297, 'loss_2': 0.0026950836181640625, 'loss_3': -16.244205474853516, 'loss_4': 1.7915267944335938, 'epoch': 19.63}
{'loss': 0.0068, 'grad_norm': 5.21183443069458, 'learning_rate': 1.0383720930232559e-05, 'loss_1': 0.00486152246594429, 'loss_2': 0.0019016265869140625, 'loss_3': -16.475723266601562, 'loss_4': 1.3855146169662476, 'epoch': 19.64}
{'loss': 0.0089, 'grad_norm': 4.870121002197266, 'learning_rate': 1.0377906976744187e-05, 'loss_1': 0.006746130995452404, 'loss_2': 0.0021610260009765625, 'loss_3': -16.278369903564453, 'loss_4': 1.8791265487670898, 'epoch': 19.65}
{'loss': 0.0133, 'grad_norm': 5.413510322570801, 'learning_rate': 1.0372093023255814e-05, 'loss_1': 0.007955554872751236, 'loss_2': 0.0053558349609375, 'loss_3': -16.182594299316406, 'loss_4': 1.5896878242492676, 'epoch': 19.65}
[INFO|trainer.py:4228] 2025-01-21 13:43:43,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:43,272 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                           | 3385/5160 [1:23:47<30:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:50,627 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014565913006663322, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.010673199780285358, 'eval_loss_2': 0.0038927122950553894, 'eval_loss_3': -18.106353759765625, 'eval_loss_4': 1.4509862661361694, 'epoch': 19.65}
{'loss': 0.0184, 'grad_norm': 5.630547046661377, 'learning_rate': 1.0366279069767443e-05, 'loss_1': 0.00809062272310257, 'loss_2': 0.0102996826171875, 'loss_3': -16.474655151367188, 'loss_4': 1.6899769306182861, 'epoch': 19.66}
{'loss': 0.0065, 'grad_norm': 4.886895179748535, 'learning_rate': 1.036046511627907e-05, 'loss_1': 0.00476790452376008, 'loss_2': 0.0017557144165039062, 'loss_3': -16.51113510131836, 'loss_4': 1.744579553604126, 'epoch': 19.66}
{'loss': 0.0166, 'grad_norm': 9.248946189880371, 'learning_rate': 1.0354651162790698e-05, 'loss_1': 0.013293920084834099, 'loss_2': 0.0032863616943359375, 'loss_3': -16.276092529296875, 'loss_4': 1.4988267421722412, 'epoch': 19.67}
{'loss': 0.0192, 'grad_norm': 9.08665943145752, 'learning_rate': 1.0348837209302325e-05, 'loss_1': 0.013949884101748466, 'loss_2': 0.005218505859375, 'loss_3': -16.355876922607422, 'loss_4': 1.404787302017212, 'epoch': 19.67}
{'loss': 0.0116, 'grad_norm': 5.032917022705078, 'learning_rate': 1.0343023255813954e-05, 'loss_1': 0.0028084050863981247, 'loss_2': 0.0088043212890625, 'loss_3': -16.390159606933594, 'loss_4': 1.4726543426513672, 'epoch': 19.68}
[INFO|trainer.py:4228] 2025-01-21 13:43:50,628 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:50,628 >>   Batch size = 64
 66%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                           | 3390/5160 [1:23:55<30:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:43:57,987 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019547007977962494, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.991, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.014941691420972347, 'eval_loss_2': 0.004605315625667572, 'eval_loss_3': -18.064022064208984, 'eval_loss_4': 1.4402499198913574, 'epoch': 19.68}
{'loss': 0.0093, 'grad_norm': 5.211828231811523, 'learning_rate': 1.0337209302325582e-05, 'loss_1': 0.006313925143331289, 'loss_2': 0.0030117034912109375, 'loss_3': -16.490371704101562, 'loss_4': 1.9108251333236694, 'epoch': 19.69}
{'loss': 0.0128, 'grad_norm': 6.752195835113525, 'learning_rate': 1.033139534883721e-05, 'loss_1': 0.010821514762938023, 'loss_2': 0.001934051513671875, 'loss_3': -16.229415893554688, 'loss_4': 1.396333932876587, 'epoch': 19.69}
{'loss': 0.0123, 'grad_norm': 4.754227638244629, 'learning_rate': 1.0325581395348838e-05, 'loss_1': 0.003145288210362196, 'loss_2': 0.00919342041015625, 'loss_3': -16.478816986083984, 'loss_4': 1.7995411157608032, 'epoch': 19.7}
{'loss': 0.0138, 'grad_norm': 7.503981113433838, 'learning_rate': 1.0319767441860465e-05, 'loss_1': 0.013488427735865116, 'loss_2': 0.00028061866760253906, 'loss_3': -16.342391967773438, 'loss_4': 1.5094844102859497, 'epoch': 19.7}
{'loss': 0.0694, 'grad_norm': 34.931793212890625, 'learning_rate': 1.0313953488372092e-05, 'loss_1': 0.0674390122294426, 'loss_2': 0.001922607421875, 'loss_3': -16.553482055664062, 'loss_4': 1.4928457736968994, 'epoch': 19.71}
[INFO|trainer.py:4228] 2025-01-21 13:43:57,987 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:43:57,988 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                           | 3395/5160 [1:24:02<30:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:05,348 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019507989287376404, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.814, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01502593606710434, 'eval_loss_2': 0.004482053220272064, 'eval_loss_3': -18.058279037475586, 'eval_loss_4': 1.3562544584274292, 'epoch': 19.71}
{'loss': 0.0639, 'grad_norm': 27.619426727294922, 'learning_rate': 1.0308139534883722e-05, 'loss_1': 0.05284266546368599, 'loss_2': 0.011077880859375, 'loss_3': -16.19183349609375, 'loss_4': 1.6154569387435913, 'epoch': 19.72}
{'loss': 0.0092, 'grad_norm': 6.707520008087158, 'learning_rate': 1.030232558139535e-05, 'loss_1': 0.0077399383299052715, 'loss_2': 0.001499176025390625, 'loss_3': -16.306743621826172, 'loss_4': 1.423112154006958, 'epoch': 19.72}
{'loss': 0.0189, 'grad_norm': 14.5665922164917, 'learning_rate': 1.0296511627906978e-05, 'loss_1': 0.015676729381084442, 'loss_2': 0.0032558441162109375, 'loss_3': -16.337886810302734, 'loss_4': 1.608618974685669, 'epoch': 19.73}
{'loss': 0.0097, 'grad_norm': 5.100660800933838, 'learning_rate': 1.0290697674418605e-05, 'loss_1': 0.003629575716331601, 'loss_2': 0.00609588623046875, 'loss_3': -16.45151138305664, 'loss_4': 1.7051715850830078, 'epoch': 19.73}
{'loss': 0.0082, 'grad_norm': 4.9394636154174805, 'learning_rate': 1.0284883720930232e-05, 'loss_1': 0.0037832476664334536, 'loss_2': 0.004436492919921875, 'loss_3': -16.438711166381836, 'loss_4': 1.1598162651062012, 'epoch': 19.74}
[INFO|trainer.py:4228] 2025-01-21 13:44:05,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:05,349 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                          | 3400/5160 [1:24:09<30:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:12,712 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016697825863957405, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.939, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.012164066545665264, 'eval_loss_2': 0.004533760249614716, 'eval_loss_3': -18.051340103149414, 'eval_loss_4': 1.237532138824463, 'epoch': 19.74}
{'loss': 0.0123, 'grad_norm': 4.95754861831665, 'learning_rate': 1.027906976744186e-05, 'loss_1': 0.006870577111840248, 'loss_2': 0.0054473876953125, 'loss_3': -16.510459899902344, 'loss_4': 1.5590417385101318, 'epoch': 19.74}
{'loss': 0.0142, 'grad_norm': 6.23684549331665, 'learning_rate': 1.0273255813953489e-05, 'loss_1': 0.010926643386483192, 'loss_2': 0.003284454345703125, 'loss_3': -16.293058395385742, 'loss_4': 1.1561721563339233, 'epoch': 19.75}
{'loss': 0.0111, 'grad_norm': 6.693700313568115, 'learning_rate': 1.0267441860465118e-05, 'loss_1': 0.005590131040662527, 'loss_2': 0.005489349365234375, 'loss_3': -16.39097023010254, 'loss_4': 1.199083924293518, 'epoch': 19.76}
{'loss': 0.0112, 'grad_norm': 4.710253715515137, 'learning_rate': 1.0261627906976745e-05, 'loss_1': 0.004996964242309332, 'loss_2': 0.006244659423828125, 'loss_3': -16.283597946166992, 'loss_4': 1.2961528301239014, 'epoch': 19.76}
{'loss': 0.0081, 'grad_norm': 5.631009578704834, 'learning_rate': 1.0255813953488371e-05, 'loss_1': 0.008081957697868347, 'loss_2': 6.473064422607422e-05, 'loss_3': -16.1499080657959, 'loss_4': 1.2248039245605469, 'epoch': 19.77}
[INFO|trainer.py:4228] 2025-01-21 13:44:12,712 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:12,712 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                          | 3405/5160 [1:24:17<30:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:20,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015688106417655945, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.868, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.012555195949971676, 'eval_loss_2': 0.0031329095363616943, 'eval_loss_3': -18.038719177246094, 'eval_loss_4': 1.0637375116348267, 'epoch': 19.77}
{'loss': 0.0156, 'grad_norm': 6.986815452575684, 'learning_rate': 1.025e-05, 'loss_1': 0.012354332953691483, 'loss_2': 0.0032329559326171875, 'loss_3': -16.454374313354492, 'loss_4': 1.0626955032348633, 'epoch': 19.77}
{'loss': 0.0096, 'grad_norm': 5.547038555145264, 'learning_rate': 1.0244186046511627e-05, 'loss_1': 0.0061823660507798195, 'loss_2': 0.0033817291259765625, 'loss_3': -16.352266311645508, 'loss_4': 1.1240037679672241, 'epoch': 19.78}
{'loss': 0.0217, 'grad_norm': 11.830483436584473, 'learning_rate': 1.0238372093023257e-05, 'loss_1': 0.017292456701397896, 'loss_2': 0.004360198974609375, 'loss_3': -16.289033889770508, 'loss_4': 1.0556741952896118, 'epoch': 19.78}
{'loss': 0.0333, 'grad_norm': 16.140134811401367, 'learning_rate': 1.0232558139534884e-05, 'loss_1': 0.023607343435287476, 'loss_2': 0.0096588134765625, 'loss_3': -16.309165954589844, 'loss_4': 0.8456988334655762, 'epoch': 19.79}
{'loss': 0.0132, 'grad_norm': 4.570601463317871, 'learning_rate': 1.0226744186046511e-05, 'loss_1': 0.0043948134407401085, 'loss_2': 0.0087738037109375, 'loss_3': -16.33553123474121, 'loss_4': 1.0726089477539062, 'epoch': 19.8}
[INFO|trainer.py:4228] 2025-01-21 13:44:20,076 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:20,077 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                          | 3410/5160 [1:24:24<30:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:27,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020369816571474075, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.495, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.015570570714771748, 'eval_loss_2': 0.004799246788024902, 'eval_loss_3': -18.042741775512695, 'eval_loss_4': 0.8626363277435303, 'epoch': 19.8}
{'loss': 0.0145, 'grad_norm': 5.240329742431641, 'learning_rate': 1.022093023255814e-05, 'loss_1': 0.005537231918424368, 'loss_2': 0.009002685546875, 'loss_3': -16.29930305480957, 'loss_4': 0.6873204708099365, 'epoch': 19.8}
{'loss': 0.019, 'grad_norm': 4.957486152648926, 'learning_rate': 1.0215116279069767e-05, 'loss_1': 0.006090163718909025, 'loss_2': 0.0129241943359375, 'loss_3': -16.20417022705078, 'loss_4': 0.9498207569122314, 'epoch': 19.81}
{'loss': 0.0205, 'grad_norm': 13.86635684967041, 'learning_rate': 1.0209302325581395e-05, 'loss_1': 0.013398819603025913, 'loss_2': 0.007080078125, 'loss_3': -16.491573333740234, 'loss_4': 1.1424942016601562, 'epoch': 19.81}
{'loss': 0.0277, 'grad_norm': 13.253838539123535, 'learning_rate': 1.0203488372093024e-05, 'loss_1': 0.026092544198036194, 'loss_2': 0.0015583038330078125, 'loss_3': -16.272390365600586, 'loss_4': 1.2378392219543457, 'epoch': 19.82}
{'loss': 0.0117, 'grad_norm': 5.607880592346191, 'learning_rate': 1.0197674418604653e-05, 'loss_1': 0.006794079206883907, 'loss_2': 0.004856109619140625, 'loss_3': -16.2065486907959, 'loss_4': 1.170965313911438, 'epoch': 19.83}
[INFO|trainer.py:4228] 2025-01-21 13:44:27,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:27,446 >>   Batch size = 64
 66%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                          | 3415/5160 [1:24:31<30:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:34,808 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.020971037447452545, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.816, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.01762423664331436, 'eval_loss_2': 0.0033468008041381836, 'eval_loss_3': -18.051727294921875, 'eval_loss_4': 0.8183578848838806, 'epoch': 19.83}
{'loss': 0.0142, 'grad_norm': 7.198532581329346, 'learning_rate': 1.019186046511628e-05, 'loss_1': 0.007260322570800781, 'loss_2': 0.006927490234375, 'loss_3': -16.380393981933594, 'loss_4': 1.1634438037872314, 'epoch': 19.83}
{'loss': 0.0186, 'grad_norm': 6.793414115905762, 'learning_rate': 1.0186046511627907e-05, 'loss_1': 0.010342341847717762, 'loss_2': 0.00823211669921875, 'loss_3': -16.240386962890625, 'loss_4': 0.7183215618133545, 'epoch': 19.84}
{'loss': 0.0124, 'grad_norm': 4.863117694854736, 'learning_rate': 1.0180232558139535e-05, 'loss_1': 0.0061461604200303555, 'loss_2': 0.00626373291015625, 'loss_3': -16.373661041259766, 'loss_4': 1.0677170753479004, 'epoch': 19.84}
{'loss': 0.0063, 'grad_norm': 5.150648593902588, 'learning_rate': 1.0174418604651162e-05, 'loss_1': 0.006078168284147978, 'loss_2': 0.00020205974578857422, 'loss_3': -16.434175491333008, 'loss_4': 0.8880500793457031, 'epoch': 19.85}
{'loss': 0.007, 'grad_norm': 4.665198802947998, 'learning_rate': 1.0168604651162793e-05, 'loss_1': 0.004321108106523752, 'loss_2': 0.0026302337646484375, 'loss_3': -16.598499298095703, 'loss_4': 0.9301817417144775, 'epoch': 19.85}
[INFO|trainer.py:4228] 2025-01-21 13:44:34,808 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:34,808 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 3420/5160 [1:24:39<30:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:42,162 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02255655825138092, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.143, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.020119206979870796, 'eval_loss_2': 0.0024373531341552734, 'eval_loss_3': -18.025537490844727, 'eval_loss_4': 0.808181643486023, 'epoch': 19.85}
{'loss': 0.1497, 'grad_norm': 42.1783332824707, 'learning_rate': 1.016279069767442e-05, 'loss_1': 0.14944647252559662, 'loss_2': 0.000232696533203125, 'loss_3': -16.190277099609375, 'loss_4': 1.0377631187438965, 'epoch': 19.86}
{'loss': 0.009, 'grad_norm': 6.575557231903076, 'learning_rate': 1.0156976744186046e-05, 'loss_1': 0.007772965356707573, 'loss_2': 0.0012664794921875, 'loss_3': -16.36069107055664, 'loss_4': 1.0037639141082764, 'epoch': 19.87}
{'loss': 0.0078, 'grad_norm': 4.429439544677734, 'learning_rate': 1.0151162790697675e-05, 'loss_1': 0.004660489968955517, 'loss_2': 0.00310516357421875, 'loss_3': -16.452983856201172, 'loss_4': 0.8869843482971191, 'epoch': 19.87}
{'loss': 0.0139, 'grad_norm': 6.2379841804504395, 'learning_rate': 1.0145348837209302e-05, 'loss_1': 0.007316164672374725, 'loss_2': 0.00662994384765625, 'loss_3': -16.390331268310547, 'loss_4': 1.3362157344818115, 'epoch': 19.88}
{'loss': 0.016, 'grad_norm': 5.3890910148620605, 'learning_rate': 1.013953488372093e-05, 'loss_1': 0.014080354943871498, 'loss_2': 0.001941680908203125, 'loss_3': -16.48048210144043, 'loss_4': 0.9139308929443359, 'epoch': 19.88}
[INFO|trainer.py:4228] 2025-01-21 13:44:42,163 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:42,163 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                         | 3425/5160 [1:24:46<30:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:49,529 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017583610489964485, 'eval_runtime': 3.8127, 'eval_samples_per_second': 268.573, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.012599947862327099, 'eval_loss_2': 0.004983663558959961, 'eval_loss_3': -18.064210891723633, 'eval_loss_4': 0.8670223951339722, 'epoch': 19.88}
{'loss': 0.0048, 'grad_norm': 5.033617973327637, 'learning_rate': 1.013372093023256e-05, 'loss_1': 0.0037701292894780636, 'loss_2': 0.00098419189453125, 'loss_3': -16.454219818115234, 'loss_4': 1.1827003955841064, 'epoch': 19.89}
{'loss': 0.0078, 'grad_norm': 6.193598747253418, 'learning_rate': 1.0127906976744186e-05, 'loss_1': 0.006298463325947523, 'loss_2': 0.0015230178833007812, 'loss_3': -16.35004234313965, 'loss_4': 0.8691433668136597, 'epoch': 19.9}
{'loss': 0.0093, 'grad_norm': 5.046871662139893, 'learning_rate': 1.0122093023255815e-05, 'loss_1': 0.0033489542547613382, 'loss_2': 0.005916595458984375, 'loss_3': -16.44366455078125, 'loss_4': 1.2794461250305176, 'epoch': 19.9}
{'loss': 0.0116, 'grad_norm': 6.2194719314575195, 'learning_rate': 1.0116279069767442e-05, 'loss_1': 0.008259979076683521, 'loss_2': 0.0033626556396484375, 'loss_3': -16.32738494873047, 'loss_4': 0.5753835439682007, 'epoch': 19.91}
{'loss': 0.0123, 'grad_norm': 6.531764984130859, 'learning_rate': 1.011046511627907e-05, 'loss_1': 0.004770427010953426, 'loss_2': 0.007537841796875, 'loss_3': -16.496253967285156, 'loss_4': 0.8181109428405762, 'epoch': 19.91}
[INFO|trainer.py:4228] 2025-01-21 13:44:49,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:49,529 >>   Batch size = 64
 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                         | 3430/5160 [1:24:54<29:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:44:56,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.017184153199195862, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.924, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.009358537383377552, 'eval_loss_2': 0.007825613021850586, 'eval_loss_3': -18.087942123413086, 'eval_loss_4': 1.0174723863601685, 'epoch': 19.91}
{'loss': 0.0103, 'grad_norm': 5.52203893661499, 'learning_rate': 1.0104651162790697e-05, 'loss_1': 0.008102395571768284, 'loss_2': 0.00217437744140625, 'loss_3': -16.399051666259766, 'loss_4': 0.9758442044258118, 'epoch': 19.92}
{'loss': 0.013, 'grad_norm': 4.106188774108887, 'learning_rate': 1.0098837209302326e-05, 'loss_1': 0.0041093421168625355, 'loss_2': 0.0089263916015625, 'loss_3': -16.492416381835938, 'loss_4': 1.9521702527999878, 'epoch': 19.92}
{'loss': 0.0063, 'grad_norm': 4.8230977058410645, 'learning_rate': 1.0093023255813955e-05, 'loss_1': 0.005954499822109938, 'loss_2': 0.00038313865661621094, 'loss_3': -16.63116455078125, 'loss_4': 1.378116488456726, 'epoch': 19.93}
{'loss': 0.0135, 'grad_norm': 4.590731620788574, 'learning_rate': 1.0087209302325581e-05, 'loss_1': 0.006270977668464184, 'loss_2': 0.00717926025390625, 'loss_3': -16.425342559814453, 'loss_4': 1.146905541419983, 'epoch': 19.94}
{'loss': 0.008, 'grad_norm': 5.153406143188477, 'learning_rate': 1.008139534883721e-05, 'loss_1': 0.003959406167268753, 'loss_2': 0.004047393798828125, 'loss_3': -16.53205108642578, 'loss_4': 1.730654001235962, 'epoch': 19.94}
[INFO|trainer.py:4228] 2025-01-21 13:44:56,889 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:44:56,889 >>   Batch size = 64
 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                         | 3435/5160 [1:25:01<29:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:04,256 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0125039741396904, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.589, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00714131398126483, 'eval_loss_2': 0.005362659692764282, 'eval_loss_3': -18.11602020263672, 'eval_loss_4': 1.1951655149459839, 'epoch': 19.94}
{'loss': 0.0141, 'grad_norm': 5.438737392425537, 'learning_rate': 1.0075581395348837e-05, 'loss_1': 0.009491912089288235, 'loss_2': 0.00460052490234375, 'loss_3': -16.407127380371094, 'loss_4': 1.248633861541748, 'epoch': 19.95}
{'loss': 0.0139, 'grad_norm': 5.714786052703857, 'learning_rate': 1.0069767441860464e-05, 'loss_1': 0.008061581291258335, 'loss_2': 0.00582122802734375, 'loss_3': -16.46070098876953, 'loss_4': 1.4397597312927246, 'epoch': 19.95}
{'loss': 0.0068, 'grad_norm': 4.764964580535889, 'learning_rate': 1.0063953488372094e-05, 'loss_1': 0.005641368683427572, 'loss_2': 0.0011272430419921875, 'loss_3': -16.30043601989746, 'loss_4': 0.9286043643951416, 'epoch': 19.96}
{'loss': 0.0147, 'grad_norm': 6.564810752868652, 'learning_rate': 1.0058139534883721e-05, 'loss_1': 0.0115085169672966, 'loss_2': 0.003177642822265625, 'loss_3': -16.245574951171875, 'loss_4': 1.2982368469238281, 'epoch': 19.97}
{'loss': 0.0608, 'grad_norm': 26.487667083740234, 'learning_rate': 1.005232558139535e-05, 'loss_1': 0.06054963916540146, 'loss_2': 0.0002105236053466797, 'loss_3': -16.413166046142578, 'loss_4': 1.7900108098983765, 'epoch': 19.97}
[INFO|trainer.py:4228] 2025-01-21 13:45:04,256 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:04,256 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                         | 3440/5160 [1:25:08<26:48,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 13:45:11,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008595898747444153, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004997566342353821, 'eval_loss_2': 0.003598332405090332, 'eval_loss_3': -18.124597549438477, 'eval_loss_4': 1.2451483011245728, 'epoch': 19.97}
{'loss': 0.0116, 'grad_norm': 4.904547691345215, 'learning_rate': 1.0046511627906977e-05, 'loss_1': 0.007933029904961586, 'loss_2': 0.003650665283203125, 'loss_3': -16.385154724121094, 'loss_4': 1.6958847045898438, 'epoch': 19.98}
{'loss': 0.0159, 'grad_norm': 8.806048393249512, 'learning_rate': 1.0040697674418604e-05, 'loss_1': 0.012520086020231247, 'loss_2': 0.003398895263671875, 'loss_3': -16.255512237548828, 'loss_4': 1.0448510646820068, 'epoch': 19.98}
{'loss': 0.0171, 'grad_norm': 5.088687419891357, 'learning_rate': 1.0034883720930232e-05, 'loss_1': 0.007176110986620188, 'loss_2': 0.0099029541015625, 'loss_3': -16.19028091430664, 'loss_4': 1.6736664772033691, 'epoch': 19.99}
{'loss': 0.0138, 'grad_norm': 4.848400115966797, 'learning_rate': 1.0029069767441861e-05, 'loss_1': 0.005047481041401625, 'loss_2': 0.008758544921875, 'loss_3': -16.449459075927734, 'loss_4': 1.4318797588348389, 'epoch': 19.99}
{'loss': 0.0112, 'grad_norm': 6.637324333190918, 'learning_rate': 1.002325581395349e-05, 'loss_1': 0.0048727234825491905, 'loss_2': 0.00630950927734375, 'loss_3': -16.33819007873535, 'loss_4': 1.5658732652664185, 'epoch': 20.0}
[INFO|trainer.py:4228] 2025-01-21 13:45:11,261 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:11,261 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                        | 3445/5160 [1:25:15<29:19,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:45:18,663 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008959177881479263, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.843, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005144420079886913, 'eval_loss_2': 0.0038147568702697754, 'eval_loss_3': -18.12343978881836, 'eval_loss_4': 1.3130508661270142, 'epoch': 20.0}
{'loss': 0.0068, 'grad_norm': 4.924722194671631, 'learning_rate': 1.0017441860465117e-05, 'loss_1': 0.005751740653067827, 'loss_2': 0.0010824203491210938, 'loss_3': -16.643831253051758, 'loss_4': 1.8050119876861572, 'epoch': 20.01}
{'loss': 0.0134, 'grad_norm': 5.324802398681641, 'learning_rate': 1.0011627906976745e-05, 'loss_1': 0.008937678299844265, 'loss_2': 0.00447845458984375, 'loss_3': -16.475255966186523, 'loss_4': 1.605918049812317, 'epoch': 20.01}
{'loss': 0.008, 'grad_norm': 4.6601996421813965, 'learning_rate': 1.0005813953488372e-05, 'loss_1': 0.005842253100126982, 'loss_2': 0.0021648406982421875, 'loss_3': -16.583873748779297, 'loss_4': 1.9350366592407227, 'epoch': 20.02}
{'loss': 0.0221, 'grad_norm': 6.581545352935791, 'learning_rate': 9.999999999999999e-06, 'loss_1': 0.02003917284309864, 'loss_2': 0.0020599365234375, 'loss_3': -16.176115036010742, 'loss_4': 2.455596446990967, 'epoch': 20.02}
{'loss': 0.017, 'grad_norm': 7.1014556884765625, 'learning_rate': 9.994186046511628e-06, 'loss_1': 0.014297607354819775, 'loss_2': 0.0027332305908203125, 'loss_3': -16.652931213378906, 'loss_4': 2.29776668548584, 'epoch': 20.03}
[INFO|trainer.py:4228] 2025-01-21 13:45:18,663 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:18,663 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 3450/5160 [1:25:23<29:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:26,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010515187866985798, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.125, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005738412030041218, 'eval_loss_2': 0.00477677583694458, 'eval_loss_3': -18.14738655090332, 'eval_loss_4': 1.4640332460403442, 'epoch': 20.03}
{'loss': 0.0242, 'grad_norm': 18.053123474121094, 'learning_rate': 9.988372093023256e-06, 'loss_1': 0.023334691300988197, 'loss_2': 0.0009136199951171875, 'loss_3': -16.342504501342773, 'loss_4': 1.4866995811462402, 'epoch': 20.03}
{'loss': 0.0124, 'grad_norm': 5.344310283660889, 'learning_rate': 9.982558139534885e-06, 'loss_1': 0.006013211794197559, 'loss_2': 0.006420135498046875, 'loss_3': -16.403379440307617, 'loss_4': 2.0319273471832275, 'epoch': 20.04}
{'loss': 0.009, 'grad_norm': 5.416762351989746, 'learning_rate': 9.976744186046512e-06, 'loss_1': 0.005768956616520882, 'loss_2': 0.003246307373046875, 'loss_3': -16.495166778564453, 'loss_4': 1.5669522285461426, 'epoch': 20.05}
{'loss': 0.0049, 'grad_norm': 5.109646320343018, 'learning_rate': 9.970930232558139e-06, 'loss_1': 0.00336853857152164, 'loss_2': 0.0015707015991210938, 'loss_3': -16.498945236206055, 'loss_4': 1.8490374088287354, 'epoch': 20.05}
{'loss': 0.0118, 'grad_norm': 5.30330228805542, 'learning_rate': 9.965116279069768e-06, 'loss_1': 0.010323997586965561, 'loss_2': 0.001506805419921875, 'loss_3': -16.319189071655273, 'loss_4': 1.7280009984970093, 'epoch': 20.06}
[INFO|trainer.py:4228] 2025-01-21 13:45:26,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:26,019 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                        | 3455/5160 [1:25:30<29:56,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 13:45:33,573 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012942574918270111, 'eval_runtime': 3.9989, 'eval_samples_per_second': 256.071, 'eval_steps_per_second': 4.001, 'eval_loss_1': 0.006343130953609943, 'eval_loss_2': 0.006599444895982742, 'eval_loss_3': -18.13408851623535, 'eval_loss_4': 1.490783929824829, 'epoch': 20.06}
{'loss': 0.0134, 'grad_norm': 4.788237571716309, 'learning_rate': 9.959302325581394e-06, 'loss_1': 0.006861417088657618, 'loss_2': 0.0065765380859375, 'loss_3': -16.373512268066406, 'loss_4': 1.4553310871124268, 'epoch': 20.06}
{'loss': 0.0136, 'grad_norm': 4.4892449378967285, 'learning_rate': 9.953488372093025e-06, 'loss_1': 0.005473480559885502, 'loss_2': 0.00811767578125, 'loss_3': -16.399948120117188, 'loss_4': 1.963141679763794, 'epoch': 20.07}
{'loss': 0.0068, 'grad_norm': 4.174715042114258, 'learning_rate': 9.947674418604652e-06, 'loss_1': 0.00355503149330616, 'loss_2': 0.00325775146484375, 'loss_3': -16.246780395507812, 'loss_4': 1.8639553785324097, 'epoch': 20.08}
{'loss': 0.0183, 'grad_norm': 5.229759216308594, 'learning_rate': 9.941860465116279e-06, 'loss_1': 0.008063254877924919, 'loss_2': 0.01019287109375, 'loss_3': -16.433685302734375, 'loss_4': 1.5584607124328613, 'epoch': 20.08}
{'loss': 0.0213, 'grad_norm': 5.18156099319458, 'learning_rate': 9.936046511627907e-06, 'loss_1': 0.007452885154634714, 'loss_2': 0.01385498046875, 'loss_3': -16.396495819091797, 'loss_4': 1.866345763206482, 'epoch': 20.09}
[INFO|trainer.py:4228] 2025-01-21 13:45:33,573 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:33,574 >>   Batch size = 64
 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                        | 3460/5160 [1:25:38<29:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:40,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011409285478293896, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.961, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006234678439795971, 'eval_loss_2': 0.005174607038497925, 'eval_loss_3': -18.126724243164062, 'eval_loss_4': 1.4825841188430786, 'epoch': 20.09}
{'loss': 0.0148, 'grad_norm': 4.928464889526367, 'learning_rate': 9.930232558139534e-06, 'loss_1': 0.0064337532967329025, 'loss_2': 0.008392333984375, 'loss_3': -16.31956672668457, 'loss_4': 2.337294578552246, 'epoch': 20.09}
{'loss': 0.0067, 'grad_norm': 6.027460098266602, 'learning_rate': 9.924418604651163e-06, 'loss_1': 0.006304413080215454, 'loss_2': 0.0003528594970703125, 'loss_3': -16.32818603515625, 'loss_4': 1.4911811351776123, 'epoch': 20.1}
{'loss': 0.0244, 'grad_norm': 7.209388732910156, 'learning_rate': 9.918604651162792e-06, 'loss_1': 0.016149349510669708, 'loss_2': 0.00827789306640625, 'loss_3': -16.274574279785156, 'loss_4': 1.8010220527648926, 'epoch': 20.1}
{'loss': 0.0157, 'grad_norm': 9.462307929992676, 'learning_rate': 9.912790697674418e-06, 'loss_1': 0.009784137830138206, 'loss_2': 0.0059051513671875, 'loss_3': -16.291690826416016, 'loss_4': 1.5449351072311401, 'epoch': 20.11}
{'loss': 0.0156, 'grad_norm': 14.79415225982666, 'learning_rate': 9.906976744186047e-06, 'loss_1': 0.014857308939099312, 'loss_2': 0.00074005126953125, 'loss_3': -16.155641555786133, 'loss_4': 1.8235009908676147, 'epoch': 20.12}
[INFO|trainer.py:4228] 2025-01-21 13:45:40,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:40,937 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 3465/5160 [1:25:45<29:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:48,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00930794421583414, 'eval_runtime': 3.8248, 'eval_samples_per_second': 267.727, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.005670944694429636, 'eval_loss_2': 0.0036370009183883667, 'eval_loss_3': -18.116371154785156, 'eval_loss_4': 1.4568849802017212, 'epoch': 20.12}
{'loss': 0.0132, 'grad_norm': 6.690927505493164, 'learning_rate': 9.901162790697674e-06, 'loss_1': 0.012893522158265114, 'loss_2': 0.0002899169921875, 'loss_3': -16.378957748413086, 'loss_4': 1.50139582157135, 'epoch': 20.12}
{'loss': 0.0062, 'grad_norm': 5.084168434143066, 'learning_rate': 9.895348837209303e-06, 'loss_1': 0.004097599070519209, 'loss_2': 0.002086639404296875, 'loss_3': -16.491004943847656, 'loss_4': 1.3204797506332397, 'epoch': 20.13}
{'loss': 0.0112, 'grad_norm': 4.601020812988281, 'learning_rate': 9.88953488372093e-06, 'loss_1': 0.006335366517305374, 'loss_2': 0.004913330078125, 'loss_3': -16.449460983276367, 'loss_4': 1.9387770891189575, 'epoch': 20.13}
{'loss': 0.0151, 'grad_norm': 12.152812957763672, 'learning_rate': 9.883720930232558e-06, 'loss_1': 0.014801722019910812, 'loss_2': 0.0002918243408203125, 'loss_3': -16.499839782714844, 'loss_4': 1.434792399406433, 'epoch': 20.14}
{'loss': 0.0107, 'grad_norm': 5.468208312988281, 'learning_rate': 9.877906976744187e-06, 'loss_1': 0.006388416979461908, 'loss_2': 0.0042724609375, 'loss_3': -16.23989486694336, 'loss_4': 1.4992088079452515, 'epoch': 20.15}
[INFO|trainer.py:4228] 2025-01-21 13:45:48,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:48,307 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 3470/5160 [1:25:52<29:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:45:55,668 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009737944230437279, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005634373053908348, 'eval_loss_2': 0.004103571176528931, 'eval_loss_3': -18.1309814453125, 'eval_loss_4': 1.4211989641189575, 'epoch': 20.15}
{'loss': 0.0095, 'grad_norm': 4.748867511749268, 'learning_rate': 9.872093023255814e-06, 'loss_1': 0.006553881801664829, 'loss_2': 0.0029449462890625, 'loss_3': -16.501623153686523, 'loss_4': 1.6615591049194336, 'epoch': 20.15}
{'loss': 0.0144, 'grad_norm': 6.772791385650635, 'learning_rate': 9.866279069767442e-06, 'loss_1': 0.007783976383507252, 'loss_2': 0.006603240966796875, 'loss_3': -16.478513717651367, 'loss_4': 1.4603188037872314, 'epoch': 20.16}
{'loss': 0.0147, 'grad_norm': 4.733617782592773, 'learning_rate': 9.86046511627907e-06, 'loss_1': 0.003381717251613736, 'loss_2': 0.01131439208984375, 'loss_3': -16.483959197998047, 'loss_4': 1.9531577825546265, 'epoch': 20.16}
{'loss': 0.0077, 'grad_norm': 4.503384113311768, 'learning_rate': 9.854651162790696e-06, 'loss_1': 0.003678625449538231, 'loss_2': 0.00402069091796875, 'loss_3': -16.483356475830078, 'loss_4': 1.510998249053955, 'epoch': 20.17}
{'loss': 0.0116, 'grad_norm': 4.824029445648193, 'learning_rate': 9.848837209302327e-06, 'loss_1': 0.005539218429476023, 'loss_2': 0.00604248046875, 'loss_3': -16.220605850219727, 'loss_4': 1.2205078601837158, 'epoch': 20.17}
[INFO|trainer.py:4228] 2025-01-21 13:45:55,668 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:45:55,668 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:26:00<29:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:03,038 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00941451732069254, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.989, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00548135582357645, 'eval_loss_2': 0.003933161497116089, 'eval_loss_3': -18.135883331298828, 'eval_loss_4': 1.3135168552398682, 'epoch': 20.17}
{'loss': 0.0052, 'grad_norm': 4.721353054046631, 'learning_rate': 9.843023255813954e-06, 'loss_1': 0.004185391589999199, 'loss_2': 0.0010585784912109375, 'loss_3': -16.384246826171875, 'loss_4': 1.602081537246704, 'epoch': 20.18}
{'loss': 0.0058, 'grad_norm': 5.174831867218018, 'learning_rate': 9.837209302325582e-06, 'loss_1': 0.0037389330100268126, 'loss_2': 0.0020751953125, 'loss_3': -16.47872543334961, 'loss_4': 1.7886701822280884, 'epoch': 20.19}
{'loss': 0.0266, 'grad_norm': 17.329479217529297, 'learning_rate': 9.831395348837209e-06, 'loss_1': 0.02421354502439499, 'loss_2': 0.00238800048828125, 'loss_3': -16.40535545349121, 'loss_4': 1.7074103355407715, 'epoch': 20.19}
{'loss': 0.0122, 'grad_norm': 5.360471248626709, 'learning_rate': 9.825581395348838e-06, 'loss_1': 0.005970953498035669, 'loss_2': 0.006256103515625, 'loss_3': -16.288549423217773, 'loss_4': 1.522662878036499, 'epoch': 20.2}
{'loss': 0.0103, 'grad_norm': 4.570096015930176, 'learning_rate': 9.819767441860465e-06, 'loss_1': 0.007110800594091415, 'loss_2': 0.0031890869140625, 'loss_3': -16.413665771484375, 'loss_4': 1.6748957633972168, 'epoch': 20.2}
[INFO|trainer.py:4228] 2025-01-21 13:46:03,038 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:03,038 >>   Batch size = 64
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 3475/5160 [1:26:03<29:15,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 13:46:06,849 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-3475
[INFO|configuration_utils.py:420] 2025-01-21 13:46:06,851 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-3475/config.json                                                                            
{'eval_loss': 0.007662676274776459, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.742, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.004946328233927488, 'eval_loss_2': 0.002716347575187683, 'eval_loss_3': -18.128704071044922, 'eval_loss_4': 1.1585960388183594, 'epoch': 20.2}
[INFO|modeling_utils.py:2988] 2025-01-21 13:46:07,338 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-3475/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 13:46:07,339 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-3475/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 13:46:07,339 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-3475/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 13:46:08,366 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-1700] due to args.save_total_limit
 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                       | 3480/5160 [1:26:09<32:22,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 13:46:12,012 >>
{'loss': 0.0089, 'grad_norm': 4.662245273590088, 'learning_rate': 9.813953488372093e-06, 'loss_1': 0.00368761969730258, 'loss_2': 0.0052337646484375, 'loss_3': -16.41672706604004, 'loss_4': 1.690535306930542, 'epoch': 20.21}
{'loss': 0.0072, 'grad_norm': 5.664456367492676, 'learning_rate': 9.808139534883722e-06, 'loss_1': 0.0037872318644076586, 'loss_2': 0.0034046173095703125, 'loss_3': -16.372426986694336, 'loss_4': 1.0778610706329346, 'epoch': 20.22}
{'loss': 0.0051, 'grad_norm': 4.651783466339111, 'learning_rate': 9.802325581395349e-06, 'loss_1': 0.0049905055202543736, 'loss_2': 0.00012373924255371094, 'loss_3': -16.39992904663086, 'loss_4': 1.37046480178833, 'epoch': 20.22}
{'loss': 0.0075, 'grad_norm': 4.47999906539917, 'learning_rate': 9.796511627906978e-06, 'loss_1': 0.0029115856159478426, 'loss_2': 0.004543304443359375, 'loss_3': -16.341659545898438, 'loss_4': 0.986236035823822, 'epoch': 20.23}
{'loss': 0.0069, 'grad_norm': 4.866767406463623, 'learning_rate': 9.790697674418604e-06, 'loss_1': 0.005191641394048929, 'loss_2': 0.0016651153564453125, 'loss_3': -16.357166290283203, 'loss_4': 1.0960859060287476, 'epoch': 20.23}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 13:46:12,012 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:12,013 >>   Batch size = 64
 68%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                       | 3485/5160 [1:26:16<29:35,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 13:46:19,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008302380330860615, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.742, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005088081583380699, 'eval_loss_2': 0.0032142996788024902, 'eval_loss_3': -18.122785568237305, 'eval_loss_4': 1.0676264762878418, 'epoch': 20.23}
{'loss': 0.0209, 'grad_norm': 9.812681198120117, 'learning_rate': 9.784883720930231e-06, 'loss_1': 0.01705124042928219, 'loss_2': 0.003894805908203125, 'loss_3': -16.454059600830078, 'loss_4': 1.13932204246521, 'epoch': 20.24}
{'loss': 0.0083, 'grad_norm': 4.903353691101074, 'learning_rate': 9.779069767441862e-06, 'loss_1': 0.003486151108518243, 'loss_2': 0.00484466552734375, 'loss_3': -16.382291793823242, 'loss_4': 0.9469345808029175, 'epoch': 20.24}
{'loss': 0.0092, 'grad_norm': 4.953521251678467, 'learning_rate': 9.773255813953489e-06, 'loss_1': 0.005337387323379517, 'loss_2': 0.00390625, 'loss_3': -16.231525421142578, 'loss_4': 1.056110143661499, 'epoch': 20.25}
{'loss': 0.0051, 'grad_norm': 5.178483009338379, 'learning_rate': 9.767441860465117e-06, 'loss_1': 0.0032982933335006237, 'loss_2': 0.0017747879028320312, 'loss_3': -16.299684524536133, 'loss_4': 0.8508056998252869, 'epoch': 20.26}
{'loss': 0.0139, 'grad_norm': 12.542803764343262, 'learning_rate': 9.761627906976744e-06, 'loss_1': 0.009782838635146618, 'loss_2': 0.004070281982421875, 'loss_3': -16.567840576171875, 'loss_4': 1.4531043767929077, 'epoch': 20.26}
[INFO|trainer.py:4228] 2025-01-21 13:46:19,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:19,381 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                       | 3490/5160 [1:26:23<29:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:26,750 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009683266282081604, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.404, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005805373191833496, 'eval_loss_2': 0.003877893090248108, 'eval_loss_3': -18.124679565429688, 'eval_loss_4': 1.061724305152893, 'epoch': 20.26}
{'loss': 0.0049, 'grad_norm': 5.245059490203857, 'learning_rate': 9.755813953488371e-06, 'loss_1': 0.0035194919910281897, 'loss_2': 0.0013885498046875, 'loss_3': -16.491195678710938, 'loss_4': 1.3948771953582764, 'epoch': 20.27}
{'loss': 0.0092, 'grad_norm': 5.641244411468506, 'learning_rate': 9.75e-06, 'loss_1': 0.007660697679966688, 'loss_2': 0.0015840530395507812, 'loss_3': -16.346330642700195, 'loss_4': 1.2481019496917725, 'epoch': 20.27}
{'loss': 0.0067, 'grad_norm': 5.17017936706543, 'learning_rate': 9.744186046511628e-06, 'loss_1': 0.0044043478555977345, 'loss_2': 0.002338409423828125, 'loss_3': -16.298744201660156, 'loss_4': 1.3920644521713257, 'epoch': 20.28}
{'loss': 0.0099, 'grad_norm': 4.77194356918335, 'learning_rate': 9.738372093023257e-06, 'loss_1': 0.004536403343081474, 'loss_2': 0.005352020263671875, 'loss_3': -16.283477783203125, 'loss_4': 0.8896150588989258, 'epoch': 20.28}
{'loss': 0.0072, 'grad_norm': 5.383761405944824, 'learning_rate': 9.732558139534884e-06, 'loss_1': 0.006135681644082069, 'loss_2': 0.0010356903076171875, 'loss_3': -16.395004272460938, 'loss_4': 1.4098031520843506, 'epoch': 20.29}
[INFO|trainer.py:4228] 2025-01-21 13:46:26,750 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:26,750 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                      | 3495/5160 [1:26:31<28:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:34,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008476943708956242, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.771, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.0052405791357159615, 'eval_loss_2': 0.00323636457324028, 'eval_loss_3': -18.12601089477539, 'eval_loss_4': 0.9892699122428894, 'epoch': 20.29}
{'loss': 0.0047, 'grad_norm': 4.922398090362549, 'learning_rate': 9.726744186046511e-06, 'loss_1': 0.0028000844176858664, 'loss_2': 0.0019245147705078125, 'loss_3': -16.313444137573242, 'loss_4': 0.836905300617218, 'epoch': 20.3}
{'loss': 0.0174, 'grad_norm': 10.361555099487305, 'learning_rate': 9.72093023255814e-06, 'loss_1': 0.01620296575129032, 'loss_2': 0.001148223876953125, 'loss_3': -16.432025909423828, 'loss_4': 1.2167824506759644, 'epoch': 20.3}
{'loss': 0.0072, 'grad_norm': 4.720715045928955, 'learning_rate': 9.715116279069767e-06, 'loss_1': 0.0051758261397480965, 'loss_2': 0.0019931793212890625, 'loss_3': -16.44440460205078, 'loss_4': 1.6248729228973389, 'epoch': 20.31}
{'loss': 0.0083, 'grad_norm': 5.632521152496338, 'learning_rate': 9.709302325581397e-06, 'loss_1': 0.006150540895760059, 'loss_2': 0.002147674560546875, 'loss_3': -16.445377349853516, 'loss_4': 0.5152397751808167, 'epoch': 20.31}
{'loss': 0.0156, 'grad_norm': 10.256754875183105, 'learning_rate': 9.703488372093024e-06, 'loss_1': 0.012456707656383514, 'loss_2': 0.003185272216796875, 'loss_3': -16.30514144897461, 'loss_4': 1.224962592124939, 'epoch': 20.32}
[INFO|trainer.py:4228] 2025-01-21 13:46:34,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:34,115 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                      | 3500/5160 [1:26:38<28:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:41,476 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009463825263082981, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.932, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0056895846500992775, 'eval_loss_2': 0.0037742406129837036, 'eval_loss_3': -18.108596801757812, 'eval_loss_4': 0.907569408416748, 'epoch': 20.32}
{'loss': 0.014, 'grad_norm': 5.899812698364258, 'learning_rate': 9.69767441860465e-06, 'loss_1': 0.006939963437616825, 'loss_2': 0.00704193115234375, 'loss_3': -16.425018310546875, 'loss_4': 0.8378781080245972, 'epoch': 20.33}
{'loss': 0.0183, 'grad_norm': 13.13828182220459, 'learning_rate': 9.69186046511628e-06, 'loss_1': 0.01548251137137413, 'loss_2': 0.002803802490234375, 'loss_3': -16.491334915161133, 'loss_4': 1.1131587028503418, 'epoch': 20.33}
{'loss': 0.0094, 'grad_norm': 5.006972789764404, 'learning_rate': 9.686046511627906e-06, 'loss_1': 0.004953079391270876, 'loss_2': 0.004425048828125, 'loss_3': -16.37314796447754, 'loss_4': 0.5449297428131104, 'epoch': 20.34}
{'loss': 0.0137, 'grad_norm': 4.5299506187438965, 'learning_rate': 9.680232558139535e-06, 'loss_1': 0.0033453120850026608, 'loss_2': 0.0103912353515625, 'loss_3': -16.4332275390625, 'loss_4': 1.004929780960083, 'epoch': 20.34}
{'loss': 0.0169, 'grad_norm': 5.379101276397705, 'learning_rate': 9.674418604651164e-06, 'loss_1': 0.005356879904866219, 'loss_2': 0.01149749755859375, 'loss_3': -16.34178924560547, 'loss_4': 0.9119600057601929, 'epoch': 20.35}
[INFO|trainer.py:4228] 2025-01-21 13:46:41,477 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:41,477 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 3505/5160 [1:26:45<28:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:48,845 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01018485240638256, 'eval_runtime': 3.809, 'eval_samples_per_second': 268.839, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006127534434199333, 'eval_loss_2': 0.0040573179721832275, 'eval_loss_3': -18.093624114990234, 'eval_loss_4': 0.8903512954711914, 'epoch': 20.35}
{'loss': 0.0174, 'grad_norm': 7.22517204284668, 'learning_rate': 9.66860465116279e-06, 'loss_1': 0.010526846162974834, 'loss_2': 0.0068359375, 'loss_3': -16.52754020690918, 'loss_4': 1.3653833866119385, 'epoch': 20.35}
{'loss': 0.0679, 'grad_norm': 26.628944396972656, 'learning_rate': 9.662790697674419e-06, 'loss_1': 0.06437299400568008, 'loss_2': 0.003543853759765625, 'loss_3': -16.345726013183594, 'loss_4': 1.0789541006088257, 'epoch': 20.36}
{'loss': 0.0235, 'grad_norm': 10.037328720092773, 'learning_rate': 9.656976744186046e-06, 'loss_1': 0.016069205477833748, 'loss_2': 0.0074462890625, 'loss_3': -16.288970947265625, 'loss_4': 0.7104153633117676, 'epoch': 20.37}
{'loss': 0.0056, 'grad_norm': 5.039877891540527, 'learning_rate': 9.651162790697675e-06, 'loss_1': 0.004290373995900154, 'loss_2': 0.0013370513916015625, 'loss_3': -16.428804397583008, 'loss_4': 0.8969218134880066, 'epoch': 20.37}
{'loss': 0.038, 'grad_norm': 25.35064697265625, 'learning_rate': 9.645348837209302e-06, 'loss_1': 0.030416250228881836, 'loss_2': 0.00762939453125, 'loss_3': -16.288166046142578, 'loss_4': 0.6116050481796265, 'epoch': 20.38}
[INFO|trainer.py:4228] 2025-01-21 13:46:48,845 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:48,845 >>   Batch size = 64
 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                      | 3510/5160 [1:26:53<28:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:46:56,200 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011119022034108639, 'eval_runtime': 3.8053, 'eval_samples_per_second': 269.1, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006910508498549461, 'eval_loss_2': 0.004208512604236603, 'eval_loss_3': -18.089908599853516, 'eval_loss_4': 0.8771052956581116, 'epoch': 20.38}
{'loss': 0.0086, 'grad_norm': 5.0730977058410645, 'learning_rate': 9.639534883720932e-06, 'loss_1': 0.005488130263984203, 'loss_2': 0.0031280517578125, 'loss_3': -16.24432373046875, 'loss_4': 1.0696892738342285, 'epoch': 20.38}
{'loss': 0.0071, 'grad_norm': 5.3579583168029785, 'learning_rate': 9.633720930232559e-06, 'loss_1': 0.004452106077224016, 'loss_2': 0.002655029296875, 'loss_3': -16.268598556518555, 'loss_4': 0.6281498670578003, 'epoch': 20.39}
{'loss': 0.0064, 'grad_norm': 5.736923694610596, 'learning_rate': 9.627906976744186e-06, 'loss_1': 0.005667011719197035, 'loss_2': 0.0007677078247070312, 'loss_3': -16.281505584716797, 'loss_4': 0.811069667339325, 'epoch': 20.4}
{'loss': 0.0068, 'grad_norm': 6.122213363647461, 'learning_rate': 9.622093023255814e-06, 'loss_1': 0.005468421149998903, 'loss_2': 0.001293182373046875, 'loss_3': -16.24840545654297, 'loss_4': 1.1352505683898926, 'epoch': 20.4}
{'loss': 0.0068, 'grad_norm': 4.580502510070801, 'learning_rate': 9.616279069767441e-06, 'loss_1': 0.002798583125695586, 'loss_2': 0.0040283203125, 'loss_3': -16.329851150512695, 'loss_4': 0.7625328302383423, 'epoch': 20.41}
[INFO|trainer.py:4228] 2025-01-21 13:46:56,200 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:46:56,200 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                     | 3515/5160 [1:27:00<28:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:03,568 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011477195657789707, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.782, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007857173681259155, 'eval_loss_2': 0.0036200210452079773, 'eval_loss_3': -18.087989807128906, 'eval_loss_4': 0.8317393660545349, 'epoch': 20.41}
{'loss': 0.0045, 'grad_norm': 5.671236515045166, 'learning_rate': 9.61046511627907e-06, 'loss_1': 0.004443442914634943, 'loss_2': 8.165836334228516e-05, 'loss_3': -16.347604751586914, 'loss_4': 1.033159852027893, 'epoch': 20.41}
{'loss': 0.0161, 'grad_norm': 5.394995212554932, 'learning_rate': 9.604651162790699e-06, 'loss_1': 0.007045303471386433, 'loss_2': 0.00909423828125, 'loss_3': -16.399972915649414, 'loss_4': 0.619464635848999, 'epoch': 20.42}
{'loss': 0.0053, 'grad_norm': 4.659255027770996, 'learning_rate': 9.598837209302326e-06, 'loss_1': 0.002768496051430702, 'loss_2': 0.002529144287109375, 'loss_3': -16.34518051147461, 'loss_4': 0.9157495498657227, 'epoch': 20.42}
{'loss': 0.0129, 'grad_norm': 6.196284294128418, 'learning_rate': 9.593023255813954e-06, 'loss_1': 0.011476904153823853, 'loss_2': 0.001468658447265625, 'loss_3': -16.364002227783203, 'loss_4': 0.6666799187660217, 'epoch': 20.43}
{'loss': 0.0068, 'grad_norm': 4.501026630401611, 'learning_rate': 9.587209302325581e-06, 'loss_1': 0.004170199856162071, 'loss_2': 0.002666473388671875, 'loss_3': -16.24492073059082, 'loss_4': 1.0058928728103638, 'epoch': 20.44}
[INFO|trainer.py:4228] 2025-01-21 13:47:03,568 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:03,568 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                     | 3520/5160 [1:27:08<28:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:10,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012103267014026642, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.518, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.008317209780216217, 'eval_loss_2': 0.003786057233810425, 'eval_loss_3': -18.1060848236084, 'eval_loss_4': 0.8594986200332642, 'epoch': 20.44}
{'loss': 0.0093, 'grad_norm': 4.447113037109375, 'learning_rate': 9.58139534883721e-06, 'loss_1': 0.00358646921813488, 'loss_2': 0.0057373046875, 'loss_3': -16.257694244384766, 'loss_4': 1.5494121313095093, 'epoch': 20.44}
{'loss': 0.0084, 'grad_norm': 5.116560935974121, 'learning_rate': 9.575581395348837e-06, 'loss_1': 0.006773808505386114, 'loss_2': 0.00160980224609375, 'loss_3': -16.413225173950195, 'loss_4': 0.6251345276832581, 'epoch': 20.45}
{'loss': 0.0048, 'grad_norm': 4.890045642852783, 'learning_rate': 9.569767441860465e-06, 'loss_1': 0.003249102272093296, 'loss_2': 0.001522064208984375, 'loss_3': -16.29016876220703, 'loss_4': 0.9664503335952759, 'epoch': 20.45}
{'loss': 0.0046, 'grad_norm': 4.898536205291748, 'learning_rate': 9.563953488372094e-06, 'loss_1': 0.003681998699903488, 'loss_2': 0.0009388923645019531, 'loss_3': -16.42831039428711, 'loss_4': 0.7046543955802917, 'epoch': 20.46}
{'loss': 0.016, 'grad_norm': 5.002974987030029, 'learning_rate': 9.558139534883721e-06, 'loss_1': 0.0073051187209784985, 'loss_2': 0.0087127685546875, 'loss_3': -16.218381881713867, 'loss_4': 0.38962799310684204, 'epoch': 20.47}
[INFO|trainer.py:4228] 2025-01-21 13:47:10,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:10,935 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 3525/5160 [1:27:15<28:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:18,294 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013150293380022049, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00965800415724516, 'eval_loss_2': 0.003492288291454315, 'eval_loss_3': -18.121591567993164, 'eval_loss_4': 0.9415410757064819, 'epoch': 20.47}
{'loss': 0.0154, 'grad_norm': 8.402478218078613, 'learning_rate': 9.55232558139535e-06, 'loss_1': 0.011277985759079456, 'loss_2': 0.004077911376953125, 'loss_3': -16.209413528442383, 'loss_4': 1.2878994941711426, 'epoch': 20.47}
{'loss': 0.0082, 'grad_norm': 3.958221673965454, 'learning_rate': 9.546511627906977e-06, 'loss_1': 0.004608946852385998, 'loss_2': 0.0035552978515625, 'loss_3': -16.335399627685547, 'loss_4': 0.9697127342224121, 'epoch': 20.48}
{'loss': 0.0654, 'grad_norm': 15.049318313598633, 'learning_rate': 9.540697674418603e-06, 'loss_1': 0.061645202338695526, 'loss_2': 0.00376129150390625, 'loss_3': -16.33930015563965, 'loss_4': 0.9966576099395752, 'epoch': 20.48}
{'loss': 0.0068, 'grad_norm': 5.096426010131836, 'learning_rate': 9.534883720930234e-06, 'loss_1': 0.004555359948426485, 'loss_2': 0.0022125244140625, 'loss_3': -16.151674270629883, 'loss_4': 0.9768152236938477, 'epoch': 20.49}
{'loss': 0.0162, 'grad_norm': 6.129577159881592, 'learning_rate': 9.52906976744186e-06, 'loss_1': 0.006591674406081438, 'loss_2': 0.00963592529296875, 'loss_3': -16.38089370727539, 'loss_4': 1.2737491130828857, 'epoch': 20.49}
[INFO|trainer.py:4228] 2025-01-21 13:47:18,294 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:18,294 >>   Batch size = 64
 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 3530/5160 [1:27:22<28:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:25,659 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014271074905991554, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.009719067253172398, 'eval_loss_2': 0.004552006721496582, 'eval_loss_3': -18.128490447998047, 'eval_loss_4': 1.0431512594223022, 'epoch': 20.49}
{'loss': 0.0148, 'grad_norm': 5.494140148162842, 'learning_rate': 9.52325581395349e-06, 'loss_1': 0.009277135133743286, 'loss_2': 0.005542755126953125, 'loss_3': -16.339046478271484, 'loss_4': 1.0501384735107422, 'epoch': 20.5}
{'loss': 0.0177, 'grad_norm': 8.228694915771484, 'learning_rate': 9.517441860465116e-06, 'loss_1': 0.01668671891093254, 'loss_2': 0.0010385513305664062, 'loss_3': -16.557849884033203, 'loss_4': 1.2348089218139648, 'epoch': 20.51}
{'loss': 0.0177, 'grad_norm': 5.770893096923828, 'learning_rate': 9.511627906976743e-06, 'loss_1': 0.006855721585452557, 'loss_2': 0.0108489990234375, 'loss_3': -16.366607666015625, 'loss_4': 0.998914897441864, 'epoch': 20.51}
{'loss': 0.0179, 'grad_norm': 7.408159255981445, 'learning_rate': 9.505813953488372e-06, 'loss_1': 0.014078621752560139, 'loss_2': 0.003810882568359375, 'loss_3': -16.207744598388672, 'loss_4': 1.3472847938537598, 'epoch': 20.52}
{'loss': 0.0218, 'grad_norm': 9.613879203796387, 'learning_rate': 9.5e-06, 'loss_1': 0.019147494807839394, 'loss_2': 0.002628326416015625, 'loss_3': -16.357749938964844, 'loss_4': 0.9172495603561401, 'epoch': 20.52}
[INFO|trainer.py:4228] 2025-01-21 13:47:25,659 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:25,659 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                     | 3535/5160 [1:27:30<28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:33,011 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013155465945601463, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.047, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.009601203724741936, 'eval_loss_2': 0.0035542622208595276, 'eval_loss_3': -18.103351593017578, 'eval_loss_4': 1.0956695079803467, 'epoch': 20.52}
{'loss': 0.0093, 'grad_norm': 5.504857540130615, 'learning_rate': 9.49418604651163e-06, 'loss_1': 0.005784056149423122, 'loss_2': 0.0035495758056640625, 'loss_3': -16.459575653076172, 'loss_4': 0.8736894130706787, 'epoch': 20.53}
{'loss': 0.0089, 'grad_norm': 4.900384902954102, 'learning_rate': 9.488372093023256e-06, 'loss_1': 0.004158866126090288, 'loss_2': 0.004779815673828125, 'loss_3': -16.044193267822266, 'loss_4': 1.1783254146575928, 'epoch': 20.53}
{'loss': 0.0072, 'grad_norm': 5.819417476654053, 'learning_rate': 9.482558139534883e-06, 'loss_1': 0.006282530725002289, 'loss_2': 0.0009255409240722656, 'loss_3': -16.5362491607666, 'loss_4': 1.0914220809936523, 'epoch': 20.54}
{'loss': 0.0078, 'grad_norm': 4.930016994476318, 'learning_rate': 9.476744186046512e-06, 'loss_1': 0.006068029440939426, 'loss_2': 0.0016832351684570312, 'loss_3': -16.262252807617188, 'loss_4': 1.3998842239379883, 'epoch': 20.55}
{'loss': 0.0105, 'grad_norm': 4.406707763671875, 'learning_rate': 9.470930232558139e-06, 'loss_1': 0.004450727719813585, 'loss_2': 0.006076812744140625, 'loss_3': -16.257816314697266, 'loss_4': 1.452825665473938, 'epoch': 20.55}
[INFO|trainer.py:4228] 2025-01-21 13:47:33,011 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:33,011 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                    | 3540/5160 [1:27:37<28:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:40,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011724157258868217, 'eval_runtime': 3.8083, 'eval_samples_per_second': 268.884, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.008351800963282585, 'eval_loss_2': 0.0033723562955856323, 'eval_loss_3': -18.104841232299805, 'eval_loss_4': 1.1668556928634644, 'epoch': 20.55}
{'loss': 0.0121, 'grad_norm': 7.592408657073975, 'learning_rate': 9.465116279069769e-06, 'loss_1': 0.008039514534175396, 'loss_2': 0.004108428955078125, 'loss_3': -16.37093734741211, 'loss_4': 1.308739185333252, 'epoch': 20.56}
{'loss': 0.0076, 'grad_norm': 4.66071891784668, 'learning_rate': 9.459302325581396e-06, 'loss_1': 0.006236150860786438, 'loss_2': 0.0013189315795898438, 'loss_3': -16.406112670898438, 'loss_4': 1.2098181247711182, 'epoch': 20.56}
{'loss': 0.0151, 'grad_norm': 5.403025150299072, 'learning_rate': 9.453488372093024e-06, 'loss_1': 0.008271929807960987, 'loss_2': 0.006824493408203125, 'loss_3': -16.172073364257812, 'loss_4': 0.922599196434021, 'epoch': 20.57}
{'loss': 0.0072, 'grad_norm': 3.936702013015747, 'learning_rate': 9.447674418604651e-06, 'loss_1': 0.003758067265152931, 'loss_2': 0.003459930419921875, 'loss_3': -16.396657943725586, 'loss_4': 1.4601750373840332, 'epoch': 20.58}
{'loss': 0.006, 'grad_norm': 5.197291851043701, 'learning_rate': 9.441860465116278e-06, 'loss_1': 0.005620831623673439, 'loss_2': 0.0003476142883300781, 'loss_3': -16.535348892211914, 'loss_4': 1.6609857082366943, 'epoch': 20.58}
[INFO|trainer.py:4228] 2025-01-21 13:47:40,382 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:40,382 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 3545/5160 [1:27:44<28:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:47,752 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012054357677698135, 'eval_runtime': 3.8137, 'eval_samples_per_second': 268.505, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008642585948109627, 'eval_loss_2': 0.0034117698669433594, 'eval_loss_3': -18.101070404052734, 'eval_loss_4': 1.2822179794311523, 'epoch': 20.58}
{'loss': 0.0064, 'grad_norm': 4.501538276672363, 'learning_rate': 9.436046511627907e-06, 'loss_1': 0.005791716277599335, 'loss_2': 0.0005593299865722656, 'loss_3': -16.377134323120117, 'loss_4': 1.765582799911499, 'epoch': 20.59}
{'loss': 0.0082, 'grad_norm': 4.424932956695557, 'learning_rate': 9.430232558139536e-06, 'loss_1': 0.004016905557364225, 'loss_2': 0.004150390625, 'loss_3': -16.21903419494629, 'loss_4': 1.0745505094528198, 'epoch': 20.59}
{'loss': 0.0062, 'grad_norm': 5.3878326416015625, 'learning_rate': 9.424418604651164e-06, 'loss_1': 0.0047548022121191025, 'loss_2': 0.0014286041259765625, 'loss_3': -16.420507431030273, 'loss_4': 1.8115019798278809, 'epoch': 20.6}
{'loss': 0.0189, 'grad_norm': 9.005406379699707, 'learning_rate': 9.418604651162791e-06, 'loss_1': 0.01379641704261303, 'loss_2': 0.005084991455078125, 'loss_3': -16.20801544189453, 'loss_4': 1.8326488733291626, 'epoch': 20.6}
{'loss': 0.0073, 'grad_norm': 4.756752014160156, 'learning_rate': 9.412790697674418e-06, 'loss_1': 0.004489116836339235, 'loss_2': 0.00283050537109375, 'loss_3': -16.399642944335938, 'loss_4': 1.8438060283660889, 'epoch': 20.61}
[INFO|trainer.py:4228] 2025-01-21 13:47:47,752 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:47,752 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                    | 3550/5160 [1:27:52<27:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:47:55,111 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012556006200611591, 'eval_runtime': 3.8045, 'eval_samples_per_second': 269.157, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.009109427221119404, 'eval_loss_2': 0.0034465789794921875, 'eval_loss_3': -18.111522674560547, 'eval_loss_4': 1.3337750434875488, 'epoch': 20.61}
{'loss': 0.0223, 'grad_norm': 9.703664779663086, 'learning_rate': 9.406976744186047e-06, 'loss_1': 0.019582828506827354, 'loss_2': 0.0027618408203125, 'loss_3': -16.288803100585938, 'loss_4': 1.6506208181381226, 'epoch': 20.62}
{'loss': 0.0073, 'grad_norm': 4.865265369415283, 'learning_rate': 9.401162790697674e-06, 'loss_1': 0.004238985478878021, 'loss_2': 0.0030975341796875, 'loss_3': -16.558170318603516, 'loss_4': 1.731874704360962, 'epoch': 20.62}
{'loss': 0.0106, 'grad_norm': 4.646787166595459, 'learning_rate': 9.395348837209304e-06, 'loss_1': 0.0028325947932899, 'loss_2': 0.0078125, 'loss_3': -16.551937103271484, 'loss_4': 1.0414538383483887, 'epoch': 20.63}
{'loss': 0.0182, 'grad_norm': 6.553972244262695, 'learning_rate': 9.389534883720931e-06, 'loss_1': 0.010256937704980373, 'loss_2': 0.00794219970703125, 'loss_3': -16.352733612060547, 'loss_4': 1.3973896503448486, 'epoch': 20.63}
{'loss': 0.0157, 'grad_norm': 7.34113883972168, 'learning_rate': 9.383720930232558e-06, 'loss_1': 0.011779780499637127, 'loss_2': 0.003925323486328125, 'loss_3': -16.283878326416016, 'loss_4': 1.0700106620788574, 'epoch': 20.64}
[INFO|trainer.py:4228] 2025-01-21 13:47:55,111 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:47:55,111 >>   Batch size = 64
 69%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                    | 3555/5160 [1:27:59<27:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:02,471 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013010873459279537, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.923, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00905169453471899, 'eval_loss_2': 0.003959178924560547, 'eval_loss_3': -18.1294002532959, 'eval_loss_4': 1.3355540037155151, 'epoch': 20.64}
{'loss': 0.0082, 'grad_norm': 4.686899662017822, 'learning_rate': 9.377906976744187e-06, 'loss_1': 0.006323367822915316, 'loss_2': 0.001926422119140625, 'loss_3': -16.209091186523438, 'loss_4': 1.3272340297698975, 'epoch': 20.65}
{'loss': 0.0076, 'grad_norm': 4.573576927185059, 'learning_rate': 9.372093023255813e-06, 'loss_1': 0.00342603144235909, 'loss_2': 0.00412750244140625, 'loss_3': -16.355133056640625, 'loss_4': 1.5187580585479736, 'epoch': 20.65}
{'loss': 0.0078, 'grad_norm': 4.448403835296631, 'learning_rate': 9.366279069767442e-06, 'loss_1': 0.004891724791377783, 'loss_2': 0.0029144287109375, 'loss_3': -16.549222946166992, 'loss_4': 1.616889238357544, 'epoch': 20.66}
{'loss': 0.0082, 'grad_norm': 5.1788740158081055, 'learning_rate': 9.36046511627907e-06, 'loss_1': 0.005364703945815563, 'loss_2': 0.00281524658203125, 'loss_3': -16.29258155822754, 'loss_4': 1.7975695133209229, 'epoch': 20.66}
{'loss': 0.0104, 'grad_norm': 4.612061023712158, 'learning_rate': 9.354651162790698e-06, 'loss_1': 0.0033554250840097666, 'loss_2': 0.007076263427734375, 'loss_3': -16.26297950744629, 'loss_4': 1.5267705917358398, 'epoch': 20.67}
[INFO|trainer.py:4228] 2025-01-21 13:48:02,471 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:02,471 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                    | 3560/5160 [1:28:06<27:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:09,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014215742237865925, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.111, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.00997083354741335, 'eval_loss_2': 0.004244908690452576, 'eval_loss_3': -18.139549255371094, 'eval_loss_4': 1.3546459674835205, 'epoch': 20.67}
{'loss': 0.0126, 'grad_norm': 5.194243907928467, 'learning_rate': 9.348837209302326e-06, 'loss_1': 0.00488710030913353, 'loss_2': 0.0077056884765625, 'loss_3': -16.490676879882812, 'loss_4': 1.5781110525131226, 'epoch': 20.67}
{'loss': 0.0051, 'grad_norm': 4.456028938293457, 'learning_rate': 9.343023255813953e-06, 'loss_1': 0.0033601645845919847, 'loss_2': 0.0017137527465820312, 'loss_3': -16.344688415527344, 'loss_4': 1.2568306922912598, 'epoch': 20.68}
{'loss': 0.0099, 'grad_norm': 4.866258144378662, 'learning_rate': 9.337209302325582e-06, 'loss_1': 0.006995463743805885, 'loss_2': 0.00292205810546875, 'loss_3': -16.200716018676758, 'loss_4': 1.1543062925338745, 'epoch': 20.69}
{'loss': 0.0181, 'grad_norm': 6.6035871505737305, 'learning_rate': 9.331395348837209e-06, 'loss_1': 0.010520788840949535, 'loss_2': 0.007537841796875, 'loss_3': -16.090051651000977, 'loss_4': 1.6153640747070312, 'epoch': 20.69}
{'loss': 0.0047, 'grad_norm': 4.085165977478027, 'learning_rate': 9.325581395348837e-06, 'loss_1': 0.003300884971395135, 'loss_2': 0.0013980865478515625, 'loss_3': -16.361583709716797, 'loss_4': 1.4272336959838867, 'epoch': 20.7}
[INFO|trainer.py:4228] 2025-01-21 13:48:09,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:09,830 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                   | 3565/5160 [1:28:14<27:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:17,190 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012667620554566383, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008637333288788795, 'eval_loss_2': 0.004030287265777588, 'eval_loss_3': -18.13800048828125, 'eval_loss_4': 1.3928446769714355, 'epoch': 20.7}
{'loss': 0.0031, 'grad_norm': 4.389355182647705, 'learning_rate': 9.319767441860466e-06, 'loss_1': 0.0031299134716391563, 'loss_2': 1.3113021850585938e-05, 'loss_3': -16.4282169342041, 'loss_4': 1.263500690460205, 'epoch': 20.7}
{'loss': 0.0102, 'grad_norm': 8.043418884277344, 'learning_rate': 9.313953488372093e-06, 'loss_1': 0.010003941133618355, 'loss_2': 0.00020611286163330078, 'loss_3': -16.29319953918457, 'loss_4': 1.5163137912750244, 'epoch': 20.71}
{'loss': 0.012, 'grad_norm': 6.102475643157959, 'learning_rate': 9.308139534883722e-06, 'loss_1': 0.007397990208119154, 'loss_2': 0.00458526611328125, 'loss_3': -16.355716705322266, 'loss_4': 1.8074891567230225, 'epoch': 20.72}
{'loss': 0.0074, 'grad_norm': 5.60822057723999, 'learning_rate': 9.302325581395349e-06, 'loss_1': 0.006200350821018219, 'loss_2': 0.001155853271484375, 'loss_3': -16.475866317749023, 'loss_4': 1.4251770973205566, 'epoch': 20.72}
{'loss': 0.013, 'grad_norm': 9.694676399230957, 'learning_rate': 9.296511627906976e-06, 'loss_1': 0.011449374258518219, 'loss_2': 0.0015621185302734375, 'loss_3': -16.306392669677734, 'loss_4': 1.2992321252822876, 'epoch': 20.73}
[INFO|trainer.py:4228] 2025-01-21 13:48:17,190 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:17,190 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                   | 3570/5160 [1:28:21<27:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:24,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012583421543240547, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.445, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.008141475729644299, 'eval_loss_2': 0.004441946744918823, 'eval_loss_3': -18.147993087768555, 'eval_loss_4': 1.48103666305542, 'epoch': 20.73}
{'loss': 0.012, 'grad_norm': 5.321742534637451, 'learning_rate': 9.290697674418606e-06, 'loss_1': 0.00851596798747778, 'loss_2': 0.0035152435302734375, 'loss_3': -16.137744903564453, 'loss_4': 1.5518388748168945, 'epoch': 20.73}
{'loss': 0.0105, 'grad_norm': 4.657278060913086, 'learning_rate': 9.284883720930233e-06, 'loss_1': 0.004517316352576017, 'loss_2': 0.00594329833984375, 'loss_3': -16.469913482666016, 'loss_4': 1.4303011894226074, 'epoch': 20.74}
{'loss': 0.0102, 'grad_norm': 4.910385608673096, 'learning_rate': 9.279069767441861e-06, 'loss_1': 0.006836728658527136, 'loss_2': 0.00336456298828125, 'loss_3': -16.27819061279297, 'loss_4': 1.42063570022583, 'epoch': 20.74}
{'loss': 0.003, 'grad_norm': 4.694857597351074, 'learning_rate': 9.273255813953488e-06, 'loss_1': 0.0022405029740184546, 'loss_2': 0.0007901191711425781, 'loss_3': -16.638437271118164, 'loss_4': 2.0054287910461426, 'epoch': 20.75}
{'loss': 0.0092, 'grad_norm': 4.955475330352783, 'learning_rate': 9.267441860465117e-06, 'loss_1': 0.008048512041568756, 'loss_2': 0.001129150390625, 'loss_3': -16.47103500366211, 'loss_4': 1.5653972625732422, 'epoch': 20.76}
[INFO|trainer.py:4228] 2025-01-21 13:48:24,563 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:24,563 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 3575/5160 [1:28:29<27:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:31,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011448642238974571, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.586, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.00806056335568428, 'eval_loss_2': 0.0033880770206451416, 'eval_loss_3': -18.148340225219727, 'eval_loss_4': 1.5717153549194336, 'epoch': 20.76}
{'loss': 0.0272, 'grad_norm': 9.859726905822754, 'learning_rate': 9.261627906976744e-06, 'loss_1': 0.02196379005908966, 'loss_2': 0.0052642822265625, 'loss_3': -16.177284240722656, 'loss_4': 1.6167360544204712, 'epoch': 20.76}
{'loss': 0.0064, 'grad_norm': 4.452151298522949, 'learning_rate': 9.255813953488373e-06, 'loss_1': 0.002935734111815691, 'loss_2': 0.00350189208984375, 'loss_3': -16.420669555664062, 'loss_4': 1.3964765071868896, 'epoch': 20.77}
{'loss': 0.013, 'grad_norm': 4.850152492523193, 'learning_rate': 9.250000000000001e-06, 'loss_1': 0.005299902055412531, 'loss_2': 0.0076904296875, 'loss_3': -16.214811325073242, 'loss_4': 1.3479810953140259, 'epoch': 20.77}
{'loss': 0.0087, 'grad_norm': 5.73000955581665, 'learning_rate': 9.244186046511628e-06, 'loss_1': 0.006697920151054859, 'loss_2': 0.0020084381103515625, 'loss_3': -16.327037811279297, 'loss_4': 1.8173192739486694, 'epoch': 20.78}
{'loss': 0.0053, 'grad_norm': 4.554205894470215, 'learning_rate': 9.238372093023257e-06, 'loss_1': 0.003300710814073682, 'loss_2': 0.0020351409912109375, 'loss_3': -16.266874313354492, 'loss_4': 1.8140950202941895, 'epoch': 20.78}
[INFO|trainer.py:4228] 2025-01-21 13:48:31,934 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:31,934 >>   Batch size = 64
 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 3580/5160 [1:28:36<27:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:39,298 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011883815750479698, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.584, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007610400673002005, 'eval_loss_2': 0.004273414611816406, 'eval_loss_3': -18.15566635131836, 'eval_loss_4': 1.618965744972229, 'epoch': 20.78}
{'loss': 0.005, 'grad_norm': 4.639091968536377, 'learning_rate': 9.232558139534884e-06, 'loss_1': 0.004343822598457336, 'loss_2': 0.0006246566772460938, 'loss_3': -16.386547088623047, 'loss_4': 1.4661035537719727, 'epoch': 20.79}
{'loss': 0.0076, 'grad_norm': 4.40989875793457, 'learning_rate': 9.22674418604651e-06, 'loss_1': 0.004155823495239019, 'loss_2': 0.003482818603515625, 'loss_3': -16.383934020996094, 'loss_4': 1.474761724472046, 'epoch': 20.8}
{'loss': 0.0158, 'grad_norm': 4.585232257843018, 'learning_rate': 9.220930232558141e-06, 'loss_1': 0.005691908299922943, 'loss_2': 0.0101165771484375, 'loss_3': -16.43551254272461, 'loss_4': 1.6594483852386475, 'epoch': 20.8}
{'loss': 0.0162, 'grad_norm': 6.034651756286621, 'learning_rate': 9.215116279069768e-06, 'loss_1': 0.008569054305553436, 'loss_2': 0.0076751708984375, 'loss_3': -16.28307342529297, 'loss_4': 2.1754374504089355, 'epoch': 20.81}
{'loss': 0.0117, 'grad_norm': 5.080717086791992, 'learning_rate': 9.209302325581397e-06, 'loss_1': 0.005653534550219774, 'loss_2': 0.0059967041015625, 'loss_3': -16.46978759765625, 'loss_4': 1.663405179977417, 'epoch': 20.81}
[INFO|trainer.py:4228] 2025-01-21 13:48:39,298 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:39,298 >>   Batch size = 64
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                  | 3585/5160 [1:28:43<27:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:46,650 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013190810568630695, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.087, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007502917665988207, 'eval_loss_2': 0.005687892436981201, 'eval_loss_3': -18.15159034729004, 'eval_loss_4': 1.640325903892517, 'epoch': 20.81}
{'loss': 0.0121, 'grad_norm': 6.110175609588623, 'learning_rate': 9.203488372093024e-06, 'loss_1': 0.006567818112671375, 'loss_2': 0.00556182861328125, 'loss_3': -16.46782875061035, 'loss_4': 1.8565096855163574, 'epoch': 20.82}
{'loss': 0.0172, 'grad_norm': 6.608381271362305, 'learning_rate': 9.19767441860465e-06, 'loss_1': 0.008117785677313805, 'loss_2': 0.00909423828125, 'loss_3': -16.40410614013672, 'loss_4': 1.8651478290557861, 'epoch': 20.83}
{'loss': 0.0079, 'grad_norm': 5.361533164978027, 'learning_rate': 9.191860465116279e-06, 'loss_1': 0.007618281524628401, 'loss_2': 0.00024700164794921875, 'loss_3': -16.448484420776367, 'loss_4': 1.6010303497314453, 'epoch': 20.83}
{'loss': 0.0078, 'grad_norm': 4.818347454071045, 'learning_rate': 9.186046511627908e-06, 'loss_1': 0.0059074293822050095, 'loss_2': 0.0018796920776367188, 'loss_3': -16.2044677734375, 'loss_4': 1.5059868097305298, 'epoch': 20.84}
{'loss': 0.0118, 'grad_norm': 5.242686748504639, 'learning_rate': 9.180232558139536e-06, 'loss_1': 0.005296783987432718, 'loss_2': 0.0065460205078125, 'loss_3': -16.478797912597656, 'loss_4': 1.489654541015625, 'epoch': 20.84}
[INFO|trainer.py:4228] 2025-01-21 13:48:46,650 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:46,651 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                  | 3590/5160 [1:28:51<27:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:48:54,007 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011464088223874569, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.032, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006914346478879452, 'eval_loss_2': 0.004549741744995117, 'eval_loss_3': -18.155853271484375, 'eval_loss_4': 1.6796760559082031, 'epoch': 20.84}
{'loss': 0.0064, 'grad_norm': 5.155482769012451, 'learning_rate': 9.174418604651163e-06, 'loss_1': 0.003467768430709839, 'loss_2': 0.0028839111328125, 'loss_3': -16.253681182861328, 'loss_4': 1.4365113973617554, 'epoch': 20.85}
{'loss': 0.0097, 'grad_norm': 5.643867015838623, 'learning_rate': 9.16860465116279e-06, 'loss_1': 0.009320235811173916, 'loss_2': 0.0003724098205566406, 'loss_3': -16.42645835876465, 'loss_4': 2.3798611164093018, 'epoch': 20.85}
{'loss': 0.0038, 'grad_norm': 4.847657203674316, 'learning_rate': 9.162790697674419e-06, 'loss_1': 0.0035700423177331686, 'loss_2': 0.000263214111328125, 'loss_3': -16.525453567504883, 'loss_4': 1.7180719375610352, 'epoch': 20.86}
{'loss': 0.0077, 'grad_norm': 5.023350238800049, 'learning_rate': 9.156976744186046e-06, 'loss_1': 0.006024943199008703, 'loss_2': 0.00164031982421875, 'loss_3': -16.561050415039062, 'loss_4': 1.7032376527786255, 'epoch': 20.87}
{'loss': 0.0069, 'grad_norm': 5.346108436584473, 'learning_rate': 9.151162790697674e-06, 'loss_1': 0.004449863918125629, 'loss_2': 0.002471923828125, 'loss_3': -16.360525131225586, 'loss_4': 1.180975079536438, 'epoch': 20.87}
[INFO|trainer.py:4228] 2025-01-21 13:48:54,007 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:48:54,007 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                  | 3595/5160 [1:28:58<27:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:01,360 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010820592753589153, 'eval_runtime': 3.8032, 'eval_samples_per_second': 269.249, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.007272021379321814, 'eval_loss_2': 0.003548569977283478, 'eval_loss_3': -18.15572738647461, 'eval_loss_4': 1.7228615283966064, 'epoch': 20.87}
{'loss': 0.0202, 'grad_norm': 6.472074031829834, 'learning_rate': 9.145348837209303e-06, 'loss_1': 0.012417681515216827, 'loss_2': 0.0078125, 'loss_3': -16.322589874267578, 'loss_4': 1.6994743347167969, 'epoch': 20.88}
{'loss': 0.007, 'grad_norm': 4.737016677856445, 'learning_rate': 9.13953488372093e-06, 'loss_1': 0.004254312254488468, 'loss_2': 0.002696990966796875, 'loss_3': -16.352577209472656, 'loss_4': 1.7548284530639648, 'epoch': 20.88}
{'loss': 0.0364, 'grad_norm': 13.283934593200684, 'learning_rate': 9.133720930232559e-06, 'loss_1': 0.0278826504945755, 'loss_2': 0.008514404296875, 'loss_3': -16.38233757019043, 'loss_4': 2.027829647064209, 'epoch': 20.89}
{'loss': 0.016, 'grad_norm': 7.195492744445801, 'learning_rate': 9.127906976744186e-06, 'loss_1': 0.015368124470114708, 'loss_2': 0.000606536865234375, 'loss_3': -16.327308654785156, 'loss_4': 1.8610832691192627, 'epoch': 20.9}
{'loss': 0.0091, 'grad_norm': 5.3154706954956055, 'learning_rate': 9.122093023255814e-06, 'loss_1': 0.004697493743151426, 'loss_2': 0.004390716552734375, 'loss_3': -16.368896484375, 'loss_4': 1.714641809463501, 'epoch': 20.9}
[INFO|trainer.py:4228] 2025-01-21 13:49:01,360 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:01,360 >>   Batch size = 64
 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                  | 3600/5160 [1:29:05<27:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:08,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013095304369926453, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.439, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007282273378223181, 'eval_loss_2': 0.005813032388687134, 'eval_loss_3': -18.15091323852539, 'eval_loss_4': 1.663535714149475, 'epoch': 20.9}
{'loss': 0.0126, 'grad_norm': 4.973247528076172, 'learning_rate': 9.116279069767441e-06, 'loss_1': 0.006373570300638676, 'loss_2': 0.0062103271484375, 'loss_3': -16.569690704345703, 'loss_4': 1.8166840076446533, 'epoch': 20.91}
{'loss': 0.0058, 'grad_norm': 4.2485032081604, 'learning_rate': 9.11046511627907e-06, 'loss_1': 0.004474654793739319, 'loss_2': 0.0012760162353515625, 'loss_3': -16.558561325073242, 'loss_4': 1.78453528881073, 'epoch': 20.91}
{'loss': 0.0149, 'grad_norm': 5.536816596984863, 'learning_rate': 9.104651162790698e-06, 'loss_1': 0.006613533478230238, 'loss_2': 0.008331298828125, 'loss_3': -16.435333251953125, 'loss_4': 1.6613109111785889, 'epoch': 20.92}
{'loss': 0.0114, 'grad_norm': 7.4289164543151855, 'learning_rate': 9.098837209302325e-06, 'loss_1': 0.008755342103540897, 'loss_2': 0.002651214599609375, 'loss_3': -16.38407325744629, 'loss_4': 1.6583025455474854, 'epoch': 20.92}
{'loss': 0.0198, 'grad_norm': 16.123001098632812, 'learning_rate': 9.093023255813954e-06, 'loss_1': 0.017991404980421066, 'loss_2': 0.0017786026000976562, 'loss_3': -16.558536529541016, 'loss_4': 1.458975076675415, 'epoch': 20.93}
[INFO|trainer.py:4228] 2025-01-21 13:49:08,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:08,732 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                  | 3605/5160 [1:29:13<26:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:16,094 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012122279033064842, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007149464450776577, 'eval_loss_2': 0.00497281551361084, 'eval_loss_3': -18.150609970092773, 'eval_loss_4': 1.6091697216033936, 'epoch': 20.93}
{'loss': 0.0079, 'grad_norm': 5.136115074157715, 'learning_rate': 9.087209302325581e-06, 'loss_1': 0.005253075156360865, 'loss_2': 0.002689361572265625, 'loss_3': -16.394075393676758, 'loss_4': 1.752124547958374, 'epoch': 20.94}
{'loss': 0.0118, 'grad_norm': 5.2218756675720215, 'learning_rate': 9.08139534883721e-06, 'loss_1': 0.008325041271746159, 'loss_2': 0.003467559814453125, 'loss_3': -16.629085540771484, 'loss_4': 1.6513086557388306, 'epoch': 20.94}
{'loss': 0.0071, 'grad_norm': 5.016245365142822, 'learning_rate': 9.075581395348838e-06, 'loss_1': 0.00354993948712945, 'loss_2': 0.003520965576171875, 'loss_3': -16.260498046875, 'loss_4': 1.7133047580718994, 'epoch': 20.95}
{'loss': 0.0063, 'grad_norm': 4.948321342468262, 'learning_rate': 9.069767441860465e-06, 'loss_1': 0.004240171518176794, 'loss_2': 0.0020294189453125, 'loss_3': -16.434431076049805, 'loss_4': 1.4889053106307983, 'epoch': 20.95}
{'loss': 0.0067, 'grad_norm': 4.99119234085083, 'learning_rate': 9.063953488372094e-06, 'loss_1': 0.00535985454916954, 'loss_2': 0.0013742446899414062, 'loss_3': -16.327754974365234, 'loss_4': 1.4320149421691895, 'epoch': 20.96}
[INFO|trainer.py:4228] 2025-01-21 13:49:16,095 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:16,095 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                 | 3610/5160 [1:29:20<26:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:23,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011400748044252396, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.749, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007775937207043171, 'eval_loss_2': 0.0036248117685317993, 'eval_loss_3': -18.1484375, 'eval_loss_4': 1.5908172130584717, 'epoch': 20.96}
{'loss': 0.005, 'grad_norm': 4.541234493255615, 'learning_rate': 9.05813953488372e-06, 'loss_1': 0.002485062461346388, 'loss_2': 0.00251007080078125, 'loss_3': -16.509239196777344, 'loss_4': 1.7401585578918457, 'epoch': 20.97}
{'loss': 0.0143, 'grad_norm': 8.92263412475586, 'learning_rate': 9.05232558139535e-06, 'loss_1': 0.009604029357433319, 'loss_2': 0.004657745361328125, 'loss_3': -16.413272857666016, 'loss_4': 1.6169334650039673, 'epoch': 20.97}
{'loss': 0.0164, 'grad_norm': 5.641664505004883, 'learning_rate': 9.046511627906976e-06, 'loss_1': 0.011662008240818977, 'loss_2': 0.00473785400390625, 'loss_3': -16.375932693481445, 'loss_4': 1.6639347076416016, 'epoch': 20.98}
{'loss': 0.0062, 'grad_norm': 4.833587646484375, 'learning_rate': 9.040697674418605e-06, 'loss_1': 0.004134311340749264, 'loss_2': 0.002044677734375, 'loss_3': -16.458215713500977, 'loss_4': 1.638273000717163, 'epoch': 20.98}
{'loss': 0.0156, 'grad_norm': 8.053567886352539, 'learning_rate': 9.034883720930234e-06, 'loss_1': 0.015492030419409275, 'loss_2': 7.814168930053711e-05, 'loss_3': -16.072696685791016, 'loss_4': 1.7390995025634766, 'epoch': 20.99}
[INFO|trainer.py:4228] 2025-01-21 13:49:23,459 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:23,459 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 3615/5160 [1:29:27<26:00,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 13:49:30,505 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010702352039515972, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.879, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00704964529722929, 'eval_loss_2': 0.003652706742286682, 'eval_loss_3': -18.158546447753906, 'eval_loss_4': 1.582036018371582, 'epoch': 20.99}
{'loss': 0.009, 'grad_norm': 4.51242208480835, 'learning_rate': 9.02906976744186e-06, 'loss_1': 0.0042382292449474335, 'loss_2': 0.0047149658203125, 'loss_3': -16.40980339050293, 'loss_4': 1.7780331373214722, 'epoch': 20.99}
{'loss': 0.0012, 'grad_norm': 5.9219536781311035, 'learning_rate': 9.023255813953489e-06, 'loss_1': 0.0008475487120449543, 'loss_2': 0.00033664703369140625, 'loss_3': -16.642343521118164, 'loss_4': 1.5863957405090332, 'epoch': 21.0}
{'loss': 0.0091, 'grad_norm': 4.7332539558410645, 'learning_rate': 9.017441860465116e-06, 'loss_1': 0.005882572382688522, 'loss_2': 0.003215789794921875, 'loss_3': -16.430810928344727, 'loss_4': 1.49061918258667, 'epoch': 21.01}
{'loss': 0.0031, 'grad_norm': 4.4793195724487305, 'learning_rate': 9.011627906976743e-06, 'loss_1': 0.001996676903218031, 'loss_2': 0.0011196136474609375, 'loss_3': -16.441509246826172, 'loss_4': 1.2882320880889893, 'epoch': 21.01}
{'loss': 0.0129, 'grad_norm': 4.863377571105957, 'learning_rate': 9.005813953488373e-06, 'loss_1': 0.006552086211740971, 'loss_2': 0.00634002685546875, 'loss_3': -16.610599517822266, 'loss_4': 2.2755823135375977, 'epoch': 21.02}
[INFO|trainer.py:4228] 2025-01-21 13:49:30,506 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:30,506 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 3620/5160 [1:29:35<26:33,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:49:37,869 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010522555559873581, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.591, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006966065149754286, 'eval_loss_2': 0.003556489944458008, 'eval_loss_3': -18.153871536254883, 'eval_loss_4': 1.598557949066162, 'epoch': 21.02}
{'loss': 0.008, 'grad_norm': 5.398000240325928, 'learning_rate': 9e-06, 'loss_1': 0.005336503963917494, 'loss_2': 0.002635955810546875, 'loss_3': -16.33428382873535, 'loss_4': 1.3737725019454956, 'epoch': 21.02}
{'loss': 0.0104, 'grad_norm': 4.811532020568848, 'learning_rate': 8.994186046511629e-06, 'loss_1': 0.004829540848731995, 'loss_2': 0.005523681640625, 'loss_3': -16.422029495239258, 'loss_4': 1.8956167697906494, 'epoch': 21.03}
{'loss': 0.0065, 'grad_norm': 5.5634589195251465, 'learning_rate': 8.988372093023256e-06, 'loss_1': 0.0054852101020514965, 'loss_2': 0.0010128021240234375, 'loss_3': -16.312742233276367, 'loss_4': 1.6490542888641357, 'epoch': 21.03}
{'loss': 0.0085, 'grad_norm': 5.942391872406006, 'learning_rate': 8.982558139534883e-06, 'loss_1': 0.006889117415994406, 'loss_2': 0.0015916824340820312, 'loss_3': -16.35934066772461, 'loss_4': 1.9764405488967896, 'epoch': 21.04}
{'loss': 0.0136, 'grad_norm': 6.352064609527588, 'learning_rate': 8.976744186046511e-06, 'loss_1': 0.009107539430260658, 'loss_2': 0.0045013427734375, 'loss_3': -16.371381759643555, 'loss_4': 1.6612892150878906, 'epoch': 21.05}
[INFO|trainer.py:4228] 2025-01-21 13:49:37,869 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:37,869 >>   Batch size = 64
 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                 | 3625/5160 [1:29:42<26:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:45,236 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010106783360242844, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.901, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006844710558652878, 'eval_loss_2': 0.003262072801589966, 'eval_loss_3': -18.143632888793945, 'eval_loss_4': 1.634278416633606, 'epoch': 21.05}
{'loss': 0.0089, 'grad_norm': 5.005937576293945, 'learning_rate': 8.97093023255814e-06, 'loss_1': 0.0070050968788564205, 'loss_2': 0.0018749237060546875, 'loss_3': -16.1820011138916, 'loss_4': 1.884962797164917, 'epoch': 21.05}
{'loss': 0.022, 'grad_norm': 10.467975616455078, 'learning_rate': 8.965116279069769e-06, 'loss_1': 0.018586698919534683, 'loss_2': 0.003437042236328125, 'loss_3': -16.476360321044922, 'loss_4': 1.4700167179107666, 'epoch': 21.06}
{'loss': 0.0067, 'grad_norm': 4.465924263000488, 'learning_rate': 8.959302325581396e-06, 'loss_1': 0.004286791197955608, 'loss_2': 0.002391815185546875, 'loss_3': -16.411977767944336, 'loss_4': 1.957404375076294, 'epoch': 21.06}
{'loss': 0.0133, 'grad_norm': 6.43625020980835, 'learning_rate': 8.953488372093023e-06, 'loss_1': 0.010108348913490772, 'loss_2': 0.00323486328125, 'loss_3': -16.371898651123047, 'loss_4': 1.5556211471557617, 'epoch': 21.07}
{'loss': 0.0038, 'grad_norm': 4.519917011260986, 'learning_rate': 8.947674418604651e-06, 'loss_1': 0.003106778021901846, 'loss_2': 0.0007295608520507812, 'loss_3': -16.291927337646484, 'loss_4': 1.63689386844635, 'epoch': 21.08}
[INFO|trainer.py:4228] 2025-01-21 13:49:45,236 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:45,236 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                 | 3630/5160 [1:29:49<26:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:52,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009622061625123024, 'eval_runtime': 3.8229, 'eval_samples_per_second': 267.863, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.006195748224854469, 'eval_loss_2': 0.0034263134002685547, 'eval_loss_3': -18.14417266845703, 'eval_loss_4': 1.6484590768814087, 'epoch': 21.08}
{'loss': 0.0103, 'grad_norm': 5.666391849517822, 'learning_rate': 8.941860465116278e-06, 'loss_1': 0.010119768790900707, 'loss_2': 0.00013875961303710938, 'loss_3': -16.193492889404297, 'loss_4': 1.5331441164016724, 'epoch': 21.08}
{'loss': 0.0178, 'grad_norm': 6.188643455505371, 'learning_rate': 8.936046511627908e-06, 'loss_1': 0.009950216859579086, 'loss_2': 0.00782012939453125, 'loss_3': -16.48123550415039, 'loss_4': 1.418006420135498, 'epoch': 21.09}
{'loss': 0.0044, 'grad_norm': 4.845887184143066, 'learning_rate': 8.930232558139535e-06, 'loss_1': 0.0032552697230130434, 'loss_2': 0.0011844635009765625, 'loss_3': -16.354740142822266, 'loss_4': 1.4678118228912354, 'epoch': 21.09}
{'loss': 0.0085, 'grad_norm': 6.308080196380615, 'learning_rate': 8.924418604651162e-06, 'loss_1': 0.0073223779909312725, 'loss_2': 0.0012273788452148438, 'loss_3': -16.26012420654297, 'loss_4': 1.6078661680221558, 'epoch': 21.1}
{'loss': 0.0098, 'grad_norm': 4.566830635070801, 'learning_rate': 8.918604651162791e-06, 'loss_1': 0.003984343260526657, 'loss_2': 0.005855560302734375, 'loss_3': -16.276355743408203, 'loss_4': 1.5676651000976562, 'epoch': 21.1}
[INFO|trainer.py:4228] 2025-01-21 13:49:52,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:52,608 >>   Batch size = 64
 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                | 3635/5160 [1:29:57<26:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:49:59,968 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009977171197533607, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.172, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005897203925997019, 'eval_loss_2': 0.004079967737197876, 'eval_loss_3': -18.149948120117188, 'eval_loss_4': 1.648305892944336, 'epoch': 21.1}
{'loss': 0.0126, 'grad_norm': 4.334716796875, 'learning_rate': 8.912790697674418e-06, 'loss_1': 0.004183008335530758, 'loss_2': 0.0084075927734375, 'loss_3': -16.46467399597168, 'loss_4': 1.6766313314437866, 'epoch': 21.11}
{'loss': 0.0105, 'grad_norm': 5.756318092346191, 'learning_rate': 8.906976744186046e-06, 'loss_1': 0.007781828287988901, 'loss_2': 0.00270843505859375, 'loss_3': -16.49117088317871, 'loss_4': 1.7348835468292236, 'epoch': 21.12}
{'loss': 0.0114, 'grad_norm': 6.269150257110596, 'learning_rate': 8.901162790697675e-06, 'loss_1': 0.010771593078970909, 'loss_2': 0.000606536865234375, 'loss_3': -16.190372467041016, 'loss_4': 1.9385395050048828, 'epoch': 21.12}
{'loss': 0.0053, 'grad_norm': 4.097640037536621, 'learning_rate': 8.895348837209304e-06, 'loss_1': 0.00450058002024889, 'loss_2': 0.0007781982421875, 'loss_3': -16.33639907836914, 'loss_4': 1.7404780387878418, 'epoch': 21.13}
{'loss': 0.0108, 'grad_norm': 4.679559707641602, 'learning_rate': 8.88953488372093e-06, 'loss_1': 0.005347325000911951, 'loss_2': 0.00543975830078125, 'loss_3': -16.61654281616211, 'loss_4': 1.5686323642730713, 'epoch': 21.13}
[INFO|trainer.py:4228] 2025-01-21 13:49:59,968 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:49:59,968 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                | 3640/5160 [1:30:04<26:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:07,325 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010450027883052826, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.138, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006221182178705931, 'eval_loss_2': 0.004228845238685608, 'eval_loss_3': -18.158401489257812, 'eval_loss_4': 1.6069254875183105, 'epoch': 21.13}
{'loss': 0.0088, 'grad_norm': 5.130495071411133, 'learning_rate': 8.883720930232558e-06, 'loss_1': 0.0072184232994914055, 'loss_2': 0.001556396484375, 'loss_3': -16.504987716674805, 'loss_4': 1.6924700736999512, 'epoch': 21.14}
{'loss': 0.0099, 'grad_norm': 5.699755668640137, 'learning_rate': 8.877906976744186e-06, 'loss_1': 0.0065834675915539265, 'loss_2': 0.00328826904296875, 'loss_3': -16.54851531982422, 'loss_4': 1.471242070198059, 'epoch': 21.15}
{'loss': 0.0093, 'grad_norm': 4.383240222930908, 'learning_rate': 8.872093023255813e-06, 'loss_1': 0.005805470515042543, 'loss_2': 0.003528594970703125, 'loss_3': -16.369613647460938, 'loss_4': 1.137927532196045, 'epoch': 21.15}
{'loss': 0.01, 'grad_norm': 5.000967979431152, 'learning_rate': 8.866279069767444e-06, 'loss_1': 0.005712640937417746, 'loss_2': 0.0043182373046875, 'loss_3': -16.48099136352539, 'loss_4': 1.7498283386230469, 'epoch': 21.16}
{'loss': 0.0408, 'grad_norm': 24.1447811126709, 'learning_rate': 8.86046511627907e-06, 'loss_1': 0.03783769905567169, 'loss_2': 0.002933502197265625, 'loss_3': -16.442344665527344, 'loss_4': 1.7736659049987793, 'epoch': 21.16}
[INFO|trainer.py:4228] 2025-01-21 13:50:07,325 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:07,325 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                | 3645/5160 [1:30:11<26:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:14,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010494472458958626, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.952, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006755366921424866, 'eval_loss_2': 0.003739103674888611, 'eval_loss_3': -18.156696319580078, 'eval_loss_4': 1.5567576885223389, 'epoch': 21.16}
{'loss': 0.0066, 'grad_norm': 6.96347188949585, 'learning_rate': 8.854651162790697e-06, 'loss_1': 0.0059879133477807045, 'loss_2': 0.00064849853515625, 'loss_3': -16.555438995361328, 'loss_4': 1.5709116458892822, 'epoch': 21.17}
{'loss': 0.0097, 'grad_norm': 5.4715962409973145, 'learning_rate': 8.848837209302326e-06, 'loss_1': 0.00553387263789773, 'loss_2': 0.004150390625, 'loss_3': -16.37139892578125, 'loss_4': 1.4042739868164062, 'epoch': 21.17}
{'loss': 0.0085, 'grad_norm': 6.191221237182617, 'learning_rate': 8.843023255813953e-06, 'loss_1': 0.00715691177174449, 'loss_2': 0.0013837814331054688, 'loss_3': -16.456127166748047, 'loss_4': 1.6491520404815674, 'epoch': 21.18}
{'loss': 0.0066, 'grad_norm': 5.107349872589111, 'learning_rate': 8.837209302325582e-06, 'loss_1': 0.005225092638283968, 'loss_2': 0.0013675689697265625, 'loss_3': -16.34842300415039, 'loss_4': 1.3077691793441772, 'epoch': 21.19}
{'loss': 0.0076, 'grad_norm': 4.57713508605957, 'learning_rate': 8.83139534883721e-06, 'loss_1': 0.003465186571702361, 'loss_2': 0.00411224365234375, 'loss_3': -16.45692253112793, 'loss_4': 1.7964601516723633, 'epoch': 21.19}
[INFO|trainer.py:4228] 2025-01-21 13:50:14,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:14,694 >>   Batch size = 64
 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                | 3650/5160 [1:30:19<26:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:22,057 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010023058392107487, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.758, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007095747161656618, 'eval_loss_2': 0.0029273107647895813, 'eval_loss_3': -18.15812110900879, 'eval_loss_4': 1.519309639930725, 'epoch': 21.19}
{'loss': 0.0131, 'grad_norm': 4.914658546447754, 'learning_rate': 8.825581395348837e-06, 'loss_1': 0.006002421956509352, 'loss_2': 0.007053375244140625, 'loss_3': -16.501956939697266, 'loss_4': 1.2545610666275024, 'epoch': 21.2}
{'loss': 0.0111, 'grad_norm': 5.266144275665283, 'learning_rate': 8.819767441860466e-06, 'loss_1': 0.00720191141590476, 'loss_2': 0.003856658935546875, 'loss_3': -16.294815063476562, 'loss_4': 1.2191039323806763, 'epoch': 21.2}
{'loss': 0.0158, 'grad_norm': 5.762429714202881, 'learning_rate': 8.813953488372093e-06, 'loss_1': 0.011479111388325691, 'loss_2': 0.004276275634765625, 'loss_3': -16.27145767211914, 'loss_4': 1.5145800113677979, 'epoch': 21.21}
{'loss': 0.0286, 'grad_norm': 23.439796447753906, 'learning_rate': 8.808139534883721e-06, 'loss_1': 0.025505302473902702, 'loss_2': 0.00305938720703125, 'loss_3': -16.40386962890625, 'loss_4': 1.2675907611846924, 'epoch': 21.22}
{'loss': 0.0239, 'grad_norm': 14.379613876342773, 'learning_rate': 8.802325581395348e-06, 'loss_1': 0.01710590347647667, 'loss_2': 0.00675201416015625, 'loss_3': -16.304039001464844, 'loss_4': 1.6765739917755127, 'epoch': 21.22}
[INFO|trainer.py:4228] 2025-01-21 13:50:22,057 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:22,057 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                               | 3655/5160 [1:30:26<26:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:29,434 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010728878900408745, 'eval_runtime': 3.8153, 'eval_samples_per_second': 268.39, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006978315766900778, 'eval_loss_2': 0.0037505626678466797, 'eval_loss_3': -18.12906265258789, 'eval_loss_4': 1.4781320095062256, 'epoch': 21.22}
{'loss': 0.0177, 'grad_norm': 5.025444507598877, 'learning_rate': 8.796511627906977e-06, 'loss_1': 0.00440590176731348, 'loss_2': 0.01328277587890625, 'loss_3': -16.324565887451172, 'loss_4': 1.2029826641082764, 'epoch': 21.23}
{'loss': 0.0114, 'grad_norm': 5.848781108856201, 'learning_rate': 8.790697674418606e-06, 'loss_1': 0.01123094279319048, 'loss_2': 0.00014030933380126953, 'loss_3': -16.53313446044922, 'loss_4': 1.5103143453598022, 'epoch': 21.23}
{'loss': 0.007, 'grad_norm': 4.714277267456055, 'learning_rate': 8.784883720930233e-06, 'loss_1': 0.005683139432221651, 'loss_2': 0.0013103485107421875, 'loss_3': -16.620574951171875, 'loss_4': 1.3018330335617065, 'epoch': 21.24}
{'loss': 0.0096, 'grad_norm': 4.732812881469727, 'learning_rate': 8.779069767441861e-06, 'loss_1': 0.003551262430846691, 'loss_2': 0.00606536865234375, 'loss_3': -16.626604080200195, 'loss_4': 1.4132130146026611, 'epoch': 21.24}
{'loss': 0.0162, 'grad_norm': 9.343088150024414, 'learning_rate': 8.773255813953488e-06, 'loss_1': 0.012538420967757702, 'loss_2': 0.00370025634765625, 'loss_3': -16.41118049621582, 'loss_4': 1.8548905849456787, 'epoch': 21.25}
[INFO|trainer.py:4228] 2025-01-21 13:50:29,434 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:29,434 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                               | 3660/5160 [1:30:33<25:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:36,795 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011633198708295822, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.786, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.007749687880277634, 'eval_loss_2': 0.0038835108280181885, 'eval_loss_3': -18.131004333496094, 'eval_loss_4': 1.4406006336212158, 'epoch': 21.25}
{'loss': 0.0083, 'grad_norm': 5.07572603225708, 'learning_rate': 8.767441860465115e-06, 'loss_1': 0.0030658249743282795, 'loss_2': 0.0052490234375, 'loss_3': -16.42672348022461, 'loss_4': 1.2389942407608032, 'epoch': 21.26}
{'loss': 0.004, 'grad_norm': 4.651183605194092, 'learning_rate': 8.761627906976745e-06, 'loss_1': 0.0029193582013249397, 'loss_2': 0.0011119842529296875, 'loss_3': -16.265716552734375, 'loss_4': 1.4456764459609985, 'epoch': 21.26}
{'loss': 0.0052, 'grad_norm': 4.2850422859191895, 'learning_rate': 8.755813953488372e-06, 'loss_1': 0.0020401873625814915, 'loss_2': 0.003139495849609375, 'loss_3': -16.492216110229492, 'loss_4': 1.2097660303115845, 'epoch': 21.27}
{'loss': 0.009, 'grad_norm': 4.634301662445068, 'learning_rate': 8.750000000000001e-06, 'loss_1': 0.006141479127109051, 'loss_2': 0.0028228759765625, 'loss_3': -16.40194320678711, 'loss_4': 1.5377557277679443, 'epoch': 21.27}
{'loss': 0.0113, 'grad_norm': 5.593505382537842, 'learning_rate': 8.744186046511628e-06, 'loss_1': 0.009678659029304981, 'loss_2': 0.0015859603881835938, 'loss_3': -16.400419235229492, 'loss_4': 1.3923008441925049, 'epoch': 21.28}
[INFO|trainer.py:4228] 2025-01-21 13:50:36,795 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:36,795 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                               | 3665/5160 [1:30:41<25:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:44,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011710554361343384, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007779388688504696, 'eval_loss_2': 0.003931164741516113, 'eval_loss_3': -18.144241333007812, 'eval_loss_4': 1.5342575311660767, 'epoch': 21.28}
{'loss': 0.0067, 'grad_norm': 4.809219837188721, 'learning_rate': 8.738372093023255e-06, 'loss_1': 0.005302573554217815, 'loss_2': 0.0014104843139648438, 'loss_3': -16.352785110473633, 'loss_4': 1.343849539756775, 'epoch': 21.28}
{'loss': 0.01, 'grad_norm': 6.029731273651123, 'learning_rate': 8.732558139534883e-06, 'loss_1': 0.009140269830822945, 'loss_2': 0.0008554458618164062, 'loss_3': -16.254989624023438, 'loss_4': 1.7064595222473145, 'epoch': 21.29}
{'loss': 0.0068, 'grad_norm': 5.093146324157715, 'learning_rate': 8.726744186046512e-06, 'loss_1': 0.004415326751768589, 'loss_2': 0.002414703369140625, 'loss_3': -16.22380828857422, 'loss_4': 1.4623589515686035, 'epoch': 21.3}
{'loss': 0.0063, 'grad_norm': 4.56232213973999, 'learning_rate': 8.72093023255814e-06, 'loss_1': 0.004241448827087879, 'loss_2': 0.0020771026611328125, 'loss_3': -16.496971130371094, 'loss_4': 1.683748483657837, 'epoch': 21.3}
{'loss': 0.0105, 'grad_norm': 5.619163513183594, 'learning_rate': 8.715116279069768e-06, 'loss_1': 0.0049922228790819645, 'loss_2': 0.005519866943359375, 'loss_3': -16.571775436401367, 'loss_4': 1.8536704778671265, 'epoch': 21.31}
[INFO|trainer.py:4228] 2025-01-21 13:50:44,152 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:44,153 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                               | 3670/5160 [1:30:48<25:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:51,510 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011912861838936806, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.033, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00797092542052269, 'eval_loss_2': 0.003941938281059265, 'eval_loss_3': -18.161636352539062, 'eval_loss_4': 1.675487756729126, 'epoch': 21.31}
{'loss': 0.0217, 'grad_norm': 20.78207778930664, 'learning_rate': 8.709302325581396e-06, 'loss_1': 0.02008422277867794, 'loss_2': 0.0015716552734375, 'loss_3': -16.38944435119629, 'loss_4': 1.6519324779510498, 'epoch': 21.31}
{'loss': 0.0162, 'grad_norm': 6.100172996520996, 'learning_rate': 8.703488372093023e-06, 'loss_1': 0.010798281989991665, 'loss_2': 0.00540924072265625, 'loss_3': -16.364009857177734, 'loss_4': 1.659221887588501, 'epoch': 21.32}
{'loss': 0.0059, 'grad_norm': 4.0991716384887695, 'learning_rate': 8.69767441860465e-06, 'loss_1': 0.003874192014336586, 'loss_2': 0.0020351409912109375, 'loss_3': -16.55742645263672, 'loss_4': 1.7119483947753906, 'epoch': 21.33}
{'loss': 0.0097, 'grad_norm': 6.33823299407959, 'learning_rate': 8.69186046511628e-06, 'loss_1': 0.009183318354189396, 'loss_2': 0.0004849433898925781, 'loss_3': -16.414958953857422, 'loss_4': 1.9446277618408203, 'epoch': 21.33}
{'loss': 0.0081, 'grad_norm': 4.584017276763916, 'learning_rate': 8.686046511627907e-06, 'loss_1': 0.003777190810069442, 'loss_2': 0.0043182373046875, 'loss_3': -16.442974090576172, 'loss_4': 1.5292057991027832, 'epoch': 21.34}
[INFO|trainer.py:4228] 2025-01-21 13:50:51,510 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:51,510 >>   Batch size = 64
 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                               | 3675/5160 [1:30:56<25:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:50:58,872 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012002781964838505, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.963, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007822529412806034, 'eval_loss_2': 0.004180252552032471, 'eval_loss_3': -18.153657913208008, 'eval_loss_4': 1.809387445449829, 'epoch': 21.34}
{'loss': 0.0092, 'grad_norm': 4.5749993324279785, 'learning_rate': 8.680232558139536e-06, 'loss_1': 0.007186308968812227, 'loss_2': 0.001972198486328125, 'loss_3': -16.468446731567383, 'loss_4': 1.335640788078308, 'epoch': 21.34}
{'loss': 0.0106, 'grad_norm': 5.020422458648682, 'learning_rate': 8.674418604651163e-06, 'loss_1': 0.00596132455393672, 'loss_2': 0.0046844482421875, 'loss_3': -16.49985122680664, 'loss_4': 1.7696253061294556, 'epoch': 21.35}
{'loss': 0.0196, 'grad_norm': 14.562755584716797, 'learning_rate': 8.66860465116279e-06, 'loss_1': 0.015414949506521225, 'loss_2': 0.004199981689453125, 'loss_3': -16.0985107421875, 'loss_4': 2.1261491775512695, 'epoch': 21.35}
{'loss': 0.0089, 'grad_norm': 5.5934062004089355, 'learning_rate': 8.662790697674419e-06, 'loss_1': 0.005785273388028145, 'loss_2': 0.0030651092529296875, 'loss_3': -16.473814010620117, 'loss_4': 1.9278929233551025, 'epoch': 21.36}
{'loss': 0.0095, 'grad_norm': 5.085657596588135, 'learning_rate': 8.656976744186047e-06, 'loss_1': 0.004255011677742004, 'loss_2': 0.005199432373046875, 'loss_3': -16.561384201049805, 'loss_4': 2.235408067703247, 'epoch': 21.37}
[INFO|trainer.py:4228] 2025-01-21 13:50:58,872 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:50:58,872 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                              | 3680/5160 [1:31:03<25:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:06,247 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012713264673948288, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.466, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.008059288375079632, 'eval_loss_2': 0.0046539753675460815, 'eval_loss_3': -18.15805435180664, 'eval_loss_4': 1.871094822883606, 'epoch': 21.37}
{'loss': 0.0071, 'grad_norm': 4.45822286605835, 'learning_rate': 8.651162790697676e-06, 'loss_1': 0.0038033192977309227, 'loss_2': 0.003265380859375, 'loss_3': -16.327556610107422, 'loss_4': 1.8535776138305664, 'epoch': 21.37}
{'loss': 0.0109, 'grad_norm': 4.8475446701049805, 'learning_rate': 8.645348837209303e-06, 'loss_1': 0.0053017763420939445, 'loss_2': 0.0055694580078125, 'loss_3': -16.296051025390625, 'loss_4': 2.1935739517211914, 'epoch': 21.38}
{'loss': 0.0142, 'grad_norm': 7.40570068359375, 'learning_rate': 8.63953488372093e-06, 'loss_1': 0.012497126124799252, 'loss_2': 0.001728057861328125, 'loss_3': -16.6309757232666, 'loss_4': 1.9708174467086792, 'epoch': 21.38}
{'loss': 0.0253, 'grad_norm': 12.435770988464355, 'learning_rate': 8.633720930232558e-06, 'loss_1': 0.01891246624290943, 'loss_2': 0.00641632080078125, 'loss_3': -16.272693634033203, 'loss_4': 1.7948603630065918, 'epoch': 21.39}
{'loss': 0.0123, 'grad_norm': 7.664401531219482, 'learning_rate': 8.627906976744185e-06, 'loss_1': 0.012209841050207615, 'loss_2': 5.155801773071289e-05, 'loss_3': -16.392135620117188, 'loss_4': 1.736867904663086, 'epoch': 21.4}
[INFO|trainer.py:4228] 2025-01-21 13:51:06,247 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:06,247 >>   Batch size = 64
 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                              | 3685/5160 [1:31:10<25:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:13,615 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012048047035932541, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.867, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.007923346944153309, 'eval_loss_2': 0.004124701023101807, 'eval_loss_3': -18.151643753051758, 'eval_loss_4': 1.9111884832382202, 'epoch': 21.4}
{'loss': 0.0072, 'grad_norm': 4.488471508026123, 'learning_rate': 8.622093023255816e-06, 'loss_1': 0.003869880922138691, 'loss_2': 0.003376007080078125, 'loss_3': -16.467906951904297, 'loss_4': 2.2462310791015625, 'epoch': 21.4}
{'loss': 0.0086, 'grad_norm': 4.752456188201904, 'learning_rate': 8.616279069767443e-06, 'loss_1': 0.0061013363301754, 'loss_2': 0.002471923828125, 'loss_3': -16.30060577392578, 'loss_4': 1.9533805847167969, 'epoch': 21.41}
{'loss': 0.0097, 'grad_norm': 5.3962273597717285, 'learning_rate': 8.61046511627907e-06, 'loss_1': 0.00829586386680603, 'loss_2': 0.00142669677734375, 'loss_3': -16.47593879699707, 'loss_4': 1.874966025352478, 'epoch': 21.41}
{'loss': 0.0165, 'grad_norm': 9.167282104492188, 'learning_rate': 8.604651162790698e-06, 'loss_1': 0.013508842326700687, 'loss_2': 0.0029449462890625, 'loss_3': -16.290616989135742, 'loss_4': 1.9473111629486084, 'epoch': 21.42}
{'loss': 0.0181, 'grad_norm': 13.83165454864502, 'learning_rate': 8.598837209302325e-06, 'loss_1': 0.01601058430969715, 'loss_2': 0.002044677734375, 'loss_3': -16.451730728149414, 'loss_4': 2.148224353790283, 'epoch': 21.42}
[INFO|trainer.py:4228] 2025-01-21 13:51:13,615 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:13,615 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                              | 3690/5160 [1:31:18<25:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:20,976 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011358997784554958, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.989, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007790304254740477, 'eval_loss_2': 0.003568693995475769, 'eval_loss_3': -18.160430908203125, 'eval_loss_4': 1.931889533996582, 'epoch': 21.42}
{'loss': 0.0188, 'grad_norm': 6.453614234924316, 'learning_rate': 8.593023255813954e-06, 'loss_1': 0.012356105260550976, 'loss_2': 0.00644683837890625, 'loss_3': -16.4061336517334, 'loss_4': 1.7508677244186401, 'epoch': 21.43}
{'loss': 0.0125, 'grad_norm': 4.87019157409668, 'learning_rate': 8.587209302325582e-06, 'loss_1': 0.004928498528897762, 'loss_2': 0.007598876953125, 'loss_3': -16.25643539428711, 'loss_4': 1.9371696710586548, 'epoch': 21.44}
{'loss': 0.0099, 'grad_norm': 6.022574424743652, 'learning_rate': 8.58139534883721e-06, 'loss_1': 0.006198146380484104, 'loss_2': 0.003658294677734375, 'loss_3': -16.457685470581055, 'loss_4': 1.7164361476898193, 'epoch': 21.44}
{'loss': 0.0161, 'grad_norm': 7.0103936195373535, 'learning_rate': 8.575581395348838e-06, 'loss_1': 0.014314460568130016, 'loss_2': 0.0018291473388671875, 'loss_3': -16.41834259033203, 'loss_4': 2.0625104904174805, 'epoch': 21.45}
{'loss': 0.0098, 'grad_norm': 5.163376808166504, 'learning_rate': 8.569767441860465e-06, 'loss_1': 0.005516375415027142, 'loss_2': 0.00429534912109375, 'loss_3': -16.436111450195312, 'loss_4': 2.0324854850769043, 'epoch': 21.45}
[INFO|trainer.py:4228] 2025-01-21 13:51:20,976 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:20,977 >>   Batch size = 64
 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 3695/5160 [1:31:25<25:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:28,339 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010423102416098118, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.148, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007305577863007784, 'eval_loss_2': 0.0031175240874290466, 'eval_loss_3': -18.149381637573242, 'eval_loss_4': 1.9098334312438965, 'epoch': 21.45}
{'loss': 0.009, 'grad_norm': 4.866928577423096, 'learning_rate': 8.563953488372093e-06, 'loss_1': 0.007373619358986616, 'loss_2': 0.0016384124755859375, 'loss_3': -16.426509857177734, 'loss_4': 1.530175805091858, 'epoch': 21.46}
{'loss': 0.0139, 'grad_norm': 5.985101699829102, 'learning_rate': 8.55813953488372e-06, 'loss_1': 0.012230798602104187, 'loss_2': 0.0016384124755859375, 'loss_3': -16.535263061523438, 'loss_4': 2.4952449798583984, 'epoch': 21.47}
{'loss': 0.0109, 'grad_norm': 5.211062431335449, 'learning_rate': 8.552325581395349e-06, 'loss_1': 0.004699683282524347, 'loss_2': 0.0062103271484375, 'loss_3': -16.656526565551758, 'loss_4': 1.886458158493042, 'epoch': 21.47}
{'loss': 0.0126, 'grad_norm': 6.352468490600586, 'learning_rate': 8.546511627906978e-06, 'loss_1': 0.008713169023394585, 'loss_2': 0.00383758544921875, 'loss_3': -16.464567184448242, 'loss_4': 2.1357686519622803, 'epoch': 21.48}
{'loss': 0.0135, 'grad_norm': 6.423413276672363, 'learning_rate': 8.540697674418605e-06, 'loss_1': 0.0088535500690341, 'loss_2': 0.0046539306640625, 'loss_3': -16.34075355529785, 'loss_4': 1.943444848060608, 'epoch': 21.48}
[INFO|trainer.py:4228] 2025-01-21 13:51:28,339 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:28,339 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                              | 3700/5160 [1:31:32<25:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:35,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010877938009798527, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.028, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.007870306260883808, 'eval_loss_2': 0.0030076317489147186, 'eval_loss_3': -18.134077072143555, 'eval_loss_4': 1.9011695384979248, 'epoch': 21.48}
{'loss': 0.0067, 'grad_norm': 4.7138519287109375, 'learning_rate': 8.534883720930233e-06, 'loss_1': 0.0059499796479940414, 'loss_2': 0.0007276535034179688, 'loss_3': -16.33013153076172, 'loss_4': 1.9872697591781616, 'epoch': 21.49}
{'loss': 0.0099, 'grad_norm': 4.970271587371826, 'learning_rate': 8.52906976744186e-06, 'loss_1': 0.005855249706655741, 'loss_2': 0.00403594970703125, 'loss_3': -16.530126571655273, 'loss_4': 1.575398564338684, 'epoch': 21.49}
{'loss': 0.0037, 'grad_norm': 4.722708702087402, 'learning_rate': 8.523255813953489e-06, 'loss_1': 0.0023573325015604496, 'loss_2': 0.0013599395751953125, 'loss_3': -16.473920822143555, 'loss_4': 2.419534683227539, 'epoch': 21.5}
{'loss': 0.008, 'grad_norm': 5.241199016571045, 'learning_rate': 8.517441860465117e-06, 'loss_1': 0.005793028511106968, 'loss_2': 0.002166748046875, 'loss_3': -16.227954864501953, 'loss_4': 2.0173511505126953, 'epoch': 21.51}
{'loss': 0.0069, 'grad_norm': 6.276307106018066, 'learning_rate': 8.511627906976744e-06, 'loss_1': 0.006069655530154705, 'loss_2': 0.0008077621459960938, 'loss_3': -16.240619659423828, 'loss_4': 2.050248146057129, 'epoch': 21.51}
[INFO|trainer.py:4228] 2025-01-21 13:51:35,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:35,693 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                             | 3705/5160 [1:31:40<25:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:43,066 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012780746445059776, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.609, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008305720053613186, 'eval_loss_2': 0.004475027322769165, 'eval_loss_3': -18.117013931274414, 'eval_loss_4': 1.8841102123260498, 'epoch': 21.51}
{'loss': 0.0147, 'grad_norm': 5.368565082550049, 'learning_rate': 8.505813953488373e-06, 'loss_1': 0.007085118908435106, 'loss_2': 0.0075836181640625, 'loss_3': -16.45642852783203, 'loss_4': 2.635855197906494, 'epoch': 21.52}
{'loss': 0.0125, 'grad_norm': 10.61314582824707, 'learning_rate': 8.5e-06, 'loss_1': 0.011586173437535763, 'loss_2': 0.0008831024169921875, 'loss_3': -16.517749786376953, 'loss_4': 1.8509304523468018, 'epoch': 21.52}
{'loss': 0.0117, 'grad_norm': 4.561811923980713, 'learning_rate': 8.494186046511629e-06, 'loss_1': 0.006512037944048643, 'loss_2': 0.00519561767578125, 'loss_3': -16.361286163330078, 'loss_4': 2.078082799911499, 'epoch': 21.53}
{'loss': 0.0071, 'grad_norm': 5.591104507446289, 'learning_rate': 8.488372093023256e-06, 'loss_1': 0.006158726289868355, 'loss_2': 0.000972747802734375, 'loss_3': -16.229148864746094, 'loss_4': 2.0321359634399414, 'epoch': 21.53}
{'loss': 0.0064, 'grad_norm': 5.284134864807129, 'learning_rate': 8.482558139534884e-06, 'loss_1': 0.0044918661005795, 'loss_2': 0.00193023681640625, 'loss_3': -16.50661277770996, 'loss_4': 1.6261422634124756, 'epoch': 21.54}
[INFO|trainer.py:4228] 2025-01-21 13:51:43,066 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:43,066 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 3710/5160 [1:31:47<25:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:50,444 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.016902517527341843, 'eval_runtime': 3.8188, 'eval_samples_per_second': 268.15, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.011482931673526764, 'eval_loss_2': 0.00541958212852478, 'eval_loss_3': -18.09585189819336, 'eval_loss_4': 1.8819639682769775, 'epoch': 21.54}
{'loss': 0.0098, 'grad_norm': 4.483828067779541, 'learning_rate': 8.476744186046513e-06, 'loss_1': 0.004433413036167622, 'loss_2': 0.005401611328125, 'loss_3': -16.274890899658203, 'loss_4': 2.002016544342041, 'epoch': 21.55}
{'loss': 0.0098, 'grad_norm': 5.693637371063232, 'learning_rate': 8.47093023255814e-06, 'loss_1': 0.00659308023750782, 'loss_2': 0.003246307373046875, 'loss_3': -16.337963104248047, 'loss_4': 2.2423126697540283, 'epoch': 21.55}
{'loss': 0.0128, 'grad_norm': 4.536323547363281, 'learning_rate': 8.465116279069768e-06, 'loss_1': 0.006487282924354076, 'loss_2': 0.006328582763671875, 'loss_3': -16.497148513793945, 'loss_4': 1.7502704858779907, 'epoch': 21.56}
{'loss': 0.0144, 'grad_norm': 6.562061786651611, 'learning_rate': 8.459302325581395e-06, 'loss_1': 0.009433428756892681, 'loss_2': 0.004962921142578125, 'loss_3': -16.453872680664062, 'loss_4': 1.6702759265899658, 'epoch': 21.56}
{'loss': 0.0084, 'grad_norm': 5.210392951965332, 'learning_rate': 8.453488372093022e-06, 'loss_1': 0.006287647411227226, 'loss_2': 0.0021266937255859375, 'loss_3': -16.535362243652344, 'loss_4': 1.9620258808135986, 'epoch': 21.57}
[INFO|trainer.py:4228] 2025-01-21 13:51:50,444 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:50,444 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                             | 3715/5160 [1:31:54<25:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:51:57,799 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.018507003784179688, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.938, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.014849124476313591, 'eval_loss_2': 0.0036578774452209473, 'eval_loss_3': -18.094430923461914, 'eval_loss_4': 1.889089822769165, 'epoch': 21.57}
{'loss': 0.0239, 'grad_norm': 6.8538126945495605, 'learning_rate': 8.447674418604653e-06, 'loss_1': 0.015295554883778095, 'loss_2': 0.0085906982421875, 'loss_3': -16.03291130065918, 'loss_4': 2.222205638885498, 'epoch': 21.58}
{'loss': 0.0123, 'grad_norm': 4.935873508453369, 'learning_rate': 8.44186046511628e-06, 'loss_1': 0.00882586557418108, 'loss_2': 0.0034809112548828125, 'loss_3': -16.470718383789062, 'loss_4': 1.8464059829711914, 'epoch': 21.58}
{'loss': 0.0118, 'grad_norm': 5.695583820343018, 'learning_rate': 8.436046511627908e-06, 'loss_1': 0.00714246928691864, 'loss_2': 0.00464630126953125, 'loss_3': -16.454689025878906, 'loss_4': 2.26930570602417, 'epoch': 21.59}
{'loss': 0.0205, 'grad_norm': 9.800183296203613, 'learning_rate': 8.430232558139535e-06, 'loss_1': 0.01481371745467186, 'loss_2': 0.00572967529296875, 'loss_3': -16.497238159179688, 'loss_4': 2.1111016273498535, 'epoch': 21.59}
{'loss': 0.0159, 'grad_norm': 7.992211818695068, 'learning_rate': 8.424418604651162e-06, 'loss_1': 0.013370050117373466, 'loss_2': 0.002506256103515625, 'loss_3': -16.559295654296875, 'loss_4': 1.9033188819885254, 'epoch': 21.6}
[INFO|trainer.py:4228] 2025-01-21 13:51:57,799 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:51:57,799 >>   Batch size = 64
 72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                             | 3720/5160 [1:32:02<24:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:05,157 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019774094223976135, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.957, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.016498476266860962, 'eval_loss_2': 0.0032756179571151733, 'eval_loss_3': -18.095809936523438, 'eval_loss_4': 1.8831912279129028, 'epoch': 21.6}
{'loss': 0.0204, 'grad_norm': 4.74501895904541, 'learning_rate': 8.41860465116279e-06, 'loss_1': 0.007419185247272253, 'loss_2': 0.012969970703125, 'loss_3': -16.432466506958008, 'loss_4': 1.8041021823883057, 'epoch': 21.6}
{'loss': 0.0127, 'grad_norm': 5.179551124572754, 'learning_rate': 8.41279069767442e-06, 'loss_1': 0.00854238960891962, 'loss_2': 0.004184722900390625, 'loss_3': -16.47092056274414, 'loss_4': 2.214442491531372, 'epoch': 21.61}
{'loss': 0.0223, 'grad_norm': 5.3532185554504395, 'learning_rate': 8.406976744186048e-06, 'loss_1': 0.009526753798127174, 'loss_2': 0.01273345947265625, 'loss_3': -16.27867317199707, 'loss_4': 1.6282408237457275, 'epoch': 21.62}
{'loss': 0.0162, 'grad_norm': 5.760753154754639, 'learning_rate': 8.401162790697675e-06, 'loss_1': 0.010422484949231148, 'loss_2': 0.00577545166015625, 'loss_3': -16.190319061279297, 'loss_4': 1.6691491603851318, 'epoch': 21.62}
{'loss': 0.0241, 'grad_norm': 11.608353614807129, 'learning_rate': 8.395348837209302e-06, 'loss_1': 0.020169781520962715, 'loss_2': 0.00395965576171875, 'loss_3': -16.2452335357666, 'loss_4': 2.0244827270507812, 'epoch': 21.63}
[INFO|trainer.py:4228] 2025-01-21 13:52:05,157 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:05,157 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                             | 3725/5160 [1:32:09<24:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:12,510 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.024655064567923546, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.020701397210359573, 'eval_loss_2': 0.003953665494918823, 'eval_loss_3': -18.088241577148438, 'eval_loss_4': 1.7911220788955688, 'epoch': 21.63}
{'loss': 0.0167, 'grad_norm': 5.327233791351318, 'learning_rate': 8.38953488372093e-06, 'loss_1': 0.009736249223351479, 'loss_2': 0.006992340087890625, 'loss_3': -16.338380813598633, 'loss_4': 2.366072654724121, 'epoch': 21.63}
{'loss': 0.0184, 'grad_norm': 6.56560754776001, 'learning_rate': 8.383720930232557e-06, 'loss_1': 0.011082145385444164, 'loss_2': 0.00732421875, 'loss_3': -16.481922149658203, 'loss_4': 2.302823781967163, 'epoch': 21.64}
{'loss': 0.0136, 'grad_norm': 5.9491963386535645, 'learning_rate': 8.377906976744188e-06, 'loss_1': 0.008137913420796394, 'loss_2': 0.00550079345703125, 'loss_3': -16.249149322509766, 'loss_4': 1.9582055807113647, 'epoch': 21.65}
{'loss': 0.0146, 'grad_norm': 5.000897407531738, 'learning_rate': 8.372093023255815e-06, 'loss_1': 0.009115592576563358, 'loss_2': 0.0054931640625, 'loss_3': -16.380647659301758, 'loss_4': 1.9614074230194092, 'epoch': 21.65}
{'loss': 0.0869, 'grad_norm': 15.733345985412598, 'learning_rate': 8.366279069767442e-06, 'loss_1': 0.08585738390684128, 'loss_2': 0.0010843276977539062, 'loss_3': -16.239356994628906, 'loss_4': 2.0393500328063965, 'epoch': 21.66}
[INFO|trainer.py:4228] 2025-01-21 13:52:12,510 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:12,510 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 3730/5160 [1:32:17<24:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:19,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02448851615190506, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.02105649746954441, 'eval_loss_2': 0.0034320205450057983, 'eval_loss_3': -18.073684692382812, 'eval_loss_4': 1.7110462188720703, 'epoch': 21.66}
{'loss': 0.0253, 'grad_norm': 9.538607597351074, 'learning_rate': 8.36046511627907e-06, 'loss_1': 0.01941334269940853, 'loss_2': 0.00585174560546875, 'loss_3': -16.494304656982422, 'loss_4': 1.9264132976531982, 'epoch': 21.66}
{'loss': 0.0201, 'grad_norm': 7.579800605773926, 'learning_rate': 8.354651162790697e-06, 'loss_1': 0.01311440858989954, 'loss_2': 0.006946563720703125, 'loss_3': -16.317739486694336, 'loss_4': 1.999671220779419, 'epoch': 21.67}
{'loss': 0.0183, 'grad_norm': 10.474270820617676, 'learning_rate': 8.348837209302326e-06, 'loss_1': 0.014200927689671516, 'loss_2': 0.0040740966796875, 'loss_3': -16.480085372924805, 'loss_4': 1.830272912979126, 'epoch': 21.67}
{'loss': 0.0064, 'grad_norm': 5.326248645782471, 'learning_rate': 8.343023255813954e-06, 'loss_1': 0.0050345659255981445, 'loss_2': 0.0013217926025390625, 'loss_3': -16.454349517822266, 'loss_4': 1.6983323097229004, 'epoch': 21.68}
{'loss': 0.0128, 'grad_norm': 5.00740909576416, 'learning_rate': 8.337209302325583e-06, 'loss_1': 0.004527162294834852, 'loss_2': 0.00829315185546875, 'loss_3': -16.531692504882812, 'loss_4': 1.8241915702819824, 'epoch': 21.69}
[INFO|trainer.py:4228] 2025-01-21 13:52:19,876 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:19,876 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                            | 3735/5160 [1:32:24<24:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:27,250 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02041933313012123, 'eval_runtime': 3.8183, 'eval_samples_per_second': 268.185, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.017179999500513077, 'eval_loss_2': 0.0032393336296081543, 'eval_loss_3': -18.085542678833008, 'eval_loss_4': 1.656375765800476, 'epoch': 21.69}
{'loss': 0.0031, 'grad_norm': 4.233645439147949, 'learning_rate': 8.33139534883721e-06, 'loss_1': 0.002718017902225256, 'loss_2': 0.00033545494079589844, 'loss_3': -16.48932647705078, 'loss_4': 1.6460824012756348, 'epoch': 21.69}
{'loss': 0.0095, 'grad_norm': 5.640194416046143, 'learning_rate': 8.325581395348837e-06, 'loss_1': 0.00820696447044611, 'loss_2': 0.0013189315795898438, 'loss_3': -16.534610748291016, 'loss_4': 2.3185105323791504, 'epoch': 21.7}
{'loss': 0.0057, 'grad_norm': 4.4408464431762695, 'learning_rate': 8.319767441860466e-06, 'loss_1': 0.004152909852564335, 'loss_2': 0.0015325546264648438, 'loss_3': -16.349966049194336, 'loss_4': 1.8282498121261597, 'epoch': 21.7}
{'loss': 0.0045, 'grad_norm': 4.63875675201416, 'learning_rate': 8.313953488372092e-06, 'loss_1': 0.003874080255627632, 'loss_2': 0.0005965232849121094, 'loss_3': -16.20709800720215, 'loss_4': 1.3945789337158203, 'epoch': 21.71}
{'loss': 0.0094, 'grad_norm': 5.067378520965576, 'learning_rate': 8.308139534883721e-06, 'loss_1': 0.007016564253717661, 'loss_2': 0.0024204254150390625, 'loss_3': -16.2532958984375, 'loss_4': 1.6974234580993652, 'epoch': 21.72}
[INFO|trainer.py:4228] 2025-01-21 13:52:27,251 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:27,251 >>   Batch size = 64
 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 3740/5160 [1:32:31<24:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:34,612 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01779213920235634, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.259, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.013971123844385147, 'eval_loss_2': 0.0038210153579711914, 'eval_loss_3': -18.087444305419922, 'eval_loss_4': 1.668452262878418, 'epoch': 21.72}
{'loss': 0.0103, 'grad_norm': 5.1344804763793945, 'learning_rate': 8.30232558139535e-06, 'loss_1': 0.005301067139953375, 'loss_2': 0.004974365234375, 'loss_3': -16.38418960571289, 'loss_4': 1.785200595855713, 'epoch': 21.72}
{'loss': 0.0195, 'grad_norm': 7.40222692489624, 'learning_rate': 8.296511627906977e-06, 'loss_1': 0.017355328425765038, 'loss_2': 0.00214385986328125, 'loss_3': -16.336536407470703, 'loss_4': 1.774292230606079, 'epoch': 21.73}
{'loss': 0.017, 'grad_norm': 8.0424222946167, 'learning_rate': 8.290697674418605e-06, 'loss_1': 0.01303212158381939, 'loss_2': 0.003936767578125, 'loss_3': -16.224403381347656, 'loss_4': 1.8326661586761475, 'epoch': 21.73}
{'loss': 0.0105, 'grad_norm': 4.758551120758057, 'learning_rate': 8.284883720930232e-06, 'loss_1': 0.006884264759719372, 'loss_2': 0.0036468505859375, 'loss_3': -16.519073486328125, 'loss_4': 1.4581469297409058, 'epoch': 21.74}
{'loss': 0.0048, 'grad_norm': 5.0688276290893555, 'learning_rate': 8.279069767441861e-06, 'loss_1': 0.002741451608017087, 'loss_2': 0.002025604248046875, 'loss_3': -16.24070167541504, 'loss_4': 1.9752602577209473, 'epoch': 21.74}
[INFO|trainer.py:4228] 2025-01-21 13:52:34,612 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:34,612 >>   Batch size = 64
 73%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                            | 3745/5160 [1:32:39<24:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:41,979 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01408623717725277, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.010786933824419975, 'eval_loss_2': 0.003299303352832794, 'eval_loss_3': -18.10137939453125, 'eval_loss_4': 1.707263469696045, 'epoch': 21.74}
{'loss': 0.0088, 'grad_norm': 5.501839637756348, 'learning_rate': 8.273255813953488e-06, 'loss_1': 0.00621064705774188, 'loss_2': 0.002628326416015625, 'loss_3': -16.304359436035156, 'loss_4': 1.5695226192474365, 'epoch': 21.75}
{'loss': 0.0184, 'grad_norm': 6.518383502960205, 'learning_rate': 8.267441860465116e-06, 'loss_1': 0.011917523108422756, 'loss_2': 0.006435394287109375, 'loss_3': -16.28985595703125, 'loss_4': 2.0489563941955566, 'epoch': 21.76}
{'loss': 0.0065, 'grad_norm': 4.690619468688965, 'learning_rate': 8.261627906976745e-06, 'loss_1': 0.003229294205084443, 'loss_2': 0.00328826904296875, 'loss_3': -16.25408935546875, 'loss_4': 1.507693886756897, 'epoch': 21.76}
{'loss': 0.0167, 'grad_norm': 7.33895206451416, 'learning_rate': 8.255813953488372e-06, 'loss_1': 0.012477357871830463, 'loss_2': 0.004245758056640625, 'loss_3': -16.255210876464844, 'loss_4': 1.6655638217926025, 'epoch': 21.77}
{'loss': 0.0142, 'grad_norm': 5.4220991134643555, 'learning_rate': 8.25e-06, 'loss_1': 0.0075479233637452126, 'loss_2': 0.00662994384765625, 'loss_3': -16.397022247314453, 'loss_4': 1.6979196071624756, 'epoch': 21.77}
[INFO|trainer.py:4228] 2025-01-21 13:52:41,979 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:41,979 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                           | 3750/5160 [1:32:46<24:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:49,344 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011534701101481915, 'eval_runtime': 3.8105, 'eval_samples_per_second': 268.734, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.008345643989741802, 'eval_loss_2': 0.0031890571117401123, 'eval_loss_3': -18.091064453125, 'eval_loss_4': 1.679781436920166, 'epoch': 21.77}
{'loss': 0.0101, 'grad_norm': 5.424472332000732, 'learning_rate': 8.244186046511628e-06, 'loss_1': 0.005784050561487675, 'loss_2': 0.00431060791015625, 'loss_3': -16.486618041992188, 'loss_4': 2.162064552307129, 'epoch': 21.78}
{'loss': 0.0558, 'grad_norm': 19.473588943481445, 'learning_rate': 8.238372093023255e-06, 'loss_1': 0.04976896196603775, 'loss_2': 0.00598907470703125, 'loss_3': -16.466590881347656, 'loss_4': 2.3637807369232178, 'epoch': 21.78}
{'loss': 0.0096, 'grad_norm': 5.582368850708008, 'learning_rate': 8.232558139534885e-06, 'loss_1': 0.007709997706115246, 'loss_2': 0.0018672943115234375, 'loss_3': -16.23551368713379, 'loss_4': 1.7279298305511475, 'epoch': 21.79}
{'loss': 0.0405, 'grad_norm': 24.414899826049805, 'learning_rate': 8.226744186046512e-06, 'loss_1': 0.040328677743673325, 'loss_2': 0.00016641616821289062, 'loss_3': -16.334606170654297, 'loss_4': 2.369154691696167, 'epoch': 21.8}
{'loss': 0.0226, 'grad_norm': 8.768491744995117, 'learning_rate': 8.22093023255814e-06, 'loss_1': 0.018652115017175674, 'loss_2': 0.003993988037109375, 'loss_3': -16.396503448486328, 'loss_4': 1.9118716716766357, 'epoch': 21.8}
[INFO|trainer.py:4228] 2025-01-21 13:52:49,345 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:49,345 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                           | 3755/5160 [1:32:53<24:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:52:56,709 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011301620863378048, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.749, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007596596144139767, 'eval_loss_2': 0.0037050247192382812, 'eval_loss_3': -18.097126007080078, 'eval_loss_4': 1.6798030138015747, 'epoch': 21.8}
{'loss': 0.0086, 'grad_norm': 4.692265033721924, 'learning_rate': 8.215116279069767e-06, 'loss_1': 0.006468591745942831, 'loss_2': 0.002162933349609375, 'loss_3': -16.26352310180664, 'loss_4': 1.7757699489593506, 'epoch': 21.81}
{'loss': 0.0092, 'grad_norm': 4.548490524291992, 'learning_rate': 8.209302325581394e-06, 'loss_1': 0.005234311800450087, 'loss_2': 0.003978729248046875, 'loss_3': -16.415973663330078, 'loss_4': 2.0102388858795166, 'epoch': 21.81}
{'loss': 0.0078, 'grad_norm': 4.679050922393799, 'learning_rate': 8.203488372093023e-06, 'loss_1': 0.0064703659154474735, 'loss_2': 0.0012912750244140625, 'loss_3': -16.274824142456055, 'loss_4': 1.8436787128448486, 'epoch': 21.82}
{'loss': 0.0115, 'grad_norm': 4.827901363372803, 'learning_rate': 8.197674418604652e-06, 'loss_1': 0.0038271488156169653, 'loss_2': 0.0076904296875, 'loss_3': -16.294754028320312, 'loss_4': 1.8489314317703247, 'epoch': 21.83}
{'loss': 0.0081, 'grad_norm': 4.294384002685547, 'learning_rate': 8.19186046511628e-06, 'loss_1': 0.003756084945052862, 'loss_2': 0.00435638427734375, 'loss_3': -16.250980377197266, 'loss_4': 1.6618496179580688, 'epoch': 21.83}
[INFO|trainer.py:4228] 2025-01-21 13:52:56,709 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:52:56,709 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                           | 3760/5160 [1:33:01<24:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:04,076 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011014524847269058, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.537, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.007450147531926632, 'eval_loss_2': 0.0035643763840198517, 'eval_loss_3': -18.10369110107422, 'eval_loss_4': 1.731163740158081, 'epoch': 21.83}
{'loss': 0.0072, 'grad_norm': 4.453121185302734, 'learning_rate': 8.186046511627907e-06, 'loss_1': 0.006461859680712223, 'loss_2': 0.0006923675537109375, 'loss_3': -16.288772583007812, 'loss_4': 2.1719889640808105, 'epoch': 21.84}
{'loss': 0.0059, 'grad_norm': 5.1187310218811035, 'learning_rate': 8.180232558139534e-06, 'loss_1': 0.0035585190635174513, 'loss_2': 0.00238037109375, 'loss_3': -16.32547950744629, 'loss_4': 1.2230448722839355, 'epoch': 21.84}
{'loss': 0.0089, 'grad_norm': 4.7188029289245605, 'learning_rate': 8.174418604651163e-06, 'loss_1': 0.005618033464998007, 'loss_2': 0.003276824951171875, 'loss_3': -16.476125717163086, 'loss_4': 2.26804256439209, 'epoch': 21.85}
{'loss': 0.0114, 'grad_norm': 5.976358413696289, 'learning_rate': 8.16860465116279e-06, 'loss_1': 0.009894066490232944, 'loss_2': 0.0015554428100585938, 'loss_3': -16.579954147338867, 'loss_4': 1.9297738075256348, 'epoch': 21.85}
{'loss': 0.0181, 'grad_norm': 10.19135856628418, 'learning_rate': 8.16279069767442e-06, 'loss_1': 0.013646908104419708, 'loss_2': 0.004425048828125, 'loss_3': -16.567371368408203, 'loss_4': 2.078479290008545, 'epoch': 21.86}
[INFO|trainer.py:4228] 2025-01-21 13:53:04,077 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:04,077 >>   Batch size = 64
 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 3765/5160 [1:33:08<24:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:11,435 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0109937135130167, 'eval_runtime': 3.8143, 'eval_samples_per_second': 268.464, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00741414213553071, 'eval_loss_2': 0.003579571843147278, 'eval_loss_3': -18.092052459716797, 'eval_loss_4': 1.7885279655456543, 'epoch': 21.86}
{'loss': 0.056, 'grad_norm': 20.154462814331055, 'learning_rate': 8.156976744186047e-06, 'loss_1': 0.05506878346204758, 'loss_2': 0.0009593963623046875, 'loss_3': -16.19677734375, 'loss_4': 1.9645884037017822, 'epoch': 21.87}
{'loss': 0.0153, 'grad_norm': 5.797380447387695, 'learning_rate': 8.151162790697676e-06, 'loss_1': 0.011969748884439468, 'loss_2': 0.003353118896484375, 'loss_3': -16.15398406982422, 'loss_4': 2.218236207962036, 'epoch': 21.87}
{'loss': 0.0138, 'grad_norm': 4.840758323669434, 'learning_rate': 8.145348837209302e-06, 'loss_1': 0.008211005479097366, 'loss_2': 0.00554656982421875, 'loss_3': -16.366104125976562, 'loss_4': 1.986386775970459, 'epoch': 21.88}
{'loss': 0.017, 'grad_norm': 7.343121528625488, 'learning_rate': 8.13953488372093e-06, 'loss_1': 0.008016201667487621, 'loss_2': 0.0090179443359375, 'loss_3': -16.23698616027832, 'loss_4': 1.8165814876556396, 'epoch': 21.88}
{'loss': 0.0139, 'grad_norm': 7.303162097930908, 'learning_rate': 8.133720930232558e-06, 'loss_1': 0.010673079639673233, 'loss_2': 0.0031890869140625, 'loss_3': -15.958930015563965, 'loss_4': 1.9489965438842773, 'epoch': 21.89}
[INFO|trainer.py:4228] 2025-01-21 13:53:11,436 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:11,436 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                           | 3770/5160 [1:33:15<24:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:18,796 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010271411389112473, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.981, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006963375955820084, 'eval_loss_2': 0.003308035433292389, 'eval_loss_3': -18.088010787963867, 'eval_loss_4': 1.864729642868042, 'epoch': 21.89}
{'loss': 0.0021, 'grad_norm': 5.044991970062256, 'learning_rate': 8.127906976744187e-06, 'loss_1': 0.002018718281760812, 'loss_2': 0.00010716915130615234, 'loss_3': -16.37509536743164, 'loss_4': 2.0769565105438232, 'epoch': 21.9}
{'loss': 0.0069, 'grad_norm': 4.484316349029541, 'learning_rate': 8.122093023255815e-06, 'loss_1': 0.003916114568710327, 'loss_2': 0.00298309326171875, 'loss_3': -16.179611206054688, 'loss_4': 1.908959984779358, 'epoch': 21.9}
{'loss': 0.002, 'grad_norm': 4.518247604370117, 'learning_rate': 8.116279069767442e-06, 'loss_1': 0.001994266640394926, 'loss_2': 3.343820571899414e-05, 'loss_3': -16.20452117919922, 'loss_4': 1.6762776374816895, 'epoch': 21.91}
{'loss': 0.0102, 'grad_norm': 5.525760650634766, 'learning_rate': 8.11046511627907e-06, 'loss_1': 0.005551840178668499, 'loss_2': 0.00467681884765625, 'loss_3': -16.150728225708008, 'loss_4': 1.8730117082595825, 'epoch': 21.91}
{'loss': 0.0038, 'grad_norm': 4.746106147766113, 'learning_rate': 8.104651162790698e-06, 'loss_1': 0.003188726492226124, 'loss_2': 0.0005788803100585938, 'loss_3': -16.533145904541016, 'loss_4': 1.9666686058044434, 'epoch': 21.92}
[INFO|trainer.py:4228] 2025-01-21 13:53:18,796 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:18,796 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 3775/5160 [1:33:23<24:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:26,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009980820119380951, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.188, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006681197322905064, 'eval_loss_2': 0.003299623727798462, 'eval_loss_3': -18.080236434936523, 'eval_loss_4': 1.8905490636825562, 'epoch': 21.92}
{'loss': 0.0241, 'grad_norm': 15.866606712341309, 'learning_rate': 8.098837209302325e-06, 'loss_1': 0.023729901760816574, 'loss_2': 0.0003943443298339844, 'loss_3': -16.275007247924805, 'loss_4': 1.9613826274871826, 'epoch': 21.92}
{'loss': 0.0094, 'grad_norm': 5.146777153015137, 'learning_rate': 8.093023255813955e-06, 'loss_1': 0.00582593958824873, 'loss_2': 0.0035877227783203125, 'loss_3': -16.398460388183594, 'loss_4': 1.916327953338623, 'epoch': 21.93}
{'loss': 0.0069, 'grad_norm': 5.961968421936035, 'learning_rate': 8.087209302325582e-06, 'loss_1': 0.005528764333575964, 'loss_2': 0.00141143798828125, 'loss_3': -16.285598754882812, 'loss_4': 1.7327758073806763, 'epoch': 21.94}
{'loss': 0.0218, 'grad_norm': 15.19109058380127, 'learning_rate': 8.081395348837209e-06, 'loss_1': 0.019684145227074623, 'loss_2': 0.0020904541015625, 'loss_3': -16.40369415283203, 'loss_4': 2.350656032562256, 'epoch': 21.94}
{'loss': 0.0073, 'grad_norm': 5.290034294128418, 'learning_rate': 8.075581395348838e-06, 'loss_1': 0.005515899043530226, 'loss_2': 0.0017681121826171875, 'loss_3': -16.311935424804688, 'loss_4': 2.135112762451172, 'epoch': 21.95}
[INFO|trainer.py:4228] 2025-01-21 13:53:26,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:26,154 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                          | 3780/5160 [1:33:30<23:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:33,517 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010712506249547005, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.984, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007158518768846989, 'eval_loss_2': 0.0035539865493774414, 'eval_loss_3': -18.084182739257812, 'eval_loss_4': 1.8950492143630981, 'epoch': 21.95}
{'loss': 0.0139, 'grad_norm': 6.743347644805908, 'learning_rate': 8.069767441860465e-06, 'loss_1': 0.008749796077609062, 'loss_2': 0.00518798828125, 'loss_3': -16.372573852539062, 'loss_4': 2.4412243366241455, 'epoch': 21.95}
{'loss': 0.0101, 'grad_norm': 5.900460720062256, 'learning_rate': 8.063953488372093e-06, 'loss_1': 0.006008574273437262, 'loss_2': 0.00408935546875, 'loss_3': -16.533245086669922, 'loss_4': 2.0339465141296387, 'epoch': 21.96}
{'loss': 0.0048, 'grad_norm': 4.576259613037109, 'learning_rate': 8.058139534883722e-06, 'loss_1': 0.0022658132947981358, 'loss_2': 0.002506256103515625, 'loss_3': -16.467388153076172, 'loss_4': 1.908023476600647, 'epoch': 21.97}
{'loss': 0.0531, 'grad_norm': 34.67513656616211, 'learning_rate': 8.052325581395349e-06, 'loss_1': 0.051722388714551926, 'loss_2': 0.001415252685546875, 'loss_3': -16.32007598876953, 'loss_4': 2.2530808448791504, 'epoch': 21.97}
{'loss': 0.0057, 'grad_norm': 6.139749526977539, 'learning_rate': 8.046511627906977e-06, 'loss_1': 0.003464571200311184, 'loss_2': 0.002246856689453125, 'loss_3': -16.259546279907227, 'loss_4': 2.2359619140625, 'epoch': 21.98}
[INFO|trainer.py:4228] 2025-01-21 13:53:33,517 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:33,517 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                          | 3785/5160 [1:33:37<22:28,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 13:53:40,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010697055608034134, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00697301747277379, 'eval_loss_2': 0.003724038600921631, 'eval_loss_3': -18.075912475585938, 'eval_loss_4': 1.8622270822525024, 'epoch': 21.98}
{'loss': 0.007, 'grad_norm': 5.318302631378174, 'learning_rate': 8.040697674418604e-06, 'loss_1': 0.005584659520536661, 'loss_2': 0.0014019012451171875, 'loss_3': -16.465904235839844, 'loss_4': 1.9598581790924072, 'epoch': 21.98}
{'loss': 0.0202, 'grad_norm': 8.962545394897461, 'learning_rate': 8.034883720930233e-06, 'loss_1': 0.01227791327983141, 'loss_2': 0.0079345703125, 'loss_3': -16.24164390563965, 'loss_4': 1.7213292121887207, 'epoch': 21.99}
{'loss': 0.0092, 'grad_norm': 5.476104736328125, 'learning_rate': 8.02906976744186e-06, 'loss_1': 0.007828354835510254, 'loss_2': 0.001346588134765625, 'loss_3': -16.21173858642578, 'loss_4': 2.284259080886841, 'epoch': 21.99}
{'loss': 0.0043, 'grad_norm': 5.961541652679443, 'learning_rate': 8.023255813953488e-06, 'loss_1': 0.0021134617272764444, 'loss_2': 0.0021514892578125, 'loss_3': -16.555431365966797, 'loss_4': 1.4815576076507568, 'epoch': 22.0}
{'loss': 0.009, 'grad_norm': 5.0432305335998535, 'learning_rate': 8.017441860465117e-06, 'loss_1': 0.007723262067884207, 'loss_2': 0.0012969970703125, 'loss_3': -16.467926025390625, 'loss_4': 2.2962684631347656, 'epoch': 22.01}
[INFO|trainer.py:4228] 2025-01-21 13:53:40,570 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:40,570 >>   Batch size = 64
 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                          | 3790/5160 [1:33:45<23:32,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 13:53:47,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011077383533120155, 'eval_runtime': 3.82, 'eval_samples_per_second': 268.062, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.00720075611025095, 'eval_loss_2': 0.003876626491546631, 'eval_loss_3': -18.067148208618164, 'eval_loss_4': 1.8265461921691895, 'epoch': 22.01}
{'loss': 0.0077, 'grad_norm': 5.11259651184082, 'learning_rate': 8.011627906976744e-06, 'loss_1': 0.006679436657577753, 'loss_2': 0.0009918212890625, 'loss_3': -16.510581970214844, 'loss_4': 2.5047688484191895, 'epoch': 22.01}
{'loss': 0.0119, 'grad_norm': 4.564959526062012, 'learning_rate': 8.005813953488373e-06, 'loss_1': 0.005292635876685381, 'loss_2': 0.006595611572265625, 'loss_3': -16.148971557617188, 'loss_4': 1.7272080183029175, 'epoch': 22.02}
{'loss': 0.0107, 'grad_norm': 4.78171968460083, 'learning_rate': 8e-06, 'loss_1': 0.0027572056278586388, 'loss_2': 0.00791168212890625, 'loss_3': -16.390609741210938, 'loss_4': 1.7049014568328857, 'epoch': 22.02}
{'loss': 0.0078, 'grad_norm': 6.035849094390869, 'learning_rate': 7.994186046511627e-06, 'loss_1': 0.00571430241689086, 'loss_2': 0.00208282470703125, 'loss_3': -16.28199005126953, 'loss_4': 2.041881799697876, 'epoch': 22.03}
{'loss': 0.006, 'grad_norm': 4.842784881591797, 'learning_rate': 7.988372093023257e-06, 'loss_1': 0.003304725047200918, 'loss_2': 0.002727508544921875, 'loss_3': -16.14665412902832, 'loss_4': 2.1141180992126465, 'epoch': 22.03}
[INFO|trainer.py:4228] 2025-01-21 13:53:47,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:47,944 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 3795/5160 [1:33:52<23:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:53:55,309 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010890031233429909, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.936, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0068441289477050304, 'eval_loss_2': 0.00404590368270874, 'eval_loss_3': -18.072288513183594, 'eval_loss_4': 1.756026268005371, 'epoch': 22.03}
{'loss': 0.0073, 'grad_norm': 4.622529029846191, 'learning_rate': 7.982558139534884e-06, 'loss_1': 0.005200057756155729, 'loss_2': 0.0020847320556640625, 'loss_3': -16.26361083984375, 'loss_4': 1.8352551460266113, 'epoch': 22.04}
{'loss': 0.0062, 'grad_norm': 4.516215801239014, 'learning_rate': 7.976744186046512e-06, 'loss_1': 0.0038185594603419304, 'loss_2': 0.0023937225341796875, 'loss_3': -16.353431701660156, 'loss_4': 1.9013378620147705, 'epoch': 22.05}
{'loss': 0.0314, 'grad_norm': 11.772794723510742, 'learning_rate': 7.97093023255814e-06, 'loss_1': 0.024021711200475693, 'loss_2': 0.007335662841796875, 'loss_3': -16.424057006835938, 'loss_4': 1.9407932758331299, 'epoch': 22.05}
{'loss': 0.0081, 'grad_norm': 4.975959777832031, 'learning_rate': 7.965116279069768e-06, 'loss_1': 0.004654722288250923, 'loss_2': 0.0034122467041015625, 'loss_3': -16.253211975097656, 'loss_4': 2.034177303314209, 'epoch': 22.06}
{'loss': 0.0036, 'grad_norm': 4.6997761726379395, 'learning_rate': 7.959302325581395e-06, 'loss_1': 0.003535051131621003, 'loss_2': 0.00011110305786132812, 'loss_3': -16.163719177246094, 'loss_4': 1.9934340715408325, 'epoch': 22.06}
[INFO|trainer.py:4228] 2025-01-21 13:53:55,310 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:53:55,310 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                         | 3800/5160 [1:33:59<23:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:02,667 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010204680263996124, 'eval_runtime': 3.8061, 'eval_samples_per_second': 269.044, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006260596215724945, 'eval_loss_2': 0.003944084048271179, 'eval_loss_3': -18.078702926635742, 'eval_loss_4': 1.6642390489578247, 'epoch': 22.06}
{'loss': 0.0162, 'grad_norm': 4.647156715393066, 'learning_rate': 7.953488372093024e-06, 'loss_1': 0.005266926251351833, 'loss_2': 0.0109710693359375, 'loss_3': -16.361804962158203, 'loss_4': 2.0054802894592285, 'epoch': 22.07}
{'loss': 0.0661, 'grad_norm': 14.239295959472656, 'learning_rate': 7.947674418604652e-06, 'loss_1': 0.06381334364414215, 'loss_2': 0.0023193359375, 'loss_3': -16.38227653503418, 'loss_4': 2.0895743370056152, 'epoch': 22.08}
{'loss': 0.0069, 'grad_norm': 4.969272136688232, 'learning_rate': 7.94186046511628e-06, 'loss_1': 0.004662224557250738, 'loss_2': 0.00226593017578125, 'loss_3': -16.485910415649414, 'loss_4': 1.5760014057159424, 'epoch': 22.08}
{'loss': 0.0105, 'grad_norm': 4.804675579071045, 'learning_rate': 7.936046511627908e-06, 'loss_1': 0.004263742361217737, 'loss_2': 0.0062103271484375, 'loss_3': -16.262317657470703, 'loss_4': 1.6674691438674927, 'epoch': 22.09}
{'loss': 0.0337, 'grad_norm': 19.84482765197754, 'learning_rate': 7.930232558139535e-06, 'loss_1': 0.03125914931297302, 'loss_2': 0.0024871826171875, 'loss_3': -16.305233001708984, 'loss_4': 1.242802381515503, 'epoch': 22.09}
[INFO|trainer.py:4228] 2025-01-21 13:54:02,667 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:02,667 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                         | 3805/5160 [1:34:07<23:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:10,033 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009720204398036003, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.862, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006236008368432522, 'eval_loss_2': 0.003484196960926056, 'eval_loss_3': -18.08847427368164, 'eval_loss_4': 1.6017482280731201, 'epoch': 22.09}
{'loss': 0.0073, 'grad_norm': 5.124422550201416, 'learning_rate': 7.924418604651162e-06, 'loss_1': 0.002910190960392356, 'loss_2': 0.0043792724609375, 'loss_3': -16.240835189819336, 'loss_4': 1.8663661479949951, 'epoch': 22.1}
{'loss': 0.0081, 'grad_norm': 5.765039443969727, 'learning_rate': 7.918604651162792e-06, 'loss_1': 0.00661831209436059, 'loss_2': 0.0014896392822265625, 'loss_3': -16.299835205078125, 'loss_4': 1.6560802459716797, 'epoch': 22.1}
{'loss': 0.0102, 'grad_norm': 4.961010456085205, 'learning_rate': 7.912790697674419e-06, 'loss_1': 0.002523618983104825, 'loss_2': 0.007633209228515625, 'loss_3': -16.226537704467773, 'loss_4': 1.9210846424102783, 'epoch': 22.11}
{'loss': 0.0064, 'grad_norm': 5.048929214477539, 'learning_rate': 7.906976744186048e-06, 'loss_1': 0.00350141990929842, 'loss_2': 0.0029315948486328125, 'loss_3': -16.221004486083984, 'loss_4': 1.7611587047576904, 'epoch': 22.12}
{'loss': 0.0184, 'grad_norm': 12.151116371154785, 'learning_rate': 7.901162790697675e-06, 'loss_1': 0.010877594351768494, 'loss_2': 0.00756072998046875, 'loss_3': -16.263158798217773, 'loss_4': 1.8343732357025146, 'epoch': 22.12}
[INFO|trainer.py:4228] 2025-01-21 13:54:10,033 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:10,033 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 3810/5160 [1:34:14<23:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:17,393 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01167879905551672, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007371141575276852, 'eval_loss_2': 0.004307657480239868, 'eval_loss_3': -18.063722610473633, 'eval_loss_4': 1.581257700920105, 'epoch': 22.12}
{'loss': 0.0081, 'grad_norm': 5.843409061431885, 'learning_rate': 7.895348837209301e-06, 'loss_1': 0.00654088007286191, 'loss_2': 0.00157928466796875, 'loss_3': -16.127155303955078, 'loss_4': 2.0080225467681885, 'epoch': 22.13}
{'loss': 0.0129, 'grad_norm': 5.424839019775391, 'learning_rate': 7.88953488372093e-06, 'loss_1': 0.008344809524714947, 'loss_2': 0.004512786865234375, 'loss_3': -16.155364990234375, 'loss_4': 1.4472163915634155, 'epoch': 22.13}
{'loss': 0.0052, 'grad_norm': 4.871966361999512, 'learning_rate': 7.883720930232559e-06, 'loss_1': 0.003777052043005824, 'loss_2': 0.0014543533325195312, 'loss_3': -16.321739196777344, 'loss_4': 1.686887502670288, 'epoch': 22.14}
{'loss': 0.0084, 'grad_norm': 5.593907833099365, 'learning_rate': 7.877906976744187e-06, 'loss_1': 0.001453799894079566, 'loss_2': 0.00695037841796875, 'loss_3': -16.418807983398438, 'loss_4': 1.53960382938385, 'epoch': 22.15}
{'loss': 0.0116, 'grad_norm': 8.47319221496582, 'learning_rate': 7.872093023255814e-06, 'loss_1': 0.011230587027966976, 'loss_2': 0.000324249267578125, 'loss_3': -16.423940658569336, 'loss_4': 1.8455297946929932, 'epoch': 22.15}
[INFO|trainer.py:4228] 2025-01-21 13:54:17,393 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:17,393 >>   Batch size = 64
 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 3815/5160 [1:34:22<23:39,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 13:54:24,969 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01079756673425436, 'eval_runtime': 4.0202, 'eval_samples_per_second': 254.712, 'eval_steps_per_second': 3.98, 'eval_loss_1': 0.007384209893643856, 'eval_loss_2': 0.003413356840610504, 'eval_loss_3': -18.067352294921875, 'eval_loss_4': 1.5082446336746216, 'epoch': 22.15}
{'loss': 0.0101, 'grad_norm': 5.207046031951904, 'learning_rate': 7.866279069767441e-06, 'loss_1': 0.005239545833319426, 'loss_2': 0.0048828125, 'loss_3': -16.32059669494629, 'loss_4': 1.3939204216003418, 'epoch': 22.16}
{'loss': 0.007, 'grad_norm': 4.6456780433654785, 'learning_rate': 7.86046511627907e-06, 'loss_1': 0.003244951833039522, 'loss_2': 0.003711700439453125, 'loss_3': -16.432846069335938, 'loss_4': 1.57767653465271, 'epoch': 22.16}
{'loss': 0.0101, 'grad_norm': 5.498752593994141, 'learning_rate': 7.854651162790697e-06, 'loss_1': 0.005515229422599077, 'loss_2': 0.00457000732421875, 'loss_3': -16.222537994384766, 'loss_4': 1.5337640047073364, 'epoch': 22.17}
{'loss': 0.0163, 'grad_norm': 9.090868949890137, 'learning_rate': 7.848837209302327e-06, 'loss_1': 0.011877452954649925, 'loss_2': 0.00439453125, 'loss_3': -16.34207534790039, 'loss_4': 2.066009283065796, 'epoch': 22.17}
{'loss': 0.0068, 'grad_norm': 5.510836124420166, 'learning_rate': 7.843023255813954e-06, 'loss_1': 0.004643828608095646, 'loss_2': 0.0021648406982421875, 'loss_3': -16.444040298461914, 'loss_4': 1.5891993045806885, 'epoch': 22.18}
[INFO|trainer.py:4228] 2025-01-21 13:54:24,969 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:24,969 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                        | 3820/5160 [1:34:29<23:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:32,349 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012877898290753365, 'eval_runtime': 3.8212, 'eval_samples_per_second': 267.979, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.009321512654423714, 'eval_loss_2': 0.003556385636329651, 'eval_loss_3': -18.07212257385254, 'eval_loss_4': 1.2914116382598877, 'epoch': 22.18}
{'loss': 0.0136, 'grad_norm': 9.500256538391113, 'learning_rate': 7.837209302325581e-06, 'loss_1': 0.013180448673665524, 'loss_2': 0.00042128562927246094, 'loss_3': -16.267593383789062, 'loss_4': 1.6625888347625732, 'epoch': 22.19}
{'loss': 0.0129, 'grad_norm': 6.913185119628906, 'learning_rate': 7.83139534883721e-06, 'loss_1': 0.012142689898610115, 'loss_2': 0.0007314682006835938, 'loss_3': -16.381969451904297, 'loss_4': 1.5561695098876953, 'epoch': 22.19}
{'loss': 0.0045, 'grad_norm': 4.4160332679748535, 'learning_rate': 7.825581395348837e-06, 'loss_1': 0.003009340027347207, 'loss_2': 0.0014543533325195312, 'loss_3': -16.419593811035156, 'loss_4': 1.4338759183883667, 'epoch': 22.2}
{'loss': 0.0579, 'grad_norm': 22.421857833862305, 'learning_rate': 7.819767441860465e-06, 'loss_1': 0.05761973559856415, 'loss_2': 0.00023937225341796875, 'loss_3': -16.445863723754883, 'loss_4': 1.784348726272583, 'epoch': 22.2}
{'loss': 0.007, 'grad_norm': 4.915034294128418, 'learning_rate': 7.813953488372094e-06, 'loss_1': 0.004956120625138283, 'loss_2': 0.002033233642578125, 'loss_3': -16.15628433227539, 'loss_4': 1.6406276226043701, 'epoch': 22.21}
[INFO|trainer.py:4228] 2025-01-21 13:54:32,349 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:32,349 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                        | 3825/5160 [1:34:36<23:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:39,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.015156783163547516, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.603, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.010780164040625095, 'eval_loss_2': 0.004376620054244995, 'eval_loss_3': -18.062650680541992, 'eval_loss_4': 1.1051931381225586, 'epoch': 22.21}
{'loss': 0.0089, 'grad_norm': 5.557333946228027, 'learning_rate': 7.80813953488372e-06, 'loss_1': 0.006531675346195698, 'loss_2': 0.00238037109375, 'loss_3': -16.39132308959961, 'loss_4': 1.1582974195480347, 'epoch': 22.22}
{'loss': 0.0104, 'grad_norm': 5.857155799865723, 'learning_rate': 7.80232558139535e-06, 'loss_1': 0.007928539998829365, 'loss_2': 0.0025043487548828125, 'loss_3': -16.331844329833984, 'loss_4': 1.0113483667373657, 'epoch': 22.22}
{'loss': 0.0045, 'grad_norm': 4.071129322052002, 'learning_rate': 7.796511627906976e-06, 'loss_1': 0.002892974531278014, 'loss_2': 0.0016345977783203125, 'loss_3': -16.41820526123047, 'loss_4': 1.1464213132858276, 'epoch': 22.23}
{'loss': 0.0311, 'grad_norm': 15.984033584594727, 'learning_rate': 7.790697674418605e-06, 'loss_1': 0.016894347965717316, 'loss_2': 0.01424407958984375, 'loss_3': -16.49612045288086, 'loss_4': 1.2655004262924194, 'epoch': 22.23}
{'loss': 0.0404, 'grad_norm': 11.867055892944336, 'learning_rate': 7.784883720930232e-06, 'loss_1': 0.033037882298231125, 'loss_2': 0.00731658935546875, 'loss_3': -16.355438232421875, 'loss_4': 1.6694786548614502, 'epoch': 22.24}
[INFO|trainer.py:4228] 2025-01-21 13:54:39,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:39,723 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3830/5160 [1:34:44<23:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:47,084 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.019643843173980713, 'eval_runtime': 3.8088, 'eval_samples_per_second': 268.851, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.015227511525154114, 'eval_loss_2': 0.004416331648826599, 'eval_loss_3': -18.05514144897461, 'eval_loss_4': 0.9674761891365051, 'epoch': 22.24}
{'loss': 0.0106, 'grad_norm': 5.016764163970947, 'learning_rate': 7.779069767441862e-06, 'loss_1': 0.00798063911497593, 'loss_2': 0.002666473388671875, 'loss_3': -16.32444190979004, 'loss_4': 1.2206164598464966, 'epoch': 22.24}
{'loss': 0.0139, 'grad_norm': 7.046707630157471, 'learning_rate': 7.77325581395349e-06, 'loss_1': 0.0056827859953045845, 'loss_2': 0.00817108154296875, 'loss_3': -16.178279876708984, 'loss_4': 1.0517367124557495, 'epoch': 22.25}
{'loss': 0.0183, 'grad_norm': 6.266185283660889, 'learning_rate': 7.767441860465116e-06, 'loss_1': 0.008520378731191158, 'loss_2': 0.0097808837890625, 'loss_3': -16.403812408447266, 'loss_4': 0.9943872690200806, 'epoch': 22.26}
{'loss': 0.0091, 'grad_norm': 6.974639892578125, 'learning_rate': 7.761627906976745e-06, 'loss_1': 0.008504901081323624, 'loss_2': 0.0005598068237304688, 'loss_3': -16.274520874023438, 'loss_4': 0.8883172273635864, 'epoch': 22.26}
{'loss': 0.0099, 'grad_norm': 4.919437408447266, 'learning_rate': 7.755813953488372e-06, 'loss_1': 0.005674238782376051, 'loss_2': 0.0041961669921875, 'loss_3': -16.45261001586914, 'loss_4': 0.9290874004364014, 'epoch': 22.27}
[INFO|trainer.py:4228] 2025-01-21 13:54:47,084 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:47,084 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                        | 3835/5160 [1:34:51<22:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:54:54,446 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.02230859361588955, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.862, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.018659761175513268, 'eval_loss_2': 0.0036488324403762817, 'eval_loss_3': -18.0498046875, 'eval_loss_4': 0.8846802711486816, 'epoch': 22.27}
{'loss': 0.0112, 'grad_norm': 7.6585211753845215, 'learning_rate': 7.75e-06, 'loss_1': 0.008351575583219528, 'loss_2': 0.00281524658203125, 'loss_3': -16.44100570678711, 'loss_4': 0.7599049210548401, 'epoch': 22.27}
{'loss': 0.0137, 'grad_norm': 4.813396453857422, 'learning_rate': 7.744186046511629e-06, 'loss_1': 0.0023601872380822897, 'loss_2': 0.0113067626953125, 'loss_3': -16.204303741455078, 'loss_4': 0.6316163539886475, 'epoch': 22.28}
{'loss': 0.0092, 'grad_norm': 5.50628662109375, 'learning_rate': 7.738372093023256e-06, 'loss_1': 0.006789884530007839, 'loss_2': 0.0023784637451171875, 'loss_3': -16.396141052246094, 'loss_4': 1.449320673942566, 'epoch': 22.28}
{'loss': 0.0328, 'grad_norm': 19.077966690063477, 'learning_rate': 7.732558139534885e-06, 'loss_1': 0.028911951929330826, 'loss_2': 0.00389862060546875, 'loss_3': -16.315078735351562, 'loss_4': 1.0107841491699219, 'epoch': 22.29}
{'loss': 0.0115, 'grad_norm': 4.670942783355713, 'learning_rate': 7.726744186046511e-06, 'loss_1': 0.0023605909664183855, 'loss_2': 0.00909423828125, 'loss_3': -16.469022750854492, 'loss_4': 0.8569591641426086, 'epoch': 22.3}
[INFO|trainer.py:4228] 2025-01-21 13:54:54,446 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:54:54,446 >>   Batch size = 64
 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                        | 3840/5160 [1:34:58<22:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:01,820 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014523658901453018, 'eval_runtime': 3.814, 'eval_samples_per_second': 268.487, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.011562097817659378, 'eval_loss_2': 0.00296156108379364, 'eval_loss_3': -18.097043991088867, 'eval_loss_4': 0.8740133047103882, 'epoch': 22.3}
{'loss': 0.0084, 'grad_norm': 5.556881427764893, 'learning_rate': 7.72093023255814e-06, 'loss_1': 0.007212415803223848, 'loss_2': 0.00122833251953125, 'loss_3': -16.15145492553711, 'loss_4': 0.8977788686752319, 'epoch': 22.3}
{'loss': 0.0071, 'grad_norm': 4.550027847290039, 'learning_rate': 7.715116279069767e-06, 'loss_1': 0.00489509291946888, 'loss_2': 0.0022125244140625, 'loss_3': -16.443010330200195, 'loss_4': 1.1572375297546387, 'epoch': 22.31}
{'loss': 0.009, 'grad_norm': 7.5280842781066895, 'learning_rate': 7.709302325581396e-06, 'loss_1': 0.006999556440860033, 'loss_2': 0.0020351409912109375, 'loss_3': -16.438488006591797, 'loss_4': 1.418569803237915, 'epoch': 22.31}
{'loss': 0.0056, 'grad_norm': 4.701321125030518, 'learning_rate': 7.703488372093024e-06, 'loss_1': 0.0023284375201910734, 'loss_2': 0.0032901763916015625, 'loss_3': -16.50469970703125, 'loss_4': 1.169651746749878, 'epoch': 22.32}
{'loss': 0.0207, 'grad_norm': 13.494471549987793, 'learning_rate': 7.697674418604651e-06, 'loss_1': 0.01957874745130539, 'loss_2': 0.0011510848999023438, 'loss_3': -16.340160369873047, 'loss_4': 1.2049272060394287, 'epoch': 22.33}
[INFO|trainer.py:4228] 2025-01-21 13:55:01,820 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:01,820 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                       | 3845/5160 [1:35:06<22:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:09,203 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011080216616392136, 'eval_runtime': 3.818, 'eval_samples_per_second': 268.202, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.008689861744642258, 'eval_loss_2': 0.002390354871749878, 'eval_loss_3': -18.127004623413086, 'eval_loss_4': 0.9708507061004639, 'epoch': 22.33}
{'loss': 0.0291, 'grad_norm': 19.086042404174805, 'learning_rate': 7.69186046511628e-06, 'loss_1': 0.028363946825265884, 'loss_2': 0.0007305145263671875, 'loss_3': -16.319761276245117, 'loss_4': 1.1578720808029175, 'epoch': 22.33}
{'loss': 0.0054, 'grad_norm': 4.34601354598999, 'learning_rate': 7.686046511627907e-06, 'loss_1': 0.003049412276595831, 'loss_2': 0.0023479461669921875, 'loss_3': -16.320446014404297, 'loss_4': 1.2501085996627808, 'epoch': 22.34}
{'loss': 0.0101, 'grad_norm': 5.1910786628723145, 'learning_rate': 7.680232558139534e-06, 'loss_1': 0.008247338235378265, 'loss_2': 0.0018720626831054688, 'loss_3': -16.397424697875977, 'loss_4': 1.6068580150604248, 'epoch': 22.34}
{'loss': 0.0187, 'grad_norm': 10.438467025756836, 'learning_rate': 7.674418604651164e-06, 'loss_1': 0.008494587615132332, 'loss_2': 0.01018524169921875, 'loss_3': -16.484283447265625, 'loss_4': 0.9875879287719727, 'epoch': 22.35}
{'loss': 0.0072, 'grad_norm': 4.6359052658081055, 'learning_rate': 7.668604651162791e-06, 'loss_1': 0.004556496627628803, 'loss_2': 0.0025959014892578125, 'loss_3': -16.432811737060547, 'loss_4': 1.6634610891342163, 'epoch': 22.35}
[INFO|trainer.py:4228] 2025-01-21 13:55:09,203 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:09,203 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                       | 3850/5160 [1:35:13<22:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:16,574 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008928886614739895, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.457, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.00619012676179409, 'eval_loss_2': 0.00273875892162323, 'eval_loss_3': -18.154550552368164, 'eval_loss_4': 1.0862623453140259, 'epoch': 22.35}
{'loss': 0.0052, 'grad_norm': 4.808964252471924, 'learning_rate': 7.66279069767442e-06, 'loss_1': 0.003940294962376356, 'loss_2': 0.0012922286987304688, 'loss_3': -16.26101303100586, 'loss_4': 1.1870061159133911, 'epoch': 22.36}
{'loss': 0.0111, 'grad_norm': 4.551765441894531, 'learning_rate': 7.656976744186047e-06, 'loss_1': 0.004012943711131811, 'loss_2': 0.007053375244140625, 'loss_3': -16.3754825592041, 'loss_4': 1.497031331062317, 'epoch': 22.37}
{'loss': 0.0131, 'grad_norm': 4.793490886688232, 'learning_rate': 7.651162790697674e-06, 'loss_1': 0.003213738091289997, 'loss_2': 0.009918212890625, 'loss_3': -16.440654754638672, 'loss_4': 1.4936671257019043, 'epoch': 22.37}
{'loss': 0.0115, 'grad_norm': 8.548388481140137, 'learning_rate': 7.645348837209302e-06, 'loss_1': 0.006773224100470543, 'loss_2': 0.00473785400390625, 'loss_3': -16.50221824645996, 'loss_4': 1.4166216850280762, 'epoch': 22.38}
{'loss': 0.0049, 'grad_norm': 4.688643455505371, 'learning_rate': 7.63953488372093e-06, 'loss_1': 0.002547674346715212, 'loss_2': 0.00235748291015625, 'loss_3': -16.58379364013672, 'loss_4': 1.37001371383667, 'epoch': 22.38}
[INFO|trainer.py:4228] 2025-01-21 13:55:16,574 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:16,574 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                       | 3855/5160 [1:35:21<22:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:23,944 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00842295028269291, 'eval_runtime': 3.8135, 'eval_samples_per_second': 268.522, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.0056620631366968155, 'eval_loss_2': 0.0027608871459960938, 'eval_loss_3': -18.143789291381836, 'eval_loss_4': 1.1140795946121216, 'epoch': 22.38}
{'loss': 0.0093, 'grad_norm': 8.939040184020996, 'learning_rate': 7.63372093023256e-06, 'loss_1': 0.007982184179127216, 'loss_2': 0.0012836456298828125, 'loss_3': -16.402484893798828, 'loss_4': 1.2123714685440063, 'epoch': 22.39}
{'loss': 0.0098, 'grad_norm': 5.019534587860107, 'learning_rate': 7.627906976744186e-06, 'loss_1': 0.003789926180616021, 'loss_2': 0.005962371826171875, 'loss_3': -16.35572624206543, 'loss_4': 1.451350450515747, 'epoch': 22.4}
{'loss': 0.0135, 'grad_norm': 5.07512903213501, 'learning_rate': 7.622093023255813e-06, 'loss_1': 0.006606702227145433, 'loss_2': 0.00689697265625, 'loss_3': -16.316587448120117, 'loss_4': 1.3651587963104248, 'epoch': 22.4}
{'loss': 0.0108, 'grad_norm': 4.980345726013184, 'learning_rate': 7.616279069767442e-06, 'loss_1': 0.00477100582793355, 'loss_2': 0.00603485107421875, 'loss_3': -16.359642028808594, 'loss_4': 1.2968981266021729, 'epoch': 22.41}
{'loss': 0.0126, 'grad_norm': 7.5342631340026855, 'learning_rate': 7.61046511627907e-06, 'loss_1': 0.00855952687561512, 'loss_2': 0.004058837890625, 'loss_3': -16.172847747802734, 'loss_4': 1.3163793087005615, 'epoch': 22.41}
[INFO|trainer.py:4228] 2025-01-21 13:55:23,944 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:23,944 >>   Batch size = 64
 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                       | 3860/5160 [1:35:28<22:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:31,313 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008764224126935005, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.407, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006027833558619022, 'eval_loss_2': 0.002736389636993408, 'eval_loss_3': -18.15557861328125, 'eval_loss_4': 1.0982810258865356, 'epoch': 22.41}
{'loss': 0.0167, 'grad_norm': 9.654236793518066, 'learning_rate': 7.604651162790698e-06, 'loss_1': 0.016270432621240616, 'loss_2': 0.0004553794860839844, 'loss_3': -16.466875076293945, 'loss_4': 0.9987106919288635, 'epoch': 22.42}
{'loss': 0.0087, 'grad_norm': 4.449299335479736, 'learning_rate': 7.598837209302325e-06, 'loss_1': 0.004819425754249096, 'loss_2': 0.00384521484375, 'loss_3': -16.390869140625, 'loss_4': 1.530376672744751, 'epoch': 22.42}
{'loss': 0.0031, 'grad_norm': 4.627231121063232, 'learning_rate': 7.593023255813955e-06, 'loss_1': 0.002196950139477849, 'loss_2': 0.0008668899536132812, 'loss_3': -16.384536743164062, 'loss_4': 1.9563332796096802, 'epoch': 22.43}
{'loss': 0.0059, 'grad_norm': 5.208528518676758, 'learning_rate': 7.587209302325582e-06, 'loss_1': 0.005268160253763199, 'loss_2': 0.0006117820739746094, 'loss_3': -16.496488571166992, 'loss_4': 1.2352826595306396, 'epoch': 22.44}
{'loss': 0.0109, 'grad_norm': 5.05446195602417, 'learning_rate': 7.581395348837209e-06, 'loss_1': 0.00801155436784029, 'loss_2': 0.0029201507568359375, 'loss_3': -16.0747127532959, 'loss_4': 1.2572559118270874, 'epoch': 22.44}
[INFO|trainer.py:4228] 2025-01-21 13:55:31,313 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:31,313 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                       | 3865/5160 [1:35:35<22:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:38,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010557098314166069, 'eval_runtime': 3.8185, 'eval_samples_per_second': 268.168, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.006240441929548979, 'eval_loss_2': 0.004316657781600952, 'eval_loss_3': -18.146841049194336, 'eval_loss_4': 1.0956107378005981, 'epoch': 22.44}
{'loss': 0.0084, 'grad_norm': 4.485367774963379, 'learning_rate': 7.575581395348838e-06, 'loss_1': 0.0037644500844180584, 'loss_2': 0.004608154296875, 'loss_3': -16.354778289794922, 'loss_4': 1.1644049882888794, 'epoch': 22.45}
{'loss': 0.0132, 'grad_norm': 11.470305442810059, 'learning_rate': 7.569767441860465e-06, 'loss_1': 0.012215115129947662, 'loss_2': 0.0009784698486328125, 'loss_3': -16.239269256591797, 'loss_4': 1.5321810245513916, 'epoch': 22.45}
{'loss': 0.0079, 'grad_norm': 4.889877796173096, 'learning_rate': 7.563953488372094e-06, 'loss_1': 0.005541069433093071, 'loss_2': 0.00235748291015625, 'loss_3': -16.355436325073242, 'loss_4': 1.4358208179473877, 'epoch': 22.46}
{'loss': 0.0132, 'grad_norm': 5.148366451263428, 'learning_rate': 7.5581395348837215e-06, 'loss_1': 0.0070836544036865234, 'loss_2': 0.00608062744140625, 'loss_3': -16.338016510009766, 'loss_4': 1.0937786102294922, 'epoch': 22.47}
{'loss': 0.0237, 'grad_norm': 6.6417083740234375, 'learning_rate': 7.5523255813953484e-06, 'loss_1': 0.013520040549337864, 'loss_2': 0.01013946533203125, 'loss_3': -16.138490676879883, 'loss_4': 0.8330389857292175, 'epoch': 22.47}
[INFO|trainer.py:4228] 2025-01-21 13:55:38,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:38,687 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                      | 3870/5160 [1:35:43<22:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:46,061 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01076771505177021, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.256, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.0068187834694981575, 'eval_loss_2': 0.003948930650949478, 'eval_loss_3': -18.13770294189453, 'eval_loss_4': 1.0962707996368408, 'epoch': 22.47}
{'loss': 0.0054, 'grad_norm': 5.9309983253479, 'learning_rate': 7.546511627906977e-06, 'loss_1': 0.004871814511716366, 'loss_2': 0.0005664825439453125, 'loss_3': -16.433929443359375, 'loss_4': 1.185457706451416, 'epoch': 22.48}
{'loss': 0.0101, 'grad_norm': 4.642965316772461, 'learning_rate': 7.540697674418605e-06, 'loss_1': 0.002664610743522644, 'loss_2': 0.007396697998046875, 'loss_3': -16.35092544555664, 'loss_4': 1.2412595748901367, 'epoch': 22.48}
{'loss': 0.0075, 'grad_norm': 5.239597320556641, 'learning_rate': 7.5348837209302335e-06, 'loss_1': 0.006161577068269253, 'loss_2': 0.0013780593872070312, 'loss_3': -16.19982147216797, 'loss_4': 1.4180467128753662, 'epoch': 22.49}
{'loss': 0.0077, 'grad_norm': 4.2717061042785645, 'learning_rate': 7.52906976744186e-06, 'loss_1': 0.002831169171258807, 'loss_2': 0.00482940673828125, 'loss_3': -16.307109832763672, 'loss_4': 1.0277787446975708, 'epoch': 22.49}
{'loss': 0.0077, 'grad_norm': 4.552177429199219, 'learning_rate': 7.523255813953488e-06, 'loss_1': 0.004031960386782885, 'loss_2': 0.0036907196044921875, 'loss_3': -16.46566390991211, 'loss_4': 1.7480652332305908, 'epoch': 22.5}
[INFO|trainer.py:4228] 2025-01-21 13:55:46,061 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:46,061 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                      | 3875/5160 [1:35:50<22:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:55:53,445 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010752825066447258, 'eval_runtime': 3.8279, 'eval_samples_per_second': 267.512, 'eval_steps_per_second': 4.18, 'eval_loss_1': 0.00710391765460372, 'eval_loss_2': 0.003648906946182251, 'eval_loss_3': -18.120830535888672, 'eval_loss_4': 1.1609395742416382, 'epoch': 22.5}
{'loss': 0.0088, 'grad_norm': 5.272637367248535, 'learning_rate': 7.517441860465117e-06, 'loss_1': 0.00629026722162962, 'loss_2': 0.00249481201171875, 'loss_3': -16.196508407592773, 'loss_4': 1.136233925819397, 'epoch': 22.51}
{'loss': 0.0084, 'grad_norm': 5.070675373077393, 'learning_rate': 7.511627906976744e-06, 'loss_1': 0.006548240780830383, 'loss_2': 0.0018453598022460938, 'loss_3': -16.209863662719727, 'loss_4': 1.6304879188537598, 'epoch': 22.51}
{'loss': 0.0206, 'grad_norm': 13.074540138244629, 'learning_rate': 7.505813953488373e-06, 'loss_1': 0.02022736147046089, 'loss_2': 0.00041484832763671875, 'loss_3': -16.536840438842773, 'loss_4': 1.6612863540649414, 'epoch': 22.52}
{'loss': 0.0602, 'grad_norm': 34.216827392578125, 'learning_rate': 7.5e-06, 'loss_1': 0.059093959629535675, 'loss_2': 0.0011272430419921875, 'loss_3': -16.321666717529297, 'loss_4': 1.7323307991027832, 'epoch': 22.52}
{'loss': 0.0082, 'grad_norm': 5.4762349128723145, 'learning_rate': 7.494186046511628e-06, 'loss_1': 0.005757027771323919, 'loss_2': 0.0024585723876953125, 'loss_3': -16.05099868774414, 'loss_4': 1.4166574478149414, 'epoch': 22.53}
[INFO|trainer.py:4228] 2025-01-21 13:55:53,445 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:55:53,445 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 3880/5160 [1:35:57<22:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:00,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010174933820962906, 'eval_runtime': 3.8203, 'eval_samples_per_second': 268.043, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007555964402854443, 'eval_loss_2': 0.0026189684867858887, 'eval_loss_3': -18.121463775634766, 'eval_loss_4': 1.2010916471481323, 'epoch': 22.53}
{'loss': 0.0062, 'grad_norm': 4.518294334411621, 'learning_rate': 7.488372093023257e-06, 'loss_1': 0.004702359903603792, 'loss_2': 0.00150299072265625, 'loss_3': -16.47887420654297, 'loss_4': 1.0866602659225464, 'epoch': 22.53}
{'loss': 0.0115, 'grad_norm': 5.988893985748291, 'learning_rate': 7.4825581395348835e-06, 'loss_1': 0.008174114860594273, 'loss_2': 0.003299713134765625, 'loss_3': -16.412973403930664, 'loss_4': 1.0874457359313965, 'epoch': 22.54}
{'loss': 0.0151, 'grad_norm': 12.641393661499023, 'learning_rate': 7.476744186046511e-06, 'loss_1': 0.01420140266418457, 'loss_2': 0.000919342041015625, 'loss_3': -16.37396240234375, 'loss_4': 1.6198676824569702, 'epoch': 22.55}
{'loss': 0.0054, 'grad_norm': 4.780635833740234, 'learning_rate': 7.47093023255814e-06, 'loss_1': 0.0039051545318216085, 'loss_2': 0.0015430450439453125, 'loss_3': -16.427139282226562, 'loss_4': 1.4205682277679443, 'epoch': 22.55}
{'loss': 0.0077, 'grad_norm': 4.426208019256592, 'learning_rate': 7.465116279069768e-06, 'loss_1': 0.004288504831492901, 'loss_2': 0.003452301025390625, 'loss_3': -16.529869079589844, 'loss_4': 1.0911139249801636, 'epoch': 22.56}
[INFO|trainer.py:4228] 2025-01-21 13:56:00,825 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:00,825 >>   Batch size = 64
 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                      | 3885/5160 [1:36:05<22:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:08,195 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011080941185355186, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.44, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.008558300323784351, 'eval_loss_2': 0.0025226399302482605, 'eval_loss_3': -18.12540626525879, 'eval_loss_4': 1.1884346008300781, 'epoch': 22.56}
{'loss': 0.0032, 'grad_norm': 4.31812047958374, 'learning_rate': 7.4593023255813955e-06, 'loss_1': 0.0028858548030257225, 'loss_2': 0.0002808570861816406, 'loss_3': -16.445270538330078, 'loss_4': 1.5488317012786865, 'epoch': 22.56}
{'loss': 0.0075, 'grad_norm': 4.476612567901611, 'learning_rate': 7.453488372093023e-06, 'loss_1': 0.005516655743122101, 'loss_2': 0.0019683837890625, 'loss_3': -16.462900161743164, 'loss_4': 1.3901355266571045, 'epoch': 22.57}
{'loss': 0.0164, 'grad_norm': 9.068522453308105, 'learning_rate': 7.447674418604651e-06, 'loss_1': 0.01083199493587017, 'loss_2': 0.00556182861328125, 'loss_3': -16.27252960205078, 'loss_4': 1.6349308490753174, 'epoch': 22.58}
{'loss': 0.0095, 'grad_norm': 4.933908939361572, 'learning_rate': 7.441860465116279e-06, 'loss_1': 0.0029953517951071262, 'loss_2': 0.00653839111328125, 'loss_3': -16.53394317626953, 'loss_4': 1.2297947406768799, 'epoch': 22.58}
{'loss': 0.0088, 'grad_norm': 4.620338439941406, 'learning_rate': 7.4360465116279075e-06, 'loss_1': 0.0034846910275518894, 'loss_2': 0.00527191162109375, 'loss_3': -16.40365982055664, 'loss_4': 1.4050300121307373, 'epoch': 22.59}
[INFO|trainer.py:4228] 2025-01-21 13:56:08,195 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:08,195 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 3890/5160 [1:36:12<22:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:15,562 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011530781164765358, 'eval_runtime': 3.8067, 'eval_samples_per_second': 268.997, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00931609608232975, 'eval_loss_2': 0.002214685082435608, 'eval_loss_3': -18.136049270629883, 'eval_loss_4': 1.2256505489349365, 'epoch': 22.59}
{'loss': 0.008, 'grad_norm': 7.291977405548096, 'learning_rate': 7.430232558139535e-06, 'loss_1': 0.00778746185824275, 'loss_2': 0.00019431114196777344, 'loss_3': -16.346555709838867, 'loss_4': 1.7547178268432617, 'epoch': 22.59}
{'loss': 0.0131, 'grad_norm': 6.560149192810059, 'learning_rate': 7.424418604651163e-06, 'loss_1': 0.008225052617490292, 'loss_2': 0.004856109619140625, 'loss_3': -16.355850219726562, 'loss_4': 1.3557002544403076, 'epoch': 22.6}
{'loss': 0.0122, 'grad_norm': 4.924276351928711, 'learning_rate': 7.418604651162791e-06, 'loss_1': 0.0041100988164544106, 'loss_2': 0.008056640625, 'loss_3': -16.29281997680664, 'loss_4': 1.4086127281188965, 'epoch': 22.6}
{'loss': 0.0064, 'grad_norm': 4.919966220855713, 'learning_rate': 7.412790697674419e-06, 'loss_1': 0.0027417470701038837, 'loss_2': 0.0036773681640625, 'loss_3': -16.556522369384766, 'loss_4': 1.192518711090088, 'epoch': 22.61}
{'loss': 0.0099, 'grad_norm': 5.953981399536133, 'learning_rate': 7.4069767441860464e-06, 'loss_1': 0.007937788031995296, 'loss_2': 0.001979827880859375, 'loss_3': -16.44831657409668, 'loss_4': 1.304731845855713, 'epoch': 22.62}
[INFO|trainer.py:4228] 2025-01-21 13:56:15,562 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:15,562 >>   Batch size = 64
 75%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                     | 3895/5160 [1:36:20<21:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:22,937 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01109902374446392, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.606, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008893114514648914, 'eval_loss_2': 0.0022059082984924316, 'eval_loss_3': -18.14282989501953, 'eval_loss_4': 1.2927308082580566, 'epoch': 22.62}
{'loss': 0.0085, 'grad_norm': 6.54260778427124, 'learning_rate': 7.401162790697675e-06, 'loss_1': 0.0075845904648303986, 'loss_2': 0.0009593963623046875, 'loss_3': -16.489925384521484, 'loss_4': 1.0362563133239746, 'epoch': 22.62}
{'loss': 0.0101, 'grad_norm': 6.598952293395996, 'learning_rate': 7.395348837209303e-06, 'loss_1': 0.008207308128476143, 'loss_2': 0.0018796920776367188, 'loss_3': -16.241296768188477, 'loss_4': 2.1199474334716797, 'epoch': 22.63}
{'loss': 0.0079, 'grad_norm': 5.813675403594971, 'learning_rate': 7.38953488372093e-06, 'loss_1': 0.0058779604732990265, 'loss_2': 0.00197601318359375, 'loss_3': -16.54363250732422, 'loss_4': 1.202415108680725, 'epoch': 22.63}
{'loss': 0.0098, 'grad_norm': 4.488132476806641, 'learning_rate': 7.3837209302325584e-06, 'loss_1': 0.0076981717720627785, 'loss_2': 0.0020923614501953125, 'loss_3': -16.199520111083984, 'loss_4': 1.2155402898788452, 'epoch': 22.64}
{'loss': 0.007, 'grad_norm': 4.499087333679199, 'learning_rate': 7.377906976744186e-06, 'loss_1': 0.003635561093688011, 'loss_2': 0.0034008026123046875, 'loss_3': -16.386537551879883, 'loss_4': 1.4918415546417236, 'epoch': 22.65}
[INFO|trainer.py:4228] 2025-01-21 13:56:22,937 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:22,938 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                     | 3900/5160 [1:36:27<21:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:30,324 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010996416211128235, 'eval_runtime': 3.8246, 'eval_samples_per_second': 267.737, 'eval_steps_per_second': 4.183, 'eval_loss_1': 0.00902104377746582, 'eval_loss_2': 0.0019753724336624146, 'eval_loss_3': -18.14741325378418, 'eval_loss_4': 1.2995178699493408, 'epoch': 22.65}
{'loss': 0.0089, 'grad_norm': 7.180924415588379, 'learning_rate': 7.372093023255814e-06, 'loss_1': 0.006985669955611229, 'loss_2': 0.0018825531005859375, 'loss_3': -16.48184585571289, 'loss_4': 1.335815668106079, 'epoch': 22.65}
{'loss': 0.0156, 'grad_norm': 8.413040161132812, 'learning_rate': 7.366279069767443e-06, 'loss_1': 0.008598356507718563, 'loss_2': 0.007015228271484375, 'loss_3': -16.23566246032715, 'loss_4': 1.1464565992355347, 'epoch': 22.66}
{'loss': 0.0132, 'grad_norm': 11.691890716552734, 'learning_rate': 7.36046511627907e-06, 'loss_1': 0.01209142617881298, 'loss_2': 0.001102447509765625, 'loss_3': -16.392414093017578, 'loss_4': 1.479182481765747, 'epoch': 22.66}
{'loss': 0.0088, 'grad_norm': 5.015458583831787, 'learning_rate': 7.354651162790697e-06, 'loss_1': 0.0060015530325472355, 'loss_2': 0.0028247833251953125, 'loss_3': -16.454362869262695, 'loss_4': 1.0938072204589844, 'epoch': 22.67}
{'loss': 0.0106, 'grad_norm': 4.279758453369141, 'learning_rate': 7.348837209302326e-06, 'loss_1': 0.005194991827011108, 'loss_2': 0.0053863525390625, 'loss_3': -16.321205139160156, 'loss_4': 1.4559259414672852, 'epoch': 22.67}
[INFO|trainer.py:4228] 2025-01-21 13:56:30,324 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:30,324 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                     | 3905/5160 [1:36:34<21:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:37,691 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010043920949101448, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.285, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008058824576437473, 'eval_loss_2': 0.0019850954413414, 'eval_loss_3': -18.13876724243164, 'eval_loss_4': 1.2689757347106934, 'epoch': 22.67}
{'loss': 0.0044, 'grad_norm': 4.674709320068359, 'learning_rate': 7.343023255813954e-06, 'loss_1': 0.003905744757503271, 'loss_2': 0.000499725341796875, 'loss_3': -16.491947174072266, 'loss_4': 2.0001749992370605, 'epoch': 22.68}
{'loss': 0.0561, 'grad_norm': 16.409229278564453, 'learning_rate': 7.3372093023255816e-06, 'loss_1': 0.05081894248723984, 'loss_2': 0.005252838134765625, 'loss_3': -16.338096618652344, 'loss_4': 1.5954430103302002, 'epoch': 22.69}
{'loss': 0.0109, 'grad_norm': 5.663246154785156, 'learning_rate': 7.33139534883721e-06, 'loss_1': 0.008446043357253075, 'loss_2': 0.00246429443359375, 'loss_3': -16.564001083374023, 'loss_4': 1.6239244937896729, 'epoch': 22.69}
{'loss': 0.0161, 'grad_norm': 10.559800148010254, 'learning_rate': 7.325581395348837e-06, 'loss_1': 0.014669985510408878, 'loss_2': 0.0013990402221679688, 'loss_3': -16.441726684570312, 'loss_4': 1.445488452911377, 'epoch': 22.7}
{'loss': 0.0134, 'grad_norm': 4.156499862670898, 'learning_rate': 7.319767441860465e-06, 'loss_1': 0.0032567745074629784, 'loss_2': 0.0101318359375, 'loss_3': -16.46865463256836, 'loss_4': 1.3248867988586426, 'epoch': 22.7}
[INFO|trainer.py:4228] 2025-01-21 13:56:37,691 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:37,691 >>   Batch size = 64
 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                     | 3910/5160 [1:36:42<21:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:45,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011551011353731155, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.799, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008086848072707653, 'eval_loss_2': 0.0034641623497009277, 'eval_loss_3': -18.1436710357666, 'eval_loss_4': 1.2645223140716553, 'epoch': 22.7}
{'loss': 0.0127, 'grad_norm': 8.47461223602295, 'learning_rate': 7.3139534883720936e-06, 'loss_1': 0.009455571882426739, 'loss_2': 0.003284454345703125, 'loss_3': -16.331907272338867, 'loss_4': 1.4222699403762817, 'epoch': 22.71}
{'loss': 0.0053, 'grad_norm': 4.937009811401367, 'learning_rate': 7.308139534883721e-06, 'loss_1': 0.0021691550500690937, 'loss_2': 0.00313568115234375, 'loss_3': -16.466751098632812, 'loss_4': 2.056326389312744, 'epoch': 22.72}
{'loss': 0.0149, 'grad_norm': 4.278655052185059, 'learning_rate': 7.302325581395349e-06, 'loss_1': 0.003589858300983906, 'loss_2': 0.01128387451171875, 'loss_3': -16.73067855834961, 'loss_4': 1.4323668479919434, 'epoch': 22.72}
{'loss': 0.0115, 'grad_norm': 4.84030818939209, 'learning_rate': 7.296511627906977e-06, 'loss_1': 0.004616330377757549, 'loss_2': 0.0068511962890625, 'loss_3': -16.242740631103516, 'loss_4': 1.2776482105255127, 'epoch': 22.73}
{'loss': 0.0095, 'grad_norm': 6.581020355224609, 'learning_rate': 7.290697674418605e-06, 'loss_1': 0.009380710311233997, 'loss_2': 9.900331497192383e-05, 'loss_3': -16.6065616607666, 'loss_4': 1.727092981338501, 'epoch': 22.73}
[INFO|trainer.py:4228] 2025-01-21 13:56:45,055 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:45,055 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                    | 3915/5160 [1:36:49<21:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:52,423 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011068944819271564, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.389, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007927294820547104, 'eval_loss_2': 0.003141649067401886, 'eval_loss_3': -18.150936126708984, 'eval_loss_4': 1.2889646291732788, 'epoch': 22.73}
{'loss': 0.0344, 'grad_norm': 12.307110786437988, 'learning_rate': 7.2848837209302325e-06, 'loss_1': 0.029010094702243805, 'loss_2': 0.005390167236328125, 'loss_3': -16.424591064453125, 'loss_4': 1.893609642982483, 'epoch': 22.74}
{'loss': 0.0066, 'grad_norm': 5.298659801483154, 'learning_rate': 7.279069767441861e-06, 'loss_1': 0.005498272366821766, 'loss_2': 0.001140594482421875, 'loss_3': -16.502626419067383, 'loss_4': 1.6008068323135376, 'epoch': 22.74}
{'loss': 0.0178, 'grad_norm': 6.631582736968994, 'learning_rate': 7.273255813953489e-06, 'loss_1': 0.015825124457478523, 'loss_2': 0.001926422119140625, 'loss_3': -16.310693740844727, 'loss_4': 1.2721760272979736, 'epoch': 22.75}
{'loss': 0.0053, 'grad_norm': 4.388458251953125, 'learning_rate': 7.267441860465116e-06, 'loss_1': 0.002900956431403756, 'loss_2': 0.002391815185546875, 'loss_3': -16.427661895751953, 'loss_4': 1.3910775184631348, 'epoch': 22.76}
{'loss': 0.0156, 'grad_norm': 7.689040660858154, 'learning_rate': 7.2616279069767445e-06, 'loss_1': 0.009512069635093212, 'loss_2': 0.00608062744140625, 'loss_3': -16.542251586914062, 'loss_4': 1.753324031829834, 'epoch': 22.76}
[INFO|trainer.py:4228] 2025-01-21 13:56:52,423 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:52,423 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                    | 3920/5160 [1:36:56<21:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:56:59,801 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011475540697574615, 'eval_runtime': 3.8211, 'eval_samples_per_second': 267.987, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.00790622178465128, 'eval_loss_2': 0.0035693198442459106, 'eval_loss_3': -18.16851806640625, 'eval_loss_4': 1.2936843633651733, 'epoch': 22.76}
{'loss': 0.0149, 'grad_norm': 7.247861862182617, 'learning_rate': 7.255813953488372e-06, 'loss_1': 0.011691701598465443, 'loss_2': 0.0031986236572265625, 'loss_3': -16.481019973754883, 'loss_4': 1.6290452480316162, 'epoch': 22.77}
{'loss': 0.009, 'grad_norm': 5.3977203369140625, 'learning_rate': 7.25e-06, 'loss_1': 0.006399935577064753, 'loss_2': 0.002567291259765625, 'loss_3': -16.492549896240234, 'loss_4': 1.6857798099517822, 'epoch': 22.77}
{'loss': 0.0038, 'grad_norm': 4.687528133392334, 'learning_rate': 7.244186046511629e-06, 'loss_1': 0.0036331070587038994, 'loss_2': 0.00017905235290527344, 'loss_3': -16.461666107177734, 'loss_4': 1.3443142175674438, 'epoch': 22.78}
{'loss': 0.0128, 'grad_norm': 6.184688091278076, 'learning_rate': 7.2383720930232565e-06, 'loss_1': 0.0058307889848947525, 'loss_2': 0.00698089599609375, 'loss_3': -16.45632553100586, 'loss_4': 1.6884114742279053, 'epoch': 22.78}
{'loss': 0.0069, 'grad_norm': 4.844753742218018, 'learning_rate': 7.232558139534883e-06, 'loss_1': 0.0038734988775104284, 'loss_2': 0.00301361083984375, 'loss_3': -16.401086807250977, 'loss_4': 1.3516275882720947, 'epoch': 22.79}
[INFO|trainer.py:4228] 2025-01-21 13:56:59,802 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:56:59,802 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 3925/5160 [1:37:04<21:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:07,173 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01074671745300293, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.68, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007818474434316158, 'eval_loss_2': 0.0029282420873641968, 'eval_loss_3': -18.180644989013672, 'eval_loss_4': 1.2703309059143066, 'epoch': 22.79}
{'loss': 0.0128, 'grad_norm': 8.819254875183105, 'learning_rate': 7.226744186046512e-06, 'loss_1': 0.012650552205741405, 'loss_2': 0.0001659393310546875, 'loss_3': -16.290637969970703, 'loss_4': 1.865666389465332, 'epoch': 22.8}
{'loss': 0.0085, 'grad_norm': 5.931085586547852, 'learning_rate': 7.22093023255814e-06, 'loss_1': 0.006699980702251196, 'loss_2': 0.0018177032470703125, 'loss_3': -16.42905044555664, 'loss_4': 1.3359973430633545, 'epoch': 22.8}
{'loss': 0.0047, 'grad_norm': 4.528450965881348, 'learning_rate': 7.215116279069768e-06, 'loss_1': 0.004032724071294069, 'loss_2': 0.0007138252258300781, 'loss_3': -16.44498062133789, 'loss_4': 1.2634108066558838, 'epoch': 22.81}
{'loss': 0.0052, 'grad_norm': 4.6688337326049805, 'learning_rate': 7.209302325581396e-06, 'loss_1': 0.0033441977575421333, 'loss_2': 0.0018262863159179688, 'loss_3': -16.42684555053711, 'loss_4': 1.1409310102462769, 'epoch': 22.81}
{'loss': 0.0087, 'grad_norm': 9.403839111328125, 'learning_rate': 7.203488372093023e-06, 'loss_1': 0.007335671689361334, 'loss_2': 0.0013895034790039062, 'loss_3': -16.47515296936035, 'loss_4': 1.5413398742675781, 'epoch': 22.82}
[INFO|trainer.py:4228] 2025-01-21 13:57:07,173 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:07,173 >>   Batch size = 64
 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                    | 3930/5160 [1:37:11<21:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:14,553 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011230852454900742, 'eval_runtime': 3.8209, 'eval_samples_per_second': 267.999, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.008054952137172222, 'eval_loss_2': 0.003175899386405945, 'eval_loss_3': -18.1749267578125, 'eval_loss_4': 1.271100640296936, 'epoch': 22.82}
{'loss': 0.0088, 'grad_norm': 4.791211128234863, 'learning_rate': 7.197674418604651e-06, 'loss_1': 0.0034418718423694372, 'loss_2': 0.0053253173828125, 'loss_3': -16.44610023498535, 'loss_4': 1.6757540702819824, 'epoch': 22.83}
{'loss': 0.0087, 'grad_norm': 5.182166576385498, 'learning_rate': 7.19186046511628e-06, 'loss_1': 0.004113759379833937, 'loss_2': 0.004558563232421875, 'loss_3': -16.548606872558594, 'loss_4': 1.4626749753952026, 'epoch': 22.83}
{'loss': 0.0139, 'grad_norm': 8.161153793334961, 'learning_rate': 7.186046511627907e-06, 'loss_1': 0.012139318510890007, 'loss_2': 0.001800537109375, 'loss_3': -16.405540466308594, 'loss_4': 1.1539517641067505, 'epoch': 22.84}
{'loss': 0.0064, 'grad_norm': 4.766090393066406, 'learning_rate': 7.180232558139535e-06, 'loss_1': 0.003281280165538192, 'loss_2': 0.003070831298828125, 'loss_3': -16.395235061645508, 'loss_4': 1.6522098779678345, 'epoch': 22.84}
{'loss': 0.006, 'grad_norm': 4.57913064956665, 'learning_rate': 7.174418604651163e-06, 'loss_1': 0.002524068346247077, 'loss_2': 0.0034770965576171875, 'loss_3': -16.27593994140625, 'loss_4': 1.6804077625274658, 'epoch': 22.85}
[INFO|trainer.py:4228] 2025-01-21 13:57:14,553 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:14,553 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 3935/5160 [1:37:19<21:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:21,917 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011011777445673943, 'eval_runtime': 3.8126, 'eval_samples_per_second': 268.581, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007762324530631304, 'eval_loss_2': 0.003249451518058777, 'eval_loss_3': -18.165225982666016, 'eval_loss_4': 1.3188146352767944, 'epoch': 22.85}
{'loss': 0.0075, 'grad_norm': 4.859080791473389, 'learning_rate': 7.168604651162791e-06, 'loss_1': 0.0035902741365134716, 'loss_2': 0.003936767578125, 'loss_3': -16.635005950927734, 'loss_4': 1.6120681762695312, 'epoch': 22.85}
{'loss': 0.0071, 'grad_norm': 4.895906448364258, 'learning_rate': 7.1627906976744185e-06, 'loss_1': 0.0037433793768286705, 'loss_2': 0.003368377685546875, 'loss_3': -16.577707290649414, 'loss_4': 1.5162643194198608, 'epoch': 22.86}
{'loss': 0.0098, 'grad_norm': 4.977273464202881, 'learning_rate': 7.156976744186047e-06, 'loss_1': 0.008618040941655636, 'loss_2': 0.0011920928955078125, 'loss_3': -16.251646041870117, 'loss_4': 1.3641083240509033, 'epoch': 22.87}
{'loss': 0.0065, 'grad_norm': 5.508054733276367, 'learning_rate': 7.151162790697675e-06, 'loss_1': 0.006102481856942177, 'loss_2': 0.000354766845703125, 'loss_3': -16.489688873291016, 'loss_4': 1.640700340270996, 'epoch': 22.87}
{'loss': 0.0067, 'grad_norm': 5.141513347625732, 'learning_rate': 7.145348837209303e-06, 'loss_1': 0.005817829631268978, 'loss_2': 0.0009145736694335938, 'loss_3': -16.26995086669922, 'loss_4': 1.582353115081787, 'epoch': 22.88}
[INFO|trainer.py:4228] 2025-01-21 13:57:21,917 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:21,917 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                   | 3940/5160 [1:37:26<21:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:29,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010782748460769653, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.459, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.007119148503988981, 'eval_loss_2': 0.0036635994911193848, 'eval_loss_3': -18.165498733520508, 'eval_loss_4': 1.344836711883545, 'epoch': 22.88}
{'loss': 0.0043, 'grad_norm': 4.96648645401001, 'learning_rate': 7.1395348837209305e-06, 'loss_1': 0.0034297844395041466, 'loss_2': 0.0009126663208007812, 'loss_3': -16.508146286010742, 'loss_4': 1.6869359016418457, 'epoch': 22.88}
{'loss': 0.0187, 'grad_norm': 8.511940956115723, 'learning_rate': 7.133720930232558e-06, 'loss_1': 0.01674732193350792, 'loss_2': 0.001903533935546875, 'loss_3': -16.489574432373047, 'loss_4': 1.518254041671753, 'epoch': 22.89}
{'loss': 0.0075, 'grad_norm': 5.163041591644287, 'learning_rate': 7.127906976744186e-06, 'loss_1': 0.0037811778020113707, 'loss_2': 0.003696441650390625, 'loss_3': -16.502017974853516, 'loss_4': 1.6865519285202026, 'epoch': 22.9}
{'loss': 0.0097, 'grad_norm': 5.289702415466309, 'learning_rate': 7.122093023255815e-06, 'loss_1': 0.0047488827258348465, 'loss_2': 0.00492095947265625, 'loss_3': -16.339345932006836, 'loss_4': 1.6343317031860352, 'epoch': 22.9}
{'loss': 0.0054, 'grad_norm': 4.508358478546143, 'learning_rate': 7.1162790697674425e-06, 'loss_1': 0.0030836095102131367, 'loss_2': 0.002269744873046875, 'loss_3': -16.44041633605957, 'loss_4': 1.735388994216919, 'epoch': 22.91}
[INFO|trainer.py:4228] 2025-01-21 13:57:29,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:29,288 >>   Batch size = 64
 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 3945/5160 [1:37:33<21:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:36,649 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010012290440499783, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.721, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007975480519235134, 'eval_loss_2': 0.0020368099212646484, 'eval_loss_3': -18.170364379882812, 'eval_loss_4': 1.2813161611557007, 'epoch': 22.91}
{'loss': 0.0104, 'grad_norm': 8.433034896850586, 'learning_rate': 7.1104651162790694e-06, 'loss_1': 0.008998209610581398, 'loss_2': 0.0014190673828125, 'loss_3': -16.386281967163086, 'loss_4': 1.6186742782592773, 'epoch': 22.91}
{'loss': 0.0054, 'grad_norm': 4.519604682922363, 'learning_rate': 7.104651162790698e-06, 'loss_1': 0.00275561329908669, 'loss_2': 0.0026702880859375, 'loss_3': -16.281631469726562, 'loss_4': 1.8716565370559692, 'epoch': 22.92}
{'loss': 0.0073, 'grad_norm': 4.468725204467773, 'learning_rate': 7.098837209302326e-06, 'loss_1': 0.0023554957006126642, 'loss_2': 0.00493621826171875, 'loss_3': -16.469152450561523, 'loss_4': 1.5367932319641113, 'epoch': 22.92}
{'loss': 0.0151, 'grad_norm': 5.088868618011475, 'learning_rate': 7.093023255813954e-06, 'loss_1': 0.007362017408013344, 'loss_2': 0.007717132568359375, 'loss_3': -16.623905181884766, 'loss_4': 1.6382755041122437, 'epoch': 22.93}
{'loss': 0.0107, 'grad_norm': 4.555391788482666, 'learning_rate': 7.087209302325581e-06, 'loss_1': 0.005309083964675665, 'loss_2': 0.00534820556640625, 'loss_3': -16.49782943725586, 'loss_4': 1.2128055095672607, 'epoch': 22.94}
[INFO|trainer.py:4228] 2025-01-21 13:57:36,649 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:36,649 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                   | 3950/5160 [1:37:41<20:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:44,015 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009141325950622559, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.601, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.006997749675065279, 'eval_loss_2': 0.002143576741218567, 'eval_loss_3': -18.15840721130371, 'eval_loss_4': 1.207378625869751, 'epoch': 22.94}
{'loss': 0.0076, 'grad_norm': 7.5172905921936035, 'learning_rate': 7.081395348837209e-06, 'loss_1': 0.0075123924762010574, 'loss_2': 5.698204040527344e-05, 'loss_3': -16.289836883544922, 'loss_4': 1.4205443859100342, 'epoch': 22.94}
{'loss': 0.0072, 'grad_norm': 5.128811359405518, 'learning_rate': 7.075581395348837e-06, 'loss_1': 0.004606774542480707, 'loss_2': 0.00262451171875, 'loss_3': -16.44198989868164, 'loss_4': 0.9339640140533447, 'epoch': 22.95}
{'loss': 0.012, 'grad_norm': 5.025676250457764, 'learning_rate': 7.069767441860465e-06, 'loss_1': 0.006421292200684547, 'loss_2': 0.00556182861328125, 'loss_3': -16.520858764648438, 'loss_4': 1.273202896118164, 'epoch': 22.95}
{'loss': 0.0086, 'grad_norm': 4.789984226226807, 'learning_rate': 7.063953488372093e-06, 'loss_1': 0.00516635924577713, 'loss_2': 0.003459930419921875, 'loss_3': -16.622821807861328, 'loss_4': 1.1307673454284668, 'epoch': 22.96}
{'loss': 0.0071, 'grad_norm': 4.612933158874512, 'learning_rate': 7.058139534883721e-06, 'loss_1': 0.0024306790437549353, 'loss_2': 0.004657745361328125, 'loss_3': -16.33710479736328, 'loss_4': 1.0979273319244385, 'epoch': 22.97}
[INFO|trainer.py:4228] 2025-01-21 13:57:44,015 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:44,015 >>   Batch size = 64
 77%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                   | 3955/5160 [1:37:48<20:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:57:51,373 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010286003351211548, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.22, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.007687955163419247, 'eval_loss_2': 0.0025980472564697266, 'eval_loss_3': -18.156734466552734, 'eval_loss_4': 1.1262062788009644, 'epoch': 22.97}
{'loss': 0.0168, 'grad_norm': 5.111240386962891, 'learning_rate': 7.052325581395349e-06, 'loss_1': 0.005820264108479023, 'loss_2': 0.010955810546875, 'loss_3': -16.315832138061523, 'loss_4': 1.3370208740234375, 'epoch': 22.97}
{'loss': 0.008, 'grad_norm': 5.2456769943237305, 'learning_rate': 7.046511627906977e-06, 'loss_1': 0.0055305976420640945, 'loss_2': 0.002490997314453125, 'loss_3': -16.245288848876953, 'loss_4': 1.2119696140289307, 'epoch': 22.98}
{'loss': 0.0055, 'grad_norm': 4.847805023193359, 'learning_rate': 7.0406976744186046e-06, 'loss_1': 0.004452800378203392, 'loss_2': 0.00109100341796875, 'loss_3': -16.45855140686035, 'loss_4': 1.2537586688995361, 'epoch': 22.98}
{'loss': 0.0096, 'grad_norm': 4.932446479797363, 'learning_rate': 7.034883720930232e-06, 'loss_1': 0.006916172802448273, 'loss_2': 0.002719879150390625, 'loss_3': -16.45516014099121, 'loss_4': 1.3586180210113525, 'epoch': 22.99}
{'loss': 0.0092, 'grad_norm': 5.258358955383301, 'learning_rate': 7.029069767441861e-06, 'loss_1': 0.00665939599275589, 'loss_2': 0.002490997314453125, 'loss_3': -16.55203628540039, 'loss_4': 1.1771376132965088, 'epoch': 22.99}
[INFO|trainer.py:4228] 2025-01-21 13:57:51,373 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:51,373 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 3960/5160 [1:37:55<20:25,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 13:57:58,458 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010320949368178844, 'eval_runtime': 3.8211, 'eval_samples_per_second': 267.982, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.00760268047451973, 'eval_loss_2': 0.0027182698249816895, 'eval_loss_3': -18.150266647338867, 'eval_loss_4': 1.0331168174743652, 'epoch': 22.99}
{'loss': 0.0027, 'grad_norm': 6.733895301818848, 'learning_rate': 7.023255813953489e-06, 'loss_1': 0.000700280477758497, 'loss_2': 0.001983642578125, 'loss_3': -16.43157386779785, 'loss_4': 1.1502829790115356, 'epoch': 23.0}
{'loss': 0.0128, 'grad_norm': 6.769352436065674, 'learning_rate': 7.017441860465116e-06, 'loss_1': 0.011161292903125286, 'loss_2': 0.0016155242919921875, 'loss_3': -16.3452091217041, 'loss_4': 1.0782957077026367, 'epoch': 23.01}
{'loss': 0.0142, 'grad_norm': 6.113056182861328, 'learning_rate': 7.011627906976744e-06, 'loss_1': 0.010217183269560337, 'loss_2': 0.004009246826171875, 'loss_3': -16.412742614746094, 'loss_4': 1.2963929176330566, 'epoch': 23.01}
{'loss': 0.0118, 'grad_norm': 5.461563587188721, 'learning_rate': 7.005813953488372e-06, 'loss_1': 0.00560346245765686, 'loss_2': 0.00616455078125, 'loss_3': -16.3902530670166, 'loss_4': 1.1592559814453125, 'epoch': 23.02}
{'loss': 0.0068, 'grad_norm': 4.731729030609131, 'learning_rate': 7e-06, 'loss_1': 0.0035520996898412704, 'loss_2': 0.00323486328125, 'loss_3': -16.315698623657227, 'loss_4': 1.0945720672607422, 'epoch': 23.02}
[INFO|trainer.py:4228] 2025-01-21 13:57:58,458 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:57:58,459 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                  | 3965/5160 [1:38:02<20:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:05,818 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01086178608238697, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.055, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008276435546576977, 'eval_loss_2': 0.0025853514671325684, 'eval_loss_3': -18.148386001586914, 'eval_loss_4': 0.9387110471725464, 'epoch': 23.02}
{'loss': 0.0101, 'grad_norm': 5.285906791687012, 'learning_rate': 6.9941860465116285e-06, 'loss_1': 0.008785223588347435, 'loss_2': 0.0013637542724609375, 'loss_3': -16.431316375732422, 'loss_4': 0.8496806025505066, 'epoch': 23.03}
{'loss': 0.033, 'grad_norm': 11.012577056884766, 'learning_rate': 6.9883720930232555e-06, 'loss_1': 0.029057499021291733, 'loss_2': 0.003955841064453125, 'loss_3': -16.426406860351562, 'loss_4': 1.1421936750411987, 'epoch': 23.03}
{'loss': 0.0062, 'grad_norm': 6.026197910308838, 'learning_rate': 6.982558139534883e-06, 'loss_1': 0.006036962382495403, 'loss_2': 0.00014352798461914062, 'loss_3': -16.5010986328125, 'loss_4': 1.4112725257873535, 'epoch': 23.04}
{'loss': 0.0124, 'grad_norm': 5.564485549926758, 'learning_rate': 6.976744186046512e-06, 'loss_1': 0.0067913527600467205, 'loss_2': 0.0055999755859375, 'loss_3': -16.399381637573242, 'loss_4': 1.2653601169586182, 'epoch': 23.05}
{'loss': 0.0111, 'grad_norm': 5.230860710144043, 'learning_rate': 6.97093023255814e-06, 'loss_1': 0.00585987139493227, 'loss_2': 0.0052642822265625, 'loss_3': -16.263671875, 'loss_4': 1.5852688550949097, 'epoch': 23.05}
[INFO|trainer.py:4228] 2025-01-21 13:58:05,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:05,818 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                  | 3970/5160 [1:38:10<20:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:13,180 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0109307412058115, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.027, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.008742998354136944, 'eval_loss_2': 0.0021877437829971313, 'eval_loss_3': -18.14081573486328, 'eval_loss_4': 0.9353393316268921, 'epoch': 23.05}
{'loss': 0.0102, 'grad_norm': 4.609749794006348, 'learning_rate': 6.9651162790697675e-06, 'loss_1': 0.00400485610589385, 'loss_2': 0.0062103271484375, 'loss_3': -16.39373207092285, 'loss_4': 0.8362354636192322, 'epoch': 23.06}
{'loss': 0.0056, 'grad_norm': 4.751403331756592, 'learning_rate': 6.959302325581396e-06, 'loss_1': 0.0022054032888263464, 'loss_2': 0.003387451171875, 'loss_3': -16.263351440429688, 'loss_4': 1.089339256286621, 'epoch': 23.06}
{'loss': 0.0046, 'grad_norm': 5.4485883712768555, 'learning_rate': 6.953488372093023e-06, 'loss_1': 0.004233092535287142, 'loss_2': 0.0003342628479003906, 'loss_3': -16.462657928466797, 'loss_4': 1.0686112642288208, 'epoch': 23.07}
{'loss': 0.0128, 'grad_norm': 6.616307258605957, 'learning_rate': 6.947674418604651e-06, 'loss_1': 0.011476141400635242, 'loss_2': 0.0013580322265625, 'loss_3': -16.573463439941406, 'loss_4': 1.3572242259979248, 'epoch': 23.08}
{'loss': 0.0133, 'grad_norm': 4.25047492980957, 'learning_rate': 6.9418604651162794e-06, 'loss_1': 0.0030145393684506416, 'loss_2': 0.010284423828125, 'loss_3': -16.50368309020996, 'loss_4': 1.2767224311828613, 'epoch': 23.08}
[INFO|trainer.py:4228] 2025-01-21 13:58:13,180 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:13,180 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 3975/5160 [1:38:17<20:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:20,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011128135956823826, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.8, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.008775063790380955, 'eval_loss_2': 0.002353072166442871, 'eval_loss_3': -18.131961822509766, 'eval_loss_4': 0.9645244479179382, 'epoch': 23.08}
{'loss': 0.0038, 'grad_norm': 5.137548923492432, 'learning_rate': 6.936046511627907e-06, 'loss_1': 0.0018631578423082829, 'loss_2': 0.00189208984375, 'loss_3': -16.512813568115234, 'loss_4': 0.7870521545410156, 'epoch': 23.09}
{'loss': 0.0141, 'grad_norm': 5.581579208374023, 'learning_rate': 6.930232558139535e-06, 'loss_1': 0.007146110758185387, 'loss_2': 0.006992340087890625, 'loss_3': -16.2358341217041, 'loss_4': 0.6771390438079834, 'epoch': 23.09}
{'loss': 0.011, 'grad_norm': 6.940276145935059, 'learning_rate': 6.924418604651163e-06, 'loss_1': 0.010339380241930485, 'loss_2': 0.0006694793701171875, 'loss_3': -16.534990310668945, 'loss_4': 1.2539477348327637, 'epoch': 23.1}
{'loss': 0.0154, 'grad_norm': 5.096317291259766, 'learning_rate': 6.918604651162791e-06, 'loss_1': 0.007230219431221485, 'loss_2': 0.008148193359375, 'loss_3': -16.403127670288086, 'loss_4': 0.9537703394889832, 'epoch': 23.1}
{'loss': 0.0071, 'grad_norm': 5.618259906768799, 'learning_rate': 6.912790697674418e-06, 'loss_1': 0.006097374949604273, 'loss_2': 0.0009760856628417969, 'loss_3': -16.242889404296875, 'loss_4': 0.8595767021179199, 'epoch': 23.11}
[INFO|trainer.py:4228] 2025-01-21 13:58:20,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:20,548 >>   Batch size = 64
 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                  | 3980/5160 [1:38:25<20:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:27,906 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011254072189331055, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.988, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.008696850389242172, 'eval_loss_2': 0.0025572218000888824, 'eval_loss_3': -18.11383819580078, 'eval_loss_4': 0.9776403903961182, 'epoch': 23.11}
{'loss': 0.0153, 'grad_norm': 6.990411758422852, 'learning_rate': 6.906976744186047e-06, 'loss_1': 0.012788497842848301, 'loss_2': 0.00255584716796875, 'loss_3': -16.176734924316406, 'loss_4': 0.9905917644500732, 'epoch': 23.12}
{'loss': 0.0066, 'grad_norm': 4.869513034820557, 'learning_rate': 6.901162790697675e-06, 'loss_1': 0.002755269641056657, 'loss_2': 0.003849029541015625, 'loss_3': -16.449859619140625, 'loss_4': 0.9665306806564331, 'epoch': 23.12}
{'loss': 0.0044, 'grad_norm': 4.297056674957275, 'learning_rate': 6.895348837209302e-06, 'loss_1': 0.0014487773878499866, 'loss_2': 0.0029659271240234375, 'loss_3': -16.64018440246582, 'loss_4': 0.93430495262146, 'epoch': 23.13}
{'loss': 0.0079, 'grad_norm': 5.614272594451904, 'learning_rate': 6.88953488372093e-06, 'loss_1': 0.007519091013818979, 'loss_2': 0.00033736228942871094, 'loss_3': -16.57467269897461, 'loss_4': 1.2965205907821655, 'epoch': 23.13}
{'loss': 0.0647, 'grad_norm': 17.941980361938477, 'learning_rate': 6.883720930232558e-06, 'loss_1': 0.05964590609073639, 'loss_2': 0.00502777099609375, 'loss_3': -16.36554718017578, 'loss_4': 1.120896577835083, 'epoch': 23.14}
[INFO|trainer.py:4228] 2025-01-21 13:58:27,906 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:27,906 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 3985/5160 [1:38:32<20:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:35,273 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011009739711880684, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.636, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.008381347171962261, 'eval_loss_2': 0.0026283934712409973, 'eval_loss_3': -18.123632431030273, 'eval_loss_4': 0.9730737209320068, 'epoch': 23.14}
{'loss': 0.0169, 'grad_norm': 8.924395561218262, 'learning_rate': 6.877906976744186e-06, 'loss_1': 0.014974875375628471, 'loss_2': 0.0019311904907226562, 'loss_3': -16.41388702392578, 'loss_4': 1.162459135055542, 'epoch': 23.15}
{'loss': 0.0142, 'grad_norm': 12.909671783447266, 'learning_rate': 6.8720930232558146e-06, 'loss_1': 0.011520822532474995, 'loss_2': 0.0027008056640625, 'loss_3': -16.47998809814453, 'loss_4': 0.6800729632377625, 'epoch': 23.15}
{'loss': 0.0123, 'grad_norm': 6.377959251403809, 'learning_rate': 6.866279069767442e-06, 'loss_1': 0.008742614649236202, 'loss_2': 0.0035190582275390625, 'loss_3': -16.507171630859375, 'loss_4': 1.2784982919692993, 'epoch': 23.16}
{'loss': 0.0084, 'grad_norm': 6.815186500549316, 'learning_rate': 6.860465116279069e-06, 'loss_1': 0.008374354802072048, 'loss_2': 2.9861927032470703e-05, 'loss_3': -16.63080596923828, 'loss_4': 1.1722276210784912, 'epoch': 23.16}
{'loss': 0.0101, 'grad_norm': 5.208820343017578, 'learning_rate': 6.854651162790698e-06, 'loss_1': 0.006971411872655153, 'loss_2': 0.003086090087890625, 'loss_3': -16.438390731811523, 'loss_4': 1.3270254135131836, 'epoch': 23.17}
[INFO|trainer.py:4228] 2025-01-21 13:58:35,273 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:35,273 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                 | 3990/5160 [1:38:39<20:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:42,631 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010234272107481956, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.976, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.007716437801718712, 'eval_loss_2': 0.0025178343057632446, 'eval_loss_3': -18.142391204833984, 'eval_loss_4': 0.9642461538314819, 'epoch': 23.17}
{'loss': 0.012, 'grad_norm': 6.115411758422852, 'learning_rate': 6.848837209302326e-06, 'loss_1': 0.00932551734149456, 'loss_2': 0.0026264190673828125, 'loss_3': -16.374292373657227, 'loss_4': 0.8416733741760254, 'epoch': 23.17}
{'loss': 0.0098, 'grad_norm': 5.643137454986572, 'learning_rate': 6.8430232558139535e-06, 'loss_1': 0.007320990785956383, 'loss_2': 0.0025177001953125, 'loss_3': -16.35284423828125, 'loss_4': 1.5329750776290894, 'epoch': 23.18}
{'loss': 0.0093, 'grad_norm': 4.702985763549805, 'learning_rate': 6.837209302325582e-06, 'loss_1': 0.003607437014579773, 'loss_2': 0.0056915283203125, 'loss_3': -16.626075744628906, 'loss_4': 0.6947404146194458, 'epoch': 23.19}
{'loss': 0.0126, 'grad_norm': 9.354475021362305, 'learning_rate': 6.831395348837209e-06, 'loss_1': 0.012578325346112251, 'loss_2': 6.818771362304688e-05, 'loss_3': -16.539613723754883, 'loss_4': 1.0845293998718262, 'epoch': 23.19}
{'loss': 0.0031, 'grad_norm': 4.424595355987549, 'learning_rate': 6.825581395348837e-06, 'loss_1': 0.0027525550685822964, 'loss_2': 0.0003871917724609375, 'loss_3': -16.510704040527344, 'loss_4': 1.2438949346542358, 'epoch': 23.2}
[INFO|trainer.py:4228] 2025-01-21 13:58:42,631 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:42,631 >>   Batch size = 64
 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                 | 3995/5160 [1:38:47<20:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:50,003 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009338128380477428, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.535, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006955849938094616, 'eval_loss_2': 0.0023822784423828125, 'eval_loss_3': -18.14931869506836, 'eval_loss_4': 0.9705914855003357, 'epoch': 23.2}
{'loss': 0.0049, 'grad_norm': 5.411045074462891, 'learning_rate': 6.8197674418604655e-06, 'loss_1': 0.004531556740403175, 'loss_2': 0.0003914833068847656, 'loss_3': -16.573514938354492, 'loss_4': 1.181337833404541, 'epoch': 23.2}
{'loss': 0.0088, 'grad_norm': 4.932343482971191, 'learning_rate': 6.813953488372093e-06, 'loss_1': 0.006550330203026533, 'loss_2': 0.00225830078125, 'loss_3': -16.56736183166504, 'loss_4': 0.933160662651062, 'epoch': 23.21}
{'loss': 0.0059, 'grad_norm': 4.977017402648926, 'learning_rate': 6.808139534883721e-06, 'loss_1': 0.003908651415258646, 'loss_2': 0.0019474029541015625, 'loss_3': -16.556968688964844, 'loss_4': 1.136174201965332, 'epoch': 23.22}
{'loss': 0.0071, 'grad_norm': 4.842484951019287, 'learning_rate': 6.802325581395349e-06, 'loss_1': 0.004924741107970476, 'loss_2': 0.0022029876708984375, 'loss_3': -16.494075775146484, 'loss_4': 0.8180025815963745, 'epoch': 23.22}
{'loss': 0.0059, 'grad_norm': 4.88153600692749, 'learning_rate': 6.796511627906977e-06, 'loss_1': 0.003279471304267645, 'loss_2': 0.00261688232421875, 'loss_3': -16.466415405273438, 'loss_4': 1.4781889915466309, 'epoch': 23.23}
[INFO|trainer.py:4228] 2025-01-21 13:58:50,003 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:50,003 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                 | 4000/5160 [1:38:54<20:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:58:57,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008387601003050804, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.144, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006092546973377466, 'eval_loss_2': 0.0022950544953346252, 'eval_loss_3': -18.16225814819336, 'eval_loss_4': 0.9613251090049744, 'epoch': 23.23}
{'loss': 0.0115, 'grad_norm': 4.683660507202148, 'learning_rate': 6.790697674418604e-06, 'loss_1': 0.004755317233502865, 'loss_2': 0.006740570068359375, 'loss_3': -16.41360092163086, 'loss_4': 0.7629043459892273, 'epoch': 23.23}
{'loss': 0.0108, 'grad_norm': 5.047868251800537, 'learning_rate': 6.784883720930233e-06, 'loss_1': 0.005856966134160757, 'loss_2': 0.004909515380859375, 'loss_3': -16.431659698486328, 'loss_4': 1.0663857460021973, 'epoch': 23.24}
{'loss': 0.0137, 'grad_norm': 5.536019325256348, 'learning_rate': 6.779069767441861e-06, 'loss_1': 0.006609470583498478, 'loss_2': 0.0071258544921875, 'loss_3': -16.35889434814453, 'loss_4': 1.0665082931518555, 'epoch': 23.24}
{'loss': 0.006, 'grad_norm': 4.9561944007873535, 'learning_rate': 6.773255813953489e-06, 'loss_1': 0.004194332752376795, 'loss_2': 0.001819610595703125, 'loss_3': -16.487548828125, 'loss_4': 0.9989320039749146, 'epoch': 23.25}
{'loss': 0.0062, 'grad_norm': 6.820690631866455, 'learning_rate': 6.767441860465116e-06, 'loss_1': 0.005282195284962654, 'loss_2': 0.0009326934814453125, 'loss_3': -16.484294891357422, 'loss_4': 1.4211256504058838, 'epoch': 23.26}
[INFO|trainer.py:4228] 2025-01-21 13:58:57,356 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:58:57,356 >>   Batch size = 64
 78%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                 | 4005/5160 [1:39:01<20:00,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:04,714 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008844460360705853, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.956, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006247910670936108, 'eval_loss_2': 0.002596549689769745, 'eval_loss_3': -18.15927505493164, 'eval_loss_4': 0.9552294015884399, 'epoch': 23.26}
{'loss': 0.0054, 'grad_norm': 5.369861602783203, 'learning_rate': 6.761627906976744e-06, 'loss_1': 0.004682487342506647, 'loss_2': 0.0007085800170898438, 'loss_3': -16.406417846679688, 'loss_4': 1.0765841007232666, 'epoch': 23.26}
{'loss': 0.0064, 'grad_norm': 4.241876602172852, 'learning_rate': 6.755813953488372e-06, 'loss_1': 0.004056298173964024, 'loss_2': 0.00229644775390625, 'loss_3': -16.634370803833008, 'loss_4': 1.1373648643493652, 'epoch': 23.27}
{'loss': 0.0101, 'grad_norm': 5.250265121459961, 'learning_rate': 6.750000000000001e-06, 'loss_1': 0.005704514682292938, 'loss_2': 0.004352569580078125, 'loss_3': -16.4615478515625, 'loss_4': 0.4658489525318146, 'epoch': 23.27}
{'loss': 0.0079, 'grad_norm': 4.672983646392822, 'learning_rate': 6.744186046511628e-06, 'loss_1': 0.0030973050743341446, 'loss_2': 0.004802703857421875, 'loss_3': -16.348283767700195, 'loss_4': 1.25626802444458, 'epoch': 23.28}
{'loss': 0.0174, 'grad_norm': 8.49372673034668, 'learning_rate': 6.738372093023255e-06, 'loss_1': 0.015451963059604168, 'loss_2': 0.001983642578125, 'loss_3': -16.39284896850586, 'loss_4': 0.9191545248031616, 'epoch': 23.28}
[INFO|trainer.py:4228] 2025-01-21 13:59:04,714 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:04,714 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                | 4010/5160 [1:39:09<19:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:12,082 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010963009670376778, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.315, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006506951991468668, 'eval_loss_2': 0.004456058144569397, 'eval_loss_3': -18.160755157470703, 'eval_loss_4': 0.9397510290145874, 'epoch': 23.28}
{'loss': 0.0176, 'grad_norm': 7.851467609405518, 'learning_rate': 6.732558139534884e-06, 'loss_1': 0.009371168911457062, 'loss_2': 0.00820159912109375, 'loss_3': -16.47580337524414, 'loss_4': 1.3272619247436523, 'epoch': 23.29}
{'loss': 0.0095, 'grad_norm': 5.123231410980225, 'learning_rate': 6.726744186046512e-06, 'loss_1': 0.00715456111356616, 'loss_2': 0.002384185791015625, 'loss_3': -16.2896728515625, 'loss_4': 1.464843511581421, 'epoch': 23.3}
{'loss': 0.0125, 'grad_norm': 5.053363800048828, 'learning_rate': 6.7209302325581395e-06, 'loss_1': 0.0059162164106965065, 'loss_2': 0.00655364990234375, 'loss_3': -16.336029052734375, 'loss_4': 1.0625033378601074, 'epoch': 23.3}
{'loss': 0.0124, 'grad_norm': 10.685433387756348, 'learning_rate': 6.715116279069768e-06, 'loss_1': 0.01057678833603859, 'loss_2': 0.001804351806640625, 'loss_3': -16.645217895507812, 'loss_4': 0.898139476776123, 'epoch': 23.31}
{'loss': 0.0098, 'grad_norm': 4.945441246032715, 'learning_rate': 6.709302325581395e-06, 'loss_1': 0.0037302998825907707, 'loss_2': 0.0060577392578125, 'loss_3': -16.522920608520508, 'loss_4': 0.9204335808753967, 'epoch': 23.31}
[INFO|trainer.py:4228] 2025-01-21 13:59:12,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:12,082 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                | 4015/5160 [1:39:16<19:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:19,454 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012168112210929394, 'eval_runtime': 3.8232, 'eval_samples_per_second': 267.837, 'eval_steps_per_second': 4.185, 'eval_loss_1': 0.0062304167076945305, 'eval_loss_2': 0.005937695503234863, 'eval_loss_3': -18.16790008544922, 'eval_loss_4': 0.9035146236419678, 'epoch': 23.31}
{'loss': 0.0167, 'grad_norm': 4.856837272644043, 'learning_rate': 6.703488372093023e-06, 'loss_1': 0.003904463490471244, 'loss_2': 0.0128021240234375, 'loss_3': -16.469158172607422, 'loss_4': 1.0963016748428345, 'epoch': 23.32}
{'loss': 0.0115, 'grad_norm': 9.477994918823242, 'learning_rate': 6.6976744186046515e-06, 'loss_1': 0.009592695161700249, 'loss_2': 0.0018815994262695312, 'loss_3': -16.493467330932617, 'loss_4': 0.630828857421875, 'epoch': 23.33}
{'loss': 0.0048, 'grad_norm': 4.3736653327941895, 'learning_rate': 6.691860465116279e-06, 'loss_1': 0.0028940951451659203, 'loss_2': 0.001880645751953125, 'loss_3': -16.277034759521484, 'loss_4': 0.8077349066734314, 'epoch': 23.33}
{'loss': 0.0246, 'grad_norm': 9.940967559814453, 'learning_rate': 6.686046511627907e-06, 'loss_1': 0.02116868458688259, 'loss_2': 0.003475189208984375, 'loss_3': -16.403799057006836, 'loss_4': 1.268405556678772, 'epoch': 23.34}
{'loss': 0.0176, 'grad_norm': 9.94926643371582, 'learning_rate': 6.680232558139536e-06, 'loss_1': 0.015013624913990498, 'loss_2': 0.002544403076171875, 'loss_3': -16.380695343017578, 'loss_4': 1.0426170825958252, 'epoch': 23.34}
[INFO|trainer.py:4228] 2025-01-21 13:59:19,455 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:19,455 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                | 4020/5160 [1:39:23<19:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:26,817 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011057857424020767, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.802, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006630543619394302, 'eval_loss_2': 0.004427313804626465, 'eval_loss_3': -18.17064094543457, 'eval_loss_4': 0.9425190687179565, 'epoch': 23.34}
{'loss': 0.0102, 'grad_norm': 4.871330738067627, 'learning_rate': 6.674418604651163e-06, 'loss_1': 0.0030752914026379585, 'loss_2': 0.00708770751953125, 'loss_3': -16.380708694458008, 'loss_4': 1.037481427192688, 'epoch': 23.35}
{'loss': 0.0103, 'grad_norm': 5.350330829620361, 'learning_rate': 6.6686046511627904e-06, 'loss_1': 0.0048352195881307125, 'loss_2': 0.0054473876953125, 'loss_3': -16.28158187866211, 'loss_4': 0.6852987408638, 'epoch': 23.35}
{'loss': 0.0069, 'grad_norm': 5.08835506439209, 'learning_rate': 6.662790697674419e-06, 'loss_1': 0.003366587683558464, 'loss_2': 0.003528594970703125, 'loss_3': -16.693267822265625, 'loss_4': 1.0307530164718628, 'epoch': 23.36}
{'loss': 0.0047, 'grad_norm': 4.873828411102295, 'learning_rate': 6.656976744186047e-06, 'loss_1': 0.00429697846993804, 'loss_2': 0.0004429817199707031, 'loss_3': -16.32632827758789, 'loss_4': 1.1345996856689453, 'epoch': 23.37}
{'loss': 0.0182, 'grad_norm': 13.280613899230957, 'learning_rate': 6.651162790697675e-06, 'loss_1': 0.01531789917498827, 'loss_2': 0.002887725830078125, 'loss_3': -16.375301361083984, 'loss_4': 0.5579789876937866, 'epoch': 23.37}
[INFO|trainer.py:4228] 2025-01-21 13:59:26,818 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:26,818 >>   Batch size = 64
 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                | 4025/5160 [1:39:31<19:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:34,174 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009889650158584118, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.946, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006608697585761547, 'eval_loss_2': 0.003280952572822571, 'eval_loss_3': -18.165611267089844, 'eval_loss_4': 0.9838461875915527, 'epoch': 23.37}
{'loss': 0.0035, 'grad_norm': 5.277574062347412, 'learning_rate': 6.6453488372093024e-06, 'loss_1': 0.003283780300989747, 'loss_2': 0.00024127960205078125, 'loss_3': -16.547189712524414, 'loss_4': 0.9615830779075623, 'epoch': 23.38}
{'loss': 0.0083, 'grad_norm': 5.145989894866943, 'learning_rate': 6.63953488372093e-06, 'loss_1': 0.0023332329001277685, 'loss_2': 0.006015777587890625, 'loss_3': -16.402244567871094, 'loss_4': 1.4496848583221436, 'epoch': 23.38}
{'loss': 0.0096, 'grad_norm': 4.629962921142578, 'learning_rate': 6.633720930232558e-06, 'loss_1': 0.0032803413923829794, 'loss_2': 0.0063629150390625, 'loss_3': -16.49462127685547, 'loss_4': 1.1071876287460327, 'epoch': 23.39}
{'loss': 0.0089, 'grad_norm': 7.752652168273926, 'learning_rate': 6.627906976744187e-06, 'loss_1': 0.007466510869562626, 'loss_2': 0.00141143798828125, 'loss_3': -16.253772735595703, 'loss_4': 0.8849934935569763, 'epoch': 23.4}
{'loss': 0.0149, 'grad_norm': 14.107938766479492, 'learning_rate': 6.622093023255814e-06, 'loss_1': 0.011998040601611137, 'loss_2': 0.00292205810546875, 'loss_3': -16.36750602722168, 'loss_4': 1.0648131370544434, 'epoch': 23.4}
[INFO|trainer.py:4228] 2025-01-21 13:59:34,174 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:34,174 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                | 4030/5160 [1:39:38<19:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:41,530 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009131195954978466, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.199, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.006463382393121719, 'eval_loss_2': 0.0026678144931793213, 'eval_loss_3': -18.176040649414062, 'eval_loss_4': 1.0506035089492798, 'epoch': 23.4}
{'loss': 0.0315, 'grad_norm': 9.681754112243652, 'learning_rate': 6.616279069767441e-06, 'loss_1': 0.028936734423041344, 'loss_2': 0.002532958984375, 'loss_3': -16.59662628173828, 'loss_4': 1.1534502506256104, 'epoch': 23.41}
{'loss': 0.0098, 'grad_norm': 5.2672858238220215, 'learning_rate': 6.61046511627907e-06, 'loss_1': 0.005907398648560047, 'loss_2': 0.00388336181640625, 'loss_3': -16.61639404296875, 'loss_4': 0.8644894361495972, 'epoch': 23.41}
{'loss': 0.0082, 'grad_norm': 4.936915397644043, 'learning_rate': 6.604651162790698e-06, 'loss_1': 0.002083718543872237, 'loss_2': 0.00611114501953125, 'loss_3': -16.29144287109375, 'loss_4': 1.4908602237701416, 'epoch': 23.42}
{'loss': 0.0065, 'grad_norm': 4.598176956176758, 'learning_rate': 6.5988372093023256e-06, 'loss_1': 0.003439948195591569, 'loss_2': 0.0030231475830078125, 'loss_3': -16.386415481567383, 'loss_4': 1.189892053604126, 'epoch': 23.42}
{'loss': 0.0154, 'grad_norm': 8.75204849243164, 'learning_rate': 6.593023255813954e-06, 'loss_1': 0.011485216207802296, 'loss_2': 0.00390625, 'loss_3': -16.207393646240234, 'loss_4': 0.9214104413986206, 'epoch': 23.43}
[INFO|trainer.py:4228] 2025-01-21 13:59:41,530 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:41,531 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                               | 4035/5160 [1:39:46<19:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:48,890 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008185053244233131, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.876, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006270575802773237, 'eval_loss_2': 0.001914478838443756, 'eval_loss_3': -18.169565200805664, 'eval_loss_4': 1.071938157081604, 'epoch': 23.43}
{'loss': 0.0108, 'grad_norm': 4.690273284912109, 'learning_rate': 6.587209302325582e-06, 'loss_1': 0.005705877207219601, 'loss_2': 0.00513458251953125, 'loss_3': -16.605167388916016, 'loss_4': 1.4962642192840576, 'epoch': 23.44}
{'loss': 0.012, 'grad_norm': 4.6093573570251465, 'learning_rate': 6.581395348837209e-06, 'loss_1': 0.005742279347032309, 'loss_2': 0.006290435791015625, 'loss_3': -16.345321655273438, 'loss_4': 1.012505292892456, 'epoch': 23.44}
{'loss': 0.0074, 'grad_norm': 4.618810653686523, 'learning_rate': 6.5755813953488375e-06, 'loss_1': 0.003365709213539958, 'loss_2': 0.00405120849609375, 'loss_3': -16.256732940673828, 'loss_4': 1.3530117273330688, 'epoch': 23.45}
{'loss': 0.01, 'grad_norm': 4.87797737121582, 'learning_rate': 6.569767441860465e-06, 'loss_1': 0.0036498834379017353, 'loss_2': 0.0063018798828125, 'loss_3': -16.404401779174805, 'loss_4': 0.9946929812431335, 'epoch': 23.45}
{'loss': 0.0106, 'grad_norm': 4.866835594177246, 'learning_rate': 6.563953488372093e-06, 'loss_1': 0.003949856851249933, 'loss_2': 0.00661468505859375, 'loss_3': -16.31214714050293, 'loss_4': 1.0932611227035522, 'epoch': 23.46}
[INFO|trainer.py:4228] 2025-01-21 13:59:48,890 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:48,890 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                               | 4040/5160 [1:39:53<19:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 13:59:56,263 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009003285318613052, 'eval_runtime': 3.8147, 'eval_samples_per_second': 268.438, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006143998820334673, 'eval_loss_2': 0.0028592869639396667, 'eval_loss_3': -18.173295974731445, 'eval_loss_4': 1.0812547206878662, 'epoch': 23.46}
{'loss': 0.0063, 'grad_norm': 4.716294765472412, 'learning_rate': 6.558139534883722e-06, 'loss_1': 0.003831747453659773, 'loss_2': 0.002506256103515625, 'loss_3': -16.38542938232422, 'loss_4': 1.2492855787277222, 'epoch': 23.47}
{'loss': 0.007, 'grad_norm': 5.564453601837158, 'learning_rate': 6.552325581395349e-06, 'loss_1': 0.0016783454921096563, 'loss_2': 0.00536346435546875, 'loss_3': -16.366043090820312, 'loss_4': 1.1563915014266968, 'epoch': 23.47}
{'loss': 0.0093, 'grad_norm': 5.572683334350586, 'learning_rate': 6.5465116279069765e-06, 'loss_1': 0.00808969046920538, 'loss_2': 0.0011882781982421875, 'loss_3': -16.386062622070312, 'loss_4': 1.2986762523651123, 'epoch': 23.48}
{'loss': 0.0047, 'grad_norm': 4.686053276062012, 'learning_rate': 6.540697674418605e-06, 'loss_1': 0.003099036170169711, 'loss_2': 0.001636505126953125, 'loss_3': -16.447105407714844, 'loss_4': 1.0074419975280762, 'epoch': 23.48}
{'loss': 0.0068, 'grad_norm': 4.992167949676514, 'learning_rate': 6.534883720930233e-06, 'loss_1': 0.0034771959763020277, 'loss_2': 0.0032806396484375, 'loss_3': -16.43095588684082, 'loss_4': 0.9285791516304016, 'epoch': 23.49}
[INFO|trainer.py:4228] 2025-01-21 13:59:56,263 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 13:59:56,263 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                               | 4045/5160 [1:40:00<19:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:03,622 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009540052153170109, 'eval_runtime': 3.8084, 'eval_samples_per_second': 268.88, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.006599218584597111, 'eval_loss_2': 0.002940833568572998, 'eval_loss_3': -18.17670440673828, 'eval_loss_4': 1.0911470651626587, 'epoch': 23.49}
{'loss': 0.015, 'grad_norm': 4.611324310302734, 'learning_rate': 6.529069767441861e-06, 'loss_1': 0.004125671926885843, 'loss_2': 0.01085662841796875, 'loss_3': -16.450389862060547, 'loss_4': 1.0346821546554565, 'epoch': 23.49}
{'loss': 0.0072, 'grad_norm': 4.461103916168213, 'learning_rate': 6.5232558139534885e-06, 'loss_1': 0.005459589883685112, 'loss_2': 0.0017681121826171875, 'loss_3': -16.24490737915039, 'loss_4': 1.0986160039901733, 'epoch': 23.5}
{'loss': 0.0115, 'grad_norm': 4.594311714172363, 'learning_rate': 6.517441860465116e-06, 'loss_1': 0.0048168133944272995, 'loss_2': 0.0067291259765625, 'loss_3': -16.59880828857422, 'loss_4': 0.9576302766799927, 'epoch': 23.51}
{'loss': 0.0089, 'grad_norm': 4.914622783660889, 'learning_rate': 6.511627906976744e-06, 'loss_1': 0.003980021923780441, 'loss_2': 0.00489044189453125, 'loss_3': -16.508865356445312, 'loss_4': 0.9274260997772217, 'epoch': 23.51}
{'loss': 0.0135, 'grad_norm': 6.318070411682129, 'learning_rate': 6.505813953488373e-06, 'loss_1': 0.008932831697165966, 'loss_2': 0.00453948974609375, 'loss_3': -16.342697143554688, 'loss_4': 1.874253273010254, 'epoch': 23.52}
[INFO|trainer.py:4228] 2025-01-21 14:00:03,622 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:03,622 >>   Batch size = 64
 78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                               | 4050/5160 [1:40:08<19:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:10,982 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008494535461068153, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.018, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006392264273017645, 'eval_loss_2': 0.002102270722389221, 'eval_loss_3': -18.172792434692383, 'eval_loss_4': 1.082362413406372, 'epoch': 23.52}
{'loss': 0.0125, 'grad_norm': 6.8808770179748535, 'learning_rate': 6.5000000000000004e-06, 'loss_1': 0.006834765896201134, 'loss_2': 0.005710601806640625, 'loss_3': -16.557579040527344, 'loss_4': 1.1979005336761475, 'epoch': 23.52}
{'loss': 0.0069, 'grad_norm': 4.887707710266113, 'learning_rate': 6.494186046511628e-06, 'loss_1': 0.003755151992663741, 'loss_2': 0.00313568115234375, 'loss_3': -16.724260330200195, 'loss_4': 0.9062960147857666, 'epoch': 23.53}
{'loss': 0.0053, 'grad_norm': 6.397528171539307, 'learning_rate': 6.488372093023256e-06, 'loss_1': 0.004369738977402449, 'loss_2': 0.0009527206420898438, 'loss_3': -16.450401306152344, 'loss_4': 1.1886142492294312, 'epoch': 23.53}
{'loss': 0.005, 'grad_norm': 4.832401275634766, 'learning_rate': 6.482558139534884e-06, 'loss_1': 0.004774933680891991, 'loss_2': 0.00018644332885742188, 'loss_3': -16.395034790039062, 'loss_4': 1.0891554355621338, 'epoch': 23.54}
{'loss': 0.0031, 'grad_norm': 4.33422327041626, 'learning_rate': 6.476744186046512e-06, 'loss_1': 0.002801683032885194, 'loss_2': 0.0003085136413574219, 'loss_3': -16.50323486328125, 'loss_4': 1.2223583459854126, 'epoch': 23.55}
[INFO|trainer.py:4228] 2025-01-21 14:00:10,982 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:10,982 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                               | 4055/5160 [1:40:15<19:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:18,337 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009387850761413574, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.822, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006434916984289885, 'eval_loss_2': 0.0029529333114624023, 'eval_loss_3': -18.16598129272461, 'eval_loss_4': 1.071740746498108, 'epoch': 23.55}
{'loss': 0.0192, 'grad_norm': 7.24718713760376, 'learning_rate': 6.47093023255814e-06, 'loss_1': 0.01354814413934946, 'loss_2': 0.005615234375, 'loss_3': -16.45694351196289, 'loss_4': 1.4029977321624756, 'epoch': 23.55}
{'loss': 0.0086, 'grad_norm': 7.087856292724609, 'learning_rate': 6.465116279069768e-06, 'loss_1': 0.006614150945097208, 'loss_2': 0.0019817352294921875, 'loss_3': -16.367412567138672, 'loss_4': 1.3155226707458496, 'epoch': 23.56}
{'loss': 0.0093, 'grad_norm': 5.98649787902832, 'learning_rate': 6.459302325581395e-06, 'loss_1': 0.007502491120249033, 'loss_2': 0.0017871856689453125, 'loss_3': -16.389013290405273, 'loss_4': 1.394410490989685, 'epoch': 23.56}
{'loss': 0.0105, 'grad_norm': 4.804203510284424, 'learning_rate': 6.453488372093024e-06, 'loss_1': 0.0037575913593173027, 'loss_2': 0.006744384765625, 'loss_3': -16.26207733154297, 'loss_4': 1.2599579095840454, 'epoch': 23.57}
{'loss': 0.0119, 'grad_norm': 4.898672103881836, 'learning_rate': 6.447674418604651e-06, 'loss_1': 0.009161259979009628, 'loss_2': 0.00278472900390625, 'loss_3': -16.623825073242188, 'loss_4': 1.4999024868011475, 'epoch': 23.58}
[INFO|trainer.py:4228] 2025-01-21 14:00:18,337 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:18,337 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                              | 4060/5160 [1:40:22<19:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:25,692 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010092766024172306, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006497175432741642, 'eval_loss_2': 0.003595590591430664, 'eval_loss_3': -18.164270401000977, 'eval_loss_4': 1.070230484008789, 'epoch': 23.58}
{'loss': 0.0126, 'grad_norm': 8.63217830657959, 'learning_rate': 6.441860465116279e-06, 'loss_1': 0.009797620587050915, 'loss_2': 0.002796173095703125, 'loss_3': -16.337800979614258, 'loss_4': 1.6441960334777832, 'epoch': 23.58}
{'loss': 0.0093, 'grad_norm': 5.658085346221924, 'learning_rate': 6.436046511627908e-06, 'loss_1': 0.0074254730716347694, 'loss_2': 0.0018625259399414062, 'loss_3': -16.437129974365234, 'loss_4': 1.6242046356201172, 'epoch': 23.59}
{'loss': 0.0092, 'grad_norm': 5.758177280426025, 'learning_rate': 6.430232558139535e-06, 'loss_1': 0.005488948430866003, 'loss_2': 0.00372314453125, 'loss_3': -16.676265716552734, 'loss_4': 1.299824833869934, 'epoch': 23.59}
{'loss': 0.0178, 'grad_norm': 11.746899604797363, 'learning_rate': 6.4244186046511625e-06, 'loss_1': 0.012872821651399136, 'loss_2': 0.00492095947265625, 'loss_3': -16.53612518310547, 'loss_4': 1.1034767627716064, 'epoch': 23.6}
{'loss': 0.0097, 'grad_norm': 5.166390895843506, 'learning_rate': 6.418604651162791e-06, 'loss_1': 0.003943321295082569, 'loss_2': 0.00579833984375, 'loss_3': -16.556922912597656, 'loss_4': 1.189544677734375, 'epoch': 23.6}
[INFO|trainer.py:4228] 2025-01-21 14:00:25,693 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:25,693 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 4065/5160 [1:40:30<18:58,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:33,051 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009985999204218388, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.905, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006902963388711214, 'eval_loss_2': 0.0030830353498458862, 'eval_loss_3': -18.173931121826172, 'eval_loss_4': 1.0469578504562378, 'epoch': 23.6}
{'loss': 0.0098, 'grad_norm': 6.470974922180176, 'learning_rate': 6.412790697674419e-06, 'loss_1': 0.006092248950153589, 'loss_2': 0.003734588623046875, 'loss_3': -16.33313751220703, 'loss_4': 0.9953840374946594, 'epoch': 23.61}
{'loss': 0.013, 'grad_norm': 7.842133522033691, 'learning_rate': 6.406976744186047e-06, 'loss_1': 0.008527180179953575, 'loss_2': 0.004444122314453125, 'loss_3': -16.237829208374023, 'loss_4': 0.6352361440658569, 'epoch': 23.62}
{'loss': 0.0047, 'grad_norm': 4.160016059875488, 'learning_rate': 6.401162790697675e-06, 'loss_1': 0.0021623685024678707, 'loss_2': 0.0025482177734375, 'loss_3': -16.397998809814453, 'loss_4': 0.7990868091583252, 'epoch': 23.62}
{'loss': 0.0024, 'grad_norm': 4.503586292266846, 'learning_rate': 6.395348837209302e-06, 'loss_1': 0.001915658824145794, 'loss_2': 0.0005311965942382812, 'loss_3': -16.455738067626953, 'loss_4': 1.0181009769439697, 'epoch': 23.63}
{'loss': 0.0086, 'grad_norm': 5.034609794616699, 'learning_rate': 6.38953488372093e-06, 'loss_1': 0.003671527374535799, 'loss_2': 0.004901885986328125, 'loss_3': -16.524934768676758, 'loss_4': 0.8476132154464722, 'epoch': 23.63}
[INFO|trainer.py:4228] 2025-01-21 14:00:33,051 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:33,051 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 4070/5160 [1:40:37<18:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:40,418 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009851435199379921, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.178, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.00647062947973609, 'eval_loss_2': 0.003380805253982544, 'eval_loss_3': -18.183961868286133, 'eval_loss_4': 1.0502748489379883, 'epoch': 23.63}
{'loss': 0.0076, 'grad_norm': 5.244356155395508, 'learning_rate': 6.383720930232559e-06, 'loss_1': 0.0058811623603105545, 'loss_2': 0.0017299652099609375, 'loss_3': -16.393613815307617, 'loss_4': 0.6816765069961548, 'epoch': 23.64}
{'loss': 0.0057, 'grad_norm': 4.854409217834473, 'learning_rate': 6.3779069767441865e-06, 'loss_1': 0.003328453516587615, 'loss_2': 0.0023937225341796875, 'loss_3': -16.394916534423828, 'loss_4': 1.1446725130081177, 'epoch': 23.65}
{'loss': 0.0061, 'grad_norm': 4.6644439697265625, 'learning_rate': 6.372093023255814e-06, 'loss_1': 0.004045853391289711, 'loss_2': 0.0020465850830078125, 'loss_3': -16.564945220947266, 'loss_4': 1.2506215572357178, 'epoch': 23.65}
{'loss': 0.0093, 'grad_norm': 4.593797206878662, 'learning_rate': 6.366279069767442e-06, 'loss_1': 0.0024424155708402395, 'loss_2': 0.0068359375, 'loss_3': -16.55336570739746, 'loss_4': 1.5588042736053467, 'epoch': 23.66}
{'loss': 0.006, 'grad_norm': 5.163463592529297, 'learning_rate': 6.36046511627907e-06, 'loss_1': 0.003235883079469204, 'loss_2': 0.002773284912109375, 'loss_3': -16.494905471801758, 'loss_4': 0.8066229820251465, 'epoch': 23.66}
[INFO|trainer.py:4228] 2025-01-21 14:00:40,418 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:40,418 >>   Batch size = 64
 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                              | 4075/5160 [1:40:44<18:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:47,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009097263216972351, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.745, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006531417369842529, 'eval_loss_2': 0.0025658458471298218, 'eval_loss_3': -18.201095581054688, 'eval_loss_4': 1.038680076599121, 'epoch': 23.66}
{'loss': 0.0075, 'grad_norm': 4.936428546905518, 'learning_rate': 6.354651162790698e-06, 'loss_1': 0.00544492295011878, 'loss_2': 0.002071380615234375, 'loss_3': -16.579063415527344, 'loss_4': 0.7847248315811157, 'epoch': 23.67}
{'loss': 0.0151, 'grad_norm': 6.892514228820801, 'learning_rate': 6.348837209302326e-06, 'loss_1': 0.007485342212021351, 'loss_2': 0.007610321044921875, 'loss_3': -16.311161041259766, 'loss_4': 1.1138111352920532, 'epoch': 23.67}
{'loss': 0.0082, 'grad_norm': 5.5691447257995605, 'learning_rate': 6.343023255813954e-06, 'loss_1': 0.005088167730718851, 'loss_2': 0.003154754638671875, 'loss_3': -16.534006118774414, 'loss_4': 0.9277633428573608, 'epoch': 23.68}
{'loss': 0.0041, 'grad_norm': 5.008582592010498, 'learning_rate': 6.337209302325581e-06, 'loss_1': 0.0025321668945252895, 'loss_2': 0.00157928466796875, 'loss_3': -16.380096435546875, 'loss_4': 1.139801263809204, 'epoch': 23.69}
{'loss': 0.0131, 'grad_norm': 5.464873790740967, 'learning_rate': 6.33139534883721e-06, 'loss_1': 0.008760420605540276, 'loss_2': 0.004329681396484375, 'loss_3': -16.24205780029297, 'loss_4': 1.0154738426208496, 'epoch': 23.69}
[INFO|trainer.py:4228] 2025-01-21 14:00:47,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:47,782 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 4080/5160 [1:40:52<18:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:00:55,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008988406509160995, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.059, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006280448287725449, 'eval_loss_2': 0.002707958221435547, 'eval_loss_3': -18.217571258544922, 'eval_loss_4': 1.0311671495437622, 'epoch': 23.69}
{'loss': 0.0038, 'grad_norm': 4.56901216506958, 'learning_rate': 6.325581395348837e-06, 'loss_1': 0.002019258216023445, 'loss_2': 0.0017452239990234375, 'loss_3': -16.39974021911621, 'loss_4': 0.8466050624847412, 'epoch': 23.7}
{'loss': 0.0055, 'grad_norm': 4.796298980712891, 'learning_rate': 6.319767441860465e-06, 'loss_1': 0.0038094264455139637, 'loss_2': 0.001689910888671875, 'loss_3': -16.400150299072266, 'loss_4': 0.7544267177581787, 'epoch': 23.7}
{'loss': 0.0218, 'grad_norm': 12.213781356811523, 'learning_rate': 6.313953488372094e-06, 'loss_1': 0.02072499319911003, 'loss_2': 0.0011167526245117188, 'loss_3': -16.48421287536621, 'loss_4': 1.1208903789520264, 'epoch': 23.71}
{'loss': 0.0031, 'grad_norm': 4.153900623321533, 'learning_rate': 6.308139534883722e-06, 'loss_1': 0.0020241274032741785, 'loss_2': 0.001056671142578125, 'loss_3': -16.364587783813477, 'loss_4': 1.1378891468048096, 'epoch': 23.72}
{'loss': 0.0046, 'grad_norm': 5.008310317993164, 'learning_rate': 6.3023255813953485e-06, 'loss_1': 0.0037561231292784214, 'loss_2': 0.0008416175842285156, 'loss_3': -16.537750244140625, 'loss_4': 1.4066517353057861, 'epoch': 23.72}
[INFO|trainer.py:4228] 2025-01-21 14:00:55,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:00:55,144 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 4085/5160 [1:40:59<18:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:02,498 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009227334521710873, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.06, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006483836565166712, 'eval_loss_2': 0.0027434974908828735, 'eval_loss_3': -18.215375900268555, 'eval_loss_4': 1.0505456924438477, 'epoch': 23.72}
{'loss': 0.0092, 'grad_norm': 5.179811000823975, 'learning_rate': 6.296511627906977e-06, 'loss_1': 0.004800877999514341, 'loss_2': 0.004444122314453125, 'loss_3': -16.495145797729492, 'loss_4': 1.4157745838165283, 'epoch': 23.73}
{'loss': 0.0108, 'grad_norm': 5.341555595397949, 'learning_rate': 6.290697674418605e-06, 'loss_1': 0.004906822461634874, 'loss_2': 0.005878448486328125, 'loss_3': -16.463598251342773, 'loss_4': 0.7728455066680908, 'epoch': 23.73}
{'loss': 0.0349, 'grad_norm': 13.566794395446777, 'learning_rate': 6.284883720930233e-06, 'loss_1': 0.030992476269602776, 'loss_2': 0.003875732421875, 'loss_3': -16.477630615234375, 'loss_4': 1.1805799007415771, 'epoch': 23.74}
{'loss': 0.0146, 'grad_norm': 10.53046703338623, 'learning_rate': 6.279069767441861e-06, 'loss_1': 0.01299508661031723, 'loss_2': 0.0015888214111328125, 'loss_3': -16.4012451171875, 'loss_4': 0.9602136015892029, 'epoch': 23.74}
{'loss': 0.0157, 'grad_norm': 5.348697662353516, 'learning_rate': 6.273255813953488e-06, 'loss_1': 0.007482432760298252, 'loss_2': 0.00826263427734375, 'loss_3': -16.359447479248047, 'loss_4': 1.1432080268859863, 'epoch': 23.75}
[INFO|trainer.py:4228] 2025-01-21 14:01:02,498 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:02,498 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                             | 4090/5160 [1:41:06<18:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:09,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009324615821242332, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.963, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.006740858778357506, 'eval_loss_2': 0.0025837570428848267, 'eval_loss_3': -18.22332000732422, 'eval_loss_4': 1.0645301342010498, 'epoch': 23.75}
{'loss': 0.0138, 'grad_norm': 4.569207191467285, 'learning_rate': 6.267441860465116e-06, 'loss_1': 0.0033719835337251425, 'loss_2': 0.010406494140625, 'loss_3': -16.52072525024414, 'loss_4': 1.3102214336395264, 'epoch': 23.76}
{'loss': 0.0113, 'grad_norm': 4.830098628997803, 'learning_rate': 6.261627906976745e-06, 'loss_1': 0.006171974819153547, 'loss_2': 0.00508880615234375, 'loss_3': -16.319591522216797, 'loss_4': 1.2263444662094116, 'epoch': 23.76}
{'loss': 0.0067, 'grad_norm': 4.666958808898926, 'learning_rate': 6.2558139534883725e-06, 'loss_1': 0.0025422864127904177, 'loss_2': 0.0041656494140625, 'loss_3': -16.707855224609375, 'loss_4': 0.8445752859115601, 'epoch': 23.77}
{'loss': 0.0099, 'grad_norm': 5.361731052398682, 'learning_rate': 6.25e-06, 'loss_1': 0.0043044681660830975, 'loss_2': 0.00556182861328125, 'loss_3': -16.5, 'loss_4': 0.948072075843811, 'epoch': 23.77}
{'loss': 0.0056, 'grad_norm': 5.3235955238342285, 'learning_rate': 6.244186046511628e-06, 'loss_1': 0.004355743993073702, 'loss_2': 0.0012836456298828125, 'loss_3': -16.525074005126953, 'loss_4': 0.7164835333824158, 'epoch': 23.78}
[INFO|trainer.py:4228] 2025-01-21 14:01:09,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:09,853 >>   Batch size = 64
 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                             | 4095/5160 [1:41:14<18:27,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:17,221 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010373537428677082, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.43, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0069841789081692696, 'eval_loss_2': 0.0033893585205078125, 'eval_loss_3': -18.219287872314453, 'eval_loss_4': 1.059641718864441, 'epoch': 23.78}
{'loss': 0.0087, 'grad_norm': 5.1314544677734375, 'learning_rate': 6.238372093023256e-06, 'loss_1': 0.005534186959266663, 'loss_2': 0.0032100677490234375, 'loss_3': -16.542312622070312, 'loss_4': 0.7535300254821777, 'epoch': 23.78}
{'loss': 0.005, 'grad_norm': 4.951008319854736, 'learning_rate': 6.232558139534884e-06, 'loss_1': 0.004813398700207472, 'loss_2': 0.0001856088638305664, 'loss_3': -16.40470314025879, 'loss_4': 1.126155138015747, 'epoch': 23.79}
{'loss': 0.0148, 'grad_norm': 8.964123725891113, 'learning_rate': 6.2267441860465114e-06, 'loss_1': 0.009363078512251377, 'loss_2': 0.00542449951171875, 'loss_3': -16.41864776611328, 'loss_4': 1.2387014627456665, 'epoch': 23.8}
{'loss': 0.006, 'grad_norm': 5.04299259185791, 'learning_rate': 6.22093023255814e-06, 'loss_1': 0.0051859342493116856, 'loss_2': 0.0007872581481933594, 'loss_3': -16.523517608642578, 'loss_4': 1.0717986822128296, 'epoch': 23.8}
{'loss': 0.0092, 'grad_norm': 4.673417568206787, 'learning_rate': 6.215116279069768e-06, 'loss_1': 0.004857896827161312, 'loss_2': 0.0043182373046875, 'loss_3': -16.522796630859375, 'loss_4': 1.182098627090454, 'epoch': 23.81}
[INFO|trainer.py:4228] 2025-01-21 14:01:17,221 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:17,221 >>   Batch size = 64
 79%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                             | 4100/5160 [1:41:21<18:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:24,581 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013082644902169704, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.917, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007053158711642027, 'eval_loss_2': 0.006029486656188965, 'eval_loss_3': -18.196868896484375, 'eval_loss_4': 1.0722582340240479, 'epoch': 23.81}
{'loss': 0.008, 'grad_norm': 4.599672317504883, 'learning_rate': 6.209302325581395e-06, 'loss_1': 0.004658486694097519, 'loss_2': 0.0032958984375, 'loss_3': -16.4649715423584, 'loss_4': 0.7263576984405518, 'epoch': 23.81}
{'loss': 0.0161, 'grad_norm': 6.230123996734619, 'learning_rate': 6.2034883720930234e-06, 'loss_1': 0.012382427230477333, 'loss_2': 0.00366973876953125, 'loss_3': -16.433734893798828, 'loss_4': 0.8306558132171631, 'epoch': 23.82}
{'loss': 0.0053, 'grad_norm': 4.597111701965332, 'learning_rate': 6.197674418604651e-06, 'loss_1': 0.003517148084938526, 'loss_2': 0.0018281936645507812, 'loss_3': -16.542476654052734, 'loss_4': 0.9895853996276855, 'epoch': 23.83}
{'loss': 0.014, 'grad_norm': 5.581182479858398, 'learning_rate': 6.191860465116279e-06, 'loss_1': 0.006107860244810581, 'loss_2': 0.0078582763671875, 'loss_3': -16.432170867919922, 'loss_4': 1.147459864616394, 'epoch': 23.83}
{'loss': 0.0147, 'grad_norm': 4.9210333824157715, 'learning_rate': 6.186046511627908e-06, 'loss_1': 0.005519698839634657, 'loss_2': 0.00921630859375, 'loss_3': -16.45440673828125, 'loss_4': 1.052525520324707, 'epoch': 23.84}
[INFO|trainer.py:4228] 2025-01-21 14:01:24,581 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:24,581 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                            | 4105/5160 [1:41:29<18:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:31,938 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01219496876001358, 'eval_runtime': 3.8092, 'eval_samples_per_second': 268.824, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.006935231853276491, 'eval_loss_2': 0.0052597373723983765, 'eval_loss_3': -18.193525314331055, 'eval_loss_4': 1.1395915746688843, 'epoch': 23.84}
{'loss': 0.0086, 'grad_norm': 4.848031997680664, 'learning_rate': 6.1802325581395346e-06, 'loss_1': 0.0031549965497106314, 'loss_2': 0.005401611328125, 'loss_3': -16.63113784790039, 'loss_4': 1.048112154006958, 'epoch': 23.84}
{'loss': 0.0062, 'grad_norm': 4.664846897125244, 'learning_rate': 6.174418604651162e-06, 'loss_1': 0.004562802612781525, 'loss_2': 0.001617431640625, 'loss_3': -16.405214309692383, 'loss_4': 1.3159472942352295, 'epoch': 23.85}
{'loss': 0.0155, 'grad_norm': 8.480652809143066, 'learning_rate': 6.168604651162791e-06, 'loss_1': 0.012483786791563034, 'loss_2': 0.002986907958984375, 'loss_3': -16.435829162597656, 'loss_4': 1.3502686023712158, 'epoch': 23.85}
{'loss': 0.0234, 'grad_norm': 9.986456871032715, 'learning_rate': 6.162790697674419e-06, 'loss_1': 0.01999155804514885, 'loss_2': 0.00337982177734375, 'loss_3': -16.66411590576172, 'loss_4': 1.2575538158416748, 'epoch': 23.86}
{'loss': 0.0103, 'grad_norm': 5.114550590515137, 'learning_rate': 6.1569767441860466e-06, 'loss_1': 0.004077304620295763, 'loss_2': 0.006191253662109375, 'loss_3': -16.44068145751953, 'loss_4': 1.0032503604888916, 'epoch': 23.87}
[INFO|trainer.py:4228] 2025-01-21 14:01:31,938 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:31,939 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                            | 4110/5160 [1:41:36<18:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:39,307 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009549581445753574, 'eval_runtime': 3.815, 'eval_samples_per_second': 268.418, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.007086135447025299, 'eval_loss_2': 0.0024634450674057007, 'eval_loss_3': -18.19232940673828, 'eval_loss_4': 1.2069480419158936, 'epoch': 23.87}
{'loss': 0.0173, 'grad_norm': 12.066043853759766, 'learning_rate': 6.151162790697674e-06, 'loss_1': 0.01593170128762722, 'loss_2': 0.0013904571533203125, 'loss_3': -16.53848648071289, 'loss_4': 0.8370168209075928, 'epoch': 23.87}
{'loss': 0.0067, 'grad_norm': 6.034897804260254, 'learning_rate': 6.145348837209302e-06, 'loss_1': 0.004839907865971327, 'loss_2': 0.00189208984375, 'loss_3': -16.65800666809082, 'loss_4': 0.7048075199127197, 'epoch': 23.88}
{'loss': 0.0045, 'grad_norm': 4.345983505249023, 'learning_rate': 6.13953488372093e-06, 'loss_1': 0.004493332467973232, 'loss_2': 1.0907649993896484e-05, 'loss_3': -16.4027042388916, 'loss_4': 1.2700399160385132, 'epoch': 23.88}
{'loss': 0.0101, 'grad_norm': 5.2123703956604, 'learning_rate': 6.1337209302325585e-06, 'loss_1': 0.007282853126525879, 'loss_2': 0.002864837646484375, 'loss_3': -16.609174728393555, 'loss_4': 1.2858113050460815, 'epoch': 23.89}
{'loss': 0.0121, 'grad_norm': 6.352339744567871, 'learning_rate': 6.127906976744186e-06, 'loss_1': 0.005694535095244646, 'loss_2': 0.0063934326171875, 'loss_3': -16.586681365966797, 'loss_4': 1.4938982725143433, 'epoch': 23.9}
[INFO|trainer.py:4228] 2025-01-21 14:01:39,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:39,307 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 4115/5160 [1:41:43<18:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:46,662 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009075523354113102, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.126, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.007195436395704746, 'eval_loss_2': 0.0018800869584083557, 'eval_loss_3': -18.186887741088867, 'eval_loss_4': 1.2484731674194336, 'epoch': 23.9}
{'loss': 0.0082, 'grad_norm': 4.296823978424072, 'learning_rate': 6.122093023255814e-06, 'loss_1': 0.004521428607404232, 'loss_2': 0.00368499755859375, 'loss_3': -16.605716705322266, 'loss_4': 1.471595048904419, 'epoch': 23.9}
{'loss': 0.0171, 'grad_norm': 6.349194526672363, 'learning_rate': 6.116279069767442e-06, 'loss_1': 0.00815741065889597, 'loss_2': 0.008941650390625, 'loss_3': -16.402502059936523, 'loss_4': 1.2216798067092896, 'epoch': 23.91}
{'loss': 0.0048, 'grad_norm': 4.762228012084961, 'learning_rate': 6.11046511627907e-06, 'loss_1': 0.004733309615403414, 'loss_2': 0.00011497735977172852, 'loss_3': -16.37145233154297, 'loss_4': 1.474349021911621, 'epoch': 23.91}
{'loss': 0.0102, 'grad_norm': 4.997211456298828, 'learning_rate': 6.1046511627906975e-06, 'loss_1': 0.005314202513545752, 'loss_2': 0.00484466552734375, 'loss_3': -16.48444938659668, 'loss_4': 0.8632333278656006, 'epoch': 23.92}
{'loss': 0.0097, 'grad_norm': 5.809077262878418, 'learning_rate': 6.098837209302326e-06, 'loss_1': 0.008126960135996342, 'loss_2': 0.001552581787109375, 'loss_3': -16.630176544189453, 'loss_4': 1.1172726154327393, 'epoch': 23.92}
[INFO|trainer.py:4228] 2025-01-21 14:01:46,662 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:46,662 >>   Batch size = 64
 80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                            | 4120/5160 [1:41:51<18:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:01:54,028 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009114873595535755, 'eval_runtime': 3.811, 'eval_samples_per_second': 268.699, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.007370383013039827, 'eval_loss_2': 0.0017444901168346405, 'eval_loss_3': -18.193439483642578, 'eval_loss_4': 1.2941474914550781, 'epoch': 23.92}
{'loss': 0.0086, 'grad_norm': 9.078593254089355, 'learning_rate': 6.093023255813954e-06, 'loss_1': 0.008338379673659801, 'loss_2': 0.00025725364685058594, 'loss_3': -16.628097534179688, 'loss_4': 1.3569250106811523, 'epoch': 23.93}
{'loss': 0.0086, 'grad_norm': 5.248401641845703, 'learning_rate': 6.087209302325581e-06, 'loss_1': 0.007669492159038782, 'loss_2': 0.0009698867797851562, 'loss_3': -16.507999420166016, 'loss_4': 0.9458863139152527, 'epoch': 23.94}
{'loss': 0.0062, 'grad_norm': 5.118710517883301, 'learning_rate': 6.0813953488372095e-06, 'loss_1': 0.0058150338008999825, 'loss_2': 0.0003936290740966797, 'loss_3': -16.642444610595703, 'loss_4': 1.5338447093963623, 'epoch': 23.94}
{'loss': 0.005, 'grad_norm': 5.010690212249756, 'learning_rate': 6.075581395348837e-06, 'loss_1': 0.0030669926200062037, 'loss_2': 0.0019054412841796875, 'loss_3': -16.321638107299805, 'loss_4': 1.2556877136230469, 'epoch': 23.95}
{'loss': 0.0052, 'grad_norm': 4.345198154449463, 'learning_rate': 6.069767441860465e-06, 'loss_1': 0.0029395646415650845, 'loss_2': 0.002292633056640625, 'loss_3': -16.582889556884766, 'loss_4': 1.392309308052063, 'epoch': 23.95}
[INFO|trainer.py:4228] 2025-01-21 14:01:54,028 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:01:54,029 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                            | 4125/5160 [1:41:58<17:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:01,403 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00967834796756506, 'eval_runtime': 3.8201, 'eval_samples_per_second': 268.058, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.007747545372694731, 'eval_loss_2': 0.0019308030605316162, 'eval_loss_3': -18.182641983032227, 'eval_loss_4': 1.2751859426498413, 'epoch': 23.95}
{'loss': 0.0128, 'grad_norm': 5.652273178100586, 'learning_rate': 6.063953488372094e-06, 'loss_1': 0.006028210744261742, 'loss_2': 0.006725311279296875, 'loss_3': -16.50181007385254, 'loss_4': 1.1559932231903076, 'epoch': 23.96}
{'loss': 0.0088, 'grad_norm': 4.714794635772705, 'learning_rate': 6.058139534883721e-06, 'loss_1': 0.005539263598620892, 'loss_2': 0.00325775146484375, 'loss_3': -16.348758697509766, 'loss_4': 1.4038357734680176, 'epoch': 23.97}
{'loss': 0.0077, 'grad_norm': 4.892030715942383, 'learning_rate': 6.052325581395348e-06, 'loss_1': 0.005193807650357485, 'loss_2': 0.0025119781494140625, 'loss_3': -16.70416259765625, 'loss_4': 1.5850590467453003, 'epoch': 23.97}
{'loss': 0.0082, 'grad_norm': 6.031338691711426, 'learning_rate': 6.046511627906977e-06, 'loss_1': 0.006662128958851099, 'loss_2': 0.0014934539794921875, 'loss_3': -16.654232025146484, 'loss_4': 1.2979116439819336, 'epoch': 23.98}
{'loss': 0.0082, 'grad_norm': 4.5968780517578125, 'learning_rate': 6.040697674418605e-06, 'loss_1': 0.0025062477216124535, 'loss_2': 0.005706787109375, 'loss_3': -16.549768447875977, 'loss_4': 1.2867385149002075, 'epoch': 23.98}
[INFO|trainer.py:4228] 2025-01-21 14:02:01,403 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:01,403 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                           | 4130/5160 [1:42:05<17:06,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 14:02:08,448 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00991213321685791, 'eval_runtime': 3.8124, 'eval_samples_per_second': 268.595, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.007469907868653536, 'eval_loss_2': 0.0024422258138656616, 'eval_loss_3': -18.182605743408203, 'eval_loss_4': 1.2102363109588623, 'epoch': 23.98}
{'loss': 0.0081, 'grad_norm': 5.159842491149902, 'learning_rate': 6.034883720930233e-06, 'loss_1': 0.007899455726146698, 'loss_2': 0.00015115737915039062, 'loss_3': -16.29073715209961, 'loss_4': 1.4614887237548828, 'epoch': 23.99}
{'loss': 0.0597, 'grad_norm': 13.487895011901855, 'learning_rate': 6.029069767441861e-06, 'loss_1': 0.04978303983807564, 'loss_2': 0.0098876953125, 'loss_3': -16.57100486755371, 'loss_4': 1.2481601238250732, 'epoch': 23.99}
{'loss': 0.0017, 'grad_norm': 8.074932098388672, 'learning_rate': 6.023255813953488e-06, 'loss_1': 0.000979515491053462, 'loss_2': 0.0007433891296386719, 'loss_3': -16.355676651000977, 'loss_4': 1.4677609205245972, 'epoch': 24.0}
{'loss': 0.0148, 'grad_norm': 10.341343879699707, 'learning_rate': 6.017441860465116e-06, 'loss_1': 0.012756381183862686, 'loss_2': 0.002056121826171875, 'loss_3': -16.42159080505371, 'loss_4': 1.7511898279190063, 'epoch': 24.01}
{'loss': 0.0064, 'grad_norm': 5.652869701385498, 'learning_rate': 6.011627906976745e-06, 'loss_1': 0.005761230364441872, 'loss_2': 0.0006475448608398438, 'loss_3': -16.393413543701172, 'loss_4': 1.1186436414718628, 'epoch': 24.01}
[INFO|trainer.py:4228] 2025-01-21 14:02:08,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:08,448 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 4135/5160 [1:42:12<17:39,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:02:15,814 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010524643585085869, 'eval_runtime': 3.8104, 'eval_samples_per_second': 268.738, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.007379001006484032, 'eval_loss_2': 0.003145642578601837, 'eval_loss_3': -18.162195205688477, 'eval_loss_4': 1.1636813879013062, 'epoch': 24.01}
{'loss': 0.0089, 'grad_norm': 5.1209893226623535, 'learning_rate': 6.005813953488372e-06, 'loss_1': 0.005754760932177305, 'loss_2': 0.003154754638671875, 'loss_3': -16.45292091369629, 'loss_4': 1.411046028137207, 'epoch': 24.02}
{'loss': 0.0186, 'grad_norm': 9.234103202819824, 'learning_rate': 6e-06, 'loss_1': 0.010736418887972832, 'loss_2': 0.00789642333984375, 'loss_3': -16.397294998168945, 'loss_4': 1.2867505550384521, 'epoch': 24.02}
{'loss': 0.0082, 'grad_norm': 5.4310302734375, 'learning_rate': 5.994186046511628e-06, 'loss_1': 0.006814461667090654, 'loss_2': 0.001392364501953125, 'loss_3': -16.59286117553711, 'loss_4': 0.9764953255653381, 'epoch': 24.03}
{'loss': 0.0371, 'grad_norm': 17.248104095458984, 'learning_rate': 5.988372093023256e-06, 'loss_1': 0.0334777906537056, 'loss_2': 0.003604888916015625, 'loss_3': -16.513900756835938, 'loss_4': 1.6109652519226074, 'epoch': 24.03}
{'loss': 0.0098, 'grad_norm': 6.704744338989258, 'learning_rate': 5.9825581395348835e-06, 'loss_1': 0.006687792483717203, 'loss_2': 0.003139495849609375, 'loss_3': -16.437511444091797, 'loss_4': 0.5611319541931152, 'epoch': 24.04}
[INFO|trainer.py:4228] 2025-01-21 14:02:15,814 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:15,814 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                           | 4140/5160 [1:42:20<17:39,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:23,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01188386045396328, 'eval_runtime': 3.8112, 'eval_samples_per_second': 268.681, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.008822387084364891, 'eval_loss_2': 0.0030614733695983887, 'eval_loss_3': -18.140316009521484, 'eval_loss_4': 1.1301417350769043, 'epoch': 24.04}
{'loss': 0.0069, 'grad_norm': 4.419443130493164, 'learning_rate': 5.976744186046512e-06, 'loss_1': 0.00392188411206007, 'loss_2': 0.0030193328857421875, 'loss_3': -16.47806739807129, 'loss_4': 1.0965540409088135, 'epoch': 24.05}
{'loss': 0.0066, 'grad_norm': 5.009739398956299, 'learning_rate': 5.97093023255814e-06, 'loss_1': 0.004126215353608131, 'loss_2': 0.002490997314453125, 'loss_3': -16.52916145324707, 'loss_4': 1.1063718795776367, 'epoch': 24.05}
{'loss': 0.0045, 'grad_norm': 4.428783416748047, 'learning_rate': 5.965116279069767e-06, 'loss_1': 0.0020406958647072315, 'loss_2': 0.0024204254150390625, 'loss_3': -16.43111801147461, 'loss_4': 0.933910071849823, 'epoch': 24.06}
{'loss': 0.0152, 'grad_norm': 11.439702033996582, 'learning_rate': 5.9593023255813955e-06, 'loss_1': 0.01472499594092369, 'loss_2': 0.0005006790161132812, 'loss_3': -16.253089904785156, 'loss_4': 1.6000754833221436, 'epoch': 24.06}
{'loss': 0.0127, 'grad_norm': 5.352145671844482, 'learning_rate': 5.953488372093023e-06, 'loss_1': 0.006108344532549381, 'loss_2': 0.006565093994140625, 'loss_3': -16.45093536376953, 'loss_4': 0.6156798005104065, 'epoch': 24.07}
[INFO|trainer.py:4228] 2025-01-21 14:02:23,176 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:23,176 >>   Batch size = 64
 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 4145/5160 [1:42:27<17:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:30,529 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012813897803425789, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.004, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.009623833000659943, 'eval_loss_2': 0.003190062940120697, 'eval_loss_3': -18.12847137451172, 'eval_loss_4': 1.0961347818374634, 'epoch': 24.07}
{'loss': 0.0085, 'grad_norm': 4.6061530113220215, 'learning_rate': 5.947674418604651e-06, 'loss_1': 0.0017968006432056427, 'loss_2': 0.0066680908203125, 'loss_3': -16.391250610351562, 'loss_4': 1.142263412475586, 'epoch': 24.08}
{'loss': 0.0068, 'grad_norm': 4.39959192276001, 'learning_rate': 5.94186046511628e-06, 'loss_1': 0.004703771788626909, 'loss_2': 0.00209808349609375, 'loss_3': -16.559589385986328, 'loss_4': 0.9853197932243347, 'epoch': 24.08}
{'loss': 0.007, 'grad_norm': 4.82015323638916, 'learning_rate': 5.9360465116279075e-06, 'loss_1': 0.002565018367022276, 'loss_2': 0.004428863525390625, 'loss_3': -16.583248138427734, 'loss_4': 0.706926167011261, 'epoch': 24.09}
{'loss': 0.0066, 'grad_norm': 4.758199691772461, 'learning_rate': 5.930232558139534e-06, 'loss_1': 0.0017564801964908838, 'loss_2': 0.00479888916015625, 'loss_3': -16.578109741210938, 'loss_4': 1.0999420881271362, 'epoch': 24.09}
{'loss': 0.0056, 'grad_norm': 5.173274040222168, 'learning_rate': 5.924418604651163e-06, 'loss_1': 0.004861967638134956, 'loss_2': 0.0007076263427734375, 'loss_3': -16.527271270751953, 'loss_4': 1.2156097888946533, 'epoch': 24.1}
[INFO|trainer.py:4228] 2025-01-21 14:02:30,529 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:30,529 >>   Batch size = 64
 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 4150/5160 [1:42:35<17:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:37,891 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01352611556649208, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.608, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.01001433003693819, 'eval_loss_2': 0.003511786460876465, 'eval_loss_3': -18.136091232299805, 'eval_loss_4': 1.06153404712677, 'epoch': 24.1}
{'loss': 0.0072, 'grad_norm': 5.374861240386963, 'learning_rate': 5.918604651162791e-06, 'loss_1': 0.005041929893195629, 'loss_2': 0.00215911865234375, 'loss_3': -16.573833465576172, 'loss_4': 0.8065658807754517, 'epoch': 24.1}
{'loss': 0.0104, 'grad_norm': 5.132641315460205, 'learning_rate': 5.912790697674419e-06, 'loss_1': 0.005474398843944073, 'loss_2': 0.004901885986328125, 'loss_3': -16.306835174560547, 'loss_4': 1.388264536857605, 'epoch': 24.11}
{'loss': 0.003, 'grad_norm': 4.669196605682373, 'learning_rate': 5.906976744186047e-06, 'loss_1': 0.00240204855799675, 'loss_2': 0.0005598068237304688, 'loss_3': -16.386505126953125, 'loss_4': 1.0370676517486572, 'epoch': 24.12}
{'loss': 0.0077, 'grad_norm': 4.654492378234863, 'learning_rate': 5.901162790697674e-06, 'loss_1': 0.002990265842527151, 'loss_2': 0.004711151123046875, 'loss_3': -16.41091537475586, 'loss_4': 1.0538140535354614, 'epoch': 24.12}
{'loss': 0.0078, 'grad_norm': 4.344208717346191, 'learning_rate': 5.895348837209302e-06, 'loss_1': 0.00543168094009161, 'loss_2': 0.002384185791015625, 'loss_3': -16.447721481323242, 'loss_4': 0.7523513436317444, 'epoch': 24.13}
[INFO|trainer.py:4228] 2025-01-21 14:02:37,891 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:37,891 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                          | 4155/5160 [1:42:42<17:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:45,260 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013556844554841518, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.418, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.01059036236256361, 'eval_loss_2': 0.0029664821922779083, 'eval_loss_3': -18.13176918029785, 'eval_loss_4': 1.0525016784667969, 'epoch': 24.13}
{'loss': 0.0057, 'grad_norm': 4.9079270362854, 'learning_rate': 5.889534883720931e-06, 'loss_1': 0.004066231660544872, 'loss_2': 0.001667022705078125, 'loss_3': -16.47620964050293, 'loss_4': 1.1895453929901123, 'epoch': 24.13}
{'loss': 0.0066, 'grad_norm': 4.6355180740356445, 'learning_rate': 5.883720930232558e-06, 'loss_1': 0.0038190148770809174, 'loss_2': 0.0027751922607421875, 'loss_3': -16.613386154174805, 'loss_4': 1.0603899955749512, 'epoch': 24.14}
{'loss': 0.0154, 'grad_norm': 10.501739501953125, 'learning_rate': 5.877906976744186e-06, 'loss_1': 0.011854423210024834, 'loss_2': 0.0035858154296875, 'loss_3': -16.210086822509766, 'loss_4': 0.3916531205177307, 'epoch': 24.15}
{'loss': 0.0067, 'grad_norm': 4.9643659591674805, 'learning_rate': 5.872093023255814e-06, 'loss_1': 0.004896498750895262, 'loss_2': 0.0017766952514648438, 'loss_3': -16.37472915649414, 'loss_4': 1.209378719329834, 'epoch': 24.15}
{'loss': 0.0134, 'grad_norm': 4.537588119506836, 'learning_rate': 5.866279069767442e-06, 'loss_1': 0.002398156560957432, 'loss_2': 0.01100921630859375, 'loss_3': -16.38133430480957, 'loss_4': 0.8329240083694458, 'epoch': 24.16}
[INFO|trainer.py:4228] 2025-01-21 14:02:45,260 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:45,260 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 4160/5160 [1:42:49<17:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:52,622 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014324270188808441, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.865, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.011067190207540989, 'eval_loss_2': 0.003257080912590027, 'eval_loss_3': -18.123390197753906, 'eval_loss_4': 1.0409449338912964, 'epoch': 24.16}
{'loss': 0.0077, 'grad_norm': 6.228837966918945, 'learning_rate': 5.8604651162790695e-06, 'loss_1': 0.006714816205203533, 'loss_2': 0.0009918212890625, 'loss_3': -16.66177749633789, 'loss_4': 0.4424899220466614, 'epoch': 24.16}
{'loss': 0.0069, 'grad_norm': 4.851190090179443, 'learning_rate': 5.854651162790698e-06, 'loss_1': 0.004568932112306356, 'loss_2': 0.0023345947265625, 'loss_3': -16.591064453125, 'loss_4': 1.0310556888580322, 'epoch': 24.17}
{'loss': 0.0113, 'grad_norm': 5.625148773193359, 'learning_rate': 5.848837209302326e-06, 'loss_1': 0.009588130749762058, 'loss_2': 0.0016651153564453125, 'loss_3': -16.528209686279297, 'loss_4': 1.0148690938949585, 'epoch': 24.17}
{'loss': 0.0064, 'grad_norm': 4.674077033996582, 'learning_rate': 5.843023255813954e-06, 'loss_1': 0.00527405459433794, 'loss_2': 0.001117706298828125, 'loss_3': -16.50409698486328, 'loss_4': 0.8348919749259949, 'epoch': 24.18}
{'loss': 0.0146, 'grad_norm': 6.803792476654053, 'learning_rate': 5.8372093023255815e-06, 'loss_1': 0.009741288609802723, 'loss_2': 0.00490570068359375, 'loss_3': -16.415443420410156, 'loss_4': 0.970401406288147, 'epoch': 24.19}
[INFO|trainer.py:4228] 2025-01-21 14:02:52,622 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:52,622 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 4165/5160 [1:42:57<17:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:02:59,977 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014552283100783825, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.01, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.011121303774416447, 'eval_loss_2': 0.003430977463722229, 'eval_loss_3': -18.110647201538086, 'eval_loss_4': 1.026915431022644, 'epoch': 24.19}
{'loss': 0.0065, 'grad_norm': 5.116827011108398, 'learning_rate': 5.831395348837209e-06, 'loss_1': 0.00400342233479023, 'loss_2': 0.0024890899658203125, 'loss_3': -16.417524337768555, 'loss_4': 1.2800962924957275, 'epoch': 24.19}
{'loss': 0.0852, 'grad_norm': 19.512300491333008, 'learning_rate': 5.825581395348837e-06, 'loss_1': 0.0739637017250061, 'loss_2': 0.011260986328125, 'loss_3': -16.43720245361328, 'loss_4': 1.4301445484161377, 'epoch': 24.2}
{'loss': 0.0095, 'grad_norm': 5.671075820922852, 'learning_rate': 5.819767441860466e-06, 'loss_1': 0.006851518992334604, 'loss_2': 0.002651214599609375, 'loss_3': -16.36898422241211, 'loss_4': 0.7605873346328735, 'epoch': 24.2}
{'loss': 0.0065, 'grad_norm': 5.228573322296143, 'learning_rate': 5.8139534883720935e-06, 'loss_1': 0.005076092202216387, 'loss_2': 0.00142669677734375, 'loss_3': -16.481246948242188, 'loss_4': 1.194742202758789, 'epoch': 24.21}
{'loss': 0.0082, 'grad_norm': 4.7925310134887695, 'learning_rate': 5.8081395348837205e-06, 'loss_1': 0.006587184499949217, 'loss_2': 0.0015659332275390625, 'loss_3': -16.337383270263672, 'loss_4': 1.1100903749465942, 'epoch': 24.22}
[INFO|trainer.py:4228] 2025-01-21 14:02:59,977 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:02:59,977 >>   Batch size = 64
 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                          | 4170/5160 [1:43:04<17:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:07,336 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01494724303483963, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.13, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.011127954348921776, 'eval_loss_2': 0.003819286823272705, 'eval_loss_3': -18.104408264160156, 'eval_loss_4': 0.9969278573989868, 'epoch': 24.22}
{'loss': 0.0046, 'grad_norm': 5.093277454376221, 'learning_rate': 5.802325581395349e-06, 'loss_1': 0.003186302026733756, 'loss_2': 0.001461029052734375, 'loss_3': -16.453777313232422, 'loss_4': 1.2291736602783203, 'epoch': 24.22}
{'loss': 0.0036, 'grad_norm': 4.591899394989014, 'learning_rate': 5.796511627906977e-06, 'loss_1': 0.003027726197615266, 'loss_2': 0.0005254745483398438, 'loss_3': -16.546497344970703, 'loss_4': 1.0084564685821533, 'epoch': 24.23}
{'loss': 0.0033, 'grad_norm': 4.556171894073486, 'learning_rate': 5.790697674418605e-06, 'loss_1': 0.002992181107401848, 'loss_2': 0.0003151893615722656, 'loss_3': -16.66927719116211, 'loss_4': 0.8682345151901245, 'epoch': 24.23}
{'loss': 0.004, 'grad_norm': 4.808009624481201, 'learning_rate': 5.784883720930233e-06, 'loss_1': 0.0034380184952169657, 'loss_2': 0.0005807876586914062, 'loss_3': -16.489212036132812, 'loss_4': 1.2886826992034912, 'epoch': 24.24}
{'loss': 0.0044, 'grad_norm': 4.533741474151611, 'learning_rate': 5.77906976744186e-06, 'loss_1': 0.0031221548561006784, 'loss_2': 0.001285552978515625, 'loss_3': -16.56360626220703, 'loss_4': 0.9910280704498291, 'epoch': 24.24}
[INFO|trainer.py:4228] 2025-01-21 14:03:07,336 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:07,336 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                         | 4175/5160 [1:43:11<17:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:14,693 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014409061521291733, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.038, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.011189188808202744, 'eval_loss_2': 0.0032198727130889893, 'eval_loss_3': -18.117998123168945, 'eval_loss_4': 1.0098837614059448, 'epoch': 24.24}
{'loss': 0.0096, 'grad_norm': 4.925114154815674, 'learning_rate': 5.773255813953488e-06, 'loss_1': 0.004648968111723661, 'loss_2': 0.00493621826171875, 'loss_3': -16.255680084228516, 'loss_4': 1.4439570903778076, 'epoch': 24.25}
{'loss': 0.0042, 'grad_norm': 4.986214637756348, 'learning_rate': 5.767441860465117e-06, 'loss_1': 0.0030547340866178274, 'loss_2': 0.0011196136474609375, 'loss_3': -16.649234771728516, 'loss_4': 1.0103726387023926, 'epoch': 24.26}
{'loss': 0.0052, 'grad_norm': 4.1592278480529785, 'learning_rate': 5.7616279069767444e-06, 'loss_1': 0.0022824436891824007, 'loss_2': 0.0029144287109375, 'loss_3': -16.605199813842773, 'loss_4': 0.9971508979797363, 'epoch': 24.26}
{'loss': 0.0057, 'grad_norm': 4.33477783203125, 'learning_rate': 5.755813953488372e-06, 'loss_1': 0.0031647488940507174, 'loss_2': 0.0025177001953125, 'loss_3': -16.65509796142578, 'loss_4': 0.702983021736145, 'epoch': 24.27}
{'loss': 0.0139, 'grad_norm': 7.411831855773926, 'learning_rate': 5.750000000000001e-06, 'loss_1': 0.012181277386844158, 'loss_2': 0.001750946044921875, 'loss_3': -16.452960968017578, 'loss_4': 1.0612889528274536, 'epoch': 24.27}
[INFO|trainer.py:4228] 2025-01-21 14:03:14,694 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:14,694 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                         | 4180/5160 [1:43:19<17:12,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:03:22,258 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.013026807457208633, 'eval_runtime': 4.0156, 'eval_samples_per_second': 255.006, 'eval_steps_per_second': 3.984, 'eval_loss_1': 0.00992337241768837, 'eval_loss_2': 0.0031034350395202637, 'eval_loss_3': -18.12238883972168, 'eval_loss_4': 1.0053764581680298, 'epoch': 24.27}
{'loss': 0.0036, 'grad_norm': 4.638820648193359, 'learning_rate': 5.744186046511628e-06, 'loss_1': 0.0027955900877714157, 'loss_2': 0.0008459091186523438, 'loss_3': -16.5490665435791, 'loss_4': 0.8198828101158142, 'epoch': 24.28}
{'loss': 0.0072, 'grad_norm': 5.469115734100342, 'learning_rate': 5.7383720930232556e-06, 'loss_1': 0.004347833339124918, 'loss_2': 0.002864837646484375, 'loss_3': -16.405960083007812, 'loss_4': 0.6728464365005493, 'epoch': 24.28}
{'loss': 0.0565, 'grad_norm': 12.651681900024414, 'learning_rate': 5.732558139534884e-06, 'loss_1': 0.04648669436573982, 'loss_2': 0.010009765625, 'loss_3': -16.492156982421875, 'loss_4': 1.4204051494598389, 'epoch': 24.29}
{'loss': 0.0071, 'grad_norm': 4.70084285736084, 'learning_rate': 5.726744186046512e-06, 'loss_1': 0.0065554543398320675, 'loss_2': 0.0005822181701660156, 'loss_3': -16.390939712524414, 'loss_4': 0.9765868186950684, 'epoch': 24.3}
{'loss': 0.012, 'grad_norm': 7.9692063331604, 'learning_rate': 5.72093023255814e-06, 'loss_1': 0.008535103872418404, 'loss_2': 0.003437042236328125, 'loss_3': -16.185535430908203, 'loss_4': 1.3546626567840576, 'epoch': 24.3}
[INFO|trainer.py:4228] 2025-01-21 14:03:22,258 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:22,258 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 4185/5160 [1:43:26<16:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:29,613 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012834761291742325, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.863, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00964275375008583, 'eval_loss_2': 0.003192007541656494, 'eval_loss_3': -18.12529754638672, 'eval_loss_4': 0.9905093908309937, 'epoch': 24.3}
{'loss': 0.0042, 'grad_norm': 4.388538360595703, 'learning_rate': 5.7151162790697676e-06, 'loss_1': 0.003426135517656803, 'loss_2': 0.0007429122924804688, 'loss_3': -16.625720977783203, 'loss_4': 1.3765265941619873, 'epoch': 24.31}
{'loss': 0.0087, 'grad_norm': 6.4749321937561035, 'learning_rate': 5.709302325581395e-06, 'loss_1': 0.006675075273960829, 'loss_2': 0.001987457275390625, 'loss_3': -16.440134048461914, 'loss_4': 1.0413343906402588, 'epoch': 24.31}
{'loss': 0.0069, 'grad_norm': 5.357086181640625, 'learning_rate': 5.703488372093023e-06, 'loss_1': 0.0038852544967085123, 'loss_2': 0.00299835205078125, 'loss_3': -16.428756713867188, 'loss_4': 0.7712750434875488, 'epoch': 24.32}
{'loss': 0.0041, 'grad_norm': 4.921779155731201, 'learning_rate': 5.697674418604652e-06, 'loss_1': 0.0026358412578701973, 'loss_2': 0.00145721435546875, 'loss_3': -16.504436492919922, 'loss_4': 0.6786676645278931, 'epoch': 24.33}
{'loss': 0.0119, 'grad_norm': 8.681621551513672, 'learning_rate': 5.6918604651162796e-06, 'loss_1': 0.011605984531342983, 'loss_2': 0.0003147125244140625, 'loss_3': -16.390777587890625, 'loss_4': 1.286297082901001, 'epoch': 24.33}
[INFO|trainer.py:4228] 2025-01-21 14:03:29,614 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:29,614 >>   Batch size = 64
 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                         | 4190/5160 [1:43:34<16:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:36,971 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014064285904169083, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.974, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.010576496832072735, 'eval_loss_2': 0.003487788140773773, 'eval_loss_3': -18.126733779907227, 'eval_loss_4': 0.9902242422103882, 'epoch': 24.33}
{'loss': 0.0059, 'grad_norm': 5.329553127288818, 'learning_rate': 5.6860465116279065e-06, 'loss_1': 0.005715411156415939, 'loss_2': 0.00016164779663085938, 'loss_3': -16.347673416137695, 'loss_4': 0.8879128098487854, 'epoch': 24.34}
{'loss': 0.0077, 'grad_norm': 5.354909420013428, 'learning_rate': 5.680232558139535e-06, 'loss_1': 0.00489854346960783, 'loss_2': 0.00279998779296875, 'loss_3': -16.545574188232422, 'loss_4': 1.0727591514587402, 'epoch': 24.34}
{'loss': 0.0111, 'grad_norm': 4.667087078094482, 'learning_rate': 5.674418604651163e-06, 'loss_1': 0.007485023699700832, 'loss_2': 0.003635406494140625, 'loss_3': -16.30832862854004, 'loss_4': 0.679262638092041, 'epoch': 24.35}
{'loss': 0.0089, 'grad_norm': 5.789366245269775, 'learning_rate': 5.668604651162791e-06, 'loss_1': 0.006546441465616226, 'loss_2': 0.002323150634765625, 'loss_3': -16.45948600769043, 'loss_4': 0.9736090898513794, 'epoch': 24.35}
{'loss': 0.0151, 'grad_norm': 6.5588154792785645, 'learning_rate': 5.662790697674419e-06, 'loss_1': 0.012814810499548912, 'loss_2': 0.0022602081298828125, 'loss_3': -16.35909652709961, 'loss_4': 0.973622739315033, 'epoch': 24.36}
[INFO|trainer.py:4228] 2025-01-21 14:03:36,971 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:36,971 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                         | 4195/5160 [1:43:41<16:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:44,328 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014284264296293259, 'eval_runtime': 3.8101, 'eval_samples_per_second': 268.756, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.011593888513743877, 'eval_loss_2': 0.0026903748512268066, 'eval_loss_3': -18.123050689697266, 'eval_loss_4': 0.9516305327415466, 'epoch': 24.36}
{'loss': 0.0121, 'grad_norm': 7.501317024230957, 'learning_rate': 5.656976744186047e-06, 'loss_1': 0.009342570789158344, 'loss_2': 0.002796173095703125, 'loss_3': -16.323415756225586, 'loss_4': 1.206091284751892, 'epoch': 24.37}
{'loss': 0.0051, 'grad_norm': 5.22225284576416, 'learning_rate': 5.651162790697674e-06, 'loss_1': 0.00431857630610466, 'loss_2': 0.0007534027099609375, 'loss_3': -16.445220947265625, 'loss_4': 0.6493989825248718, 'epoch': 24.37}
{'loss': 0.0411, 'grad_norm': 14.2317476272583, 'learning_rate': 5.645348837209303e-06, 'loss_1': 0.038748662918806076, 'loss_2': 0.0023059844970703125, 'loss_3': -16.55786895751953, 'loss_4': 0.9948458671569824, 'epoch': 24.38}
{'loss': 0.0049, 'grad_norm': 4.713533401489258, 'learning_rate': 5.6395348837209305e-06, 'loss_1': 0.0026505356654524803, 'loss_2': 0.002288818359375, 'loss_3': -16.376352310180664, 'loss_4': 0.798224925994873, 'epoch': 24.38}
{'loss': 0.011, 'grad_norm': 5.210760116577148, 'learning_rate': 5.633720930232558e-06, 'loss_1': 0.007095835171639919, 'loss_2': 0.0038852691650390625, 'loss_3': -16.47089385986328, 'loss_4': 1.3085072040557861, 'epoch': 24.39}
[INFO|trainer.py:4228] 2025-01-21 14:03:44,328 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:44,328 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                        | 4200/5160 [1:43:48<16:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:51,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.01378507912158966, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.943, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.011712893843650818, 'eval_loss_2': 0.0020721852779388428, 'eval_loss_3': -18.126144409179688, 'eval_loss_4': 0.9386245608329773, 'epoch': 24.39}
{'loss': 0.0062, 'grad_norm': 4.934542179107666, 'learning_rate': 5.627906976744187e-06, 'loss_1': 0.0034809026401489973, 'loss_2': 0.002696990966796875, 'loss_3': -16.464262008666992, 'loss_4': 0.8919936418533325, 'epoch': 24.4}
{'loss': 0.0102, 'grad_norm': 4.672119140625, 'learning_rate': 5.622093023255814e-06, 'loss_1': 0.0023811962455511093, 'loss_2': 0.007801055908203125, 'loss_3': -16.33612632751465, 'loss_4': 1.0571355819702148, 'epoch': 24.4}
{'loss': 0.0107, 'grad_norm': 4.918354034423828, 'learning_rate': 5.616279069767442e-06, 'loss_1': 0.0026432047598063946, 'loss_2': 0.0081024169921875, 'loss_3': -16.286842346191406, 'loss_4': 0.7447144985198975, 'epoch': 24.41}
{'loss': 0.0092, 'grad_norm': 4.643004894256592, 'learning_rate': 5.61046511627907e-06, 'loss_1': 0.0034696951042860746, 'loss_2': 0.0056915283203125, 'loss_3': -16.263179779052734, 'loss_4': 1.0389865636825562, 'epoch': 24.41}
{'loss': 0.0068, 'grad_norm': 6.144087314605713, 'learning_rate': 5.604651162790698e-06, 'loss_1': 0.0051829698495566845, 'loss_2': 0.00157928466796875, 'loss_3': -16.420948028564453, 'loss_4': 0.7917022705078125, 'epoch': 24.42}
[INFO|trainer.py:4228] 2025-01-21 14:03:51,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:51,688 >>   Batch size = 64
 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 4205/5160 [1:43:56<16:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:03:59,048 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.014600113034248352, 'eval_runtime': 3.8102, 'eval_samples_per_second': 268.753, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.01251149270683527, 'eval_loss_2': 0.0020886212587356567, 'eval_loss_3': -18.116079330444336, 'eval_loss_4': 0.9378595352172852, 'epoch': 24.42}
{'loss': 0.0145, 'grad_norm': 4.9688496589660645, 'learning_rate': 5.598837209302326e-06, 'loss_1': 0.010550962761044502, 'loss_2': 0.00392913818359375, 'loss_3': -16.496728897094727, 'loss_4': 1.2604988813400269, 'epoch': 24.42}
{'loss': 0.0102, 'grad_norm': 4.542471885681152, 'learning_rate': 5.593023255813954e-06, 'loss_1': 0.004403344821184874, 'loss_2': 0.0058441162109375, 'loss_3': -16.641752243041992, 'loss_4': 0.705541729927063, 'epoch': 24.43}
{'loss': 0.0134, 'grad_norm': 7.213434219360352, 'learning_rate': 5.587209302325581e-06, 'loss_1': 0.007803700864315033, 'loss_2': 0.00554656982421875, 'loss_3': -16.572711944580078, 'loss_4': 0.8861675262451172, 'epoch': 24.44}
{'loss': 0.01, 'grad_norm': 4.775389671325684, 'learning_rate': 5.581395348837209e-06, 'loss_1': 0.004067960195243359, 'loss_2': 0.00588226318359375, 'loss_3': -16.353551864624023, 'loss_4': 0.957119345664978, 'epoch': 24.44}
{'loss': 0.0135, 'grad_norm': 6.567101955413818, 'learning_rate': 5.575581395348838e-06, 'loss_1': 0.011136142536997795, 'loss_2': 0.0023784637451171875, 'loss_3': -16.435688018798828, 'loss_4': 1.1834555864334106, 'epoch': 24.45}
[INFO|trainer.py:4228] 2025-01-21 14:03:59,048 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:03:59,048 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                        | 4210/5160 [1:44:03<16:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:06,419 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.012773951515555382, 'eval_runtime': 3.8151, 'eval_samples_per_second': 268.407, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.011207855306565762, 'eval_loss_2': 0.0015660971403121948, 'eval_loss_3': -18.125112533569336, 'eval_loss_4': 0.9996844530105591, 'epoch': 24.45}
{'loss': 0.0065, 'grad_norm': 4.7473883628845215, 'learning_rate': 5.569767441860466e-06, 'loss_1': 0.0033215831499546766, 'loss_2': 0.00315093994140625, 'loss_3': -16.47211456298828, 'loss_4': 0.7837890386581421, 'epoch': 24.45}
{'loss': 0.0079, 'grad_norm': 5.551247596740723, 'learning_rate': 5.563953488372093e-06, 'loss_1': 0.0036072784569114447, 'loss_2': 0.00432586669921875, 'loss_3': -16.55224609375, 'loss_4': 1.057230830192566, 'epoch': 24.46}
{'loss': 0.0134, 'grad_norm': 5.809818744659424, 'learning_rate': 5.558139534883721e-06, 'loss_1': 0.010614259168505669, 'loss_2': 0.002780914306640625, 'loss_3': -16.214435577392578, 'loss_4': 1.2113454341888428, 'epoch': 24.47}
{'loss': 0.0055, 'grad_norm': 5.3858842849731445, 'learning_rate': 5.552325581395349e-06, 'loss_1': 0.005407296121120453, 'loss_2': 0.0001354217529296875, 'loss_3': -16.49888801574707, 'loss_4': 0.7193372845649719, 'epoch': 24.47}
{'loss': 0.0051, 'grad_norm': 5.295589447021484, 'learning_rate': 5.546511627906977e-06, 'loss_1': 0.0034223939292132854, 'loss_2': 0.0016870498657226562, 'loss_3': -16.491573333740234, 'loss_4': 1.0230991840362549, 'epoch': 24.48}
[INFO|trainer.py:4228] 2025-01-21 14:04:06,419 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:06,419 >>   Batch size = 64
 82%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                        | 4215/5160 [1:44:10<16:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:13,778 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011571111157536507, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.108, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.009344750083982944, 'eval_loss_2': 0.0022263601422309875, 'eval_loss_3': -18.138559341430664, 'eval_loss_4': 1.063761830329895, 'epoch': 24.48}
{'loss': 0.0258, 'grad_norm': 9.180360794067383, 'learning_rate': 5.540697674418605e-06, 'loss_1': 0.0166623517870903, 'loss_2': 0.00914764404296875, 'loss_3': -16.54258918762207, 'loss_4': 1.0908477306365967, 'epoch': 24.48}
{'loss': 0.007, 'grad_norm': 4.734339714050293, 'learning_rate': 5.534883720930233e-06, 'loss_1': 0.003798913210630417, 'loss_2': 0.003208160400390625, 'loss_3': -16.741369247436523, 'loss_4': 1.0051164627075195, 'epoch': 24.49}
{'loss': 0.0075, 'grad_norm': 6.643988132476807, 'learning_rate': 5.52906976744186e-06, 'loss_1': 0.004722564946860075, 'loss_2': 0.00276947021484375, 'loss_3': -16.534496307373047, 'loss_4': 0.8483826518058777, 'epoch': 24.49}
{'loss': 0.01, 'grad_norm': 6.166674613952637, 'learning_rate': 5.523255813953489e-06, 'loss_1': 0.0076874191872775555, 'loss_2': 0.0023288726806640625, 'loss_3': -16.39739990234375, 'loss_4': 0.7962672114372253, 'epoch': 24.5}
{'loss': 0.0048, 'grad_norm': 4.805750846862793, 'learning_rate': 5.5174418604651165e-06, 'loss_1': 0.004703505430370569, 'loss_2': 0.0001323223114013672, 'loss_3': -16.459009170532227, 'loss_4': 0.8848205804824829, 'epoch': 24.51}
[INFO|trainer.py:4228] 2025-01-21 14:04:13,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:13,779 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                        | 4220/5160 [1:44:18<16:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:21,144 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.011584447696805, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.898, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.008723885752260685, 'eval_loss_2': 0.0028605610132217407, 'eval_loss_3': -18.124048233032227, 'eval_loss_4': 1.0779839754104614, 'epoch': 24.51}
{'loss': 0.0071, 'grad_norm': 4.626145839691162, 'learning_rate': 5.511627906976744e-06, 'loss_1': 0.003976320382207632, 'loss_2': 0.0031280517578125, 'loss_3': -16.31863021850586, 'loss_4': 1.0842876434326172, 'epoch': 24.51}
{'loss': 0.0068, 'grad_norm': 4.637507438659668, 'learning_rate': 5.505813953488373e-06, 'loss_1': 0.0033132010139524937, 'loss_2': 0.00351715087890625, 'loss_3': -16.46267318725586, 'loss_4': 0.9714286923408508, 'epoch': 24.52}
{'loss': 0.0077, 'grad_norm': 4.632844924926758, 'learning_rate': 5.5e-06, 'loss_1': 0.006260094698518515, 'loss_2': 0.0014286041259765625, 'loss_3': -16.244659423828125, 'loss_4': 0.9616199731826782, 'epoch': 24.52}
{'loss': 0.1212, 'grad_norm': 22.67855453491211, 'learning_rate': 5.494186046511628e-06, 'loss_1': 0.11016374081373215, 'loss_2': 0.01100921630859375, 'loss_3': -16.454439163208008, 'loss_4': 1.006063461303711, 'epoch': 24.53}
{'loss': 0.006, 'grad_norm': 4.8570146560668945, 'learning_rate': 5.488372093023256e-06, 'loss_1': 0.0034838856663554907, 'loss_2': 0.0024967193603515625, 'loss_3': -16.3908748626709, 'loss_4': 0.9207376837730408, 'epoch': 24.53}
[INFO|trainer.py:4228] 2025-01-21 14:04:21,144 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:21,144 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                       | 4225/5160 [1:44:25<16:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:28,512 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0119711235165596, 'eval_runtime': 3.8172, 'eval_samples_per_second': 268.26, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.008266935124993324, 'eval_loss_2': 0.0037041902542114258, 'eval_loss_3': -18.13704490661621, 'eval_loss_4': 1.0835041999816895, 'epoch': 24.53}
{'loss': 0.0122, 'grad_norm': 7.635946750640869, 'learning_rate': 5.482558139534884e-06, 'loss_1': 0.009376193396747112, 'loss_2': 0.0028076171875, 'loss_3': -16.568607330322266, 'loss_4': 1.4056684970855713, 'epoch': 24.54}
{'loss': 0.0161, 'grad_norm': 7.453466892242432, 'learning_rate': 5.476744186046512e-06, 'loss_1': 0.013693064451217651, 'loss_2': 0.00241851806640625, 'loss_3': -16.4534912109375, 'loss_4': 0.6567866206169128, 'epoch': 24.55}
{'loss': 0.0142, 'grad_norm': 9.440658569335938, 'learning_rate': 5.4709302325581405e-06, 'loss_1': 0.013675827533006668, 'loss_2': 0.0005369186401367188, 'loss_3': -16.407135009765625, 'loss_4': 1.3014851808547974, 'epoch': 24.55}
{'loss': 0.0223, 'grad_norm': 8.54836654663086, 'learning_rate': 5.465116279069767e-06, 'loss_1': 0.014502445235848427, 'loss_2': 0.0077972412109375, 'loss_3': -16.393918991088867, 'loss_4': 1.1134238243103027, 'epoch': 24.56}
{'loss': 0.0158, 'grad_norm': 5.940758228302002, 'learning_rate': 5.459302325581395e-06, 'loss_1': 0.00592608330771327, 'loss_2': 0.00991058349609375, 'loss_3': -16.357677459716797, 'loss_4': 1.1722896099090576, 'epoch': 24.56}
[INFO|trainer.py:4228] 2025-01-21 14:04:28,512 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:28,513 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                       | 4230/5160 [1:44:33<16:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:35,870 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.010814020410180092, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.916, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0075159757398068905, 'eval_loss_2': 0.003298044204711914, 'eval_loss_3': -18.144817352294922, 'eval_loss_4': 1.0864824056625366, 'epoch': 24.56}
{'loss': 0.0174, 'grad_norm': 5.496116638183594, 'learning_rate': 5.453488372093024e-06, 'loss_1': 0.007440180517733097, 'loss_2': 0.0099334716796875, 'loss_3': -16.335660934448242, 'loss_4': 0.7133513689041138, 'epoch': 24.57}
{'loss': 0.0074, 'grad_norm': 5.868042945861816, 'learning_rate': 5.447674418604652e-06, 'loss_1': 0.005175743252038956, 'loss_2': 0.0022487640380859375, 'loss_3': -16.385631561279297, 'loss_4': 0.6650944948196411, 'epoch': 24.58}
{'loss': 0.0098, 'grad_norm': 4.805234909057617, 'learning_rate': 5.441860465116279e-06, 'loss_1': 0.003455324098467827, 'loss_2': 0.00634765625, 'loss_3': -16.487571716308594, 'loss_4': 0.9505277872085571, 'epoch': 24.58}
{'loss': 0.0077, 'grad_norm': 4.494739055633545, 'learning_rate': 5.436046511627907e-06, 'loss_1': 0.005189389921724796, 'loss_2': 0.002552032470703125, 'loss_3': -16.37078094482422, 'loss_4': 0.8491946458816528, 'epoch': 24.59}
{'loss': 0.0104, 'grad_norm': 4.6951494216918945, 'learning_rate': 5.430232558139535e-06, 'loss_1': 0.005257334094494581, 'loss_2': 0.00510406494140625, 'loss_3': -16.543350219726562, 'loss_4': 1.3783693313598633, 'epoch': 24.59}
[INFO|trainer.py:4228] 2025-01-21 14:04:35,871 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:35,871 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 4235/5160 [1:44:40<16:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:43,241 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008854747749865055, 'eval_runtime': 3.8134, 'eval_samples_per_second': 268.53, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.006400284823030233, 'eval_loss_2': 0.002454463392496109, 'eval_loss_3': -18.15036392211914, 'eval_loss_4': 1.1196306943893433, 'epoch': 24.59}
{'loss': 0.0103, 'grad_norm': 4.691203594207764, 'learning_rate': 5.424418604651163e-06, 'loss_1': 0.0038587588351219893, 'loss_2': 0.00643157958984375, 'loss_3': -16.49311065673828, 'loss_4': 0.9033150672912598, 'epoch': 24.6}
{'loss': 0.0046, 'grad_norm': 5.42735481262207, 'learning_rate': 5.4186046511627905e-06, 'loss_1': 0.0045181093737483025, 'loss_2': 0.00010037422180175781, 'loss_3': -16.388442993164062, 'loss_4': 1.2434316873550415, 'epoch': 24.6}
{'loss': 0.0152, 'grad_norm': 7.445025444030762, 'learning_rate': 5.412790697674419e-06, 'loss_1': 0.011285832151770592, 'loss_2': 0.0038700103759765625, 'loss_3': -16.60211181640625, 'loss_4': 1.237079381942749, 'epoch': 24.61}
{'loss': 0.005, 'grad_norm': 5.052540302276611, 'learning_rate': 5.406976744186046e-06, 'loss_1': 0.00357228796929121, 'loss_2': 0.00140380859375, 'loss_3': -16.59143829345703, 'loss_4': 1.2289947271347046, 'epoch': 24.62}
{'loss': 0.0118, 'grad_norm': 8.415809631347656, 'learning_rate': 5.401162790697674e-06, 'loss_1': 0.01040205080062151, 'loss_2': 0.0014019012451171875, 'loss_3': -16.662208557128906, 'loss_4': 1.2144068479537964, 'epoch': 24.62}
[INFO|trainer.py:4228] 2025-01-21 14:04:43,241 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:43,241 >>   Batch size = 64
 82%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                       | 4240/5160 [1:44:47<15:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:50,606 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008519736118614674, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.726, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.006385107524693012, 'eval_loss_2': 0.0021346285939216614, 'eval_loss_3': -18.16133689880371, 'eval_loss_4': 1.1630890369415283, 'epoch': 24.62}
{'loss': 0.0179, 'grad_norm': 9.282337188720703, 'learning_rate': 5.3953488372093025e-06, 'loss_1': 0.015806518495082855, 'loss_2': 0.0020885467529296875, 'loss_3': -16.435441970825195, 'loss_4': 1.231330156326294, 'epoch': 24.63}
{'loss': 0.0059, 'grad_norm': 6.4347310066223145, 'learning_rate': 5.38953488372093e-06, 'loss_1': 0.004581015091389418, 'loss_2': 0.0013360977172851562, 'loss_3': -16.554222106933594, 'loss_4': 1.6286879777908325, 'epoch': 24.63}
{'loss': 0.0097, 'grad_norm': 5.309844493865967, 'learning_rate': 5.383720930232558e-06, 'loss_1': 0.005600443109869957, 'loss_2': 0.004119873046875, 'loss_3': -16.36131477355957, 'loss_4': 1.3332130908966064, 'epoch': 24.64}
{'loss': 0.0665, 'grad_norm': 17.8907413482666, 'learning_rate': 5.377906976744187e-06, 'loss_1': 0.06605610996484756, 'loss_2': 0.00046634674072265625, 'loss_3': -16.46917152404785, 'loss_4': 1.4081614017486572, 'epoch': 24.65}
{'loss': 0.0099, 'grad_norm': 4.609103679656982, 'learning_rate': 5.372093023255814e-06, 'loss_1': 0.006736897863447666, 'loss_2': 0.003170013427734375, 'loss_3': -16.257585525512695, 'loss_4': 1.0511877536773682, 'epoch': 24.65}
[INFO|trainer.py:4228] 2025-01-21 14:04:50,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:50,607 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                      | 4245/5160 [1:44:55<15:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:04:57,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008485387079417706, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.959, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.007075395435094833, 'eval_loss_2': 0.0014099925756454468, 'eval_loss_3': -18.150859832763672, 'eval_loss_4': 1.1707602739334106, 'epoch': 24.65}
{'loss': 0.0063, 'grad_norm': 4.676287651062012, 'learning_rate': 5.3662790697674415e-06, 'loss_1': 0.0023162374272942543, 'loss_2': 0.00394439697265625, 'loss_3': -16.39517593383789, 'loss_4': 0.9765992164611816, 'epoch': 24.66}
{'loss': 0.0101, 'grad_norm': 5.3776960372924805, 'learning_rate': 5.36046511627907e-06, 'loss_1': 0.004483936820179224, 'loss_2': 0.005584716796875, 'loss_3': -16.336793899536133, 'loss_4': 1.5069093704223633, 'epoch': 24.66}
{'loss': 0.0058, 'grad_norm': 4.800711631774902, 'learning_rate': 5.354651162790698e-06, 'loss_1': 0.0047513628378510475, 'loss_2': 0.001049041748046875, 'loss_3': -16.56338119506836, 'loss_4': 1.3953673839569092, 'epoch': 24.67}
{'loss': 0.0209, 'grad_norm': 12.496902465820312, 'learning_rate': 5.348837209302326e-06, 'loss_1': 0.016779562458395958, 'loss_2': 0.0041046142578125, 'loss_3': -16.575016021728516, 'loss_4': 1.3333208560943604, 'epoch': 24.67}
{'loss': 0.0088, 'grad_norm': 5.8576741218566895, 'learning_rate': 5.3430232558139534e-06, 'loss_1': 0.00767940329387784, 'loss_2': 0.0011425018310546875, 'loss_3': -16.534568786621094, 'loss_4': 1.319857120513916, 'epoch': 24.68}
[INFO|trainer.py:4228] 2025-01-21 14:04:57,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:04:57,963 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 4250/5160 [1:45:02<15:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:05,318 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00860997848212719, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.985, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0067286184057593346, 'eval_loss_2': 0.0018813610076904297, 'eval_loss_3': -18.16543197631836, 'eval_loss_4': 1.1598427295684814, 'epoch': 24.68}
{'loss': 0.0108, 'grad_norm': 5.292895793914795, 'learning_rate': 5.337209302325581e-06, 'loss_1': 0.004654809832572937, 'loss_2': 0.00609588623046875, 'loss_3': -16.52029037475586, 'loss_4': 1.1334336996078491, 'epoch': 24.69}
{'loss': 0.0113, 'grad_norm': 6.233679294586182, 'learning_rate': 5.331395348837209e-06, 'loss_1': 0.00665988028049469, 'loss_2': 0.004669189453125, 'loss_3': -16.48645782470703, 'loss_4': 1.00456702709198, 'epoch': 24.69}
{'loss': 0.009, 'grad_norm': 5.269312858581543, 'learning_rate': 5.325581395348838e-06, 'loss_1': 0.007977315224707127, 'loss_2': 0.0010633468627929688, 'loss_3': -16.422292709350586, 'loss_4': 0.7922874093055725, 'epoch': 24.7}
{'loss': 0.0121, 'grad_norm': 5.2685112953186035, 'learning_rate': 5.3197674418604654e-06, 'loss_1': 0.006031415890902281, 'loss_2': 0.00601959228515625, 'loss_3': -16.364166259765625, 'loss_4': 0.9590351581573486, 'epoch': 24.7}
{'loss': 0.0053, 'grad_norm': 4.9684624671936035, 'learning_rate': 5.313953488372092e-06, 'loss_1': 0.004496175330132246, 'loss_2': 0.0008172988891601562, 'loss_3': -16.588085174560547, 'loss_4': 1.0036317110061646, 'epoch': 24.71}
[INFO|trainer.py:4228] 2025-01-21 14:05:05,318 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:05,318 >>   Batch size = 64
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                      | 4255/5160 [1:45:09<15:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:12,683 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008227970451116562, 'eval_runtime': 3.8149, 'eval_samples_per_second': 268.422, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.006318132858723402, 'eval_loss_2': 0.0019098371267318726, 'eval_loss_3': -18.17221450805664, 'eval_loss_4': 1.1327775716781616, 'epoch': 24.71}
{'loss': 0.0152, 'grad_norm': 6.0184326171875, 'learning_rate': 5.308139534883721e-06, 'loss_1': 0.013653570786118507, 'loss_2': 0.00154876708984375, 'loss_3': -16.61107635498047, 'loss_4': 1.1932570934295654, 'epoch': 24.72}
{'loss': 0.011, 'grad_norm': 5.204884052276611, 'learning_rate': 5.302325581395349e-06, 'loss_1': 0.005347477272152901, 'loss_2': 0.00562286376953125, 'loss_3': -16.427997589111328, 'loss_4': 1.3004947900772095, 'epoch': 24.72}
{'loss': 0.0082, 'grad_norm': 5.94456672668457, 'learning_rate': 5.296511627906977e-06, 'loss_1': 0.0057572973892092705, 'loss_2': 0.0024566650390625, 'loss_3': -16.356414794921875, 'loss_4': 0.6728354692459106, 'epoch': 24.73}
{'loss': 0.0069, 'grad_norm': 4.62262487411499, 'learning_rate': 5.290697674418605e-06, 'loss_1': 0.002789167920127511, 'loss_2': 0.0041046142578125, 'loss_3': -16.271156311035156, 'loss_4': 1.079581379890442, 'epoch': 24.73}
{'loss': 0.0057, 'grad_norm': 4.879852294921875, 'learning_rate': 5.284883720930233e-06, 'loss_1': 0.00392031529918313, 'loss_2': 0.0017795562744140625, 'loss_3': -16.553739547729492, 'loss_4': 1.1572250127792358, 'epoch': 24.74}
[INFO|trainer.py:4228] 2025-01-21 14:05:12,684 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:12,684 >>   Batch size = 64
 83%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 4260/5160 [1:45:17<15:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:20,047 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008543049916625023, 'eval_runtime': 3.8118, 'eval_samples_per_second': 268.638, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0064584072679281235, 'eval_loss_2': 0.0020846426486968994, 'eval_loss_3': -18.1694278717041, 'eval_loss_4': 1.1128871440887451, 'epoch': 24.74}
{'loss': 0.0104, 'grad_norm': 5.144291400909424, 'learning_rate': 5.27906976744186e-06, 'loss_1': 0.005394631996750832, 'loss_2': 0.00501251220703125, 'loss_3': -16.368927001953125, 'loss_4': 0.8286024928092957, 'epoch': 24.74}
{'loss': 0.0116, 'grad_norm': 5.508936405181885, 'learning_rate': 5.2732558139534886e-06, 'loss_1': 0.006901685614138842, 'loss_2': 0.0047454833984375, 'loss_3': -16.583253860473633, 'loss_4': 1.2526907920837402, 'epoch': 24.75}
{'loss': 0.0051, 'grad_norm': 4.898060321807861, 'learning_rate': 5.267441860465116e-06, 'loss_1': 0.0036001885309815407, 'loss_2': 0.001491546630859375, 'loss_3': -16.52202606201172, 'loss_4': 1.2240362167358398, 'epoch': 24.76}
{'loss': 0.0109, 'grad_norm': 4.496150016784668, 'learning_rate': 5.261627906976744e-06, 'loss_1': 0.005534320138394833, 'loss_2': 0.005405426025390625, 'loss_3': -16.391277313232422, 'loss_4': 1.0548858642578125, 'epoch': 24.76}
{'loss': 0.0231, 'grad_norm': 11.012322425842285, 'learning_rate': 5.255813953488373e-06, 'loss_1': 0.02311219833791256, 'loss_2': 2.664327621459961e-05, 'loss_3': -16.508804321289062, 'loss_4': 1.062406063079834, 'epoch': 24.77}
[INFO|trainer.py:4228] 2025-01-21 14:05:20,047 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:20,047 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                      | 4265/5160 [1:45:24<15:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:27,417 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008562812581658363, 'eval_runtime': 3.8217, 'eval_samples_per_second': 267.943, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.006446852348744869, 'eval_loss_2': 0.0021159611642360687, 'eval_loss_3': -18.158634185791016, 'eval_loss_4': 1.0678457021713257, 'epoch': 24.77}
{'loss': 0.0083, 'grad_norm': 4.8138017654418945, 'learning_rate': 5.25e-06, 'loss_1': 0.005073470529168844, 'loss_2': 0.0032176971435546875, 'loss_3': -16.40677833557129, 'loss_4': 1.0434234142303467, 'epoch': 24.77}
{'loss': 0.0082, 'grad_norm': 5.328327655792236, 'learning_rate': 5.2441860465116275e-06, 'loss_1': 0.005389812868088484, 'loss_2': 0.00278472900390625, 'loss_3': -16.440221786499023, 'loss_4': 1.0115532875061035, 'epoch': 24.78}
{'loss': 0.0038, 'grad_norm': 4.728994369506836, 'learning_rate': 5.238372093023256e-06, 'loss_1': 0.0026279082521796227, 'loss_2': 0.0011844635009765625, 'loss_3': -16.656951904296875, 'loss_4': 1.2358760833740234, 'epoch': 24.78}
{'loss': 0.0114, 'grad_norm': 4.430784702301025, 'learning_rate': 5.232558139534884e-06, 'loss_1': 0.0028761466965079308, 'loss_2': 0.0085601806640625, 'loss_3': -16.342844009399414, 'loss_4': 0.7360678911209106, 'epoch': 24.79}
{'loss': 0.0108, 'grad_norm': 8.660995483398438, 'learning_rate': 5.226744186046512e-06, 'loss_1': 0.009080123156309128, 'loss_2': 0.00174713134765625, 'loss_3': -16.667158126831055, 'loss_4': 0.6526312232017517, 'epoch': 24.8}
[INFO|trainer.py:4228] 2025-01-21 14:05:27,417 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:27,417 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 4270/5160 [1:45:31<15:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:34,779 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008601060137152672, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.843, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.0062779393047094345, 'eval_loss_2': 0.0023231208324432373, 'eval_loss_3': -18.14974594116211, 'eval_loss_4': 0.9601675271987915, 'epoch': 24.8}
{'loss': 0.0084, 'grad_norm': 4.983304500579834, 'learning_rate': 5.2209302325581395e-06, 'loss_1': 0.004364550579339266, 'loss_2': 0.00402069091796875, 'loss_3': -16.561630249023438, 'loss_4': 0.7283192873001099, 'epoch': 24.8}
{'loss': 0.0023, 'grad_norm': 4.488089561462402, 'learning_rate': 5.215116279069767e-06, 'loss_1': 0.0021433450747281313, 'loss_2': 0.00014340877532958984, 'loss_3': -16.4012393951416, 'loss_4': 0.8603635430335999, 'epoch': 24.81}
{'loss': 0.0088, 'grad_norm': 5.283344268798828, 'learning_rate': 5.209302325581395e-06, 'loss_1': 0.005574720911681652, 'loss_2': 0.003215789794921875, 'loss_3': -16.263927459716797, 'loss_4': 0.48034051060676575, 'epoch': 24.81}
{'loss': 0.0157, 'grad_norm': 4.674949645996094, 'learning_rate': 5.203488372093024e-06, 'loss_1': 0.005581412464380264, 'loss_2': 0.01009368896484375, 'loss_3': -16.422502517700195, 'loss_4': 0.7158369421958923, 'epoch': 24.82}
{'loss': 0.018, 'grad_norm': 6.6060333251953125, 'learning_rate': 5.1976744186046515e-06, 'loss_1': 0.007914519868791103, 'loss_2': 0.0101318359375, 'loss_3': -16.410192489624023, 'loss_4': 0.8059070706367493, 'epoch': 24.83}
[INFO|trainer.py:4228] 2025-01-21 14:05:34,779 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:34,779 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                     | 4275/5160 [1:45:39<15:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:42,143 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008862055838108063, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006502813659608364, 'eval_loss_2': 0.002359241247177124, 'eval_loss_3': -18.14308738708496, 'eval_loss_4': 0.8691607117652893, 'epoch': 24.83}
{'loss': 0.0055, 'grad_norm': 4.811447620391846, 'learning_rate': 5.191860465116279e-06, 'loss_1': 0.0021559582091867924, 'loss_2': 0.003314971923828125, 'loss_3': -16.448490142822266, 'loss_4': 1.2977591753005981, 'epoch': 24.83}
{'loss': 0.0076, 'grad_norm': 4.505276679992676, 'learning_rate': 5.186046511627907e-06, 'loss_1': 0.0028508335817605257, 'loss_2': 0.004726409912109375, 'loss_3': -16.542970657348633, 'loss_4': 0.6473684310913086, 'epoch': 24.84}
{'loss': 0.0081, 'grad_norm': 5.498934268951416, 'learning_rate': 5.180232558139535e-06, 'loss_1': 0.007954138331115246, 'loss_2': 0.00011074542999267578, 'loss_3': -16.564838409423828, 'loss_4': 0.6111817359924316, 'epoch': 24.84}
{'loss': 0.0065, 'grad_norm': 4.627768039703369, 'learning_rate': 5.174418604651163e-06, 'loss_1': 0.003521980717778206, 'loss_2': 0.00295257568359375, 'loss_3': -16.56171417236328, 'loss_4': 0.6482497453689575, 'epoch': 24.85}
{'loss': 0.0112, 'grad_norm': 6.2292375564575195, 'learning_rate': 5.168604651162791e-06, 'loss_1': 0.008158224634826183, 'loss_2': 0.003047943115234375, 'loss_3': -16.422103881835938, 'loss_4': 0.349590927362442, 'epoch': 24.85}
[INFO|trainer.py:4228] 2025-01-21 14:05:42,143 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:42,143 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                     | 4280/5160 [1:45:46<15:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:49,499 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008578397333621979, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.119, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.006243772804737091, 'eval_loss_2': 0.0023346245288848877, 'eval_loss_3': -18.140583038330078, 'eval_loss_4': 0.8181358575820923, 'epoch': 24.85}
{'loss': 0.0111, 'grad_norm': 5.385178089141846, 'learning_rate': 5.162790697674419e-06, 'loss_1': 0.006445413455367088, 'loss_2': 0.004608154296875, 'loss_3': -16.530349731445312, 'loss_4': 0.6860421299934387, 'epoch': 24.86}
{'loss': 0.012, 'grad_norm': 4.927871227264404, 'learning_rate': 5.156976744186046e-06, 'loss_1': 0.0062916474416852, 'loss_2': 0.00568389892578125, 'loss_3': -16.563495635986328, 'loss_4': 0.5622578859329224, 'epoch': 24.87}
{'loss': 0.0131, 'grad_norm': 7.921036243438721, 'learning_rate': 5.151162790697675e-06, 'loss_1': 0.012027682736515999, 'loss_2': 0.0011167526245117188, 'loss_3': -16.524330139160156, 'loss_4': 0.7947644591331482, 'epoch': 24.87}
{'loss': 0.0124, 'grad_norm': 7.888975620269775, 'learning_rate': 5.145348837209302e-06, 'loss_1': 0.008587148040533066, 'loss_2': 0.0037689208984375, 'loss_3': -16.34391975402832, 'loss_4': 0.9915937185287476, 'epoch': 24.88}
{'loss': 0.0087, 'grad_norm': 4.546180725097656, 'learning_rate': 5.13953488372093e-06, 'loss_1': 0.0033113774843513966, 'loss_2': 0.005428314208984375, 'loss_3': -16.474822998046875, 'loss_4': 0.913388729095459, 'epoch': 24.88}
[INFO|trainer.py:4228] 2025-01-21 14:05:49,499 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:49,499 >>   Batch size = 64
 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                     | 4285/5160 [1:45:54<15:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:05:56,855 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008391153067350388, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.952, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006200793199241161, 'eval_loss_2': 0.0021903589367866516, 'eval_loss_3': -18.13134002685547, 'eval_loss_4': 0.765143096446991, 'epoch': 24.88}
{'loss': 0.0042, 'grad_norm': 4.4948811531066895, 'learning_rate': 5.133720930232559e-06, 'loss_1': 0.002689167857170105, 'loss_2': 0.0015506744384765625, 'loss_3': -16.564292907714844, 'loss_4': 0.5634624361991882, 'epoch': 24.89}
{'loss': 0.025, 'grad_norm': 11.59900951385498, 'learning_rate': 5.127906976744186e-06, 'loss_1': 0.018923165276646614, 'loss_2': 0.0060882568359375, 'loss_3': -16.174510955810547, 'loss_4': 0.7417631149291992, 'epoch': 24.9}
{'loss': 0.0265, 'grad_norm': 7.732717037200928, 'learning_rate': 5.1220930232558135e-06, 'loss_1': 0.019065402448177338, 'loss_2': 0.00738525390625, 'loss_3': -16.234926223754883, 'loss_4': 0.7862614393234253, 'epoch': 24.9}
{'loss': 0.0065, 'grad_norm': 5.509142875671387, 'learning_rate': 5.116279069767442e-06, 'loss_1': 0.004983292892575264, 'loss_2': 0.0014781951904296875, 'loss_3': -16.485206604003906, 'loss_4': 0.5462228059768677, 'epoch': 24.91}
{'loss': 0.0123, 'grad_norm': 5.411280632019043, 'learning_rate': 5.11046511627907e-06, 'loss_1': 0.006602514069527388, 'loss_2': 0.005680084228515625, 'loss_3': -16.342859268188477, 'loss_4': 0.8171505331993103, 'epoch': 24.91}
[INFO|trainer.py:4228] 2025-01-21 14:05:56,855 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:05:56,855 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 4290/5160 [1:46:01<15:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:04,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008516182191669941, 'eval_runtime': 3.8164, 'eval_samples_per_second': 268.318, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.006255534943193197, 'eval_loss_2': 0.002260647714138031, 'eval_loss_3': -18.13297462463379, 'eval_loss_4': 0.7444663047790527, 'epoch': 24.91}
{'loss': 0.0052, 'grad_norm': 4.687155723571777, 'learning_rate': 5.104651162790698e-06, 'loss_1': 0.004650651942938566, 'loss_2': 0.0005679130554199219, 'loss_3': -16.593555450439453, 'loss_4': 0.8625134825706482, 'epoch': 24.92}
{'loss': 0.0092, 'grad_norm': 4.784266948699951, 'learning_rate': 5.098837209302326e-06, 'loss_1': 0.006556931883096695, 'loss_2': 0.00267791748046875, 'loss_3': -16.61157989501953, 'loss_4': 0.5802093148231506, 'epoch': 24.92}
{'loss': 0.0137, 'grad_norm': 5.791815280914307, 'learning_rate': 5.093023255813953e-06, 'loss_1': 0.006941360421478748, 'loss_2': 0.006748199462890625, 'loss_3': -16.24182891845703, 'loss_4': 0.940622866153717, 'epoch': 24.93}
{'loss': 0.0048, 'grad_norm': 5.1643290519714355, 'learning_rate': 5.087209302325581e-06, 'loss_1': 0.003727647243067622, 'loss_2': 0.00102996826171875, 'loss_3': -16.534793853759766, 'loss_4': 0.5024967193603516, 'epoch': 24.94}
{'loss': 0.0214, 'grad_norm': 19.513486862182617, 'learning_rate': 5.08139534883721e-06, 'loss_1': 0.016642946749925613, 'loss_2': 0.004802703857421875, 'loss_3': -16.31856918334961, 'loss_4': 0.7207212448120117, 'epoch': 24.94}
[INFO|trainer.py:4228] 2025-01-21 14:06:04,228 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:04,228 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                    | 4295/5160 [1:46:08<14:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:11,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008857615292072296, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.7, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.006179519463330507, 'eval_loss_2': 0.002678096294403076, 'eval_loss_3': -18.13042640686035, 'eval_loss_4': 0.758476197719574, 'epoch': 24.94}
{'loss': 0.0138, 'grad_norm': 5.6871018409729, 'learning_rate': 5.0755813953488375e-06, 'loss_1': 0.007722843904048204, 'loss_2': 0.0060882568359375, 'loss_3': -16.403711318969727, 'loss_4': 1.1706314086914062, 'epoch': 24.95}
{'loss': 0.0124, 'grad_norm': 7.692474365234375, 'learning_rate': 5.069767441860465e-06, 'loss_1': 0.011660322546958923, 'loss_2': 0.000759124755859375, 'loss_3': -16.25852394104004, 'loss_4': 0.9113657474517822, 'epoch': 24.95}
{'loss': 0.0116, 'grad_norm': 5.590706825256348, 'learning_rate': 5.063953488372093e-06, 'loss_1': 0.00446642329916358, 'loss_2': 0.00713348388671875, 'loss_3': -16.421493530273438, 'loss_4': 0.377496600151062, 'epoch': 24.96}
{'loss': 0.0085, 'grad_norm': 4.754605293273926, 'learning_rate': 5.058139534883721e-06, 'loss_1': 0.005024236626923084, 'loss_2': 0.003498077392578125, 'loss_3': -16.56892967224121, 'loss_4': 0.7514126300811768, 'epoch': 24.97}
{'loss': 0.0071, 'grad_norm': 4.646604061126709, 'learning_rate': 5.052325581395349e-06, 'loss_1': 0.003226448316127062, 'loss_2': 0.003841400146484375, 'loss_3': -16.48184585571289, 'loss_4': 0.4040682315826416, 'epoch': 24.97}
[INFO|trainer.py:4228] 2025-01-21 14:06:11,586 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:11,586 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                    | 4300/5160 [1:46:15<13:23,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 14:06:18,588 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008908404037356377, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.006299290340393782, 'eval_loss_2': 0.002609115093946457, 'eval_loss_3': -18.13016700744629, 'eval_loss_4': 0.8112185001373291, 'epoch': 24.97}
{'loss': 0.0077, 'grad_norm': 5.35478401184082, 'learning_rate': 5.046511627906977e-06, 'loss_1': 0.005239739082753658, 'loss_2': 0.002452850341796875, 'loss_3': -16.559526443481445, 'loss_4': 0.7892518043518066, 'epoch': 24.98}
{'loss': 0.0078, 'grad_norm': 5.2093892097473145, 'learning_rate': 5.040697674418605e-06, 'loss_1': 0.004376647993922234, 'loss_2': 0.003467559814453125, 'loss_3': -16.298173904418945, 'loss_4': 0.9384242296218872, 'epoch': 24.98}
{'loss': 0.006, 'grad_norm': 4.965536117553711, 'learning_rate': 5.034883720930232e-06, 'loss_1': 0.0037561915814876556, 'loss_2': 0.00222015380859375, 'loss_3': -16.383899688720703, 'loss_4': 0.8649783134460449, 'epoch': 24.99}
{'loss': 0.0062, 'grad_norm': 4.568929672241211, 'learning_rate': 5.029069767441861e-06, 'loss_1': 0.0028780209831893444, 'loss_2': 0.003307342529296875, 'loss_3': -16.358585357666016, 'loss_4': 1.3922653198242188, 'epoch': 24.99}
{'loss': 0.0043, 'grad_norm': 5.902284622192383, 'learning_rate': 5.023255813953488e-06, 'loss_1': 0.0018243691883981228, 'loss_2': 0.002445220947265625, 'loss_3': -16.40203857421875, 'loss_4': 1.0708305835723877, 'epoch': 25.0}
[INFO|trainer.py:4228] 2025-01-21 14:06:18,588 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:18,588 >>   Batch size = 64
 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                    | 4305/5160 [1:46:23<14:36,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:06:25,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009125925600528717, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.636, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.0065538217313587666, 'eval_loss_2': 0.002572104334831238, 'eval_loss_3': -18.12008285522461, 'eval_loss_4': 0.8430662155151367, 'epoch': 25.0}
{'loss': 0.0084, 'grad_norm': 5.227107048034668, 'learning_rate': 5.017441860465116e-06, 'loss_1': 0.007320557255297899, 'loss_2': 0.0011205673217773438, 'loss_3': -16.389989852905273, 'loss_4': 0.9652819633483887, 'epoch': 25.01}
{'loss': 0.0102, 'grad_norm': 5.124448299407959, 'learning_rate': 5.011627906976745e-06, 'loss_1': 0.005029773339629173, 'loss_2': 0.0051422119140625, 'loss_3': -16.43523406982422, 'loss_4': 0.6748732328414917, 'epoch': 25.01}
{'loss': 0.0056, 'grad_norm': 4.747546195983887, 'learning_rate': 5.005813953488373e-06, 'loss_1': 0.0025631734170019627, 'loss_2': 0.00304412841796875, 'loss_3': -16.716983795166016, 'loss_4': 0.9542338848114014, 'epoch': 25.02}
{'loss': 0.0187, 'grad_norm': 9.488825798034668, 'learning_rate': 4.9999999999999996e-06, 'loss_1': 0.015472396276891232, 'loss_2': 0.003215789794921875, 'loss_3': -16.607118606567383, 'loss_4': 1.6078016757965088, 'epoch': 25.02}
{'loss': 0.0446, 'grad_norm': 11.466995239257812, 'learning_rate': 4.994186046511628e-06, 'loss_1': 0.04133172333240509, 'loss_2': 0.00322723388671875, 'loss_3': -16.455028533935547, 'loss_4': 1.1728757619857788, 'epoch': 25.03}
[INFO|trainer.py:4228] 2025-01-21 14:06:25,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:25,993 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:30<14:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:06:33,347 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00890885479748249, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.074, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.006212274543941021, 'eval_loss_2': 0.002696581184864044, 'eval_loss_3': -18.118799209594727, 'eval_loss_4': 0.8885470032691956, 'epoch': 25.03}
{'loss': 0.0145, 'grad_norm': 10.351020812988281, 'learning_rate': 4.988372093023256e-06, 'loss_1': 0.009531588293612003, 'loss_2': 0.00498199462890625, 'loss_3': -16.440977096557617, 'loss_4': 1.1004114151000977, 'epoch': 25.03}
{'loss': 0.0321, 'grad_norm': 26.804737091064453, 'learning_rate': 4.982558139534884e-06, 'loss_1': 0.02803763933479786, 'loss_2': 0.004108428955078125, 'loss_3': -16.352584838867188, 'loss_4': 0.5274911522865295, 'epoch': 25.04}
{'loss': 0.0164, 'grad_norm': 9.524450302124023, 'learning_rate': 4.976744186046512e-06, 'loss_1': 0.0152462562546134, 'loss_2': 0.0011262893676757812, 'loss_3': -16.436389923095703, 'loss_4': 0.8871080875396729, 'epoch': 25.05}
{'loss': 0.004, 'grad_norm': 5.306859493255615, 'learning_rate': 4.970930232558139e-06, 'loss_1': 0.003492954419925809, 'loss_2': 0.0004749298095703125, 'loss_3': -16.30423355102539, 'loss_4': 0.9905333518981934, 'epoch': 25.05}
{'loss': 0.0038, 'grad_norm': 4.518579483032227, 'learning_rate': 4.965116279069767e-06, 'loss_1': 0.0023690643720328808, 'loss_2': 0.0014553070068359375, 'loss_3': -16.48303985595703, 'loss_4': 0.9049477577209473, 'epoch': 25.06}
[INFO|trainer.py:4228] 2025-01-21 14:06:33,348 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:33,348 >>   Batch size = 64
 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 4310/5160 [1:46:34<14:41,  1.04s/it][INFO|trainer.py:3910] 2025-01-21 14:06:37,160 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4310
[INFO|configuration_utils.py:420] 2025-01-21 14:06:37,161 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4310/config.json                                                                            
{'eval_loss': 0.006902159191668034, 'eval_runtime': 3.8109, 'eval_samples_per_second': 268.701, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004495518282055855, 'eval_loss_2': 0.0024066418409347534, 'eval_loss_3': -18.156803131103516, 'eval_loss_4': 0.9062429666519165, 'epoch': 25.06}
[INFO|modeling_utils.py:2988] 2025-01-21 14:06:37,663 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4310/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:06:37,665 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4310/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:06:37,665 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4310/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:06:38,740 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-3475] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:39<16:20,  1.16s/it][INFO|trainer.py:4226] 2025-01-21 14:06:42,389 >>
{'loss': 0.0102, 'grad_norm': 4.908276081085205, 'learning_rate': 4.959302325581396e-06, 'loss_1': 0.00450859684497118, 'loss_2': 0.005687713623046875, 'loss_3': -16.505910873413086, 'loss_4': 0.5152011513710022, 'epoch': 25.06}
{'loss': 0.0094, 'grad_norm': 6.262488842010498, 'learning_rate': 4.9534883720930235e-06, 'loss_1': 0.006733123678714037, 'loss_2': 0.002704620361328125, 'loss_3': -16.574337005615234, 'loss_4': 1.1167716979980469, 'epoch': 25.07}
{'loss': 0.0123, 'grad_norm': 6.493231773376465, 'learning_rate': 4.947674418604651e-06, 'loss_1': 0.009143290109932423, 'loss_2': 0.003154754638671875, 'loss_3': -16.37196159362793, 'loss_4': 0.8687153458595276, 'epoch': 25.08}
{'loss': 0.0047, 'grad_norm': 4.641591548919678, 'learning_rate': 4.941860465116279e-06, 'loss_1': 0.001769507653079927, 'loss_2': 0.0029449462890625, 'loss_3': -16.489320755004883, 'loss_4': 0.8087775707244873, 'epoch': 25.08}
{'loss': 0.011, 'grad_norm': 7.159489154815674, 'learning_rate': 4.936046511627907e-06, 'loss_1': 0.007858376018702984, 'loss_2': 0.0031452178955078125, 'loss_3': -16.43514633178711, 'loss_4': 0.7519047260284424, 'epoch': 25.09}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:06:42,389 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:42,389 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                   | 4315/5160 [1:46:43<16:20,  1.16s/it][INFO|trainer.py:3910] 2025-01-21 14:06:46,205 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4315
[INFO|configuration_utils.py:420] 2025-01-21 14:06:46,207 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4315/config.json                                                                            
{'eval_loss': 0.005828141234815121, 'eval_runtime': 3.8148, 'eval_samples_per_second': 268.432, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.0035548058804124594, 'eval_loss_2': 0.0022733360528945923, 'eval_loss_3': -18.18364906311035, 'eval_loss_4': 0.918878436088562, 'epoch': 25.09}
[INFO|modeling_utils.py:2988] 2025-01-21 14:06:46,711 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4315/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:06:46,713 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4315/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:06:46,713 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4315/special_tokens_map.json
[INFO|trainer.py:4002] 2025-01-21 14:06:47,787 >> Deleting older checkpoint [SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4310] due to args.save_total_limit
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 4320/5160 [1:46:48<16:30,  1.18s/it][INFO|trainer.py:4226] 2025-01-21 14:06:51,411 >>
{'loss': 0.007, 'grad_norm': 4.8174285888671875, 'learning_rate': 4.930232558139535e-06, 'loss_1': 0.004387738648802042, 'loss_2': 0.0026416778564453125, 'loss_3': -16.484580993652344, 'loss_4': 0.6609439253807068, 'epoch': 25.09}
{'loss': 0.0059, 'grad_norm': 4.7845306396484375, 'learning_rate': 4.924418604651163e-06, 'loss_1': 0.002629081020131707, 'loss_2': 0.0032901763916015625, 'loss_3': -16.483272552490234, 'loss_4': 1.1233913898468018, 'epoch': 25.1}
{'loss': 0.0075, 'grad_norm': 7.656563758850098, 'learning_rate': 4.918604651162791e-06, 'loss_1': 0.006776027847081423, 'loss_2': 0.000675201416015625, 'loss_3': -16.504966735839844, 'loss_4': 1.0229904651641846, 'epoch': 25.1}
{'loss': 0.0168, 'grad_norm': 7.12915563583374, 'learning_rate': 4.912790697674419e-06, 'loss_1': 0.006363744847476482, 'loss_2': 0.0104522705078125, 'loss_3': -16.259239196777344, 'loss_4': 0.5040652751922607, 'epoch': 25.11}
{'loss': 0.0069, 'grad_norm': 4.916769981384277, 'learning_rate': 4.906976744186047e-06, 'loss_1': 0.0061997417360544205, 'loss_2': 0.000675201416015625, 'loss_3': -16.432212829589844, 'loss_4': 0.8699944019317627, 'epoch': 25.12}
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:06:51,411 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:51,411 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                   | 4325/5160 [1:46:55<14:47,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:06:58,770 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006707071792334318, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004056691657751799, 'eval_loss_2': 0.0026503801345825195, 'eval_loss_3': -18.202083587646484, 'eval_loss_4': 0.9299418330192566, 'epoch': 25.12}
{'loss': 0.0049, 'grad_norm': 4.687695503234863, 'learning_rate': 4.9011627906976745e-06, 'loss_1': 0.004633483476936817, 'loss_2': 0.00027370452880859375, 'loss_3': -16.520828247070312, 'loss_4': 0.8450441360473633, 'epoch': 25.12}
{'loss': 0.0032, 'grad_norm': 5.107346534729004, 'learning_rate': 4.895348837209302e-06, 'loss_1': 0.0023245946504175663, 'loss_2': 0.0008325576782226562, 'loss_3': -16.376861572265625, 'loss_4': 1.0332142114639282, 'epoch': 25.13}
{'loss': 0.0125, 'grad_norm': 5.826621055603027, 'learning_rate': 4.889534883720931e-06, 'loss_1': 0.007193785160779953, 'loss_2': 0.005268096923828125, 'loss_3': -16.544742584228516, 'loss_4': 0.9174255132675171, 'epoch': 25.13}
{'loss': 0.01, 'grad_norm': 5.872508525848389, 'learning_rate': 4.883720930232559e-06, 'loss_1': 0.007421632297337055, 'loss_2': 0.00255584716796875, 'loss_3': -16.398792266845703, 'loss_4': 0.6583019495010376, 'epoch': 25.14}
{'loss': 0.0108, 'grad_norm': 5.023667812347412, 'learning_rate': 4.877906976744186e-06, 'loss_1': 0.004224744625389576, 'loss_2': 0.006561279296875, 'loss_3': -16.47569465637207, 'loss_4': 1.0216586589813232, 'epoch': 25.15}
[INFO|trainer.py:4228] 2025-01-21 14:06:58,770 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:06:58,770 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                   | 4330/5160 [1:47:03<14:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:06,126 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007208103314042091, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.898, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004517299588769674, 'eval_loss_2': 0.0026908032596111298, 'eval_loss_3': -18.206707000732422, 'eval_loss_4': 0.9260374307632446, 'epoch': 25.15}
{'loss': 0.0047, 'grad_norm': 4.668742656707764, 'learning_rate': 4.872093023255814e-06, 'loss_1': 0.003259226679801941, 'loss_2': 0.0014486312866210938, 'loss_3': -16.419239044189453, 'loss_4': 0.7264411449432373, 'epoch': 25.15}
{'loss': 0.0152, 'grad_norm': 9.230341911315918, 'learning_rate': 4.866279069767442e-06, 'loss_1': 0.0097627192735672, 'loss_2': 0.005428314208984375, 'loss_3': -16.566408157348633, 'loss_4': 0.8735597133636475, 'epoch': 25.16}
{'loss': 0.0085, 'grad_norm': 5.047874927520752, 'learning_rate': 4.86046511627907e-06, 'loss_1': 0.006676593795418739, 'loss_2': 0.0018157958984375, 'loss_3': -16.355377197265625, 'loss_4': 1.0020067691802979, 'epoch': 25.16}
{'loss': 0.0049, 'grad_norm': 4.628926753997803, 'learning_rate': 4.8546511627906984e-06, 'loss_1': 0.003982936963438988, 'loss_2': 0.0008792877197265625, 'loss_3': -16.502147674560547, 'loss_4': 0.4930160641670227, 'epoch': 25.17}
{'loss': 0.0274, 'grad_norm': 17.139102935791016, 'learning_rate': 4.848837209302325e-06, 'loss_1': 0.02555367723107338, 'loss_2': 0.0018625259399414062, 'loss_3': -16.439960479736328, 'loss_4': 0.6228737235069275, 'epoch': 25.17}
[INFO|trainer.py:4228] 2025-01-21 14:07:06,126 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:06,126 >>   Batch size = 64
 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                   | 4335/5160 [1:47:10<14:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:13,478 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007882525213062763, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.138, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.0049151829443871975, 'eval_loss_2': 0.002967342734336853, 'eval_loss_3': -18.22052764892578, 'eval_loss_4': 0.9411897659301758, 'epoch': 25.17}
{'loss': 0.0033, 'grad_norm': 4.783807754516602, 'learning_rate': 4.843023255813953e-06, 'loss_1': 0.002717631170526147, 'loss_2': 0.0006170272827148438, 'loss_3': -16.497203826904297, 'loss_4': 1.0761303901672363, 'epoch': 25.18}
{'loss': 0.0108, 'grad_norm': 5.029558181762695, 'learning_rate': 4.837209302325582e-06, 'loss_1': 0.007074219640344381, 'loss_2': 0.0037097930908203125, 'loss_3': -16.539325714111328, 'loss_4': 1.0003139972686768, 'epoch': 25.19}
{'loss': 0.0042, 'grad_norm': 4.282461643218994, 'learning_rate': 4.8313953488372096e-06, 'loss_1': 0.0022761293221265078, 'loss_2': 0.0019397735595703125, 'loss_3': -16.433921813964844, 'loss_4': 0.9640167355537415, 'epoch': 25.19}
{'loss': 0.0196, 'grad_norm': 6.58702278137207, 'learning_rate': 4.825581395348837e-06, 'loss_1': 0.011507346294820309, 'loss_2': 0.00811767578125, 'loss_3': -16.366731643676758, 'loss_4': 0.6656485795974731, 'epoch': 25.2}
{'loss': 0.0229, 'grad_norm': 10.817371368408203, 'learning_rate': 4.819767441860466e-06, 'loss_1': 0.020393909886479378, 'loss_2': 0.002544403076171875, 'loss_3': -16.49169158935547, 'loss_4': 0.7978104948997498, 'epoch': 25.2}
[INFO|trainer.py:4228] 2025-01-21 14:07:13,478 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:13,479 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 4340/5160 [1:47:17<14:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:20,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008121228776872158, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.023, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004627264570444822, 'eval_loss_2': 0.003493964672088623, 'eval_loss_3': -18.221723556518555, 'eval_loss_4': 0.9211132526397705, 'epoch': 25.2}
{'loss': 0.0112, 'grad_norm': 4.826198577880859, 'learning_rate': 4.813953488372093e-06, 'loss_1': 0.0027430010959506035, 'loss_2': 0.00848388671875, 'loss_3': -16.36885643005371, 'loss_4': 0.7156364917755127, 'epoch': 25.21}
{'loss': 0.0107, 'grad_norm': 8.851031303405762, 'learning_rate': 4.808139534883721e-06, 'loss_1': 0.008721270598471165, 'loss_2': 0.0020084381103515625, 'loss_3': -16.380138397216797, 'loss_4': 0.8117130398750305, 'epoch': 25.22}
{'loss': 0.0112, 'grad_norm': 4.968711853027344, 'learning_rate': 4.802325581395349e-06, 'loss_1': 0.00508367782458663, 'loss_2': 0.00609588623046875, 'loss_3': -16.499597549438477, 'loss_4': 0.7086293697357178, 'epoch': 25.22}
{'loss': 0.0041, 'grad_norm': 4.645205497741699, 'learning_rate': 4.796511627906977e-06, 'loss_1': 0.0031078385654836893, 'loss_2': 0.0009732246398925781, 'loss_3': -16.106355667114258, 'loss_4': 0.2790377140045166, 'epoch': 25.23}
{'loss': 0.006, 'grad_norm': 4.713080406188965, 'learning_rate': 4.790697674418605e-06, 'loss_1': 0.003910164348781109, 'loss_2': 0.00205230712890625, 'loss_3': -16.493820190429688, 'loss_4': 1.2264494895935059, 'epoch': 25.23}
[INFO|trainer.py:4228] 2025-01-21 14:07:20,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:20,836 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                  | 4345/5160 [1:47:25<14:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:28,206 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008940216153860092, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.723, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.004745315760374069, 'eval_loss_2': 0.004194900393486023, 'eval_loss_3': -18.219120025634766, 'eval_loss_4': 0.8933429718017578, 'epoch': 25.23}
{'loss': 0.0152, 'grad_norm': 6.324272632598877, 'learning_rate': 4.784883720930233e-06, 'loss_1': 0.005493465811014175, 'loss_2': 0.00969696044921875, 'loss_3': -16.44521713256836, 'loss_4': 0.3555220663547516, 'epoch': 25.24}
{'loss': 0.0217, 'grad_norm': 13.48154354095459, 'learning_rate': 4.7790697674418605e-06, 'loss_1': 0.014191299676895142, 'loss_2': 0.00746917724609375, 'loss_3': -16.48562240600586, 'loss_4': 0.9022781252861023, 'epoch': 25.24}
{'loss': 0.0107, 'grad_norm': 4.4927191734313965, 'learning_rate': 4.773255813953488e-06, 'loss_1': 0.004979880526661873, 'loss_2': 0.005706787109375, 'loss_3': -16.547420501708984, 'loss_4': 0.7972283363342285, 'epoch': 25.25}
{'loss': 0.0099, 'grad_norm': 6.053675651550293, 'learning_rate': 4.767441860465117e-06, 'loss_1': 0.00899108499288559, 'loss_2': 0.0009450912475585938, 'loss_3': -16.581205368041992, 'loss_4': 0.8690028190612793, 'epoch': 25.26}
{'loss': 0.0108, 'grad_norm': 5.3744988441467285, 'learning_rate': 4.761627906976745e-06, 'loss_1': 0.004941253922879696, 'loss_2': 0.005828857421875, 'loss_3': -16.480314254760742, 'loss_4': 0.6804364919662476, 'epoch': 25.26}
[INFO|trainer.py:4228] 2025-01-21 14:07:28,206 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:28,206 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                  | 4350/5160 [1:47:32<14:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:35,556 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008613095618784428, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.384, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005064830649644136, 'eval_loss_2': 0.003548264503479004, 'eval_loss_3': -18.20479393005371, 'eval_loss_4': 0.875735878944397, 'epoch': 25.26}
{'loss': 0.0112, 'grad_norm': 5.5883331298828125, 'learning_rate': 4.755813953488372e-06, 'loss_1': 0.007017501164227724, 'loss_2': 0.00415802001953125, 'loss_3': -16.537525177001953, 'loss_4': 0.6310865879058838, 'epoch': 25.27}
{'loss': 0.0093, 'grad_norm': 5.4979753494262695, 'learning_rate': 4.75e-06, 'loss_1': 0.005583499558269978, 'loss_2': 0.003719329833984375, 'loss_3': -16.395357131958008, 'loss_4': 1.1354238986968994, 'epoch': 25.27}
{'loss': 0.0068, 'grad_norm': 4.694316387176514, 'learning_rate': 4.744186046511628e-06, 'loss_1': 0.004088862799108028, 'loss_2': 0.0027523040771484375, 'loss_3': -16.327640533447266, 'loss_4': 0.9766620993614197, 'epoch': 25.28}
{'loss': 0.009, 'grad_norm': 5.683384895324707, 'learning_rate': 4.738372093023256e-06, 'loss_1': 0.004533651750534773, 'loss_2': 0.004459381103515625, 'loss_3': -16.260353088378906, 'loss_4': 1.0524286031723022, 'epoch': 25.28}
{'loss': 0.0557, 'grad_norm': 12.171414375305176, 'learning_rate': 4.7325581395348845e-06, 'loss_1': 0.05267392471432686, 'loss_2': 0.0030574798583984375, 'loss_3': -16.326934814453125, 'loss_4': 0.8513910174369812, 'epoch': 25.29}
[INFO|trainer.py:4228] 2025-01-21 14:07:35,556 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:35,556 >>   Batch size = 64
 84%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                  | 4355/5160 [1:47:40<13:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:42,909 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006924396380782127, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.406, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004479391500353813, 'eval_loss_2': 0.002445004880428314, 'eval_loss_3': -18.207408905029297, 'eval_loss_4': 0.858455240726471, 'epoch': 25.29}
{'loss': 0.0132, 'grad_norm': 8.344766616821289, 'learning_rate': 4.726744186046512e-06, 'loss_1': 0.012304788455367088, 'loss_2': 0.0008807182312011719, 'loss_3': -16.65566635131836, 'loss_4': 1.0402920246124268, 'epoch': 25.3}
{'loss': 0.0053, 'grad_norm': 4.95211124420166, 'learning_rate': 4.720930232558139e-06, 'loss_1': 0.002813144354149699, 'loss_2': 0.002475738525390625, 'loss_3': -16.491077423095703, 'loss_4': 0.8180710077285767, 'epoch': 25.3}
{'loss': 0.0057, 'grad_norm': 5.805107593536377, 'learning_rate': 4.715116279069768e-06, 'loss_1': 0.005558396689593792, 'loss_2': 0.0001723766326904297, 'loss_3': -16.541580200195312, 'loss_4': 0.6977428793907166, 'epoch': 25.31}
{'loss': 0.0141, 'grad_norm': 9.091532707214355, 'learning_rate': 4.709302325581396e-06, 'loss_1': 0.012472307309508324, 'loss_2': 0.0016307830810546875, 'loss_3': -16.232559204101562, 'loss_4': 0.8750923871994019, 'epoch': 25.31}
{'loss': 0.0071, 'grad_norm': 4.230732440948486, 'learning_rate': 4.703488372093023e-06, 'loss_1': 0.00446374760940671, 'loss_2': 0.002605438232421875, 'loss_3': -16.388946533203125, 'loss_4': 1.0043421983718872, 'epoch': 25.32}
[INFO|trainer.py:4228] 2025-01-21 14:07:42,910 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:42,910 >>   Batch size = 64
 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 4360/5160 [1:47:47<13:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:50,262 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006526029668748379, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.026, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004437901079654694, 'eval_loss_2': 0.0020881295204162598, 'eval_loss_3': -18.209428787231445, 'eval_loss_4': 0.8486892580986023, 'epoch': 25.32}
{'loss': 0.0047, 'grad_norm': 4.357107162475586, 'learning_rate': 4.697674418604652e-06, 'loss_1': 0.0013575457269325852, 'loss_2': 0.003368377685546875, 'loss_3': -16.373268127441406, 'loss_4': 0.9363808035850525, 'epoch': 25.33}
{'loss': 0.0102, 'grad_norm': 6.008384704589844, 'learning_rate': 4.691860465116279e-06, 'loss_1': 0.005663342773914337, 'loss_2': 0.00453948974609375, 'loss_3': -16.361995697021484, 'loss_4': 1.183106541633606, 'epoch': 25.33}
{'loss': 0.0106, 'grad_norm': 6.110686302185059, 'learning_rate': 4.686046511627907e-06, 'loss_1': 0.007894555106759071, 'loss_2': 0.002719879150390625, 'loss_3': -16.483266830444336, 'loss_4': 0.6645203232765198, 'epoch': 25.34}
{'loss': 0.0179, 'grad_norm': 7.079851150512695, 'learning_rate': 4.680232558139535e-06, 'loss_1': 0.009295404888689518, 'loss_2': 0.008636474609375, 'loss_3': -16.371299743652344, 'loss_4': 0.40240010619163513, 'epoch': 25.34}
{'loss': 0.0134, 'grad_norm': 4.493061542510986, 'learning_rate': 4.674418604651163e-06, 'loss_1': 0.003312219399958849, 'loss_2': 0.01009368896484375, 'loss_3': -16.835718154907227, 'loss_4': 0.7825853824615479, 'epoch': 25.35}
[INFO|trainer.py:4228] 2025-01-21 14:07:50,262 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:50,262 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                 | 4365/5160 [1:47:54<13:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:07:57,624 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006630139425396919, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.686, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004773409571498632, 'eval_loss_2': 0.0018567293882369995, 'eval_loss_3': -18.217620849609375, 'eval_loss_4': 0.8357407450675964, 'epoch': 25.35}
{'loss': 0.0079, 'grad_norm': 5.128942489624023, 'learning_rate': 4.668604651162791e-06, 'loss_1': 0.004581073764711618, 'loss_2': 0.003292083740234375, 'loss_3': -16.346254348754883, 'loss_4': 0.6752790212631226, 'epoch': 25.35}
{'loss': 0.0062, 'grad_norm': 5.4752607345581055, 'learning_rate': 4.662790697674419e-06, 'loss_1': 0.0036516974214464426, 'loss_2': 0.002559661865234375, 'loss_3': -16.50641441345215, 'loss_4': 0.9754467606544495, 'epoch': 25.36}
{'loss': 0.0063, 'grad_norm': 4.791456699371338, 'learning_rate': 4.6569767441860465e-06, 'loss_1': 0.0041620125994086266, 'loss_2': 0.0021686553955078125, 'loss_3': -16.456497192382812, 'loss_4': 0.9425232410430908, 'epoch': 25.37}
{'loss': 0.0212, 'grad_norm': 12.239219665527344, 'learning_rate': 4.651162790697674e-06, 'loss_1': 0.020529866218566895, 'loss_2': 0.0006604194641113281, 'loss_3': -16.35076141357422, 'loss_4': 0.5043455958366394, 'epoch': 25.37}
{'loss': 0.0118, 'grad_norm': 6.143986225128174, 'learning_rate': 4.645348837209303e-06, 'loss_1': 0.011490356177091599, 'loss_2': 0.0003070831298828125, 'loss_3': -16.37464714050293, 'loss_4': 0.8669356107711792, 'epoch': 25.38}
[INFO|trainer.py:4228] 2025-01-21 14:07:57,624 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:07:57,624 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 4370/5160 [1:48:02<13:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:04,988 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006851745769381523, 'eval_runtime': 3.8145, 'eval_samples_per_second': 268.45, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004575712140649557, 'eval_loss_2': 0.0022760331630706787, 'eval_loss_3': -18.219263076782227, 'eval_loss_4': 0.7949410080909729, 'epoch': 25.38}
{'loss': 0.0175, 'grad_norm': 7.676883697509766, 'learning_rate': 4.639534883720931e-06, 'loss_1': 0.010036434046924114, 'loss_2': 0.00743865966796875, 'loss_3': -16.624074935913086, 'loss_4': 0.5716489553451538, 'epoch': 25.38}
{'loss': 0.009, 'grad_norm': 9.851527214050293, 'learning_rate': 4.6337209302325585e-06, 'loss_1': 0.00852048210799694, 'loss_2': 0.0005216598510742188, 'loss_3': -16.425609588623047, 'loss_4': 0.6180227398872375, 'epoch': 25.39}
{'loss': 0.0118, 'grad_norm': 4.823496341705322, 'learning_rate': 4.627906976744186e-06, 'loss_1': 0.004370767157524824, 'loss_2': 0.007450103759765625, 'loss_3': -16.384532928466797, 'loss_4': 1.0997211933135986, 'epoch': 25.4}
{'loss': 0.0087, 'grad_norm': 4.928356647491455, 'learning_rate': 4.622093023255814e-06, 'loss_1': 0.0025176110211759806, 'loss_2': 0.006137847900390625, 'loss_3': -16.448678970336914, 'loss_4': 0.6109665632247925, 'epoch': 25.4}
{'loss': 0.002, 'grad_norm': 4.512383460998535, 'learning_rate': 4.616279069767442e-06, 'loss_1': 0.001891345833428204, 'loss_2': 0.00010323524475097656, 'loss_3': -16.401588439941406, 'loss_4': 0.6616181135177612, 'epoch': 25.41}
[INFO|trainer.py:4228] 2025-01-21 14:08:04,988 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:04,988 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                 | 4375/5160 [1:48:09<13:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:12,351 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007135023362934589, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.712, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005001300014555454, 'eval_loss_2': 0.002133723348379135, 'eval_loss_3': -18.220550537109375, 'eval_loss_4': 0.7802163362503052, 'epoch': 25.41}
{'loss': 0.0069, 'grad_norm': 5.905945777893066, 'learning_rate': 4.6104651162790705e-06, 'loss_1': 0.005610917694866657, 'loss_2': 0.0012464523315429688, 'loss_3': -16.63590431213379, 'loss_4': 0.9266149997711182, 'epoch': 25.41}
{'loss': 0.0063, 'grad_norm': 5.130159378051758, 'learning_rate': 4.604651162790698e-06, 'loss_1': 0.004322938155382872, 'loss_2': 0.002010345458984375, 'loss_3': -16.64483070373535, 'loss_4': 0.344062864780426, 'epoch': 25.42}
{'loss': 0.0123, 'grad_norm': 7.701681613922119, 'learning_rate': 4.598837209302325e-06, 'loss_1': 0.008544811978936195, 'loss_2': 0.0037097930908203125, 'loss_3': -16.48381805419922, 'loss_4': 0.6395364999771118, 'epoch': 25.42}
{'loss': 0.0046, 'grad_norm': 4.119248390197754, 'learning_rate': 4.593023255813954e-06, 'loss_1': 0.0030446185264736414, 'loss_2': 0.0016002655029296875, 'loss_3': -16.38282012939453, 'loss_4': 0.9427884817123413, 'epoch': 25.43}
{'loss': 0.0486, 'grad_norm': 18.430299758911133, 'learning_rate': 4.587209302325582e-06, 'loss_1': 0.04601845517754555, 'loss_2': 0.002597808837890625, 'loss_3': -16.497814178466797, 'loss_4': 0.5738897323608398, 'epoch': 25.44}
[INFO|trainer.py:4228] 2025-01-21 14:08:12,351 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:12,351 >>   Batch size = 64
 85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                 | 4380/5160 [1:48:16<13:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:19,703 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00735397869721055, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.208, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005051123909652233, 'eval_loss_2': 0.0023028552532196045, 'eval_loss_3': -18.206850051879883, 'eval_loss_4': 0.815960168838501, 'epoch': 25.44}
{'loss': 0.01, 'grad_norm': 4.799427509307861, 'learning_rate': 4.5813953488372094e-06, 'loss_1': 0.004469036124646664, 'loss_2': 0.0055084228515625, 'loss_3': -16.457218170166016, 'loss_4': 0.813251256942749, 'epoch': 25.44}
{'loss': 0.011, 'grad_norm': 5.261749267578125, 'learning_rate': 4.575581395348837e-06, 'loss_1': 0.005921573378145695, 'loss_2': 0.005100250244140625, 'loss_3': -16.548370361328125, 'loss_4': 0.5997904539108276, 'epoch': 25.45}
{'loss': 0.0156, 'grad_norm': 8.041943550109863, 'learning_rate': 4.569767441860465e-06, 'loss_1': 0.01099262572824955, 'loss_2': 0.004638671875, 'loss_3': -16.565330505371094, 'loss_4': 1.027505874633789, 'epoch': 25.45}
{'loss': 0.011, 'grad_norm': 4.858616352081299, 'learning_rate': 4.563953488372093e-06, 'loss_1': 0.008182123303413391, 'loss_2': 0.0028057098388671875, 'loss_3': -16.498764038085938, 'loss_4': 0.5930905342102051, 'epoch': 25.46}
{'loss': 0.0108, 'grad_norm': 4.770954132080078, 'learning_rate': 4.5581395348837206e-06, 'loss_1': 0.004253503866493702, 'loss_2': 0.0065765380859375, 'loss_3': -16.36032485961914, 'loss_4': 0.8411632180213928, 'epoch': 25.47}
[INFO|trainer.py:4228] 2025-01-21 14:08:19,703 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:19,703 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 4385/5160 [1:48:24<13:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:27,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007745654322206974, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.14, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005027697887271643, 'eval_loss_2': 0.0027179569005966187, 'eval_loss_3': -18.198001861572266, 'eval_loss_4': 0.816780686378479, 'epoch': 25.47}
{'loss': 0.0059, 'grad_norm': 4.6845703125, 'learning_rate': 4.552325581395349e-06, 'loss_1': 0.002019480336457491, 'loss_2': 0.003864288330078125, 'loss_3': -16.53390121459961, 'loss_4': 0.6152493953704834, 'epoch': 25.47}
{'loss': 0.0052, 'grad_norm': 5.124537944793701, 'learning_rate': 4.546511627906977e-06, 'loss_1': 0.001987796276807785, 'loss_2': 0.0031890869140625, 'loss_3': -16.507741928100586, 'loss_4': 0.5694912672042847, 'epoch': 25.48}
{'loss': 0.0167, 'grad_norm': 10.381657600402832, 'learning_rate': 4.540697674418605e-06, 'loss_1': 0.009524025022983551, 'loss_2': 0.007171630859375, 'loss_3': -16.51607894897461, 'loss_4': 1.1488957405090332, 'epoch': 25.48}
{'loss': 0.0046, 'grad_norm': 4.794841766357422, 'learning_rate': 4.5348837209302326e-06, 'loss_1': 0.004137029405683279, 'loss_2': 0.0004742145538330078, 'loss_3': -16.427268981933594, 'loss_4': 0.6882794499397278, 'epoch': 25.49}
{'loss': 0.0046, 'grad_norm': 5.176516532897949, 'learning_rate': 4.52906976744186e-06, 'loss_1': 0.002817283384501934, 'loss_2': 0.00176239013671875, 'loss_3': -16.551101684570312, 'loss_4': 0.9192046523094177, 'epoch': 25.49}
[INFO|trainer.py:4228] 2025-01-21 14:08:27,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:27,054 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 4390/5160 [1:48:31<13:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:34,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007964053191244602, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.034, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004835942294448614, 'eval_loss_2': 0.0031281113624572754, 'eval_loss_3': -18.1914119720459, 'eval_loss_4': 0.7799956798553467, 'epoch': 25.49}
{'loss': 0.0145, 'grad_norm': 9.30565071105957, 'learning_rate': 4.523255813953488e-06, 'loss_1': 0.010776999406516552, 'loss_2': 0.003696441650390625, 'loss_3': -16.393966674804688, 'loss_4': 0.5605962872505188, 'epoch': 25.5}
{'loss': 0.0073, 'grad_norm': 5.1712517738342285, 'learning_rate': 4.517441860465117e-06, 'loss_1': 0.004712342284619808, 'loss_2': 0.002544403076171875, 'loss_3': -16.324005126953125, 'loss_4': 1.0177123546600342, 'epoch': 25.51}
{'loss': 0.011, 'grad_norm': 5.58983850479126, 'learning_rate': 4.5116279069767445e-06, 'loss_1': 0.007566913962364197, 'loss_2': 0.00344085693359375, 'loss_3': -16.285232543945312, 'loss_4': 0.7377835512161255, 'epoch': 25.51}
{'loss': 0.0181, 'grad_norm': 16.449871063232422, 'learning_rate': 4.5058139534883715e-06, 'loss_1': 0.014552857726812363, 'loss_2': 0.0035247802734375, 'loss_3': -16.44121551513672, 'loss_4': 0.43128809332847595, 'epoch': 25.52}
{'loss': 0.0038, 'grad_norm': 5.008843421936035, 'learning_rate': 4.5e-06, 'loss_1': 0.0015620600897818804, 'loss_2': 0.00226593017578125, 'loss_3': -16.673892974853516, 'loss_4': 0.4934561848640442, 'epoch': 25.52}
[INFO|trainer.py:4228] 2025-01-21 14:08:34,409 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:34,409 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                | 4395/5160 [1:48:38<13:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:41,771 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007676309905946255, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.944, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004637367092072964, 'eval_loss_2': 0.003038942813873291, 'eval_loss_3': -18.190574645996094, 'eval_loss_4': 0.7380271553993225, 'epoch': 25.52}
{'loss': 0.0162, 'grad_norm': 7.27627420425415, 'learning_rate': 4.494186046511628e-06, 'loss_1': 0.008869779296219349, 'loss_2': 0.00737762451171875, 'loss_3': -16.374977111816406, 'loss_4': 0.7875975370407104, 'epoch': 25.53}
{'loss': 0.0183, 'grad_norm': 5.956275463104248, 'learning_rate': 4.488372093023256e-06, 'loss_1': 0.006477348040789366, 'loss_2': 0.01178741455078125, 'loss_3': -16.48204231262207, 'loss_4': 0.5612062215805054, 'epoch': 25.53}
{'loss': 0.0073, 'grad_norm': 4.256261348724365, 'learning_rate': 4.482558139534884e-06, 'loss_1': 0.0017630456713959575, 'loss_2': 0.0054931640625, 'loss_3': -16.428884506225586, 'loss_4': 0.7054175138473511, 'epoch': 25.54}
{'loss': 0.0068, 'grad_norm': 6.207115650177002, 'learning_rate': 4.476744186046511e-06, 'loss_1': 0.004795222543179989, 'loss_2': 0.0020008087158203125, 'loss_3': -16.524019241333008, 'loss_4': 0.4343913793563843, 'epoch': 25.55}
{'loss': 0.0047, 'grad_norm': 4.997256278991699, 'learning_rate': 4.470930232558139e-06, 'loss_1': 0.004211476072669029, 'loss_2': 0.0005064010620117188, 'loss_3': -16.34522819519043, 'loss_4': 0.9225000143051147, 'epoch': 25.55}
[INFO|trainer.py:4228] 2025-01-21 14:08:41,771 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:41,772 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                | 4400/5160 [1:48:46<13:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:49,136 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007125722244381905, 'eval_runtime': 3.8141, 'eval_samples_per_second': 268.477, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004727078136056662, 'eval_loss_2': 0.0023986436426639557, 'eval_loss_3': -18.186859130859375, 'eval_loss_4': 0.7134023308753967, 'epoch': 25.55}
{'loss': 0.0156, 'grad_norm': 6.023749351501465, 'learning_rate': 4.465116279069768e-06, 'loss_1': 0.008149889297783375, 'loss_2': 0.0074310302734375, 'loss_3': -16.451433181762695, 'loss_4': 0.8473258018493652, 'epoch': 25.56}
{'loss': 0.0107, 'grad_norm': 5.041340351104736, 'learning_rate': 4.4593023255813955e-06, 'loss_1': 0.008541733026504517, 'loss_2': 0.00213623046875, 'loss_3': -16.27672576904297, 'loss_4': 0.3913003206253052, 'epoch': 25.56}
{'loss': 0.0052, 'grad_norm': 4.3065972328186035, 'learning_rate': 4.453488372093023e-06, 'loss_1': 0.0023807091638445854, 'loss_2': 0.0027790069580078125, 'loss_3': -16.389617919921875, 'loss_4': 0.7073836326599121, 'epoch': 25.57}
{'loss': 0.0081, 'grad_norm': 5.218711853027344, 'learning_rate': 4.447674418604652e-06, 'loss_1': 0.006144750863313675, 'loss_2': 0.0019102096557617188, 'loss_3': -16.557979583740234, 'loss_4': 0.3232019543647766, 'epoch': 25.58}
{'loss': 0.0078, 'grad_norm': 4.615769863128662, 'learning_rate': 4.441860465116279e-06, 'loss_1': 0.003576067276299, 'loss_2': 0.0042572021484375, 'loss_3': -16.400211334228516, 'loss_4': 1.2194902896881104, 'epoch': 25.58}
[INFO|trainer.py:4228] 2025-01-21 14:08:49,136 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:49,136 >>   Batch size = 64
 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                | 4405/5160 [1:48:53<13:03,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:08:56,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007316913455724716, 'eval_runtime': 3.8036, 'eval_samples_per_second': 269.219, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0048545487225055695, 'eval_loss_2': 0.0024623647332191467, 'eval_loss_3': -18.19085693359375, 'eval_loss_4': 0.669176459312439, 'epoch': 25.58}
{'loss': 0.009, 'grad_norm': 4.851347923278809, 'learning_rate': 4.436046511627907e-06, 'loss_1': 0.002891433658078313, 'loss_2': 0.0061492919921875, 'loss_3': -16.501523971557617, 'loss_4': 0.7655636668205261, 'epoch': 25.59}
{'loss': 0.0093, 'grad_norm': 5.140103340148926, 'learning_rate': 4.430232558139535e-06, 'loss_1': 0.007167577277868986, 'loss_2': 0.00209808349609375, 'loss_3': -16.531879425048828, 'loss_4': 0.002825714647769928, 'epoch': 25.59}
{'loss': 0.0219, 'grad_norm': 17.284799575805664, 'learning_rate': 4.424418604651163e-06, 'loss_1': 0.017902793362736702, 'loss_2': 0.00395965576171875, 'loss_3': -16.511512756347656, 'loss_4': -0.1200864389538765, 'epoch': 25.6}
{'loss': 0.0064, 'grad_norm': 5.325918197631836, 'learning_rate': 4.418604651162791e-06, 'loss_1': 0.004572352394461632, 'loss_2': 0.0018157958984375, 'loss_3': -16.3688907623291, 'loss_4': 0.4477880597114563, 'epoch': 25.6}
{'loss': 0.0194, 'grad_norm': 17.79822540283203, 'learning_rate': 4.412790697674419e-06, 'loss_1': 0.01634746976196766, 'loss_2': 0.00308990478515625, 'loss_3': -16.61836051940918, 'loss_4': 1.1425261497497559, 'epoch': 25.61}
[INFO|trainer.py:4228] 2025-01-21 14:08:56,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:08:56,481 >>   Batch size = 64
 85%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                               | 4410/5160 [1:49:00<12:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:03,836 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006890180520713329, 'eval_runtime': 3.8012, 'eval_samples_per_second': 269.389, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.0043297577649354935, 'eval_loss_2': 0.0025604218244552612, 'eval_loss_3': -18.197477340698242, 'eval_loss_4': 0.6203091740608215, 'epoch': 25.61}
{'loss': 0.0057, 'grad_norm': 5.006239414215088, 'learning_rate': 4.406976744186046e-06, 'loss_1': 0.004387418273836374, 'loss_2': 0.0012989044189453125, 'loss_3': -16.490062713623047, 'loss_4': 0.7067476511001587, 'epoch': 25.62}
{'loss': 0.0093, 'grad_norm': 4.726959705352783, 'learning_rate': 4.401162790697674e-06, 'loss_1': 0.0033394380006939173, 'loss_2': 0.005962371826171875, 'loss_3': -16.5244083404541, 'loss_4': 0.35362303256988525, 'epoch': 25.62}
{'loss': 0.0062, 'grad_norm': 4.84451150894165, 'learning_rate': 4.395348837209303e-06, 'loss_1': 0.003369092009961605, 'loss_2': 0.0028285980224609375, 'loss_3': -16.283777236938477, 'loss_4': 0.5376179218292236, 'epoch': 25.63}
{'loss': 0.0048, 'grad_norm': 4.976809501647949, 'learning_rate': 4.389534883720931e-06, 'loss_1': 0.004274989943951368, 'loss_2': 0.0005707740783691406, 'loss_3': -16.515859603881836, 'loss_4': 0.16202494502067566, 'epoch': 25.63}
{'loss': 0.0069, 'grad_norm': 4.654167175292969, 'learning_rate': 4.3837209302325575e-06, 'loss_1': 0.0037357264664024115, 'loss_2': 0.0031757354736328125, 'loss_3': -16.331626892089844, 'loss_4': 0.34829673171043396, 'epoch': 25.64}
[INFO|trainer.py:4228] 2025-01-21 14:09:03,836 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:03,836 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 4415/5160 [1:49:08<12:53,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:11,187 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0073427013121545315, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004493270069360733, 'eval_loss_2': 0.0028494298458099365, 'eval_loss_3': -18.19908332824707, 'eval_loss_4': 0.5970674753189087, 'epoch': 25.64}
{'loss': 0.0078, 'grad_norm': 4.939074516296387, 'learning_rate': 4.377906976744186e-06, 'loss_1': 0.003921137657016516, 'loss_2': 0.003894805908203125, 'loss_3': -16.530181884765625, 'loss_4': 0.2774641811847687, 'epoch': 25.65}
{'loss': 0.0071, 'grad_norm': 5.266537666320801, 'learning_rate': 4.372093023255814e-06, 'loss_1': 0.005776426754891872, 'loss_2': 0.001338958740234375, 'loss_3': -16.19733428955078, 'loss_4': 0.4259470999240875, 'epoch': 25.65}
{'loss': 0.0111, 'grad_norm': 5.621645450592041, 'learning_rate': 4.366279069767442e-06, 'loss_1': 0.006539012771099806, 'loss_2': 0.004520416259765625, 'loss_3': -16.548816680908203, 'loss_4': 1.0850253105163574, 'epoch': 25.66}
{'loss': 0.0171, 'grad_norm': 8.430228233337402, 'learning_rate': 4.36046511627907e-06, 'loss_1': 0.015795081853866577, 'loss_2': 0.0012807846069335938, 'loss_3': -16.492942810058594, 'loss_4': 0.43657562136650085, 'epoch': 25.66}
{'loss': 0.01, 'grad_norm': 4.948422908782959, 'learning_rate': 4.354651162790698e-06, 'loss_1': 0.002319636754691601, 'loss_2': 0.00765228271484375, 'loss_3': -16.39313507080078, 'loss_4': 0.7528084516525269, 'epoch': 25.67}
[INFO|trainer.py:4228] 2025-01-21 14:09:11,187 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:11,187 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                               | 4420/5160 [1:49:15<12:48,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:18,538 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009020714089274406, 'eval_runtime': 3.8028, 'eval_samples_per_second': 269.277, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005016380921006203, 'eval_loss_2': 0.004004333168268204, 'eval_loss_3': -18.189937591552734, 'eval_loss_4': 0.5993692278862, 'epoch': 25.67}
{'loss': 0.0043, 'grad_norm': 4.709089279174805, 'learning_rate': 4.348837209302325e-06, 'loss_1': 0.004012067802250385, 'loss_2': 0.0002913475036621094, 'loss_3': -16.49687385559082, 'loss_4': 0.8110632300376892, 'epoch': 25.67}
{'loss': 0.0019, 'grad_norm': 4.520718574523926, 'learning_rate': 4.343023255813954e-06, 'loss_1': 0.001858276897110045, 'loss_2': 5.173683166503906e-05, 'loss_3': -16.48346710205078, 'loss_4': 0.7600407004356384, 'epoch': 25.68}
{'loss': 0.0153, 'grad_norm': 5.77607536315918, 'learning_rate': 4.3372093023255815e-06, 'loss_1': 0.0049019684083759785, 'loss_2': 0.0103607177734375, 'loss_3': -16.41712188720703, 'loss_4': 0.8634388446807861, 'epoch': 25.69}
{'loss': 0.0086, 'grad_norm': 4.523739814758301, 'learning_rate': 4.331395348837209e-06, 'loss_1': 0.005673878360539675, 'loss_2': 0.002956390380859375, 'loss_3': -16.430282592773438, 'loss_4': 0.008315466344356537, 'epoch': 25.69}
{'loss': 0.0229, 'grad_norm': 7.938676357269287, 'learning_rate': 4.325581395348838e-06, 'loss_1': 0.01176412869244814, 'loss_2': 0.0111846923828125, 'loss_3': -16.343181610107422, 'loss_4': 0.3616701364517212, 'epoch': 25.7}
[INFO|trainer.py:4228] 2025-01-21 14:09:18,539 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:18,539 >>   Batch size = 64
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                               | 4425/5160 [1:49:23<12:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:25,897 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00908986758440733, 'eval_runtime': 3.8074, 'eval_samples_per_second': 268.953, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.00511421263217926, 'eval_loss_2': 0.003975655883550644, 'eval_loss_3': -18.183292388916016, 'eval_loss_4': 0.5954487919807434, 'epoch': 25.7}
{'loss': 0.0045, 'grad_norm': 4.844564437866211, 'learning_rate': 4.319767441860465e-06, 'loss_1': 0.0041535357013344765, 'loss_2': 0.00038433074951171875, 'loss_3': -16.676401138305664, 'loss_4': 0.8731950521469116, 'epoch': 25.7}
{'loss': 0.0105, 'grad_norm': 5.661144733428955, 'learning_rate': 4.313953488372093e-06, 'loss_1': 0.008770933374762535, 'loss_2': 0.0017147064208984375, 'loss_3': -16.410234451293945, 'loss_4': 0.34323927760124207, 'epoch': 25.71}
{'loss': 0.0042, 'grad_norm': 4.112980842590332, 'learning_rate': 4.308139534883721e-06, 'loss_1': 0.0015750437742099166, 'loss_2': 0.00264739990234375, 'loss_3': -16.48492431640625, 'loss_4': 0.6341532468795776, 'epoch': 25.72}
{'loss': 0.0124, 'grad_norm': 8.950202941894531, 'learning_rate': 4.302325581395349e-06, 'loss_1': 0.011283507570624352, 'loss_2': 0.0011472702026367188, 'loss_3': -16.691547393798828, 'loss_4': 0.6892082691192627, 'epoch': 25.72}
{'loss': 0.0093, 'grad_norm': 5.034287929534912, 'learning_rate': 4.296511627906977e-06, 'loss_1': 0.0031106015667319298, 'loss_2': 0.006145477294921875, 'loss_3': -16.497631072998047, 'loss_4': 0.5419625639915466, 'epoch': 25.73}
[INFO|trainer.py:4228] 2025-01-21 14:09:25,898 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:25,898 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                               | 4430/5160 [1:49:30<12:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:33,270 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008567444048821926, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.303, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.0052075753919780254, 'eval_loss_2': 0.003359869122505188, 'eval_loss_3': -18.1871280670166, 'eval_loss_4': 0.5816411375999451, 'epoch': 25.73}
{'loss': 0.0029, 'grad_norm': 4.858574390411377, 'learning_rate': 4.290697674418605e-06, 'loss_1': 0.0028060239274054766, 'loss_2': 7.617473602294922e-05, 'loss_3': -16.422016143798828, 'loss_4': 0.3690185844898224, 'epoch': 25.73}
{'loss': 0.0094, 'grad_norm': 6.1862287521362305, 'learning_rate': 4.284883720930232e-06, 'loss_1': 0.005106932017952204, 'loss_2': 0.00431060791015625, 'loss_3': -16.42222023010254, 'loss_4': 0.6841873526573181, 'epoch': 25.74}
{'loss': 0.0115, 'grad_norm': 5.560565948486328, 'learning_rate': 4.27906976744186e-06, 'loss_1': 0.0046607814729213715, 'loss_2': 0.00679779052734375, 'loss_3': -16.346900939941406, 'loss_4': 0.5419632196426392, 'epoch': 25.74}
{'loss': 0.0119, 'grad_norm': 4.8986921310424805, 'learning_rate': 4.273255813953489e-06, 'loss_1': 0.0043268753215670586, 'loss_2': 0.007572174072265625, 'loss_3': -16.381427764892578, 'loss_4': 0.8512547016143799, 'epoch': 25.75}
{'loss': 0.0102, 'grad_norm': 5.115570545196533, 'learning_rate': 4.267441860465117e-06, 'loss_1': 0.0038137976080179214, 'loss_2': 0.006366729736328125, 'loss_3': -16.6026611328125, 'loss_4': 0.5186213850975037, 'epoch': 25.76}
[INFO|trainer.py:4228] 2025-01-21 14:09:33,271 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:33,271 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 4435/5160 [1:49:37<12:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:40,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007909851148724556, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005559427663683891, 'eval_loss_2': 0.0023504234850406647, 'eval_loss_3': -18.182878494262695, 'eval_loss_4': 0.5886827707290649, 'epoch': 25.76}
{'loss': 0.0053, 'grad_norm': 4.762856483459473, 'learning_rate': 4.261627906976744e-06, 'loss_1': 0.003155905520543456, 'loss_2': 0.002117156982421875, 'loss_3': -16.439010620117188, 'loss_4': 0.9414339661598206, 'epoch': 25.76}
{'loss': 0.0129, 'grad_norm': 4.7745208740234375, 'learning_rate': 4.255813953488372e-06, 'loss_1': 0.007442509289830923, 'loss_2': 0.005466461181640625, 'loss_3': -16.51425552368164, 'loss_4': 0.1716269552707672, 'epoch': 25.77}
{'loss': 0.0123, 'grad_norm': 5.238001823425293, 'learning_rate': 4.25e-06, 'loss_1': 0.004817316308617592, 'loss_2': 0.00743865966796875, 'loss_3': -16.333816528320312, 'loss_4': 0.9527119994163513, 'epoch': 25.77}
{'loss': 0.0064, 'grad_norm': 4.752163410186768, 'learning_rate': 4.244186046511628e-06, 'loss_1': 0.004205872770398855, 'loss_2': 0.002155303955078125, 'loss_3': -16.34775161743164, 'loss_4': 1.0902979373931885, 'epoch': 25.78}
{'loss': 0.0068, 'grad_norm': 5.34893274307251, 'learning_rate': 4.238372093023256e-06, 'loss_1': 0.005087716039270163, 'loss_2': 0.0016632080078125, 'loss_3': -16.39156150817871, 'loss_4': 0.41249144077301025, 'epoch': 25.78}
[INFO|trainer.py:4228] 2025-01-21 14:09:40,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:40,633 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 4440/5160 [1:49:45<12:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:47,989 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007439646869897842, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005262210965156555, 'eval_loss_2': 0.0021774359047412872, 'eval_loss_3': -18.195722579956055, 'eval_loss_4': 0.5903339982032776, 'epoch': 25.78}
{'loss': 0.009, 'grad_norm': 6.147589206695557, 'learning_rate': 4.232558139534884e-06, 'loss_1': 0.006141394842416048, 'loss_2': 0.002880096435546875, 'loss_3': -16.387096405029297, 'loss_4': 0.6330482959747314, 'epoch': 25.79}
{'loss': 0.008, 'grad_norm': 4.361745357513428, 'learning_rate': 4.226744186046511e-06, 'loss_1': 0.0024018550757318735, 'loss_2': 0.005573272705078125, 'loss_3': -16.536251068115234, 'loss_4': 0.5814743041992188, 'epoch': 25.8}
{'loss': 0.0106, 'grad_norm': 5.249256610870361, 'learning_rate': 4.22093023255814e-06, 'loss_1': 0.0058576855808496475, 'loss_2': 0.00469970703125, 'loss_3': -16.225149154663086, 'loss_4': 0.6175416707992554, 'epoch': 25.8}
{'loss': 0.0071, 'grad_norm': 4.960512638092041, 'learning_rate': 4.2151162790697675e-06, 'loss_1': 0.0046488624066114426, 'loss_2': 0.0024776458740234375, 'loss_3': -16.395174026489258, 'loss_4': 0.6161477565765381, 'epoch': 25.81}
{'loss': 0.0064, 'grad_norm': 4.999118804931641, 'learning_rate': 4.209302325581395e-06, 'loss_1': 0.003524915548041463, 'loss_2': 0.002857208251953125, 'loss_3': -16.382579803466797, 'loss_4': 0.33722031116485596, 'epoch': 25.81}
[INFO|trainer.py:4228] 2025-01-21 14:09:47,989 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:47,989 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 4445/5160 [1:49:52<12:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:09:55,352 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007758133579045534, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.072, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005493238568305969, 'eval_loss_2': 0.0022648945450782776, 'eval_loss_3': -18.201171875, 'eval_loss_4': 0.5953240990638733, 'epoch': 25.81}
{'loss': 0.0048, 'grad_norm': 4.615294933319092, 'learning_rate': 4.203488372093024e-06, 'loss_1': 0.0035559479147195816, 'loss_2': 0.0012140274047851562, 'loss_3': -16.490842819213867, 'loss_4': 0.3981078565120697, 'epoch': 25.82}
{'loss': 0.0163, 'grad_norm': 8.499802589416504, 'learning_rate': 4.197674418604651e-06, 'loss_1': 0.014790128916501999, 'loss_2': 0.0014715194702148438, 'loss_3': -16.391101837158203, 'loss_4': 0.9129332304000854, 'epoch': 25.83}
{'loss': 0.0137, 'grad_norm': 5.0823259353637695, 'learning_rate': 4.191860465116279e-06, 'loss_1': 0.008287111297249794, 'loss_2': 0.00537872314453125, 'loss_3': -16.49506378173828, 'loss_4': 0.3889814019203186, 'epoch': 25.83}
{'loss': 0.0087, 'grad_norm': 4.972049236297607, 'learning_rate': 4.186046511627907e-06, 'loss_1': 0.0041869040578603745, 'loss_2': 0.00455474853515625, 'loss_3': -16.250957489013672, 'loss_4': 0.2656385004520416, 'epoch': 25.84}
{'loss': 0.0069, 'grad_norm': 5.264019012451172, 'learning_rate': 4.180232558139535e-06, 'loss_1': 0.004438157193362713, 'loss_2': 0.002414703369140625, 'loss_3': -16.32365608215332, 'loss_4': 0.5560779571533203, 'epoch': 25.84}
[INFO|trainer.py:4228] 2025-01-21 14:09:55,352 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:09:55,352 >>   Batch size = 64
 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 4450/5160 [1:49:59<12:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:02,705 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008381943218410015, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.006, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005938809365034103, 'eval_loss_2': 0.0024431347846984863, 'eval_loss_3': -18.20229148864746, 'eval_loss_4': 0.5792290568351746, 'epoch': 25.84}
{'loss': 0.0047, 'grad_norm': 5.177044868469238, 'learning_rate': 4.174418604651163e-06, 'loss_1': 0.00437987269833684, 'loss_2': 0.0003561973571777344, 'loss_3': -16.431005477905273, 'loss_4': 0.7718815803527832, 'epoch': 25.85}
{'loss': 0.0094, 'grad_norm': 5.137308597564697, 'learning_rate': 4.1686046511627915e-06, 'loss_1': 0.003471164032816887, 'loss_2': 0.00589752197265625, 'loss_3': -16.483333587646484, 'loss_4': 0.27225351333618164, 'epoch': 25.85}
{'loss': 0.012, 'grad_norm': 5.1396636962890625, 'learning_rate': 4.1627906976744184e-06, 'loss_1': 0.00748300738632679, 'loss_2': 0.00449371337890625, 'loss_3': -16.42816925048828, 'loss_4': 0.4076162576675415, 'epoch': 25.86}
{'loss': 0.0036, 'grad_norm': 4.8939971923828125, 'learning_rate': 4.156976744186046e-06, 'loss_1': 0.003146891016513109, 'loss_2': 0.0004968643188476562, 'loss_3': -16.252193450927734, 'loss_4': 0.0785088762640953, 'epoch': 25.87}
{'loss': 0.0109, 'grad_norm': 4.593359470367432, 'learning_rate': 4.151162790697675e-06, 'loss_1': 0.0030245922971516848, 'loss_2': 0.0079193115234375, 'loss_3': -16.47469711303711, 'loss_4': 0.5060675144195557, 'epoch': 25.87}
[INFO|trainer.py:4228] 2025-01-21 14:10:02,706 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:02,706 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                              | 4455/5160 [1:50:07<12:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:10,083 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008055039681494236, 'eval_runtime': 3.8176, 'eval_samples_per_second': 268.234, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.005385793745517731, 'eval_loss_2': 0.0026692450046539307, 'eval_loss_3': -18.19672203063965, 'eval_loss_4': 0.5292866230010986, 'epoch': 25.87}
{'loss': 0.0063, 'grad_norm': 4.748715877532959, 'learning_rate': 4.145348837209303e-06, 'loss_1': 0.004079439677298069, 'loss_2': 0.002216339111328125, 'loss_3': -16.404035568237305, 'loss_4': 0.4498419165611267, 'epoch': 25.88}
{'loss': 0.009, 'grad_norm': 4.616330623626709, 'learning_rate': 4.1395348837209304e-06, 'loss_1': 0.005017775576561689, 'loss_2': 0.004032135009765625, 'loss_3': -16.303306579589844, 'loss_4': 0.6261823773384094, 'epoch': 25.88}
{'loss': 0.0085, 'grad_norm': 5.9186692237854, 'learning_rate': 4.133720930232558e-06, 'loss_1': 0.0045496681705117226, 'loss_2': 0.00396728515625, 'loss_3': -16.379837036132812, 'loss_4': 0.3717464208602905, 'epoch': 25.89}
{'loss': 0.0133, 'grad_norm': 7.930228233337402, 'learning_rate': 4.127906976744186e-06, 'loss_1': 0.012003712356090546, 'loss_2': 0.00130462646484375, 'loss_3': -16.381092071533203, 'loss_4': 0.3215634226799011, 'epoch': 25.9}
{'loss': 0.0053, 'grad_norm': 4.442573547363281, 'learning_rate': 4.122093023255814e-06, 'loss_1': 0.0034536144230514765, 'loss_2': 0.001804351806640625, 'loss_3': -16.349475860595703, 'loss_4': 0.7743921279907227, 'epoch': 25.9}
[INFO|trainer.py:4228] 2025-01-21 14:10:10,083 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:10,083 >>   Batch size = 64
 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                             | 4460/5160 [1:50:14<12:08,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:17,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00814603827893734, 'eval_runtime': 3.8111, 'eval_samples_per_second': 268.687, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005327416118234396, 'eval_loss_2': 0.0028186216950416565, 'eval_loss_3': -18.189836502075195, 'eval_loss_4': 0.4994630813598633, 'epoch': 25.9}
{'loss': 0.0027, 'grad_norm': 4.887002468109131, 'learning_rate': 4.116279069767442e-06, 'loss_1': 0.002312124241143465, 'loss_2': 0.00035381317138671875, 'loss_3': -16.568960189819336, 'loss_4': 0.5343968868255615, 'epoch': 25.91}
{'loss': 0.0075, 'grad_norm': 5.419072151184082, 'learning_rate': 4.11046511627907e-06, 'loss_1': 0.005458423867821693, 'loss_2': 0.0020732879638671875, 'loss_3': -16.491939544677734, 'loss_4': 0.7726322412490845, 'epoch': 25.91}
{'loss': 0.0045, 'grad_norm': 4.5007195472717285, 'learning_rate': 4.104651162790697e-06, 'loss_1': 0.002784714801236987, 'loss_2': 0.0016880035400390625, 'loss_3': -16.375118255615234, 'loss_4': 0.6875630617141724, 'epoch': 25.92}
{'loss': 0.0106, 'grad_norm': 6.362522125244141, 'learning_rate': 4.098837209302326e-06, 'loss_1': 0.006144867744296789, 'loss_2': 0.00446319580078125, 'loss_3': -16.31964874267578, 'loss_4': 0.31028300523757935, 'epoch': 25.92}
{'loss': 0.0048, 'grad_norm': 5.322412967681885, 'learning_rate': 4.0930232558139536e-06, 'loss_1': 0.004801181610673666, 'loss_2': 3.6776065826416016e-05, 'loss_3': -16.348337173461914, 'loss_4': 0.49735110998153687, 'epoch': 25.93}
[INFO|trainer.py:4228] 2025-01-21 14:10:17,447 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:17,447 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                             | 4465/5160 [1:50:21<12:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:24,804 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008283698931336403, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.567, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.00537189282476902, 'eval_loss_2': 0.002911806106567383, 'eval_loss_3': -18.200111389160156, 'eval_loss_4': 0.5034531354904175, 'epoch': 25.93}
{'loss': 0.006, 'grad_norm': 5.1687750816345215, 'learning_rate': 4.087209302325581e-06, 'loss_1': 0.005570738110691309, 'loss_2': 0.0004363059997558594, 'loss_3': -16.257234573364258, 'loss_4': 0.4997103214263916, 'epoch': 25.94}
{'loss': 0.0105, 'grad_norm': 6.445962429046631, 'learning_rate': 4.08139534883721e-06, 'loss_1': 0.007479237392544746, 'loss_2': 0.0029811859130859375, 'loss_3': -16.361236572265625, 'loss_4': -0.016154780983924866, 'epoch': 25.94}
{'loss': 0.0128, 'grad_norm': 9.621670722961426, 'learning_rate': 4.075581395348838e-06, 'loss_1': 0.010773787274956703, 'loss_2': 0.002002716064453125, 'loss_3': -16.513866424560547, 'loss_4': 0.5242997407913208, 'epoch': 25.95}
{'loss': 0.0083, 'grad_norm': 5.652400493621826, 'learning_rate': 4.069767441860465e-06, 'loss_1': 0.005482472479343414, 'loss_2': 0.002803802490234375, 'loss_3': -16.438920974731445, 'loss_4': 0.5891458988189697, 'epoch': 25.95}
{'loss': 0.0066, 'grad_norm': 4.791228771209717, 'learning_rate': 4.063953488372093e-06, 'loss_1': 0.005125404801219702, 'loss_2': 0.00148773193359375, 'loss_3': -16.46914291381836, 'loss_4': 0.37956270575523376, 'epoch': 25.96}
[INFO|trainer.py:4228] 2025-01-21 14:10:24,804 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:24,804 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                             | 4470/5160 [1:50:29<11:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:32,152 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007527845911681652, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.19, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004997773561626673, 'eval_loss_2': 0.002530071884393692, 'eval_loss_3': -18.202068328857422, 'eval_loss_4': 0.4771769046783447, 'epoch': 25.96}
{'loss': 0.0076, 'grad_norm': 4.70906925201416, 'learning_rate': 4.058139534883721e-06, 'loss_1': 0.004890288691967726, 'loss_2': 0.002704620361328125, 'loss_3': -16.577836990356445, 'loss_4': 0.09040520340204239, 'epoch': 25.97}
{'loss': 0.0162, 'grad_norm': 10.647198677062988, 'learning_rate': 4.052325581395349e-06, 'loss_1': 0.011865610256791115, 'loss_2': 0.004306793212890625, 'loss_3': -16.449005126953125, 'loss_4': 0.40852850675582886, 'epoch': 25.97}
{'loss': 0.0154, 'grad_norm': 5.487430572509766, 'learning_rate': 4.0465116279069775e-06, 'loss_1': 0.006920119281858206, 'loss_2': 0.0084381103515625, 'loss_3': -16.36598777770996, 'loss_4': 0.6874001026153564, 'epoch': 25.98}
{'loss': 0.0182, 'grad_norm': 6.569418907165527, 'learning_rate': 4.0406976744186045e-06, 'loss_1': 0.012100213207304478, 'loss_2': 0.00611114501953125, 'loss_3': -16.156747817993164, 'loss_4': 0.4553440809249878, 'epoch': 25.98}
{'loss': 0.0113, 'grad_norm': 5.32736349105835, 'learning_rate': 4.034883720930232e-06, 'loss_1': 0.004327323753386736, 'loss_2': 0.00696563720703125, 'loss_3': -16.28240203857422, 'loss_4': 0.4207109212875366, 'epoch': 25.99}
[INFO|trainer.py:4228] 2025-01-21 14:10:32,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:32,153 >>   Batch size = 64
 87%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                             | 4475/5160 [1:50:36<11:31,  1.01s/it][INFO|trainer.py:4226] 2025-01-21 14:10:39,201 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0073781744576990604, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.874, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004658474121242762, 'eval_loss_2': 0.002719700336456299, 'eval_loss_3': -18.200706481933594, 'eval_loss_4': 0.4348892569541931, 'epoch': 25.99}
{'loss': 0.0117, 'grad_norm': 5.383581161499023, 'learning_rate': 4.029069767441861e-06, 'loss_1': 0.00580142205581069, 'loss_2': 0.00585174560546875, 'loss_3': -16.49097442626953, 'loss_4': 0.4262910485267639, 'epoch': 25.99}
{'loss': 0.0049, 'grad_norm': 6.138556480407715, 'learning_rate': 4.023255813953489e-06, 'loss_1': 0.003796324133872986, 'loss_2': 0.0011444091796875, 'loss_3': -16.548503875732422, 'loss_4': 1.0797899961471558, 'epoch': 26.0}
{'loss': 0.0118, 'grad_norm': 5.321761608123779, 'learning_rate': 4.0174418604651165e-06, 'loss_1': 0.006581089459359646, 'loss_2': 0.00518798828125, 'loss_3': -16.328405380249023, 'loss_4': 0.19896200299263, 'epoch': 26.01}
{'loss': 0.0077, 'grad_norm': 5.472469329833984, 'learning_rate': 4.011627906976744e-06, 'loss_1': 0.0047192624770104885, 'loss_2': 0.003002166748046875, 'loss_3': -16.524551391601562, 'loss_4': 0.13647045195102692, 'epoch': 26.01}
{'loss': 0.0126, 'grad_norm': 5.842899799346924, 'learning_rate': 4.005813953488372e-06, 'loss_1': 0.011114474385976791, 'loss_2': 0.0014410018920898438, 'loss_3': -16.204544067382812, 'loss_4': 0.38151854276657104, 'epoch': 26.02}
[INFO|trainer.py:4228] 2025-01-21 14:10:39,202 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:39,202 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                            | 4480/5160 [1:50:43<11:44,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:46,566 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0076242717914283276, 'eval_runtime': 3.8063, 'eval_samples_per_second': 269.031, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004834007006138563, 'eval_loss_2': 0.0027902647852897644, 'eval_loss_3': -18.196794509887695, 'eval_loss_4': 0.3756282925605774, 'epoch': 26.02}
{'loss': 0.0106, 'grad_norm': 9.38469123840332, 'learning_rate': 4e-06, 'loss_1': 0.009477280080318451, 'loss_2': 0.001110076904296875, 'loss_3': -16.479305267333984, 'loss_4': 0.09429532289505005, 'epoch': 26.02}
{'loss': 0.0047, 'grad_norm': 4.97732400894165, 'learning_rate': 3.9941860465116285e-06, 'loss_1': 0.004074689466506243, 'loss_2': 0.0005984306335449219, 'loss_3': -16.323087692260742, 'loss_4': 0.350885808467865, 'epoch': 26.03}
{'loss': 0.0039, 'grad_norm': 5.146932125091553, 'learning_rate': 3.988372093023256e-06, 'loss_1': 0.003467399626970291, 'loss_2': 0.0004820823669433594, 'loss_3': -16.357648849487305, 'loss_4': 0.2468034327030182, 'epoch': 26.03}
{'loss': 0.0029, 'grad_norm': 4.589432716369629, 'learning_rate': 3.982558139534884e-06, 'loss_1': 0.0017904387786984444, 'loss_2': 0.0010738372802734375, 'loss_3': -16.550073623657227, 'loss_4': 0.4798610806465149, 'epoch': 26.04}
{'loss': 0.0041, 'grad_norm': 5.282338619232178, 'learning_rate': 3.976744186046512e-06, 'loss_1': 0.0033049355261027813, 'loss_2': 0.0008401870727539062, 'loss_3': -16.423320770263672, 'loss_4': 0.6411340236663818, 'epoch': 26.05}
[INFO|trainer.py:4228] 2025-01-21 14:10:46,566 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:46,566 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                            | 4485/5160 [1:50:51<11:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:10:53,935 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007453990634530783, 'eval_runtime': 3.8206, 'eval_samples_per_second': 268.021, 'eval_steps_per_second': 4.188, 'eval_loss_1': 0.0047348118387162685, 'eval_loss_2': 0.002719178795814514, 'eval_loss_3': -18.185787200927734, 'eval_loss_4': 0.3758827745914459, 'epoch': 26.05}
{'loss': 0.0175, 'grad_norm': 13.964967727661133, 'learning_rate': 3.97093023255814e-06, 'loss_1': 0.01722983457148075, 'loss_2': 0.00029850006103515625, 'loss_3': -16.380638122558594, 'loss_4': 0.20655344426631927, 'epoch': 26.05}
{'loss': 0.037, 'grad_norm': 20.416296005249023, 'learning_rate': 3.965116279069767e-06, 'loss_1': 0.03269364312291145, 'loss_2': 0.0043487548828125, 'loss_3': -16.246322631835938, 'loss_4': 0.8055520057678223, 'epoch': 26.06}
{'loss': 0.0079, 'grad_norm': 4.991695404052734, 'learning_rate': 3.959302325581396e-06, 'loss_1': 0.004602442029863596, 'loss_2': 0.0032749176025390625, 'loss_3': -16.410343170166016, 'loss_4': 0.820723295211792, 'epoch': 26.06}
{'loss': 0.0086, 'grad_norm': 5.4381608963012695, 'learning_rate': 3.953488372093024e-06, 'loss_1': 0.008031051605939865, 'loss_2': 0.0005908012390136719, 'loss_3': -16.15436363220215, 'loss_4': 0.2834591865539551, 'epoch': 26.07}
{'loss': 0.0267, 'grad_norm': 14.543814659118652, 'learning_rate': 3.947674418604651e-06, 'loss_1': 0.019142910838127136, 'loss_2': 0.00750732421875, 'loss_3': -16.421308517456055, 'loss_4': 0.7390275001525879, 'epoch': 26.08}
[INFO|trainer.py:4228] 2025-01-21 14:10:53,935 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:10:53,935 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 4490/5160 [1:50:58<11:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:01,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006900861859321594, 'eval_runtime': 3.8039, 'eval_samples_per_second': 269.197, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.0047219241969287395, 'eval_loss_2': 0.0021789371967315674, 'eval_loss_3': -18.19977378845215, 'eval_loss_4': 0.3598884046077728, 'epoch': 26.08}
{'loss': 0.011, 'grad_norm': 6.545359134674072, 'learning_rate': 3.941860465116279e-06, 'loss_1': 0.007691819220781326, 'loss_2': 0.0032825469970703125, 'loss_3': -16.360820770263672, 'loss_4': 0.1946556568145752, 'epoch': 26.08}
{'loss': 0.0192, 'grad_norm': 8.45417594909668, 'learning_rate': 3.936046511627907e-06, 'loss_1': 0.014600645750761032, 'loss_2': 0.00461578369140625, 'loss_3': -16.535072326660156, 'loss_4': 0.16095007956027985, 'epoch': 26.09}
{'loss': 0.0083, 'grad_norm': 4.802667617797852, 'learning_rate': 3.930232558139535e-06, 'loss_1': 0.005388369783759117, 'loss_2': 0.0029125213623046875, 'loss_3': -16.292797088623047, 'loss_4': 0.7614535689353943, 'epoch': 26.09}
{'loss': 0.0035, 'grad_norm': 4.610980033874512, 'learning_rate': 3.9244186046511636e-06, 'loss_1': 0.002570596756413579, 'loss_2': 0.000911712646484375, 'loss_3': -16.60818862915039, 'loss_4': 0.593299925327301, 'epoch': 26.1}
{'loss': 0.0067, 'grad_norm': 5.343846321105957, 'learning_rate': 3.9186046511627905e-06, 'loss_1': 0.004891061224043369, 'loss_2': 0.0018053054809570312, 'loss_3': -16.412353515625, 'loss_4': 0.43498343229293823, 'epoch': 26.1}
[INFO|trainer.py:4228] 2025-01-21 14:11:01,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:01,288 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4495/5160 [1:51:05<11:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:08,644 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007341635879129171, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.033, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00499425595626235, 'eval_loss_2': 0.0023473799228668213, 'eval_loss_3': -18.203229904174805, 'eval_loss_4': 0.35198596119880676, 'epoch': 26.1}
{'loss': 0.0061, 'grad_norm': 4.439425945281982, 'learning_rate': 3.912790697674418e-06, 'loss_1': 0.0025558979250490665, 'loss_2': 0.0035762786865234375, 'loss_3': -16.44051742553711, 'loss_4': 0.4475610852241516, 'epoch': 26.11}
{'loss': 0.008, 'grad_norm': 5.669605731964111, 'learning_rate': 3.906976744186047e-06, 'loss_1': 0.00520382821559906, 'loss_2': 0.00274658203125, 'loss_3': -16.39344024658203, 'loss_4': 0.3910866975784302, 'epoch': 26.12}
{'loss': 0.0048, 'grad_norm': 4.349059104919434, 'learning_rate': 3.901162790697675e-06, 'loss_1': 0.004104126710444689, 'loss_2': 0.0006914138793945312, 'loss_3': -16.6207332611084, 'loss_4': 0.5120882391929626, 'epoch': 26.12}
{'loss': 0.0082, 'grad_norm': 5.496335506439209, 'learning_rate': 3.8953488372093025e-06, 'loss_1': 0.004172926302999258, 'loss_2': 0.00405120849609375, 'loss_3': -16.277212142944336, 'loss_4': 0.1790747344493866, 'epoch': 26.13}
{'loss': 0.0071, 'grad_norm': 6.521227836608887, 'learning_rate': 3.889534883720931e-06, 'loss_1': 0.005730144213885069, 'loss_2': 0.0013790130615234375, 'loss_3': -16.49919891357422, 'loss_4': 0.10927163064479828, 'epoch': 26.13}
[INFO|trainer.py:4228] 2025-01-21 14:11:08,644 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:08,644 >>   Batch size = 64
 87%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                            | 4500/5160 [1:51:13<11:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:16,005 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007680666632950306, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.917, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004898004699498415, 'eval_loss_2': 0.0027826614677906036, 'eval_loss_3': -18.199832916259766, 'eval_loss_4': 0.3666854202747345, 'epoch': 26.13}
{'loss': 0.0084, 'grad_norm': 4.409266471862793, 'learning_rate': 3.883720930232558e-06, 'loss_1': 0.003682064125314355, 'loss_2': 0.0047454833984375, 'loss_3': -16.354413986206055, 'loss_4': 0.47756853699684143, 'epoch': 26.14}
{'loss': 0.0093, 'grad_norm': 4.680692672729492, 'learning_rate': 3.877906976744186e-06, 'loss_1': 0.004883620887994766, 'loss_2': 0.004383087158203125, 'loss_3': -16.40329933166504, 'loss_4': 0.368086576461792, 'epoch': 26.15}
{'loss': 0.0064, 'grad_norm': 4.902985095977783, 'learning_rate': 3.8720930232558145e-06, 'loss_1': 0.005103795789182186, 'loss_2': 0.0013217926025390625, 'loss_3': -16.46962547302246, 'loss_4': 0.029159702360630035, 'epoch': 26.15}
{'loss': 0.0062, 'grad_norm': 4.603710174560547, 'learning_rate': 3.866279069767442e-06, 'loss_1': 0.0038796947337687016, 'loss_2': 0.002300262451171875, 'loss_3': -16.533655166625977, 'loss_4': 0.9098442196846008, 'epoch': 26.16}
{'loss': 0.0043, 'grad_norm': 4.5275444984436035, 'learning_rate': 3.86046511627907e-06, 'loss_1': 0.0033362656831741333, 'loss_2': 0.0009183883666992188, 'loss_3': -16.575286865234375, 'loss_4': 0.24576660990715027, 'epoch': 26.16}
[INFO|trainer.py:4228] 2025-01-21 14:11:16,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:16,005 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 4505/5160 [1:51:20<11:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:23,356 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008175020106136799, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.104, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004894827492535114, 'eval_loss_2': 0.0032801926136016846, 'eval_loss_3': -18.20243263244629, 'eval_loss_4': 0.35465580224990845, 'epoch': 26.16}
{'loss': 0.0132, 'grad_norm': 4.399499893188477, 'learning_rate': 3.854651162790698e-06, 'loss_1': 0.004619859624654055, 'loss_2': 0.00853729248046875, 'loss_3': -16.44917869567871, 'loss_4': 0.060974206775426865, 'epoch': 26.17}
{'loss': 0.0213, 'grad_norm': 6.533324718475342, 'learning_rate': 3.848837209302326e-06, 'loss_1': 0.007306271232664585, 'loss_2': 0.0140380859375, 'loss_3': -16.260173797607422, 'loss_4': -0.23573037981987, 'epoch': 26.17}
{'loss': 0.0068, 'grad_norm': 6.904996395111084, 'learning_rate': 3.843023255813953e-06, 'loss_1': 0.005868705455213785, 'loss_2': 0.0009350776672363281, 'loss_3': -16.454524993896484, 'loss_4': 0.3401797413825989, 'epoch': 26.18}
{'loss': 0.0117, 'grad_norm': 12.534974098205566, 'learning_rate': 3.837209302325582e-06, 'loss_1': 0.010313782840967178, 'loss_2': 0.001392364501953125, 'loss_3': -16.45433807373047, 'loss_4': -0.004470273852348328, 'epoch': 26.19}
{'loss': 0.0069, 'grad_norm': 4.55463981628418, 'learning_rate': 3.83139534883721e-06, 'loss_1': 0.0031974560115486383, 'loss_2': 0.003726959228515625, 'loss_3': -16.519819259643555, 'loss_4': 0.2119354009628296, 'epoch': 26.19}
[INFO|trainer.py:4228] 2025-01-21 14:11:23,357 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:23,357 >>   Batch size = 64
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 4510/5160 [1:51:27<11:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:30,723 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008106758818030357, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.29, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.00469971215352416, 'eval_loss_2': 0.0034070461988449097, 'eval_loss_3': -18.21916961669922, 'eval_loss_4': 0.3601684868335724, 'epoch': 26.19}
{'loss': 0.0061, 'grad_norm': 5.178877830505371, 'learning_rate': 3.825581395348837e-06, 'loss_1': 0.005032374523580074, 'loss_2': 0.0011138916015625, 'loss_3': -16.36266326904297, 'loss_4': 0.3682718873023987, 'epoch': 26.2}
{'loss': 0.0071, 'grad_norm': 4.977093696594238, 'learning_rate': 3.819767441860465e-06, 'loss_1': 0.0034735011868178844, 'loss_2': 0.0036296844482421875, 'loss_3': -16.439128875732422, 'loss_4': 0.37463077902793884, 'epoch': 26.2}
{'loss': 0.005, 'grad_norm': 4.277724742889404, 'learning_rate': 3.813953488372093e-06, 'loss_1': 0.0040056584402918816, 'loss_2': 0.000949859619140625, 'loss_3': -16.41666030883789, 'loss_4': 0.3626610040664673, 'epoch': 26.21}
{'loss': 0.0114, 'grad_norm': 7.265513896942139, 'learning_rate': 3.808139534883721e-06, 'loss_1': 0.007683114148676395, 'loss_2': 0.0037384033203125, 'loss_3': -16.4902286529541, 'loss_4': 0.4076077938079834, 'epoch': 26.22}
{'loss': 0.0051, 'grad_norm': 4.623685359954834, 'learning_rate': 3.802325581395349e-06, 'loss_1': 0.004665129352360964, 'loss_2': 0.0004711151123046875, 'loss_3': -16.162582397460938, 'loss_4': 0.23187926411628723, 'epoch': 26.22}
[INFO|trainer.py:4228] 2025-01-21 14:11:30,723 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:30,723 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                           | 4515/5160 [1:51:35<11:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:38,080 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007914528250694275, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.812, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00475369393825531, 'eval_loss_2': 0.003160834312438965, 'eval_loss_3': -18.218507766723633, 'eval_loss_4': 0.37432706356048584, 'epoch': 26.22}
{'loss': 0.0083, 'grad_norm': 4.752254962921143, 'learning_rate': 3.7965116279069774e-06, 'loss_1': 0.003481518942862749, 'loss_2': 0.004810333251953125, 'loss_3': -16.365636825561523, 'loss_4': 0.6221188902854919, 'epoch': 26.23}
{'loss': 0.0061, 'grad_norm': 4.580069065093994, 'learning_rate': 3.7906976744186043e-06, 'loss_1': 0.0030899804551154375, 'loss_2': 0.0029697418212890625, 'loss_3': -16.371822357177734, 'loss_4': 0.4337007403373718, 'epoch': 26.23}
{'loss': 0.055, 'grad_norm': 24.313426971435547, 'learning_rate': 3.7848837209302325e-06, 'loss_1': 0.05071285367012024, 'loss_2': 0.00431060791015625, 'loss_3': -16.52934455871582, 'loss_4': 0.2960263192653656, 'epoch': 26.24}
{'loss': 0.0029, 'grad_norm': 4.719381332397461, 'learning_rate': 3.7790697674418607e-06, 'loss_1': 0.001605279161594808, 'loss_2': 0.001293182373046875, 'loss_3': -16.347454071044922, 'loss_4': 0.2901310920715332, 'epoch': 26.24}
{'loss': 0.0063, 'grad_norm': 4.693143367767334, 'learning_rate': 3.7732558139534885e-06, 'loss_1': 0.003954155836254358, 'loss_2': 0.00231170654296875, 'loss_3': -16.430164337158203, 'loss_4': 0.5251784324645996, 'epoch': 26.25}
[INFO|trainer.py:4228] 2025-01-21 14:11:38,080 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:38,081 >>   Batch size = 64
 88%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 4520/5160 [1:51:42<11:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:45,428 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007823983207345009, 'eval_runtime': 3.8022, 'eval_samples_per_second': 269.319, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004762197379022837, 'eval_loss_2': 0.0030617862939834595, 'eval_loss_3': -18.21445083618164, 'eval_loss_4': 0.38246285915374756, 'epoch': 26.25}
{'loss': 0.015, 'grad_norm': 7.588832378387451, 'learning_rate': 3.7674418604651167e-06, 'loss_1': 0.012440328486263752, 'loss_2': 0.0025177001953125, 'loss_3': -16.366853713989258, 'loss_4': 0.47144579887390137, 'epoch': 26.26}
{'loss': 0.011, 'grad_norm': 5.224515438079834, 'learning_rate': 3.761627906976744e-06, 'loss_1': 0.0027915353421121836, 'loss_2': 0.0081634521484375, 'loss_3': -16.582645416259766, 'loss_4': 0.1751301884651184, 'epoch': 26.26}
{'loss': 0.0058, 'grad_norm': 4.701371669769287, 'learning_rate': 3.755813953488372e-06, 'loss_1': 0.004762127995491028, 'loss_2': 0.0010528564453125, 'loss_3': -16.487937927246094, 'loss_4': 0.23592302203178406, 'epoch': 26.27}
{'loss': 0.0111, 'grad_norm': 5.6852498054504395, 'learning_rate': 3.75e-06, 'loss_1': 0.008423037827014923, 'loss_2': 0.002719879150390625, 'loss_3': -16.399940490722656, 'loss_4': 0.5579109787940979, 'epoch': 26.27}
{'loss': 0.0077, 'grad_norm': 4.320309162139893, 'learning_rate': 3.7441860465116283e-06, 'loss_1': 0.004603154491633177, 'loss_2': 0.003086090087890625, 'loss_3': -16.446964263916016, 'loss_4': 0.4696844816207886, 'epoch': 26.28}
[INFO|trainer.py:4228] 2025-01-21 14:11:45,428 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:45,428 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 4525/5160 [1:51:49<10:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:11:52,776 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007635999470949173, 'eval_runtime': 3.8025, 'eval_samples_per_second': 269.295, 'eval_steps_per_second': 4.208, 'eval_loss_1': 0.004707659594714642, 'eval_loss_2': 0.002928338944911957, 'eval_loss_3': -18.20767593383789, 'eval_loss_4': 0.39380645751953125, 'epoch': 26.28}
{'loss': 0.0064, 'grad_norm': 4.624517917633057, 'learning_rate': 3.7383720930232557e-06, 'loss_1': 0.004559093154966831, 'loss_2': 0.0017957687377929688, 'loss_3': -16.517854690551758, 'loss_4': 0.2621893882751465, 'epoch': 26.28}
{'loss': 0.0091, 'grad_norm': 7.813252925872803, 'learning_rate': 3.732558139534884e-06, 'loss_1': 0.007160722278058529, 'loss_2': 0.001895904541015625, 'loss_3': -16.445995330810547, 'loss_4': -0.18203988671302795, 'epoch': 26.29}
{'loss': 0.0951, 'grad_norm': 17.41767692565918, 'learning_rate': 3.7267441860465117e-06, 'loss_1': 0.09237413108348846, 'loss_2': 0.0027408599853515625, 'loss_3': -16.52657127380371, 'loss_4': 0.4622652530670166, 'epoch': 26.3}
{'loss': 0.0031, 'grad_norm': 4.486240863800049, 'learning_rate': 3.7209302325581394e-06, 'loss_1': 0.0021970178931951523, 'loss_2': 0.0009489059448242188, 'loss_3': -16.253889083862305, 'loss_4': 0.5292209386825562, 'epoch': 26.3}
{'loss': 0.0052, 'grad_norm': 4.439772129058838, 'learning_rate': 3.7151162790697677e-06, 'loss_1': 0.003893660381436348, 'loss_2': 0.0013456344604492188, 'loss_3': -16.399152755737305, 'loss_4': 0.41653361916542053, 'epoch': 26.31}
[INFO|trainer.py:4228] 2025-01-21 14:11:52,776 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:11:52,776 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                          | 4530/5160 [1:51:57<10:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:00,137 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007720569148659706, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.086, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0047256071120500565, 'eval_loss_2': 0.0029949620366096497, 'eval_loss_3': -18.19964027404785, 'eval_loss_4': 0.3774978220462799, 'epoch': 26.31}
{'loss': 0.0044, 'grad_norm': 4.764728546142578, 'learning_rate': 3.7093023255813954e-06, 'loss_1': 0.0037942680064588785, 'loss_2': 0.0005931854248046875, 'loss_3': -16.580686569213867, 'loss_4': 0.07782134413719177, 'epoch': 26.31}
{'loss': 0.0187, 'grad_norm': 10.710643768310547, 'learning_rate': 3.7034883720930232e-06, 'loss_1': 0.01137277577072382, 'loss_2': 0.0073394775390625, 'loss_3': -16.366382598876953, 'loss_4': 0.3178943395614624, 'epoch': 26.32}
{'loss': 0.0065, 'grad_norm': 5.1250786781311035, 'learning_rate': 3.6976744186046514e-06, 'loss_1': 0.003908059559762478, 'loss_2': 0.0025959014892578125, 'loss_3': -16.418460845947266, 'loss_4': 0.4727225601673126, 'epoch': 26.33}
{'loss': 0.0056, 'grad_norm': 5.12839937210083, 'learning_rate': 3.6918604651162792e-06, 'loss_1': 0.005364962387830019, 'loss_2': 0.0001920461654663086, 'loss_3': -16.409381866455078, 'loss_4': 0.5189907550811768, 'epoch': 26.33}
{'loss': 0.0095, 'grad_norm': 10.30820369720459, 'learning_rate': 3.686046511627907e-06, 'loss_1': 0.008848725818097591, 'loss_2': 0.0006589889526367188, 'loss_3': -16.320594787597656, 'loss_4': 0.48861587047576904, 'epoch': 26.34}
[INFO|trainer.py:4228] 2025-01-21 14:12:00,137 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:00,137 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                          | 4535/5160 [1:52:04<10:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:07,492 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0074537876062095165, 'eval_runtime': 3.803, 'eval_samples_per_second': 269.261, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0043610516004264355, 'eval_loss_2': 0.003092736005783081, 'eval_loss_3': -18.198875427246094, 'eval_loss_4': 0.36331602931022644, 'epoch': 26.34}
{'loss': 0.0101, 'grad_norm': 4.409335613250732, 'learning_rate': 3.680232558139535e-06, 'loss_1': 0.003956869710236788, 'loss_2': 0.006134033203125, 'loss_3': -16.453161239624023, 'loss_4': -0.027697168290615082, 'epoch': 26.34}
{'loss': 0.0107, 'grad_norm': 5.882745265960693, 'learning_rate': 3.674418604651163e-06, 'loss_1': 0.006513504311442375, 'loss_2': 0.00421142578125, 'loss_3': -16.47783088684082, 'loss_4': 0.40854257345199585, 'epoch': 26.35}
{'loss': 0.0116, 'grad_norm': 6.684556484222412, 'learning_rate': 3.6686046511627908e-06, 'loss_1': 0.009055993519723415, 'loss_2': 0.002536773681640625, 'loss_3': -16.405427932739258, 'loss_4': 0.6298996210098267, 'epoch': 26.35}
{'loss': 0.0074, 'grad_norm': 5.190736293792725, 'learning_rate': 3.6627906976744186e-06, 'loss_1': 0.006567932199686766, 'loss_2': 0.0008044242858886719, 'loss_3': -16.467674255371094, 'loss_4': 0.5191514492034912, 'epoch': 26.36}
{'loss': 0.0041, 'grad_norm': 4.717257976531982, 'learning_rate': 3.6569767441860468e-06, 'loss_1': 0.0031237320508807898, 'loss_2': 0.000995635986328125, 'loss_3': -16.44482421875, 'loss_4': 0.5180128216743469, 'epoch': 26.37}
[INFO|trainer.py:4228] 2025-01-21 14:12:07,492 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:07,492 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                          | 4540/5160 [1:52:12<10:54,  1.06s/it][INFO|trainer.py:4226] 2025-01-21 14:12:15,054 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007404612842947245, 'eval_runtime': 4.0039, 'eval_samples_per_second': 255.753, 'eval_steps_per_second': 3.996, 'eval_loss_1': 0.004155605100095272, 'eval_loss_2': 0.00324900820851326, 'eval_loss_3': -18.19634437561035, 'eval_loss_4': 0.34869739413261414, 'epoch': 26.37}
{'loss': 0.0107, 'grad_norm': 5.238508701324463, 'learning_rate': 3.6511627906976746e-06, 'loss_1': 0.0068323346786201, 'loss_2': 0.003887176513671875, 'loss_3': -16.494049072265625, 'loss_4': 0.5254437923431396, 'epoch': 26.37}
{'loss': 0.0084, 'grad_norm': 5.35534143447876, 'learning_rate': 3.6453488372093023e-06, 'loss_1': 0.00785419624298811, 'loss_2': 0.0005884170532226562, 'loss_3': -16.544363021850586, 'loss_4': 0.29269665479660034, 'epoch': 26.38}
{'loss': 0.0177, 'grad_norm': 13.06251049041748, 'learning_rate': 3.6395348837209306e-06, 'loss_1': 0.01613796316087246, 'loss_2': 0.001556396484375, 'loss_3': -16.43172836303711, 'loss_4': 0.3396610915660858, 'epoch': 26.38}
{'loss': 0.0131, 'grad_norm': 6.298466682434082, 'learning_rate': 3.633720930232558e-06, 'loss_1': 0.011132397688925266, 'loss_2': 0.00199127197265625, 'loss_3': -16.30557632446289, 'loss_4': 0.154710054397583, 'epoch': 26.39}
{'loss': 0.007, 'grad_norm': 6.138694763183594, 'learning_rate': 3.627906976744186e-06, 'loss_1': 0.006825888529419899, 'loss_2': 0.0001728534698486328, 'loss_3': -16.314319610595703, 'loss_4': 0.4128226637840271, 'epoch': 26.4}
[INFO|trainer.py:4228] 2025-01-21 14:12:15,054 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:15,054 >>   Batch size = 64
 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                          | 4545/5160 [1:52:19<10:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:22,421 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00709337554872036, 'eval_runtime': 3.8078, 'eval_samples_per_second': 268.922, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.003973639104515314, 'eval_loss_2': 0.003119736909866333, 'eval_loss_3': -18.190561294555664, 'eval_loss_4': 0.3606773912906647, 'epoch': 26.4}
{'loss': 0.0044, 'grad_norm': 4.155887126922607, 'learning_rate': 3.6220930232558143e-06, 'loss_1': 0.0025320614222437143, 'loss_2': 0.001873016357421875, 'loss_3': -16.31699562072754, 'loss_4': 0.2668822407722473, 'epoch': 26.4}
{'loss': 0.0063, 'grad_norm': 4.5410919189453125, 'learning_rate': 3.6162790697674417e-06, 'loss_1': 0.0032427452970296144, 'loss_2': 0.003021240234375, 'loss_3': -16.422958374023438, 'loss_4': 0.370901882648468, 'epoch': 26.41}
{'loss': 0.0058, 'grad_norm': 5.545037746429443, 'learning_rate': 3.61046511627907e-06, 'loss_1': 0.0055642761290073395, 'loss_2': 0.0002853870391845703, 'loss_3': -16.56988525390625, 'loss_4': -0.030854571610689163, 'epoch': 26.41}
{'loss': 0.0093, 'grad_norm': 5.948937892913818, 'learning_rate': 3.604651162790698e-06, 'loss_1': 0.007455554325133562, 'loss_2': 0.0018110275268554688, 'loss_3': -16.436975479125977, 'loss_4': 0.21064874529838562, 'epoch': 26.42}
{'loss': 0.0084, 'grad_norm': 5.1016082763671875, 'learning_rate': 3.5988372093023255e-06, 'loss_1': 0.0025689355097711086, 'loss_2': 0.005828857421875, 'loss_3': -16.391550064086914, 'loss_4': 0.27952149510383606, 'epoch': 26.42}
[INFO|trainer.py:4228] 2025-01-21 14:12:22,421 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:22,421 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                          | 4550/5160 [1:52:26<10:34,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:29,782 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007121484726667404, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.931, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004010837525129318, 'eval_loss_2': 0.003110647201538086, 'eval_loss_3': -18.192808151245117, 'eval_loss_4': 0.36903896927833557, 'epoch': 26.42}
{'loss': 0.0089, 'grad_norm': 5.583313465118408, 'learning_rate': 3.5930232558139537e-06, 'loss_1': 0.0069062914699316025, 'loss_2': 0.00202178955078125, 'loss_3': -16.440404891967773, 'loss_4': 0.14998233318328857, 'epoch': 26.43}
{'loss': 0.0035, 'grad_norm': 4.7259392738342285, 'learning_rate': 3.5872093023255815e-06, 'loss_1': 0.002660692436620593, 'loss_2': 0.0008769035339355469, 'loss_3': -16.39736557006836, 'loss_4': 0.5141460299491882, 'epoch': 26.44}
{'loss': 0.0089, 'grad_norm': 7.73469877243042, 'learning_rate': 3.5813953488372093e-06, 'loss_1': 0.008862918242812157, 'loss_2': 6.365776062011719e-05, 'loss_3': -16.549942016601562, 'loss_4': 0.047301217913627625, 'epoch': 26.44}
{'loss': 0.0114, 'grad_norm': 5.947439670562744, 'learning_rate': 3.5755813953488375e-06, 'loss_1': 0.006060655228793621, 'loss_2': 0.005313873291015625, 'loss_3': -16.653728485107422, 'loss_4': 0.2719130516052246, 'epoch': 26.45}
{'loss': 0.0116, 'grad_norm': 6.422281742095947, 'learning_rate': 3.5697674418604653e-06, 'loss_1': 0.009409224614501, 'loss_2': 0.0022125244140625, 'loss_3': -16.423629760742188, 'loss_4': 0.5106834769248962, 'epoch': 26.45}
[INFO|trainer.py:4228] 2025-01-21 14:12:29,782 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:29,782 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                         | 4555/5160 [1:52:34<10:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:37,140 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006981413811445236, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.078, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004259538371115923, 'eval_loss_2': 0.0027218759059906006, 'eval_loss_3': -18.19025993347168, 'eval_loss_4': 0.3671334981918335, 'epoch': 26.45}
{'loss': 0.0035, 'grad_norm': 4.914849281311035, 'learning_rate': 3.563953488372093e-06, 'loss_1': 0.0015920340083539486, 'loss_2': 0.0018682479858398438, 'loss_3': -16.378841400146484, 'loss_4': 0.2755565941333771, 'epoch': 26.46}
{'loss': 0.0074, 'grad_norm': 4.923922538757324, 'learning_rate': 3.5581395348837212e-06, 'loss_1': 0.0032304050400853157, 'loss_2': 0.004199981689453125, 'loss_3': -16.38818359375, 'loss_4': 0.10170155018568039, 'epoch': 26.47}
{'loss': 0.0044, 'grad_norm': 4.604107856750488, 'learning_rate': 3.552325581395349e-06, 'loss_1': 0.003982699941843748, 'loss_2': 0.00038170814514160156, 'loss_3': -16.492095947265625, 'loss_4': 0.5520445108413696, 'epoch': 26.47}
{'loss': 0.0038, 'grad_norm': 4.816648006439209, 'learning_rate': 3.546511627906977e-06, 'loss_1': 0.003661410417407751, 'loss_2': 9.1552734375e-05, 'loss_3': -16.672935485839844, 'loss_4': 0.09705966711044312, 'epoch': 26.48}
{'loss': 0.0116, 'grad_norm': 4.790844917297363, 'learning_rate': 3.5406976744186046e-06, 'loss_1': 0.003046774072572589, 'loss_2': 0.008575439453125, 'loss_3': -16.563072204589844, 'loss_4': 0.38372230529785156, 'epoch': 26.48}
[INFO|trainer.py:4228] 2025-01-21 14:12:37,140 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:37,140 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 4560/5160 [1:52:41<10:22,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:44,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006927588954567909, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004399555269628763, 'eval_loss_2': 0.0025280341506004333, 'eval_loss_3': -18.191503524780273, 'eval_loss_4': 0.3672860860824585, 'epoch': 26.48}
{'loss': 0.007, 'grad_norm': 4.511767864227295, 'learning_rate': 3.5348837209302324e-06, 'loss_1': 0.0034930501133203506, 'loss_2': 0.00350189208984375, 'loss_3': -16.598913192749023, 'loss_4': 0.2298639416694641, 'epoch': 26.49}
{'loss': 0.0185, 'grad_norm': 6.233428001403809, 'learning_rate': 3.5290697674418606e-06, 'loss_1': 0.014730882830917835, 'loss_2': 0.003726959228515625, 'loss_3': -16.360618591308594, 'loss_4': 0.5989583730697632, 'epoch': 26.49}
{'loss': 0.0105, 'grad_norm': 7.6215009689331055, 'learning_rate': 3.5232558139534884e-06, 'loss_1': 0.009052067063748837, 'loss_2': 0.00148773193359375, 'loss_3': -16.485706329345703, 'loss_4': 0.22739842534065247, 'epoch': 26.5}
{'loss': 0.0058, 'grad_norm': 5.6745781898498535, 'learning_rate': 3.517441860465116e-06, 'loss_1': 0.0032946141436696053, 'loss_2': 0.00254058837890625, 'loss_3': -16.430831909179688, 'loss_4': 0.19941776990890503, 'epoch': 26.51}
{'loss': 0.0101, 'grad_norm': 5.715286731719971, 'learning_rate': 3.5116279069767444e-06, 'loss_1': 0.0072913928888738155, 'loss_2': 0.002788543701171875, 'loss_3': -16.524051666259766, 'loss_4': 0.16320839524269104, 'epoch': 26.51}
[INFO|trainer.py:4228] 2025-01-21 14:12:44,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:44,484 >>   Batch size = 64
 88%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                         | 4565/5160 [1:52:48<10:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:51,853 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007063477765768766, 'eval_runtime': 3.8144, 'eval_samples_per_second': 268.454, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.004527419339865446, 'eval_loss_2': 0.0025360584259033203, 'eval_loss_3': -18.184694290161133, 'eval_loss_4': 0.3772949278354645, 'epoch': 26.51}
{'loss': 0.0078, 'grad_norm': 5.666411399841309, 'learning_rate': 3.505813953488372e-06, 'loss_1': 0.006532167084515095, 'loss_2': 0.00122833251953125, 'loss_3': -16.514354705810547, 'loss_4': 0.39872488379478455, 'epoch': 26.52}
{'loss': 0.0233, 'grad_norm': 10.24349308013916, 'learning_rate': 3.5e-06, 'loss_1': 0.018492545932531357, 'loss_2': 0.00482177734375, 'loss_3': -16.456722259521484, 'loss_4': 0.22490954399108887, 'epoch': 26.52}
{'loss': 0.0029, 'grad_norm': 4.533308506011963, 'learning_rate': 3.4941860465116277e-06, 'loss_1': 0.0020668581128120422, 'loss_2': 0.0008096694946289062, 'loss_3': -16.38092041015625, 'loss_4': 0.4231255352497101, 'epoch': 26.53}
{'loss': 0.0065, 'grad_norm': 4.765499591827393, 'learning_rate': 3.488372093023256e-06, 'loss_1': 0.004384856671094894, 'loss_2': 0.0020771026611328125, 'loss_3': -16.58883285522461, 'loss_4': 0.12288855016231537, 'epoch': 26.53}
{'loss': 0.0105, 'grad_norm': 4.946218490600586, 'learning_rate': 3.4825581395348837e-06, 'loss_1': 0.0055857086554169655, 'loss_2': 0.0048980712890625, 'loss_3': -16.58984375, 'loss_4': 0.45222270488739014, 'epoch': 26.54}
[INFO|trainer.py:4228] 2025-01-21 14:12:51,853 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:51,853 >>   Batch size = 64
 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                         | 4570/5160 [1:52:56<10:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:12:59,216 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006862823385745287, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.646, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004149262327700853, 'eval_loss_2': 0.0027135610580444336, 'eval_loss_3': -18.18857192993164, 'eval_loss_4': 0.4054071605205536, 'epoch': 26.54}
{'loss': 0.0047, 'grad_norm': 4.682301998138428, 'learning_rate': 3.4767441860465115e-06, 'loss_1': 0.0018630118574947119, 'loss_2': 0.0027980804443359375, 'loss_3': -16.36288070678711, 'loss_4': 0.35272109508514404, 'epoch': 26.55}
{'loss': 0.009, 'grad_norm': 7.9347243309021, 'learning_rate': 3.4709302325581397e-06, 'loss_1': 0.008823500014841557, 'loss_2': 0.00019919872283935547, 'loss_3': -16.41002655029297, 'loss_4': 0.578830361366272, 'epoch': 26.55}
{'loss': 0.0091, 'grad_norm': 5.160919189453125, 'learning_rate': 3.4651162790697675e-06, 'loss_1': 0.0045595476403832436, 'loss_2': 0.00458526611328125, 'loss_3': -16.450876235961914, 'loss_4': 0.48882168531417847, 'epoch': 26.56}
{'loss': 0.005, 'grad_norm': 4.752291679382324, 'learning_rate': 3.4593023255813953e-06, 'loss_1': 0.0037894095294177532, 'loss_2': 0.0012035369873046875, 'loss_3': -16.63262939453125, 'loss_4': 0.44020143151283264, 'epoch': 26.56}
{'loss': 0.0117, 'grad_norm': 4.8714165687561035, 'learning_rate': 3.4534883720930235e-06, 'loss_1': 0.004832206293940544, 'loss_2': 0.00685882568359375, 'loss_3': -16.435283660888672, 'loss_4': 0.7031394839286804, 'epoch': 26.57}
[INFO|trainer.py:4228] 2025-01-21 14:12:59,216 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:12:59,217 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                        | 4575/5160 [1:53:03<10:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:06,569 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007185251452028751, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004309420473873615, 'eval_loss_2': 0.002875830978155136, 'eval_loss_3': -18.18453598022461, 'eval_loss_4': 0.41547518968582153, 'epoch': 26.57}
{'loss': 0.0075, 'grad_norm': 5.474225997924805, 'learning_rate': 3.447674418604651e-06, 'loss_1': 0.005500423721969128, 'loss_2': 0.0020236968994140625, 'loss_3': -16.29088020324707, 'loss_4': 0.09041166305541992, 'epoch': 26.58}
{'loss': 0.0192, 'grad_norm': 10.10459041595459, 'learning_rate': 3.441860465116279e-06, 'loss_1': 0.016247835010290146, 'loss_2': 0.0029087066650390625, 'loss_3': -16.463973999023438, 'loss_4': 0.2869078814983368, 'epoch': 26.58}
{'loss': 0.003, 'grad_norm': 4.725696086883545, 'learning_rate': 3.4360465116279073e-06, 'loss_1': 0.002431433880701661, 'loss_2': 0.0005512237548828125, 'loss_3': -16.313648223876953, 'loss_4': -0.15758749842643738, 'epoch': 26.59}
{'loss': 0.0128, 'grad_norm': 10.206050872802734, 'learning_rate': 3.4302325581395346e-06, 'loss_1': 0.00983054656535387, 'loss_2': 0.002994537353515625, 'loss_3': -16.564189910888672, 'loss_4': 0.2945530116558075, 'epoch': 26.59}
{'loss': 0.0096, 'grad_norm': 5.7155442237854, 'learning_rate': 3.424418604651163e-06, 'loss_1': 0.005491090472787619, 'loss_2': 0.00408172607421875, 'loss_3': -16.33657455444336, 'loss_4': 0.22234183549880981, 'epoch': 26.6}
[INFO|trainer.py:4228] 2025-01-21 14:13:06,569 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:06,570 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 4580/5160 [1:53:11<10:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:13,920 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00699489563703537, 'eval_runtime': 3.8038, 'eval_samples_per_second': 269.204, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004317350685596466, 'eval_loss_2': 0.002677544951438904, 'eval_loss_3': -18.193214416503906, 'eval_loss_4': 0.4097525477409363, 'epoch': 26.6}
{'loss': 0.0077, 'grad_norm': 4.6782684326171875, 'learning_rate': 3.418604651162791e-06, 'loss_1': 0.0027857827953994274, 'loss_2': 0.00492095947265625, 'loss_3': -16.466060638427734, 'loss_4': 0.5684224963188171, 'epoch': 26.6}
{'loss': 0.0116, 'grad_norm': 5.120138645172119, 'learning_rate': 3.4127906976744184e-06, 'loss_1': 0.003651686478406191, 'loss_2': 0.00794219970703125, 'loss_3': -16.444791793823242, 'loss_4': 0.7057169675827026, 'epoch': 26.61}
{'loss': 0.0044, 'grad_norm': 4.9110517501831055, 'learning_rate': 3.4069767441860466e-06, 'loss_1': 0.003434371203184128, 'loss_2': 0.0010128021240234375, 'loss_3': -16.457313537597656, 'loss_4': 0.1439700722694397, 'epoch': 26.62}
{'loss': 0.0192, 'grad_norm': 7.201376438140869, 'learning_rate': 3.4011627906976744e-06, 'loss_1': 0.009610387496650219, 'loss_2': 0.0096282958984375, 'loss_3': -16.265033721923828, 'loss_4': 0.39417529106140137, 'epoch': 26.62}
{'loss': 0.0073, 'grad_norm': 5.121203899383545, 'learning_rate': 3.395348837209302e-06, 'loss_1': 0.002302176784723997, 'loss_2': 0.005023956298828125, 'loss_3': -16.223526000976562, 'loss_4': 0.24857135117053986, 'epoch': 26.63}
[INFO|trainer.py:4228] 2025-01-21 14:13:13,921 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:13,921 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 4585/5160 [1:53:18<09:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:21,274 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0068318103440105915, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.955, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004382686223834753, 'eval_loss_2': 0.002449125051498413, 'eval_loss_3': -18.1965389251709, 'eval_loss_4': 0.4045451283454895, 'epoch': 26.63}
{'loss': 0.0034, 'grad_norm': 4.666175842285156, 'learning_rate': 3.3895348837209304e-06, 'loss_1': 0.0021318267099559307, 'loss_2': 0.001224517822265625, 'loss_3': -16.504436492919922, 'loss_4': 0.21429796516895294, 'epoch': 26.63}
{'loss': 0.0055, 'grad_norm': 4.536386013031006, 'learning_rate': 3.383720930232558e-06, 'loss_1': 0.0036914770025759935, 'loss_2': 0.00177001953125, 'loss_3': -16.56365966796875, 'loss_4': 0.410800039768219, 'epoch': 26.64}
{'loss': 0.0075, 'grad_norm': 5.094716548919678, 'learning_rate': 3.377906976744186e-06, 'loss_1': 0.0033146184869110584, 'loss_2': 0.004184722900390625, 'loss_3': -16.180919647216797, 'loss_4': 0.18713583052158356, 'epoch': 26.65}
{'loss': 0.0057, 'grad_norm': 5.219569683074951, 'learning_rate': 3.372093023255814e-06, 'loss_1': 0.0031869288068264723, 'loss_2': 0.002468109130859375, 'loss_3': -16.386323928833008, 'loss_4': 0.13506218791007996, 'epoch': 26.65}
{'loss': 0.0085, 'grad_norm': 6.215660095214844, 'learning_rate': 3.366279069767442e-06, 'loss_1': 0.008428574539721012, 'loss_2': 0.0001201629638671875, 'loss_3': -16.544395446777344, 'loss_4': 0.2835586667060852, 'epoch': 26.66}
[INFO|trainer.py:4228] 2025-01-21 14:13:21,274 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:21,274 >>   Batch size = 64
 89%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 4590/5160 [1:53:25<09:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:28,633 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007032280787825584, 'eval_runtime': 3.8087, 'eval_samples_per_second': 268.859, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004398082848638296, 'eval_loss_2': 0.002634197473526001, 'eval_loss_3': -18.19769287109375, 'eval_loss_4': 0.3827529549598694, 'epoch': 26.66}
{'loss': 0.0132, 'grad_norm': 5.353341579437256, 'learning_rate': 3.3604651162790698e-06, 'loss_1': 0.004547643009573221, 'loss_2': 0.00862884521484375, 'loss_3': -16.54288101196289, 'loss_4': 0.4249270260334015, 'epoch': 26.66}
{'loss': 0.0058, 'grad_norm': 5.835724353790283, 'learning_rate': 3.3546511627906975e-06, 'loss_1': 0.005209663882851601, 'loss_2': 0.0006189346313476562, 'loss_3': -16.406139373779297, 'loss_4': 0.32120487093925476, 'epoch': 26.67}
{'loss': 0.0049, 'grad_norm': 4.950372695922852, 'learning_rate': 3.3488372093023258e-06, 'loss_1': 0.0048736990429461, 'loss_2': 5.739927291870117e-05, 'loss_3': -16.545475006103516, 'loss_4': 0.6578048467636108, 'epoch': 26.67}
{'loss': 0.014, 'grad_norm': 6.024737358093262, 'learning_rate': 3.3430232558139535e-06, 'loss_1': 0.0075826989486813545, 'loss_2': 0.006443023681640625, 'loss_3': -16.408472061157227, 'loss_4': 0.4555744528770447, 'epoch': 26.68}
{'loss': 0.007, 'grad_norm': 5.218639850616455, 'learning_rate': 3.3372093023255813e-06, 'loss_1': 0.005325178150087595, 'loss_2': 0.0016870498657226562, 'loss_3': -16.42885971069336, 'loss_4': 0.3202798366546631, 'epoch': 26.69}
[INFO|trainer.py:4228] 2025-01-21 14:13:28,633 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:28,633 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 4595/5160 [1:53:33<09:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:35,993 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007301774341613054, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.872, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004425314255058765, 'eval_loss_2': 0.002876460552215576, 'eval_loss_3': -18.19703483581543, 'eval_loss_4': 0.38213834166526794, 'epoch': 26.69}
{'loss': 0.0035, 'grad_norm': 5.258720874786377, 'learning_rate': 3.3313953488372095e-06, 'loss_1': 0.003486452391371131, 'loss_2': 3.4689903259277344e-05, 'loss_3': -16.537748336791992, 'loss_4': 0.665108859539032, 'epoch': 26.69}
{'loss': 0.007, 'grad_norm': 4.761215686798096, 'learning_rate': 3.3255813953488373e-06, 'loss_1': 0.006504732649773359, 'loss_2': 0.0005207061767578125, 'loss_3': -16.562374114990234, 'loss_4': 0.3299385607242584, 'epoch': 26.7}
{'loss': 0.0142, 'grad_norm': 7.276524543762207, 'learning_rate': 3.319767441860465e-06, 'loss_1': 0.01222638413310051, 'loss_2': 0.0019445419311523438, 'loss_3': -16.43734359741211, 'loss_4': 0.3110424876213074, 'epoch': 26.7}
{'loss': 0.0164, 'grad_norm': 7.523667812347412, 'learning_rate': 3.3139534883720933e-06, 'loss_1': 0.011153630912303925, 'loss_2': 0.005237579345703125, 'loss_3': -16.753463745117188, 'loss_4': 0.3602892756462097, 'epoch': 26.71}
{'loss': 0.0078, 'grad_norm': 5.993293762207031, 'learning_rate': 3.3081395348837207e-06, 'loss_1': 0.005261632148176432, 'loss_2': 0.0024890899658203125, 'loss_3': -16.141063690185547, 'loss_4': 0.4573187530040741, 'epoch': 26.72}
[INFO|trainer.py:4228] 2025-01-21 14:13:35,993 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:35,993 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 4600/5160 [1:53:40<09:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:43,341 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.006961132399737835, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.088, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.004337992053478956, 'eval_loss_2': 0.002623140811920166, 'eval_loss_3': -18.20501708984375, 'eval_loss_4': 0.361453115940094, 'epoch': 26.72}
{'loss': 0.0029, 'grad_norm': 4.807118892669678, 'learning_rate': 3.302325581395349e-06, 'loss_1': 0.0017500894609838724, 'loss_2': 0.0011529922485351562, 'loss_3': -16.439725875854492, 'loss_4': 0.5389376878738403, 'epoch': 26.72}
{'loss': 0.0038, 'grad_norm': 4.805909633636475, 'learning_rate': 3.296511627906977e-06, 'loss_1': 0.0033862339332699776, 'loss_2': 0.00041937828063964844, 'loss_3': -16.658069610595703, 'loss_4': 0.07483938336372375, 'epoch': 26.73}
{'loss': 0.0097, 'grad_norm': 5.488360404968262, 'learning_rate': 3.2906976744186045e-06, 'loss_1': 0.006898064166307449, 'loss_2': 0.002788543701171875, 'loss_3': -16.384462356567383, 'loss_4': 0.39388567209243774, 'epoch': 26.73}
{'loss': 0.0074, 'grad_norm': 5.135702133178711, 'learning_rate': 3.2848837209302327e-06, 'loss_1': 0.003973284736275673, 'loss_2': 0.0034332275390625, 'loss_3': -16.4942569732666, 'loss_4': 0.347856730222702, 'epoch': 26.74}
{'loss': 0.0074, 'grad_norm': 5.906001567840576, 'learning_rate': 3.279069767441861e-06, 'loss_1': 0.007303454447537661, 'loss_2': 9.620189666748047e-05, 'loss_3': -16.418516159057617, 'loss_4': -0.13267651200294495, 'epoch': 26.74}
[INFO|trainer.py:4228] 2025-01-21 14:13:43,341 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:43,341 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 4605/5160 [1:53:47<09:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:50,688 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0065790805965662, 'eval_runtime': 3.804, 'eval_samples_per_second': 269.192, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004502149298787117, 'eval_loss_2': 0.0020769312977790833, 'eval_loss_3': -18.217357635498047, 'eval_loss_4': 0.3125016689300537, 'epoch': 26.74}
{'loss': 0.0088, 'grad_norm': 5.274740695953369, 'learning_rate': 3.2732558139534882e-06, 'loss_1': 0.005332693457603455, 'loss_2': 0.003467559814453125, 'loss_3': -16.25137710571289, 'loss_4': 0.34808868169784546, 'epoch': 26.75}
{'loss': 0.003, 'grad_norm': 4.772515773773193, 'learning_rate': 3.2674418604651164e-06, 'loss_1': 0.0021843304857611656, 'loss_2': 0.0008211135864257812, 'loss_3': -16.47996711730957, 'loss_4': 0.29377326369285583, 'epoch': 26.76}
{'loss': 0.0066, 'grad_norm': 5.2212138175964355, 'learning_rate': 3.2616279069767442e-06, 'loss_1': 0.0037979225162416697, 'loss_2': 0.002765655517578125, 'loss_3': -16.549346923828125, 'loss_4': 0.13527391850948334, 'epoch': 26.76}
{'loss': 0.005, 'grad_norm': 5.958389759063721, 'learning_rate': 3.255813953488372e-06, 'loss_1': 0.004815804306417704, 'loss_2': 0.00019681453704833984, 'loss_3': -16.421344757080078, 'loss_4': 0.2592087686061859, 'epoch': 26.77}
{'loss': 0.009, 'grad_norm': 5.02665376663208, 'learning_rate': 3.2500000000000002e-06, 'loss_1': 0.004025363828986883, 'loss_2': 0.00501251220703125, 'loss_3': -16.605337142944336, 'loss_4': 0.03392178192734718, 'epoch': 26.77}
[INFO|trainer.py:4228] 2025-01-21 14:13:50,688 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:50,688 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                       | 4610/5160 [1:53:55<09:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:13:58,043 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007077918853610754, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.024, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00445126136764884, 'eval_loss_2': 0.002626657485961914, 'eval_loss_3': -18.210840225219727, 'eval_loss_4': 0.27156537771224976, 'epoch': 26.77}
{'loss': 0.009, 'grad_norm': 5.175642967224121, 'learning_rate': 3.244186046511628e-06, 'loss_1': 0.0030217927414923906, 'loss_2': 0.006011962890625, 'loss_3': -16.25326156616211, 'loss_4': -0.031009554862976074, 'epoch': 26.78}
{'loss': 0.0078, 'grad_norm': 4.807774066925049, 'learning_rate': 3.238372093023256e-06, 'loss_1': 0.003595361951738596, 'loss_2': 0.004238128662109375, 'loss_3': -16.38726806640625, 'loss_4': 0.08444873243570328, 'epoch': 26.78}
{'loss': 0.0147, 'grad_norm': 6.367467880249023, 'learning_rate': 3.232558139534884e-06, 'loss_1': 0.007885579951107502, 'loss_2': 0.0068511962890625, 'loss_3': -16.438535690307617, 'loss_4': -0.20969074964523315, 'epoch': 26.79}
{'loss': 0.0042, 'grad_norm': 4.603674411773682, 'learning_rate': 3.226744186046512e-06, 'loss_1': 0.003374560968950391, 'loss_2': 0.0008301734924316406, 'loss_3': -16.321800231933594, 'loss_4': 0.3069852888584137, 'epoch': 26.8}
{'loss': 0.0191, 'grad_norm': 5.9911088943481445, 'learning_rate': 3.2209302325581396e-06, 'loss_1': 0.009884347207844257, 'loss_2': 0.00922393798828125, 'loss_3': -16.13580894470215, 'loss_4': -0.034867897629737854, 'epoch': 26.8}
[INFO|trainer.py:4228] 2025-01-21 14:13:58,043 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:13:58,043 >>   Batch size = 64
 89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 4615/5160 [1:54:02<09:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:05,395 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007203512825071812, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.054, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.00438005942851305, 'eval_loss_2': 0.0028234533965587616, 'eval_loss_3': -18.200641632080078, 'eval_loss_4': 0.27645039558410645, 'epoch': 26.8}
{'loss': 0.0153, 'grad_norm': 5.942705154418945, 'learning_rate': 3.2151162790697674e-06, 'loss_1': 0.0064453622326254845, 'loss_2': 0.008819580078125, 'loss_3': -16.274578094482422, 'loss_4': 0.2606789171695709, 'epoch': 26.81}
{'loss': 0.0037, 'grad_norm': 4.296233177185059, 'learning_rate': 3.2093023255813956e-06, 'loss_1': 0.00247797928750515, 'loss_2': 0.0012645721435546875, 'loss_3': -16.36751365661621, 'loss_4': 0.2510707378387451, 'epoch': 26.81}
{'loss': 0.0037, 'grad_norm': 4.547855854034424, 'learning_rate': 3.2034883720930234e-06, 'loss_1': 0.002400672296062112, 'loss_2': 0.001285552978515625, 'loss_3': -16.36540985107422, 'loss_4': -0.011061355471611023, 'epoch': 26.82}
{'loss': 0.0083, 'grad_norm': 4.981851577758789, 'learning_rate': 3.197674418604651e-06, 'loss_1': 0.006917532067745924, 'loss_2': 0.00135040283203125, 'loss_3': -16.457469940185547, 'loss_4': 0.27552419900894165, 'epoch': 26.83}
{'loss': 0.0058, 'grad_norm': 4.4008049964904785, 'learning_rate': 3.1918604651162793e-06, 'loss_1': 0.0032706812489777803, 'loss_2': 0.0025768280029296875, 'loss_3': -16.401256561279297, 'loss_4': 0.07449451088905334, 'epoch': 26.83}
[INFO|trainer.py:4228] 2025-01-21 14:14:05,395 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:05,395 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 4620/5160 [1:54:09<09:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:12,748 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007167305331677198, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.93, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004497612826526165, 'eval_loss_2': 0.002669692039489746, 'eval_loss_3': -18.205228805541992, 'eval_loss_4': 0.2651439905166626, 'epoch': 26.83}
{'loss': 0.0114, 'grad_norm': 5.282127380371094, 'learning_rate': 3.186046511627907e-06, 'loss_1': 0.003930280450731516, 'loss_2': 0.007495880126953125, 'loss_3': -16.408287048339844, 'loss_4': 0.5160865783691406, 'epoch': 26.84}
{'loss': 0.0076, 'grad_norm': 5.4372639656066895, 'learning_rate': 3.180232558139535e-06, 'loss_1': 0.004454583860933781, 'loss_2': 0.0031909942626953125, 'loss_3': -16.423118591308594, 'loss_4': 0.41767627000808716, 'epoch': 26.84}
{'loss': 0.0085, 'grad_norm': 4.707274913787842, 'learning_rate': 3.174418604651163e-06, 'loss_1': 0.0045841452665627, 'loss_2': 0.003887176513671875, 'loss_3': -16.458173751831055, 'loss_4': 0.10444141924381256, 'epoch': 26.85}
{'loss': 0.0157, 'grad_norm': 6.938702583312988, 'learning_rate': 3.1686046511627905e-06, 'loss_1': 0.010581470094621181, 'loss_2': 0.00507354736328125, 'loss_3': -16.478927612304688, 'loss_4': 0.2951253652572632, 'epoch': 26.85}
{'loss': 0.014, 'grad_norm': 6.169941425323486, 'learning_rate': 3.1627906976744187e-06, 'loss_1': 0.007773524150252342, 'loss_2': 0.006229400634765625, 'loss_3': -16.41878318786621, 'loss_4': 0.3337039649486542, 'epoch': 26.86}
[INFO|trainer.py:4228] 2025-01-21 14:14:12,748 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:12,748 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                      | 4625/5160 [1:54:17<09:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:20,110 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00720401294529438, 'eval_runtime': 3.8125, 'eval_samples_per_second': 268.591, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.004371194634586573, 'eval_loss_2': 0.002832818776369095, 'eval_loss_3': -18.20449447631836, 'eval_loss_4': 0.26279735565185547, 'epoch': 26.86}
{'loss': 0.0053, 'grad_norm': 4.897575855255127, 'learning_rate': 3.156976744186047e-06, 'loss_1': 0.004177698865532875, 'loss_2': 0.0011663436889648438, 'loss_3': -16.40925407409668, 'loss_4': 0.0834292471408844, 'epoch': 26.87}
{'loss': 0.0083, 'grad_norm': 5.0647125244140625, 'learning_rate': 3.1511627906976743e-06, 'loss_1': 0.004471149295568466, 'loss_2': 0.0038776397705078125, 'loss_3': -16.328903198242188, 'loss_4': 0.7805731296539307, 'epoch': 26.87}
{'loss': 0.0088, 'grad_norm': 4.877169609069824, 'learning_rate': 3.1453488372093025e-06, 'loss_1': 0.004948778077960014, 'loss_2': 0.003803253173828125, 'loss_3': -16.429523468017578, 'loss_4': -0.3408334255218506, 'epoch': 26.88}
{'loss': 0.0059, 'grad_norm': 4.417847156524658, 'learning_rate': 3.1395348837209307e-06, 'loss_1': 0.0023559711407870054, 'loss_2': 0.0035552978515625, 'loss_3': -16.441898345947266, 'loss_4': 0.29984182119369507, 'epoch': 26.88}
{'loss': 0.0103, 'grad_norm': 5.079915523529053, 'learning_rate': 3.133720930232558e-06, 'loss_1': 0.005417164880782366, 'loss_2': 0.0048370361328125, 'loss_3': -16.411977767944336, 'loss_4': 0.03746815770864487, 'epoch': 26.89}
[INFO|trainer.py:4228] 2025-01-21 14:14:20,110 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:20,110 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 4630/5160 [1:54:24<09:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:27,452 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007987071759998798, 'eval_runtime': 3.8044, 'eval_samples_per_second': 269.162, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.00488706398755312, 'eval_loss_2': 0.0031000077724456787, 'eval_loss_3': -18.20089340209961, 'eval_loss_4': 0.2654801905155182, 'epoch': 26.89}
{'loss': 0.0084, 'grad_norm': 5.54733419418335, 'learning_rate': 3.1279069767441863e-06, 'loss_1': 0.006385446526110172, 'loss_2': 0.0020599365234375, 'loss_3': -16.308326721191406, 'loss_4': 0.17412783205509186, 'epoch': 26.9}
{'loss': 0.0067, 'grad_norm': 5.219882011413574, 'learning_rate': 3.122093023255814e-06, 'loss_1': 0.004225058481097221, 'loss_2': 0.00246429443359375, 'loss_3': -16.4412784576416, 'loss_4': 0.37263625860214233, 'epoch': 26.9}
{'loss': 0.0085, 'grad_norm': 4.822336673736572, 'learning_rate': 3.116279069767442e-06, 'loss_1': 0.003071199869737029, 'loss_2': 0.0054779052734375, 'loss_3': -16.226558685302734, 'loss_4': -0.04882417619228363, 'epoch': 26.91}
{'loss': 0.0081, 'grad_norm': 5.388967037200928, 'learning_rate': 3.11046511627907e-06, 'loss_1': 0.007973231375217438, 'loss_2': 0.000125885009765625, 'loss_3': -16.36166763305664, 'loss_4': 0.29243436455726624, 'epoch': 26.91}
{'loss': 0.0045, 'grad_norm': 4.7453508377075195, 'learning_rate': 3.1046511627906974e-06, 'loss_1': 0.002876944374293089, 'loss_2': 0.001617431640625, 'loss_3': -16.467567443847656, 'loss_4': 0.3899461627006531, 'epoch': 26.92}
[INFO|trainer.py:4228] 2025-01-21 14:14:27,453 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:27,453 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 4635/5160 [1:54:31<09:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:34,807 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009178481996059418, 'eval_runtime': 3.8059, 'eval_samples_per_second': 269.058, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.0052756210789084435, 'eval_loss_2': 0.0039028599858283997, 'eval_loss_3': -18.19156837463379, 'eval_loss_4': 0.2725100517272949, 'epoch': 26.92}
{'loss': 0.0086, 'grad_norm': 4.524994373321533, 'learning_rate': 3.0988372093023256e-06, 'loss_1': 0.0028333719819784164, 'loss_2': 0.0058135986328125, 'loss_3': -16.485172271728516, 'loss_4': 0.32665354013442993, 'epoch': 26.92}
{'loss': 0.0116, 'grad_norm': 4.673690319061279, 'learning_rate': 3.093023255813954e-06, 'loss_1': 0.004559976980090141, 'loss_2': 0.007038116455078125, 'loss_3': -16.43467140197754, 'loss_4': 0.25650131702423096, 'epoch': 26.93}
{'loss': 0.0104, 'grad_norm': 4.923686504364014, 'learning_rate': 3.087209302325581e-06, 'loss_1': 0.004636801313608885, 'loss_2': 0.005741119384765625, 'loss_3': -16.50125503540039, 'loss_4': 0.24231378734111786, 'epoch': 26.94}
{'loss': 0.0085, 'grad_norm': 5.246702194213867, 'learning_rate': 3.0813953488372094e-06, 'loss_1': 0.002425541402772069, 'loss_2': 0.00608062744140625, 'loss_3': -16.40807342529297, 'loss_4': 0.13919270038604736, 'epoch': 26.94}
{'loss': 0.0166, 'grad_norm': 9.176743507385254, 'learning_rate': 3.075581395348837e-06, 'loss_1': 0.013679652474820614, 'loss_2': 0.002872467041015625, 'loss_3': -16.484783172607422, 'loss_4': 0.5192493796348572, 'epoch': 26.95}
[INFO|trainer.py:4228] 2025-01-21 14:14:34,807 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:34,807 >>   Batch size = 64
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                      | 4640/5160 [1:54:39<08:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:14:42,153 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00946792121976614, 'eval_runtime': 3.8011, 'eval_samples_per_second': 269.394, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.00541891111060977, 'eval_loss_2': 0.0040490105748176575, 'eval_loss_3': -18.18544578552246, 'eval_loss_4': 0.29536646604537964, 'epoch': 26.95}
{'loss': 0.0105, 'grad_norm': 6.6399312019348145, 'learning_rate': 3.069767441860465e-06, 'loss_1': 0.008648979477584362, 'loss_2': 0.001834869384765625, 'loss_3': -16.436067581176758, 'loss_4': -0.16897818446159363, 'epoch': 26.95}
{'loss': 0.0108, 'grad_norm': 5.196094989776611, 'learning_rate': 3.063953488372093e-06, 'loss_1': 0.005364483688026667, 'loss_2': 0.005451202392578125, 'loss_3': -16.370933532714844, 'loss_4': 0.7662889957427979, 'epoch': 26.96}
{'loss': 0.0047, 'grad_norm': 4.733549118041992, 'learning_rate': 3.058139534883721e-06, 'loss_1': 0.002496583154425025, 'loss_2': 0.002246856689453125, 'loss_3': -16.328468322753906, 'loss_4': 0.13450835645198822, 'epoch': 26.97}
{'loss': 0.0108, 'grad_norm': 5.675374984741211, 'learning_rate': 3.0523255813953487e-06, 'loss_1': 0.008254794403910637, 'loss_2': 0.00257110595703125, 'loss_3': -16.537195205688477, 'loss_4': -0.1511697769165039, 'epoch': 26.97}
{'loss': 0.01, 'grad_norm': 5.409318923950195, 'learning_rate': 3.046511627906977e-06, 'loss_1': 0.007186478935182095, 'loss_2': 0.0028018951416015625, 'loss_3': -16.12862777709961, 'loss_4': 0.16311393678188324, 'epoch': 26.98}
[INFO|trainer.py:4228] 2025-01-21 14:14:42,153 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:42,153 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 4645/5160 [1:54:46<08:23,  1.02it/s][INFO|trainer.py:4226] 2025-01-21 14:14:49,189 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00896083191037178, 'eval_runtime': 3.806, 'eval_samples_per_second': 269.052, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005221937317401171, 'eval_loss_2': 0.003738895058631897, 'eval_loss_3': -18.180280685424805, 'eval_loss_4': 0.3106474280357361, 'epoch': 26.98}
{'loss': 0.0082, 'grad_norm': 7.198407173156738, 'learning_rate': 3.0406976744186047e-06, 'loss_1': 0.007415937725454569, 'loss_2': 0.000812530517578125, 'loss_3': -16.555522918701172, 'loss_4': 0.7393429279327393, 'epoch': 26.98}
{'loss': 0.0095, 'grad_norm': 4.130990028381348, 'learning_rate': 3.0348837209302325e-06, 'loss_1': 0.0025780252180993557, 'loss_2': 0.006931304931640625, 'loss_3': -16.373897552490234, 'loss_4': 0.5554184913635254, 'epoch': 26.99}
{'loss': 0.0036, 'grad_norm': 4.619622707366943, 'learning_rate': 3.0290697674418603e-06, 'loss_1': 0.002395634539425373, 'loss_2': 0.0011844635009765625, 'loss_3': -16.39872169494629, 'loss_4': 0.3220330774784088, 'epoch': 26.99}
{'loss': 0.0103, 'grad_norm': 6.225788116455078, 'learning_rate': 3.0232558139534885e-06, 'loss_1': 0.0019225822761654854, 'loss_2': 0.0083465576171875, 'loss_3': -16.32996940612793, 'loss_4': 0.21339169144630432, 'epoch': 27.0}
{'loss': 0.0034, 'grad_norm': 4.746147632598877, 'learning_rate': 3.0174418604651163e-06, 'loss_1': 0.002572309924289584, 'loss_2': 0.0008664131164550781, 'loss_3': -16.40094566345215, 'loss_4': 0.22445058822631836, 'epoch': 27.01}
[INFO|trainer.py:4228] 2025-01-21 14:14:49,189 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:49,189 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                     | 4650/5160 [1:54:53<08:44,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:14:56,548 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007950527593493462, 'eval_runtime': 3.8093, 'eval_samples_per_second': 268.816, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005124635528773069, 'eval_loss_2': 0.002825893461704254, 'eval_loss_3': -18.182281494140625, 'eval_loss_4': 0.3266551196575165, 'epoch': 27.01}
{'loss': 0.0026, 'grad_norm': 5.329586505889893, 'learning_rate': 3.011627906976744e-06, 'loss_1': 0.0019747656770050526, 'loss_2': 0.0005826950073242188, 'loss_3': -16.145156860351562, 'loss_4': 0.7116833329200745, 'epoch': 27.01}
{'loss': 0.0057, 'grad_norm': 5.354465961456299, 'learning_rate': 3.0058139534883723e-06, 'loss_1': 0.003967196214944124, 'loss_2': 0.001750946044921875, 'loss_3': -16.452800750732422, 'loss_4': 0.13469886779785156, 'epoch': 27.02}
{'loss': 0.0117, 'grad_norm': 4.885518550872803, 'learning_rate': 3e-06, 'loss_1': 0.00576938409358263, 'loss_2': 0.00589752197265625, 'loss_3': -16.398536682128906, 'loss_4': 0.3601090610027313, 'epoch': 27.02}
{'loss': 0.0177, 'grad_norm': 5.719588279724121, 'learning_rate': 2.994186046511628e-06, 'loss_1': 0.003864436410367489, 'loss_2': 0.0138397216796875, 'loss_3': -16.493267059326172, 'loss_4': 0.19550985097885132, 'epoch': 27.03}
{'loss': 0.013, 'grad_norm': 5.803066253662109, 'learning_rate': 2.988372093023256e-06, 'loss_1': 0.00542643154039979, 'loss_2': 0.00757598876953125, 'loss_3': -16.25968360900879, 'loss_4': 0.006226986646652222, 'epoch': 27.03}
[INFO|trainer.py:4228] 2025-01-21 14:14:56,548 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:14:56,548 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 4655/5160 [1:55:01<08:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:03,896 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0076038772240281105, 'eval_runtime': 3.8031, 'eval_samples_per_second': 269.251, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004807860124856234, 'eval_loss_2': 0.0027960166335105896, 'eval_loss_3': -18.174076080322266, 'eval_loss_4': 0.3664345145225525, 'epoch': 27.03}
{'loss': 0.0033, 'grad_norm': 4.759617805480957, 'learning_rate': 2.9825581395348834e-06, 'loss_1': 0.0027741931844502687, 'loss_2': 0.0004773139953613281, 'loss_3': -16.357364654541016, 'loss_4': 0.5953173637390137, 'epoch': 27.04}
{'loss': 0.0037, 'grad_norm': 4.905038356781006, 'learning_rate': 2.9767441860465116e-06, 'loss_1': 0.002257951069623232, 'loss_2': 0.001491546630859375, 'loss_3': -16.558717727661133, 'loss_4': 0.4947994649410248, 'epoch': 27.05}
{'loss': 0.0065, 'grad_norm': 4.427884578704834, 'learning_rate': 2.97093023255814e-06, 'loss_1': 0.0031838510185480118, 'loss_2': 0.00328826904296875, 'loss_3': -16.42760467529297, 'loss_4': 0.3609501123428345, 'epoch': 27.05}
{'loss': 0.0136, 'grad_norm': 5.450338363647461, 'learning_rate': 2.965116279069767e-06, 'loss_1': 0.009365740232169628, 'loss_2': 0.004207611083984375, 'loss_3': -16.364572525024414, 'loss_4': -0.14233367145061493, 'epoch': 27.06}
{'loss': 0.006, 'grad_norm': 5.332128047943115, 'learning_rate': 2.9593023255813954e-06, 'loss_1': 0.004805309232324362, 'loss_2': 0.0011491775512695312, 'loss_3': -16.395423889160156, 'loss_4': 0.38391971588134766, 'epoch': 27.06}
[INFO|trainer.py:4228] 2025-01-21 14:15:03,896 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:03,896 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 4660/5160 [1:55:08<08:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:11,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007409178651869297, 'eval_runtime': 3.8034, 'eval_samples_per_second': 269.233, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.004652941133826971, 'eval_loss_2': 0.0027562379837036133, 'eval_loss_3': -18.17489242553711, 'eval_loss_4': 0.3768755793571472, 'epoch': 27.06}
{'loss': 0.0043, 'grad_norm': 4.868695259094238, 'learning_rate': 2.9534883720930236e-06, 'loss_1': 0.0038534337654709816, 'loss_2': 0.0004153251647949219, 'loss_3': -16.391220092773438, 'loss_4': 0.44157159328460693, 'epoch': 27.07}
{'loss': 0.0087, 'grad_norm': 4.989147186279297, 'learning_rate': 2.947674418604651e-06, 'loss_1': 0.003475318429991603, 'loss_2': 0.00518035888671875, 'loss_3': -16.19471549987793, 'loss_4': 0.3280808925628662, 'epoch': 27.08}
{'loss': 0.0043, 'grad_norm': 5.015624046325684, 'learning_rate': 2.941860465116279e-06, 'loss_1': 0.002625449327751994, 'loss_2': 0.0017070770263671875, 'loss_3': -16.48056411743164, 'loss_4': 0.4200042486190796, 'epoch': 27.08}
{'loss': 0.0124, 'grad_norm': 5.303009510040283, 'learning_rate': 2.936046511627907e-06, 'loss_1': 0.004511790815740824, 'loss_2': 0.007904052734375, 'loss_3': -16.4016170501709, 'loss_4': 0.26953738927841187, 'epoch': 27.09}
{'loss': 0.0078, 'grad_norm': 5.180281639099121, 'learning_rate': 2.9302325581395348e-06, 'loss_1': 0.005500688683241606, 'loss_2': 0.002285003662109375, 'loss_3': -16.57291603088379, 'loss_4': 0.2711852192878723, 'epoch': 27.09}
[INFO|trainer.py:4228] 2025-01-21 14:15:11,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:11,241 >>   Batch size = 64
 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                     | 4665/5160 [1:55:15<08:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:18,585 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0074684033170342445, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.111, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004709930624812841, 'eval_loss_2': 0.0027584731578826904, 'eval_loss_3': -18.175512313842773, 'eval_loss_4': 0.3575263023376465, 'epoch': 27.09}
{'loss': 0.0034, 'grad_norm': 4.453466415405273, 'learning_rate': 2.924418604651163e-06, 'loss_1': 0.0025478920433670282, 'loss_2': 0.0008077621459960938, 'loss_3': -16.6589412689209, 'loss_4': 0.387236624956131, 'epoch': 27.1}
{'loss': 0.0131, 'grad_norm': 6.506680965423584, 'learning_rate': 2.9186046511627908e-06, 'loss_1': 0.0069243223406374454, 'loss_2': 0.006130218505859375, 'loss_3': -16.38755226135254, 'loss_4': 0.40077173709869385, 'epoch': 27.1}
{'loss': 0.0073, 'grad_norm': 4.917530059814453, 'learning_rate': 2.9127906976744186e-06, 'loss_1': 0.005075111053884029, 'loss_2': 0.0022144317626953125, 'loss_3': -16.24953842163086, 'loss_4': 0.7377461194992065, 'epoch': 27.11}
{'loss': 0.0074, 'grad_norm': 4.985611915588379, 'learning_rate': 2.9069767441860468e-06, 'loss_1': 0.00309112761169672, 'loss_2': 0.00435638427734375, 'loss_3': -16.204816818237305, 'loss_4': 0.271839439868927, 'epoch': 27.12}
{'loss': 0.0072, 'grad_norm': 4.9960527420043945, 'learning_rate': 2.9011627906976745e-06, 'loss_1': 0.0031650324817746878, 'loss_2': 0.003993988037109375, 'loss_3': -16.635990142822266, 'loss_4': 0.3331570625305176, 'epoch': 27.12}
[INFO|trainer.py:4228] 2025-01-21 14:15:18,585 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:18,585 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 4670/5160 [1:55:23<08:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:25,933 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00739406980574131, 'eval_runtime': 3.8035, 'eval_samples_per_second': 269.229, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.0045621939934790134, 'eval_loss_2': 0.002831876277923584, 'eval_loss_3': -18.172653198242188, 'eval_loss_4': 0.3249706029891968, 'epoch': 27.12}
{'loss': 0.0078, 'grad_norm': 4.728251934051514, 'learning_rate': 2.8953488372093023e-06, 'loss_1': 0.006749517749994993, 'loss_2': 0.0010280609130859375, 'loss_3': -16.542007446289062, 'loss_4': 0.15683799982070923, 'epoch': 27.13}
{'loss': 0.006, 'grad_norm': 5.018532752990723, 'learning_rate': 2.88953488372093e-06, 'loss_1': 0.005015922710299492, 'loss_2': 0.0010004043579101562, 'loss_3': -16.579547882080078, 'loss_4': 0.5119007229804993, 'epoch': 27.13}
{'loss': 0.0044, 'grad_norm': 5.500682353973389, 'learning_rate': 2.8837209302325583e-06, 'loss_1': 0.004141818266361952, 'loss_2': 0.0002894401550292969, 'loss_3': -16.54510498046875, 'loss_4': 0.38179758191108704, 'epoch': 27.14}
{'loss': 0.0074, 'grad_norm': 5.656736373901367, 'learning_rate': 2.877906976744186e-06, 'loss_1': 0.007233781274408102, 'loss_2': 0.00021219253540039062, 'loss_3': -16.659835815429688, 'loss_4': 0.0014067813754081726, 'epoch': 27.15}
{'loss': 0.0314, 'grad_norm': 32.22718048095703, 'learning_rate': 2.872093023255814e-06, 'loss_1': 0.030354736372828484, 'loss_2': 0.0009984970092773438, 'loss_3': -16.25122833251953, 'loss_4': 0.40457621216773987, 'epoch': 27.15}
[INFO|trainer.py:4228] 2025-01-21 14:15:25,933 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:25,933 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                    | 4675/5160 [1:55:30<08:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:33,288 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007703462615609169, 'eval_runtime': 3.8051, 'eval_samples_per_second': 269.11, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004869916941970587, 'eval_loss_2': 0.002833545207977295, 'eval_loss_3': -18.180797576904297, 'eval_loss_4': 0.2889236509799957, 'epoch': 27.15}
{'loss': 0.009, 'grad_norm': 6.0965423583984375, 'learning_rate': 2.866279069767442e-06, 'loss_1': 0.006866011768579483, 'loss_2': 0.0021114349365234375, 'loss_3': -16.343969345092773, 'loss_4': 0.3276444971561432, 'epoch': 27.16}
{'loss': 0.013, 'grad_norm': 5.3239617347717285, 'learning_rate': 2.86046511627907e-06, 'loss_1': 0.006273021921515465, 'loss_2': 0.006771087646484375, 'loss_3': -16.43030548095703, 'loss_4': 0.05035005509853363, 'epoch': 27.16}
{'loss': 0.0063, 'grad_norm': 5.554956912994385, 'learning_rate': 2.8546511627906977e-06, 'loss_1': 0.004518106114119291, 'loss_2': 0.0018291473388671875, 'loss_3': -16.165477752685547, 'loss_4': 0.5317641496658325, 'epoch': 27.17}
{'loss': 0.0101, 'grad_norm': 4.813223838806152, 'learning_rate': 2.848837209302326e-06, 'loss_1': 0.0032409338746219873, 'loss_2': 0.0068206787109375, 'loss_3': -16.324684143066406, 'loss_4': 0.41717690229415894, 'epoch': 27.17}
{'loss': 0.0118, 'grad_norm': 4.221622467041016, 'learning_rate': 2.8430232558139532e-06, 'loss_1': 0.0035302178002893925, 'loss_2': 0.00823974609375, 'loss_3': -16.46902084350586, 'loss_4': 0.32057321071624756, 'epoch': 27.18}
[INFO|trainer.py:4228] 2025-01-21 14:15:33,288 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:33,288 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                    | 4680/5160 [1:55:37<08:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:40,637 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007894407957792282, 'eval_runtime': 3.8079, 'eval_samples_per_second': 268.917, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004989992827177048, 'eval_loss_2': 0.0029044151306152344, 'eval_loss_3': -18.184375762939453, 'eval_loss_4': 0.2556670606136322, 'epoch': 27.18}
{'loss': 0.0028, 'grad_norm': 5.033239841461182, 'learning_rate': 2.8372093023255815e-06, 'loss_1': 0.00244644982740283, 'loss_2': 0.0003342628479003906, 'loss_3': -16.385723114013672, 'loss_4': 0.5000752210617065, 'epoch': 27.19}
{'loss': 0.0114, 'grad_norm': 5.3029937744140625, 'learning_rate': 2.8313953488372097e-06, 'loss_1': 0.0031681545078754425, 'loss_2': 0.008209228515625, 'loss_3': -16.381166458129883, 'loss_4': 0.3430263102054596, 'epoch': 27.19}
{'loss': 0.0068, 'grad_norm': 5.294654369354248, 'learning_rate': 2.825581395348837e-06, 'loss_1': 0.004647181835025549, 'loss_2': 0.0021228790283203125, 'loss_3': -16.404903411865234, 'loss_4': 0.17970943450927734, 'epoch': 27.2}
{'loss': 0.0059, 'grad_norm': 4.517527103424072, 'learning_rate': 2.8197674418604652e-06, 'loss_1': 0.002748302649706602, 'loss_2': 0.003108978271484375, 'loss_3': -16.42782211303711, 'loss_4': 0.29293620586395264, 'epoch': 27.2}
{'loss': 0.0029, 'grad_norm': 4.584103584289551, 'learning_rate': 2.8139534883720934e-06, 'loss_1': 0.0016095872269943357, 'loss_2': 0.0012760162353515625, 'loss_3': -16.445613861083984, 'loss_4': 0.5223298668861389, 'epoch': 27.21}
[INFO|trainer.py:4228] 2025-01-21 14:15:40,637 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:40,637 >>   Batch size = 64
 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                    | 4685/5160 [1:55:45<08:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:47,986 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008090019226074219, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.129, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005176633596420288, 'eval_loss_2': 0.0029133856296539307, 'eval_loss_3': -18.180858612060547, 'eval_loss_4': 0.23609709739685059, 'epoch': 27.21}
{'loss': 0.0047, 'grad_norm': 4.528759956359863, 'learning_rate': 2.808139534883721e-06, 'loss_1': 0.004124592058360577, 'loss_2': 0.0005645751953125, 'loss_3': -16.205615997314453, 'loss_4': 0.24954254925251007, 'epoch': 27.22}
{'loss': 0.0079, 'grad_norm': 5.07781457901001, 'learning_rate': 2.802325581395349e-06, 'loss_1': 0.0055633652955293655, 'loss_2': 0.002300262451171875, 'loss_3': -16.33323097229004, 'loss_4': 0.05258085951209068, 'epoch': 27.22}
{'loss': 0.0157, 'grad_norm': 6.812918186187744, 'learning_rate': 2.796511627906977e-06, 'loss_1': 0.011126714758574963, 'loss_2': 0.00455474853515625, 'loss_3': -16.25341033935547, 'loss_4': 0.4366122782230377, 'epoch': 27.23}
{'loss': 0.0063, 'grad_norm': 4.388754367828369, 'learning_rate': 2.7906976744186046e-06, 'loss_1': 0.0028625924605876207, 'loss_2': 0.00345611572265625, 'loss_3': -16.357770919799805, 'loss_4': -0.21122410893440247, 'epoch': 27.23}
{'loss': 0.0074, 'grad_norm': 4.337267875671387, 'learning_rate': 2.784883720930233e-06, 'loss_1': 0.002007718663662672, 'loss_2': 0.0053863525390625, 'loss_3': -16.571231842041016, 'loss_4': 0.4223247170448303, 'epoch': 27.24}
[INFO|trainer.py:4228] 2025-01-21 14:15:47,986 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:47,986 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                    | 4690/5160 [1:55:52<08:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:15:55,335 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008425332605838776, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.266, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005483544897288084, 'eval_loss_2': 0.0029417872428894043, 'eval_loss_3': -18.178791046142578, 'eval_loss_4': 0.20223203301429749, 'epoch': 27.24}
{'loss': 0.0035, 'grad_norm': 4.5039849281311035, 'learning_rate': 2.7790697674418606e-06, 'loss_1': 0.0029377173632383347, 'loss_2': 0.0005283355712890625, 'loss_3': -16.484098434448242, 'loss_4': 0.3050430417060852, 'epoch': 27.24}
{'loss': 0.0104, 'grad_norm': 5.504077434539795, 'learning_rate': 2.7732558139534884e-06, 'loss_1': 0.005661427974700928, 'loss_2': 0.004779815673828125, 'loss_3': -16.501262664794922, 'loss_4': 0.2884986996650696, 'epoch': 27.25}
{'loss': 0.0135, 'grad_norm': 8.398072242736816, 'learning_rate': 2.7674418604651166e-06, 'loss_1': 0.01172388531267643, 'loss_2': 0.001773834228515625, 'loss_3': -16.435081481933594, 'loss_4': 0.47760212421417236, 'epoch': 27.26}
{'loss': 0.009, 'grad_norm': 4.738647937774658, 'learning_rate': 2.7616279069767444e-06, 'loss_1': 0.004139627795666456, 'loss_2': 0.004856109619140625, 'loss_3': -16.296829223632812, 'loss_4': 0.4556909203529358, 'epoch': 27.26}
{'loss': 0.0066, 'grad_norm': 4.588832378387451, 'learning_rate': 2.755813953488372e-06, 'loss_1': 0.001381295034661889, 'loss_2': 0.00518035888671875, 'loss_3': -16.368881225585938, 'loss_4': -0.02529294788837433, 'epoch': 27.27}
[INFO|trainer.py:4228] 2025-01-21 14:15:55,335 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:15:55,335 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                   | 4695/5160 [1:55:59<08:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:02,674 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007995296269655228, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.378, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005203831475228071, 'eval_loss_2': 0.002791464328765869, 'eval_loss_3': -18.187971115112305, 'eval_loss_4': 0.1688532829284668, 'epoch': 27.27}
{'loss': 0.0065, 'grad_norm': 4.445589065551758, 'learning_rate': 2.75e-06, 'loss_1': 0.00334947369992733, 'loss_2': 0.0031719207763671875, 'loss_3': -16.234941482543945, 'loss_4': 0.015881367027759552, 'epoch': 27.27}
{'loss': 0.0064, 'grad_norm': 4.598077297210693, 'learning_rate': 2.744186046511628e-06, 'loss_1': 0.0038905558176338673, 'loss_2': 0.002471923828125, 'loss_3': -16.413259506225586, 'loss_4': 0.27051836252212524, 'epoch': 27.28}
{'loss': 0.0084, 'grad_norm': 5.229708194732666, 'learning_rate': 2.738372093023256e-06, 'loss_1': 0.005134667735546827, 'loss_2': 0.003231048583984375, 'loss_3': -16.364669799804688, 'loss_4': 0.2819911539554596, 'epoch': 27.28}
{'loss': 0.0055, 'grad_norm': 4.496533393859863, 'learning_rate': 2.7325581395348837e-06, 'loss_1': 0.0031045584473758936, 'loss_2': 0.00237274169921875, 'loss_3': -16.449726104736328, 'loss_4': 0.3946720361709595, 'epoch': 27.29}
{'loss': 0.0101, 'grad_norm': 6.575277328491211, 'learning_rate': 2.726744186046512e-06, 'loss_1': 0.009181415662169456, 'loss_2': 0.0008945465087890625, 'loss_3': -16.27432632446289, 'loss_4': 0.5177240967750549, 'epoch': 27.3}
[INFO|trainer.py:4228] 2025-01-21 14:16:02,674 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:02,674 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                   | 4700/5160 [1:56:07<07:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:10,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008252494968473911, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.187, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.005308920051902533, 'eval_loss_2': 0.002943575382232666, 'eval_loss_3': -18.187240600585938, 'eval_loss_4': 0.13679906725883484, 'epoch': 27.3}
{'loss': 0.0026, 'grad_norm': 4.4109978675842285, 'learning_rate': 2.7209302325581397e-06, 'loss_1': 0.0012574666179716587, 'loss_2': 0.0013828277587890625, 'loss_3': -16.637948989868164, 'loss_4': -0.0735992044210434, 'epoch': 27.3}
{'loss': 0.0121, 'grad_norm': 4.966161251068115, 'learning_rate': 2.7151162790697675e-06, 'loss_1': 0.00640625087544322, 'loss_2': 0.005645751953125, 'loss_3': -16.2547664642334, 'loss_4': 0.07843862473964691, 'epoch': 27.31}
{'loss': 0.0084, 'grad_norm': 4.748873710632324, 'learning_rate': 2.7093023255813953e-06, 'loss_1': 0.004315438214689493, 'loss_2': 0.00411224365234375, 'loss_3': -16.372783660888672, 'loss_4': 0.19419020414352417, 'epoch': 27.31}
{'loss': 0.0208, 'grad_norm': 11.642295837402344, 'learning_rate': 2.703488372093023e-06, 'loss_1': 0.01992087811231613, 'loss_2': 0.0008497238159179688, 'loss_3': -16.555419921875, 'loss_4': 0.2476646900177002, 'epoch': 27.32}
{'loss': 0.0071, 'grad_norm': 4.9917144775390625, 'learning_rate': 2.6976744186046513e-06, 'loss_1': 0.002819674788042903, 'loss_2': 0.004238128662109375, 'loss_3': -16.483261108398438, 'loss_4': 0.6478644013404846, 'epoch': 27.33}
[INFO|trainer.py:4228] 2025-01-21 14:16:10,024 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:10,024 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                   | 4705/5160 [1:56:14<07:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:17,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008487025275826454, 'eval_runtime': 3.8076, 'eval_samples_per_second': 268.935, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.0051938979886472225, 'eval_loss_2': 0.0032931268215179443, 'eval_loss_3': -18.183300018310547, 'eval_loss_4': 0.1391182541847229, 'epoch': 27.33}
{'loss': 0.0066, 'grad_norm': 4.505518436431885, 'learning_rate': 2.691860465116279e-06, 'loss_1': 0.0033233168069273233, 'loss_2': 0.003231048583984375, 'loss_3': -16.636123657226562, 'loss_4': 0.2573111057281494, 'epoch': 27.33}
{'loss': 0.002, 'grad_norm': 5.0809855461120605, 'learning_rate': 2.686046511627907e-06, 'loss_1': 0.0019490167032927275, 'loss_2': 7.593631744384766e-05, 'loss_3': -16.484710693359375, 'loss_4': 0.08018611371517181, 'epoch': 27.34}
{'loss': 0.0239, 'grad_norm': 9.625636100769043, 'learning_rate': 2.680232558139535e-06, 'loss_1': 0.021123388782143593, 'loss_2': 0.0027923583984375, 'loss_3': -16.309186935424805, 'loss_4': 0.20151321589946747, 'epoch': 27.34}
{'loss': 0.0383, 'grad_norm': 16.987974166870117, 'learning_rate': 2.674418604651163e-06, 'loss_1': 0.03354458883404732, 'loss_2': 0.00473785400390625, 'loss_3': -16.356428146362305, 'loss_4': 0.1534307450056076, 'epoch': 27.35}
{'loss': 0.0045, 'grad_norm': 4.396873950958252, 'learning_rate': 2.6686046511627906e-06, 'loss_1': 0.002469979925081134, 'loss_2': 0.002063751220703125, 'loss_3': -16.512033462524414, 'loss_4': 0.16575412452220917, 'epoch': 27.35}
[INFO|trainer.py:4228] 2025-01-21 14:16:17,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:17,382 >>   Batch size = 64
 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                   | 4710/5160 [1:56:21<07:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:24,732 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00860322080552578, 'eval_runtime': 3.8047, 'eval_samples_per_second': 269.142, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005345887038856745, 'eval_loss_2': 0.0032573342323303223, 'eval_loss_3': -18.178972244262695, 'eval_loss_4': 0.15166527032852173, 'epoch': 27.35}
{'loss': 0.0064, 'grad_norm': 5.925688743591309, 'learning_rate': 2.662790697674419e-06, 'loss_1': 0.0049146064557135105, 'loss_2': 0.0014667510986328125, 'loss_3': -16.370765686035156, 'loss_4': 0.07809002697467804, 'epoch': 27.36}
{'loss': 0.011, 'grad_norm': 4.470812797546387, 'learning_rate': 2.656976744186046e-06, 'loss_1': 0.004522314295172691, 'loss_2': 0.006473541259765625, 'loss_3': -16.600933074951172, 'loss_4': -0.01719047501683235, 'epoch': 27.37}
{'loss': 0.0097, 'grad_norm': 5.656655311584473, 'learning_rate': 2.6511627906976744e-06, 'loss_1': 0.0041715470142662525, 'loss_2': 0.00553131103515625, 'loss_3': -16.462236404418945, 'loss_4': 0.20027153193950653, 'epoch': 27.37}
{'loss': 0.0038, 'grad_norm': 4.5625481605529785, 'learning_rate': 2.6453488372093026e-06, 'loss_1': 0.0034942161291837692, 'loss_2': 0.0003190040588378906, 'loss_3': -16.298648834228516, 'loss_4': -0.05667400360107422, 'epoch': 27.38}
{'loss': 0.0111, 'grad_norm': 6.366129398345947, 'learning_rate': 2.63953488372093e-06, 'loss_1': 0.008035799488425255, 'loss_2': 0.0030364990234375, 'loss_3': -16.41864585876465, 'loss_4': 0.4223063588142395, 'epoch': 27.38}
[INFO|trainer.py:4228] 2025-01-21 14:16:24,732 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:24,732 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                   | 4715/5160 [1:56:29<07:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:32,081 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008999034762382507, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.986, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005439684726297855, 'eval_loss_2': 0.0035593509674072266, 'eval_loss_3': -18.174922943115234, 'eval_loss_4': 0.16589708626270294, 'epoch': 27.38}
{'loss': 0.0103, 'grad_norm': 7.283749580383301, 'learning_rate': 2.633720930232558e-06, 'loss_1': 0.008431077003479004, 'loss_2': 0.0018672943115234375, 'loss_3': -16.358745574951172, 'loss_4': -0.29997095465660095, 'epoch': 27.39}
{'loss': 0.0064, 'grad_norm': 5.07872200012207, 'learning_rate': 2.6279069767441864e-06, 'loss_1': 0.006328686140477657, 'loss_2': 9.721517562866211e-05, 'loss_3': -16.343799591064453, 'loss_4': 0.43443405628204346, 'epoch': 27.4}
{'loss': 0.0683, 'grad_norm': 19.89720344543457, 'learning_rate': 2.6220930232558137e-06, 'loss_1': 0.0600498802959919, 'loss_2': 0.0082855224609375, 'loss_3': -16.521236419677734, 'loss_4': 0.9408007860183716, 'epoch': 27.4}
{'loss': 0.0116, 'grad_norm': 6.953912734985352, 'learning_rate': 2.616279069767442e-06, 'loss_1': 0.010450108908116817, 'loss_2': 0.0011396408081054688, 'loss_3': -16.393356323242188, 'loss_4': 0.2485242486000061, 'epoch': 27.41}
{'loss': 0.0104, 'grad_norm': 4.510362148284912, 'learning_rate': 2.6104651162790697e-06, 'loss_1': 0.003912902902811766, 'loss_2': 0.006458282470703125, 'loss_3': -16.267805099487305, 'loss_4': 0.18679949641227722, 'epoch': 27.41}
[INFO|trainer.py:4228] 2025-01-21 14:16:32,082 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:32,082 >>   Batch size = 64
 91%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 4720/5160 [1:56:36<07:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:39,425 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00900937058031559, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.962, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005341599695384502, 'eval_loss_2': 0.003667771816253662, 'eval_loss_3': -18.172990798950195, 'eval_loss_4': 0.18408802151679993, 'epoch': 27.41}
{'loss': 0.0123, 'grad_norm': 5.554837703704834, 'learning_rate': 2.6046511627906975e-06, 'loss_1': 0.006148804444819689, 'loss_2': 0.00611114501953125, 'loss_3': -16.475631713867188, 'loss_4': 0.31039226055145264, 'epoch': 27.42}
{'loss': 0.0079, 'grad_norm': 6.51522159576416, 'learning_rate': 2.5988372093023257e-06, 'loss_1': 0.0069808438420295715, 'loss_2': 0.0009088516235351562, 'loss_3': -16.374755859375, 'loss_4': 0.05320340394973755, 'epoch': 27.42}
{'loss': 0.0069, 'grad_norm': 5.653724193572998, 'learning_rate': 2.5930232558139535e-06, 'loss_1': 0.004841158166527748, 'loss_2': 0.002025604248046875, 'loss_3': -16.383371353149414, 'loss_4': 0.3259633481502533, 'epoch': 27.43}
{'loss': 0.0107, 'grad_norm': 6.00974702835083, 'learning_rate': 2.5872093023255813e-06, 'loss_1': 0.0104793980717659, 'loss_2': 0.00017714500427246094, 'loss_3': -16.343334197998047, 'loss_4': 0.43552887439727783, 'epoch': 27.44}
{'loss': 0.0138, 'grad_norm': 6.334961891174316, 'learning_rate': 2.5813953488372095e-06, 'loss_1': 0.010366752743721008, 'loss_2': 0.00347137451171875, 'loss_3': -16.304443359375, 'loss_4': 0.35716110467910767, 'epoch': 27.44}
[INFO|trainer.py:4228] 2025-01-21 14:16:39,426 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:39,426 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                  | 4725/5160 [1:56:43<07:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:46,777 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008299466222524643, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.976, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.004951592069119215, 'eval_loss_2': 0.0033478736877441406, 'eval_loss_3': -18.17274284362793, 'eval_loss_4': 0.19644905626773834, 'epoch': 27.44}
{'loss': 0.009, 'grad_norm': 5.257290840148926, 'learning_rate': 2.5755813953488373e-06, 'loss_1': 0.0028173800092190504, 'loss_2': 0.0061492919921875, 'loss_3': -16.35888671875, 'loss_4': -0.14650973677635193, 'epoch': 27.45}
{'loss': 0.0087, 'grad_norm': 6.721001625061035, 'learning_rate': 2.569767441860465e-06, 'loss_1': 0.00817901361733675, 'loss_2': 0.000522613525390625, 'loss_3': -16.322284698486328, 'loss_4': 0.5402234196662903, 'epoch': 27.45}
{'loss': 0.0117, 'grad_norm': 10.051165580749512, 'learning_rate': 2.563953488372093e-06, 'loss_1': 0.010428068228065968, 'loss_2': 0.0013141632080078125, 'loss_3': -16.44900131225586, 'loss_4': 0.13906177878379822, 'epoch': 27.46}
{'loss': 0.005, 'grad_norm': 5.003511428833008, 'learning_rate': 2.558139534883721e-06, 'loss_1': 0.0019259878899902105, 'loss_2': 0.003047943115234375, 'loss_3': -16.440702438354492, 'loss_4': 0.36982420086860657, 'epoch': 27.47}
{'loss': 0.0037, 'grad_norm': 4.990757942199707, 'learning_rate': 2.552325581395349e-06, 'loss_1': 0.003428444266319275, 'loss_2': 0.00023949146270751953, 'loss_3': -16.26278305053711, 'loss_4': -0.0373619943857193, 'epoch': 27.47}
[INFO|trainer.py:4228] 2025-01-21 14:16:46,777 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:46,777 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                  | 4730/5160 [1:56:51<07:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:16:54,125 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008107412606477737, 'eval_runtime': 3.8041, 'eval_samples_per_second': 269.185, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004833360202610493, 'eval_loss_2': 0.0032740533351898193, 'eval_loss_3': -18.17144203186035, 'eval_loss_4': 0.19256608188152313, 'epoch': 27.47}
{'loss': 0.0064, 'grad_norm': 4.185887813568115, 'learning_rate': 2.5465116279069767e-06, 'loss_1': 0.0025345226749777794, 'loss_2': 0.0038604736328125, 'loss_3': -16.46744155883789, 'loss_4': 0.052668482065200806, 'epoch': 27.48}
{'loss': 0.0094, 'grad_norm': 4.720641136169434, 'learning_rate': 2.540697674418605e-06, 'loss_1': 0.0024982993490993977, 'loss_2': 0.006862640380859375, 'loss_3': -16.217668533325195, 'loss_4': 0.12650886178016663, 'epoch': 27.48}
{'loss': 0.0071, 'grad_norm': 4.486734390258789, 'learning_rate': 2.5348837209302326e-06, 'loss_1': 0.005365896970033646, 'loss_2': 0.0017147064208984375, 'loss_3': -16.28898811340332, 'loss_4': 0.4023836851119995, 'epoch': 27.49}
{'loss': 0.0067, 'grad_norm': 5.015018939971924, 'learning_rate': 2.5290697674418604e-06, 'loss_1': 0.002680662553757429, 'loss_2': 0.00400543212890625, 'loss_3': -16.480552673339844, 'loss_4': 0.3651236891746521, 'epoch': 27.49}
{'loss': 0.0077, 'grad_norm': 4.6632914543151855, 'learning_rate': 2.5232558139534886e-06, 'loss_1': 0.0039949179627001286, 'loss_2': 0.003749847412109375, 'loss_3': -16.410747528076172, 'loss_4': 0.372699499130249, 'epoch': 27.5}
[INFO|trainer.py:4228] 2025-01-21 14:16:54,125 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:16:54,125 >>   Batch size = 64
 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 4735/5160 [1:56:58<07:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:01,481 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008141569793224335, 'eval_runtime': 3.8089, 'eval_samples_per_second': 268.841, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.004564375150948763, 'eval_loss_2': 0.003577195107936859, 'eval_loss_3': -18.163246154785156, 'eval_loss_4': 0.1925012469291687, 'epoch': 27.5}
{'loss': 0.0085, 'grad_norm': 4.677273273468018, 'learning_rate': 2.517441860465116e-06, 'loss_1': 0.006121146958321333, 'loss_2': 0.002338409423828125, 'loss_3': -16.269407272338867, 'loss_4': 0.32887569069862366, 'epoch': 27.51}
{'loss': 0.0043, 'grad_norm': 4.8158345222473145, 'learning_rate': 2.511627906976744e-06, 'loss_1': 0.0037204413674771786, 'loss_2': 0.000568389892578125, 'loss_3': -16.540136337280273, 'loss_4': 0.4070626199245453, 'epoch': 27.51}
{'loss': 0.0098, 'grad_norm': 5.407156467437744, 'learning_rate': 2.5058139534883724e-06, 'loss_1': 0.004369466099888086, 'loss_2': 0.0053863525390625, 'loss_3': -16.350534439086914, 'loss_4': 0.4501780569553375, 'epoch': 27.52}
{'loss': 0.0028, 'grad_norm': 4.593453407287598, 'learning_rate': 2.4999999999999998e-06, 'loss_1': 0.0025468645617365837, 'loss_2': 0.0003008842468261719, 'loss_3': -16.379634857177734, 'loss_4': 0.4200385510921478, 'epoch': 27.52}
{'loss': 0.0097, 'grad_norm': 5.965462684631348, 'learning_rate': 2.494186046511628e-06, 'loss_1': 0.004954940173774958, 'loss_2': 0.00476837158203125, 'loss_3': -16.46221923828125, 'loss_4': 0.3544987440109253, 'epoch': 27.53}
[INFO|trainer.py:4228] 2025-01-21 14:17:01,481 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:01,481 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 4740/5160 [1:57:05<07:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:08,842 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008518097922205925, 'eval_runtime': 3.8043, 'eval_samples_per_second': 269.17, 'eval_steps_per_second': 4.206, 'eval_loss_1': 0.004924070555716753, 'eval_loss_2': 0.00359402596950531, 'eval_loss_3': -18.154645919799805, 'eval_loss_4': 0.2053249180316925, 'epoch': 27.53}
{'loss': 0.0104, 'grad_norm': 4.909489631652832, 'learning_rate': 2.488372093023256e-06, 'loss_1': 0.004221190698444843, 'loss_2': 0.006191253662109375, 'loss_3': -16.24212646484375, 'loss_4': -0.22455674409866333, 'epoch': 27.53}
{'loss': 0.0044, 'grad_norm': 4.624845504760742, 'learning_rate': 2.4825581395348836e-06, 'loss_1': 0.002400625729933381, 'loss_2': 0.002010345458984375, 'loss_3': -16.4136905670166, 'loss_4': 0.08739343285560608, 'epoch': 27.54}
{'loss': 0.006, 'grad_norm': 5.067922592163086, 'learning_rate': 2.4767441860465118e-06, 'loss_1': 0.004208132158964872, 'loss_2': 0.001827239990234375, 'loss_3': -16.42576026916504, 'loss_4': 0.2083950638771057, 'epoch': 27.55}
{'loss': 0.0101, 'grad_norm': 5.498248100280762, 'learning_rate': 2.4709302325581396e-06, 'loss_1': 0.004827943630516529, 'loss_2': 0.0052642822265625, 'loss_3': -16.408206939697266, 'loss_4': -0.0524449497461319, 'epoch': 27.55}
{'loss': 0.0163, 'grad_norm': 7.822704315185547, 'learning_rate': 2.4651162790697673e-06, 'loss_1': 0.011314245872199535, 'loss_2': 0.004974365234375, 'loss_3': -16.306934356689453, 'loss_4': 0.25059977173805237, 'epoch': 27.56}
[INFO|trainer.py:4228] 2025-01-21 14:17:08,843 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:08,843 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 4745/5160 [1:57:13<07:13,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:16,238 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008156169205904007, 'eval_runtime': 3.8259, 'eval_samples_per_second': 267.647, 'eval_steps_per_second': 4.182, 'eval_loss_1': 0.004685085732489824, 'eval_loss_2': 0.00347108393907547, 'eval_loss_3': -18.1495418548584, 'eval_loss_4': 0.21401390433311462, 'epoch': 27.56}
{'loss': 0.0027, 'grad_norm': 4.899878978729248, 'learning_rate': 2.4593023255813955e-06, 'loss_1': 0.002554828068241477, 'loss_2': 0.0001577138900756836, 'loss_3': -16.33132553100586, 'loss_4': 0.22400794923305511, 'epoch': 27.56}
{'loss': 0.0085, 'grad_norm': 5.514613628387451, 'learning_rate': 2.4534883720930233e-06, 'loss_1': 0.003909651655703783, 'loss_2': 0.0045623779296875, 'loss_3': -16.29546546936035, 'loss_4': 0.46082478761672974, 'epoch': 27.57}
{'loss': 0.0112, 'grad_norm': 5.894576072692871, 'learning_rate': 2.447674418604651e-06, 'loss_1': 0.005599129479378462, 'loss_2': 0.00563812255859375, 'loss_3': -16.3731689453125, 'loss_4': 0.18469840288162231, 'epoch': 27.58}
{'loss': 0.0126, 'grad_norm': 6.264187335968018, 'learning_rate': 2.4418604651162793e-06, 'loss_1': 0.008614573627710342, 'loss_2': 0.00397491455078125, 'loss_3': -16.316471099853516, 'loss_4': 0.5756586194038391, 'epoch': 27.58}
{'loss': 0.0149, 'grad_norm': 5.583788871765137, 'learning_rate': 2.436046511627907e-06, 'loss_1': 0.008864026516675949, 'loss_2': 0.006072998046875, 'loss_3': -16.449542999267578, 'loss_4': 0.3919069766998291, 'epoch': 27.59}
[INFO|trainer.py:4228] 2025-01-21 14:17:16,238 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:16,238 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 4750/5160 [1:57:20<07:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:23,618 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007907617837190628, 'eval_runtime': 3.8173, 'eval_samples_per_second': 268.252, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.004430937580764294, 'eval_loss_2': 0.0034766793251037598, 'eval_loss_3': -18.152742385864258, 'eval_loss_4': 0.2293018102645874, 'epoch': 27.59}
{'loss': 0.0126, 'grad_norm': 7.439634799957275, 'learning_rate': 2.430232558139535e-06, 'loss_1': 0.011831571348011494, 'loss_2': 0.0008058547973632812, 'loss_3': -16.429080963134766, 'loss_4': 0.3424915075302124, 'epoch': 27.59}
{'loss': 0.0289, 'grad_norm': 23.258718490600586, 'learning_rate': 2.4244186046511627e-06, 'loss_1': 0.026369020342826843, 'loss_2': 0.002521514892578125, 'loss_3': -16.36800193786621, 'loss_4': 0.10847006738185883, 'epoch': 27.6}
{'loss': 0.0048, 'grad_norm': 4.719021797180176, 'learning_rate': 2.418604651162791e-06, 'loss_1': 0.004529733210802078, 'loss_2': 0.00031185150146484375, 'loss_3': -16.37557601928711, 'loss_4': 0.22843031585216522, 'epoch': 27.6}
{'loss': 0.0128, 'grad_norm': 9.013832092285156, 'learning_rate': 2.4127906976744187e-06, 'loss_1': 0.011905577033758163, 'loss_2': 0.0008683204650878906, 'loss_3': -16.341217041015625, 'loss_4': -0.1938719004392624, 'epoch': 27.61}
{'loss': 0.0042, 'grad_norm': 4.6246442794799805, 'learning_rate': 2.4069767441860465e-06, 'loss_1': 0.0023143815342336893, 'loss_2': 0.0018472671508789062, 'loss_3': -16.470218658447266, 'loss_4': 0.5323449969291687, 'epoch': 27.62}
[INFO|trainer.py:4228] 2025-01-21 14:17:23,619 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:23,619 >>   Batch size = 64
 92%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                 | 4755/5160 [1:57:28<07:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:30,985 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008075501769781113, 'eval_runtime': 3.8117, 'eval_samples_per_second': 268.648, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.004630025010555983, 'eval_loss_2': 0.0034454762935638428, 'eval_loss_3': -18.15800666809082, 'eval_loss_4': 0.25004392862319946, 'epoch': 27.62}
{'loss': 0.0081, 'grad_norm': 4.925143241882324, 'learning_rate': 2.4011627906976747e-06, 'loss_1': 0.0055545237846672535, 'loss_2': 0.00257110595703125, 'loss_3': -16.366912841796875, 'loss_4': -0.09851200878620148, 'epoch': 27.62}
{'loss': 0.0041, 'grad_norm': 4.448444366455078, 'learning_rate': 2.3953488372093025e-06, 'loss_1': 0.0019280374981462955, 'loss_2': 0.0021266937255859375, 'loss_3': -16.363910675048828, 'loss_4': 0.13919594883918762, 'epoch': 27.63}
{'loss': 0.0072, 'grad_norm': 5.779139518737793, 'learning_rate': 2.3895348837209302e-06, 'loss_1': 0.005091181490570307, 'loss_2': 0.0020904541015625, 'loss_3': -16.319194793701172, 'loss_4': 0.1987990438938141, 'epoch': 27.63}
{'loss': 0.0093, 'grad_norm': 4.778092861175537, 'learning_rate': 2.3837209302325585e-06, 'loss_1': 0.004510198254138231, 'loss_2': 0.004756927490234375, 'loss_3': -16.25566864013672, 'loss_4': 0.292307049036026, 'epoch': 27.64}
{'loss': 0.004, 'grad_norm': 4.81674861907959, 'learning_rate': 2.377906976744186e-06, 'loss_1': 0.003125951625406742, 'loss_2': 0.0008916854858398438, 'loss_3': -16.271516799926758, 'loss_4': 0.05942033976316452, 'epoch': 27.65}
[INFO|trainer.py:4228] 2025-01-21 14:17:30,985 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:30,985 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                 | 4760/5160 [1:57:35<06:56,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:38,369 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00797992292791605, 'eval_runtime': 3.8239, 'eval_samples_per_second': 267.792, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.004677229560911655, 'eval_loss_2': 0.0033026933670043945, 'eval_loss_3': -18.1603946685791, 'eval_loss_4': 0.24958160519599915, 'epoch': 27.65}
{'loss': 0.0058, 'grad_norm': 4.887703895568848, 'learning_rate': 2.372093023255814e-06, 'loss_1': 0.004410295747220516, 'loss_2': 0.001399993896484375, 'loss_3': -16.230670928955078, 'loss_4': 0.30764663219451904, 'epoch': 27.65}
{'loss': 0.0102, 'grad_norm': 5.754271030426025, 'learning_rate': 2.3662790697674422e-06, 'loss_1': 0.005338004790246487, 'loss_2': 0.004852294921875, 'loss_3': -16.403736114501953, 'loss_4': 0.4215075373649597, 'epoch': 27.66}
{'loss': 0.004, 'grad_norm': 5.069992542266846, 'learning_rate': 2.3604651162790696e-06, 'loss_1': 0.0034257282968610525, 'loss_2': 0.0005474090576171875, 'loss_3': -16.342208862304688, 'loss_4': 0.3379867672920227, 'epoch': 27.66}
{'loss': 0.0029, 'grad_norm': 4.531723976135254, 'learning_rate': 2.354651162790698e-06, 'loss_1': 0.001837453804910183, 'loss_2': 0.0010824203491210938, 'loss_3': -16.434810638427734, 'loss_4': 0.13916951417922974, 'epoch': 27.67}
{'loss': 0.0083, 'grad_norm': 4.528656959533691, 'learning_rate': 2.348837209302326e-06, 'loss_1': 0.0015860670246183872, 'loss_2': 0.0067291259765625, 'loss_3': -16.53931427001953, 'loss_4': 0.33288127183914185, 'epoch': 27.67}
[INFO|trainer.py:4228] 2025-01-21 14:17:38,369 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:38,369 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 4765/5160 [1:57:42<06:50,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:45,727 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00787116028368473, 'eval_runtime': 3.808, 'eval_samples_per_second': 268.904, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004744740203022957, 'eval_loss_2': 0.0031264200806617737, 'eval_loss_3': -18.159442901611328, 'eval_loss_4': 0.25303971767425537, 'epoch': 27.67}
{'loss': 0.0044, 'grad_norm': 4.16170597076416, 'learning_rate': 2.3430232558139534e-06, 'loss_1': 0.002525530057027936, 'loss_2': 0.0018749237060546875, 'loss_3': -16.448429107666016, 'loss_4': 0.37750643491744995, 'epoch': 27.68}
{'loss': 0.0102, 'grad_norm': 5.3771796226501465, 'learning_rate': 2.3372093023255816e-06, 'loss_1': 0.004443539772182703, 'loss_2': 0.005733489990234375, 'loss_3': -16.37919044494629, 'loss_4': 0.810798168182373, 'epoch': 27.69}
{'loss': 0.0092, 'grad_norm': 5.332948684692383, 'learning_rate': 2.3313953488372094e-06, 'loss_1': 0.0036914185620844364, 'loss_2': 0.005462646484375, 'loss_3': -16.202152252197266, 'loss_4': -0.137840136885643, 'epoch': 27.69}
{'loss': 0.0083, 'grad_norm': 4.860875606536865, 'learning_rate': 2.325581395348837e-06, 'loss_1': 0.005732220131903887, 'loss_2': 0.002590179443359375, 'loss_3': -16.377201080322266, 'loss_4': 0.23862600326538086, 'epoch': 27.7}
{'loss': 0.0075, 'grad_norm': 5.3077569007873535, 'learning_rate': 2.3197674418604654e-06, 'loss_1': 0.005287088919430971, 'loss_2': 0.002197265625, 'loss_3': -16.462322235107422, 'loss_4': 0.5238085985183716, 'epoch': 27.7}
[INFO|trainer.py:4228] 2025-01-21 14:17:45,728 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:45,728 >>   Batch size = 64
 92%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 4770/5160 [1:57:50<06:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:17:53,090 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007809706963598728, 'eval_runtime': 3.8077, 'eval_samples_per_second': 268.929, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.004823194816708565, 'eval_loss_2': 0.002986513078212738, 'eval_loss_3': -18.1600284576416, 'eval_loss_4': 0.2570984959602356, 'epoch': 27.7}
{'loss': 0.0098, 'grad_norm': 4.852346897125244, 'learning_rate': 2.313953488372093e-06, 'loss_1': 0.0028318774420768023, 'loss_2': 0.00691986083984375, 'loss_3': -16.26508331298828, 'loss_4': -0.09961477667093277, 'epoch': 27.71}
{'loss': 0.0052, 'grad_norm': 4.937793731689453, 'learning_rate': 2.308139534883721e-06, 'loss_1': 0.002546668751165271, 'loss_2': 0.002681732177734375, 'loss_3': -16.45840835571289, 'loss_4': 0.07048192620277405, 'epoch': 27.72}
{'loss': 0.0194, 'grad_norm': 13.390521049499512, 'learning_rate': 2.302325581395349e-06, 'loss_1': 0.01604832522571087, 'loss_2': 0.00337982177734375, 'loss_3': -16.386842727661133, 'loss_4': -0.013246744871139526, 'epoch': 27.72}
{'loss': 0.0042, 'grad_norm': 4.328964710235596, 'learning_rate': 2.296511627906977e-06, 'loss_1': 0.002601306652650237, 'loss_2': 0.0016384124755859375, 'loss_3': -16.388635635375977, 'loss_4': 0.5738605856895447, 'epoch': 27.73}
{'loss': 0.0093, 'grad_norm': 4.376214027404785, 'learning_rate': 2.2906976744186047e-06, 'loss_1': 0.004223532043397427, 'loss_2': 0.00504302978515625, 'loss_3': -16.352840423583984, 'loss_4': 0.0994948148727417, 'epoch': 27.73}
[INFO|trainer.py:4228] 2025-01-21 14:17:53,090 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:17:53,090 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 4775/5160 [1:57:57<06:40,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:00,447 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008042228408157825, 'eval_runtime': 3.8046, 'eval_samples_per_second': 269.15, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004902106709778309, 'eval_loss_2': 0.0031401216983795166, 'eval_loss_3': -18.163551330566406, 'eval_loss_4': 0.27128204703330994, 'epoch': 27.73}
{'loss': 0.0042, 'grad_norm': 5.435677528381348, 'learning_rate': 2.2848837209302325e-06, 'loss_1': 0.0025197071954607964, 'loss_2': 0.0017242431640625, 'loss_3': -16.50079345703125, 'loss_4': 0.01922956481575966, 'epoch': 27.74}
{'loss': 0.0048, 'grad_norm': 4.274755477905273, 'learning_rate': 2.2790697674418603e-06, 'loss_1': 0.0024294068571180105, 'loss_2': 0.0023517608642578125, 'loss_3': -16.413402557373047, 'loss_4': 0.4185965955257416, 'epoch': 27.74}
{'loss': 0.0077, 'grad_norm': 4.830112934112549, 'learning_rate': 2.2732558139534885e-06, 'loss_1': 0.004040788393467665, 'loss_2': 0.003612518310546875, 'loss_3': -16.339439392089844, 'loss_4': 0.57268226146698, 'epoch': 27.75}
{'loss': 0.0053, 'grad_norm': 5.164491176605225, 'learning_rate': 2.2674418604651163e-06, 'loss_1': 0.0031061454210430384, 'loss_2': 0.002162933349609375, 'loss_3': -16.38155746459961, 'loss_4': 0.07130958139896393, 'epoch': 27.76}
{'loss': 0.0089, 'grad_norm': 4.8734941482543945, 'learning_rate': 2.261627906976744e-06, 'loss_1': 0.0023644764441996813, 'loss_2': 0.00653076171875, 'loss_3': -16.37525177001953, 'loss_4': 0.42216724157333374, 'epoch': 27.76}
[INFO|trainer.py:4228] 2025-01-21 14:18:00,448 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:00,448 >>   Batch size = 64
 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                | 4780/5160 [1:58:04<06:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:07,809 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007850782945752144, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.983, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00482306070625782, 'eval_loss_2': 0.0030277222394943237, 'eval_loss_3': -18.169776916503906, 'eval_loss_4': 0.2925294041633606, 'epoch': 27.76}
{'loss': 0.0104, 'grad_norm': 6.267549991607666, 'learning_rate': 2.2558139534883723e-06, 'loss_1': 0.007503770291805267, 'loss_2': 0.0029277801513671875, 'loss_3': -16.310611724853516, 'loss_4': 0.4644554853439331, 'epoch': 27.77}
{'loss': 0.0024, 'grad_norm': 4.872488975524902, 'learning_rate': 2.25e-06, 'loss_1': 0.0020814589224755764, 'loss_2': 0.000286102294921875, 'loss_3': -16.32900619506836, 'loss_4': 0.4648398160934448, 'epoch': 27.77}
{'loss': 0.0046, 'grad_norm': 4.617260932922363, 'learning_rate': 2.244186046511628e-06, 'loss_1': 0.004123718477785587, 'loss_2': 0.0005116462707519531, 'loss_3': -16.298080444335938, 'loss_4': 0.29599377512931824, 'epoch': 27.78}
{'loss': 0.0047, 'grad_norm': 5.168948173522949, 'learning_rate': 2.2383720930232556e-06, 'loss_1': 0.003901659045368433, 'loss_2': 0.0008020401000976562, 'loss_3': -16.571123123168945, 'loss_4': 0.714706540107727, 'epoch': 27.78}
{'loss': 0.0062, 'grad_norm': 4.363887310028076, 'learning_rate': 2.232558139534884e-06, 'loss_1': 0.001420200220309198, 'loss_2': 0.00482177734375, 'loss_3': -16.493215560913086, 'loss_4': 0.14229343831539154, 'epoch': 27.79}
[INFO|trainer.py:4228] 2025-01-21 14:18:07,809 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:07,809 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                | 4785/5160 [1:58:12<06:29,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:15,175 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007913989946246147, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.38, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.004817300476133823, 'eval_loss_2': 0.003096688538789749, 'eval_loss_3': -18.169143676757812, 'eval_loss_4': 0.3180895745754242, 'epoch': 27.79}
{'loss': 0.0058, 'grad_norm': 6.716135025024414, 'learning_rate': 2.2267441860465116e-06, 'loss_1': 0.005602006800472736, 'loss_2': 0.00017571449279785156, 'loss_3': -16.46560287475586, 'loss_4': 0.48524075746536255, 'epoch': 27.8}
{'loss': 0.0137, 'grad_norm': 6.289416790008545, 'learning_rate': 2.2209302325581394e-06, 'loss_1': 0.01106440182775259, 'loss_2': 0.00260162353515625, 'loss_3': -16.58096694946289, 'loss_4': 0.7022469639778137, 'epoch': 27.8}
{'loss': 0.0051, 'grad_norm': 5.331114292144775, 'learning_rate': 2.2151162790697676e-06, 'loss_1': 0.004897047765552998, 'loss_2': 0.00021195411682128906, 'loss_3': -16.561389923095703, 'loss_4': 0.5211144089698792, 'epoch': 27.81}
{'loss': 0.005, 'grad_norm': 4.919399261474609, 'learning_rate': 2.2093023255813954e-06, 'loss_1': 0.0014351882273331285, 'loss_2': 0.00359344482421875, 'loss_3': -16.611478805541992, 'loss_4': -0.020105618983507156, 'epoch': 27.81}
{'loss': 0.009, 'grad_norm': 4.9035468101501465, 'learning_rate': 2.203488372093023e-06, 'loss_1': 0.005960212554782629, 'loss_2': 0.003047943115234375, 'loss_3': -16.283912658691406, 'loss_4': 0.7033853530883789, 'epoch': 27.82}
[INFO|trainer.py:4228] 2025-01-21 14:18:15,175 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:15,175 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎               | 4790/5160 [1:58:19<06:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:22,534 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008520612493157387, 'eval_runtime': 3.8068, 'eval_samples_per_second': 268.993, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0052282908000051975, 'eval_loss_2': 0.0032923221588134766, 'eval_loss_3': -18.161375045776367, 'eval_loss_4': 0.32496440410614014, 'epoch': 27.82}
{'loss': 0.0093, 'grad_norm': 4.764308929443359, 'learning_rate': 2.1976744186046514e-06, 'loss_1': 0.005976320244371891, 'loss_2': 0.003326416015625, 'loss_3': -16.43474769592285, 'loss_4': 0.5567808151245117, 'epoch': 27.83}
{'loss': 0.0118, 'grad_norm': 5.0722975730896, 'learning_rate': 2.1918604651162788e-06, 'loss_1': 0.008393541909754276, 'loss_2': 0.0033721923828125, 'loss_3': -16.304214477539062, 'loss_4': 0.28442686796188354, 'epoch': 27.83}
{'loss': 0.0056, 'grad_norm': 4.849149227142334, 'learning_rate': 2.186046511627907e-06, 'loss_1': 0.0037026277277618647, 'loss_2': 0.00193023681640625, 'loss_3': -16.36819076538086, 'loss_4': 0.3494955897331238, 'epoch': 27.84}
{'loss': 0.0373, 'grad_norm': 18.48685646057129, 'learning_rate': 2.180232558139535e-06, 'loss_1': 0.03502267226576805, 'loss_2': 0.002269744873046875, 'loss_3': -16.337682723999023, 'loss_4': 0.5972567796707153, 'epoch': 27.84}
{'loss': 0.022, 'grad_norm': 11.32869815826416, 'learning_rate': 2.1744186046511625e-06, 'loss_1': 0.01631856895983219, 'loss_2': 0.005664825439453125, 'loss_3': -16.410228729248047, 'loss_4': 0.5122577548027039, 'epoch': 27.85}
[INFO|trainer.py:4228] 2025-01-21 14:18:22,535 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:22,535 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌               | 4795/5160 [1:58:27<06:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:29,888 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008372982032597065, 'eval_runtime': 3.8056, 'eval_samples_per_second': 269.075, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005004329141229391, 'eval_loss_2': 0.003368653357028961, 'eval_loss_3': -18.162731170654297, 'eval_loss_4': 0.33203136920928955, 'epoch': 27.85}
{'loss': 0.0038, 'grad_norm': 4.639923095703125, 'learning_rate': 2.1686046511627907e-06, 'loss_1': 0.0030651434790343046, 'loss_2': 0.0007205009460449219, 'loss_3': -16.405601501464844, 'loss_4': 0.5030843019485474, 'epoch': 27.85}
{'loss': 0.0226, 'grad_norm': 18.96380615234375, 'learning_rate': 2.162790697674419e-06, 'loss_1': 0.021675005555152893, 'loss_2': 0.0009441375732421875, 'loss_3': -16.47943115234375, 'loss_4': 0.38838860392570496, 'epoch': 27.86}
{'loss': 0.0049, 'grad_norm': 4.696603775024414, 'learning_rate': 2.1569767441860463e-06, 'loss_1': 0.002520904643461108, 'loss_2': 0.00241851806640625, 'loss_3': -16.429515838623047, 'loss_4': -0.0180647075176239, 'epoch': 27.87}
{'loss': 0.0059, 'grad_norm': 5.112626552581787, 'learning_rate': 2.1511627906976745e-06, 'loss_1': 0.003168186405673623, 'loss_2': 0.0027256011962890625, 'loss_3': -16.132259368896484, 'loss_4': 0.5063676834106445, 'epoch': 27.87}
{'loss': 0.0061, 'grad_norm': 6.601909637451172, 'learning_rate': 2.1453488372093023e-06, 'loss_1': 0.005308781284838915, 'loss_2': 0.0007505416870117188, 'loss_3': -16.472049713134766, 'loss_4': 0.1941608190536499, 'epoch': 27.88}
[INFO|trainer.py:4228] 2025-01-21 14:18:29,888 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:29,888 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 4800/5160 [1:58:34<06:14,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:37,240 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008943410590291023, 'eval_runtime': 3.8013, 'eval_samples_per_second': 269.382, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.004950853064656258, 'eval_loss_2': 0.003992557525634766, 'eval_loss_3': -18.15658950805664, 'eval_loss_4': 0.3295256197452545, 'epoch': 27.88}
{'loss': 0.004, 'grad_norm': 3.7919552326202393, 'learning_rate': 2.13953488372093e-06, 'loss_1': 0.002819910878315568, 'loss_2': 0.0011501312255859375, 'loss_3': -16.312244415283203, 'loss_4': 0.1682785600423813, 'epoch': 27.88}
{'loss': 0.0046, 'grad_norm': 4.419917583465576, 'learning_rate': 2.1337209302325583e-06, 'loss_1': 0.0017954771174117923, 'loss_2': 0.0028476715087890625, 'loss_3': -16.400379180908203, 'loss_4': 0.6227742433547974, 'epoch': 27.89}
{'loss': 0.013, 'grad_norm': 5.964486122131348, 'learning_rate': 2.127906976744186e-06, 'loss_1': 0.007586677558720112, 'loss_2': 0.0054168701171875, 'loss_3': -16.414714813232422, 'loss_4': 0.5017741322517395, 'epoch': 27.9}
{'loss': 0.0043, 'grad_norm': 4.889180660247803, 'learning_rate': 2.122093023255814e-06, 'loss_1': 0.0034883758053183556, 'loss_2': 0.0008282661437988281, 'loss_3': -16.325111389160156, 'loss_4': -0.10477320849895477, 'epoch': 27.9}
{'loss': 0.004, 'grad_norm': 4.78005313873291, 'learning_rate': 2.116279069767442e-06, 'loss_1': 0.002374226227402687, 'loss_2': 0.001644134521484375, 'loss_3': -16.353609085083008, 'loss_4': 0.36401423811912537, 'epoch': 27.91}
[INFO|trainer.py:4228] 2025-01-21 14:18:37,240 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:37,240 >>   Batch size = 64
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉               | 4805/5160 [1:58:41<06:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:44,608 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009360427036881447, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.904, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005106920842081308, 'eval_loss_2': 0.004253506660461426, 'eval_loss_3': -18.15448760986328, 'eval_loss_4': 0.33647337555885315, 'epoch': 27.91}
{'loss': 0.0118, 'grad_norm': 4.633440971374512, 'learning_rate': 2.11046511627907e-06, 'loss_1': 0.00543615035712719, 'loss_2': 0.00640106201171875, 'loss_3': -16.343639373779297, 'loss_4': -0.03879862651228905, 'epoch': 27.91}
{'loss': 0.0086, 'grad_norm': 6.284424781799316, 'learning_rate': 2.1046511627906977e-06, 'loss_1': 0.0058359806425869465, 'loss_2': 0.002803802490234375, 'loss_3': -16.432796478271484, 'loss_4': 0.3273598253726959, 'epoch': 27.92}
{'loss': 0.0121, 'grad_norm': 4.680768966674805, 'learning_rate': 2.0988372093023254e-06, 'loss_1': 0.0036903154104948044, 'loss_2': 0.008453369140625, 'loss_3': -16.528505325317383, 'loss_4': 0.5095211863517761, 'epoch': 27.92}
{'loss': 0.0061, 'grad_norm': 5.00689697265625, 'learning_rate': 2.0930232558139536e-06, 'loss_1': 0.00288051413372159, 'loss_2': 0.0032501220703125, 'loss_3': -16.33280372619629, 'loss_4': 1.2561962604522705, 'epoch': 27.93}
{'loss': 0.0074, 'grad_norm': 4.8636860847473145, 'learning_rate': 2.0872093023255814e-06, 'loss_1': 0.0039041314739733934, 'loss_2': 0.003505706787109375, 'loss_3': -16.374588012695312, 'loss_4': 0.05436412990093231, 'epoch': 27.94}
[INFO|trainer.py:4228] 2025-01-21 14:18:44,608 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:44,608 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 4810/5160 [1:58:49<06:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:51,975 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009043260477483273, 'eval_runtime': 3.8097, 'eval_samples_per_second': 268.787, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005166424438357353, 'eval_loss_2': 0.0038768351078033447, 'eval_loss_3': -18.15308380126953, 'eval_loss_4': 0.3499976694583893, 'epoch': 27.94}
{'loss': 0.0035, 'grad_norm': 4.739671230316162, 'learning_rate': 2.0813953488372092e-06, 'loss_1': 0.002890448784455657, 'loss_2': 0.0006170272827148438, 'loss_3': -16.507225036621094, 'loss_4': 0.7093290090560913, 'epoch': 27.94}
{'loss': 0.0069, 'grad_norm': 6.756763458251953, 'learning_rate': 2.0755813953488374e-06, 'loss_1': 0.006864124909043312, 'loss_2': 4.678964614868164e-05, 'loss_3': -16.41611099243164, 'loss_4': 0.6863107681274414, 'epoch': 27.95}
{'loss': 0.0046, 'grad_norm': 4.87333869934082, 'learning_rate': 2.0697674418604652e-06, 'loss_1': 0.0023840491194278, 'loss_2': 0.002166748046875, 'loss_3': -16.564607620239258, 'loss_4': 0.5085203051567078, 'epoch': 27.95}
{'loss': 0.0046, 'grad_norm': 4.583629131317139, 'learning_rate': 2.063953488372093e-06, 'loss_1': 0.002527305856347084, 'loss_2': 0.00211334228515625, 'loss_3': -16.521411895751953, 'loss_4': 0.3099406957626343, 'epoch': 27.96}
{'loss': 0.0048, 'grad_norm': 5.052126884460449, 'learning_rate': 2.058139534883721e-06, 'loss_1': 0.004718722775578499, 'loss_2': 8.171796798706055e-05, 'loss_3': -16.38184928894043, 'loss_4': 0.470680832862854, 'epoch': 27.97}
[INFO|trainer.py:4228] 2025-01-21 14:18:51,975 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:51,975 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎              | 4815/5160 [1:58:56<05:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:18:59,332 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008969868533313274, 'eval_runtime': 3.8214, 'eval_samples_per_second': 267.963, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.005353803280740976, 'eval_loss_2': 0.0036160647869110107, 'eval_loss_3': -18.14679527282715, 'eval_loss_4': 0.36758363246917725, 'epoch': 27.97}
{'loss': 0.0071, 'grad_norm': 4.345214366912842, 'learning_rate': 2.0523255813953486e-06, 'loss_1': 0.0026470539160072803, 'loss_2': 0.004467010498046875, 'loss_3': -16.45372772216797, 'loss_4': -0.09295086562633514, 'epoch': 27.97}
{'loss': 0.0095, 'grad_norm': 5.248260021209717, 'learning_rate': 2.0465116279069768e-06, 'loss_1': 0.003030825639143586, 'loss_2': 0.00649261474609375, 'loss_3': -16.46841812133789, 'loss_4': 0.44082847237586975, 'epoch': 27.98}
{'loss': 0.0046, 'grad_norm': 4.516118049621582, 'learning_rate': 2.040697674418605e-06, 'loss_1': 0.0038156588561832905, 'loss_2': 0.0008325576782226562, 'loss_3': -16.332355499267578, 'loss_4': 0.06912559270858765, 'epoch': 27.98}
{'loss': 0.0079, 'grad_norm': 4.987755298614502, 'learning_rate': 2.0348837209302324e-06, 'loss_1': 0.004468982573598623, 'loss_2': 0.00341796875, 'loss_3': -16.305574417114258, 'loss_4': 0.6001571416854858, 'epoch': 27.99}
{'loss': 0.0053, 'grad_norm': 4.624983787536621, 'learning_rate': 2.0290697674418606e-06, 'loss_1': 0.0030184921342879534, 'loss_2': 0.002231597900390625, 'loss_3': -16.330535888671875, 'loss_4': -0.10491439700126648, 'epoch': 27.99}
[INFO|trainer.py:4228] 2025-01-21 14:18:59,333 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:18:59,333 >>   Batch size = 64
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌              | 4820/5160 [1:59:03<05:46,  1.02s/it][INFO|trainer.py:4226] 2025-01-21 14:19:06,396 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008235346525907516, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.977, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005127109587192535, 'eval_loss_2': 0.003108236938714981, 'eval_loss_3': -18.144672393798828, 'eval_loss_4': 0.3763262629508972, 'epoch': 27.99}
{'loss': 0.0067, 'grad_norm': 6.380908489227295, 'learning_rate': 2.0232558139534888e-06, 'loss_1': 0.0017837575869634748, 'loss_2': 0.0049591064453125, 'loss_3': -16.58646583557129, 'loss_4': 0.443338006734848, 'epoch': 28.0}
{'loss': 0.0243, 'grad_norm': 11.7822265625, 'learning_rate': 2.017441860465116e-06, 'loss_1': 0.02346867136657238, 'loss_2': 0.000812530517578125, 'loss_3': -16.445449829101562, 'loss_4': -0.056971706449985504, 'epoch': 28.01}
{'loss': 0.0045, 'grad_norm': 4.152862548828125, 'learning_rate': 2.0116279069767443e-06, 'loss_1': 0.0023845727555453777, 'loss_2': 0.0021495819091796875, 'loss_3': -16.569480895996094, 'loss_4': 0.33923089504241943, 'epoch': 28.01}
{'loss': 0.007, 'grad_norm': 5.55997371673584, 'learning_rate': 2.005813953488372e-06, 'loss_1': 0.0033903864677995443, 'loss_2': 0.003612518310546875, 'loss_3': -16.396133422851562, 'loss_4': 0.2827215790748596, 'epoch': 28.02}
{'loss': 0.0069, 'grad_norm': 5.103610038757324, 'learning_rate': 2e-06, 'loss_1': 0.004763665609061718, 'loss_2': 0.002162933349609375, 'loss_3': -16.44443702697754, 'loss_4': 0.4655981957912445, 'epoch': 28.02}
[INFO|trainer.py:4228] 2025-01-21 14:19:06,396 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:06,396 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 4825/5160 [1:59:10<05:47,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:13,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007842568680644035, 'eval_runtime': 3.805, 'eval_samples_per_second': 269.12, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004961392376571894, 'eval_loss_2': 0.002881176769733429, 'eval_loss_3': -18.145036697387695, 'eval_loss_4': 0.38424766063690186, 'epoch': 28.02}
{'loss': 0.0055, 'grad_norm': 4.88594913482666, 'learning_rate': 1.994186046511628e-06, 'loss_1': 0.002210632897913456, 'loss_2': 0.0033283233642578125, 'loss_3': -16.30356216430664, 'loss_4': 0.7530369758605957, 'epoch': 28.03}
{'loss': 0.003, 'grad_norm': 4.953044414520264, 'learning_rate': 1.988372093023256e-06, 'loss_1': 0.001982172718271613, 'loss_2': 0.0010471343994140625, 'loss_3': -16.499282836914062, 'loss_4': 0.6218045949935913, 'epoch': 28.03}
{'loss': 0.0068, 'grad_norm': 5.165633678436279, 'learning_rate': 1.9825581395348837e-06, 'loss_1': 0.0042246924713253975, 'loss_2': 0.002529144287109375, 'loss_3': -16.29171371459961, 'loss_4': 0.746696412563324, 'epoch': 28.04}
{'loss': 0.0084, 'grad_norm': 5.110789775848389, 'learning_rate': 1.976744186046512e-06, 'loss_1': 0.005263549741357565, 'loss_2': 0.0031833648681640625, 'loss_3': -16.285064697265625, 'loss_4': 0.5534750819206238, 'epoch': 28.05}
{'loss': 0.0082, 'grad_norm': 5.287288188934326, 'learning_rate': 1.9709302325581397e-06, 'loss_1': 0.006108933128416538, 'loss_2': 0.002071380615234375, 'loss_3': -16.549652099609375, 'loss_4': -0.11153681576251984, 'epoch': 28.05}
[INFO|trainer.py:4228] 2025-01-21 14:19:13,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:13,754 >>   Batch size = 64
 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉              | 4830/5160 [1:59:18<05:42,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:21,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008229659870266914, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.135, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005352819338440895, 'eval_loss_2': 0.0028768405318260193, 'eval_loss_3': -18.140893936157227, 'eval_loss_4': 0.3901323676109314, 'epoch': 28.05}
{'loss': 0.0071, 'grad_norm': 5.048127174377441, 'learning_rate': 1.9651162790697675e-06, 'loss_1': 0.003944829106330872, 'loss_2': 0.003108978271484375, 'loss_3': -16.548389434814453, 'loss_4': 0.2461691051721573, 'epoch': 28.06}
{'loss': 0.0094, 'grad_norm': 4.813248157501221, 'learning_rate': 1.9593023255813953e-06, 'loss_1': 0.0032017019111663103, 'loss_2': 0.0062408447265625, 'loss_3': -16.43874168395996, 'loss_4': 0.7554008960723877, 'epoch': 28.06}
{'loss': 0.0209, 'grad_norm': 10.959136009216309, 'learning_rate': 1.9534883720930235e-06, 'loss_1': 0.016017161309719086, 'loss_2': 0.00484466552734375, 'loss_3': -16.310527801513672, 'loss_4': 0.110615573823452, 'epoch': 28.07}
{'loss': 0.0095, 'grad_norm': 5.7780375480651855, 'learning_rate': 1.9476744186046512e-06, 'loss_1': 0.007503107655793428, 'loss_2': 0.001972198486328125, 'loss_3': -16.353912353515625, 'loss_4': 0.9388447999954224, 'epoch': 28.08}
{'loss': 0.0031, 'grad_norm': 4.755799293518066, 'learning_rate': 1.941860465116279e-06, 'loss_1': 0.002311090240254998, 'loss_2': 0.0007801055908203125, 'loss_3': -16.365673065185547, 'loss_4': 0.32881197333335876, 'epoch': 28.08}
[INFO|trainer.py:4228] 2025-01-21 14:19:21,115 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:21,115 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏             | 4835/5160 [1:59:25<05:37,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:28,470 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00833756010979414, 'eval_runtime': 3.8009, 'eval_samples_per_second': 269.408, 'eval_steps_per_second': 4.209, 'eval_loss_1': 0.005387726239860058, 'eval_loss_2': 0.002949833869934082, 'eval_loss_3': -18.13262939453125, 'eval_loss_4': 0.3859459161758423, 'epoch': 28.08}
{'loss': 0.0057, 'grad_norm': 4.430337429046631, 'learning_rate': 1.9360465116279072e-06, 'loss_1': 0.0018712930614128709, 'loss_2': 0.003780364990234375, 'loss_3': -16.33490753173828, 'loss_4': 0.5106022953987122, 'epoch': 28.09}
{'loss': 0.0073, 'grad_norm': 5.016663551330566, 'learning_rate': 1.930232558139535e-06, 'loss_1': 0.0047442433424293995, 'loss_2': 0.0025501251220703125, 'loss_3': -16.37848663330078, 'loss_4': 0.24828794598579407, 'epoch': 28.09}
{'loss': 0.004, 'grad_norm': 5.162990093231201, 'learning_rate': 1.924418604651163e-06, 'loss_1': 0.0032610376365482807, 'loss_2': 0.0007143020629882812, 'loss_3': -16.41489028930664, 'loss_4': 0.35191580653190613, 'epoch': 28.1}
{'loss': 0.0076, 'grad_norm': 5.086909770965576, 'learning_rate': 1.918604651162791e-06, 'loss_1': 0.003268319647759199, 'loss_2': 0.004302978515625, 'loss_3': -16.546566009521484, 'loss_4': 0.7198130488395691, 'epoch': 28.1}
{'loss': 0.0075, 'grad_norm': 4.121218681335449, 'learning_rate': 1.9127906976744184e-06, 'loss_1': 0.002925014356151223, 'loss_2': 0.00457763671875, 'loss_3': -16.218551635742188, 'loss_4': 0.36809849739074707, 'epoch': 28.11}
[INFO|trainer.py:4228] 2025-01-21 14:19:28,470 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:28,470 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍             | 4840/5160 [1:59:32<05:32,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:35,829 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00854548066854477, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.768, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.00558145996183157, 'eval_loss_2': 0.002964019775390625, 'eval_loss_3': -18.12735939025879, 'eval_loss_4': 0.37041324377059937, 'epoch': 28.11}
{'loss': 0.0027, 'grad_norm': 4.258420944213867, 'learning_rate': 1.9069767441860466e-06, 'loss_1': 0.0023034149780869484, 'loss_2': 0.00041794776916503906, 'loss_3': -16.38365936279297, 'loss_4': 0.5178765058517456, 'epoch': 28.12}
{'loss': 0.0033, 'grad_norm': 4.981395244598389, 'learning_rate': 1.9011627906976746e-06, 'loss_1': 0.0032803528010845184, 'loss_2': 5.4955482482910156e-05, 'loss_3': -16.304588317871094, 'loss_4': 0.6374344229698181, 'epoch': 28.12}
{'loss': 0.0056, 'grad_norm': 4.627969264984131, 'learning_rate': 1.8953488372093022e-06, 'loss_1': 0.003573630703613162, 'loss_2': 0.002063751220703125, 'loss_3': -16.166080474853516, 'loss_4': -0.053480178117752075, 'epoch': 28.13}
{'loss': 0.0172, 'grad_norm': 17.213369369506836, 'learning_rate': 1.8895348837209304e-06, 'loss_1': 0.014417667873203754, 'loss_2': 0.002811431884765625, 'loss_3': -16.58615493774414, 'loss_4': 0.23543670773506165, 'epoch': 28.13}
{'loss': 0.0058, 'grad_norm': 4.6956562995910645, 'learning_rate': 1.8837209302325584e-06, 'loss_1': 0.0029320865869522095, 'loss_2': 0.00290679931640625, 'loss_3': -16.427734375, 'loss_4': 0.5825157761573792, 'epoch': 28.14}
[INFO|trainer.py:4228] 2025-01-21 14:19:35,830 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:35,830 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋             | 4845/5160 [1:59:40<05:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:43,177 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008388038724660873, 'eval_runtime': 3.8029, 'eval_samples_per_second': 269.269, 'eval_steps_per_second': 4.207, 'eval_loss_1': 0.005407777149230242, 'eval_loss_2': 0.002980262041091919, 'eval_loss_3': -18.13532257080078, 'eval_loss_4': 0.3511520028114319, 'epoch': 28.14}
{'loss': 0.0097, 'grad_norm': 4.836681842803955, 'learning_rate': 1.877906976744186e-06, 'loss_1': 0.0024590161629021168, 'loss_2': 0.007236480712890625, 'loss_3': -16.41692352294922, 'loss_4': 0.5134296417236328, 'epoch': 28.15}
{'loss': 0.0084, 'grad_norm': 4.032820224761963, 'learning_rate': 1.8720930232558142e-06, 'loss_1': 0.00421988544985652, 'loss_2': 0.00414276123046875, 'loss_3': -16.21633529663086, 'loss_4': -0.0059368908405303955, 'epoch': 28.15}
{'loss': 0.006, 'grad_norm': 5.163630962371826, 'learning_rate': 1.866279069767442e-06, 'loss_1': 0.002147190272808075, 'loss_2': 0.003833770751953125, 'loss_3': -16.49279022216797, 'loss_4': 0.8750186562538147, 'epoch': 28.16}
{'loss': 0.0196, 'grad_norm': 12.647540092468262, 'learning_rate': 1.8604651162790697e-06, 'loss_1': 0.015984153375029564, 'loss_2': 0.003566741943359375, 'loss_3': -16.406524658203125, 'loss_4': 0.32595521211624146, 'epoch': 28.16}
{'loss': 0.0064, 'grad_norm': 5.8287553787231445, 'learning_rate': 1.8546511627906977e-06, 'loss_1': 0.0050767106004059315, 'loss_2': 0.0012874603271484375, 'loss_3': -16.281219482421875, 'loss_4': 0.5078544020652771, 'epoch': 28.17}
[INFO|trainer.py:4228] 2025-01-21 14:19:43,177 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:43,177 >>   Batch size = 64
 94%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊             | 4850/5160 [1:59:47<05:21,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:50,532 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008887018077075481, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.971, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.00557833444327116, 'eval_loss_2': 0.0033086836338043213, 'eval_loss_3': -18.140777587890625, 'eval_loss_4': 0.35303938388824463, 'epoch': 28.17}
{'loss': 0.0093, 'grad_norm': 5.347716808319092, 'learning_rate': 1.8488372093023257e-06, 'loss_1': 0.0036840883549302816, 'loss_2': 0.00563812255859375, 'loss_3': -16.45526123046875, 'loss_4': 0.1635608673095703, 'epoch': 28.17}
{'loss': 0.0136, 'grad_norm': 6.340712547302246, 'learning_rate': 1.8430232558139535e-06, 'loss_1': 0.008952762000262737, 'loss_2': 0.00469207763671875, 'loss_3': -16.482158660888672, 'loss_4': 0.5004138350486755, 'epoch': 28.18}
{'loss': 0.0081, 'grad_norm': 4.868431568145752, 'learning_rate': 1.8372093023255815e-06, 'loss_1': 0.0044412254355847836, 'loss_2': 0.0036468505859375, 'loss_3': -16.34353256225586, 'loss_4': 0.17892883718013763, 'epoch': 28.19}
{'loss': 0.0171, 'grad_norm': 6.966094017028809, 'learning_rate': 1.8313953488372093e-06, 'loss_1': 0.011770930141210556, 'loss_2': 0.005279541015625, 'loss_3': -16.364171981811523, 'loss_4': 0.25535130500793457, 'epoch': 28.19}
{'loss': 0.0045, 'grad_norm': 4.340856552124023, 'learning_rate': 1.8255813953488373e-06, 'loss_1': 0.0036085445899516344, 'loss_2': 0.0008544921875, 'loss_3': -16.459280014038086, 'loss_4': 0.3484399914741516, 'epoch': 28.2}
[INFO|trainer.py:4228] 2025-01-21 14:19:50,532 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:50,532 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 4855/5160 [1:59:55<05:16,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:19:57,886 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008926485665142536, 'eval_runtime': 3.8062, 'eval_samples_per_second': 269.036, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005474958568811417, 'eval_loss_2': 0.003451526165008545, 'eval_loss_3': -18.14451789855957, 'eval_loss_4': 0.36776629090309143, 'epoch': 28.2}
{'loss': 0.0064, 'grad_norm': 5.261167526245117, 'learning_rate': 1.8197674418604653e-06, 'loss_1': 0.006110548973083496, 'loss_2': 0.00026679039001464844, 'loss_3': -16.27707290649414, 'loss_4': 0.15009911358356476, 'epoch': 28.2}
{'loss': 0.0187, 'grad_norm': 9.779940605163574, 'learning_rate': 1.813953488372093e-06, 'loss_1': 0.015511250123381615, 'loss_2': 0.003204345703125, 'loss_3': -16.314851760864258, 'loss_4': 0.5412314534187317, 'epoch': 28.21}
{'loss': 0.0128, 'grad_norm': 7.789292812347412, 'learning_rate': 1.8081395348837208e-06, 'loss_1': 0.010403946973383427, 'loss_2': 0.0024204254150390625, 'loss_3': -16.556392669677734, 'loss_4': 0.6785917282104492, 'epoch': 28.22}
{'loss': 0.0075, 'grad_norm': 5.4041056632995605, 'learning_rate': 1.802325581395349e-06, 'loss_1': 0.004067845642566681, 'loss_2': 0.0034503936767578125, 'loss_3': -16.3568115234375, 'loss_4': 0.9167571067810059, 'epoch': 28.22}
{'loss': 0.0072, 'grad_norm': 4.91530179977417, 'learning_rate': 1.7965116279069768e-06, 'loss_1': 0.006185254547744989, 'loss_2': 0.0010585784912109375, 'loss_3': -16.41731071472168, 'loss_4': 0.4043143391609192, 'epoch': 28.23}
[INFO|trainer.py:4228] 2025-01-21 14:19:57,886 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:19:57,886 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎            | 4860/5160 [2:00:02<05:11,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:05,243 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009050088934600353, 'eval_runtime': 3.8049, 'eval_samples_per_second': 269.124, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005552275106310844, 'eval_loss_2': 0.003497812896966934, 'eval_loss_3': -18.137706756591797, 'eval_loss_4': 0.38686537742614746, 'epoch': 28.23}
{'loss': 0.0112, 'grad_norm': 4.590453147888184, 'learning_rate': 1.7906976744186046e-06, 'loss_1': 0.002997376723214984, 'loss_2': 0.008209228515625, 'loss_3': -16.519012451171875, 'loss_4': 0.06413934379816055, 'epoch': 28.23}
{'loss': 0.0077, 'grad_norm': 5.171874523162842, 'learning_rate': 1.7848837209302326e-06, 'loss_1': 0.005114241503179073, 'loss_2': 0.00260162353515625, 'loss_3': -16.345977783203125, 'loss_4': 0.20890572667121887, 'epoch': 28.24}
{'loss': 0.0102, 'grad_norm': 6.337025165557861, 'learning_rate': 1.7790697674418606e-06, 'loss_1': 0.007013094145804644, 'loss_2': 0.0032196044921875, 'loss_3': -16.41443634033203, 'loss_4': 0.2215871959924698, 'epoch': 28.24}
{'loss': 0.0058, 'grad_norm': 5.468888282775879, 'learning_rate': 1.7732558139534884e-06, 'loss_1': 0.004103939514607191, 'loss_2': 0.0017156600952148438, 'loss_3': -16.241043090820312, 'loss_4': 0.2421569675207138, 'epoch': 28.25}
{'loss': 0.0133, 'grad_norm': 6.922401428222656, 'learning_rate': 1.7674418604651162e-06, 'loss_1': 0.009054833091795444, 'loss_2': 0.00421905517578125, 'loss_3': -16.07503318786621, 'loss_4': 0.3812201917171478, 'epoch': 28.26}
[INFO|trainer.py:4228] 2025-01-21 14:20:05,243 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:05,243 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍            | 4865/5160 [2:00:09<05:06,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:12,607 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009073380380868912, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.65, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005423237569630146, 'eval_loss_2': 0.0036501437425613403, 'eval_loss_3': -18.136240005493164, 'eval_loss_4': 0.382571280002594, 'epoch': 28.26}
{'loss': 0.0085, 'grad_norm': 6.14636754989624, 'learning_rate': 1.7616279069767442e-06, 'loss_1': 0.007322556804865599, 'loss_2': 0.0011386871337890625, 'loss_3': -16.429275512695312, 'loss_4': 0.8004113435745239, 'epoch': 28.26}
{'loss': 0.0084, 'grad_norm': 4.536418437957764, 'learning_rate': 1.7558139534883722e-06, 'loss_1': 0.0048031932674348354, 'loss_2': 0.0035762786865234375, 'loss_3': -16.509185791015625, 'loss_4': 0.1805737465620041, 'epoch': 28.27}
{'loss': 0.0165, 'grad_norm': 12.345453262329102, 'learning_rate': 1.75e-06, 'loss_1': 0.014347328804433346, 'loss_2': 0.00213623046875, 'loss_3': -16.56707763671875, 'loss_4': 0.6583430767059326, 'epoch': 28.27}
{'loss': 0.0062, 'grad_norm': 4.9952287673950195, 'learning_rate': 1.744186046511628e-06, 'loss_1': 0.003372595412656665, 'loss_2': 0.0028228759765625, 'loss_3': -16.355005264282227, 'loss_4': 0.3303735852241516, 'epoch': 28.28}
{'loss': 0.0055, 'grad_norm': 4.7017011642456055, 'learning_rate': 1.7383720930232558e-06, 'loss_1': 0.004249939229339361, 'loss_2': 0.001255035400390625, 'loss_3': -16.312219619750977, 'loss_4': -0.011016154661774635, 'epoch': 28.28}
[INFO|trainer.py:4228] 2025-01-21 14:20:12,607 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:12,607 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 4870/5160 [2:00:17<05:01,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:19,962 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.009031985886394978, 'eval_runtime': 3.8091, 'eval_samples_per_second': 268.833, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005417858716100454, 'eval_loss_2': 0.0036141276359558105, 'eval_loss_3': -18.137027740478516, 'eval_loss_4': 0.38109731674194336, 'epoch': 28.28}
{'loss': 0.0061, 'grad_norm': 4.421572208404541, 'learning_rate': 1.7325581395348838e-06, 'loss_1': 0.004167452920228243, 'loss_2': 0.00191497802734375, 'loss_3': -16.2869815826416, 'loss_4': 0.7267822623252869, 'epoch': 28.29}
{'loss': 0.0035, 'grad_norm': 5.174004077911377, 'learning_rate': 1.7267441860465118e-06, 'loss_1': 0.003000180935487151, 'loss_2': 0.0004949569702148438, 'loss_3': -16.433984756469727, 'loss_4': 0.32692238688468933, 'epoch': 28.3}
{'loss': 0.0045, 'grad_norm': 4.307250022888184, 'learning_rate': 1.7209302325581395e-06, 'loss_1': 0.0020294503774493933, 'loss_2': 0.0024509429931640625, 'loss_3': -16.50469970703125, 'loss_4': 0.6881116628646851, 'epoch': 28.3}
{'loss': 0.0101, 'grad_norm': 5.058629035949707, 'learning_rate': 1.7151162790697673e-06, 'loss_1': 0.00419967994093895, 'loss_2': 0.005901336669921875, 'loss_3': -16.29559326171875, 'loss_4': 0.590737521648407, 'epoch': 28.31}
{'loss': 0.0534, 'grad_norm': 20.86807632446289, 'learning_rate': 1.7093023255813955e-06, 'loss_1': 0.050999175757169724, 'loss_2': 0.0024261474609375, 'loss_3': -16.346881866455078, 'loss_4': 0.24693815410137177, 'epoch': 28.31}
[INFO|trainer.py:4228] 2025-01-21 14:20:19,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:19,963 >>   Batch size = 64
 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 4875/5160 [2:00:24<04:55,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:27,308 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008936841040849686, 'eval_runtime': 3.8004, 'eval_samples_per_second': 269.447, 'eval_steps_per_second': 4.21, 'eval_loss_1': 0.005484689958393574, 'eval_loss_2': 0.0034521520137786865, 'eval_loss_3': -18.137615203857422, 'eval_loss_4': 0.3850144147872925, 'epoch': 28.31}
{'loss': 0.0105, 'grad_norm': 4.956966876983643, 'learning_rate': 1.7034883720930233e-06, 'loss_1': 0.0038672464434057474, 'loss_2': 0.006610870361328125, 'loss_3': -16.368316650390625, 'loss_4': 0.08938594907522202, 'epoch': 28.32}
{'loss': 0.0584, 'grad_norm': 11.402099609375, 'learning_rate': 1.697674418604651e-06, 'loss_1': 0.05580221861600876, 'loss_2': 0.002597808837890625, 'loss_3': -16.265880584716797, 'loss_4': 1.0236923694610596, 'epoch': 28.33}
{'loss': 0.0085, 'grad_norm': 6.485827922821045, 'learning_rate': 1.691860465116279e-06, 'loss_1': 0.004808257799595594, 'loss_2': 0.003719329833984375, 'loss_3': -16.424713134765625, 'loss_4': 0.27497491240501404, 'epoch': 28.33}
{'loss': 0.0039, 'grad_norm': 4.259507656097412, 'learning_rate': 1.686046511627907e-06, 'loss_1': 0.0018343054689466953, 'loss_2': 0.0020313262939453125, 'loss_3': -16.29180335998535, 'loss_4': 0.3858770728111267, 'epoch': 28.34}
{'loss': 0.0076, 'grad_norm': 5.123165607452393, 'learning_rate': 1.6802325581395349e-06, 'loss_1': 0.00396498991176486, 'loss_2': 0.0036468505859375, 'loss_3': -16.44963836669922, 'loss_4': 0.3769163489341736, 'epoch': 28.34}
[INFO|trainer.py:4228] 2025-01-21 14:20:27,308 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:27,308 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████            | 4880/5160 [2:00:31<04:51,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:34,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00894735287874937, 'eval_runtime': 3.8064, 'eval_samples_per_second': 269.023, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005699958186596632, 'eval_loss_2': 0.003247395157814026, 'eval_loss_3': -18.1337947845459, 'eval_loss_4': 0.40698736906051636, 'epoch': 28.34}
{'loss': 0.0066, 'grad_norm': 4.734536170959473, 'learning_rate': 1.6744186046511629e-06, 'loss_1': 0.003762564854696393, 'loss_2': 0.002872467041015625, 'loss_3': -16.437307357788086, 'loss_4': 0.4514766037464142, 'epoch': 28.35}
{'loss': 0.009, 'grad_norm': 10.416738510131836, 'learning_rate': 1.6686046511627907e-06, 'loss_1': 0.00774000957608223, 'loss_2': 0.0012607574462890625, 'loss_3': -16.578393936157227, 'loss_4': 0.21735301613807678, 'epoch': 28.35}
{'loss': 0.0116, 'grad_norm': 8.217970848083496, 'learning_rate': 1.6627906976744187e-06, 'loss_1': 0.009257928468286991, 'loss_2': 0.00231170654296875, 'loss_3': -16.174335479736328, 'loss_4': 0.6209664940834045, 'epoch': 28.36}
{'loss': 0.0068, 'grad_norm': 5.0127458572387695, 'learning_rate': 1.6569767441860467e-06, 'loss_1': 0.001667903852649033, 'loss_2': 0.0051116943359375, 'loss_3': -16.355777740478516, 'loss_4': 0.6917824745178223, 'epoch': 28.37}
{'loss': 0.0122, 'grad_norm': 4.468283653259277, 'learning_rate': 1.6511627906976744e-06, 'loss_1': 0.002889300463721156, 'loss_2': 0.0093231201171875, 'loss_3': -16.353042602539062, 'loss_4': -0.044117093086242676, 'epoch': 28.37}
[INFO|trainer.py:4228] 2025-01-21 14:20:34,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:34,666 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎           | 4885/5160 [2:00:39<04:45,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:42,024 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008840573951601982, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.966, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005706530995666981, 'eval_loss_2': 0.0031340420246124268, 'eval_loss_3': -18.13353729248047, 'eval_loss_4': 0.4074360132217407, 'epoch': 28.37}
{'loss': 0.0051, 'grad_norm': 5.1575117111206055, 'learning_rate': 1.6453488372093022e-06, 'loss_1': 0.0031753943767398596, 'loss_2': 0.0019474029541015625, 'loss_3': -16.240970611572266, 'loss_4': 0.3652963638305664, 'epoch': 28.38}
{'loss': 0.005, 'grad_norm': 5.5171003341674805, 'learning_rate': 1.6395348837209304e-06, 'loss_1': 0.004423708654940128, 'loss_2': 0.0005407333374023438, 'loss_3': -16.333803176879883, 'loss_4': 0.03535209596157074, 'epoch': 28.38}
{'loss': 0.0106, 'grad_norm': 4.827374458312988, 'learning_rate': 1.6337209302325582e-06, 'loss_1': 0.0033390067983418703, 'loss_2': 0.007274627685546875, 'loss_3': -16.33538818359375, 'loss_4': 0.6324533224105835, 'epoch': 28.39}
{'loss': 0.0063, 'grad_norm': 4.649824619293213, 'learning_rate': 1.627906976744186e-06, 'loss_1': 0.0026478322688490152, 'loss_2': 0.00365447998046875, 'loss_3': -16.425765991210938, 'loss_4': 0.309673011302948, 'epoch': 28.4}
{'loss': 0.0084, 'grad_norm': 4.6123175621032715, 'learning_rate': 1.622093023255814e-06, 'loss_1': 0.003505188738927245, 'loss_2': 0.0049285888671875, 'loss_3': -16.144474029541016, 'loss_4': 0.42596352100372314, 'epoch': 28.4}
[INFO|trainer.py:4228] 2025-01-21 14:20:42,024 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:42,024 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 4890/5160 [2:00:46<04:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:49,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008773693814873695, 'eval_runtime': 3.807, 'eval_samples_per_second': 268.978, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.0057908049784600735, 'eval_loss_2': 0.0029828883707523346, 'eval_loss_3': -18.132598876953125, 'eval_loss_4': 0.39335179328918457, 'epoch': 28.4}
{'loss': 0.007, 'grad_norm': 5.693359375, 'learning_rate': 1.616279069767442e-06, 'loss_1': 0.00661470228806138, 'loss_2': 0.00039386749267578125, 'loss_3': -16.35665512084961, 'loss_4': 0.27543944120407104, 'epoch': 28.41}
{'loss': 0.0056, 'grad_norm': 4.923099040985107, 'learning_rate': 1.6104651162790698e-06, 'loss_1': 0.0026734136044979095, 'loss_2': 0.002925872802734375, 'loss_3': -16.36172103881836, 'loss_4': 0.46803709864616394, 'epoch': 28.41}
{'loss': 0.0102, 'grad_norm': 6.60813045501709, 'learning_rate': 1.6046511627906978e-06, 'loss_1': 0.007080931682139635, 'loss_2': 0.0031681060791015625, 'loss_3': -16.497936248779297, 'loss_4': -0.11300279945135117, 'epoch': 28.42}
{'loss': 0.0067, 'grad_norm': 4.439488887786865, 'learning_rate': 1.5988372093023256e-06, 'loss_1': 0.001873151632025838, 'loss_2': 0.0048370361328125, 'loss_3': -16.509836196899414, 'loss_4': 0.39696642756462097, 'epoch': 28.42}
{'loss': 0.0088, 'grad_norm': 4.327958583831787, 'learning_rate': 1.5930232558139536e-06, 'loss_1': 0.0036267342511564493, 'loss_2': 0.00519561767578125, 'loss_3': -16.459659576416016, 'loss_4': 0.07148876041173935, 'epoch': 28.43}
[INFO|trainer.py:4228] 2025-01-21 14:20:49,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:49,391 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 4895/5160 [2:00:53<04:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:20:56,757 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008564387448132038, 'eval_runtime': 3.8178, 'eval_samples_per_second': 268.216, 'eval_steps_per_second': 4.191, 'eval_loss_1': 0.005578938871622086, 'eval_loss_2': 0.002985447645187378, 'eval_loss_3': -18.130367279052734, 'eval_loss_4': 0.39089101552963257, 'epoch': 28.43}
{'loss': 0.0061, 'grad_norm': 4.688880443572998, 'learning_rate': 1.5872093023255816e-06, 'loss_1': 0.0044203768484294415, 'loss_2': 0.0017147064208984375, 'loss_3': -16.34758758544922, 'loss_4': 0.47631022334098816, 'epoch': 28.44}
{'loss': 0.008, 'grad_norm': 4.478796482086182, 'learning_rate': 1.5813953488372093e-06, 'loss_1': 0.0018378403037786484, 'loss_2': 0.00614166259765625, 'loss_3': -16.467103958129883, 'loss_4': 0.3412541449069977, 'epoch': 28.44}
{'loss': 0.0068, 'grad_norm': 4.636230945587158, 'learning_rate': 1.5755813953488371e-06, 'loss_1': 0.005797413177788258, 'loss_2': 0.001007080078125, 'loss_3': -16.53107261657715, 'loss_4': 0.48603013157844543, 'epoch': 28.45}
{'loss': 0.0068, 'grad_norm': 5.11753511428833, 'learning_rate': 1.5697674418604653e-06, 'loss_1': 0.005716871470212936, 'loss_2': 0.00107574462890625, 'loss_3': -16.41048812866211, 'loss_4': 0.7645641565322876, 'epoch': 28.45}
{'loss': 0.0089, 'grad_norm': 4.6705827713012695, 'learning_rate': 1.5639534883720931e-06, 'loss_1': 0.0028134675230830908, 'loss_2': 0.00605010986328125, 'loss_3': -16.41947364807129, 'loss_4': 0.24996793270111084, 'epoch': 28.46}
[INFO|trainer.py:4228] 2025-01-21 14:20:56,757 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:20:56,758 >>   Batch size = 64
 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉           | 4900/5160 [2:01:01<04:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:04,115 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008650610223412514, 'eval_runtime': 3.8095, 'eval_samples_per_second': 268.804, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005542079918086529, 'eval_loss_2': 0.0031085312366485596, 'eval_loss_3': -18.131450653076172, 'eval_loss_4': 0.39756065607070923, 'epoch': 28.46}
{'loss': 0.0048, 'grad_norm': 4.459953784942627, 'learning_rate': 1.558139534883721e-06, 'loss_1': 0.002506028162315488, 'loss_2': 0.002254486083984375, 'loss_3': -16.470165252685547, 'loss_4': 0.6319462060928345, 'epoch': 28.47}
{'loss': 0.0066, 'grad_norm': 5.48167085647583, 'learning_rate': 1.5523255813953487e-06, 'loss_1': 0.0062965210527181625, 'loss_2': 0.000347137451171875, 'loss_3': -16.249197006225586, 'loss_4': -0.058181993663311005, 'epoch': 28.47}
{'loss': 0.0159, 'grad_norm': 6.922961711883545, 'learning_rate': 1.546511627906977e-06, 'loss_1': 0.014820716343820095, 'loss_2': 0.0010700225830078125, 'loss_3': -16.474456787109375, 'loss_4': 0.8557413816452026, 'epoch': 28.48}
{'loss': 0.003, 'grad_norm': 4.224908828735352, 'learning_rate': 1.5406976744186047e-06, 'loss_1': 0.0024333407636731863, 'loss_2': 0.0005369186401367188, 'loss_3': -16.136655807495117, 'loss_4': 0.4036160707473755, 'epoch': 28.48}
{'loss': 0.0096, 'grad_norm': 5.074561595916748, 'learning_rate': 1.5348837209302325e-06, 'loss_1': 0.004877577535808086, 'loss_2': 0.00469207763671875, 'loss_3': -16.243682861328125, 'loss_4': 0.41573432087898254, 'epoch': 28.49}
[INFO|trainer.py:4228] 2025-01-21 14:21:04,116 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:04,116 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 4905/5160 [2:01:08<04:24,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:11,466 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00868163537234068, 'eval_runtime': 3.8058, 'eval_samples_per_second': 269.066, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005519072990864515, 'eval_loss_2': 0.003162562847137451, 'eval_loss_3': -18.129898071289062, 'eval_loss_4': 0.39357540011405945, 'epoch': 28.49}
{'loss': 0.0081, 'grad_norm': 7.362453460693359, 'learning_rate': 1.5290697674418605e-06, 'loss_1': 0.00756056746467948, 'loss_2': 0.0005331039428710938, 'loss_3': -16.280033111572266, 'loss_4': 0.22436928749084473, 'epoch': 28.49}
{'loss': 0.0087, 'grad_norm': 5.208535194396973, 'learning_rate': 1.5232558139534885e-06, 'loss_1': 0.0030587411019951105, 'loss_2': 0.005645751953125, 'loss_3': -16.407093048095703, 'loss_4': 0.2769809663295746, 'epoch': 28.5}
{'loss': 0.0126, 'grad_norm': 6.291694164276123, 'learning_rate': 1.5174418604651163e-06, 'loss_1': 0.010120280086994171, 'loss_2': 0.00244140625, 'loss_3': -16.364704132080078, 'loss_4': 0.47346460819244385, 'epoch': 28.51}
{'loss': 0.0051, 'grad_norm': 4.458237648010254, 'learning_rate': 1.5116279069767443e-06, 'loss_1': 0.0023195515386760235, 'loss_2': 0.0028133392333984375, 'loss_3': -16.374961853027344, 'loss_4': 0.517715334892273, 'epoch': 28.51}
{'loss': 0.0032, 'grad_norm': 4.814713954925537, 'learning_rate': 1.505813953488372e-06, 'loss_1': 0.003185073146596551, 'loss_2': 4.678964614868164e-05, 'loss_3': -16.378257751464844, 'loss_4': 0.508080005645752, 'epoch': 28.52}
[INFO|trainer.py:4228] 2025-01-21 14:21:11,466 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:11,466 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍          | 4910/5160 [2:01:15<04:19,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:18,825 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008524542674422264, 'eval_runtime': 3.8048, 'eval_samples_per_second': 269.133, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.005448734853416681, 'eval_loss_2': 0.00307580828666687, 'eval_loss_3': -18.130413055419922, 'eval_loss_4': 0.39135241508483887, 'epoch': 28.52}
{'loss': 0.0062, 'grad_norm': 4.140763282775879, 'learning_rate': 1.5e-06, 'loss_1': 0.0017730963882058859, 'loss_2': 0.00438690185546875, 'loss_3': -16.299293518066406, 'loss_4': 0.4216368794441223, 'epoch': 28.52}
{'loss': 0.011, 'grad_norm': 4.804869174957275, 'learning_rate': 1.494186046511628e-06, 'loss_1': 0.0042195627465844154, 'loss_2': 0.0067901611328125, 'loss_3': -16.336956024169922, 'loss_4': 0.2163415551185608, 'epoch': 28.53}
{'loss': 0.0109, 'grad_norm': 5.5162434577941895, 'learning_rate': 1.4883720930232558e-06, 'loss_1': 0.00598961440846324, 'loss_2': 0.0048828125, 'loss_3': -16.303447723388672, 'loss_4': 0.570507824420929, 'epoch': 28.53}
{'loss': 0.0084, 'grad_norm': 5.06452751159668, 'learning_rate': 1.4825581395348836e-06, 'loss_1': 0.0020404790993779898, 'loss_2': 0.00640869140625, 'loss_3': -16.47760772705078, 'loss_4': 0.6023762226104736, 'epoch': 28.54}
{'loss': 0.0056, 'grad_norm': 4.442333221435547, 'learning_rate': 1.4767441860465118e-06, 'loss_1': 0.0034053483977913857, 'loss_2': 0.0021915435791015625, 'loss_3': -16.387571334838867, 'loss_4': 0.5341569781303406, 'epoch': 28.55}
[INFO|trainer.py:4228] 2025-01-21 14:21:18,826 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:18,826 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌          | 4915/5160 [2:01:23<04:18,  1.05s/it][INFO|trainer.py:4226] 2025-01-21 14:21:26,391 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008603371679782867, 'eval_runtime': 4.0131, 'eval_samples_per_second': 255.166, 'eval_steps_per_second': 3.987, 'eval_loss_1': 0.00558439688757062, 'eval_loss_2': 0.003018975257873535, 'eval_loss_3': -18.13252830505371, 'eval_loss_4': 0.38272613286972046, 'epoch': 28.55}
{'loss': 0.0094, 'grad_norm': 4.654062271118164, 'learning_rate': 1.4709302325581396e-06, 'loss_1': 0.003596866736188531, 'loss_2': 0.0057830810546875, 'loss_3': -16.22372817993164, 'loss_4': 0.4860798716545105, 'epoch': 28.55}
{'loss': 0.0032, 'grad_norm': 5.1318793296813965, 'learning_rate': 1.4651162790697674e-06, 'loss_1': 0.0022638312075287104, 'loss_2': 0.0009632110595703125, 'loss_3': -16.3898983001709, 'loss_4': 0.7192152738571167, 'epoch': 28.56}
{'loss': 0.0073, 'grad_norm': 4.776601314544678, 'learning_rate': 1.4593023255813954e-06, 'loss_1': 0.0032417853362858295, 'loss_2': 0.004032135009765625, 'loss_3': -16.14336585998535, 'loss_4': 0.2213013619184494, 'epoch': 28.56}
{'loss': 0.0057, 'grad_norm': 4.690675258636475, 'learning_rate': 1.4534883720930234e-06, 'loss_1': 0.003056901041418314, 'loss_2': 0.002651214599609375, 'loss_3': -16.578861236572266, 'loss_4': 0.46096426248550415, 'epoch': 28.57}
{'loss': 0.0054, 'grad_norm': 4.949302673339844, 'learning_rate': 1.4476744186046512e-06, 'loss_1': 0.003601210191845894, 'loss_2': 0.00180816650390625, 'loss_3': -16.58510398864746, 'loss_4': 0.6978441476821899, 'epoch': 28.58}
[INFO|trainer.py:4228] 2025-01-21 14:21:26,391 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:26,391 >>   Batch size = 64
 95%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 4920/5160 [2:01:30<04:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:33,763 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008720941841602325, 'eval_runtime': 3.8146, 'eval_samples_per_second': 268.443, 'eval_steps_per_second': 4.194, 'eval_loss_1': 0.005721375811845064, 'eval_loss_2': 0.0029995664954185486, 'eval_loss_3': -18.13334846496582, 'eval_loss_4': 0.37388432025909424, 'epoch': 28.58}
{'loss': 0.0044, 'grad_norm': 4.347622871398926, 'learning_rate': 1.4418604651162792e-06, 'loss_1': 0.002292645862326026, 'loss_2': 0.00213623046875, 'loss_3': -16.47234344482422, 'loss_4': 0.481763631105423, 'epoch': 28.58}
{'loss': 0.0059, 'grad_norm': 5.147567272186279, 'learning_rate': 1.436046511627907e-06, 'loss_1': 0.003068451303988695, 'loss_2': 0.0028228759765625, 'loss_3': -16.263477325439453, 'loss_4': 0.3792003393173218, 'epoch': 28.59}
{'loss': 0.0121, 'grad_norm': 9.75722599029541, 'learning_rate': 1.430232558139535e-06, 'loss_1': 0.011068916879594326, 'loss_2': 0.001033782958984375, 'loss_3': -16.366029739379883, 'loss_4': 0.6900750398635864, 'epoch': 28.59}
{'loss': 0.0115, 'grad_norm': 6.713873863220215, 'learning_rate': 1.424418604651163e-06, 'loss_1': 0.007928578183054924, 'loss_2': 0.003589630126953125, 'loss_3': -16.36206817626953, 'loss_4': 0.36572977900505066, 'epoch': 28.6}
{'loss': 0.0053, 'grad_norm': 4.815530776977539, 'learning_rate': 1.4186046511627907e-06, 'loss_1': 0.0029214355163276196, 'loss_2': 0.002422332763671875, 'loss_3': -16.370891571044922, 'loss_4': 0.44548481702804565, 'epoch': 28.6}
[INFO|trainer.py:4228] 2025-01-21 14:21:33,763 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:33,763 >>   Batch size = 64
 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 4925/5160 [2:01:38<04:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:41,154 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008732233196496964, 'eval_runtime': 3.8218, 'eval_samples_per_second': 267.936, 'eval_steps_per_second': 4.187, 'eval_loss_1': 0.005916764494031668, 'eval_loss_2': 0.0028154700994491577, 'eval_loss_3': -18.13384437561035, 'eval_loss_4': 0.36130812764167786, 'epoch': 28.6}
{'loss': 0.0052, 'grad_norm': 4.755535125732422, 'learning_rate': 1.4127906976744185e-06, 'loss_1': 0.0018335124477744102, 'loss_2': 0.003387451171875, 'loss_3': -16.524803161621094, 'loss_4': 0.37954553961753845, 'epoch': 28.61}
{'loss': 0.0038, 'grad_norm': 4.594930648803711, 'learning_rate': 1.4069767441860467e-06, 'loss_1': 0.002162064891308546, 'loss_2': 0.0016574859619140625, 'loss_3': -16.434932708740234, 'loss_4': 0.29004693031311035, 'epoch': 28.62}
{'loss': 0.0088, 'grad_norm': 6.746576309204102, 'learning_rate': 1.4011627906976745e-06, 'loss_1': 0.00868876650929451, 'loss_2': 0.00016033649444580078, 'loss_3': -16.26688003540039, 'loss_4': 0.2474653273820877, 'epoch': 28.62}
{'loss': 0.0109, 'grad_norm': 10.77825927734375, 'learning_rate': 1.3953488372093023e-06, 'loss_1': 0.008203945122659206, 'loss_2': 0.002735137939453125, 'loss_3': -16.298954010009766, 'loss_4': 0.30911391973495483, 'epoch': 28.63}
{'loss': 0.0049, 'grad_norm': 5.242057800292969, 'learning_rate': 1.3895348837209303e-06, 'loss_1': 0.0028728507459163666, 'loss_2': 0.002044677734375, 'loss_3': -16.47730827331543, 'loss_4': 0.2512374520301819, 'epoch': 28.63}
[INFO|trainer.py:4228] 2025-01-21 14:21:41,155 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:41,155 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏         | 4930/5160 [2:01:45<03:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:48,525 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008869956247508526, 'eval_runtime': 3.8055, 'eval_samples_per_second': 269.087, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005997182801365852, 'eval_loss_2': 0.002872772514820099, 'eval_loss_3': -18.13707733154297, 'eval_loss_4': 0.36543649435043335, 'epoch': 28.63}
{'loss': 0.0084, 'grad_norm': 4.409476280212402, 'learning_rate': 1.3837209302325583e-06, 'loss_1': 0.0028622732497751713, 'loss_2': 0.005558013916015625, 'loss_3': -16.399486541748047, 'loss_4': -0.055624935775995255, 'epoch': 28.64}
{'loss': 0.0075, 'grad_norm': 4.436265468597412, 'learning_rate': 1.377906976744186e-06, 'loss_1': 0.0040886541828513145, 'loss_2': 0.0033626556396484375, 'loss_3': -16.44004249572754, 'loss_4': 0.37508904933929443, 'epoch': 28.65}
{'loss': 0.0051, 'grad_norm': 4.634064197540283, 'learning_rate': 1.372093023255814e-06, 'loss_1': 0.0019156847847625613, 'loss_2': 0.003223419189453125, 'loss_3': -16.29355239868164, 'loss_4': 0.31361091136932373, 'epoch': 28.65}
{'loss': 0.0177, 'grad_norm': 7.322776794433594, 'learning_rate': 1.3662790697674419e-06, 'loss_1': 0.00860630627721548, 'loss_2': 0.00913238525390625, 'loss_3': -16.404102325439453, 'loss_4': 0.5513991117477417, 'epoch': 28.66}
{'loss': 0.006, 'grad_norm': 4.922937870025635, 'learning_rate': 1.3604651162790699e-06, 'loss_1': 0.003546641208231449, 'loss_2': 0.002437591552734375, 'loss_3': -16.638154983520508, 'loss_4': 0.5721220970153809, 'epoch': 28.66}
[INFO|trainer.py:4228] 2025-01-21 14:21:48,525 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:48,525 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍         | 4935/5160 [2:01:53<03:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:21:55,899 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008695021271705627, 'eval_runtime': 3.8069, 'eval_samples_per_second': 268.987, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005929816979914904, 'eval_loss_2': 0.002765204757452011, 'eval_loss_3': -18.134998321533203, 'eval_loss_4': 0.37963178753852844, 'epoch': 28.66}
{'loss': 0.005, 'grad_norm': 4.728079795837402, 'learning_rate': 1.3546511627906976e-06, 'loss_1': 0.001660341047681868, 'loss_2': 0.003322601318359375, 'loss_3': -16.371089935302734, 'loss_4': 0.3574734926223755, 'epoch': 28.67}
{'loss': 0.004, 'grad_norm': 4.254255294799805, 'learning_rate': 1.3488372093023256e-06, 'loss_1': 0.0020899877417832613, 'loss_2': 0.0018835067749023438, 'loss_3': -16.553007125854492, 'loss_4': 0.7188431024551392, 'epoch': 28.67}
{'loss': 0.0071, 'grad_norm': 5.847951412200928, 'learning_rate': 1.3430232558139534e-06, 'loss_1': 0.006914733909070492, 'loss_2': 0.0001373291015625, 'loss_3': -16.412498474121094, 'loss_4': 0.7931355237960815, 'epoch': 28.68}
{'loss': 0.0066, 'grad_norm': 4.658157825469971, 'learning_rate': 1.3372093023255814e-06, 'loss_1': 0.003623350989073515, 'loss_2': 0.0029449462890625, 'loss_3': -16.300569534301758, 'loss_4': 0.5680246353149414, 'epoch': 28.69}
{'loss': 0.0082, 'grad_norm': 4.651407241821289, 'learning_rate': 1.3313953488372094e-06, 'loss_1': 0.0037979825865477324, 'loss_2': 0.00440216064453125, 'loss_3': -16.41461181640625, 'loss_4': -0.02340635657310486, 'epoch': 28.69}
[INFO|trainer.py:4228] 2025-01-21 14:21:55,899 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:21:55,900 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋         | 4940/5160 [2:02:00<03:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:03,275 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008724468760192394, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.797, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005855681374669075, 'eval_loss_2': 0.0028687864542007446, 'eval_loss_3': -18.13163948059082, 'eval_loss_4': 0.3852342963218689, 'epoch': 28.69}
{'loss': 0.0051, 'grad_norm': 4.674377918243408, 'learning_rate': 1.3255813953488372e-06, 'loss_1': 0.003714590100571513, 'loss_2': 0.001384735107421875, 'loss_3': -16.185016632080078, 'loss_4': 0.4035833775997162, 'epoch': 28.7}
{'loss': 0.0113, 'grad_norm': 4.581413269042969, 'learning_rate': 1.319767441860465e-06, 'loss_1': 0.003452751785516739, 'loss_2': 0.00787353515625, 'loss_3': -16.54201316833496, 'loss_4': 0.30504950881004333, 'epoch': 28.7}
{'loss': 0.0055, 'grad_norm': 5.034786701202393, 'learning_rate': 1.3139534883720932e-06, 'loss_1': 0.003910149913281202, 'loss_2': 0.0015478134155273438, 'loss_3': -16.27041244506836, 'loss_4': 0.327187180519104, 'epoch': 28.71}
{'loss': 0.0066, 'grad_norm': 4.286050319671631, 'learning_rate': 1.308139534883721e-06, 'loss_1': 0.0023688392248004675, 'loss_2': 0.0042724609375, 'loss_3': -16.476608276367188, 'loss_4': 0.22622673213481903, 'epoch': 28.72}
{'loss': 0.0035, 'grad_norm': 4.775824546813965, 'learning_rate': 1.3023255813953488e-06, 'loss_1': 0.002412117086350918, 'loss_2': 0.0010709762573242188, 'loss_3': -16.31388282775879, 'loss_4': 0.6072962284088135, 'epoch': 28.72}
[INFO|trainer.py:4228] 2025-01-21 14:22:03,275 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:03,275 >>   Batch size = 64
 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉         | 4945/5160 [2:02:07<03:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:10,647 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00860203243792057, 'eval_runtime': 3.8196, 'eval_samples_per_second': 268.087, 'eval_steps_per_second': 4.189, 'eval_loss_1': 0.0057122716680169106, 'eval_loss_2': 0.002889759838581085, 'eval_loss_3': -18.129695892333984, 'eval_loss_4': 0.4024518132209778, 'epoch': 28.72}
{'loss': 0.0051, 'grad_norm': 4.893848896026611, 'learning_rate': 1.2965116279069768e-06, 'loss_1': 0.003870143787935376, 'loss_2': 0.0012359619140625, 'loss_3': -16.47588539123535, 'loss_4': 0.3486439287662506, 'epoch': 28.73}
{'loss': 0.0055, 'grad_norm': 5.8420090675354, 'learning_rate': 1.2906976744186048e-06, 'loss_1': 0.005431219469755888, 'loss_2': 0.00010144710540771484, 'loss_3': -16.426746368408203, 'loss_4': 0.9298771023750305, 'epoch': 28.73}
{'loss': 0.008, 'grad_norm': 6.5581841468811035, 'learning_rate': 1.2848837209302325e-06, 'loss_1': 0.006540072150528431, 'loss_2': 0.00141143798828125, 'loss_3': -16.44141960144043, 'loss_4': 0.5014114379882812, 'epoch': 28.74}
{'loss': 0.0058, 'grad_norm': 4.675580024719238, 'learning_rate': 1.2790697674418605e-06, 'loss_1': 0.001956538762897253, 'loss_2': 0.00385284423828125, 'loss_3': -16.548728942871094, 'loss_4': 0.15923351049423218, 'epoch': 28.74}
{'loss': 0.0099, 'grad_norm': 4.861990451812744, 'learning_rate': 1.2732558139534883e-06, 'loss_1': 0.003984210547059774, 'loss_2': 0.005950927734375, 'loss_3': -16.14488983154297, 'loss_4': 0.4449019432067871, 'epoch': 28.75}
[INFO|trainer.py:4228] 2025-01-21 14:22:10,647 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:10,647 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████         | 4950/5160 [2:02:15<03:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:18,019 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008488004095852375, 'eval_runtime': 3.8186, 'eval_samples_per_second': 268.162, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.005738746840506792, 'eval_loss_2': 0.0027492567896842957, 'eval_loss_3': -18.129236221313477, 'eval_loss_4': 0.4132976531982422, 'epoch': 28.75}
{'loss': 0.0022, 'grad_norm': 4.858092308044434, 'learning_rate': 1.2674418604651163e-06, 'loss_1': 0.002083732280880213, 'loss_2': 0.00015687942504882812, 'loss_3': -16.54578971862793, 'loss_4': 0.44656258821487427, 'epoch': 28.76}
{'loss': 0.0037, 'grad_norm': 4.541916370391846, 'learning_rate': 1.2616279069767443e-06, 'loss_1': 0.0023539995308965445, 'loss_2': 0.001377105712890625, 'loss_3': -16.410951614379883, 'loss_4': 0.26162973046302795, 'epoch': 28.76}
{'loss': 0.0138, 'grad_norm': 5.786171913146973, 'learning_rate': 1.255813953488372e-06, 'loss_1': 0.008094574324786663, 'loss_2': 0.0057220458984375, 'loss_3': -16.21263885498047, 'loss_4': 0.07894306629896164, 'epoch': 28.77}
{'loss': 0.0064, 'grad_norm': 5.168395042419434, 'learning_rate': 1.2499999999999999e-06, 'loss_1': 0.004544023424386978, 'loss_2': 0.0018520355224609375, 'loss_3': -16.542701721191406, 'loss_4': 0.5619537830352783, 'epoch': 28.77}
{'loss': 0.0059, 'grad_norm': 5.125216007232666, 'learning_rate': 1.244186046511628e-06, 'loss_1': 0.0026194979436695576, 'loss_2': 0.0033206939697265625, 'loss_3': -16.304725646972656, 'loss_4': 0.6606427431106567, 'epoch': 28.78}
[INFO|trainer.py:4228] 2025-01-21 14:22:18,019 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:18,019 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎        | 4955/5160 [2:02:22<03:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:25,381 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008308183401823044, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.87, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.00569167360663414, 'eval_loss_2': 0.002616509795188904, 'eval_loss_3': -18.129669189453125, 'eval_loss_4': 0.4104836583137512, 'epoch': 28.78}
{'loss': 0.0067, 'grad_norm': 5.02303409576416, 'learning_rate': 1.2383720930232559e-06, 'loss_1': 0.0022439458407461643, 'loss_2': 0.00449371337890625, 'loss_3': -16.32541275024414, 'loss_4': 0.7914327383041382, 'epoch': 28.78}
{'loss': 0.0082, 'grad_norm': 5.275539398193359, 'learning_rate': 1.2325581395348837e-06, 'loss_1': 0.005611374508589506, 'loss_2': 0.0026092529296875, 'loss_3': -16.3922119140625, 'loss_4': 0.45649808645248413, 'epoch': 28.79}
{'loss': 0.0086, 'grad_norm': 4.943744659423828, 'learning_rate': 1.2267441860465117e-06, 'loss_1': 0.0030621911864727736, 'loss_2': 0.00551605224609375, 'loss_3': -16.416858673095703, 'loss_4': 0.4293896555900574, 'epoch': 28.8}
{'loss': 0.009, 'grad_norm': 5.121923923492432, 'learning_rate': 1.2209302325581397e-06, 'loss_1': 0.007997702807188034, 'loss_2': 0.0009784698486328125, 'loss_3': -16.33603286743164, 'loss_4': 0.7574977874755859, 'epoch': 28.8}
{'loss': 0.0074, 'grad_norm': 5.607884407043457, 'learning_rate': 1.2151162790697674e-06, 'loss_1': 0.006186585873365402, 'loss_2': 0.0012378692626953125, 'loss_3': -16.479337692260742, 'loss_4': 0.7357196807861328, 'epoch': 28.81}
[INFO|trainer.py:4228] 2025-01-21 14:22:25,381 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:25,381 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌        | 4960/5160 [2:02:29<03:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:32,754 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00835692323744297, 'eval_runtime': 3.8123, 'eval_samples_per_second': 268.601, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005692877806723118, 'eval_loss_2': 0.002664044499397278, 'eval_loss_3': -18.130428314208984, 'eval_loss_4': 0.41249096393585205, 'epoch': 28.81}
{'loss': 0.0139, 'grad_norm': 8.88134765625, 'learning_rate': 1.2093023255813954e-06, 'loss_1': 0.009934247471392155, 'loss_2': 0.00399017333984375, 'loss_3': -16.332199096679688, 'loss_4': 0.894464373588562, 'epoch': 28.81}
{'loss': 0.0092, 'grad_norm': 4.755284309387207, 'learning_rate': 1.2034883720930232e-06, 'loss_1': 0.0037064524367451668, 'loss_2': 0.0055084228515625, 'loss_3': -16.444990158081055, 'loss_4': 0.22784051299095154, 'epoch': 28.82}
{'loss': 0.0163, 'grad_norm': 12.616671562194824, 'learning_rate': 1.1976744186046512e-06, 'loss_1': 0.012180037796497345, 'loss_2': 0.004150390625, 'loss_3': -16.34008026123047, 'loss_4': 0.5497889518737793, 'epoch': 28.83}
{'loss': 0.0106, 'grad_norm': 4.647951126098633, 'learning_rate': 1.1918604651162792e-06, 'loss_1': 0.0027072199154645205, 'loss_2': 0.00791168212890625, 'loss_3': -16.502517700195312, 'loss_4': 0.6193897128105164, 'epoch': 28.83}
{'loss': 0.0062, 'grad_norm': 4.518515586853027, 'learning_rate': 1.186046511627907e-06, 'loss_1': 0.003300858661532402, 'loss_2': 0.002925872802734375, 'loss_3': -16.472415924072266, 'loss_4': 0.4182127118110657, 'epoch': 28.84}
[INFO|trainer.py:4228] 2025-01-21 14:22:32,754 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:32,754 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋        | 4965/5160 [2:02:37<03:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:40,121 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008143133483827114, 'eval_runtime': 3.8119, 'eval_samples_per_second': 268.633, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005346139892935753, 'eval_loss_2': 0.0027969926595687866, 'eval_loss_3': -18.134258270263672, 'eval_loss_4': 0.4168126583099365, 'epoch': 28.84}
{'loss': 0.004, 'grad_norm': 4.509616851806641, 'learning_rate': 1.1802325581395348e-06, 'loss_1': 0.0020500365644693375, 'loss_2': 0.0019588470458984375, 'loss_3': -16.3245906829834, 'loss_4': 0.38895347714424133, 'epoch': 28.84}
{'loss': 0.0108, 'grad_norm': 5.410045146942139, 'learning_rate': 1.174418604651163e-06, 'loss_1': 0.0057938979007303715, 'loss_2': 0.0049896240234375, 'loss_3': -16.450519561767578, 'loss_4': 0.3077238202095032, 'epoch': 28.85}
{'loss': 0.0052, 'grad_norm': 4.3108954429626465, 'learning_rate': 1.1686046511627908e-06, 'loss_1': 0.002081116894260049, 'loss_2': 0.0031585693359375, 'loss_3': -16.367319107055664, 'loss_4': 0.48537418246269226, 'epoch': 28.85}
{'loss': 0.0078, 'grad_norm': 4.56498384475708, 'learning_rate': 1.1627906976744186e-06, 'loss_1': 0.0026807626709342003, 'loss_2': 0.005168914794921875, 'loss_3': -16.506114959716797, 'loss_4': 0.5778669118881226, 'epoch': 28.86}
{'loss': 0.0114, 'grad_norm': 5.842911243438721, 'learning_rate': 1.1569767441860466e-06, 'loss_1': 0.0062674772925674915, 'loss_2': 0.00510406494140625, 'loss_3': -16.423126220703125, 'loss_4': -0.04164205119013786, 'epoch': 28.87}
[INFO|trainer.py:4228] 2025-01-21 14:22:40,121 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:40,121 >>   Batch size = 64
 96%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉        | 4970/5160 [2:02:44<03:17,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:47,488 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.008057012222707272, 'eval_runtime': 3.8116, 'eval_samples_per_second': 268.656, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005173748824745417, 'eval_loss_2': 0.0028832629323005676, 'eval_loss_3': -18.137361526489258, 'eval_loss_4': 0.4262840747833252, 'epoch': 28.87}
{'loss': 0.0066, 'grad_norm': 5.021710395812988, 'learning_rate': 1.1511627906976746e-06, 'loss_1': 0.002058807061985135, 'loss_2': 0.004558563232421875, 'loss_3': -16.32365608215332, 'loss_4': 0.43622899055480957, 'epoch': 28.87}
{'loss': 0.0085, 'grad_norm': 4.398836612701416, 'learning_rate': 1.1453488372093024e-06, 'loss_1': 0.0026313550770282745, 'loss_2': 0.005855560302734375, 'loss_3': -16.51770782470703, 'loss_4': 0.5506571531295776, 'epoch': 28.88}
{'loss': 0.003, 'grad_norm': 4.690586090087891, 'learning_rate': 1.1395348837209301e-06, 'loss_1': 0.0013363135512918234, 'loss_2': 0.0016641616821289062, 'loss_3': -16.454269409179688, 'loss_4': 0.5746766328811646, 'epoch': 28.88}
{'loss': 0.0063, 'grad_norm': 4.831420421600342, 'learning_rate': 1.1337209302325581e-06, 'loss_1': 0.006306609138846397, 'loss_2': 1.2755393981933594e-05, 'loss_3': -16.390100479125977, 'loss_4': 0.3805665373802185, 'epoch': 28.89}
{'loss': 0.0142, 'grad_norm': 6.285532474517822, 'learning_rate': 1.1279069767441861e-06, 'loss_1': 0.00886526983231306, 'loss_2': 0.00536346435546875, 'loss_3': -16.39820671081543, 'loss_4': 0.36709922552108765, 'epoch': 28.9}
[INFO|trainer.py:4228] 2025-01-21 14:22:47,488 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:47,488 >>   Batch size = 64
 96%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏       | 4975/5160 [2:02:52<03:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:22:54,867 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00805632397532463, 'eval_runtime': 3.8243, 'eval_samples_per_second': 267.76, 'eval_steps_per_second': 4.184, 'eval_loss_1': 0.005133506376296282, 'eval_loss_2': 0.0029228180646896362, 'eval_loss_3': -18.13979721069336, 'eval_loss_4': 0.43918925523757935, 'epoch': 28.9}
{'loss': 0.0055, 'grad_norm': 4.691983222961426, 'learning_rate': 1.122093023255814e-06, 'loss_1': 0.002333366312086582, 'loss_2': 0.0031337738037109375, 'loss_3': -16.38896942138672, 'loss_4': 0.43581637740135193, 'epoch': 28.9}
{'loss': 0.007, 'grad_norm': 4.4884819984436035, 'learning_rate': 1.116279069767442e-06, 'loss_1': 0.003077948931604624, 'loss_2': 0.0039043426513671875, 'loss_3': -16.5729923248291, 'loss_4': 0.6761206388473511, 'epoch': 28.91}
{'loss': 0.0095, 'grad_norm': 4.125330448150635, 'learning_rate': 1.1104651162790697e-06, 'loss_1': 0.003490857081487775, 'loss_2': 0.00600433349609375, 'loss_3': -16.271236419677734, 'loss_4': 0.5969471335411072, 'epoch': 28.91}
{'loss': 0.005, 'grad_norm': 4.216375827789307, 'learning_rate': 1.1046511627906977e-06, 'loss_1': 0.0024908313062042, 'loss_2': 0.00250244140625, 'loss_3': -16.504730224609375, 'loss_4': 0.41839998960494995, 'epoch': 28.92}
{'loss': 0.0173, 'grad_norm': 6.25675106048584, 'learning_rate': 1.0988372093023257e-06, 'loss_1': 0.011057820171117783, 'loss_2': 0.006221771240234375, 'loss_3': -16.513591766357422, 'loss_4': 0.5717809200286865, 'epoch': 28.92}
[INFO|trainer.py:4228] 2025-01-21 14:22:54,868 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:22:54,868 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 4980/5160 [2:02:59<03:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:02,227 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007868705317378044, 'eval_runtime': 3.8108, 'eval_samples_per_second': 268.711, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.004953770432621241, 'eval_loss_2': 0.002914935350418091, 'eval_loss_3': -18.138492584228516, 'eval_loss_4': 0.43853873014450073, 'epoch': 28.92}
{'loss': 0.0079, 'grad_norm': 4.815362453460693, 'learning_rate': 1.0930232558139535e-06, 'loss_1': 0.003561201971024275, 'loss_2': 0.00438690185546875, 'loss_3': -16.198741912841797, 'loss_4': 0.42643967270851135, 'epoch': 28.93}
{'loss': 0.0105, 'grad_norm': 5.121228218078613, 'learning_rate': 1.0872093023255813e-06, 'loss_1': 0.004069284535944462, 'loss_2': 0.0064697265625, 'loss_3': -16.20706558227539, 'loss_4': 0.6452252268791199, 'epoch': 28.94}
{'loss': 0.0052, 'grad_norm': 5.227414131164551, 'learning_rate': 1.0813953488372095e-06, 'loss_1': 0.0031096460297703743, 'loss_2': 0.002117156982421875, 'loss_3': -16.394412994384766, 'loss_4': 0.4246981739997864, 'epoch': 28.94}
{'loss': 0.0069, 'grad_norm': 5.1596479415893555, 'learning_rate': 1.0755813953488373e-06, 'loss_1': 0.006306569557636976, 'loss_2': 0.0006160736083984375, 'loss_3': -16.358448028564453, 'loss_4': 0.8001272678375244, 'epoch': 28.95}
{'loss': 0.0078, 'grad_norm': 4.599959850311279, 'learning_rate': 1.069767441860465e-06, 'loss_1': 0.0047984374687075615, 'loss_2': 0.00304412841796875, 'loss_3': -16.377843856811523, 'loss_4': 0.7583974003791809, 'epoch': 28.95}
[INFO|trainer.py:4228] 2025-01-21 14:23:02,227 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:02,227 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 4985/5160 [2:03:06<03:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:09,589 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00780284870415926, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.793, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.004867230542004108, 'eval_loss_2': 0.0029356181621551514, 'eval_loss_3': -18.136341094970703, 'eval_loss_4': 0.44002997875213623, 'epoch': 28.95}
{'loss': 0.0128, 'grad_norm': 4.584113597869873, 'learning_rate': 1.063953488372093e-06, 'loss_1': 0.005028244573622942, 'loss_2': 0.00777435302734375, 'loss_3': -16.562171936035156, 'loss_4': 0.18824982643127441, 'epoch': 28.96}
{'loss': 0.0062, 'grad_norm': 4.3210673332214355, 'learning_rate': 1.058139534883721e-06, 'loss_1': 0.003842935897409916, 'loss_2': 0.002391815185546875, 'loss_3': -16.35932731628418, 'loss_4': 0.5407510995864868, 'epoch': 28.97}
{'loss': 0.0024, 'grad_norm': 4.928838729858398, 'learning_rate': 1.0523255813953488e-06, 'loss_1': 0.0020672690588980913, 'loss_2': 0.0003609657287597656, 'loss_3': -16.44017791748047, 'loss_4': 0.6918658018112183, 'epoch': 28.97}
{'loss': 0.0073, 'grad_norm': 4.693018436431885, 'learning_rate': 1.0465116279069768e-06, 'loss_1': 0.0022815284319221973, 'loss_2': 0.0050201416015625, 'loss_3': -16.539012908935547, 'loss_4': -0.13645049929618835, 'epoch': 28.98}
{'loss': 0.0071, 'grad_norm': 4.973942279815674, 'learning_rate': 1.0406976744186046e-06, 'loss_1': 0.0021424246951937675, 'loss_2': 0.00493621826171875, 'loss_3': -16.46273422241211, 'loss_4': 0.30669981241226196, 'epoch': 28.98}
[INFO|trainer.py:4228] 2025-01-21 14:23:09,589 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:09,590 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 4990/5160 [2:03:13<02:49,  1.00it/s][INFO|trainer.py:4226] 2025-01-21 14:23:16,635 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007780399173498154, 'eval_runtime': 3.8052, 'eval_samples_per_second': 269.104, 'eval_steps_per_second': 4.205, 'eval_loss_1': 0.004947271663695574, 'eval_loss_2': 0.002833127975463867, 'eval_loss_3': -18.134199142456055, 'eval_loss_4': 0.4449167251586914, 'epoch': 28.98}
{'loss': 0.0066, 'grad_norm': 4.585170269012451, 'learning_rate': 1.0348837209302326e-06, 'loss_1': 0.006318137515336275, 'loss_2': 0.0002627372741699219, 'loss_3': -16.37761688232422, 'loss_4': 0.11058689653873444, 'epoch': 28.99}
{'loss': 0.0099, 'grad_norm': 8.000758171081543, 'learning_rate': 1.0290697674418606e-06, 'loss_1': 0.007327668368816376, 'loss_2': 0.0025386810302734375, 'loss_3': -16.30992889404297, 'loss_4': 0.5074008107185364, 'epoch': 28.99}
{'loss': 0.0155, 'grad_norm': 6.123115062713623, 'learning_rate': 1.0232558139534884e-06, 'loss_1': 0.0028978954069316387, 'loss_2': 0.01259613037109375, 'loss_3': -16.322769165039062, 'loss_4': 1.1519641876220703, 'epoch': 29.0}
{'loss': 0.0033, 'grad_norm': 5.33549165725708, 'learning_rate': 1.0174418604651162e-06, 'loss_1': 0.0024971815291792154, 'loss_2': 0.0008358955383300781, 'loss_3': -16.330087661743164, 'loss_4': 0.7542250752449036, 'epoch': 29.01}
{'loss': 0.007, 'grad_norm': 5.951356410980225, 'learning_rate': 1.0116279069767444e-06, 'loss_1': 0.00640391930937767, 'loss_2': 0.0005950927734375, 'loss_3': -16.622495651245117, 'loss_4': 0.10033159703016281, 'epoch': 29.01}
[INFO|trainer.py:4228] 2025-01-21 14:23:16,635 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:16,635 >>   Batch size = 64
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉       | 4995/5160 [2:03:21<02:50,  1.03s/it][INFO|trainer.py:4226] 2025-01-21 14:23:24,004 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0077079590409994125, 'eval_runtime': 3.8155, 'eval_samples_per_second': 268.38, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005017367657274008, 'eval_loss_2': 0.0026905909180641174, 'eval_loss_3': -18.132434844970703, 'eval_loss_4': 0.4453256130218506, 'epoch': 29.01}
{'loss': 0.0063, 'grad_norm': 4.732450008392334, 'learning_rate': 1.0058139534883722e-06, 'loss_1': 0.0026511370670050383, 'loss_2': 0.00362396240234375, 'loss_3': -16.565086364746094, 'loss_4': 0.747372567653656, 'epoch': 29.02}
{'loss': 0.0116, 'grad_norm': 5.0702290534973145, 'learning_rate': 1e-06, 'loss_1': 0.0037981905043125153, 'loss_2': 0.0077667236328125, 'loss_3': -16.487728118896484, 'loss_4': 0.37096449732780457, 'epoch': 29.02}
{'loss': 0.0092, 'grad_norm': 4.967408180236816, 'learning_rate': 9.94186046511628e-07, 'loss_1': 0.003400542074814439, 'loss_2': 0.0057830810546875, 'loss_3': -16.40251922607422, 'loss_4': 0.5845197439193726, 'epoch': 29.03}
{'loss': 0.0034, 'grad_norm': 4.337294578552246, 'learning_rate': 9.88372093023256e-07, 'loss_1': 0.00336561631411314, 'loss_2': 4.5359134674072266e-05, 'loss_3': -16.45029640197754, 'loss_4': 0.5134837627410889, 'epoch': 29.03}
{'loss': 0.0081, 'grad_norm': 4.893393039703369, 'learning_rate': 9.825581395348837e-07, 'loss_1': 0.0023753417190164328, 'loss_2': 0.00574493408203125, 'loss_3': -16.395214080810547, 'loss_4': 0.3754573464393616, 'epoch': 29.04}
[INFO|trainer.py:4228] 2025-01-21 14:23:24,005 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:24,005 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏      | 5000/5160 [2:03:28<02:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:31,409 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007611635606735945, 'eval_runtime': 3.8502, 'eval_samples_per_second': 265.958, 'eval_steps_per_second': 4.156, 'eval_loss_1': 0.004951688461005688, 'eval_loss_2': 0.0026599466800689697, 'eval_loss_3': -18.13410186767578, 'eval_loss_4': 0.43986403942108154, 'epoch': 29.04}
{'loss': 0.0071, 'grad_norm': 5.9690260887146, 'learning_rate': 9.767441860465117e-07, 'loss_1': 0.00560010178014636, 'loss_2': 0.0014514923095703125, 'loss_3': -16.530620574951172, 'loss_4': 0.1752999871969223, 'epoch': 29.05}
{'loss': 0.0082, 'grad_norm': 5.167480945587158, 'learning_rate': 9.709302325581395e-07, 'loss_1': 0.002582334913313389, 'loss_2': 0.005584716796875, 'loss_3': -16.40823745727539, 'loss_4': 0.49710264801979065, 'epoch': 29.05}
{'loss': 0.0058, 'grad_norm': 4.957240581512451, 'learning_rate': 9.651162790697675e-07, 'loss_1': 0.0032421378418803215, 'loss_2': 0.002529144287109375, 'loss_3': -16.50917625427246, 'loss_4': 0.8435906171798706, 'epoch': 29.06}
{'loss': 0.0076, 'grad_norm': 4.526012897491455, 'learning_rate': 9.593023255813955e-07, 'loss_1': 0.003221054095774889, 'loss_2': 0.004405975341796875, 'loss_3': -16.222084045410156, 'loss_4': 0.15038463473320007, 'epoch': 29.06}
{'loss': 0.0043, 'grad_norm': 4.42862606048584, 'learning_rate': 9.534883720930233e-07, 'loss_1': 0.0019552186131477356, 'loss_2': 0.0023517608642578125, 'loss_3': -16.34090232849121, 'loss_4': 0.775754451751709, 'epoch': 29.07}
[INFO|trainer.py:4228] 2025-01-21 14:23:31,410 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:31,410 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍      | 5005/5160 [2:03:35<02:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:38,769 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0078109754249453545, 'eval_runtime': 3.8082, 'eval_samples_per_second': 268.891, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005048310849815607, 'eval_loss_2': 0.00276266410946846, 'eval_loss_3': -18.133548736572266, 'eval_loss_4': 0.4397014379501343, 'epoch': 29.07}
{'loss': 0.0053, 'grad_norm': 5.333924293518066, 'learning_rate': 9.476744186046511e-07, 'loss_1': 0.0043685236014425755, 'loss_2': 0.0009069442749023438, 'loss_3': -16.43681526184082, 'loss_4': 0.15965023636817932, 'epoch': 29.08}
{'loss': 0.0051, 'grad_norm': 4.501362323760986, 'learning_rate': 9.418604651162792e-07, 'loss_1': 0.0017503598937764764, 'loss_2': 0.00339508056640625, 'loss_3': -16.478097915649414, 'loss_4': 0.39124101400375366, 'epoch': 29.08}
{'loss': 0.0034, 'grad_norm': 5.205763816833496, 'learning_rate': 9.360465116279071e-07, 'loss_1': 0.003248567460104823, 'loss_2': 0.0001239776611328125, 'loss_3': -16.13225746154785, 'loss_4': 0.5666155815124512, 'epoch': 29.09}
{'loss': 0.0584, 'grad_norm': 16.666704177856445, 'learning_rate': 9.302325581395349e-07, 'loss_1': 0.056227874010801315, 'loss_2': 0.00213623046875, 'loss_3': -16.351449966430664, 'loss_4': 1.2050776481628418, 'epoch': 29.09}
{'loss': 0.0055, 'grad_norm': 4.558032989501953, 'learning_rate': 9.244186046511629e-07, 'loss_1': 0.0022320107091218233, 'loss_2': 0.003261566162109375, 'loss_3': -16.446311950683594, 'loss_4': 0.8564053773880005, 'epoch': 29.1}
[INFO|trainer.py:4228] 2025-01-21 14:23:38,769 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:38,769 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋      | 5010/5160 [2:03:43<02:35,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:46,129 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007887057960033417, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.014, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005049724131822586, 'eval_loss_2': 0.0028373338282108307, 'eval_loss_3': -18.135221481323242, 'eval_loss_4': 0.44744807481765747, 'epoch': 29.1}
{'loss': 0.0122, 'grad_norm': 4.673181056976318, 'learning_rate': 9.186046511627907e-07, 'loss_1': 0.0031618725042790174, 'loss_2': 0.0090179443359375, 'loss_3': -16.367338180541992, 'loss_4': -0.20824864506721497, 'epoch': 29.1}
{'loss': 0.0032, 'grad_norm': 4.7066779136657715, 'learning_rate': 9.127906976744186e-07, 'loss_1': 0.001767231384292245, 'loss_2': 0.00144195556640625, 'loss_3': -16.529647827148438, 'loss_4': 0.4854070544242859, 'epoch': 29.11}
{'loss': 0.0071, 'grad_norm': 4.5995073318481445, 'learning_rate': 9.069767441860465e-07, 'loss_1': 0.004094135016202927, 'loss_2': 0.002979278564453125, 'loss_3': -16.609174728393555, 'loss_4': 0.6330031156539917, 'epoch': 29.12}
{'loss': 0.0065, 'grad_norm': 4.5932464599609375, 'learning_rate': 9.011627906976745e-07, 'loss_1': 0.0027602044865489006, 'loss_2': 0.003726959228515625, 'loss_3': -16.441204071044922, 'loss_4': 0.37341365218162537, 'epoch': 29.12}
{'loss': 0.0152, 'grad_norm': 5.792755603790283, 'learning_rate': 8.953488372093023e-07, 'loss_1': 0.012103410437703133, 'loss_2': 0.003070831298828125, 'loss_3': -16.280563354492188, 'loss_4': 0.3036462366580963, 'epoch': 29.13}
[INFO|trainer.py:4228] 2025-01-21 14:23:46,129 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:46,129 >>   Batch size = 64
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊      | 5015/5160 [2:03:50<02:30,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:23:53,484 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007806074805557728, 'eval_runtime': 3.8071, 'eval_samples_per_second': 268.973, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005020869895815849, 'eval_loss_2': 0.002785205841064453, 'eval_loss_3': -18.13884735107422, 'eval_loss_4': 0.4496915638446808, 'epoch': 29.13}
{'loss': 0.0116, 'grad_norm': 5.361306667327881, 'learning_rate': 8.895348837209303e-07, 'loss_1': 0.005780491046607494, 'loss_2': 0.005828857421875, 'loss_3': -16.200239181518555, 'loss_4': 0.7681165933609009, 'epoch': 29.13}
{'loss': 0.0067, 'grad_norm': 5.110061168670654, 'learning_rate': 8.837209302325581e-07, 'loss_1': 0.003854225156828761, 'loss_2': 0.0028228759765625, 'loss_3': -16.431663513183594, 'loss_4': 0.10179846733808517, 'epoch': 29.14}
{'loss': 0.0066, 'grad_norm': 4.90936279296875, 'learning_rate': 8.779069767441861e-07, 'loss_1': 0.003115840023383498, 'loss_2': 0.003513336181640625, 'loss_3': -16.266834259033203, 'loss_4': 0.720555305480957, 'epoch': 29.15}
{'loss': 0.0036, 'grad_norm': 5.153735160827637, 'learning_rate': 8.72093023255814e-07, 'loss_1': 0.0018347601871937513, 'loss_2': 0.0017576217651367188, 'loss_3': -16.407634735107422, 'loss_4': 0.5502153635025024, 'epoch': 29.15}
{'loss': 0.004, 'grad_norm': 4.91663932800293, 'learning_rate': 8.662790697674419e-07, 'loss_1': 0.0015884831082075834, 'loss_2': 0.002422332763671875, 'loss_3': -16.3491153717041, 'loss_4': 0.5753045082092285, 'epoch': 29.16}
[INFO|trainer.py:4228] 2025-01-21 14:23:53,484 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:23:53,484 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████      | 5020/5160 [2:03:57<02:25,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:00,846 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007695104461163282, 'eval_runtime': 3.8099, 'eval_samples_per_second': 268.776, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005003682803362608, 'eval_loss_2': 0.0026914216578006744, 'eval_loss_3': -18.13934326171875, 'eval_loss_4': 0.4460129141807556, 'epoch': 29.16}
{'loss': 0.0061, 'grad_norm': 6.964033126831055, 'learning_rate': 8.604651162790698e-07, 'loss_1': 0.005372840445488691, 'loss_2': 0.0007510185241699219, 'loss_3': -16.259525299072266, 'loss_4': 0.5728023052215576, 'epoch': 29.16}
{'loss': 0.0063, 'grad_norm': 5.120664596557617, 'learning_rate': 8.546511627906978e-07, 'loss_1': 0.0030044501181691885, 'loss_2': 0.0033111572265625, 'loss_3': -16.509902954101562, 'loss_4': 0.09886139631271362, 'epoch': 29.17}
{'loss': 0.0035, 'grad_norm': 4.694564342498779, 'learning_rate': 8.488372093023256e-07, 'loss_1': 0.0023573371581733227, 'loss_2': 0.00110626220703125, 'loss_3': -16.55111312866211, 'loss_4': 0.41187143325805664, 'epoch': 29.17}
{'loss': 0.0041, 'grad_norm': 4.6184163093566895, 'learning_rate': 8.430232558139535e-07, 'loss_1': 0.003861526492983103, 'loss_2': 0.0001990795135498047, 'loss_3': -16.39312744140625, 'loss_4': 0.23850004374980927, 'epoch': 29.18}
{'loss': 0.0074, 'grad_norm': 5.111306190490723, 'learning_rate': 8.372093023255814e-07, 'loss_1': 0.005868077743798494, 'loss_2': 0.00148773193359375, 'loss_3': -16.187631607055664, 'loss_4': 0.5512818098068237, 'epoch': 29.19}
[INFO|trainer.py:4228] 2025-01-21 14:24:00,846 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:00,846 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎     | 5025/5160 [2:04:05<02:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:08,217 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00778556102886796, 'eval_runtime': 3.8166, 'eval_samples_per_second': 268.304, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005105006042867899, 'eval_loss_2': 0.002680554986000061, 'eval_loss_3': -18.13835906982422, 'eval_loss_4': 0.44440197944641113, 'epoch': 29.19}
{'loss': 0.0071, 'grad_norm': 7.014951705932617, 'learning_rate': 8.313953488372093e-07, 'loss_1': 0.006936871446669102, 'loss_2': 0.0001862049102783203, 'loss_3': -16.514835357666016, 'loss_4': 0.5067415833473206, 'epoch': 29.19}
{'loss': 0.0055, 'grad_norm': 4.37800407409668, 'learning_rate': 8.255813953488372e-07, 'loss_1': 0.001823839615099132, 'loss_2': 0.00372314453125, 'loss_3': -16.459522247314453, 'loss_4': 0.349395751953125, 'epoch': 29.2}
{'loss': 0.0091, 'grad_norm': 5.7319655418396, 'learning_rate': 8.197674418604652e-07, 'loss_1': 0.006297644693404436, 'loss_2': 0.002841949462890625, 'loss_3': -16.451995849609375, 'loss_4': 0.5037695169448853, 'epoch': 29.2}
{'loss': 0.0107, 'grad_norm': 4.597047805786133, 'learning_rate': 8.13953488372093e-07, 'loss_1': 0.0049705482088029385, 'loss_2': 0.005702972412109375, 'loss_3': -16.460983276367188, 'loss_4': 0.37485265731811523, 'epoch': 29.21}
{'loss': 0.0043, 'grad_norm': 4.861853122711182, 'learning_rate': 8.08139534883721e-07, 'loss_1': 0.0032353615388274193, 'loss_2': 0.0010986328125, 'loss_3': -16.44710922241211, 'loss_4': 0.6464036703109741, 'epoch': 29.22}
[INFO|trainer.py:4228] 2025-01-21 14:24:08,218 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:08,218 >>   Batch size = 64
 97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 5030/5160 [2:04:12<02:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:15,582 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007877717725932598, 'eval_runtime': 3.8121, 'eval_samples_per_second': 268.622, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005177858751267195, 'eval_loss_2': 0.0026998594403266907, 'eval_loss_3': -18.13485336303711, 'eval_loss_4': 0.43358805775642395, 'epoch': 29.22}
{'loss': 0.0035, 'grad_norm': 4.3702802658081055, 'learning_rate': 8.023255813953489e-07, 'loss_1': 0.0025736838579177856, 'loss_2': 0.00093841552734375, 'loss_3': -16.302610397338867, 'loss_4': 0.3375934362411499, 'epoch': 29.22}
{'loss': 0.0041, 'grad_norm': 4.837952136993408, 'learning_rate': 7.965116279069768e-07, 'loss_1': 0.0031517844181507826, 'loss_2': 0.0009198188781738281, 'loss_3': -16.238985061645508, 'loss_4': -0.38332849740982056, 'epoch': 29.23}
{'loss': 0.0068, 'grad_norm': 4.753965854644775, 'learning_rate': 7.906976744186047e-07, 'loss_1': 0.003452775301411748, 'loss_2': 0.0033512115478515625, 'loss_3': -16.50656509399414, 'loss_4': 0.21998314559459686, 'epoch': 29.23}
{'loss': 0.0043, 'grad_norm': 4.3686323165893555, 'learning_rate': 7.848837209302327e-07, 'loss_1': 0.0021554711274802685, 'loss_2': 0.0021514892578125, 'loss_3': -16.35684585571289, 'loss_4': 0.3869202435016632, 'epoch': 29.24}
{'loss': 0.0118, 'grad_norm': 6.957486152648926, 'learning_rate': 7.790697674418605e-07, 'loss_1': 0.007805272936820984, 'loss_2': 0.004016876220703125, 'loss_3': -16.17099952697754, 'loss_4': -0.0265360027551651, 'epoch': 29.24}
[INFO|trainer.py:4228] 2025-01-21 14:24:15,583 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:15,583 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋     | 5035/5160 [2:04:20<02:09,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:22,945 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007941204123198986, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.61, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005187767557799816, 'eval_loss_2': 0.00275343656539917, 'eval_loss_3': -18.13107681274414, 'eval_loss_4': 0.42349714040756226, 'epoch': 29.24}
{'loss': 0.006, 'grad_norm': 4.484724998474121, 'learning_rate': 7.732558139534885e-07, 'loss_1': 0.005594533868134022, 'loss_2': 0.0003790855407714844, 'loss_3': -16.341094970703125, 'loss_4': 0.1628846973180771, 'epoch': 29.25}
{'loss': 0.018, 'grad_norm': 12.55241870880127, 'learning_rate': 7.674418604651162e-07, 'loss_1': 0.016123320907354355, 'loss_2': 0.0018863677978515625, 'loss_3': -16.59065818786621, 'loss_4': 0.5600297451019287, 'epoch': 29.26}
{'loss': 0.0036, 'grad_norm': 5.463040351867676, 'learning_rate': 7.616279069767442e-07, 'loss_1': 0.0032241088338196278, 'loss_2': 0.00041222572326660156, 'loss_3': -16.323244094848633, 'loss_4': 0.4521936774253845, 'epoch': 29.26}
{'loss': 0.0093, 'grad_norm': 4.8083176612854, 'learning_rate': 7.558139534883721e-07, 'loss_1': 0.0052842567674815655, 'loss_2': 0.00405120849609375, 'loss_3': -16.093461990356445, 'loss_4': 0.008242323994636536, 'epoch': 29.27}
{'loss': 0.0087, 'grad_norm': 4.753223896026611, 'learning_rate': 7.5e-07, 'loss_1': 0.0027798230294138193, 'loss_2': 0.005954742431640625, 'loss_3': -16.40587615966797, 'loss_4': -0.2379188984632492, 'epoch': 29.27}
[INFO|trainer.py:4228] 2025-01-21 14:24:22,946 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:22,946 >>   Batch size = 64
 98%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉     | 5040/5160 [2:04:27<02:04,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:30,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007931914180517197, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.945, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005170970223844051, 'eval_loss_2': 0.0027609430253505707, 'eval_loss_3': -18.13165283203125, 'eval_loss_4': 0.4225901663303375, 'epoch': 29.27}
{'loss': 0.0256, 'grad_norm': 9.411149978637695, 'learning_rate': 7.441860465116279e-07, 'loss_1': 0.01884807087481022, 'loss_2': 0.006801605224609375, 'loss_3': -16.399250030517578, 'loss_4': 0.28335216641426086, 'epoch': 29.28}
{'loss': 0.01, 'grad_norm': 4.644333362579346, 'learning_rate': 7.383720930232559e-07, 'loss_1': 0.0031841089949011803, 'loss_2': 0.006824493408203125, 'loss_3': -16.35845375061035, 'loss_4': 0.27679961919784546, 'epoch': 29.28}
{'loss': 0.0118, 'grad_norm': 5.196956634521484, 'learning_rate': 7.325581395348837e-07, 'loss_1': 0.006174786482006311, 'loss_2': 0.00566864013671875, 'loss_3': -16.289291381835938, 'loss_4': 0.6029313802719116, 'epoch': 29.29}
{'loss': 0.0094, 'grad_norm': 4.545892715454102, 'learning_rate': 7.267441860465117e-07, 'loss_1': 0.0028189080767333508, 'loss_2': 0.00656890869140625, 'loss_3': -16.353479385375977, 'loss_4': 0.5654540061950684, 'epoch': 29.3}
{'loss': 0.0051, 'grad_norm': 4.476089000701904, 'learning_rate': 7.209302325581396e-07, 'loss_1': 0.001977682812139392, 'loss_2': 0.0031108856201171875, 'loss_3': -16.552936553955078, 'loss_4': 0.9906924366950989, 'epoch': 29.3}
[INFO|trainer.py:4228] 2025-01-21 14:24:30,307 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:30,307 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 5045/5160 [2:04:34<01:59,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:37,666 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0077368104830384254, 'eval_runtime': 3.8096, 'eval_samples_per_second': 268.794, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005103432573378086, 'eval_loss_2': 0.0026333779096603394, 'eval_loss_3': -18.129615783691406, 'eval_loss_4': 0.4141266942024231, 'epoch': 29.3}
{'loss': 0.0066, 'grad_norm': 4.589663505554199, 'learning_rate': 7.151162790697675e-07, 'loss_1': 0.0028663016855716705, 'loss_2': 0.003780364990234375, 'loss_3': -16.443586349487305, 'loss_4': 0.38628995418548584, 'epoch': 29.31}
{'loss': 0.0021, 'grad_norm': 4.717536449432373, 'learning_rate': 7.093023255813954e-07, 'loss_1': 0.0018004360608756542, 'loss_2': 0.0003070831298828125, 'loss_3': -16.450424194335938, 'loss_4': 0.4832145869731903, 'epoch': 29.31}
{'loss': 0.0075, 'grad_norm': 6.983376502990723, 'learning_rate': 7.034883720930234e-07, 'loss_1': 0.005864604841917753, 'loss_2': 0.001674652099609375, 'loss_3': -16.493488311767578, 'loss_4': 0.5673419833183289, 'epoch': 29.32}
{'loss': 0.0034, 'grad_norm': 4.904786586761475, 'learning_rate': 6.976744186046511e-07, 'loss_1': 0.001904178992845118, 'loss_2': 0.0014591217041015625, 'loss_3': -16.230682373046875, 'loss_4': 0.6850427389144897, 'epoch': 29.33}
{'loss': 0.0071, 'grad_norm': 5.345090866088867, 'learning_rate': 6.918604651162791e-07, 'loss_1': 0.005582659039646387, 'loss_2': 0.0015544891357421875, 'loss_3': -16.463008880615234, 'loss_4': -0.30840227007865906, 'epoch': 29.33}
[INFO|trainer.py:4228] 2025-01-21 14:24:37,666 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:37,666 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎    | 5050/5160 [2:04:42<01:54,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:45,035 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0075541092082858086, 'eval_runtime': 3.8122, 'eval_samples_per_second': 268.61, 'eval_steps_per_second': 4.197, 'eval_loss_1': 0.005050200037658215, 'eval_loss_2': 0.002503909170627594, 'eval_loss_3': -18.13033103942871, 'eval_loss_4': 0.4036722481250763, 'epoch': 29.33}
{'loss': 0.0201, 'grad_norm': 21.837247848510742, 'learning_rate': 6.86046511627907e-07, 'loss_1': 0.017947569489479065, 'loss_2': 0.0021114349365234375, 'loss_3': -16.29178237915039, 'loss_4': 0.030487865209579468, 'epoch': 29.34}
{'loss': 0.0079, 'grad_norm': 4.661892414093018, 'learning_rate': 6.802325581395349e-07, 'loss_1': 0.0026265697088092566, 'loss_2': 0.00527191162109375, 'loss_3': -16.292926788330078, 'loss_4': 0.35913193225860596, 'epoch': 29.34}
{'loss': 0.0099, 'grad_norm': 5.029936790466309, 'learning_rate': 6.744186046511628e-07, 'loss_1': 0.0048253778368234634, 'loss_2': 0.00506591796875, 'loss_3': -16.54003143310547, 'loss_4': 0.4154101014137268, 'epoch': 29.35}
{'loss': 0.0071, 'grad_norm': 4.938542366027832, 'learning_rate': 6.686046511627907e-07, 'loss_1': 0.005185381043702364, 'loss_2': 0.0019474029541015625, 'loss_3': -16.344423294067383, 'loss_4': 0.5016432404518127, 'epoch': 29.35}
{'loss': 0.0054, 'grad_norm': 4.854225158691406, 'learning_rate': 6.627906976744186e-07, 'loss_1': 0.004130083601921797, 'loss_2': 0.0012235641479492188, 'loss_3': -16.38444709777832, 'loss_4': 0.5436904430389404, 'epoch': 29.36}
[INFO|trainer.py:4228] 2025-01-21 14:24:45,035 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:45,035 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 5055/5160 [2:04:49<01:49,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:52,401 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00749929528683424, 'eval_runtime': 3.8128, 'eval_samples_per_second': 268.566, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005013364367187023, 'eval_loss_2': 0.002485930919647217, 'eval_loss_3': -18.13295555114746, 'eval_loss_4': 0.3992454409599304, 'epoch': 29.36}
{'loss': 0.0075, 'grad_norm': 4.904127597808838, 'learning_rate': 6.569767441860466e-07, 'loss_1': 0.004810255020856857, 'loss_2': 0.002712249755859375, 'loss_3': -16.26266098022461, 'loss_4': 0.41949543356895447, 'epoch': 29.37}
{'loss': 0.0106, 'grad_norm': 4.432219982147217, 'learning_rate': 6.511627906976744e-07, 'loss_1': 0.0022466760128736496, 'loss_2': 0.0083465576171875, 'loss_3': -16.25062370300293, 'loss_4': 0.8676435351371765, 'epoch': 29.37}
{'loss': 0.0094, 'grad_norm': 5.248450756072998, 'learning_rate': 6.453488372093024e-07, 'loss_1': 0.0037698394153267145, 'loss_2': 0.0056304931640625, 'loss_3': -16.498199462890625, 'loss_4': 0.6592271327972412, 'epoch': 29.38}
{'loss': 0.0089, 'grad_norm': 5.8942413330078125, 'learning_rate': 6.395348837209303e-07, 'loss_1': 0.005752483382821083, 'loss_2': 0.0030975341796875, 'loss_3': -16.448856353759766, 'loss_4': 0.46429282426834106, 'epoch': 29.38}
{'loss': 0.0096, 'grad_norm': 6.4120097160339355, 'learning_rate': 6.337209302325582e-07, 'loss_1': 0.005744463764131069, 'loss_2': 0.00386810302734375, 'loss_3': -16.366539001464844, 'loss_4': 0.7252594232559204, 'epoch': 29.39}
[INFO|trainer.py:4228] 2025-01-21 14:24:52,402 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:52,402 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊    | 5060/5160 [2:04:56<01:43,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:24:59,758 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.0075398641638457775, 'eval_runtime': 3.8057, 'eval_samples_per_second': 269.072, 'eval_steps_per_second': 4.204, 'eval_loss_1': 0.005044158548116684, 'eval_loss_2': 0.002495706081390381, 'eval_loss_3': -18.13133430480957, 'eval_loss_4': 0.3980482518672943, 'epoch': 29.39}
{'loss': 0.004, 'grad_norm': 4.387914180755615, 'learning_rate': 6.27906976744186e-07, 'loss_1': 0.0020741112530231476, 'loss_2': 0.0018968582153320312, 'loss_3': -16.306659698486328, 'loss_4': 0.4203994870185852, 'epoch': 29.4}
{'loss': 0.0054, 'grad_norm': 4.477464199066162, 'learning_rate': 6.22093023255814e-07, 'loss_1': 0.0036183453630656004, 'loss_2': 0.0017824172973632812, 'loss_3': -16.555805206298828, 'loss_4': 0.7489473223686218, 'epoch': 29.4}
{'loss': 0.0037, 'grad_norm': 4.747215747833252, 'learning_rate': 6.162790697674418e-07, 'loss_1': 0.0033494161907583475, 'loss_2': 0.00030803680419921875, 'loss_3': -16.460954666137695, 'loss_4': 0.7642486095428467, 'epoch': 29.41}
{'loss': 0.0069, 'grad_norm': 5.0886454582214355, 'learning_rate': 6.104651162790698e-07, 'loss_1': 0.005740014370530844, 'loss_2': 0.0011653900146484375, 'loss_3': -16.309123992919922, 'loss_4': 0.11813347041606903, 'epoch': 29.41}
{'loss': 0.0074, 'grad_norm': 4.991851806640625, 'learning_rate': 6.046511627906977e-07, 'loss_1': 0.0019437771989032626, 'loss_2': 0.005458831787109375, 'loss_3': -16.501787185668945, 'loss_4': 0.9839250445365906, 'epoch': 29.42}
[INFO|trainer.py:4228] 2025-01-21 14:24:59,759 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:24:59,759 >>   Batch size = 64
 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉    | 5065/5160 [2:05:04<01:38,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:07,122 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.00755386333912611, 'eval_runtime': 3.8114, 'eval_samples_per_second': 268.67, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.00506131537258625, 'eval_loss_2': 0.002492547035217285, 'eval_loss_3': -18.130455017089844, 'eval_loss_4': 0.3929564356803894, 'epoch': 29.42}
{'loss': 0.0072, 'grad_norm': 4.6659955978393555, 'learning_rate': 5.988372093023256e-07, 'loss_1': 0.002786940196529031, 'loss_2': 0.004390716552734375, 'loss_3': -16.566247940063477, 'loss_4': 0.5770738124847412, 'epoch': 29.42}
{'loss': 0.0474, 'grad_norm': 30.63819694519043, 'learning_rate': 5.930232558139535e-07, 'loss_1': 0.045867204666137695, 'loss_2': 0.0014934539794921875, 'loss_3': -16.304048538208008, 'loss_4': 0.6154643893241882, 'epoch': 29.43}
{'loss': 0.0063, 'grad_norm': 5.18384313583374, 'learning_rate': 5.872093023255815e-07, 'loss_1': 0.005254595074802637, 'loss_2': 0.0010824203491210938, 'loss_3': -16.508888244628906, 'loss_4': 0.5231570601463318, 'epoch': 29.44}
{'loss': 0.0074, 'grad_norm': 5.165321350097656, 'learning_rate': 5.813953488372093e-07, 'loss_1': 0.004194291308522224, 'loss_2': 0.003173828125, 'loss_3': -16.339214324951172, 'loss_4': 0.7134280800819397, 'epoch': 29.44}
{'loss': 0.0152, 'grad_norm': 4.804439067840576, 'learning_rate': 5.755813953488373e-07, 'loss_1': 0.003721782471984625, 'loss_2': 0.01143646240234375, 'loss_3': -16.512733459472656, 'loss_4': 0.16279295086860657, 'epoch': 29.45}
[INFO|trainer.py:4228] 2025-01-21 14:25:07,122 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:07,122 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 5070/5160 [2:05:11<01:33,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:14,508 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007549636997282505, 'eval_runtime': 3.8184, 'eval_samples_per_second': 268.178, 'eval_steps_per_second': 4.19, 'eval_loss_1': 0.005108126439154148, 'eval_loss_2': 0.002441510558128357, 'eval_loss_3': -18.128568649291992, 'eval_loss_4': 0.389143168926239, 'epoch': 29.45}
{'loss': 0.004, 'grad_norm': 4.607364177703857, 'learning_rate': 5.697674418604651e-07, 'loss_1': 0.0036661913618445396, 'loss_2': 0.0003483295440673828, 'loss_3': -16.386554718017578, 'loss_4': 0.33127012848854065, 'epoch': 29.45}
{'loss': 0.012, 'grad_norm': 5.968399524688721, 'learning_rate': 5.639534883720931e-07, 'loss_1': 0.0053974236361682415, 'loss_2': 0.006595611572265625, 'loss_3': -16.555723190307617, 'loss_4': 0.35844454169273376, 'epoch': 29.46}
{'loss': 0.0031, 'grad_norm': 4.493865966796875, 'learning_rate': 5.58139534883721e-07, 'loss_1': 0.002459913259372115, 'loss_2': 0.0006265640258789062, 'loss_3': -16.39853286743164, 'loss_4': 0.7437693476676941, 'epoch': 29.47}
{'loss': 0.0073, 'grad_norm': 5.001986980438232, 'learning_rate': 5.523255813953489e-07, 'loss_1': 0.0026606679894030094, 'loss_2': 0.0046234130859375, 'loss_3': -16.34697914123535, 'loss_4': 0.680187463760376, 'epoch': 29.47}
{'loss': 0.0068, 'grad_norm': 4.478989601135254, 'learning_rate': 5.465116279069767e-07, 'loss_1': 0.0029916998464614153, 'loss_2': 0.0037746429443359375, 'loss_3': -16.408348083496094, 'loss_4': 0.43689772486686707, 'epoch': 29.48}
[INFO|trainer.py:4228] 2025-01-21 14:25:14,508 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:14,508 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 5075/5160 [2:05:19<01:28,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:21,876 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007597913034260273, 'eval_runtime': 3.8072, 'eval_samples_per_second': 268.962, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005194966681301594, 'eval_loss_2': 0.002402946352958679, 'eval_loss_3': -18.127565383911133, 'eval_loss_4': 0.38637733459472656, 'epoch': 29.48}
{'loss': 0.0072, 'grad_norm': 5.038719177246094, 'learning_rate': 5.406976744186047e-07, 'loss_1': 0.004383126739412546, 'loss_2': 0.002780914306640625, 'loss_3': -16.335735321044922, 'loss_4': 0.4991835951805115, 'epoch': 29.48}
{'loss': 0.0163, 'grad_norm': 8.76914119720459, 'learning_rate': 5.348837209302325e-07, 'loss_1': 0.009859513491392136, 'loss_2': 0.006450653076171875, 'loss_3': -16.415090560913086, 'loss_4': 0.3401355743408203, 'epoch': 29.49}
{'loss': 0.0052, 'grad_norm': 4.674223899841309, 'learning_rate': 5.290697674418605e-07, 'loss_1': 0.0023934359196573496, 'loss_2': 0.002838134765625, 'loss_3': -16.364437103271484, 'loss_4': 0.2198587954044342, 'epoch': 29.49}
{'loss': 0.003, 'grad_norm': 4.908113479614258, 'learning_rate': 5.232558139534884e-07, 'loss_1': 0.0027508409693837166, 'loss_2': 0.0002799034118652344, 'loss_3': -16.302087783813477, 'loss_4': 0.5330185890197754, 'epoch': 29.5}
{'loss': 0.0072, 'grad_norm': 5.372586250305176, 'learning_rate': 5.174418604651163e-07, 'loss_1': 0.003573636757209897, 'loss_2': 0.003673553466796875, 'loss_3': -16.232501983642578, 'loss_4': 0.4862695336341858, 'epoch': 29.51}
[INFO|trainer.py:4228] 2025-01-21 14:25:21,877 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:21,877 >>   Batch size = 64
 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌   | 5080/5160 [2:05:26<01:23,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:29,249 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007728893309831619, 'eval_runtime': 3.8168, 'eval_samples_per_second': 268.284, 'eval_steps_per_second': 4.192, 'eval_loss_1': 0.005341074429452419, 'eval_loss_2': 0.0023878179490566254, 'eval_loss_3': -18.12479591369629, 'eval_loss_4': 0.38556069135665894, 'epoch': 29.51}
{'loss': 0.0076, 'grad_norm': 4.6483635902404785, 'learning_rate': 5.116279069767442e-07, 'loss_1': 0.003858111798763275, 'loss_2': 0.003719329833984375, 'loss_3': -16.344104766845703, 'loss_4': 0.6965295076370239, 'epoch': 29.51}
{'loss': 0.0033, 'grad_norm': 5.143781661987305, 'learning_rate': 5.058139534883722e-07, 'loss_1': 0.0019201197428628802, 'loss_2': 0.0013828277587890625, 'loss_3': -16.242717742919922, 'loss_4': -0.06662158668041229, 'epoch': 29.52}
{'loss': 0.0045, 'grad_norm': 5.268441677093506, 'learning_rate': 5e-07, 'loss_1': 0.003217508550733328, 'loss_2': 0.001255035400390625, 'loss_3': -16.508975982666016, 'loss_4': 0.16246061027050018, 'epoch': 29.52}
{'loss': 0.0084, 'grad_norm': 5.005345821380615, 'learning_rate': 4.94186046511628e-07, 'loss_1': 0.0017972053028643131, 'loss_2': 0.006587982177734375, 'loss_3': -16.386898040771484, 'loss_4': 0.3985424041748047, 'epoch': 29.53}
{'loss': 0.006, 'grad_norm': 5.128506660461426, 'learning_rate': 4.883720930232559e-07, 'loss_1': 0.004993277136236429, 'loss_2': 0.0009708404541015625, 'loss_3': -16.253042221069336, 'loss_4': 0.5003171563148499, 'epoch': 29.53}
[INFO|trainer.py:4228] 2025-01-21 14:25:29,250 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:29,250 >>   Batch size = 64
 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊   | 5085/5160 [2:05:33<01:18,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:36,611 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007796476129442453, 'eval_runtime': 3.8085, 'eval_samples_per_second': 268.875, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005378453526645899, 'eval_loss_2': 0.0024180226027965546, 'eval_loss_3': -18.124065399169922, 'eval_loss_4': 0.38853806257247925, 'epoch': 29.53}
{'loss': 0.0067, 'grad_norm': 5.476928234100342, 'learning_rate': 4.825581395348838e-07, 'loss_1': 0.004983510356396437, 'loss_2': 0.0017490386962890625, 'loss_3': -16.380035400390625, 'loss_4': 0.42661261558532715, 'epoch': 29.54}
{'loss': 0.0074, 'grad_norm': 5.546212673187256, 'learning_rate': 4.7674418604651165e-07, 'loss_1': 0.005210360046476126, 'loss_2': 0.0022335052490234375, 'loss_3': -16.401479721069336, 'loss_4': 0.26766037940979004, 'epoch': 29.55}
{'loss': 0.0062, 'grad_norm': 4.622370719909668, 'learning_rate': 4.709302325581396e-07, 'loss_1': 0.005085050594061613, 'loss_2': 0.001140594482421875, 'loss_3': -16.410743713378906, 'loss_4': 0.40338334441185, 'epoch': 29.55}
{'loss': 0.0104, 'grad_norm': 4.980266571044922, 'learning_rate': 4.6511627906976743e-07, 'loss_1': 0.0038889755960553885, 'loss_2': 0.006488800048828125, 'loss_3': -16.342731475830078, 'loss_4': 0.21130149066448212, 'epoch': 29.56}
{'loss': 0.0111, 'grad_norm': 4.637072563171387, 'learning_rate': 4.593023255813954e-07, 'loss_1': 0.002175522968173027, 'loss_2': 0.00890350341796875, 'loss_3': -16.29949951171875, 'loss_4': 0.2265186905860901, 'epoch': 29.56}
[INFO|trainer.py:4228] 2025-01-21 14:25:36,611 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:36,611 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████   | 5090/5160 [2:05:41<01:12,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:43,963 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007827294990420341, 'eval_runtime': 3.8066, 'eval_samples_per_second': 269.008, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005341066047549248, 'eval_loss_2': 0.0024862289428710938, 'eval_loss_3': -18.12327766418457, 'eval_loss_4': 0.3946205675601959, 'epoch': 29.56}
{'loss': 0.0031, 'grad_norm': 4.91243314743042, 'learning_rate': 4.5348837209302327e-07, 'loss_1': 0.0029369601979851723, 'loss_2': 0.0001285076141357422, 'loss_3': -16.502256393432617, 'loss_4': 0.5159765481948853, 'epoch': 29.57}
{'loss': 0.0063, 'grad_norm': 4.685417652130127, 'learning_rate': 4.4767441860465116e-07, 'loss_1': 0.002454195637255907, 'loss_2': 0.003887176513671875, 'loss_3': -16.317989349365234, 'loss_4': 0.40971639752388, 'epoch': 29.58}
{'loss': 0.0065, 'grad_norm': 5.111476421356201, 'learning_rate': 4.4186046511627905e-07, 'loss_1': 0.003632398322224617, 'loss_2': 0.002849578857421875, 'loss_3': -16.27205467224121, 'loss_4': 0.4688657224178314, 'epoch': 29.58}
{'loss': 0.0036, 'grad_norm': 4.911098003387451, 'learning_rate': 4.36046511627907e-07, 'loss_1': 0.003159963758662343, 'loss_2': 0.0004425048828125, 'loss_3': -16.45262908935547, 'loss_4': 0.737255334854126, 'epoch': 29.59}
{'loss': 0.0057, 'grad_norm': 4.764111042022705, 'learning_rate': 4.302325581395349e-07, 'loss_1': 0.001996422652155161, 'loss_2': 0.00370025634765625, 'loss_3': -16.29007339477539, 'loss_4': 0.23689459264278412, 'epoch': 29.59}
[INFO|trainer.py:4228] 2025-01-21 14:25:43,963 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:43,963 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 5095/5160 [2:05:48<01:07,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:51,329 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007787766400724649, 'eval_runtime': 3.8103, 'eval_samples_per_second': 268.742, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005324098281562328, 'eval_loss_2': 0.0024636685848236084, 'eval_loss_3': -18.124107360839844, 'eval_loss_4': 0.39802682399749756, 'epoch': 29.59}
{'loss': 0.0069, 'grad_norm': 4.9235358238220215, 'learning_rate': 4.244186046511628e-07, 'loss_1': 0.0028304934967309237, 'loss_2': 0.00405120849609375, 'loss_3': -16.51446533203125, 'loss_4': 0.16102953255176544, 'epoch': 29.6}
{'loss': 0.012, 'grad_norm': 4.900737762451172, 'learning_rate': 4.186046511627907e-07, 'loss_1': 0.006882850546389818, 'loss_2': 0.00510406494140625, 'loss_3': -16.39025115966797, 'loss_4': 0.6875966191291809, 'epoch': 29.6}
{'loss': 0.0029, 'grad_norm': 4.765839099884033, 'learning_rate': 4.127906976744186e-07, 'loss_1': 0.0024271062575280666, 'loss_2': 0.0004487037658691406, 'loss_3': -16.442663192749023, 'loss_4': 0.3149203658103943, 'epoch': 29.61}
{'loss': 0.0082, 'grad_norm': 4.883417129516602, 'learning_rate': 4.069767441860465e-07, 'loss_1': 0.0027991856914013624, 'loss_2': 0.005420684814453125, 'loss_3': -16.207149505615234, 'loss_4': 0.7919126152992249, 'epoch': 29.62}
{'loss': 0.0108, 'grad_norm': 7.387056350708008, 'learning_rate': 4.0116279069767445e-07, 'loss_1': 0.0060699861496686935, 'loss_2': 0.00470733642578125, 'loss_3': -16.272390365600586, 'loss_4': 0.46259570121765137, 'epoch': 29.62}
[INFO|trainer.py:4228] 2025-01-21 14:25:51,329 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:51,329 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 5100/5160 [2:05:55<01:02,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:25:58,680 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007787598296999931, 'eval_runtime': 3.81, 'eval_samples_per_second': 268.768, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005358808673918247, 'eval_loss_2': 0.0024287886917591095, 'eval_loss_3': -18.125110626220703, 'eval_loss_4': 0.397614985704422, 'epoch': 29.62}
{'loss': 0.0109, 'grad_norm': 4.7759690284729, 'learning_rate': 3.9534883720930234e-07, 'loss_1': 0.0030202369671314955, 'loss_2': 0.00789642333984375, 'loss_3': -16.396900177001953, 'loss_4': 0.44463464617729187, 'epoch': 29.63}
{'loss': 0.004, 'grad_norm': 4.885531425476074, 'learning_rate': 3.8953488372093023e-07, 'loss_1': 0.0034178360365331173, 'loss_2': 0.0005583763122558594, 'loss_3': -16.357418060302734, 'loss_4': 0.3007681965827942, 'epoch': 29.63}
{'loss': 0.0171, 'grad_norm': 10.784723281860352, 'learning_rate': 3.837209302325581e-07, 'loss_1': 0.012545868754386902, 'loss_2': 0.004589080810546875, 'loss_3': -16.102989196777344, 'loss_4': 0.31742507219314575, 'epoch': 29.64}
{'loss': 0.0043, 'grad_norm': 5.451962471008301, 'learning_rate': 3.7790697674418606e-07, 'loss_1': 0.004161831922829151, 'loss_2': 9.083747863769531e-05, 'loss_3': -16.25263214111328, 'loss_4': 0.5297601222991943, 'epoch': 29.65}
{'loss': 0.0062, 'grad_norm': 4.599061965942383, 'learning_rate': 3.7209302325581396e-07, 'loss_1': 0.003972143866121769, 'loss_2': 0.002193450927734375, 'loss_3': -16.39190673828125, 'loss_4': 0.675346851348877, 'epoch': 29.65}
[INFO|trainer.py:4228] 2025-01-21 14:25:58,681 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:25:58,681 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋  | 5105/5160 [2:06:03<00:57,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:06,052 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007817909121513367, 'eval_runtime': 3.816, 'eval_samples_per_second': 268.347, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.00537706958130002, 'eval_loss_2': 0.002440840005874634, 'eval_loss_3': -18.125030517578125, 'eval_loss_4': 0.39868441224098206, 'epoch': 29.65}
{'loss': 0.0062, 'grad_norm': 5.536055088043213, 'learning_rate': 3.6627906976744185e-07, 'loss_1': 0.0035891742445528507, 'loss_2': 0.00264739990234375, 'loss_3': -16.452905654907227, 'loss_4': 0.5208865404129028, 'epoch': 29.66}
{'loss': 0.0118, 'grad_norm': 6.6132941246032715, 'learning_rate': 3.604651162790698e-07, 'loss_1': 0.007176902610808611, 'loss_2': 0.004634857177734375, 'loss_3': -16.363557815551758, 'loss_4': 0.6674359440803528, 'epoch': 29.66}
{'loss': 0.0081, 'grad_norm': 4.590663433074951, 'learning_rate': 3.546511627906977e-07, 'loss_1': 0.0036086563486605883, 'loss_2': 0.00447845458984375, 'loss_3': -16.361303329467773, 'loss_4': 0.6128138303756714, 'epoch': 29.67}
{'loss': 0.0144, 'grad_norm': 9.750747680664062, 'learning_rate': 3.4883720930232557e-07, 'loss_1': 0.010812266729772091, 'loss_2': 0.0036373138427734375, 'loss_3': -16.47665786743164, 'loss_4': 0.730553388595581, 'epoch': 29.67}
{'loss': 0.0054, 'grad_norm': 4.417147159576416, 'learning_rate': 3.430232558139535e-07, 'loss_1': 0.0025102023500949144, 'loss_2': 0.002857208251953125, 'loss_3': -16.391029357910156, 'loss_4': 0.3458697199821472, 'epoch': 29.68}
[INFO|trainer.py:4228] 2025-01-21 14:26:06,052 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:06,052 >>   Batch size = 64
 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉  | 5110/5160 [2:06:10<00:52,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:13,424 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007801257073879242, 'eval_runtime': 3.8139, 'eval_samples_per_second': 268.494, 'eval_steps_per_second': 4.195, 'eval_loss_1': 0.005378834903240204, 'eval_loss_2': 0.002422422170639038, 'eval_loss_3': -18.124629974365234, 'eval_loss_4': 0.4013618528842926, 'epoch': 29.68}
{'loss': 0.005, 'grad_norm': 4.7371931076049805, 'learning_rate': 3.372093023255814e-07, 'loss_1': 0.003577217925339937, 'loss_2': 0.001399993896484375, 'loss_3': -16.307754516601562, 'loss_4': 0.30092331767082214, 'epoch': 29.69}
{'loss': 0.0043, 'grad_norm': 4.247333526611328, 'learning_rate': 3.313953488372093e-07, 'loss_1': 0.003526881104335189, 'loss_2': 0.00072479248046875, 'loss_3': -16.247783660888672, 'loss_4': 0.20098283886909485, 'epoch': 29.69}
{'loss': 0.0202, 'grad_norm': 6.297810077667236, 'learning_rate': 3.255813953488372e-07, 'loss_1': 0.010413739830255508, 'loss_2': 0.009796142578125, 'loss_3': -16.403701782226562, 'loss_4': 0.6060071587562561, 'epoch': 29.7}
{'loss': 0.0016, 'grad_norm': 4.49735689163208, 'learning_rate': 3.1976744186046514e-07, 'loss_1': 0.0011364181991666555, 'loss_2': 0.00041866302490234375, 'loss_3': -16.54784393310547, 'loss_4': 0.3307274580001831, 'epoch': 29.7}
{'loss': 0.0058, 'grad_norm': 4.24628210067749, 'learning_rate': 3.13953488372093e-07, 'loss_1': 0.0033388682641088963, 'loss_2': 0.00247955322265625, 'loss_3': -16.668066024780273, 'loss_4': 0.4479885995388031, 'epoch': 29.71}
[INFO|trainer.py:4228] 2025-01-21 14:26:13,424 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:13,424 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████  | 5115/5160 [2:06:17<00:46,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:20,784 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007810964249074459, 'eval_runtime': 3.8086, 'eval_samples_per_second': 268.863, 'eval_steps_per_second': 4.201, 'eval_loss_1': 0.005434273276478052, 'eval_loss_2': 0.0023766905069351196, 'eval_loss_3': -18.124374389648438, 'eval_loss_4': 0.4042849838733673, 'epoch': 29.71}
{'loss': 0.0153, 'grad_norm': 8.510640144348145, 'learning_rate': 3.081395348837209e-07, 'loss_1': 0.011912484653294086, 'loss_2': 0.003421783447265625, 'loss_3': -16.351560592651367, 'loss_4': 0.4058528542518616, 'epoch': 29.72}
{'loss': 0.0068, 'grad_norm': 4.9118332862854, 'learning_rate': 3.0232558139534886e-07, 'loss_1': 0.004839019384235144, 'loss_2': 0.001964569091796875, 'loss_3': -16.250516891479492, 'loss_4': 0.6301288604736328, 'epoch': 29.72}
{'loss': 0.0031, 'grad_norm': 4.7026801109313965, 'learning_rate': 2.9651162790697675e-07, 'loss_1': 0.001972293248400092, 'loss_2': 0.0011196136474609375, 'loss_3': -16.331031799316406, 'loss_4': 0.7902282476425171, 'epoch': 29.73}
{'loss': 0.0067, 'grad_norm': 5.254726886749268, 'learning_rate': 2.9069767441860464e-07, 'loss_1': 0.004090850707143545, 'loss_2': 0.0025882720947265625, 'loss_3': -16.1961612701416, 'loss_4': 0.4402099847793579, 'epoch': 29.73}
{'loss': 0.0113, 'grad_norm': 4.875598430633545, 'learning_rate': 2.8488372093023254e-07, 'loss_1': 0.004153548274189234, 'loss_2': 0.00717926025390625, 'loss_3': -16.3154296875, 'loss_4': 0.9115613102912903, 'epoch': 29.74}
[INFO|trainer.py:4228] 2025-01-21 14:26:20,785 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:20,785 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎ | 5120/5160 [2:06:25<00:41,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:28,139 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007811372168362141, 'eval_runtime': 3.8094, 'eval_samples_per_second': 268.811, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005464350339025259, 'eval_loss_2': 0.002347022294998169, 'eval_loss_3': -18.123964309692383, 'eval_loss_4': 0.4045534133911133, 'epoch': 29.74}
{'loss': 0.0044, 'grad_norm': 5.25960111618042, 'learning_rate': 2.790697674418605e-07, 'loss_1': 0.003411287907510996, 'loss_2': 0.0010042190551757812, 'loss_3': -16.410127639770508, 'loss_4': 0.38633573055267334, 'epoch': 29.74}
{'loss': 0.0135, 'grad_norm': 4.942563533782959, 'learning_rate': 2.7325581395348837e-07, 'loss_1': 0.0028758333064615726, 'loss_2': 0.01067352294921875, 'loss_3': -16.562519073486328, 'loss_4': 0.7657217979431152, 'epoch': 29.75}
{'loss': 0.0114, 'grad_norm': 6.012329578399658, 'learning_rate': 2.6744186046511626e-07, 'loss_1': 0.006544678471982479, 'loss_2': 0.004901885986328125, 'loss_3': -16.481082916259766, 'loss_4': 0.6679795980453491, 'epoch': 29.76}
{'loss': 0.0033, 'grad_norm': 4.749338626861572, 'learning_rate': 2.616279069767442e-07, 'loss_1': 0.0027375747449696064, 'loss_2': 0.0005702972412109375, 'loss_3': -16.521236419677734, 'loss_4': 0.25718623399734497, 'epoch': 29.76}
{'loss': 0.0072, 'grad_norm': 4.5981268882751465, 'learning_rate': 2.558139534883721e-07, 'loss_1': 0.00208459235727787, 'loss_2': 0.005161285400390625, 'loss_3': -16.353797912597656, 'loss_4': 0.567286491394043, 'epoch': 29.77}
[INFO|trainer.py:4228] 2025-01-21 14:26:28,139 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:28,139 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 5125/5160 [2:06:32<00:36,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:35,497 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007798138074576855, 'eval_runtime': 3.8075, 'eval_samples_per_second': 268.946, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005492018535733223, 'eval_loss_2': 0.002306118607521057, 'eval_loss_3': -18.123714447021484, 'eval_loss_4': 0.4035569429397583, 'epoch': 29.77}
{'loss': 0.0034, 'grad_norm': 4.768270969390869, 'learning_rate': 2.5e-07, 'loss_1': 0.0030068743508309126, 'loss_2': 0.0003895759582519531, 'loss_3': -16.15563201904297, 'loss_4': 0.5001665949821472, 'epoch': 29.77}
{'loss': 0.0265, 'grad_norm': 17.269113540649414, 'learning_rate': 2.4418604651162793e-07, 'loss_1': 0.020730964839458466, 'loss_2': 0.00579833984375, 'loss_3': -16.231969833374023, 'loss_4': 0.41457799077033997, 'epoch': 29.78}
{'loss': 0.0049, 'grad_norm': 5.085330009460449, 'learning_rate': 2.3837209302325582e-07, 'loss_1': 0.004823267459869385, 'loss_2': 4.1365623474121094e-05, 'loss_3': -16.265527725219727, 'loss_4': 0.45663338899612427, 'epoch': 29.78}
{'loss': 0.0022, 'grad_norm': 4.8563313484191895, 'learning_rate': 2.3255813953488372e-07, 'loss_1': 0.002148495754227042, 'loss_2': 1.1324882507324219e-05, 'loss_3': -16.511377334594727, 'loss_4': 0.4897973835468292, 'epoch': 29.79}
{'loss': 0.0064, 'grad_norm': 4.693929195404053, 'learning_rate': 2.2674418604651163e-07, 'loss_1': 0.003074354026466608, 'loss_2': 0.00336456298828125, 'loss_3': -16.287967681884766, 'loss_4': 0.32281219959259033, 'epoch': 29.8}
[INFO|trainer.py:4228] 2025-01-21 14:26:35,497 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:35,497 >>   Batch size = 64
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋ | 5130/5160 [2:06:40<00:31,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:42,858 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007786125410348177, 'eval_runtime': 3.8098, 'eval_samples_per_second': 268.782, 'eval_steps_per_second': 4.2, 'eval_loss_1': 0.005487948656082153, 'eval_loss_2': 0.0022981762886047363, 'eval_loss_3': -18.123933792114258, 'eval_loss_4': 0.4013570547103882, 'epoch': 29.8}
{'loss': 0.0064, 'grad_norm': 5.615555763244629, 'learning_rate': 2.2093023255813952e-07, 'loss_1': 0.004039442632347345, 'loss_2': 0.0023651123046875, 'loss_3': -16.514171600341797, 'loss_4': 0.5487060546875, 'epoch': 29.8}
{'loss': 0.0115, 'grad_norm': 4.710190773010254, 'learning_rate': 2.1511627906976744e-07, 'loss_1': 0.003365086391568184, 'loss_2': 0.00811004638671875, 'loss_3': -16.420166015625, 'loss_4': 0.505233883857727, 'epoch': 29.81}
{'loss': 0.0033, 'grad_norm': 4.917698860168457, 'learning_rate': 2.0930232558139536e-07, 'loss_1': 0.002579679014161229, 'loss_2': 0.000732421875, 'loss_3': -16.288469314575195, 'loss_4': 0.2944656014442444, 'epoch': 29.81}
{'loss': 0.0079, 'grad_norm': 4.5972771644592285, 'learning_rate': 2.0348837209302325e-07, 'loss_1': 0.004151882138103247, 'loss_2': 0.0037689208984375, 'loss_3': -16.423280715942383, 'loss_4': 0.8047696352005005, 'epoch': 29.82}
{'loss': 0.0117, 'grad_norm': 6.079015731811523, 'learning_rate': 1.9767441860465117e-07, 'loss_1': 0.007819967344403267, 'loss_2': 0.00391387939453125, 'loss_3': -16.241802215576172, 'loss_4': 0.35384270548820496, 'epoch': 29.83}
[INFO|trainer.py:4228] 2025-01-21 14:26:42,858 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:42,858 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 5135/5160 [2:06:47<00:26,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:50,228 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007777207996696234, 'eval_runtime': 3.8154, 'eval_samples_per_second': 268.384, 'eval_steps_per_second': 4.193, 'eval_loss_1': 0.005480805411934853, 'eval_loss_2': 0.0022964030504226685, 'eval_loss_3': -18.123823165893555, 'eval_loss_4': 0.39859166741371155, 'epoch': 29.83}
{'loss': 0.003, 'grad_norm': 4.403359889984131, 'learning_rate': 1.9186046511627906e-07, 'loss_1': 0.00281006982550025, 'loss_2': 0.00017690658569335938, 'loss_3': -16.208938598632812, 'loss_4': 0.2556226849555969, 'epoch': 29.83}
{'loss': 0.0091, 'grad_norm': 5.236827373504639, 'learning_rate': 1.8604651162790698e-07, 'loss_1': 0.006748227868229151, 'loss_2': 0.002399444580078125, 'loss_3': -16.323183059692383, 'loss_4': 0.22328978776931763, 'epoch': 29.84}
{'loss': 0.0084, 'grad_norm': 5.336330890655518, 'learning_rate': 1.802325581395349e-07, 'loss_1': 0.006552729289978743, 'loss_2': 0.0018367767333984375, 'loss_3': -16.329496383666992, 'loss_4': 0.6426510214805603, 'epoch': 29.84}
{'loss': 0.0078, 'grad_norm': 4.440316677093506, 'learning_rate': 1.7441860465116279e-07, 'loss_1': 0.002624728949740529, 'loss_2': 0.005222320556640625, 'loss_3': -16.49078941345215, 'loss_4': 0.18248222768306732, 'epoch': 29.85}
{'loss': 0.0084, 'grad_norm': 5.37568473815918, 'learning_rate': 1.686046511627907e-07, 'loss_1': 0.0033101197332143784, 'loss_2': 0.00504302978515625, 'loss_3': -16.472713470458984, 'loss_4': 0.35878610610961914, 'epoch': 29.85}
[INFO|trainer.py:4228] 2025-01-21 14:26:50,229 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:50,229 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏| 5140/5160 [2:06:54<00:20,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:26:57,586 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007831940427422523, 'eval_runtime': 3.8081, 'eval_samples_per_second': 268.904, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005518975667655468, 'eval_loss_2': 0.00231296569108963, 'eval_loss_3': -18.12273406982422, 'eval_loss_4': 0.39556461572647095, 'epoch': 29.85}
{'loss': 0.0121, 'grad_norm': 5.287166118621826, 'learning_rate': 1.627906976744186e-07, 'loss_1': 0.00863654911518097, 'loss_2': 0.003429412841796875, 'loss_3': -16.46005630493164, 'loss_4': 0.2822657823562622, 'epoch': 29.86}
{'loss': 0.0135, 'grad_norm': 5.559003829956055, 'learning_rate': 1.569767441860465e-07, 'loss_1': 0.006802198011428118, 'loss_2': 0.006744384765625, 'loss_3': -16.619741439819336, 'loss_4': 0.7677544355392456, 'epoch': 29.87}
{'loss': 0.008, 'grad_norm': 6.84369421005249, 'learning_rate': 1.5116279069767443e-07, 'loss_1': 0.005675677675753832, 'loss_2': 0.00237274169921875, 'loss_3': -16.171972274780273, 'loss_4': 0.43278566002845764, 'epoch': 29.87}
{'loss': 0.008, 'grad_norm': 4.307251930236816, 'learning_rate': 1.4534883720930232e-07, 'loss_1': 0.002670380286872387, 'loss_2': 0.00528717041015625, 'loss_3': -16.212984085083008, 'loss_4': 0.06549397855997086, 'epoch': 29.88}
{'loss': 0.0065, 'grad_norm': 5.334556579589844, 'learning_rate': 1.3953488372093024e-07, 'loss_1': 0.00404779938980937, 'loss_2': 0.002498626708984375, 'loss_3': -16.27198028564453, 'loss_4': 0.4478786885738373, 'epoch': 29.88}
[INFO|trainer.py:4228] 2025-01-21 14:26:57,586 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:26:57,586 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 5145/5160 [2:07:02<00:15,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:04,943 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007853597402572632, 'eval_runtime': 3.8065, 'eval_samples_per_second': 269.011, 'eval_steps_per_second': 4.203, 'eval_loss_1': 0.005529478192329407, 'eval_loss_2': 0.002324119210243225, 'eval_loss_3': -18.122243881225586, 'eval_loss_4': 0.3946576714515686, 'epoch': 29.88}
{'loss': 0.0119, 'grad_norm': 5.1632466316223145, 'learning_rate': 1.3372093023255813e-07, 'loss_1': 0.007960129529237747, 'loss_2': 0.0039825439453125, 'loss_3': -16.41230010986328, 'loss_4': 0.20809690654277802, 'epoch': 29.89}
{'loss': 0.0098, 'grad_norm': 6.032425880432129, 'learning_rate': 1.2790697674418605e-07, 'loss_1': 0.009415123611688614, 'loss_2': 0.00041484832763671875, 'loss_3': -16.328235626220703, 'loss_4': 0.15323679149150848, 'epoch': 29.9}
{'loss': 0.0171, 'grad_norm': 12.205286979675293, 'learning_rate': 1.2209302325581397e-07, 'loss_1': 0.01661130227148533, 'loss_2': 0.00048232078552246094, 'loss_3': -16.356300354003906, 'loss_4': 0.17871510982513428, 'epoch': 29.9}
{'loss': 0.0052, 'grad_norm': 4.607733726501465, 'learning_rate': 1.1627906976744186e-07, 'loss_1': 0.004634397104382515, 'loss_2': 0.0005388259887695312, 'loss_3': -16.441499710083008, 'loss_4': 0.6048774123191833, 'epoch': 29.91}
{'loss': 0.0035, 'grad_norm': 4.070066928863525, 'learning_rate': 1.1046511627906976e-07, 'loss_1': 0.0025475164875388145, 'loss_2': 0.0009813308715820312, 'loss_3': -16.25775909423828, 'loss_4': 0.4720485210418701, 'epoch': 29.91}
[INFO|trainer.py:4228] 2025-01-21 14:27:04,943 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:04,943 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌| 5150/5160 [2:07:09<00:10,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:12,306 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007905984297394753, 'eval_runtime': 3.8073, 'eval_samples_per_second': 268.958, 'eval_steps_per_second': 4.202, 'eval_loss_1': 0.005572654772549868, 'eval_loss_2': 0.002333328127861023, 'eval_loss_3': -18.121753692626953, 'eval_loss_4': 0.3948250412940979, 'epoch': 29.91}
{'loss': 0.0136, 'grad_norm': 5.963174343109131, 'learning_rate': 1.0465116279069768e-07, 'loss_1': 0.005960395559668541, 'loss_2': 0.007617950439453125, 'loss_3': -16.458988189697266, 'loss_4': 0.5270102024078369, 'epoch': 29.92}
{'loss': 0.0098, 'grad_norm': 5.116158485412598, 'learning_rate': 9.883720930232558e-08, 'loss_1': 0.00447642058134079, 'loss_2': 0.0053253173828125, 'loss_3': -16.587322235107422, 'loss_4': 0.6425714492797852, 'epoch': 29.92}
{'loss': 0.0061, 'grad_norm': 5.492434978485107, 'learning_rate': 9.302325581395349e-08, 'loss_1': 0.005317686125636101, 'loss_2': 0.0008249282836914062, 'loss_3': -16.2214412689209, 'loss_4': 0.3104897737503052, 'epoch': 29.93}
{'loss': 0.0074, 'grad_norm': 4.442555904388428, 'learning_rate': 8.720930232558139e-08, 'loss_1': 0.004837708547711372, 'loss_2': 0.0025272369384765625, 'loss_3': -16.341325759887695, 'loss_4': 0.49452143907546997, 'epoch': 29.94}
{'loss': 0.0047, 'grad_norm': 4.666384696960449, 'learning_rate': 8.13953488372093e-08, 'loss_1': 0.0033199551980942488, 'loss_2': 0.0014009475708007812, 'loss_3': -16.562915802001953, 'loss_4': 0.3687615990638733, 'epoch': 29.94}
[INFO|trainer.py:4228] 2025-01-21 14:27:12,306 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:12,306 >>   Batch size = 64
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊| 5155/5160 [2:07:16<00:05,  1.04s/it][INFO|trainer.py:4226] 2025-01-21 14:27:19,677 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007920433767139912, 'eval_runtime': 3.8106, 'eval_samples_per_second': 268.726, 'eval_steps_per_second': 4.199, 'eval_loss_1': 0.005591069348156452, 'eval_loss_2': 0.0023293644189834595, 'eval_loss_3': -18.12181282043457, 'eval_loss_4': 0.39448782801628113, 'epoch': 29.94}
{'loss': 0.0108, 'grad_norm': 5.384612083435059, 'learning_rate': 7.558139534883722e-08, 'loss_1': 0.008883052505552769, 'loss_2': 0.001934051513671875, 'loss_3': -16.329050064086914, 'loss_4': 0.40762394666671753, 'epoch': 29.95}
{'loss': 0.0086, 'grad_norm': 5.773909091949463, 'learning_rate': 6.976744186046512e-08, 'loss_1': 0.005872388370335102, 'loss_2': 0.00267791748046875, 'loss_3': -16.49020004272461, 'loss_4': 0.6067200899124146, 'epoch': 29.95}
{'loss': 0.0085, 'grad_norm': 5.21497106552124, 'learning_rate': 6.395348837209302e-08, 'loss_1': 0.004416438285261393, 'loss_2': 0.004058837890625, 'loss_3': -16.306781768798828, 'loss_4': 0.7305417656898499, 'epoch': 29.96}
{'loss': 0.0044, 'grad_norm': 4.605567455291748, 'learning_rate': 5.813953488372093e-08, 'loss_1': 0.002314514247700572, 'loss_2': 0.00206756591796875, 'loss_3': -16.37518310546875, 'loss_4': 0.729691743850708, 'epoch': 29.97}
{'loss': 0.0038, 'grad_norm': 4.588700294494629, 'learning_rate': 5.232558139534884e-08, 'loss_1': 0.002536121290177107, 'loss_2': 0.00128173828125, 'loss_3': -16.47418785095215, 'loss_4': 0.47390738129615784, 'epoch': 29.97}
[INFO|trainer.py:4228] 2025-01-21 14:27:19,677 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:19,677 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:23<00:00,  1.07it/s][INFO|trainer.py:4226] 2025-01-21 14:27:26,687 >>
***** Running Evaluation *****                                                                                                                                                                                                                                        
{'eval_loss': 0.007913815788924694, 'eval_runtime': 3.8113, 'eval_samples_per_second': 268.678, 'eval_steps_per_second': 4.198, 'eval_loss_1': 0.005586463026702404, 'eval_loss_2': 0.00232735276222229, 'eval_loss_3': -18.121858596801758, 'eval_loss_4': 0.3940514922142029, 'epoch': 29.97}
{'loss': 0.0093, 'grad_norm': 6.414769649505615, 'learning_rate': 4.6511627906976744e-08, 'loss_1': 0.006929438095539808, 'loss_2': 0.00241851806640625, 'loss_3': -16.361553192138672, 'loss_4': 0.4904114603996277, 'epoch': 29.98}
{'loss': 0.01, 'grad_norm': 5.974214553833008, 'learning_rate': 4.069767441860465e-08, 'loss_1': 0.005485324654728174, 'loss_2': 0.0045166015625, 'loss_3': -16.32560157775879, 'loss_4': 0.9143978357315063, 'epoch': 29.98}
{'loss': 0.0066, 'grad_norm': 5.074524879455566, 'learning_rate': 3.488372093023256e-08, 'loss_1': 0.004396537318825722, 'loss_2': 0.002193450927734375, 'loss_3': -16.171161651611328, 'loss_4': 0.371257483959198, 'epoch': 29.99}
{'loss': 0.0069, 'grad_norm': 4.953159809112549, 'learning_rate': 2.9069767441860464e-08, 'loss_1': 0.004729158245027065, 'loss_2': 0.002147674560546875, 'loss_3': -16.170272827148438, 'loss_4': 0.637523889541626, 'epoch': 29.99}
{'loss': 0.0124, 'grad_norm': 6.678821563720703, 'learning_rate': 2.3255813953488372e-08, 'loss_1': 0.001777265453711152, 'loss_2': 0.0106201171875, 'loss_3': -16.285472869873047, 'loss_4': 0.13510480523109436, 'epoch': 30.0}
[INFO|trainer.py:4228] 2025-01-21 14:27:26,687 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:26,688 >>   Batch size = 64
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:27<00:00,  1.07it/s][INFO|trainer.py:2643] 2025-01-21 14:27:30,502 >>
                                                                                                                                                                                                                                                                      
{'eval_loss': 0.007905088365077972, 'eval_runtime': 3.8133, 'eval_samples_per_second': 268.537, 'eval_steps_per_second': 4.196, 'eval_loss_1': 0.005564772058278322, 'eval_loss_2': 0.0023403167724609375, 'eval_loss_3': -18.121923446655273, 'eval_loss_4': 0.3942650854587555, 'epoch': 30.0}
Training completed. Do not forget to share your model on huggingface.co/models =)


[INFO|trainer.py:2881] 2025-01-21 14:27:30,502 >> Loading best model from SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/checkpoint-4315 (score: 0.005828141234815121).
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5160/5160 [2:07:27<00:00,  1.48s/it]
{'train_runtime': 7648.7399, 'train_samples_per_second': 43.058, 'train_steps_per_second': 0.675, 'train_loss': 0.036809380951517104, 'epoch': 30.0}
[INFO|trainer.py:3910] 2025-01-21 14:27:30,583 >> Saving model checkpoint to SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32
[INFO|configuration_utils.py:420] 2025-01-21 14:27:30,584 >> Configuration saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/config.json
[INFO|modeling_utils.py:2988] 2025-01-21 14:27:31,073 >> Model weights saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/model.safetensors
[INFO|tokenization_utils_base.py:2491] 2025-01-21 14:27:31,075 >> tokenizer config file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/tokenizer_config.json
[INFO|tokenization_utils_base.py:2500] 2025-01-21 14:27:31,075 >> Special tokens file saved in SimCSE/result/twitter-roberta-base-sentiment/end2end-c4-loss_cl2_gr-wneg32/special_tokens_map.json
01/21/2025 14:27:31 - INFO - __main__ -   ***** Train results *****
01/21/2025 14:27:31 - INFO - __main__ -     epoch = 30.0
01/21/2025 14:27:31 - INFO - __main__ -     total_flos = 1.645885589078016e+17
01/21/2025 14:27:31 - INFO - __main__ -     train_loss = 0.036809380951517104
01/21/2025 14:27:31 - INFO - __main__ -     train_runtime = 7648.7399
01/21/2025 14:27:31 - INFO - __main__ -     train_samples_per_second = 43.058
01/21/2025 14:27:31 - INFO - __main__ -     train_steps_per_second = 0.675
01/21/2025 14:27:31 - INFO - __main__ -   *** Evaluate ***
[INFO|trainer.py:4226] 2025-01-21 14:27:31,291 >>
***** Running Evaluation *****
[INFO|trainer.py:4228] 2025-01-21 14:27:31,291 >>   Num examples = 1024
[INFO|trainer.py:4231] 2025-01-21 14:27:31,291 >>   Batch size = 64
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  4.53it/s]
01/21/2025 14:27:35 - INFO - __main__ -   ***** Eval results *****
01/21/2025 14:27:35 - INFO - __main__ -     epoch = 30.0
01/21/2025 14:27:35 - INFO - __main__ -     eval_loss = 0.005828141234815121
01/21/2025 14:27:35 - INFO - __main__ -     eval_loss_1 = 0.0035548058804124594
01/21/2025 14:27:35 - INFO - __main__ -     eval_loss_2 = 0.0022733360528945923
01/21/2025 14:27:35 - INFO - __main__ -     eval_loss_3 = -18.18364906311035
01/21/2025 14:27:35 - INFO - __main__ -     eval_loss_4 = 0.918878436088562
01/21/2025 14:27:35 - INFO - __main__ -     eval_runtime = 3.813
01/21/2025 14:27:35 - INFO - __main__ -     eval_samples_per_second = 268.554
01/21/2025 14:27:35 - INFO - __main__ -     eval_steps_per_second = 4.196
